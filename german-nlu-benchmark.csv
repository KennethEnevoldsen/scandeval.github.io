rank,model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,de_score,germeval,sb10k,scala_de,germanquad
1,deepset/gbert-large,336.0,31,512,5463,64.31,64.31,80.99,66.16,77.48,32.63
1,google/rembert,576.0,250,256,3355,61.07,61.07,77.85,59.69,72.25,34.48
2,microsoft/mdeberta-v3-base,279.0,251,512,9237,59.47,59.47,80.3,59.5,71.84,26.25
3,xlm-roberta-large,560.0,250,512,4744,58.0,58.0,79.2,58.44,62.12,32.23
3,sentence-transformers/use-cmlm-multilingual,471.0,501,512,13305,57.4,57.4,78.42,59.17,61.58,30.42
4,deepset/gbert-base,110.0,31,512,10570,55.21,55.21,80.25,57.77,66.13,16.68
5,dbmdz/bert-base-german-uncased,110.0,31,512,11438,54.11,54.11,78.08,56.26,68.22,13.87
5,dbmdz/bert-base-german-cased,110.0,31,512,11844,53.51,53.51,79.02,53.44,67.08,14.49
6,setu4993/LaBSE,471.0,501,512,13386,53.3,53.3,77.93,58.2,53.53,23.55
7,ZurichNLP/unsup-simcse-xlm-roberta-base,278.0,250,512,10471,50.99,50.99,75.98,57.27,52.46,18.24
8,cardiffnlp/twitter-xlm-roberta-base,278.0,250,512,10116,47.2,47.2,74.67,63.32,49.39,1.43
9,facebook/xlm-v-base,778.0,902,512,13135,46.92,46.92,74.43,57.43,35.0,20.81
10,jhu-clsp/bernice,278.0,250,128,5567,45.29,45.29,71.08,62.0,48.1,0.0
11,"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,42.72,42.72,46.22,55.5,38.96,30.2
12,Twitter/twhin-bert-large,561.0,250,512,5299,42.53,42.53,74.0,55.04,29.15,11.93
13,clips/mfaq,278.0,250,128,5591,42.51,42.51,76.46,59.51,32.54,1.53
14,microsoft/xlm-align-base,278.0,250,512,9943,42.46,42.46,79.33,58.58,15.34,16.58
14,microsoft/infoxlm-base,278.0,250,512,9814,42.35,42.35,79.61,58.3,11.85,19.63
15,sentence-transformers/paraphrase-xlm-r-multilingual-v1,278.0,250,512,14994,41.73,41.73,70.17,57.71,38.75,0.3
16,dbmdz/bert-base-historic-multilingual-cased,111.0,32,512,15165,40.56,40.56,64.92,41.36,48.21,7.75
17,sentence-transformers/stsb-xlm-r-multilingual,278.0,250,512,15040,39.02,39.02,68.22,52.68,34.44,0.73
17,sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118.0,250,512,17428,38.12,38.12,64.02,55.6,32.22,0.64
18,sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking,135.0,120,512,26151,33.01,33.01,64.45,49.61,17.6,0.36
19,mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2451,31.91,31.91,33.5,54.31,23.12,16.71
20,sentence-transformers/distiluse-base-multilingual-cased-v1,135.0,120,512,26344,31.76,31.76,52.79,53.53,20.15,0.58
21,sentence-transformers/distiluse-base-multilingual-cased-v2,135.0,120,512,17807,30.54,30.54,52.41,51.94,17.74,0.06
21,3ebdola/Dialectal-Arabic-XLM-R-Base,278.0,250,512,15177,17.51,17.51,33.53,34.81,1.25,0.46
22,fresh-electra-small,14.0,31,512,2237,4.83,4.83,9.75,9.76,-0.18,0.0
