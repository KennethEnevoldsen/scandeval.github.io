model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,conll_nl_rank,dutch_social_rank,scala_nl_rank,squad_nl_rank,wiki_lingua_nl_rank,mmlu_nl_rank,hellaswag_nl_rank,nl_rank,conll_nl,dutch_social,scala_nl,squad_nl,wiki_lingua_nl,mmlu_nl,hellaswag_nl
"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,1.23,1.0,2.3745592591728197,1.0,1.0,1.251961026834651,1.0,1.0,1.23,68.96,8.81,58.95,55.57,69.13,42.28,61.52
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,1.59,1.218964447596053,1.7649485639579274,2.935414304995834,1.3108579173516375,1.0,1.0,1.8817477937403,1.59,63.53,11.25,27.76,50.88,71.2,40.23,47.87
BramVanroy/GEITje-7B-ultra (few-shot),7242.0,32,8192,2475,2.12,2.0770784863901977,1.0,3.7579837947923598,1.1844312717285304,1.3527144772696575,2.151943885031869,3.312807055729582,2.12,42.25,12.78,18.23,53.44,68.3,26.92,25.72
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,2.17,1.4358940930065476,1.7649485639579274,3.563046704327619,1.3108579173516375,1.3527144772696575,2.4671785588270985,3.312807055729582,2.17,55.56,12.37,21.5,50.8,67.98,22.86,24.8
mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,2.28,1.4358940930065476,2.8972983811368618,3.2959179853095084,1.3108579173516375,1.779958196581118,1.5521669011762294,3.6652531911559856,2.28,58.15,7.94,25.41,50.14,64.24,35.49,19.88
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,2.33,1.4358940930065476,2.3745592591728197,3.7579837947923598,1.0,1.6061073727057238,2.319547097523889,3.8169127011491906,2.33,57.66,8.41,16.93,56.29,66.22,25.7,17.92
Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,2.45,1.8644447218694395,3.5714897654753095,2.935414304995834,1.0,1.4391938356616663,2.151943885031869,4.218840965862539,2.45,47.53,4.36,30.67,56.55,67.58,28.12,11.7
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,2.52,1.654797732637806,2.8972983811368618,3.7579837947923598,1.1844312717285304,1.779958196581118,2.319547097523889,4.0530825944668925,2.52,52.72,7.91,18.14,52.74,64.8,26.06,14.26
meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,2.53,1.654797732637806,2.3745592591728197,4.026917203242985,1.1844312717285304,1.4391938356616663,2.7977085636467542,4.218840965862539,2.53,50.23,10.07,14.73,53.41,67.59,20.19,11.42
01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,2.63,1.8644447218694395,2.3745592591728197,4.974743061063504,1.0,2.468604741922928,2.053460907192736,3.6652531911559856,2.63,46.34,8.96,0.88,55.24,58.35,29.33,20.27
Qwen/Qwen1.5-4B-Chat (few-shot),3950.0,152,32768,4347,2.69,3.6795987287605176,1.0,4.753683897298722,1.0814361293932255,2.0297880809320725,2.4671785588270985,3.8169127011491906,2.69,1.02,14.68,4.07,55.18,62.75,24.25,16.21
meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,2.92,2.0770784863901977,2.8972983811368618,3.7579837947923598,2.120227421197096,2.0297880809320725,3.0276952179254155,4.542851676973941,2.92,40.49,7.1,18.66,37.51,62.58,17.36,6.68
Qwen/Qwen1.5-4B (few-shot),3950.0,152,32768,3248,2.98,3.6795987287605176,1.7649485639579274,4.974743061063504,1.3108579173516375,2.468604741922928,2.6334893244235453,4.0530825944668925,2.98,1.05,12.55,0.23,51.3,58.9,22.2,13.11
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,2.99,2.3499303018966966,1.0,4.753683897298722,1.6801794110532207,2.468604741922928,3.834880088555319,4.864730753266393,2.99,35.3,15.67,1.76,45.05,59.15,6.24,0.47
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,3.14,2.3499303018966966,1.7649485639579274,4.753683897298722,2.120227421197096,2.0297880809320725,4.000019085940293,4.964877205671865,3.14,35.49,11.36,2.52,37.61,62.24,5.41,0.15
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837.0,152,32768,8304,3.41,3.6795987287605176,2.8972983811368618,4.753683897298722,2.2983321582126006,2.2522377138351213,3.454367188106316,4.542851676973941,3.41,2.22,6.82,4.11,33.1,60.92,12.11,6.41
Qwen/Qwen1.5-0.5B-Chat (few-shot),620.0,152,32768,11740,3.57,3.6795987287605176,2.3745592591728197,4.974743061063504,2.7705404098820106,2.0297880809320725,4.2702713126083855,4.864730753266393,3.57,2.52,8.59,0.34,26.61,62.39,2.09,1.44
Qwen/Qwen1.5-1.8B (few-shot),1837.0,152,32768,5666,3.59,3.6795987287605176,3.5714897654753095,4.753683897298722,2.2983321582126006,2.9742099447373898,3.3371559868842082,4.542851676973941,3.59,1.44,5.2,2.89,34.6,55.0,13.56,5.89
Qwen/Qwen1.5-0.5B (few-shot),620.0,152,32768,11371,3.76,3.475691958539001,3.5714897654753095,4.974743061063504,3.1138222680100793,2.468604741922928,3.834880088555319,4.864730753266393,3.76,7.57,4.54,-0.42,20.81,58.4,7.44,1.7
RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,4.19,3.776868969265791,4.615531741019747,4.974743061063504,4.344222359759462,2.2522377138351213,4.43067273430224,4.964877205671865,4.19,0.0,0.95,0.0,0.0,60.14,0.11,-0.13
ai-forever/mGPT (few-shot),unknown,100,1024,13551,4.61,3.776868969265791,5.011646316041201,5.101629033795316,3.1138222680100793,5.997501215940061,4.2702713126083855,4.964877205671865,4.61,0.11,-0.67,-0.97,0.29,30.2,1.45,-0.56
