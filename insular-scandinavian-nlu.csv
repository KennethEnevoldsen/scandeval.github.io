rank,model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,mim_gold_ner_score,scala_is_score,nqii_score,fone_score,scala_fo_score,is_score,fo_score,mim_gold_ner,scala_is,nqii,fone,scala_fo
1,vesteinn/FoBERT,124.0,50,512,15623,93.89,100.0,80,83.33,100,100.0,87.78,100.0,85.04,50.78,17.76,91.31,64.39
2,microsoft/mdeberta-v3-base,278.0,251,512,9237,92.1,91.3,90,100.0,92,88.89,93.77,90.44,81.12,54.11,30.93,88.6,46.81
3,vesteinn/ScandiBERT-no-faroese,124.0,50,512,15436,88.87,95.65,100,88.89,88,77.78,94.85,82.89,83.94,58.64,25.35,88.14,27.71
4,mideind/IceBERT-xlmr-ic3,277.0,250,512,11004,84.89,100.0,100,66.67,84,77.78,88.89,80.89,84.35,59.12,11.18,87.79,22.51
5,NbAiLab/nb-roberta-base-scandi-1e4,277.0,250,512,15074,83.1,91.3,80,50.0,96,88.89,73.77,92.44,81.83,51.09,6.66,90.52,44.99
6,sentence-transformers/use-cmlm-multilingual,470.0,501,512,13305,82.29,91.3,70,77.78,92,77.78,79.69,84.89,80.91,41.91,13.73,88.81,30.92
7,google/rembert,575.0,250,256,3355,82.16,86.96,80,100.0,84,66.67,88.99,75.34,78.05,48.29,29.38,87.35,14.65
8,mideind/IceBERT-large,406.0,50,512,5677,82.04,100.0,100,72.22,80,66.67,90.74,73.34,85.14,59.31,12.84,86.84,9.82
8,mideind/IceBERT,124.0,50,512,16697,82.04,100.0,100,72.22,80,66.67,90.74,73.34,85.32,60.44,13.31,86.5,10.13
9,setu4993/LaBSE,470.0,501,512,13386,80.44,91.3,70,66.67,92,77.78,75.99,84.89,80.45,36.92,11.75,89.16,22.76
10,pere/roberta-base-exp-32,277.0,250,512,15081,79.65,95.65,60,55.56,100,77.78,70.4,88.89,83.57,23.07,7.81,90.6,22.86
11,jonfd/electra-small-nordic,22.0,96,128,5989,77.22,82.61,100,50.0,76,77.78,77.54,76.89,77.4,60.64,6.51,85.8,30.88
12,vesteinn/XLMR-ENIS,125.0,50,512,10711,77.12,95.65,80,94.44,84,44.44,90.03,64.22,82.2,48.51,27.06,87.09,3.09
13,mideind/IceBERT-ic3,124.0,50,512,12119,76.0,100.0,80,66.67,84,55.56,82.22,69.78,85.03,45.06,10.82,87.22,6.23
14,vesteinn/IceBERT,163.0,50,512,12360,75.81,100.0,90,72.22,84,44.44,87.41,64.22,85.34,55.88,13.31,87.13,3.66
15,mideind/IceBERT-igc,124.0,50,512,12551,70.57,86.96,90,61.11,68,55.56,79.36,61.78,79.85,54.38,9.91,83.82,4.93
16,xlm-roberta-large,559.0,250,512,6663,69.23,95.65,60,77.78,88,33.33,77.81,60.66,82.83,22.78,15.72,87.85,1.17
17,intfloat/multilingual-e5-large,559.0,250,512,6732,67.23,86.96,40,77.78,88,44.44,68.25,66.22,78.43,10.78,13.79,88.39,2.85
18,Geotrend/bert-base-25lang-cased,151.0,85,512,13908,64.9,78.26,30,61.11,80,66.67,56.46,73.34,74.65,2.89,9.29,86.09,15.24
19,"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,64.4,73.91,40,94.44,52,66.67,69.45,59.34,69.59,7.28,28.5,72.48,8.29
20,mideind/IceBERT-mC4-is,163.0,50,512,12308,62.42,86.96,50,5.56,88,66.67,47.51,77.34,79.19,20.95,0.0,88.44,11.83
21,Geotrend/bert-base-da-cased,103.0,23,512,15432,61.93,78.26,40,66.67,80,44.44,61.64,62.22,73.81,6.23,10.57,86.62,3.64
22,microsoft/xlm-align-base,277.0,250,512,14744,60.6,86.96,40,66.67,80,33.33,64.54,56.66,78.01,5.92,10.47,85.97,0.02
23,AI-Sweden-Models/roberta-large-1160k,354.0,50,512,5741,59.48,78.26,30,66.67,88,33.33,58.31,60.66,74.3,2.06,11.47,88.24,1.73
24,NbAiLab/nb-roberta-base-scandinavian,125.0,50,512,14051,58.82,69.57,30,50.0,80,55.56,49.86,67.78,69.04,3.34,7.17,86.1,6.28
25,cardiffnlp/twitter-xlm-roberta-base,277.0,250,512,14837,56.91,73.91,60,55.56,68,33.33,63.16,50.66,72.69,28.72,8.46,83.96,1.05
26,KBLab/megatron-bert-large-swedish-cased-165k,369.0,64,512,7138,55.03,60.87,40,50.0,64,55.56,50.29,59.78,63.35,4.94,7.02,82.76,7.58
27,bert-base-multilingual-uncased,167.0,106,512,13993,54.83,56.52,50,61.11,52,55.56,55.88,53.78,60.88,13.5,9.65,73.06,5.48
28,microsoft/infoxlm-base,277.0,250,512,14918,54.61,82.61,20,61.11,76,33.33,54.57,54.66,77.09,1.71,8.56,85.58,0.35
29,KennethEnevoldsen/dfm-sentence-encoder-medium-2,124.0,50,512,14965,54.42,65.22,20,66.67,72,44.44,50.63,58.22,64.57,0.86,10.76,84.72,3.79
30,KBLab/megatron-bert-large-swedish-cased-110k,369.0,64,512,7075,54.3,60.87,30,55.56,64,55.56,48.81,59.78,63.11,3.47,7.76,82.36,5.2
31,KennethEnevoldsen/dfm-sentence-encoder-medium,124.0,50,512,14998,53.69,65.22,10,72.22,72,44.44,49.15,58.22,64.88,-0.6,12.39,84.92,2.96
32,Twitter/twhin-bert-large,560.0,250,512,5299,52.91,73.91,30,55.56,72,33.33,53.16,52.66,71.48,2.2,8.19,84.73,1.37
33,vesteinn/DanskBERT,124.0,50,512,15749,52.76,65.22,10,66.67,72,44.44,47.3,58.22,65.29,-0.03,10.49,85.04,4.48
34,flax-community/nordic-roberta-wiki,124.0,50,512,16227,52.44,60.87,30,44.44,64,55.56,45.1,59.78,63.31,2.47,5.99,82.64,8.03
35,KennethEnevoldsen/dfm-sentence-encoder-large-1,354.0,50,512,6245,51.17,43.48,30,55.56,52,66.67,43.01,59.34,48.31,3.18,7.94,72.99,13.4
36,patrickvonplaten/norwegian-roberta-base,124.0,50,512,15698,50.98,56.52,20,50.0,64,55.56,42.17,59.78,60.79,1.29,6.64,82.57,5.74
37,sentence-transformers/stsb-xlm-r-multilingual,277.0,250,512,15040,50.83,65.22,10,61.11,68,44.44,45.44,56.22,66.23,0.04,10.04,82.97,2.93
38,DeepPavlov/rubert-base-cased,177.0,120,512,15785,50.66,60.87,30,44.44,68,44.44,45.1,56.22,61.95,2.4,6.04,83.15,3.21
39,flax-community/swe-roberta-wiki-oscar,124.0,50,512,15437,48.85,60.87,20,38.89,60,55.56,39.92,57.78,62.23,1.45,5.52,80.52,6.51
40,mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,48.43,43.48,20,94.44,44,44.44,52.64,44.22,47.24,1.35,26.26,62.63,2.84
41,sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118.0,250,512,17428,47.81,60.87,30,33.33,64,44.44,41.4,54.22,62.44,1.91,3.69,82.24,2.84
42,"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,47.5,43.48,20,88.89,44,44.44,50.79,44.22,49.86,1.26,22.42,62.78,3.69
43,KB/bert-base-swedish-cased,124.0,50,512,16181,47.34,56.52,20,38.89,68,44.44,38.47,56.22,60.09,1.76,5.57,82.76,3.98
44,sentence-transformers/quora-distilbert-multilingual,135.0,120,512,26458,46.22,60.87,20,44.44,68,33.33,41.77,50.66,63.36,1.02,6.48,82.91,1.67
45,mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,44.74,39.13,30,83.33,44,33.33,50.82,38.66,43.11,3.4,19.03,61.28,1.68
46,AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,44.59,30.43,40,94.44,24,44.44,54.96,34.22,27.54,4.61,28.12,46.5,3.95
47,danish-foundation-models/encoder-large-v1,354.0,50,512,6671,43.88,43.48,20,61.11,48,44.44,41.53,46.22,49.68,0.33,9.3,72.46,2.93
48,dbmdz/bert-medium-historic-multilingual-cased,42.0,32,512,24291,42.77,52.17,20,44.44,60,33.33,38.87,46.66,58.9,0.27,5.9,80.58,1.58
49,roberta-base,124.0,50,512,13354,42.64,56.52,20,50.0,64,22.22,42.17,43.11,60.18,1.07,6.66,81.78,-1.18
50,DDSC/roberta-base-danish,125.0,50,512,15004,42.56,56.52,20,38.89,60,33.33,38.47,46.66,59.63,1.76,5.55,80.21,1.1
51,deepset/gbert-base,109.0,31,512,16043,41.3,47.83,10,50.0,60,33.33,35.94,46.66,56.89,-0.13,6.69,80.48,0.6
52,RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,40.52,30.43,30,83.33,44,22.22,47.92,33.11,28.35,3.14,19.8,60.54,-0.33
53,sarnikowski/convbert-medium-small-da-cased,24.0,29,512,13821,40.45,30.43,30,38.89,40,55.56,33.11,47.78,28.16,2.05,5.37,59.66,4.58
54,pdelobelle/robbert-v2-dutch-base,116.0,40,512,15481,40.11,47.83,20,38.89,56,33.33,35.57,44.66,55.54,1.06,5.42,78.59,0.65
55,KBLab/albert-base-swedish-cased-alpha,14.0,50,512,15925,39.52,39.13,20,50.0,52,33.33,36.38,42.66,42.07,0.27,7.35,73.8,0.81
56,meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,39.35,34.78,20,83.33,32,33.33,46.04,32.66,32.71,0.66,18.31,52.34,0.11
57,DDSC/roberta-base-scandinavian,124.0,50,512,14491,38.11,47.83,20,38.89,48,33.33,35.57,40.66,51.53,0.89,5.19,63.86,0.73
58,ltg/norbert2,125.0,50,512,15523,37.73,30.43,30,33.33,44,44.44,31.25,44.22,28.74,3.0,3.47,60.57,4.16
59,meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,37.7,39.13,10,77.78,44,22.22,42.3,33.11,41.1,-1.07,16.12,59.77,-0.54
60,mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,37.68,34.78,10,83.33,32,33.33,42.7,32.66,36.04,-0.36,17.92,55.42,1.11
61,sarnikowski/convbert-small-da-cased,13.0,29,512,14273,37.05,26.09,20,38.89,36,55.56,28.33,45.78,25.49,1.63,5.28,58.5,5.96
62,Maltehb/aelaectra-danish-electra-small-uncased,14.0,32,128,5995,36.81,30.43,30,11.11,44,55.56,23.85,49.78,30.5,3.59,0.06,62.07,5.11
63,danish-foundation-models/encoder-small-v1,22.0,96,128,6002,32.84,30.43,10,16.67,60,33.33,19.03,46.66,28.99,-0.17,0.42,79.97,0.93
64,Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,31.61,26.09,10,72.22,32,22.22,36.1,27.11,22.55,-0.44,11.98,54.17,0.0
65,TurkuNLP/bert-base-finnish-cased-v1,124.0,50,512,16701,30.94,34.78,20,38.89,28,33.33,31.22,30.66,34.58,0.55,5.07,51.26,1.77
66,Maltehb/danish-bert-botxo,110.0,32,512,16091,27.16,17.39,10,38.89,20,44.44,22.09,32.22,12.64,0.06,4.77,43.59,3.13
67,alexanderfalk/danbert-small-cased,83.0,52,512,30013,26.97,17.39,20,27.78,20,44.44,21.72,32.22,12.39,1.63,1.7,45.16,2.24
68,asafaya/bert-base-arabic,110.0,32,512,16347,26.72,26.09,20,38.89,28,22.22,28.33,25.11,22.51,0.23,5.05,50.44,-0.06
69,01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,26.17,4.35,30,83.33,4,22.22,39.23,13.11,0.0,2.12,16.85,0.0,-0.28
70,fresh-xlm-roberta-base,277.0,250,512,1319,26.1,21.74,10,22.22,24,44.44,17.99,34.22,17.34,-0.06,1.02,48.7,2.37
71,RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,18.02,13.04,10,27.78,16,22.22,16.94,19.11,9.48,0.07,1.04,18.86,-0.43
72,fresh-electra-small,13.0,31,512,7219,17.02,13.04,10,11.11,12,33.33,11.38,22.66,9.96,-0.1,0.12,12.1,0.64
73,ltg/norbert,112.0,33,512,16280,13.57,4.35,10,27.78,4,22.22,14.04,13.11,0.0,-0.03,1.68,0.0,-1.21
74,Qwen/Qwen1.5-0.5B (few-shot),620.0,152,32768,11371,13.45,8.7,10,33.33,8,11.11,17.34,9.55,1.14,-0.57,3.31,1.18,-1.47
75,RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,9.88,4.35,10,5.56,4,22.22,6.64,13.11,0.0,0.0,0.0,0.0,0.0
75,ai-forever/mGPT (few-shot),unknown,100,1024,13551,9.88,4.35,10,5.56,4,22.22,6.64,13.11,0.0,0.0,0.0,0.0,-0.24
