rank,model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,is_score,fo_score,mim_gold_ner,scala_is,nqii,fone,scala_fo
1,vesteinn/FoBERT,124.0,50,512,15623,64.52,51.19,77.85,85.04,50.78,17.76,91.31,64.39
2,microsoft/mdeberta-v3-base,278.0,251,512,9237,61.55,55.39,67.7,81.12,54.11,30.93,88.6,46.81
3,NbAiLab/nb-roberta-base-scandi-1e4,277.0,250,512,15074,57.14,46.53,67.75,81.83,51.09,6.66,90.52,44.99
4,vesteinn/ScandiBERT-no-faroese,124.0,50,512,15436,56.95,55.98,57.92,83.94,58.64,25.35,88.14,27.71
5,mideind/IceBERT-xlmr-ic3,277.0,250,512,11004,53.35,51.55,55.15,84.35,59.12,11.18,87.79,22.51
6,jonfd/electra-small-nordic,22.0,96,128,5989,53.26,48.18,58.34,77.4,60.64,6.51,85.8,30.88
7,sentence-transformers/use-cmlm-multilingual,470.0,501,512,13305,52.69,45.52,59.87,80.91,41.91,13.73,88.81,30.92
8,google/rembert,575.0,250,256,3355,51.45,51.91,51.0,78.05,48.29,29.38,87.35,14.65
8,mideind/IceBERT,124.0,50,512,16697,50.67,53.02,48.31,85.32,60.44,13.31,86.5,10.13
8,mideind/IceBERT-large,406.0,50,512,5677,50.38,52.43,48.33,85.14,59.31,12.84,86.84,9.82
9,setu4993/LaBSE,470.0,501,512,13386,49.5,43.04,55.96,80.45,36.92,11.75,89.16,22.76
10,vesteinn/XLMR-ENIS,125.0,50,512,10711,48.84,52.59,45.09,82.2,48.51,27.06,87.09,3.09
11,vesteinn/IceBERT,163.0,50,512,12360,48.45,51.51,45.39,85.34,55.88,13.31,87.13,3.66
11,pere/roberta-base-exp-32,277.0,250,512,15081,47.44,38.15,56.73,83.57,23.07,7.81,90.6,22.86
11,mideind/IceBERT-ic3,124.0,50,512,12119,46.85,46.97,46.73,85.03,45.06,10.82,87.22,6.23
12,mideind/IceBERT-igc,124.0,50,512,12551,46.21,48.05,44.38,79.85,54.38,9.91,83.82,4.93
13,xlm-roberta-large,559.0,250,512,6663,42.48,40.44,44.51,82.83,22.78,15.72,87.85,1.17
14,mideind/IceBERT-mC4-is,163.0,50,512,12308,41.76,33.38,50.13,79.19,20.95,0.0,88.44,11.83
15,intfloat/multilingual-e5-large,559.0,250,512,6732,39.98,34.33,45.62,78.43,10.78,13.79,88.39,2.85
16,Geotrend/bert-base-25lang-cased,151.0,85,512,13908,39.8,28.94,50.66,74.65,2.89,9.29,86.09,15.24
16,cardiffnlp/twitter-xlm-roberta-base,277.0,250,512,14837,39.56,36.62,42.5,72.69,28.72,8.46,83.96,1.05
16,"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,37.75,35.12,40.39,69.59,7.28,28.5,72.48,8.29
16,Geotrend/bert-base-da-cased,103.0,23,512,15432,37.67,30.2,45.13,73.81,6.23,10.57,86.62,3.64
16,microsoft/xlm-align-base,277.0,250,512,14744,37.23,31.47,42.99,78.01,5.92,10.47,85.97,0.02
17,NbAiLab/nb-roberta-base-scandinavian,125.0,50,512,14051,36.35,26.52,46.19,69.04,3.34,7.17,86.1,6.28
17,microsoft/infoxlm-base,277.0,250,512,14918,36.04,29.12,42.96,77.09,1.71,8.56,85.58,0.35
17,Twitter/twhin-bert-large,560.0,250,512,5299,35.17,27.29,43.05,71.48,2.2,8.19,84.73,1.37
18,KBLab/megatron-bert-large-swedish-cased-165k,369.0,64,512,7138,35.14,25.1,45.17,63.35,4.94,7.02,82.76,7.58
18,vesteinn/DanskBERT,124.0,50,512,15749,35.01,25.25,44.76,65.29,-0.03,10.49,85.04,4.48
18,KennethEnevoldsen/dfm-sentence-encoder-medium-2,124.0,50,512,14965,34.83,25.4,44.26,64.57,0.86,10.76,84.72,3.79
18,KennethEnevoldsen/dfm-sentence-encoder-medium,124.0,50,512,14998,34.75,25.56,43.94,64.88,-0.6,12.39,84.92,2.96
18,flax-community/nordic-roberta-wiki,124.0,50,512,16227,34.63,23.92,45.34,63.31,2.47,5.99,82.64,8.03
18,KBLab/megatron-bert-large-swedish-cased-110k,369.0,64,512,7075,34.28,24.78,43.78,63.11,3.47,7.76,82.36,5.2
18,sentence-transformers/stsb-xlm-r-multilingual,277.0,250,512,15040,34.19,25.44,42.95,66.23,0.04,10.04,82.97,2.93
18,bert-base-multilingual-uncased,167.0,106,512,13993,33.64,28.01,39.27,60.88,13.5,9.65,73.06,5.48
18,patrickvonplaten/norwegian-roberta-base,124.0,50,512,15698,33.53,22.91,44.15,60.79,1.29,6.64,82.57,5.74
18,DeepPavlov/rubert-base-cased,177.0,120,512,15785,33.32,23.46,43.18,61.95,2.4,6.04,83.15,3.21
19,flax-community/swe-roberta-wiki-oscar,124.0,50,512,15437,33.29,23.07,43.52,62.23,1.45,5.52,80.52,6.51
19,sentence-transformers/quora-distilbert-multilingual,135.0,120,512,26458,32.95,23.62,42.29,63.36,1.02,6.48,82.91,1.67
19,KB/bert-base-swedish-cased,124.0,50,512,16181,32.92,22.47,43.37,60.09,1.76,5.57,82.76,3.98
19,sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118.0,250,512,17428,32.61,22.68,42.54,62.44,1.91,3.69,82.24,2.84
20,KennethEnevoldsen/dfm-sentence-encoder-large-1,354.0,50,512,6245,31.5,19.81,43.2,48.31,3.18,7.94,72.99,13.4
21,DDSC/roberta-base-danish,125.0,50,512,15004,31.48,22.31,40.65,59.63,1.76,5.55,80.21,1.1
21,roberta-base,124.0,50,512,13354,31.47,22.64,40.3,60.18,1.07,6.66,81.78,-1.18
21,dbmdz/bert-medium-historic-multilingual-cased,42.0,32,512,24291,31.38,21.69,41.08,58.9,0.27,5.9,80.58,1.58
21,deepset/gbert-base,109.0,31,512,16043,30.84,21.15,40.54,56.89,-0.13,6.69,80.48,0.6
21,pdelobelle/robbert-v2-dutch-base,116.0,40,512,15481,30.15,20.67,39.62,55.54,1.06,5.42,78.59,0.65
21,"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,28.87,24.51,33.23,49.86,1.26,22.42,62.78,3.69
22,mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,28.84,24.95,32.73,47.24,1.35,26.26,62.63,2.84
22,danish-foundation-models/encoder-large-v1,354.0,50,512,6671,28.73,19.77,37.7,49.68,0.33,9.3,72.46,2.93
22,KBLab/albert-base-swedish-cased-alpha,14.0,50,512,15925,26.93,16.56,37.3,42.07,0.27,7.35,73.8,0.81
23,DDSC/roberta-base-scandinavian,124.0,50,512,14491,25.75,19.2,32.3,51.53,0.89,5.19,63.86,0.73
24,danish-foundation-models/encoder-small-v1,22.0,96,128,6002,25.1,9.75,40.45,28.99,-0.17,0.42,79.97,0.93
24,meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,24.17,18.72,29.62,41.1,-1.07,16.12,59.77,-0.54
24,RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,23.6,17.1,30.11,28.35,3.14,19.8,60.54,-0.33
24,mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,23.07,17.87,28.27,36.04,-0.36,17.92,55.42,1.11
24,AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,22.66,20.09,25.23,27.54,4.61,28.12,46.5,3.95
25,Maltehb/aelaectra-danish-electra-small-uncased,14.0,32,128,5995,22.49,11.38,33.59,30.5,3.59,0.06,62.07,5.11
25,ltg/norbert2,125.0,50,512,15523,22.05,11.74,32.37,28.74,3.0,3.47,60.57,4.16
25,sarnikowski/convbert-medium-small-da-cased,24.0,29,512,13821,21.99,11.86,32.12,28.16,2.05,5.37,59.66,4.58
25,meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,21.73,17.23,26.23,32.71,0.66,18.31,52.34,0.11
26,sarnikowski/convbert-small-da-cased,13.0,29,512,14273,21.51,10.8,32.23,25.49,1.63,5.28,58.5,5.96
27,TurkuNLP/bert-base-finnish-cased-v1,124.0,50,512,16701,19.96,13.4,26.52,34.58,0.55,5.07,51.26,1.77
27,Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,19.22,11.36,27.09,22.55,-0.44,11.98,54.17,0.0
27,asafaya/bert-base-arabic,110.0,32,512,16347,17.23,9.26,25.19,22.51,0.23,5.05,50.44,-0.06
28,fresh-xlm-roberta-base,277.0,250,512,1319,15.82,6.1,25.54,17.34,-0.06,1.02,48.7,2.37
28,Maltehb/danish-bert-botxo,110.0,32,512,16091,14.59,5.82,23.36,12.64,0.06,4.77,43.59,3.13
28,alexanderfalk/danbert-small-cased,83.0,52,512,30013,14.47,5.24,23.7,12.39,1.63,1.7,45.16,2.24
29,RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,6.37,3.53,9.21,9.48,0.07,1.04,18.86,-0.43
29,fresh-electra-small,13.0,31,512,7219,4.85,3.33,6.37,9.96,-0.1,0.12,12.1,0.64
30,RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
30,ai-forever/mGPT (few-shot),unknown,100,1024,13551,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
30,ltg/norbert,112.0,33,512,16280,-0.03,0.55,-0.6,0.0,-0.03,1.68,0.0,-1.21
