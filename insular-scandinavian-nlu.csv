rank,model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,mim_gold_ner_score,scala_is_score,nqii_score,fone_score,scala_fo_score,is_score,fo_score,mim_gold_ner,scala_is,nqii,fone,scala_fo
1,vesteinn/FoBERT,124.0,50,512,15623,78.86,90.91,60,72.22,91.67,75.0,74.38,83.34,85.04,50.78,17.76,91.31,64.39
2,microsoft/mdeberta-v3-base,278.0,251,512,9237,76.57,81.82,70,88.89,83.33,62.5,80.24,72.91,81.12,54.11,30.93,88.6,46.81
3,vesteinn/ScandiBERT-no-faroese,124.0,50,512,15436,72.98,86.36,80,77.78,79.17,50.0,81.38,64.59,83.94,58.64,25.35,88.14,27.71
4,mideind/IceBERT-xlmr-ic3,277.0,250,512,11004,69.0,90.91,80,55.56,75.0,50.0,75.49,62.5,84.35,59.12,11.18,87.79,22.51
5,NbAiLab/nb-roberta-base-scandi-1e4,277.0,250,512,15074,67.62,81.82,60,38.89,87.5,62.5,60.24,75.0,81.83,51.09,6.66,90.52,44.99
6,sentence-transformers/use-cmlm-multilingual,470.0,501,512,13305,66.41,81.82,50,66.67,83.33,50.0,66.16,66.66,80.91,41.91,13.73,88.81,30.92
7,google/rembert,575.0,250,256,3355,65.82,77.27,60,88.89,75.0,37.5,75.39,56.25,78.05,48.29,29.38,87.35,14.65
8,mideind/IceBERT-large,406.0,50,512,5677,65.75,90.91,80,61.11,70.83,37.5,77.34,54.16,85.14,59.31,12.84,86.84,9.82
8,mideind/IceBERT,124.0,50,512,16697,65.75,90.91,80,61.11,70.83,37.5,77.34,54.16,85.32,60.44,13.31,86.5,10.13
9,setu4993/LaBSE,470.0,501,512,13386,64.56,81.82,50,55.56,83.33,50.0,62.46,66.66,80.45,36.92,11.75,89.16,22.76
10,pere/roberta-base-exp-32,277.0,250,512,15081,63.89,86.36,40,44.44,91.67,50.0,56.93,70.84,83.57,23.07,7.81,90.6,22.86
11,jonfd/electra-small-nordic,22.0,96,128,5989,61.11,72.73,80,38.89,66.67,50.0,63.87,58.34,77.4,60.64,6.51,85.8,30.88
12,vesteinn/XLMR-ENIS,125.0,50,512,10711,60.16,86.36,60,83.33,75.0,12.5,76.56,43.75,82.2,48.51,27.06,87.09,3.09
13,mideind/IceBERT-ic3,124.0,50,512,12119,59.41,90.91,60,55.56,75.0,25.0,68.82,50.0,85.03,45.06,10.82,87.22,6.23
14,vesteinn/IceBERT,163.0,50,512,12360,58.88,90.91,70,61.11,75.0,12.5,74.01,43.75,85.34,55.88,13.31,87.13,3.66
15,mideind/IceBERT-igc,124.0,50,512,12551,53.71,77.27,70,50.0,58.33,25.0,65.76,41.66,79.85,54.38,9.91,83.82,4.93
16,xlm-roberta-large,559.0,250,512,6663,51.97,86.36,40,66.67,79.17,0.0,64.34,39.59,82.83,22.78,15.72,87.85,1.17
17,intfloat/multilingual-e5-large,559.0,250,512,6732,50.25,77.27,20,66.67,79.17,12.5,54.65,45.84,78.43,10.78,13.79,88.39,2.85
18,Geotrend/bert-base-25lang-cased,151.0,85,512,13908,48.44,68.18,10,50.0,70.83,37.5,42.73,54.16,74.65,2.89,9.29,86.09,15.24
19,"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,47.62,63.64,20,83.33,41.67,37.5,55.66,39.59,69.59,7.28,28.5,72.48,8.29
20,mideind/IceBERT-mC4-is,163.0,50,512,12308,46.12,77.27,30,-5.56,79.17,37.5,33.9,58.34,79.19,20.95,0.0,88.44,11.83
21,Geotrend/bert-base-da-cased,103.0,23,512,15432,44.78,68.18,20,55.56,70.83,12.5,47.91,41.66,73.81,6.23,10.57,86.62,3.64
22,microsoft/xlm-align-base,277.0,250,512,14744,43.17,77.27,20,55.56,70.83,0.0,50.94,35.41,78.01,5.92,10.47,85.97,0.02
23,NbAiLab/nb-roberta-base-scandinavian,125.0,50,512,14051,41.95,59.09,10,38.89,70.83,25.0,35.99,47.91,69.04,3.34,7.17,86.1,6.28
24,cardiffnlp/twitter-xlm-roberta-base,277.0,250,512,14837,39.26,63.64,40,44.44,58.33,0.0,49.36,29.16,72.69,28.72,8.46,83.96,1.05
25,KBLab/megatron-bert-large-swedish-cased-165k,369.0,64,512,7138,37.95,50.0,20,38.89,54.17,25.0,36.3,39.59,63.35,4.94,7.02,82.76,7.58
26,bert-base-multilingual-uncased,167.0,106,512,13993,37.58,45.45,30,50.0,41.67,25.0,41.82,33.34,60.88,13.5,9.65,73.06,5.48
27,KBLab/megatron-bert-large-swedish-cased-110k,369.0,64,512,7075,37.2,50.0,10,44.44,54.17,25.0,34.81,39.59,63.11,3.47,7.76,82.36,5.2
28,microsoft/infoxlm-base,277.0,250,512,14918,37.12,72.73,0,50.0,66.67,0.0,40.91,33.34,77.09,1.71,8.56,85.58,0.35
29,KennethEnevoldsen/dfm-sentence-encoder-medium-2,124.0,50,512,14965,37.1,54.55,0,55.56,62.5,12.5,36.7,37.5,64.57,0.86,10.76,84.72,3.79
30,KennethEnevoldsen/dfm-sentence-encoder-medium,124.0,50,512,14998,36.36,54.55,-10,61.11,62.5,12.5,35.22,37.5,64.88,-0.6,12.39,84.92,2.96
31,vesteinn/DanskBERT,124.0,50,512,15749,35.44,54.55,-10,55.56,62.5,12.5,33.37,37.5,65.29,-0.03,10.49,85.04,4.48
32,flax-community/nordic-roberta-wiki,124.0,50,512,16227,35.35,50.0,10,33.33,54.17,25.0,31.11,39.59,63.31,2.47,5.99,82.64,8.03
33,Twitter/twhin-bert-large,560.0,250,512,5299,35.3,63.64,10,44.44,62.5,0.0,39.36,31.25,71.48,2.2,8.19,84.73,1.37
34,KennethEnevoldsen/dfm-sentence-encoder-large-1,354.0,50,512,6245,34.17,31.82,10,44.44,41.67,37.5,28.75,39.59,48.31,3.18,7.94,72.99,13.4
35,patrickvonplaten/norwegian-roberta-base,124.0,50,512,15698,33.85,45.45,0,38.89,54.17,25.0,28.11,39.59,60.79,1.29,6.64,82.57,5.74
36,sentence-transformers/stsb-xlm-r-multilingual,277.0,250,512,15040,33.46,54.55,-10,50.0,58.33,12.5,31.52,35.41,66.23,0.04,10.04,82.97,2.93
37,DeepPavlov/rubert-base-cased,177.0,120,512,15785,33.26,50.0,10,33.33,58.33,12.5,31.11,35.41,61.95,2.4,6.04,83.15,3.21
38,flax-community/swe-roberta-wiki-oscar,124.0,50,512,15437,31.71,50.0,0,27.78,50.0,25.0,25.93,37.5,62.23,1.45,5.52,80.52,6.51
39,mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,30.65,31.82,0,83.33,33.33,12.5,38.38,22.91,47.24,1.35,26.26,62.63,2.84
40,sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118.0,250,512,17428,30.38,50.0,10,22.22,54.17,12.5,27.41,33.34,62.44,1.91,3.69,82.24,2.84
41,KB/bert-base-swedish-cased,124.0,50,512,16181,29.91,45.45,0,27.78,58.33,12.5,24.41,35.41,60.09,1.76,5.57,82.76,3.98
42,"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,29.72,31.82,0,77.78,33.33,12.5,36.53,22.91,49.86,1.26,22.42,62.78,3.69
43,sentence-transformers/quora-distilbert-multilingual,135.0,120,512,26458,28.47,50.0,0,33.33,58.33,0.0,27.78,29.16,63.36,1.02,6.48,82.91,1.67
44,mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,26.58,27.27,10,72.22,33.33,0.0,36.5,16.66,43.11,3.4,19.03,61.28,1.68
45,AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,26.5,18.18,20,83.33,12.5,12.5,40.5,12.5,27.54,4.61,28.12,46.5,3.95
46,danish-foundation-models/encoder-large-v1,354.0,50,512,6671,26.13,31.82,0,50.0,37.5,12.5,27.27,25.0,49.68,0.33,9.3,72.46,2.93
47,dbmdz/bert-medium-historic-multilingual-cased,42.0,32,512,24291,24.88,40.91,0,33.33,50.0,0.0,24.75,25.0,58.9,0.27,5.9,80.58,1.58
48,DDSC/roberta-base-danish,125.0,50,512,15004,24.7,45.45,0,27.78,50.0,0.0,24.41,25.0,59.63,1.76,5.55,80.21,1.1
49,roberta-base,124.0,50,512,13354,24.48,45.45,0,38.89,54.17,-12.5,28.11,20.84,60.18,1.07,6.66,81.78,-1.18
50,deepset/gbert-base,109.0,31,512,16043,23.38,36.36,-10,38.89,50.0,0.0,21.75,25.0,56.89,-0.13,6.69,80.48,0.6
51,sarnikowski/convbert-medium-small-da-cased,24.0,29,512,13821,22.87,18.18,10,27.78,29.17,25.0,18.65,27.09,28.16,2.05,5.37,59.66,4.58
52,pdelobelle/robbert-v2-dutch-base,116.0,40,512,15481,22.14,36.36,0,27.78,45.83,0.0,21.38,22.91,55.54,1.06,5.42,78.59,0.65
53,RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,21.94,18.18,10,72.22,33.33,-12.5,33.47,10.41,28.35,3.14,19.8,60.54,-0.33
54,KBLab/albert-base-swedish-cased-alpha,14.0,50,512,15925,21.45,27.27,0,38.89,41.67,0.0,22.05,20.84,42.07,0.27,7.35,73.8,0.81
55,meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,21.03,22.73,0,72.22,20.83,0.0,31.65,10.41,32.71,0.66,18.31,52.34,0.11
56,DDSC/roberta-base-scandinavian,124.0,50,512,14491,20.06,36.36,0,27.78,37.5,0.0,21.38,18.75,51.53,0.89,5.19,63.86,0.73
57,ltg/norbert2,125.0,50,512,15523,19.86,18.18,10,22.22,33.33,12.5,16.8,22.91,28.74,3.0,3.47,60.57,4.16
58,sarnikowski/convbert-small-da-cased,13.0,29,512,14273,19.41,13.64,0,27.78,25.0,25.0,13.81,25.0,25.49,1.63,5.28,58.5,5.96
59,mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,19.37,22.73,-10,72.22,20.83,0.0,28.32,10.41,36.04,-0.36,17.92,55.42,1.11
60,Maltehb/aelaectra-danish-electra-small-uncased,14.0,32,128,5995,19.27,18.18,10,0.0,33.33,25.0,9.39,29.16,30.5,3.59,0.06,62.07,5.11
61,meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,19.2,27.27,-10,66.67,33.33,-12.5,27.98,10.41,41.1,-1.07,16.12,59.77,-0.54
62,danish-foundation-models/encoder-small-v1,22.0,96,128,6002,14.79,18.18,-10,5.56,50.0,0.0,4.58,25.0,28.99,-0.17,0.42,79.97,0.93
63,Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,12.87,13.64,-10,61.11,20.83,-12.5,21.58,4.16,22.55,-0.44,11.98,54.17,0.0
64,TurkuNLP/bert-base-finnish-cased-v1,124.0,50,512,16701,12.59,22.73,0,27.78,16.67,0.0,16.84,8.34,34.58,0.55,5.07,51.26,1.77
65,Maltehb/danish-bert-botxo,110.0,32,512,16091,8.93,4.55,-10,27.78,8.33,12.5,7.44,10.41,12.64,0.06,4.77,43.59,3.13
66,01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,8.78,-4.55,10,72.22,-4.17,-12.5,25.89,-8.34,0.0,2.12,16.85,0.0,-0.28
67,alexanderfalk/danbert-small-cased,83.0,52,512,30013,8.74,4.55,0,16.67,8.33,12.5,7.07,10.41,12.39,1.63,1.7,45.16,2.24
68,asafaya/bert-base-arabic,110.0,32,512,16347,7.95,13.64,0,27.78,16.67,-12.5,13.81,2.09,22.51,0.23,5.05,50.44,-0.06
68,fresh-xlm-roberta-base,277.0,250,512,1319,7.95,9.09,-10,11.11,12.5,12.5,3.4,12.5,17.34,-0.06,1.02,48.7,2.37
69,RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,-0.97,0.0,-10,16.67,4.17,-12.5,2.22,-4.17,9.48,0.07,1.04,18.86,-0.43
70,fresh-electra-small,13.0,31,512,7219,-1.67,0.0,-10,0.0,0.0,0.0,-3.33,0.0,9.96,-0.1,0.12,12.1,0.64
71,ltg/norbert,112.0,33,512,16280,-3.81,-4.55,-10,16.67,-4.17,-12.5,0.71,-8.34,0.0,-0.03,1.68,0.0,-1.21
72,RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,-7.52,-4.55,-10,-5.56,-4.17,-12.5,-6.7,-8.34,0.0,0.0,0.0,0.0,0.0
72,ai-forever/mGPT (few-shot),unknown,100,1024,13551,-7.52,-4.55,-10,-5.56,-4.17,-12.5,-6.7,-8.34,0.0,0.0,0.0,0.0,-0.24
