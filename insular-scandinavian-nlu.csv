rank,model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,mim_gold_ner_score,scala_is_score,nqii_score,fone_score,scala_fo_score,is_score,fo_score,mim_gold_ner,scala_is,nqii,fone,scala_fo
1,vesteinn/FoBERT,124.0,50,512,15623,93.89,100.0,80,83.33,100.0,100.0,87.78,100.0,85.04,50.78,17.76,91.31,64.39
2,microsoft/mdeberta-v3-base,278.0,251,512,9237,91.62,90.91,90,100.0,91.67,87.5,93.64,89.59,81.12,54.11,30.93,88.6,46.81
3,vesteinn/ScandiBERT-no-faroese,124.0,50,512,15436,88.02,95.45,100,88.89,87.5,75.0,94.78,81.25,83.94,58.64,25.35,88.14,27.71
4,mideind/IceBERT-xlmr-ic3,277.0,250,512,11004,84.03,100.0,100,66.67,83.33,75.0,88.89,79.16,84.35,59.12,11.18,87.79,22.51
5,NbAiLab/nb-roberta-base-scandi-1e4,277.0,250,512,15074,82.65,90.91,80,50.0,95.83,87.5,73.64,91.66,81.83,51.09,6.66,90.52,44.99
6,sentence-transformers/use-cmlm-multilingual,470.0,501,512,13305,81.45,90.91,70,77.78,91.67,75.0,79.56,83.34,80.91,41.91,13.73,88.81,30.92
7,google/rembert,575.0,250,256,3355,80.85,86.36,80,100.0,83.33,62.5,88.79,72.91,78.05,48.29,29.38,87.35,14.65
8,mideind/IceBERT-large,406.0,50,512,5677,80.79,100.0,100,72.22,79.17,62.5,90.74,70.84,85.14,59.31,12.84,86.84,9.82
8,mideind/IceBERT,124.0,50,512,16697,80.79,100.0,100,72.22,79.17,62.5,90.74,70.84,85.32,60.44,13.31,86.5,10.13
9,setu4993/LaBSE,470.0,501,512,13386,79.6,90.91,70,66.67,91.67,75.0,75.86,83.34,80.45,36.92,11.75,89.16,22.76
10,pere/roberta-base-exp-32,277.0,250,512,15081,78.92,95.45,60,55.56,100.0,75.0,70.34,87.5,83.57,23.07,7.81,90.6,22.86
11,jonfd/electra-small-nordic,22.0,96,128,5989,76.13,81.82,100,50.0,75.0,75.0,77.27,75.0,77.4,60.64,6.51,85.8,30.88
12,vesteinn/XLMR-ENIS,125.0,50,512,10711,75.19,95.45,80,94.44,83.33,37.5,89.96,60.41,82.2,48.51,27.06,87.09,3.09
13,mideind/IceBERT-ic3,124.0,50,512,12119,74.44,100.0,80,66.67,83.33,50.0,82.22,66.66,85.03,45.06,10.82,87.22,6.23
14,vesteinn/IceBERT,163.0,50,512,12360,73.91,100.0,90,72.22,83.33,37.5,87.41,60.41,85.34,55.88,13.31,87.13,3.66
15,mideind/IceBERT-igc,124.0,50,512,12551,68.75,86.36,90,61.11,66.67,50.0,79.16,58.34,79.85,54.38,9.91,83.82,4.93
16,xlm-roberta-large,559.0,250,512,6663,67.0,95.45,60,77.78,87.5,25.0,77.74,56.25,82.83,22.78,15.72,87.85,1.17
17,intfloat/multilingual-e5-large,559.0,250,512,6732,65.28,86.36,40,77.78,87.5,37.5,68.05,62.5,78.43,10.78,13.79,88.39,2.85
18,Geotrend/bert-base-25lang-cased,151.0,85,512,13908,63.48,77.27,30,61.11,79.17,62.5,56.13,70.84,74.65,2.89,9.29,86.09,15.24
19,"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,62.66,72.73,40,94.44,50.0,62.5,69.06,56.25,69.59,7.28,28.5,72.48,8.29
20,mideind/IceBERT-mC4-is,163.0,50,512,12308,61.16,86.36,50,5.56,87.5,62.5,47.31,75.0,79.19,20.95,0.0,88.44,11.83
21,Geotrend/bert-base-da-cased,103.0,23,512,15432,59.83,77.27,40,66.67,79.17,37.5,61.31,58.34,73.81,6.23,10.57,86.62,3.64
22,microsoft/xlm-align-base,277.0,250,512,14744,58.22,86.36,40,66.67,79.17,25.0,64.34,52.09,78.01,5.92,10.47,85.97,0.02
23,AI-Sweden-Models/roberta-large-1160k,354.0,50,512,5741,57.11,77.27,30,66.67,87.5,25.0,57.98,56.25,74.3,2.06,11.47,88.24,1.73
24,NbAiLab/nb-roberta-base-scandinavian,125.0,50,512,14051,56.99,68.18,30,50.0,79.17,50.0,49.39,64.59,69.04,3.34,7.17,86.1,6.28
25,cardiffnlp/twitter-xlm-roberta-base,277.0,250,512,14837,54.3,72.73,60,55.56,66.67,25.0,62.76,45.84,72.69,28.72,8.46,83.96,1.05
26,KBLab/megatron-bert-large-swedish-cased-165k,369.0,64,512,7138,52.98,59.09,40,50.0,62.5,50.0,49.7,56.25,63.35,4.94,7.02,82.76,7.58
27,bert-base-multilingual-uncased,167.0,106,512,13993,52.61,54.55,50,61.11,50.0,50.0,55.22,50.0,60.88,13.5,9.65,73.06,5.48
28,KBLab/megatron-bert-large-swedish-cased-110k,369.0,64,512,7075,52.23,59.09,30,55.56,62.5,50.0,48.22,56.25,63.11,3.47,7.76,82.36,5.2
29,microsoft/infoxlm-base,277.0,250,512,14918,52.16,81.82,20,61.11,75.0,25.0,54.31,50.0,77.09,1.71,8.56,85.58,0.35
30,KennethEnevoldsen/dfm-sentence-encoder-medium-2,124.0,50,512,14965,52.13,63.64,20,66.67,70.83,37.5,50.1,54.16,64.57,0.86,10.76,84.72,3.79
31,KennethEnevoldsen/dfm-sentence-encoder-medium,124.0,50,512,14998,51.39,63.64,10,72.22,70.83,37.5,48.62,54.16,64.88,-0.6,12.39,84.92,2.96
32,vesteinn/DanskBERT,124.0,50,512,15749,50.47,63.64,10,66.67,70.83,37.5,46.77,54.16,65.29,-0.03,10.49,85.04,4.48
33,flax-community/nordic-roberta-wiki,124.0,50,512,16227,50.38,59.09,30,44.44,62.5,50.0,44.51,56.25,63.31,2.47,5.99,82.64,8.03
34,Twitter/twhin-bert-large,560.0,250,512,5299,50.33,72.73,30,55.56,70.83,25.0,52.76,47.91,71.48,2.2,8.19,84.73,1.37
35,KennethEnevoldsen/dfm-sentence-encoder-large-1,354.0,50,512,6245,49.2,40.91,30,55.56,50.0,62.5,42.16,56.25,48.31,3.18,7.94,72.99,13.4
36,patrickvonplaten/norwegian-roberta-base,124.0,50,512,15698,48.89,54.55,20,50.0,62.5,50.0,41.52,56.25,60.79,1.29,6.64,82.57,5.74
37,sentence-transformers/stsb-xlm-r-multilingual,277.0,250,512,15040,48.51,63.64,10,61.11,66.67,37.5,44.92,52.09,66.23,0.04,10.04,82.97,2.93
38,DeepPavlov/rubert-base-cased,177.0,120,512,15785,48.3,59.09,30,44.44,66.67,37.5,44.51,52.09,61.95,2.4,6.04,83.15,3.21
39,flax-community/swe-roberta-wiki-oscar,124.0,50,512,15437,46.74,59.09,20,38.89,58.33,50.0,39.33,54.16,62.23,1.45,5.52,80.52,6.51
40,mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,45.69,40.91,20,94.44,41.67,37.5,51.78,39.59,47.24,1.35,26.26,62.63,2.84
41,sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118.0,250,512,17428,45.41,59.09,30,33.33,62.5,37.5,40.81,50.0,62.44,1.91,3.69,82.24,2.84
42,KB/bert-base-swedish-cased,124.0,50,512,16181,44.95,54.55,20,38.89,66.67,37.5,37.81,52.09,60.09,1.76,5.57,82.76,3.98
43,"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,44.76,40.91,20,88.89,41.67,37.5,49.93,39.59,49.86,1.26,22.42,62.78,3.69
44,sentence-transformers/quora-distilbert-multilingual,135.0,120,512,26458,43.51,59.09,20,44.44,66.67,25.0,41.18,45.84,63.36,1.02,6.48,82.91,1.67
45,mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,41.62,36.36,30,83.33,41.67,25.0,49.9,33.34,43.11,3.4,19.03,61.28,1.68
46,AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,41.53,27.27,40,94.44,20.83,37.5,53.9,29.16,27.54,4.61,28.12,46.5,3.95
47,danish-foundation-models/encoder-large-v1,354.0,50,512,6671,41.16,40.91,20,61.11,45.83,37.5,40.67,41.66,49.68,0.33,9.3,72.46,2.93
48,dbmdz/bert-medium-historic-multilingual-cased,42.0,32,512,24291,39.91,50.0,20,44.44,58.33,25.0,38.15,41.66,58.9,0.27,5.9,80.58,1.58
49,DDSC/roberta-base-danish,125.0,50,512,15004,39.73,54.55,20,38.89,58.33,25.0,37.81,41.66,59.63,1.76,5.55,80.21,1.1
50,roberta-base,124.0,50,512,13354,39.51,54.55,20,50.0,62.5,12.5,41.52,37.5,60.18,1.07,6.66,81.78,-1.18
51,deepset/gbert-base,109.0,31,512,16043,38.41,45.45,10,50.0,58.33,25.0,35.15,41.66,56.89,-0.13,6.69,80.48,0.6
52,sarnikowski/convbert-medium-small-da-cased,24.0,29,512,13821,37.9,27.27,30,38.89,37.5,50.0,32.05,43.75,28.16,2.05,5.37,59.66,4.58
53,pdelobelle/robbert-v2-dutch-base,116.0,40,512,15481,37.19,45.45,20,38.89,54.17,25.0,34.78,39.59,55.54,1.06,5.42,78.59,0.65
54,RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,36.98,27.27,30,83.33,41.67,12.5,46.87,27.09,28.35,3.14,19.8,60.54,-0.33
55,KBLab/albert-base-swedish-cased-alpha,14.0,50,512,15925,36.48,36.36,20,50.0,50.0,25.0,35.45,37.5,42.07,0.27,7.35,73.8,0.81
56,meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,36.07,31.82,20,83.33,29.17,25.0,45.05,27.09,32.71,0.66,18.31,52.34,0.11
57,DDSC/roberta-base-scandinavian,124.0,50,512,14491,35.09,45.45,20,38.89,45.83,25.0,34.78,35.41,51.53,0.89,5.19,63.86,0.73
58,ltg/norbert2,125.0,50,512,15523,34.9,27.27,30,33.33,41.67,37.5,30.2,39.59,28.74,3.0,3.47,60.57,4.16
59,sarnikowski/convbert-small-da-cased,13.0,29,512,14273,34.44,22.73,20,38.89,33.33,50.0,27.21,41.66,25.49,1.63,5.28,58.5,5.96
60,mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,34.41,31.82,10,83.33,29.17,25.0,41.72,27.09,36.04,-0.36,17.92,55.42,1.11
61,Maltehb/aelaectra-danish-electra-small-uncased,14.0,32,128,5995,34.31,27.27,30,11.11,41.67,50.0,22.79,45.84,30.5,3.59,0.06,62.07,5.11
62,meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,34.23,36.36,10,77.78,41.67,12.5,41.38,27.09,41.1,-1.07,16.12,59.77,-0.54
63,danish-foundation-models/encoder-small-v1,22.0,96,128,6002,29.82,27.27,10,16.67,58.33,25.0,17.98,41.66,28.99,-0.17,0.42,79.97,0.93
64,Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,27.91,22.73,10,72.22,29.17,12.5,34.98,20.84,22.55,-0.44,11.98,54.17,0.0
65,TurkuNLP/bert-base-finnish-cased-v1,124.0,50,512,16701,27.62,31.82,20,38.89,25.0,25.0,30.24,25.0,34.58,0.55,5.07,51.26,1.77
66,Maltehb/danish-bert-botxo,110.0,32,512,16091,23.96,13.64,10,38.89,16.67,37.5,20.84,27.09,12.64,0.06,4.77,43.59,3.13
67,01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,23.81,4.55,30,83.33,4.17,12.5,39.29,8.34,0.0,2.12,16.85,0.0,-0.28
68,alexanderfalk/danbert-small-cased,83.0,52,512,30013,23.78,13.64,20,27.78,16.67,37.5,20.47,27.09,12.39,1.63,1.7,45.16,2.24
69,asafaya/bert-base-arabic,110.0,32,512,16347,22.98,22.73,20,38.89,25.0,12.5,27.21,18.75,22.51,0.23,5.05,50.44,-0.06
69,fresh-xlm-roberta-base,277.0,250,512,1319,22.98,18.18,10,22.22,20.83,37.5,16.8,29.16,17.34,-0.06,1.02,48.7,2.37
70,RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,14.06,9.09,10,27.78,12.5,12.5,15.62,12.5,9.48,0.07,1.04,18.86,-0.43
71,fresh-electra-small,13.0,31,512,7219,13.37,9.09,10,11.11,8.33,25.0,10.07,16.66,9.96,-0.1,0.12,12.1,0.64
72,ltg/norbert,112.0,33,512,16280,11.22,4.55,10,27.78,4.17,12.5,14.11,8.34,0.0,-0.03,1.68,0.0,-1.21
73,RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,7.52,4.55,10,5.56,4.17,12.5,6.7,8.34,0.0,0.0,0.0,0.0,0.0
73,ai-forever/mGPT (few-shot),unknown,100,1024,13551,7.52,4.55,10,5.56,4.17,12.5,6.7,8.34,0.0,0.0,0.0,0.0,-0.24
