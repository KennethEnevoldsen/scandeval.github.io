model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,conll_en_score,sst5_score,scala_en_score,squad_score,cnn_dailymail_score,mmlu_score,hellaswag_score,en_score,conll_en,sst5,scala_en,squad,cnn_dailymail,mmlu,hellaswag
"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,4.86,0.0,0.0,0.0,0.3943300339275503,0.10125058989562227,0.49731944955535107,0.0,4.86,71.48,66.41,41.43,67.9,69.57,43.69,75.6
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,4.67,0.0,0.16890563635800615,0.8344044522745442,1.1213570528783512,0.0,0.0,0.1565965421716169,4.67,69.16,63.85,28.4,52.69,70.55,51.74,71.96
01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,4.59,0.6345745515177519,0.0,1.250245055403089,0.0,0.6547190041615766,0.0,0.3145448009770442,4.59,52.7,68.66,25.29,75.83,64.51,50.89,68.29
mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,4.49,0.22979617730769974,0.0,0.504412494240846,0.8468045458717219,0.15555438649286063,0.247366950818649,1.6144960941597106,4.49,63.4,68.17,30.92,58.79,69.11,47.74,34.96
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,4.38,0.48750122826921294,0.306698316693777,0.504412494240846,0.5153834090182592,0.10125058989562227,0.8240187257291914,1.6144960941597106,4.38,57.58,61.44,34.92,65.46,69.61,38.4,35.72
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,4.34,0.22979617730769974,0.16890563635800615,0.8344044522745442,0.6829805970515826,0.15555438649286063,0.9420239657133508,1.6144960941597106,4.34,64.93,64.14,28.08,62.09,68.84,36.49,38.09
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,4.32,0.3138826933644843,0.4287794664091246,0.8344044522745442,0.8468045458717219,0.0,1.0385380085806148,1.3206914790234259,4.32,62.11,59.91,30.66,58.3,69.77,34.93,44.91
meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,4.19,0.3138826933644843,0.306698316693777,1.250245055403089,0.5153834090182592,0.0,1.3136196086440293,1.9545395635084604,4.19,62.53,62.23,22.71,64.54,69.95,30.47,30.18
Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,3.94,0.6345745515177519,0.16890563635800615,2.231109427624378,0.3943300339275503,0.2602952817765079,1.2408951620966329,2.492022903079373,3.94,53.39,65.21,12.63,65.74,68.05,31.65,17.69
meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,3.88,0.48750122826921294,0.16890563635800615,1.250245055403089,1.550182371038816,0.15555438649286063,1.5132569985524857,2.7467282578917174,3.88,55.27,65.16,20.43,44.64,68.82,25.98,11.77
microsoft/phi-2 (few-shot),2780.0,51,2048,3472,3.83,2.432350935219314,0.306698316693777,2.231109427624378,0.0,0.2602952817765079,0.7157775055728015,2.225583797313809,3.83,1.42,62.4,12.31,75.79,67.79,40.15,23.21
Qwen/Qwen1.5-1.8B (few-shot),1837.0,152,32768,5666,3.69,2.432350935219314,0.16890563635800615,2.0243710704434994,0.5153834090182592,0.2602952817765079,1.5132569985524857,2.225583797313809,3.69,1.44,64.34,15.3,64.41,68.15,27.24,22.84
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837.0,152,32768,8304,3.55,2.470472764640904,0.6494089889944398,2.231109427624378,0.6829805970515826,0.36487662584674063,1.5132569985524857,2.225583797313809,3.55,1.07,55.33,11.23,60.71,67.18,26.84,23.89
Qwen/Qwen1.5-0.5B (few-shot),620.0,152,32768,11371,3.18,2.3794390090184807,0.4287794664091246,2.981661537581172,1.550182371038816,0.5780667993509782,2.0691590926255974,2.7467282578917174,3.18,3.67,57.15,2.94,42.57,65.22,18.24,10.89
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,3.16,0.8989421429076772,0.306698316693777,2.6964921859913877,0.5153834090182592,2.9379389188552967,2.633643621559489,2.8940858076774445,3.16,45.86,62.08,6.62,65.29,43.45,9.1,8.35
Qwen/Qwen1.5-0.5B-Chat (few-shot),620.0,152,32768,11740,3.14,2.432350935219314,0.6494089889944398,2.981661537581172,1.1213570528783512,0.36487662584674063,2.4755948787225863,3.0288082969321866,3.14,2.16,55.41,1.15,53.27,65.82,11.66,5.22
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,2.65,1.8524355498662062,2.289604202555493,3.1779429757516975,1.944875721825062,1.0073144300620915,2.9662253883303307,3.226814450602361,2.65,18.69,21.95,0.01,36.7,60.11,3.71,0.62
RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,2.11,2.5081799250647436,3.3657722119590265,3.1779429757516975,3.768844186763884,1.0073144300620915,3.172961996710443,3.226814450602361,2.11,0.0,0.0,0.41,0.0,61.26,0.0,0.36
ai-forever/mGPT (few-shot),unknown,100,1024,13551,1.77,2.432350935219314,3.183935071812893,3.1779429757516975,3.491857594098991,3.896037118436136,3.172961996710443,3.226814450602361,1.77,1.55,3.71,-0.42,5.57,34.62,0.37,-0.17
