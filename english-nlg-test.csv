model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,conll_en_rank,sst5_rank,scala_en_rank,squad_rank,cnn_dailymail_rank,mmlu_rank,hellaswag_rank,en_rank,conll_en,sst5,scala_en,squad,cnn_dailymail,mmlu,hellaswag
"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,1.15,1.0,1.0,1.0,1.4160582616837596,1.1102421543851462,1.5260590496492652,1.0,1.15,71.48,66.41,41.43,67.9,69.57,43.69,75.6
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,1.34,1.0,1.1840357465907296,1.8569481289536622,2.1831456546703443,1.0,1.0,1.159795347440014,1.34,69.16,63.85,28.4,52.69,70.55,51.74,71.96
01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,1.42,1.622987268819606,1.0,2.284023782520187,1.0,1.7128613631789857,1.0,1.3209700230959949,1.42,52.7,68.66,25.29,75.83,64.51,50.89,68.29
mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,1.53,1.2256001167139539,1.0,1.5180405521354023,1.8934648569173542,1.169368402778798,1.26166204273459,2.647475485276435,1.53,63.4,68.17,30.92,58.79,69.11,47.74,34.96
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,1.64,1.4785994931868052,1.3341715226792303,1.5180405521354023,1.5437818750985217,1.1102421543851462,1.8534680444196423,2.647475485276435,1.64,57.58,61.44,34.92,65.46,69.61,38.4,35.72
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,1.69,1.2256001167139539,1.1840357465907296,1.8569481289536622,1.7206139414306596,1.169368402778798,1.9964626008354858,2.647475485276435,1.69,64.93,64.14,28.08,62.09,68.84,36.49,38.09
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,1.71,1.3081512194291196,1.467188371713787,1.8569481289536622,1.8934648569173542,1.0,2.098554094972617,2.347669308817377,1.71,62.11,59.91,30.66,58.3,69.77,34.93,44.91
meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,1.84,1.3081512194291196,1.3341715226792303,2.284023782520187,1.5437818750985217,1.0,2.3895323891751503,2.994465039296995,1.84,62.53,62.23,22.71,64.54,69.95,30.47,30.18
Qwen/Qwen1.5-4B (few-shot),3950.0,152,32768,3248,1.85,3.425362121212961,1.3341715226792303,1.8569481289536622,1.2801387619331555,1.2213770009519982,1.757141581087592,2.0442517114450505,1.85,0.76,60.55,28.6,70.49,68.67,39.82,51.82
Qwen/Qwen1.5-4B-Chat (few-shot),3950.0,152,32768,4347,1.93,3.425362121212961,1.467188371713787,1.8569481289536622,1.2801387619331555,1.3859996030923867,1.8534680444196423,2.2353642732669705,1.93,0.73,59.62,28.55,70.04,67.27,38.68,47.47
Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,2.09,1.622987268819606,1.1840357465907296,3.2913888394072224,1.4160582616837596,1.2834108193237463,2.312605268646891,3.542927577478889,2.09,53.39,65.21,12.63,65.74,68.05,31.65,17.69
meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,2.17,1.4785994931868052,1.1840357465907296,2.284023782520187,2.6355999469868365,1.169368402778798,2.600706626787616,3.8028358111004583,2.17,55.27,65.16,20.43,44.64,68.82,25.98,11.77
microsoft/phi-2 (few-shot),2780.0,51,2048,3472,2.19,3.3879363934762274,1.3341715226792303,3.2913888394072224,1.0,1.2834108193237463,1.757141581087592,3.271045906996309,2.19,1.42,62.4,12.31,75.79,67.79,40.15,23.21
Qwen/Qwen1.5-1.8B (few-shot),1837.0,152,32768,5666,2.34,3.3879363934762274,1.1840357465907296,3.0790648904084272,1.5437818750985217,1.2834108193237463,2.600706626787616,3.271045906996309,2.34,1.44,64.34,15.3,64.41,68.15,27.24,22.84
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837.0,152,32768,8304,2.49,3.425362121212961,1.7075812904135668,3.2913888394072224,1.7206139414306596,1.3859996030923867,2.600706626787616,3.271045906996309,2.49,1.07,55.33,11.23,60.71,67.18,26.84,23.89
google/gemma-2b (few-shot),2506.0,256,8192,6087,2.59,3.3879363934762274,1.3341715226792303,3.636052622656609,1.4160582616837596,1.3859996030923867,3.048762479599634,3.95320344080274,2.59,1.86,62.14,8.3,66.3,66.51,20.38,7.41
google/gemma-2b-it (few-shot),2506.0,256,8192,6471,2.74,3.3359906349944213,2.0592052071668494,3.8328878550218946,1.5437818750985217,1.3859996030923867,3.1887337541553538,3.8028358111004583,2.74,3.37,48.83,5.83,63.67,67.28,18.21,10.84
Qwen/Qwen1.5-0.5B (few-shot),620.0,152,32768,11371,2.87,3.3359906349944213,1.467188371713787,4.062219129869372,2.6355999469868365,1.6294020548885044,3.1887337541553538,3.8028358111004583,2.87,3.67,57.15,2.94,42.57,65.22,18.24,10.89
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,2.9,1.882527528243041,1.3341715226792303,3.636052622656609,1.5437818750985217,4.198842754402353,3.785839286822895,3.95320344080274,2.9,45.86,62.08,6.62,65.29,43.45,9.1,8.35
Qwen/Qwen1.5-0.5B-Chat (few-shot),620.0,152,32768,11740,2.92,3.3879363934762274,1.7075812904135668,4.062219129869372,2.1831456546703443,1.3859996030923867,3.618657063144775,4.090677912971175,2.92,2.16,55.41,1.15,53.27,65.82,11.66,5.22
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,3.45,2.8186102186343494,3.494700756589639,4.263803638113609,3.0520415448805314,2.0967690462620414,4.1376406256094045,4.292728748080362,3.45,18.69,21.95,0.01,36.7,60.11,3.71,0.62
RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,4.02,3.462380751776077,4.667268986626984,4.263803638113609,4.976513645902056,2.0967690462620414,4.356324338521481,4.292728748080362,4.02,0.0,0.0,0.41,0.0,61.26,0.0,0.36
ai-forever/mGPT (few-shot),unknown,100,1024,13551,4.39,3.3879363934762274,4.46914336710185,4.263803638113609,4.684264640402677,5.242024919989799,4.356324338521481,4.292728748080362,4.39,1.55,3.71,-0.42,5.57,34.62,0.37,-0.17
