model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,conll_nl,dutch_social,scala_nl,squad_nl
intfloat/multilingual-e5-large,559,250,512,6732,1.34,82.31,32.64,58.51,45.32
setu4993/LaBSE,470,501,512,13386,1.42,82.02,33.99,60.77,41.55
gpt-4-1106-preview (few-shot),-1,100,8192,4,1.65,66.44,15.05,74.01,57.81
DTAI-KULeuven/robbert-2022-dutch-base,118,43,512,11307,1.69,79.84,24.58,68.76,27.63
pdelobelle/robbert-v2-dutch-base,116,40,512,15481,1.72,78.3,26.68,63.83,28.34
ZurichNLP/unsup-simcse-xlm-roberta-base,277,250,512,10471,1.73,78.45,22.67,54.92,31.82
intfloat/multilingual-e5-base,277,250,512,14965,1.81,79.12,27.67,39.28,35.71
FacebookAI/xlm-roberta-large,559,250,512,6663,1.94,83.49,8.82,64.8,50.72
DTAI-KULeuven/robbertje-1-gb-non-shuffled,74,40,512,21007,1.99,74.5,32.23,54.57,6.31
microsoft/mdeberta-v3-base,278,251,512,9237,2.0,84.47,5.16,71.23,46.43
DTAI-KULeuven/robbert-2023-dutch-base,124,50,512,11230,2.01,82.22,28.2,55.12,9.74
DTAI-KULeuven/robbertje-1-gb-merged,74,40,512,21027,2.07,72.51,32.26,50.0,5.97
"gpt-3.5-turbo-0613 (few-shot, val)",-1,100,4095,1344,2.07,68.96,8.81,58.95,55.57
jhu-clsp/bernice,277,250,128,5567,2.08,78.74,22.58,55.39,5.95
DTAI-KULeuven/robbertje-1-gb-shuffled,74,40,512,20616,2.12,73.55,26.02,57.03,6.64
DTAI-KULeuven/robbert-2023-dutch-large,354,50,512,5444,2.13,81.05,16.35,65.18,11.44
cardiffnlp/twitter-xlm-roberta-base,277,250,512,14837,2.27,77.15,18.78,56.72,14.61
sentence-transformers/paraphrase-xlm-r-multilingual-v1,277,250,512,14994,2.3,70.59,21.37,45.86,5.2
microsoft/xlm-align-base,277,250,512,14744,2.34,78.85,11.8,14.56,42.08
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242,32,32768,2538,2.4,55.56,12.37,21.5,50.8
DTAI-KULeuven/robbertje-1-gb-bort,45,40,512,31087,2.42,66.74,24.93,37.19,5.23
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242,32,8192,2549,2.44,63.53,11.25,27.76,50.88
BramVanroy/GEITje-7B-ultra (few-shot),7242,32,8192,2475,2.56,42.25,12.78,18.23,53.41
sentence-transformers/quora-distilbert-multilingual,135,120,512,26458,2.59,67.89,23.25,21.36,4.5
Geotrend/distilbert-base-25lang-cased,108,85,512,26099,2.61,75.02,7.45,45.28,20.18
mistralai/Mistral-7B-v0.1 (few-shot),7242,32,32768,2657,2.62,58.15,7.94,25.41,50.14
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),-1,32,4096,7778,2.63,57.66,8.41,16.93,56.29
occiglot/occiglot-7b-eu5-instruct (few-shot),7242,32,32768,2088,2.64,48.14,7.78,16.23,63.09
Rijgersberg/GEITje-7B (few-shot),7242,32,32768,10401,2.65,47.53,4.36,30.67,56.55
Twitter/twhin-bert-base,278,250,512,11514,2.7,74.03,9.53,39.12,7.71
meta-llama/Llama-2-7b-chat-hf (few-shot),6738,32,4096,2643,2.7,50.23,10.07,14.73,53.41
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242,32,32768,5443,2.73,52.72,7.91,18.14,52.74
EuropeanParliament/EUBERT,93,66,512,20070,2.75,49.54,14.86,27.9,20.65
occiglot/occiglot-7b-eu5 (few-shot),7242,32,32768,2219,2.76,42.51,7.41,13.04,59.28
Twitter/twhin-bert-large,560,250,512,5299,2.81,77.35,6.55,18.25,28.37
AI-Sweden-Models/roberta-large-1350k,354,50,512,5744,2.85,73.03,3.65,2.0,42.85
Qwen/Qwen1.5-4B-Chat (few-shot),3950,152,32768,4347,2.88,22.82,14.68,4.07,55.18
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918,64,2048,4880,2.89,35.3,15.67,1.76,45.05
Qwen/Qwen1.5-4B (few-shot),3950,152,32768,3248,2.91,24.85,12.55,0.23,51.3
01-ai/Yi-6B (few-shot),6061,64,4096,2786,2.93,46.34,8.96,0.88,55.24
AI-Sweden-Models/roberta-large-1160k,354,50,512,5741,2.99,70.92,3.5,2.06,41.4
meta-llama/Llama-2-7b-hf (few-shot),6738,32,4096,2648,3.03,40.49,7.1,18.66,37.51
sentence-transformers/distiluse-base-multilingual-cased-v1,135,120,512,26344,3.11,58.67,17.82,9.27,2.17
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),-1,32,4096,10890,3.18,35.49,11.36,2.52,37.61
sentence-transformers/distiluse-base-multilingual-cased,135,120,512,19206,3.2,56.98,9.66,19.37,3.11
google/gemma-2b-it (few-shot),2506,256,8192,6471,3.21,29.22,11.25,-2.27,45.88
google/gemma-2b (few-shot),2506,256,8192,6087,3.25,17.12,9.95,0.41,49.15
jpostma/DagoBERT,116,40,512,11241,3.31,42.28,8.01,31.21,3.65
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837,152,32768,8304,3.47,23.79,6.82,4.11,33.1
Qwen/Qwen1.5-1.8B (few-shot),1837,152,32768,5666,3.52,17.85,5.2,2.89,34.6
3ebdola/Dialectal-Arabic-XLM-R-Base,277,250,512,15177,3.56,44.46,8.39,2.07,4.3
dbmdz/bert-tiny-historic-multilingual-cased,5,32,512,78027,3.6,41.38,8.45,1.55,4.4
Qwen/Qwen1.5-0.5B (few-shot),620,152,32768,11371,3.68,22.6,4.54,-0.42,20.81
Qwen/Qwen1.5-0.5B-Chat (few-shot),620,152,32768,11740,3.69,8.34,8.59,0.34,26.61
allenai/OLMo-1B (few-shot),1177,50,2176,8536,3.9,19.25,4.92,-1.27,6.64
fresh-xlm-roberta-base,277,250,512,1319,4.09,13.09,0.92,1.93,0.26
RJuro/kanelsnegl-v0.1 (few-shot),7242,32,512,9757,4.27,0.0,0.95,0.0,0.0
ai-forever/mGPT (few-shot),-1,100,1024,13551,4.36,0.11,-0.67,-0.97,0.29
