model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,conll_en,sst5,scala_en,squad
microsoft/deberta-v3-large,434.0,128,512,2521,1.25,91.88,64.04,75.1,74.47
microsoft/deberta-v3-base,184.0,128,512,5367,2.75,91.57,61.66,68.74,68.69
roberta-large,354.0,50,512,4542,2.75,91.53,62.92,48.77,71.23
google/electra-base-discriminator,109.0,31,512,9977,4.0,89.83,63.55,67.87,58.27
microsoft/mdeberta-v3-base,278.0,251,512,9237,4.25,91.83,53.75,62.11,62.1
roberta-base,124.0,50,512,13354,4.25,91.0,59.54,57.29,62.75
AI-Sweden-Models/roberta-large-1160k,354.0,50,512,5741,4.5,89.53,53.9,55.31,69.89
AI-Sweden-Models/roberta-large-1350k,354.0,50,512,5744,4.5,89.48,51.88,50.69,69.46
"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,4.5,71.48,66.41,41.43,67.9
bert-large-cased,333.0,29,512,5051,5.0,89.84,58.19,63.62,55.17
xlm-roberta-large,559.0,250,512,6663,5.0,89.81,41.97,35.55,68.88
google/electra-large-discriminator,334.0,31,512,4700,5.25,67.87,48.08,55.46,70.66
01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,5.5,52.7,68.66,25.29,75.83
bert-large-uncased,334.0,31,512,4711,5.75,88.8,57.94,59.27,52.38
mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,5.75,63.4,68.17,30.92,58.79
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,6.0,64.93,64.14,28.08,62.09
distilroberta-base,82.0,50,512,17448,6.25,90.04,56.08,54.9,49.36
meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,6.5,62.53,62.23,22.71,64.54
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,6.5,57.58,61.44,34.92,65.46
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,6.75,69.16,63.85,28.4,52.69
bert-base-multilingual-cased,177.0,120,512,14083,7.0,89.32,41.89,38.34,55.19
bert-base-uncased,109.0,31,512,10296,7.0,87.62,54.01,56.97,42.37
Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,7.25,53.39,65.21,12.63,65.74
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,7.25,62.11,59.91,30.66,58.3
microsoft/phi-2 (few-shot),2780.0,51,2048,3472,7.5,1.42,62.4,12.31,75.79
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,8.0,45.86,62.08,6.62,65.29
Qwen/Qwen1.5-1.8B (few-shot),1837.0,152,32768,5666,8.0,1.44,64.34,15.3,64.41
meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,8.25,55.27,65.16,20.43,44.64
distilbert-base-cased,65.0,29,512,19667,8.5,84.75,50.94,53.47,24.93
distilbert-base-multilingual-cased,135.0,120,512,26355,8.75,87.7,36.48,40.79,29.0
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837.0,152,32768,8304,10.0,1.07,55.33,11.23,60.71
Qwen/Qwen1.5-0.5B-Chat (few-shot),620.0,152,32768,11740,11.0,2.16,55.41,1.15,53.27
Qwen/Qwen1.5-0.5B (few-shot),620.0,152,32768,11371,11.0,3.67,57.15,2.94,42.57
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,12.75,18.69,21.95,0.01,36.7
ai-forever/mGPT (few-shot),unknown,100,1024,13551,14.25,1.55,3.71,-0.42,5.57
RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,15.25,0.0,0.0,0.41,0.0
