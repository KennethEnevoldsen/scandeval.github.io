model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,conll_en_rank,sst5_rank,scala_en_rank,squad_rank,en_rank,conll_en,sst5,scala_en,squad
microsoft/deberta-v3-large,434.0,128,512,2521,1.06,1.0,1.22826583412485,1.0,1.0,1.06,91.88,64.04,75.1,74.47
microsoft/deberta-v3-base,184.0,128,512,5367,1.29,1.0,1.4640004560563433,1.2858759208735875,1.4147256705759144,1.29,91.57,61.66,68.74,68.69
roberta-large,354.0,50,512,4542,1.37,1.0,1.3387257391815128,1.8895017057080894,1.2674631648036603,1.37,91.53,62.92,48.77,71.23
google/electra-base-discriminator,109.0,31,512,9977,1.42,1.0506085701174872,1.3387257391815128,1.2858759208735875,2.0189304626505855,1.42,89.83,63.55,67.87,58.27
roberta-base,124.0,50,512,13354,1.52,1.0243277181456212,1.5989523925211775,1.7114366772872822,1.7599271280833426,1.52,91.0,59.54,57.29,62.75
AI-Sweden-Models/roberta-large-1160k,354.0,50,512,5741,1.56,1.0506085701174872,1.970579757907271,1.8895017057080894,1.3366568153284122,1.56,89.53,53.9,55.31,69.89
AI-Sweden-Models/roberta-large-1350k,354.0,50,512,5744,1.56,1.0506085701174872,1.970579757907271,1.8895017057080894,1.3366568153284122,1.56,89.48,51.88,50.69,69.46
microsoft/mdeberta-v3-base,278.0,251,512,9237,1.56,1.0,1.970579757907271,1.5159695250592178,1.7599271280833426,1.56,91.83,53.75,62.11,62.1
bert-large-cased,333.0,29,512,5051,1.59,1.0506085701174872,1.5989523925211775,1.5159695250592178,2.199207459362249,1.59,89.84,58.19,63.62,55.17
"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,1.62,1.5609777621984668,1.0,2.513397642866483,1.4147256705759144,1.62,71.48,66.41,41.43,67.9
bert-large-uncased,334.0,31,512,4711,1.7,1.0704106780306637,1.710345229837645,1.7114366772872822,2.3109485061012256,1.7,88.8,57.94,59.27,52.38
google/electra-large-discriminator,334.0,31,512,4700,1.71,1.5609777621984668,2.313768464020264,1.7114366772872822,1.2674631648036603,1.71,67.87,48.08,55.46,70.66
xlm-roberta-large,559.0,250,512,6663,1.8,1.0506085701174872,2.313768464020264,2.513397642866483,1.3366568153284122,1.8,89.81,41.97,35.55,68.88
01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,1.82,2.058071887866262,1.0,3.2385998876495092,1.0,1.82,52.7,68.66,25.29,75.83
distilroberta-base,82.0,50,512,17448,1.83,1.0506085701174872,1.8331088381021654,1.8895017057080894,2.5378338016346578,1.83,90.04,56.08,54.9,49.36
mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,1.86,1.7409886522780653,1.0,2.805981142028677,1.8787329675628854,1.86,63.4,68.17,30.92,58.79
bert-base-uncased,109.0,31,512,10296,1.9,1.1149045795816706,1.970579757907271,1.7114366772872822,2.8122767037326986,1.9,87.62,54.01,56.97,42.37
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,1.93,1.7409886522780653,1.22826583412485,2.997392343930394,1.7599271280833426,1.93,64.93,64.14,28.08,62.09
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,1.94,1.9428619651638317,1.4640004560563433,2.805981142028677,1.5540050590058048,1.94,57.58,61.44,34.92,65.46
meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,1.98,1.8068578446049957,1.3387257391815128,3.2385998876495092,1.5540050590058048,1.98,62.53,62.23,22.71,64.54
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,2.02,1.5609777621984668,1.22826583412485,2.997392343930394,2.3109485061012256,2.02,69.16,63.85,28.4,52.69
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,2.07,1.8068578446049957,1.4640004560563433,2.997392343930394,2.0189304626505855,2.07,62.11,59.91,30.66,58.3
bert-base-multilingual-cased,177.0,120,512,14083,2.14,1.0704106780306637,2.7736327650673545,2.513397642866483,2.199207459362249,2.14,89.32,41.89,38.34,55.19
Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,2.16,2.058071887866262,1.22826583412485,3.807548384177044,1.5540050590058048,2.16,53.39,65.21,12.63,65.74
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,2.29,2.2651643033792395,1.3387257391815128,4.002210626972329,1.5540050590058048,2.29,45.86,62.08,6.62,65.29
distilbert-base-cased,65.0,29,512,19667,2.3,1.1961188621048204,2.1738813169344473,1.8895017057080894,3.9574396197739645,2.3,84.75,50.94,53.47,24.93
Qwen/Qwen1.5-4B (few-shot),3950.0,152,32768,3248,2.31,3.4962231892141697,1.4640004560563433,2.997392343930394,1.2674631648036603,2.31,0.76,60.55,28.6,70.49
meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,2.31,1.9428619651638317,1.22826583412485,3.2385998876495092,2.8122767037326986,2.31,55.27,65.16,20.43,44.64
Qwen/Qwen1.5-4B-Chat (few-shot),3950.0,152,32768,4347,2.36,3.4962231892141697,1.5989523925211775,2.997392343930394,1.3366568153284122,2.36,0.73,59.62,28.55,70.04
microsoft/phi-2 (few-shot),2780.0,51,2048,3472,2.4,3.4663604450813366,1.3387257391815128,3.807548384177044,1.0,2.4,1.42,62.4,12.31,75.79
Qwen/Qwen1.5-1.8B (few-shot),1837.0,152,32768,5666,2.51,3.4663604450813366,1.22826583412485,3.6876301968885605,1.6637200944357535,2.51,1.44,64.34,15.3,64.41
google/gemma-2b (few-shot),2506.0,256,8192,6087,2.59,3.4663604450813366,1.3387257391815128,4.002210626972329,1.5540050590058048,2.59,1.86,62.14,8.3,66.3
distilbert-base-multilingual-cased,135.0,120,512,26355,2.62,1.1149045795816706,3.1317450971260348,2.513397642866483,3.721164139288546,2.62,87.7,36.48,40.79,29.0
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837.0,152,32768,8304,2.75,3.4962231892141697,1.8331088381021654,3.807548384177044,1.8787329675628854,2.75,1.07,55.33,11.23,60.71
google/gemma-2b-it (few-shot),2506.0,256,8192,6471,2.88,3.4249118751232546,2.313768464020264,4.113380960658457,1.6637200944357535,2.88,3.37,48.83,5.83,63.67
Qwen/Qwen1.5-0.5B-Chat (few-shot),620.0,152,32768,11740,2.96,3.4663604450813366,1.8331088381021654,4.242904695017893,2.3109485061012256,2.96,2.16,55.41,1.15,53.27
Qwen/Qwen1.5-0.5B (few-shot),620.0,152,32768,11371,3.05,3.4249118751232546,1.710345229837645,4.242904695017893,2.8122767037326986,3.05,3.67,57.15,2.94,42.57
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,3.68,3.0120835902123133,4.094262716042978,4.356757366504455,3.2737021321929483,3.68,18.69,21.95,0.01,36.7
ai-forever/mGPT (few-shot),unknown,100,1024,13551,4.55,3.4663604450813366,5.302897230890926,4.356757366504455,5.08223721851321,4.55,1.55,3.71,-0.42,5.57
RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,4.71,3.525761102289115,5.548639216566036,4.356757366504455,5.406054827661028,4.71,0.0,0.0,0.41,0.0
