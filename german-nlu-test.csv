model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,germeval_rank,sb10k_rank,scala_de_rank,germanquad_rank,de_rank,germeval,sb10k,scala_de,germanquad
deepset/gbert-large,335.0,31,512,5463,1.04,1.0,1.0,1.0,1.1666019674126171,1.04,82.15,66.16,77.48,32.63
google/rembert,575.0,250,256,3355,1.17,1.0775868931048234,1.4012391640317952,1.2187387683080009,1.0,1.17,79.32,59.69,72.25,34.48
xlm-roberta-large,559.0,250,512,6663,1.25,1.0445280796736989,1.4012391640317952,1.3873729180807768,1.1666019674126171,1.25,80.27,58.44,62.12,32.23
microsoft/mdeberta-v3-base,278.0,251,512,9237,1.3,1.0,1.4012391640317952,1.2187387683080009,1.5963251536590386,1.3,81.05,59.5,71.84,26.25
sentence-transformers/use-cmlm-multilingual,470.0,501,512,13305,1.39,1.1126905198476502,1.4012391640317952,1.6648287779503192,1.3660344514738259,1.39,78.99,59.17,61.58,30.42
deepset/gbert-base,109.0,31,512,16043,1.6,1.0,1.4012391640317952,1.3873729180807768,2.605245320713119,1.6,81.33,57.77,66.13,16.68
setu4993/LaBSE,470.0,501,512,13386,1.62,1.1126905198476502,1.4012391640317952,2.000956095945607,1.9471653573278211,1.62,78.94,58.2,53.53,23.55
dbmdz/bert-base-german-cased,109.0,31,512,11844,1.71,1.0445280796736989,1.783062192221606,1.3873729180807768,2.605245320713119,1.71,80.9,53.44,67.08,14.49
dbmdz/bert-base-german-uncased,109.0,31,512,11438,1.73,1.0775868931048234,1.6139950323517607,1.3873729180807768,2.858201535310366,1.73,79.93,56.26,68.22,13.87
ZurichNLP/unsup-simcse-xlm-roberta-base,277.0,250,512,10471,1.75,1.1942379911216594,1.4012391640317952,2.000956095945607,2.4110599023856616,1.75,76.7,57.27,52.46,18.24
"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,1.83,1.736113005864403,1.6139950323517607,2.6100977804070213,1.3660344514738259,1.83,61.5,55.5,38.96,30.2
facebook/xlm-v-base,778.0,902,512,13135,1.88,1.2617655285271125,1.4012391640317952,2.6100977804070213,2.232437449082246,1.88,73.96,57.43,35.0,20.81
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,1.92,1.58939319796459,1.4012391640317952,3.1073992879203676,1.5963251536590386,1.92,64.81,59.6,27.06,25.22
microsoft/infoxlm-base,277.0,250,512,14918,2.07,1.0775868931048234,1.4012391640317952,3.5771557273619172,2.232437449082246,2.07,79.97,58.3,11.85,19.63
cardiffnlp/twitter-xlm-roberta-base,277.0,250,512,14837,2.13,1.1942379911216594,1.1759897713236063,2.1742081563411584,3.971609798933017,2.13,75.55,63.32,49.39,1.43
mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,2.14,1.9069113468796184,1.6139950323517607,3.1073992879203676,1.9471653573278211,2.14,55.37,54.27,23.12,22.94
Twitter/twhin-bert-large,560.0,250,512,5299,2.16,1.2617655285271125,1.6139950323517607,2.8919113851847067,2.858201535310366,2.16,74.8,55.04,29.15,11.93
microsoft/xlm-align-base,277.0,250,512,14744,2.17,1.0775868931048234,1.4012391640317952,3.5771557273619172,2.605245320713119,2.17,79.38,58.58,15.34,16.58
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,2.2,1.9069113468796184,1.9917874090148682,3.312544581802762,1.5963251536590386,2.2,56.71,49.77,19.92,27.87
jhu-clsp/bernice,277.0,250,128,5567,2.2,1.3528875990548974,1.1759897713236063,2.1742081563411584,4.109266442353977,2.2,72.25,62.0,48.1,0.0
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,2.24,1.9069113468796184,1.9917874090148682,3.1073992879203676,1.9471653573278211,2.24,55.15,47.85,24.29,23.98
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,2.25,2.082269537432912,1.9917874090148682,3.312544581802762,1.5963251536590386,2.25,51.79,47.27,22.15,24.3
clips/mfaq,277.0,250,128,5591,2.29,1.1942379911216594,1.4012391640317952,2.6100977804070213,3.971609798933017,2.29,76.68,59.51,32.54,1.53
01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,2.32,2.3256264696346465,1.783062192221606,3.807323719345257,1.3660344514738259,2.32,44.97,53.14,7.64,30.12
sentence-transformers/paraphrase-xlm-r-multilingual-v1,277.0,250,512,14994,2.36,1.3528875990548974,1.4012391640317952,2.6100977804070213,4.082045769223519,2.36,71.8,57.71,38.75,0.3
meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,2.38,2.1461930147593757,2.21660458044586,3.5771557273619172,1.5963251536590386,2.38,50.0,46.54,15.3,25.57
dbmdz/bert-base-historic-multilingual-cased,110.0,32,512,15165,2.41,1.5313596222102523,2.5279632711008504,2.1742081563411584,3.410684453855732,2.41,67.24,41.36,48.21,7.75
sentence-transformers/stsb-xlm-r-multilingual,277.0,250,512,15040,2.45,1.4543281210457746,1.783062192221606,2.6100977804070213,3.971609798933017,2.45,69.4,52.68,34.44,0.73
Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,2.46,2.43550839819568,1.9917874090148682,3.807323719345257,1.5963251536590386,2.46,39.09,47.83,10.31,26.13
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118.0,250,512,17428,2.52,1.58939319796459,1.6139950323517607,2.8919113851847067,3.971609798933017,2.52,65.62,55.6,32.22,0.64
AI-Sweden-Models/roberta-large-1160k,354.0,50,512,5741,2.55,1.4543281210457746,2.21660458044586,4.101749090815004,2.4110599023856616,2.55,68.39,45.91,2.79,18.83
AI-Sweden-Models/roberta-large-1350k,354.0,50,512,5744,2.57,1.5313596222102523,2.21660458044586,4.101749090815004,2.4110599023856616,2.57,67.24,45.84,2.28,18.17
meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,2.6,2.43550839819568,1.9917874090148682,3.5771557273619172,2.4110599023856616,2.6,41.88,50.17,15.82,18.35
sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking,135.0,120,512,26151,2.72,1.5313596222102523,1.9917874090148682,3.312544581802762,4.056896098884485,2.72,66.75,49.61,17.6,0.36
sentence-transformers/distiluse-base-multilingual-cased-v1,135.0,120,512,26344,2.79,2.011692298222804,1.783062192221606,3.312544581802762,4.056896098884485,2.79,53.77,53.53,20.15,0.58
sentence-transformers/distiluse-base-multilingual-cased-v2,135.0,120,512,17807,2.8,2.011692298222804,1.783062192221606,3.312544581802762,4.082045769223519,2.8,53.13,51.94,17.74,0.06
Qwen/Qwen1.5-4B-Chat (few-shot),3950.0,152,32768,4347,2.85,3.917097155491204,2.5279632711008504,3.5771557273619172,1.3660344514738259,2.85,0.33,41.52,12.78,29.35
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,3.01,2.6531948373902967,2.8572680761147393,4.101749090815004,2.4110599023856616,3.01,35.78,34.13,2.18,17.99
Qwen/Qwen1.5-4B (few-shot),3950.0,152,32768,3248,3.04,3.917097155491204,2.5279632711008504,4.101749090815004,1.5963251536590386,3.04,0.19,39.91,3.27,27.55
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,3.07,2.9581249300261114,2.8572680761147393,4.219618022520609,2.232437449082246,3.07,27.22,33.54,0.45,20.4
Qwen/Qwen1.5-1.8B (few-shot),1837.0,152,32768,5666,3.32,3.927609197313481,2.5279632711008504,4.219618022520609,2.605245320713119,3.32,0.03,38.3,0.39,16.67
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837.0,152,32768,8304,3.36,3.877189658364847,2.8572680761147393,4.101749090815004,2.605245320713119,3.36,1.45,36.21,3.12,16.36
3ebdola/Dialectal-Arabic-XLM-R-Base,277.0,250,512,15177,3.42,2.6531948373902967,2.8572680761147393,4.101749090815004,4.056896098884485,3.42,34.18,34.81,1.25,0.46
Qwen/Qwen1.5-0.5B-Chat (few-shot),620.0,152,32768,11740,3.8,3.7880082412214033,4.443601914947697,4.101749090815004,2.858201535310366,3.8,3.95,9.31,1.11,13.61
Qwen/Qwen1.5-0.5B (few-shot),620.0,152,32768,11371,3.81,3.720048385696919,4.443601914947697,4.219618022520609,2.858201535310366,3.81,5.85,10.64,0.33,11.81
fresh-electra-small,13.0,31,512,7219,4.09,3.592835029467419,4.443601914947697,4.219618022520609,4.109266442353977,4.09,9.42,9.76,-0.18,0.0
ai-forever/mGPT (few-shot),unknown,100,1024,13551,4.33,3.917097155491204,5.085222522445249,4.219618022520609,4.109266442353977,4.33,0.3,0.29,-0.11,0.0
RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,4.34,3.927609197313481,5.085222522445249,4.219618022520609,4.109266442353977,4.34,0.0,0.0,0.0,0.0
