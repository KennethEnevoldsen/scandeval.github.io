model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,germeval,sb10k,scala_de,germanquad
deepset/gbert-large,335,31,512,5463,1.04,82.15,66.16,77.48,32.63
google/rembert,575,250,256,3355,1.18,79.32,59.69,72.25,34.48
FacebookAI/xlm-roberta-large,559,250,512,6663,1.26,80.27,58.44,62.12,32.23
microsoft/mdeberta-v3-base,278,251,512,9237,1.31,81.05,59.5,71.84,26.25
sentence-transformers/use-cmlm-multilingual,470,501,512,13305,1.39,78.99,59.17,61.58,30.42
deepset/gbert-base,109,31,512,16043,1.6,81.33,57.77,66.13,16.68
setu4993/LaBSE,470,501,512,13386,1.62,78.94,58.2,53.53,23.55
dbmdz/bert-base-german-cased,109,31,512,11844,1.71,80.9,53.44,67.08,14.49
dbmdz/bert-base-german-uncased,109,31,512,11438,1.74,79.93,56.26,68.22,13.87
ZurichNLP/unsup-simcse-xlm-roberta-base,277,250,512,10471,1.76,76.7,57.27,52.46,18.24
"gpt-3.5-turbo-0613 (few-shot, val)",-1,100,4095,1344,1.83,61.5,55.5,38.96,30.2
facebook/xlm-v-base,778,902,512,13135,1.89,73.96,57.43,35.0,20.81
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242,32,8192,2549,1.93,64.81,59.6,27.06,25.22
microsoft/infoxlm-base,277,250,512,14918,2.1,79.97,58.3,11.85,19.63
cardiffnlp/twitter-xlm-roberta-base,277,250,512,14837,2.13,75.55,63.32,49.39,1.43
Twitter/twhin-bert-large,560,250,512,5299,2.17,74.8,55.04,29.15,11.93
mistralai/Mistral-7B-v0.1 (few-shot),7242,32,32768,2657,2.18,55.37,54.27,23.12,22.94
microsoft/xlm-align-base,277,250,512,14744,2.19,79.38,58.58,15.34,16.58
jhu-clsp/bernice,277,250,128,5567,2.2,72.25,62.0,48.1,0.0
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),-1,32,4096,7778,2.23,56.71,49.77,19.92,27.87
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242,32,32768,5443,2.23,51.79,47.27,22.15,24.3
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242,32,32768,2538,2.27,55.15,47.85,24.29,23.98
clips/mfaq,277,250,128,5591,2.3,76.68,59.51,32.54,1.53
01-ai/Yi-6B (few-shot),6061,64,4096,2786,2.32,44.97,53.14,7.64,30.12
sentence-transformers/paraphrase-xlm-r-multilingual-v1,277,250,512,14994,2.36,71.8,57.71,38.75,0.3
meta-llama/Llama-2-7b-chat-hf (few-shot),6738,32,4096,2643,2.39,50.0,46.54,15.3,25.57
dbmdz/bert-base-historic-multilingual-cased,110,32,512,15165,2.42,67.24,41.36,48.21,7.75
occiglot/occiglot-7b-de-en (few-shot),7242,32,32768,1992,2.43,0.75,54.96,21.57,31.49
Rijgersberg/GEITje-7B (few-shot),7242,32,32768,10401,2.46,39.09,47.83,10.31,26.13
sentence-transformers/stsb-xlm-r-multilingual,277,250,512,15040,2.46,69.4,52.68,34.44,0.73
occiglot/occiglot-7b-eu5 (few-shot),7242,32,32768,2219,2.52,0.67,47.3,21.83,31.55
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118,250,512,17428,2.52,65.62,55.6,32.22,0.64
AI-Sweden-Models/roberta-large-1160k,354,50,512,5741,2.58,68.39,45.91,2.79,18.83
AI-Sweden-Models/roberta-large-1350k,354,50,512,5744,2.59,67.24,45.84,2.28,18.17
meta-llama/Llama-2-7b-hf (few-shot),6738,32,4096,2648,2.6,41.88,50.17,15.82,18.35
DiscoResearch/DiscoLM_German_7b_v1 (few-shot),7242,32,32768,1972,2.62,2.21,48.67,8.72,34.07
"mayflowergmbh/Wiedervereinigung-7b-dpo (few-shot, val)",7242,32,32768,2374,2.69,6.74,51.92,29.06,15.01
sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking,135,120,512,26151,2.76,66.75,49.61,17.6,0.36
Qwen/Qwen1.5-4B-Chat (few-shot),3950,152,32768,4347,2.8,0.33,41.52,12.78,29.35
sentence-transformers/distiluse-base-multilingual-cased-v1,135,120,512,26344,2.81,53.77,53.53,20.15,0.58
sentence-transformers/distiluse-base-multilingual-cased-v2,135,120,512,17807,2.81,53.13,51.94,17.74,0.06
Qwen/Qwen1.5-4B (few-shot),3950,152,32768,3248,3.0,0.19,39.91,3.27,27.55
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918,64,2048,4880,3.01,35.78,34.13,2.18,17.99
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),-1,32,4096,10890,3.06,27.22,33.54,0.45,20.4
occiglot/occiglot-7b-de-en-instruct (few-shot),7242,32,32768,1584,3.06,0.76,55.91,22.47,3.85
occiglot/occiglot-7b-eu5-instruct (few-shot),7242,32,32768,2088,3.1,0.74,43.16,27.09,7.23
google/gemma-2b (few-shot),2506,256,8192,6087,3.11,1.08,44.96,0.77,17.92
google/gemma-2b-it (few-shot),2506,256,8192,6471,3.26,5.27,28.54,1.15,23.48
Qwen/Qwen1.5-1.8B (few-shot),1837,152,32768,5666,3.28,0.03,38.3,0.39,16.67
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837,152,32768,8304,3.33,1.45,36.21,3.12,16.36
3ebdola/Dialectal-Arabic-XLM-R-Base,277,250,512,15177,3.41,34.18,34.81,1.25,0.46
Qwen/Qwen1.5-0.5B-Chat (few-shot),620,152,32768,11740,3.78,3.95,9.31,1.11,13.61
Qwen/Qwen1.5-0.5B (few-shot),620,152,32768,11371,3.79,5.85,10.64,0.33,11.81
allenai/OLMo-1B (few-shot),1177,50,2080,8536,3.89,7.27,21.03,0.13,0.71
fresh-electra-small,13,31,512,7219,4.08,9.42,9.76,-0.18,0.0
ai-forever/mGPT (few-shot),-1,100,1024,13551,4.31,0.3,0.29,-0.11,0.0
RJuro/kanelsnegl-v0.1 (few-shot),7242,32,512,9757,4.32,0.0,0.0,0.0,0.0
