rank,model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,da_score,no_score,sv_score,dansk,angry_tweets,scala_da,scandiqa_da,nordjylland_news,mmlu_da,arc_da,hellaswag_da,norne_nb,norne_nn,norec,no_sammendrag,scala_nb,scala_nn,norquad,mmlu_no,arc_no,hellaswag_no,suc3,swerec,scala_sv,scandiqa_sv,swedn,mmlu_sv,arc_sv,hellaswag_sv
1,"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,58.52,56.72,57.31,61.54,59.61,50.54,57.57,51.09,66.38,39.74,65.24,59.36,77.7,73.92,58.88,64.35,54.29,32.82,46.44,40.26,65.97,59.02,73.04,72.77,58.06,57.59,66.66,40.73,63.58,50.51
2,RJuro/munin-neuralbeagle-7b (few-shot),7242.0,32,32768,2499,48.54,49.02,44.99,51.62,49.85,50.81,24.76,51.43,68.63,38.87,64.25,46.12,61.9,62.27,54.72,66.24,18.9,8.64,34.91,32.71,56.27,38.69,58.18,79.42,19.92,50.72,64.98,36.57,60.67,39.48
3,"birgermoell/NeuralBeagle-Flashback-dare-ties (few-shot, val)",7242.0,32,32768,2910,44.72,44.67,42.52,46.97,46.44,45.16,19.43,58.11,66.16,36.0,56.25,31.3,52.25,63.39,58.77,65.31,-2.15,-0.04,42.89,27.85,51.55,34.26,54.02,39.03,21.18,60.61,67.68,31.58,60.34,40.32
4,timpal0l/Mistral-7B-v0.1-flashback-v2 (few-shot),7242.0,32,32768,2505,42.0,39.68,36.79,49.52,41.66,47.52,17.36,51.28,66.48,31.12,47.36,14.21,48.28,50.51,49.76,64.48,14.54,9.16,32.04,25.52,44.4,15.04,44.16,80.29,34.8,51.82,64.96,33.42,57.37,25.2
4,mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,40.3,39.6,35.98,45.31,45.42,43.16,8.79,48.51,67.52,34.76,55.75,18.53,52.0,55.12,47.25,65.05,8.66,6.8,29.44,27.78,48.07,10.88,53.34,80.0,4.61,48.43,64.82,35.52,57.11,19.67
5,neph1/bellman-7b-mistral-instruct-v0.2 (few-shot),7242.0,32,32768,2518,37.71,38.76,33.57,40.8,46.11,47.58,18.41,46.93,66.66,24.43,43.68,11.59,57.01,56.77,38.81,63.93,14.16,9.29,25.79,17.08,37.58,10.52,54.38,55.84,16.05,48.44,65.03,22.36,44.29,12.52
5,danish-foundation-models/munin-7b-alpha (few-shot),7242.0,32,32768,3019,37.5,39.56,30.82,42.13,38.31,37.13,26.46,39.77,62.96,35.57,58.95,25.06,46.32,48.2,20.46,58.74,4.5,1.1,31.16,28.98,50.48,15.62,39.55,78.79,15.77,39.62,61.17,30.96,51.42,18.79
6,meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,32.01,30.68,27.35,38.01,31.77,43.91,0.31,45.42,66.53,16.18,21.61,7.93,42.13,43.8,41.74,64.71,0.0,0.02,18.67,14.48,19.2,6.49,44.11,79.05,7.34,43.42,64.31,15.65,22.6,8.74
7,AI-Sweden-Models/gpt-sw3-6.7b-v2 (few-shot),7111.0,64,2048,2351,26.67,23.65,24.28,32.08,20.84,18.07,10.54,39.18,66.28,4.93,5.23,5.57,29.62,32.3,34.67,63.58,8.37,7.76,24.67,3.03,1.92,5.57,28.73,77.47,8.78,35.78,63.08,5.23,5.49,5.39
7,AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct (few-shot),7111.0,64,2048,2383,26.36,23.06,26.09,29.94,15.35,2.85,10.99,44.04,67.12,8.25,11.72,11.08,24.67,29.03,34.39,64.83,2.42,5.11,31.39,6.89,10.3,12.81,14.58,56.6,10.92,42.72,64.86,6.16,11.86,10.9
8,mhenrichsen/danskgpt-tiny-chat (few-shot),1100.0,32,2048,1745,19.73,20.51,17.79,20.88,22.31,34.05,0.7,18.78,65.74,1.73,-1.91,2.11,28.74,30.34,27.49,60.72,-2.17,0.26,5.35,3.21,1.26,0.18,27.31,45.94,-0.97,15.08,58.65,0.14,-0.84,0.52
9,mhenrichsen/danskgpt-tiny (few-shot),1100.0,32,2048,8597,16.87,16.66,15.16,18.8,14.13,26.31,-0.54,14.16,63.76,-1.11,0.05,-0.7,27.37,27.59,18.09,58.73,-0.19,-0.8,2.15,-0.5,0.76,0.07,23.92,31.93,0.46,21.56,55.33,-0.85,0.17,-1.24
10,AI-Sweden-Models/gpt-sw3-126m (few-shot),186.0,64,2048,8958,10.65,10.88,10.3,10.76,3.43,9.18,-0.22,7.7,57.45,-0.37,0.23,-1.28,13.55,9.38,7.78,55.0,-1.46,-2.97,0.9,0.39,-0.51,-0.8,5.66,8.15,-0.81,7.64,54.07,-0.49,-0.66,1.17
