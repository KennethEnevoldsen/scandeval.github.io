rank,model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,da_score,no_score,sv_score,dansk,angry_tweets,scala_da,scandiqa_da,nordjylland_news,mmlu_da,arc_da,hellaswag_da,norne_nb,norne_nn,norec,no_sammendrag,scala_nb,scala_nn,norquad,mmlu_no,arc_no,hellaswag_no,suc3,swerec,scala_sv,scandiqa_sv,swedn,mmlu_sv,arc_sv,hellaswag_sv
1,"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,58.52,56.72,57.31,61.54,59.61,50.54,57.57,51.09,66.38,39.74,65.24,59.36,77.7,73.92,58.88,64.35,54.29,32.82,46.44,40.26,65.97,59.02,73.04,72.77,58.06,57.59,66.66,40.73,63.58,50.51
2,"RJuro/munin-neuralbeagle-7b (few-shot, val)",7242.0,32,32768,2493,49.23,49.48,46.22,52.0,51.44,54.91,22.77,56.7,68.75,37.02,63.51,41.49,61.18,65.16,55.61,65.99,20.84,9.12,42.98,27.77,54.47,39.67,62.96,77.13,15.73,58.43,67.58,32.54,61.97,34.94
2,"timpal0l/BeagleCatMunin2 (few-shot, val)",7242.0,32,32768,2477,48.55,47.78,46.39,51.47,51.53,47.95,14.1,58.28,68.44,37.34,66.59,42.21,61.17,65.44,58.69,66.08,15.03,5.95,42.42,27.31,56.92,41.63,60.87,73.72,6.78,58.69,68.06,33.71,67.71,41.45
2,"birgermoell/Munin-NeuralBeagle-NorskGPT (few-shot, val)",7242.0,32,32768,2903,48.0,45.13,48.4,50.49,51.85,44.02,1.22,57.38,68.14,36.17,66.24,42.09,63.33,68.84,58.28,65.94,18.65,10.72,44.57,26.61,58.53,46.64,63.85,73.72,-0.56,59.98,68.11,27.79,63.97,42.43
2,"birgermoell/WestLake-Munin-Cat-NorskGPT (few-shot, val)",7242.0,32,32768,2856,48.0,45.13,48.4,50.49,51.85,44.02,1.22,57.38,68.14,36.17,66.24,42.09,63.33,68.84,58.28,65.94,18.65,10.72,44.57,26.61,58.53,46.64,63.85,73.72,-0.56,59.98,68.11,27.79,63.97,42.43
2,bineric/NorskGPT-Mistral-7b (few-shot),7242.0,32,32768,2443,47.28,43.66,48.48,49.71,50.76,40.41,0.0,57.24,67.61,34.79,57.52,43.42,63.28,61.25,56.9,66.2,13.86,10.17,49.06,32.37,58.24,47.62,58.4,74.3,0.0,59.13,65.33,35.01,59.22,43.72
2,"birgermoell/BeagleCatMunin-Flashback-Bellman (few-shot, val)",7242.0,32,32768,2890,47.05,47.32,43.21,50.62,50.4,52.3,21.3,58.23,66.78,37.14,59.96,33.7,53.96,63.45,52.7,65.23,14.87,2.48,41.56,27.42,51.66,36.05,52.96,76.99,14.27,60.1,67.62,27.95,64.7,36.11
2,"birgermoell/Flashback-Bellman (few-shot, val)",7242.0,32,32768,2887,46.39,44.79,42.71,51.67,47.71,48.21,19.55,58.27,66.17,32.41,58.14,28.33,56.44,66.56,53.24,64.96,11.96,2.5,42.02,26.64,51.17,31.14,55.29,78.29,18.45,60.18,67.54,29.44,59.54,37.45
3,"birgermoell/NeuralBeagle-Flashback (few-shot, val)",7242.0,32,32768,2904,42.14,42.7,41.05,42.67,48.28,44.2,22.79,58.16,66.22,23.49,44.0,25.54,51.78,61.22,53.06,65.11,10.27,8.06,41.18,25.61,43.76,27.67,51.73,36.06,19.42,59.03,67.55,23.1,48.12,29.31
3,timpal0l/Mistral-7B-v0.1-flashback-v2 (few-shot),7242.0,32,32768,2505,42.0,39.68,36.79,49.52,41.66,47.52,17.36,51.28,66.48,31.12,47.36,14.21,48.28,50.51,49.76,64.48,14.54,9.16,32.04,25.52,44.4,15.04,44.16,80.29,34.8,51.82,64.96,33.42,57.37,25.2
3,mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,40.3,39.6,35.98,45.31,45.42,43.16,8.79,48.51,67.52,34.76,55.75,18.53,52.0,55.12,47.25,65.05,8.66,6.8,29.44,27.78,48.07,10.88,53.34,80.0,4.61,48.43,64.82,35.52,57.11,19.67
4,mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,38.06,37.19,35.28,41.72,37.93,44.49,14.09,51.42,66.59,24.65,37.27,14.85,50.08,51.27,43.65,63.31,14.09,8.28,37.31,20.44,29.49,15.87,45.01,73.33,11.59,52.05,63.91,24.03,37.48,15.37
4,neph1/bellman-7b-mistral-instruct-v0.2 (few-shot),7242.0,32,32768,2518,37.71,38.76,33.57,40.8,46.11,47.58,18.41,46.93,66.66,24.43,43.68,11.59,57.01,56.77,38.81,63.93,14.16,9.29,25.79,17.08,37.58,10.52,54.38,55.84,16.05,48.44,65.03,22.36,44.29,12.52
5,danish-foundation-models/munin-7b-alpha (few-shot),7242.0,32,32768,3019,37.5,39.56,30.82,42.13,38.31,37.13,26.46,39.77,62.96,35.57,58.95,25.06,46.32,48.2,20.46,58.74,4.5,1.1,31.16,28.98,50.48,15.62,39.55,78.79,15.77,39.62,61.17,30.96,51.42,18.79
6,meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,34.79,34.7,31.57,38.1,35.44,44.88,9.74,55.0,66.86,17.57,21.78,11.32,44.99,49.09,41.56,64.39,3.04,4.03,33.76,14.81,21.17,12.69,39.72,66.18,6.74,54.07,65.64,17.73,25.2,12.85
7,meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,32.01,30.68,27.35,38.01,31.77,43.91,0.31,45.42,66.53,16.18,21.61,7.93,42.13,43.8,41.74,64.71,0.0,0.02,18.67,14.48,19.2,6.49,44.11,79.05,7.34,43.42,64.31,15.65,22.6,8.74
8,AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,30.44,27.68,28.42,35.22,27.41,30.24,11.34,52.8,64.47,5.03,3.95,3.03,30.82,39.56,34.51,63.1,15.17,12.46,42.81,4.51,3.98,5.27,31.86,78.88,12.26,53.58,64.14,3.15,2.99,2.77
8,Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,29.8,27.8,25.73,35.88,33.41,26.08,-0.22,51.9,65.25,12.68,15.27,4.19,41.44,45.09,34.51,62.38,0.0,0.56,24.53,8.98,12.43,4.46,41.08,76.38,-0.21,52.58,62.36,13.09,17.64,3.59
8,AI-Sweden-Models/gpt-sw3-6.7b-v2 (few-shot),7111.0,64,2048,2351,26.67,23.65,24.28,32.08,20.84,18.07,10.54,39.18,66.28,4.93,5.23,5.57,29.62,32.3,34.67,63.58,8.37,7.76,24.67,3.03,1.92,5.57,28.73,77.47,8.78,35.78,63.08,5.23,5.49,5.39
8,AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct (few-shot),7111.0,64,2048,2383,26.36,23.06,26.09,29.94,15.35,2.85,10.99,44.04,67.12,8.25,11.72,11.08,24.67,29.03,34.39,64.83,2.42,5.11,31.39,6.89,10.3,12.81,14.58,56.6,10.92,42.72,64.86,6.16,11.86,10.9
9,AI-Sweden-Models/gpt-sw3-1.3b (few-shot),1445.0,64,2048,4608,22.63,21.19,20.07,26.64,8.8,28.65,2.84,45.31,63.77,-1.05,-0.38,-0.33,13.49,14.74,27.28,61.24,3.09,1.86,34.9,-0.01,0.45,0.25,6.08,71.38,1.17,45.53,60.9,2.2,-0.76,0.67
9,mhenrichsen/danskgpt-tiny-chat (few-shot),1100.0,32,2048,1745,19.73,20.51,17.79,20.88,22.31,34.05,0.7,18.78,65.74,1.73,-1.91,2.11,28.74,30.34,27.49,60.72,-2.17,0.26,5.35,3.21,1.26,0.18,27.31,45.94,-0.97,15.08,58.65,0.14,-0.84,0.52
10,RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,18.06,15.11,16.81,22.28,10.12,10.65,-0.66,26.21,60.03,0.76,-0.23,-0.88,21.04,18.71,12.22,60.08,-1.18,0.36,26.79,0.21,-1.42,-0.3,22.38,31.11,0.09,44.37,58.49,1.12,-0.28,-0.91
10,mhenrichsen/danskgpt-tiny (few-shot),1100.0,32,2048,8597,16.87,16.66,15.16,18.8,14.13,26.31,-0.54,14.16,63.76,-1.11,0.05,-0.7,27.37,27.59,18.09,58.73,-0.19,-0.8,2.15,-0.5,0.76,0.07,23.92,31.93,0.46,21.56,55.33,-0.85,0.17,-1.24
11,RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,11.05,10.81,8.78,13.56,0.0,13.0,0.0,0.0,62.29,0.64,0.0,0.04,0.0,0.0,0.95,60.13,0.0,0.0,0.0,0.18,0.0,0.3,0.0,34.63,0.0,0.0,60.3,-0.25,0.0,0.08
11,AI-Sweden-Models/gpt-sw3-126m (few-shot),186.0,64,2048,8958,10.65,10.88,10.3,10.76,3.43,9.18,-0.22,7.7,57.45,-0.37,0.23,-1.28,13.55,9.38,7.78,55.0,-1.46,-2.97,0.9,0.39,-0.51,-0.8,5.66,8.15,-0.81,7.64,54.07,-0.49,-0.66,1.17
11,NbAiLab/nb-gpt-j-6B-v2 (few-shot),6051.0,50,1024,2556,8.25,9.52,8.24,6.98,0.24,0.0,0.92,6.82,58.94,-0.18,0.0,-0.18,5.29,6.77,0.0,49.57,0.2,-0.9,2.45,0.0,0.0,0.0,0.31,0.33,0.41,17.79,29.95,0.17,0.0,-0.01
11,NbAiLab/nb-gpt-j-6B@sharded (few-shot),unknown,50,1024,2630,7.18,8.78,6.59,6.17,0.36,-1.0,-0.75,5.16,57.26,0.0,0.24,0.33,0.22,0.24,0.0,44.8,0.75,0.42,0.55,-0.01,-0.03,0.0,0.01,7.45,0.0,4.82,30.78,0.29,0.32,-0.15
11,ai-forever/mGPT (few-shot),unknown,100,1024,13551,5.14,4.88,4.57,5.96,0.65,0.41,-0.11,2.0,31.24,0.58,0.17,-0.41,0.08,0.0,-0.73,33.33,-0.23,0.88,0.0,-0.4,0.32,-0.94,0.0,0.0,1.38,6.24,34.81,-0.16,-0.83,-0.19
