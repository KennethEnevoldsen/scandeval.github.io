model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,is_rank,fo_rank,mim_gold_ner,scala_is,nqii,fone,scala_fo
vesteinn/FoBERT,124,50,512,15623,1.43,1.85,1.0,85.04,50.78,17.76,91.31,64.39
microsoft/mdeberta-v3-base,278,251,512,9237,1.61,1.4,1.82,81.12,54.11,30.93,88.6,46.81
"gpt-4-1106-preview (few-shot, val)",-1,100,128000,576,1.74,1.08,2.39,86.37,52.13,37.26,86.51,35.09
vesteinn/ScandiBERT-no-faroese,124,50,512,15436,1.95,1.54,2.36,83.94,58.64,25.35,88.14,27.71
NbAiLab/nb-roberta-base-scandi-1e4,277,250,512,15074,2.14,2.48,1.8,81.83,51.09,6.66,90.52,44.99
google/rembert,575,250,256,3355,2.23,1.53,2.92,78.05,48.29,29.38,87.35,14.65
sentence-transformers/use-cmlm-multilingual,470,501,512,13305,2.3,2.25,2.35,80.91,41.91,13.73,88.81,30.92
jonfd/electra-small-nordic,22,96,128,5989,2.38,2.36,2.4,77.4,60.64,6.51,85.8,30.88
mideind/IceBERT-xlmr-ic3,277,250,512,11004,2.49,2.06,2.92,84.35,59.12,11.18,87.79,22.51
pere/roberta-base-exp-32,277,250,512,15081,2.54,2.77,2.31,83.57,23.07,7.81,90.6,22.86
setu4993/LaBSE,470,501,512,13386,2.66,2.42,2.9,80.45,36.92,11.75,89.16,22.76
vesteinn/XLMR-ENIS,125,50,512,10711,2.69,1.56,3.81,82.2,48.51,27.06,87.09,3.09
mideind/IceBERT-large,406,50,512,5677,2.71,1.98,3.43,85.14,59.31,12.84,86.84,9.82
mideind/IceBERT,124,50,512,16697,2.71,1.98,3.43,85.32,60.44,13.31,86.5,10.13
vesteinn/IceBERT,163,50,512,12360,2.87,2.07,3.67,85.34,55.88,13.31,87.13,3.66
mideind/IceBERT-ic3,124,50,512,12119,2.95,2.23,3.66,85.03,45.06,10.82,87.22,6.23
mideind/IceBERT-igc,124,50,512,12551,3.0,2.28,3.73,79.85,54.38,9.91,83.82,4.93
"gpt-3.5-turbo-0613 (few-shot, val)",-1,100,4095,921,3.02,2.37,3.67,69.59,7.28,28.5,72.48,8.29
Geotrend/bert-base-25lang-cased,151,85,512,13908,3.1,3.25,2.96,74.65,2.89,9.29,86.09,15.24
FacebookAI/xlm-roberta-large,559,250,512,6663,3.12,2.45,3.79,82.83,22.78,15.72,87.85,1.17
intfloat/multilingual-e5-large,559,250,512,6732,3.29,2.79,3.79,78.43,10.78,13.79,88.39,2.85
mideind/IceBERT-mC4-is,163,50,512,12308,3.34,3.29,3.4,79.19,20.95,0.0,88.44,11.83
cardiffnlp/twitter-xlm-roberta-base,277,250,512,14837,3.38,2.9,3.87,72.69,28.72,8.46,83.96,1.05
KennethEnevoldsen/dfm-sentence-encoder-large-1,354,50,512,6245,3.39,3.6,3.18,48.31,3.18,7.94,72.99,13.4
Geotrend/bert-base-da-cased,103,23,512,15432,3.4,3.12,3.67,73.81,6.23,10.57,86.62,3.64
AI-Sweden-Models/roberta-large-1350k,354,50,512,5744,3.41,3.03,3.79,73.92,11.77,11.84,88.21,3.16
mhenrichsen/hestenettetLM (few-shot),7242,32,32768,5160,3.46,2.81,4.11,49.85,0.99,25.74,63.66,4.96
KBLab/megatron-bert-large-swedish-cased-165k,369,64,512,7138,3.47,3.43,3.51,63.35,4.94,7.02,82.76,7.58
AI-Sweden-Models/roberta-large-1160k,354,50,512,5741,3.48,3.17,3.79,74.3,2.06,11.47,88.24,1.73
KennethEnevoldsen/dfm-sentence-encoder-medium-2,124,50,512,14965,3.5,3.3,3.71,64.57,0.86,10.76,84.72,3.79
flax-community/nordic-roberta-wiki,124,50,512,16227,3.51,3.52,3.51,63.31,2.47,5.99,82.64,8.03
google-bert/bert-base-multilingual-uncased,167,106,512,13993,3.51,3.11,3.92,60.88,13.5,9.65,73.06,5.48
microsoft/xlm-align-base,277,250,512,14744,3.51,3.08,3.94,78.01,5.92,10.47,85.97,0.02
vesteinn/DanskBERT,124,50,512,15749,3.52,3.33,3.71,65.29,-0.03,10.49,85.04,4.48
mistralai/Mistral-7B-v0.1 (few-shot),7242,32,32768,2657,3.53,2.81,4.25,47.24,1.35,25.7,62.63,2.84
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242,32,8192,2549,3.53,2.94,4.11,49.86,1.26,22.42,62.78,3.69
NbAiLab/nb-roberta-base-scandinavian,125,50,512,14051,3.55,3.41,3.69,69.04,3.34,7.17,86.1,6.28
KennethEnevoldsen/dfm-sentence-encoder-medium,124,50,512,14998,3.56,3.27,3.85,64.88,-0.6,12.39,84.92,2.96
flax-community/swe-roberta-wiki-oscar,124,50,512,15437,3.56,3.58,3.55,62.23,1.45,5.52,80.52,6.51
microsoft/infoxlm-base,277,250,512,14918,3.58,3.23,3.94,77.09,1.71,8.56,85.58,0.35
Twitter/twhin-bert-large,560,250,512,5299,3.59,3.33,3.85,71.48,2.2,8.19,84.73,1.37
DeepPavlov/rubert-base-cased,177,120,512,15785,3.62,3.52,3.73,61.95,2.4,6.04,83.15,3.21
KBLab/megatron-bert-large-swedish-cased-110k,369,64,512,7075,3.62,3.48,3.75,63.11,3.47,7.76,82.36,5.2
sentence-transformers/stsb-xlm-r-multilingual,277,250,512,15040,3.63,3.4,3.87,66.23,0.04,10.04,82.97,2.93
KB/bert-base-swedish-cased,124,50,512,16181,3.67,3.61,3.73,60.09,1.76,5.57,82.76,3.98
patrickvonplaten/norwegian-roberta-base,124,50,512,15698,3.67,3.58,3.75,60.79,1.29,6.64,82.57,5.74
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918,64,2048,4880,3.69,3.01,4.38,27.54,4.61,28.12,46.5,3.95
"timpal0l/tyr (few-shot, val)",7242,32,32768,6079,3.69,2.96,4.42,50.64,-0.06,23.36,60.21,0.0
sentence-transformers/quora-distilbert-multilingual,135,120,512,26458,3.71,3.55,3.87,63.36,1.02,6.48,82.91,1.67
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242,32,32768,2538,3.72,3.19,4.25,43.11,3.4,19.18,61.28,1.68
DDSC/roberta-base-danish,125,50,512,15004,3.77,3.61,3.93,59.63,1.76,5.55,80.21,1.1
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118,250,512,17428,3.77,3.64,3.89,62.44,1.91,3.69,82.24,2.84
FacebookAI/roberta-base,124,50,512,13354,3.79,3.58,4.01,60.18,1.07,6.66,81.78,-1.18
dbmdz/bert-medium-historic-multilingual-cased,42,32,512,24291,3.79,3.64,3.93,58.9,0.27,5.9,80.58,1.58
occiglot/occiglot-7b-eu5-instruct (few-shot),7242,32,32768,2088,3.79,3.22,4.36,36.79,0.71,20.66,61.9,0.0
pdelobelle/robbert-v2-dutch-base,116,40,512,15481,3.82,3.66,3.97,55.54,1.06,5.42,78.59,0.65
danish-foundation-models/encoder-large-v1,354,50,512,6671,3.83,3.57,4.08,49.68,0.33,9.3,72.46,2.93
deepset/gbert-base,109,31,512,16043,3.85,3.66,4.05,56.89,-0.13,6.69,80.48,0.6
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242,32,32768,5443,3.87,3.34,4.4,36.04,-0.36,18.06,55.42,1.11
DDSC/roberta-base-scandinavian,124,50,512,14491,3.88,3.69,4.08,51.53,0.89,5.19,63.86,0.73
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),-1,32,4096,7778,3.88,3.35,4.42,28.35,3.14,19.8,60.54,-0.33
KBLab/albert-base-swedish-cased-alpha,14,50,512,15925,3.9,3.75,4.06,42.07,0.27,7.35,73.8,0.81
meta-llama/Llama-2-7b-hf (few-shot),6738,32,4096,2648,3.91,3.31,4.51,32.71,0.66,18.04,52.34,0.11
bineric/NorskGPT-Llama-7B-v0.1 (few-shot),6738,32,4096,5384,3.92,3.34,4.51,34.62,-0.24,18.1,53.38,0.46
occiglot/occiglot-7b-eu5 (few-shot),7242,32,32768,2219,3.92,3.41,4.42,36.1,1.59,15.98,58.74,0.0
meta-llama/Llama-2-7b-chat-hf (few-shot),6738,32,4096,2643,3.93,3.44,4.42,41.1,-1.07,16.13,59.77,-0.54
sarnikowski/convbert-medium-small-da-cased,24,29,512,13821,4.07,3.98,4.16,28.16,2.05,5.37,59.66,4.58
danish-foundation-models/encoder-small-v1,22,96,128,6002,4.08,4.24,3.93,28.99,-0.17,0.42,79.97,0.93
tollefj/nordavind-7b-instruct-warm (few-shot),7248,33,2048,6450,4.1,3.61,4.59,34.66,0.77,12.8,50.63,-0.52
ltg/norbert2,125,50,512,15523,4.11,4.05,4.16,28.74,3.0,3.47,60.57,4.16
Maltehb/aelaectra-danish-electra-small-uncased,14,32,128,5995,4.12,4.13,4.11,30.5,3.59,0.06,62.07,5.11
sarnikowski/convbert-small-da-cased,13,29,512,14273,4.12,4.04,4.2,25.49,1.63,5.28,58.5,5.96
TurkuNLP/bert-base-finnish-cased-v1,124,50,512,16701,4.21,3.95,4.47,34.58,0.55,5.07,51.26,1.77
timpal0l/Mistral-7B-v0.1-flashback-v2-instruct (few-shot),7242,32,32768,5172,4.23,3.88,4.59,24.98,1.18,8.52,43.52,1.82
asafaya/bert-base-arabic,110,32,512,16347,4.34,4.1,4.59,22.51,0.23,5.05,50.44,-0.06
google/gemma-2b (few-shot),2506,256,8192,6087,4.38,3.81,4.94,9.04,0.31,16.08,22.37,1.28
alpindale/Mistral-7B-v0.2-hf (few-shot),7242,32,32768,3467,4.39,3.44,5.35,0.93,-0.44,25.38,3.0,1.3
Maltehb/danish-bert-botxo,110,32,512,16091,4.42,4.24,4.59,12.64,0.06,4.77,43.59,3.13
google/gemma-2b-it (few-shot),2506,256,8192,6471,4.44,3.89,4.99,20.6,-0.01,10.95,34.58,-1.62
fresh-xlm-roberta-base,277,250,512,1319,4.45,4.37,4.52,17.34,-0.06,1.02,48.7,2.37
alexanderfalk/danbert-small-cased,83,52,512,30013,4.47,4.36,4.59,12.39,1.63,1.7,45.16,2.24
HPLT/gpt-7b-nordic-prerelease (few-shot),7550,131,4096,5404,4.5,3.53,5.46,3.9,-0.0,23.17,4.0,-0.48
Qwen/Qwen1.5-1.8B (few-shot),1837,152,32768,5666,4.54,4.15,4.94,12.21,0.94,6.31,19.56,1.14
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837,152,32768,8304,4.57,4.08,5.06,14.13,0.78,7.8,25.82,0.15
Qwen/Qwen1.5-4B-Chat (few-shot),3950,152,32768,4347,4.57,3.84,5.31,7.94,-0.35,14.55,11.62,-0.42
allenai/OLMo-1B (few-shot),1177,50,2176,8536,4.58,4.38,4.78,13.6,-1.04,1.51,31.84,1.01
01-ai/Yi-6B (few-shot),6061,64,4096,2786,4.62,3.72,5.53,0.0,2.12,16.91,0.0,-0.28
Qwen/Qwen1.5-4B (few-shot),3950,152,32768,3248,4.65,3.91,5.39,4.16,-0.55,14.11,7.72,-0.36
Qwen/Qwen1.5-0.5B (few-shot),620,152,32768,11371,4.67,4.26,5.08,16.02,-0.57,3.31,29.84,-1.47
Qwen/Qwen1.5-0.5B-Chat (few-shot),620,152,32768,11740,4.7,4.33,5.06,9.5,1.76,3.14,22.3,-0.54
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),-1,32,4096,10890,4.81,4.43,5.19,9.48,0.07,1.04,18.86,-0.43
fresh-electra-small,13,31,512,7219,4.9,4.49,5.31,9.96,-0.1,0.12,12.1,0.64
ltg/norbert,112,33,512,16280,5.04,4.56,5.53,0.0,-0.03,1.68,0.0,-1.21
RJuro/kanelsnegl-v0.1 (few-shot),7242,32,512,9757,5.08,4.63,5.53,0.0,0.0,0.0,0.0,0.0
ai-forever/mGPT (few-shot),-1,100,1024,13551,5.08,4.63,5.53,0.0,0.0,0.0,0.0,-0.24
