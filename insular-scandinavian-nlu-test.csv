model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,is_rank,fo_rank,mim_gold_ner,scala_is,nqii,fone,scala_fo
vesteinn/FoBERT,124,50,512,15623,1.48,1.95,1.0,85.04,50.78,17.76,91.31,64.39
microsoft/mdeberta-v3-base,278,251,512,9237,1.62,1.4,1.84,81.12,54.11,30.93,88.6,46.81
"gpt-4-1106-preview (few-shot, val)",-1,100,128000,576,1.75,1.08,2.41,86.37,52.13,37.26,86.51,35.09
vesteinn/ScandiBERT-no-faroese,124,50,512,15436,1.97,1.54,2.39,83.94,58.64,25.35,88.14,27.71
NbAiLab/nb-roberta-base-scandi-1e4,277,250,512,15074,2.15,2.48,1.82,81.83,51.09,6.66,90.52,44.99
google/rembert,575,250,256,3355,2.25,1.53,2.96,78.05,48.29,29.38,87.35,14.65
sentence-transformers/use-cmlm-multilingual,470,501,512,13305,2.37,2.35,2.38,80.91,41.91,13.73,88.81,30.92
jonfd/electra-small-nordic,22,96,128,5989,2.4,2.36,2.43,77.4,60.64,6.51,85.8,30.88
mideind/IceBERT-xlmr-ic3,277,250,512,11004,2.51,2.06,2.96,84.35,59.12,11.18,87.79,22.51
pere/roberta-base-exp-32,277,250,512,15081,2.55,2.77,2.34,83.57,23.07,7.81,90.6,22.86
setu4993/LaBSE,470,501,512,13386,2.69,2.43,2.94,80.45,36.92,11.75,89.16,22.76
mideind/IceBERT-large,406,50,512,5677,2.71,1.96,3.47,85.14,59.31,12.84,86.84,9.82
mideind/IceBERT,124,50,512,16697,2.71,1.96,3.47,85.32,60.44,13.31,86.5,10.13
vesteinn/XLMR-ENIS,125,50,512,10711,2.71,1.56,3.87,82.2,48.51,27.06,87.09,3.09
vesteinn/IceBERT,163,50,512,12360,2.89,2.05,3.73,85.34,55.88,13.31,87.13,3.66
mideind/IceBERT-ic3,124,50,512,12119,2.97,2.23,3.71,85.03,45.06,10.82,87.22,6.23
mideind/IceBERT-igc,124,50,512,12551,3.04,2.28,3.79,79.85,54.38,9.91,83.82,4.93
"gpt-3.5-turbo-0613 (few-shot, val)",-1,100,4095,921,3.05,2.38,3.72,69.59,7.28,28.5,72.48,8.29
Geotrend/bert-base-25lang-cased,151,85,512,13908,3.12,3.26,2.99,74.65,2.89,9.29,86.09,15.24
FacebookAI/xlm-roberta-large,559,250,512,6663,3.16,2.48,3.84,82.83,22.78,15.72,87.85,1.17
intfloat/multilingual-e5-large,559,250,512,6732,3.37,2.9,3.84,78.43,10.78,13.79,88.39,2.85
mideind/IceBERT-mC4-is,163,50,512,12308,3.38,3.3,3.45,79.19,20.95,0.0,88.44,11.83
KennethEnevoldsen/dfm-sentence-encoder-large-1,354,50,512,6245,3.42,3.62,3.22,48.31,3.18,7.94,72.99,13.4
cardiffnlp/twitter-xlm-roberta-base,277,250,512,14837,3.42,2.91,3.93,72.69,28.72,8.46,83.96,1.05
AI-Sweden-Models/roberta-large-1350k,354,50,512,5744,3.44,3.04,3.84,73.92,11.77,11.84,88.21,3.16
Geotrend/bert-base-da-cased,103,23,512,15432,3.44,3.14,3.73,73.81,6.23,10.57,86.62,3.64
mhenrichsen/hestenettetLM (few-shot),7242,32,32768,5160,3.49,2.82,4.15,50.82,0.99,25.74,62.82,4.96
KBLab/megatron-bert-large-swedish-cased-165k,369,64,512,7138,3.5,3.44,3.55,63.35,4.94,7.02,82.76,7.58
AI-Sweden-Models/roberta-large-1160k,354,50,512,5741,3.51,3.19,3.84,74.3,2.06,11.47,88.24,1.73
KennethEnevoldsen/dfm-sentence-encoder-medium-2,124,50,512,14965,3.54,3.32,3.77,64.57,0.86,10.76,84.72,3.79
flax-community/nordic-roberta-wiki,124,50,512,16227,3.54,3.53,3.55,63.31,2.47,5.99,82.64,8.03
google-bert/bert-base-multilingual-uncased,167,106,512,13993,3.54,3.12,3.97,60.88,13.5,9.65,73.06,5.48
microsoft/xlm-align-base,277,250,512,14744,3.55,3.1,4.0,78.01,5.92,10.47,85.97,0.02
mistralai/Mistral-7B-v0.1 (few-shot),7242,32,32768,2657,3.55,2.82,4.29,47.24,1.35,25.7,62.63,2.84
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242,32,8192,2549,3.55,2.95,4.15,49.86,1.26,22.42,62.78,3.69
vesteinn/DanskBERT,124,50,512,15749,3.56,3.35,3.77,65.29,-0.03,10.49,85.04,4.48
NbAiLab/nb-roberta-base-scandinavian,125,50,512,14051,3.58,3.42,3.75,69.04,3.34,7.17,86.1,6.28
KennethEnevoldsen/dfm-sentence-encoder-medium,124,50,512,14998,3.59,3.27,3.91,64.88,-0.6,12.39,84.92,2.96
flax-community/swe-roberta-wiki-oscar,124,50,512,15437,3.6,3.6,3.6,62.23,1.45,5.52,80.52,6.51
"mlabonne/AlphaMonarch-7B (few-shot, val)",7242,32,8192,5340,3.61,3.07,4.15,50.85,1.8,20.23,64.39,4.74
microsoft/infoxlm-base,277,250,512,14918,3.62,3.25,4.0,77.09,1.71,8.56,85.58,0.35
Twitter/twhin-bert-large,560,250,512,5299,3.63,3.35,3.91,71.48,2.2,8.19,84.73,1.37
KBLab/megatron-bert-large-swedish-cased-110k,369,64,512,7075,3.65,3.49,3.81,63.11,3.47,7.76,82.36,5.2
DeepPavlov/rubert-base-cased,177,120,512,15785,3.66,3.53,3.79,61.95,2.4,6.04,83.15,3.21
sentence-transformers/stsb-xlm-r-multilingual,277,250,512,15040,3.67,3.42,3.93,66.23,0.04,10.04,82.97,2.93
KB/bert-base-swedish-cased,124,50,512,16181,3.71,3.63,3.79,60.09,1.76,5.57,82.76,3.98
patrickvonplaten/norwegian-roberta-base,124,50,512,15698,3.71,3.6,3.81,60.79,1.29,6.64,82.57,5.74
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918,64,2048,4880,3.73,3.02,4.44,27.54,4.61,28.12,46.5,3.95
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242,32,32768,2538,3.73,3.16,4.29,43.11,3.4,19.18,61.28,1.68
"timpal0l/tyr (few-shot, val)",7242,32,32768,6079,3.73,2.98,4.48,50.64,-0.06,23.36,60.21,0.0
sentence-transformers/quora-distilbert-multilingual,135,120,512,26458,3.75,3.56,3.93,63.36,1.02,6.48,82.91,1.67
occiglot/occiglot-7b-eu5-instruct (few-shot),7242,32,32768,2088,3.8,3.19,4.41,36.79,0.71,20.66,61.9,0.0
DDSC/roberta-base-danish,125,50,512,15004,3.81,3.63,3.99,59.63,1.76,5.55,80.21,1.1
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118,250,512,17428,3.81,3.66,3.95,62.44,1.91,3.69,82.24,2.84
dbmdz/bert-medium-historic-multilingual-cased,42,32,512,24291,3.82,3.65,3.99,58.9,0.27,5.9,80.58,1.58
FacebookAI/roberta-base,124,50,512,13354,3.83,3.6,4.06,60.18,1.07,6.66,81.78,-1.18
danish-foundation-models/encoder-large-v1,354,50,512,6671,3.86,3.58,4.14,49.68,0.33,9.3,72.46,2.93
pdelobelle/robbert-v2-dutch-base,116,40,512,15481,3.86,3.68,4.03,55.54,1.06,5.42,78.59,0.65
deepset/gbert-base,109,31,512,16043,3.89,3.67,4.11,56.89,-0.13,6.69,80.48,0.6
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),-1,32,4096,7778,3.9,3.31,4.48,28.35,3.14,19.8,60.54,-0.33
occiglot/occiglot-7b-eu5 (few-shot),7242,32,32768,2219,3.91,3.34,4.48,36.1,1.59,15.98,58.74,0.0
meta-llama/Llama-2-7b-chat-hf (few-shot),6738,32,4096,2643,3.93,3.37,4.48,41.1,-1.07,16.13,59.77,-0.54
KBLab/albert-base-swedish-cased-alpha,14,50,512,15925,3.95,3.77,4.12,42.07,0.27,7.35,73.8,0.81
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242,32,32768,5443,3.96,3.46,4.46,36.04,-0.36,18.06,55.42,1.11
DDSC/roberta-base-scandinavian,124,50,512,14491,4.0,3.71,4.29,51.53,0.89,5.19,63.86,0.73
meta-llama/Llama-2-7b-hf (few-shot),6738,32,4096,2648,4.0,3.43,4.57,32.71,0.66,18.04,52.34,0.11
bineric/NorskGPT-Llama-7B-v0.1 (few-shot),6738,32,4096,5384,4.02,3.46,4.57,34.62,-0.24,18.1,53.38,0.46
tollefj/nordavind-7b-instruct-warm (few-shot),7248,33,2048,6450,4.09,3.61,4.57,34.76,0.77,12.8,53.24,-0.52
sarnikowski/convbert-medium-small-da-cased,24,29,512,13821,4.11,4.0,4.22,28.16,2.05,5.37,59.66,4.58
LumiOpen/Viking-13B (few-shot),14030,131,4224,3480,4.12,3.47,4.76,20.51,1.12,21.85,43.11,-0.26
danish-foundation-models/encoder-small-v1,22,96,128,6002,4.12,4.25,3.99,28.99,-0.17,0.42,79.97,0.93
HPLT/gpt-7b-nordic-prerelease (few-shot),7550,131,4096,5404,4.13,3.26,5.0,27.96,-0.0,23.17,32.16,-0.48
ltg/norbert2,125,50,512,15523,4.14,4.06,4.22,28.74,3.0,3.47,60.57,4.16
Maltehb/aelaectra-danish-electra-small-uncased,14,32,128,5995,4.15,4.15,4.15,30.5,3.59,0.06,62.07,5.11
sarnikowski/convbert-small-da-cased,13,29,512,14273,4.16,4.06,4.26,25.49,1.63,5.28,58.5,5.96
TurkuNLP/bert-base-finnish-cased-v1,124,50,512,16701,4.25,3.96,4.53,34.58,0.55,5.07,51.26,1.77
timpal0l/Mistral-7B-v0.1-flashback-v2-instruct (few-shot),7242,32,32768,5172,4.27,3.89,4.65,24.98,1.18,8.52,43.52,1.82
Qwen/Qwen1.5-4B (few-shot),3950,152,32768,3248,4.34,3.78,4.9,15.66,-0.55,14.11,34.2,-0.36
asafaya/bert-base-arabic,110,32,512,16347,4.38,4.12,4.65,22.51,0.23,5.05,50.44,-0.06
google/gemma-2b (few-shot),2506,256,8192,6087,4.41,3.75,5.07,8.83,0.31,16.08,20.15,1.28
alpindale/Mistral-7B-v0.2-hf (few-shot),7242,32,32768,3467,4.44,3.45,5.43,0.93,-0.44,25.38,3.0,1.3
Maltehb/danish-bert-botxo,110,32,512,16091,4.45,4.25,4.65,12.64,0.06,4.77,43.59,3.13
google/gemma-2b-it (few-shot),2506,256,8192,6471,4.45,3.9,5.0,20.49,-0.01,10.95,37.6,-1.62
fresh-xlm-roberta-base,277,250,512,1319,4.48,4.39,4.58,17.34,-0.06,1.02,48.7,2.37
alexanderfalk/danbert-small-cased,83,52,512,30013,4.51,4.37,4.65,12.39,1.63,1.7,45.16,2.24
allenai/OLMo-7B-Twin-2T (few-shot),6888,50,2176,5484,4.59,4.11,5.07,9.04,-0.08,8.86,19.57,0.7
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837,152,32768,8304,4.61,4.09,5.12,14.15,0.78,7.8,26.11,0.15
Qwen/Qwen1.5-1.8B (few-shot),1837,152,32768,5666,4.62,4.17,5.07,12.26,0.94,6.31,18.65,1.14
Qwen/Qwen1.5-4B-Chat (few-shot),3950,152,32768,4347,4.62,3.87,5.38,7.94,-0.35,14.55,11.62,-0.42
allenai/OLMo-1B (few-shot),1177,50,2176,8536,4.64,4.4,4.89,13.6,-1.04,1.51,31.84,1.01
allenai/OLMo-7B (few-shot),6888,50,2176,5403,4.65,4.31,5.0,8.84,-0.38,5.08,25.08,1.69
Qwen/Qwen1.5-0.5B (few-shot),620,152,32768,11371,4.69,4.28,5.1,16.2,-0.57,3.31,29.34,-1.47
01-ai/Yi-6B (few-shot),6061,64,4096,2786,4.72,3.84,5.6,0.0,2.12,16.91,0.0,-0.28
Qwen/Qwen1.5-0.5B-Chat (few-shot),620,152,32768,11740,4.77,4.34,5.19,9.5,1.76,3.14,22.3,-0.54
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),-1,32,4096,10890,4.82,4.45,5.19,9.48,0.07,1.04,18.86,-0.43
fresh-electra-small,13,31,512,7219,4.94,4.5,5.38,9.96,-0.1,0.12,12.1,0.64
ltg/norbert,112,33,512,16280,5.08,4.57,5.6,0.0,-0.03,1.68,0.0,-1.21
NorGLM/NorGPT-369M (few-shot),-1,64,1024,19896,5.09,4.63,5.55,1.68,-1.38,0.08,1.84,0.0
RJuro/kanelsnegl-v0.1 (few-shot),7242,32,512,9757,5.12,4.64,5.6,0.0,0.0,0.0,0.0,0.0
ai-forever/mGPT (few-shot),-1,100,1024,13551,5.12,4.64,5.6,0.0,0.0,0.0,0.0,-0.24
