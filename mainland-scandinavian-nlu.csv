rank,model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,score,da_score,no_score,sv_score,dansk,angry_tweets,scala_da,scandiqa_da,norne_nb,norne_nn,norec,scala_nb,scala_nn,norquad,suc3,swerec,scala_sv,scandiqa_sv
1,ltg/norbert3-large,354.0,50,508,5048,67.78,60.51,74.76,68.08,73.62,48.29,71.55,48.59,93.12,89.39,64.62,77.97,76.3,66.03,79.01,75.32,69.11,48.88
1,"gpt-4-0613 (few-shot, val)",unknown,100,8192,1244,67.34,61.57,67.09,73.37,64.94,59.97,71.56,49.82,81.16,75.75,72.72,77.3,57.18,49.93,76.86,79.19,80.93,56.5
2,danish-foundation-models/encoder-large-v1,355.0,50,512,6671,64.31,62.39,65.49,65.05,74.6,51.42,76.11,47.42,88.66,84.59,55.59,71.43,53.3,57.38,74.18,75.11,64.11,46.79
2,KennethEnevoldsen/dfm-sentence-encoder-large-1,355.0,50,512,6245,64.24,62.35,66.32,64.05,74.99,53.85,75.71,44.85,86.39,83.22,59.61,67.88,62.44,55.69,71.65,74.92,63.43,46.2
2,KennethEnevoldsen/dfm-sentence-encoder-large-2,355.0,50,512,6569,64.24,62.98,66.24,63.52,75.3,55.12,76.34,45.15,86.78,83.28,58.73,70.73,59.58,56.04,71.86,74.67,62.77,44.77
2,google/rembert,576.0,250,256,3355,63.7,57.49,65.53,68.1,70.19,50.19,69.72,39.85,88.7,86.11,54.19,69.83,54.84,58.18,78.23,75.99,72.17,46.0
2,microsoft/mdeberta-v3-base,279.0,251,512,9237,62.86,56.37,64.44,67.78,72.9,43.38,67.05,42.15,91.9,86.81,53.69,70.55,61.21,48.82,78.84,75.24,72.3,44.74
3,NbAiLab/nb-roberta-base-scandi,278.0,250,512,15079,62.7,56.44,66.16,65.49,73.28,52.08,67.99,32.39,92.24,87.58,59.98,70.18,70.81,44.27,80.02,76.21,71.92,33.8
3,intfloat/multilingual-e5-large,560.0,250,512,6732,62.44,57.24,62.56,67.54,69.5,55.07,57.67,46.71,89.86,84.32,61.52,62.34,34.88,53.01,80.36,79.65,63.15,46.99
3,NbAiLab/nb-roberta-base-scandi-1e4,278.0,250,512,15074,61.93,53.96,66.29,65.53,72.16,51.7,62.03,29.95,92.09,86.85,59.84,73.33,71.06,43.67,79.9,76.2,73.62,32.38
3,ltg/norbert3-base,124.0,50,508,11405,61.4,52.38,69.86,61.95,73.26,43.94,51.62,40.7,92.36,88.49,59.73,74.4,68.85,57.67,78.21,71.05,56.02,42.52
3,KennethEnevoldsen/dfm-sentence-encoder-medium-3,178.0,120,512,14050,61.28,56.45,64.01,63.39,71.21,47.55,68.72,38.33,91.17,87.3,59.1,74.32,72.94,34.06,81.35,71.16,63.89,37.18
3,vesteinn/ScandiBERT-no-faroese,124.0,50,512,15436,61.23,54.43,63.89,65.39,69.79,47.73,68.28,31.9,91.09,85.72,50.9,69.34,66.24,48.45,79.08,72.53,73.01,36.92
4,sentence-transformers/use-cmlm-multilingual,471.0,501,512,13305,60.83,53.71,63.11,65.66,69.17,48.03,55.31,42.34,90.08,86.04,56.35,59.38,46.54,55.05,80.05,75.09,61.83,45.69
4,NbAiLab/nb-bert-base,178.0,120,512,14050,60.67,54.88,64.39,62.74,70.36,46.32,66.41,36.42,93.01,88.43,60.84,73.89,72.1,33.01,80.38,71.21,64.03,35.33
4,vesteinn/FoBERT,124.0,50,512,15623,60.15,54.17,62.6,63.69,69.65,49.18,65.45,32.4,90.65,84.88,52.44,68.77,65.4,43.13,78.58,73.41,71.14,31.62
4,xlm-roberta-large,560.0,250,512,6663,60.14,55.48,61.61,63.33,72.74,48.33,57.3,43.57,91.66,86.19,50.25,55.51,43.89,57.57,80.33,76.63,49.72,46.64
4,pere/roberta-debug-8,278.0,250,512,15103,59.95,54.32,63.08,62.45,71.34,49.77,64.31,31.86,91.16,84.75,55.25,68.03,66.9,41.65,74.48,74.58,69.07,31.66
4,setu4993/LaBSE,471.0,501,512,13386,58.93,52.69,60.74,63.36,71.24,46.5,52.92,40.08,90.58,85.21,54.26,59.44,49.3,46.42,77.78,73.58,60.36,41.71
5,"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,58.75,54.7,56.17,65.37,59.61,50.54,57.57,51.09,77.7,73.92,58.88,54.29,32.82,46.44,73.04,72.77,58.06,57.59
5,pere/roberta-base-exp-8,278.0,250,512,15112,58.74,52.79,63.83,59.59,68.77,49.66,60.13,32.6,88.99,82.99,57.37,69.92,70.05,41.98,73.44,73.63,58.91,32.39
5,pere/roberta-debug-32,278.0,250,512,14958,58.74,53.4,60.5,62.34,68.46,50.48,64.34,30.3,89.07,83.27,53.23,70.06,66.81,34.17,72.25,75.04,70.16,31.89
5,gpt-3.5-turbo-0613 (few-shot),unknown,100,4096,1344,58.47,55.49,54.81,65.09,59.4,51.8,54.22,56.55,74.92,75.34,57.64,49.93,34.22,44.39,71.43,77.5,55.99,55.46
5,pere/roberta-base-exp-32,278.0,250,512,15081,57.64,50.05,62.81,60.06,71.9,51.33,44.45,32.51,91.66,87.74,57.43,63.31,62.79,41.05,79.75,74.73,53.55,32.2
5,AI-Sweden-Models/bert-large-nordic-pile-1M-steps,369.0,64,512,6571,56.03,46.96,52.1,69.05,67.4,41.53,41.62,37.3,87.5,80.57,47.11,52.62,25.06,38.4,80.65,77.43,76.56,41.54
6,pere/roberta-base-exp-32B,278.0,250,512,15103,55.06,51.14,56.67,57.38,71.81,47.83,54.99,29.92,90.6,86.76,52.19,54.98,58.33,29.17,77.97,73.27,47.19,31.07
6,vesteinn/DanskBERT,124.0,50,512,15749,54.51,59.57,52.31,51.65,72.55,52.86,75.2,37.65,86.82,79.91,47.84,51.99,30.57,36.75,72.33,67.77,33.79,32.71
6,ltg/norbert3-small,41.0,50,508,13515,54.2,48.24,62.56,51.81,67.89,39.34,50.9,34.82,90.02,86.52,51.36,67.29,56.67,48.63,74.22,63.8,37.77,31.45
6,KBLab/megatron-bert-large-swedish-cased-165k,370.0,64,512,7138,52.91,41.65,46.69,70.39,58.5,41.02,27.1,39.99,85.99,79.47,39.53,27.39,23.56,39.01,81.05,78.0,76.79,45.71
6,AI-Nordics/bert-large-swedish-cased,335.0,31,512,7199,52.54,42.27,47.34,68.02,60.66,38.46,32.29,37.68,83.32,77.97,38.44,37.54,23.1,39.97,78.61,77.47,72.87,43.11
7,cardiffnlp/twitter-xlm-roberta-base,278.0,250,512,14837,52.05,47.29,50.94,57.92,70.1,45.3,51.74,22.01,87.7,81.41,48.34,55.3,37.46,24.49,72.49,70.69,56.6,31.89
7,KBLab/megatron-bert-large-swedish-cased-110k,370.0,64,512,7075,51.65,41.35,43.68,69.92,60.18,39.2,26.68,39.34,84.03,77.98,39.15,21.39,17.1,35.32,80.39,78.45,76.28,44.56
8,bert-base-multilingual-uncased,167.0,106,512,13993,50.63,45.57,51.06,55.28,64.92,33.5,46.75,37.09,82.9,77.33,37.28,49.41,43.58,40.35,70.85,63.3,48.97,38.0
9,KB/bert-base-swedish-cased,125.0,50,512,16181,50.33,39.21,43.04,68.74,61.74,33.28,33.15,28.67,85.91,79.67,38.7,39.13,24.13,19.04,81.95,75.58,78.86,38.56
9,KBLab/bert-base-swedish-cased,125.0,50,512,16164,50.13,39.27,42.61,68.53,61.74,33.31,33.35,28.67,85.33,79.44,38.17,39.49,22.17,19.04,81.23,75.73,78.6,38.56
9,jonfd/electra-small-nordic,22.0,96,128,5989,49.76,43.43,51.22,54.63,65.4,34.43,67.27,6.6,84.95,79.57,40.15,72.87,63.77,14.16,71.07,66.42,69.19,11.85
9,bert-base-multilingual-cased,178.0,120,512,14083,49.52,40.76,51.05,56.75,63.17,32.38,27.93,39.57,88.72,83.08,35.87,44.22,39.55,40.55,76.29,61.78,47.74,41.17
9,KBLab/megatron-bert-base-swedish-cased-600k,135.0,64,512,15726,49.26,38.19,43.03,66.55,57.97,39.4,23.5,31.87,82.2,76.64,40.2,24.45,19.18,30.69,78.91,76.09,70.08,41.14
9,Geotrend/bert-base-en-fr-de-no-da-cased,118.0,42,512,13973,49.23,44.89,49.07,53.73,63.38,34.78,41.08,40.32,88.05,83.08,35.34,31.45,36.12,41.59,76.55,61.6,37.44,39.32
9,Geotrend/bert-base-en-no-cased,111.0,33,512,14081,49.11,44.37,49.54,53.42,62.66,33.91,40.96,39.93,89.07,82.69,34.97,39.58,31.27,41.89,75.33,61.8,36.62,39.95
9,facebook/xlm-v-base,778.0,902,512,13135,49.09,47.72,43.3,56.24,71.42,31.86,52.95,34.66,89.99,78.6,17.93,43.46,10.97,43.74,68.39,73.43,45.09,38.04
9,Geotrend/bert-base-25lang-cased,151.0,85,512,13908,48.84,40.98,51.22,54.32,62.53,32.88,29.01,39.51,87.99,83.1,36.21,46.43,39.82,40.01,75.62,62.5,38.18,40.96
10,microsoft/infoxlm-large,560.0,250,512,6696,48.48,42.97,47.09,55.39,74.42,37.94,15.26,44.25,91.9,86.59,30.56,9.79,6.36,60.47,79.53,75.42,18.44,48.19
11,Geotrend/bert-base-en-da-cased,111.0,33,512,14062,48.38,42.7,48.2,54.23,62.57,33.67,35.79,38.77,88.55,83.09,35.16,31.82,32.94,39.46,74.88,61.89,40.22,39.95
11,"RJuro/munin-neuralbeagle-7b (few-shot, val)",7242.0,32,32768,2493,48.07,46.45,44.18,53.56,51.44,54.91,22.77,56.7,61.18,65.16,55.61,20.84,9.12,42.98,62.96,77.13,15.73,58.43
11,Geotrend/bert-base-da-cased,104.0,23,512,15432,46.94,40.89,47.23,52.71,62.76,32.06,30.95,37.79,87.52,82.66,32.73,36.41,30.37,37.71,74.13,62.18,36.93,37.59
11,"timpal0l/BeagleCatMunin (few-shot, val)",7242.0,32,32768,2495,46.89,45.38,41.38,53.92,47.62,54.73,21.8,57.39,54.04,62.21,54.74,14.51,5.38,42.71,50.53,77.37,27.84,59.92
12,microsoft/xlm-align-base,278.0,250,512,14744,46.85,39.98,50.53,50.02,70.36,47.83,11.87,29.87,90.07,85.65,54.46,12.16,8.99,49.24,78.6,73.67,15.41,32.41
13,"merge-crew/da-sv-dare-ties-density-0.9 (few-shot, val)",7242.0,32,32768,2443,46.66,43.27,42.72,53.98,45.61,53.73,17.08,56.67,48.24,61.5,49.4,24.12,13.2,47.93,46.61,76.38,34.16,58.77
13,"merge-crew/da-sv-task-arithmetic (few-shot, val)",7242.0,32,32768,2500,46.44,45.76,39.27,54.28,46.06,51.51,27.68,57.78,49.69,61.78,55.87,2.99,-1.29,44.62,47.28,76.62,33.23,60.0
13,KBLab/megatron-bert-base-swedish-cased-125k,135.0,64,512,15763,46.4,35.39,38.03,65.78,53.93,36.31,23.46,27.85,77.98,75.0,33.88,24.23,18.18,20.56,79.29,75.85,70.43,37.56
13,"birgermoell/Flashback-Bellman (few-shot, val)",7242.0,32,32768,2887,45.83,43.44,41.0,53.05,47.71,48.21,19.55,58.27,56.44,66.56,53.24,11.96,2.5,42.02,55.29,78.29,18.45,60.18
13,"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,45.69,43.95,41.99,51.13,53.02,51.29,19.73,51.75,62.47,66.69,54.04,16.75,13.0,34.48,61.25,76.03,16.28,50.96
13,"birgermoell/BeagleCatMunin-Flashback-Bellman (few-shot, val)",7242.0,32,32768,2890,45.68,45.56,40.41,51.08,50.4,52.3,21.3,58.23,53.96,63.45,52.7,14.87,2.48,41.56,52.96,76.99,14.27,60.1
13,"timpal0l/BeagleCatMunin2 (few-shot, val)",7242.0,32,32768,2477,45.57,42.97,43.73,50.02,51.53,47.95,14.1,58.28,61.17,65.44,58.69,15.03,5.95,42.42,60.87,73.72,6.78,58.69
13,"birgermoell/Rapid-Cycling (few-shot, val)",7242.0,32,32768,2346,45.44,44.68,39.79,51.85,49.99,51.25,20.66,56.81,55.93,63.85,50.41,15.74,2.23,39.87,53.66,77.72,16.22,59.81
14,jhu-clsp/bernice,278.0,250,512,5567,45.09,40.81,41.42,53.05,61.98,47.2,40.52,13.53,84.11,77.82,39.63,45.75,33.74,5.35,71.34,70.91,53.52,16.41
14,flax-community/nordic-roberta-wiki,125.0,50,512,16227,44.99,41.0,39.45,54.52,60.82,34.45,41.89,26.83,85.42,78.92,36.27,48.07,29.81,0.44,72.9,61.11,55.05,29.04
15,"RJuro/munin-neuralbeagle-SkoleGPTOpenOrca-7b (few-shot, val)",7242.0,32,32768,3008,44.85,42.96,38.65,52.95,50.83,43.41,19.72,57.88,53.68,61.92,47.78,0.91,1.24,47.95,59.36,72.04,22.38,58.03
16,microsoft/infoxlm-base,278.0,250,512,14918,44.7,39.03,47.1,47.97,69.78,46.78,11.27,28.28,90.14,84.12,44.42,11.2,7.12,47.69,79.43,71.48,7.26,33.72
16,"birgermoell/Munin-NeuralBeagle-NorskGPT (few-shot, val)",7242.0,32,32768,2903,44.59,38.62,45.91,49.25,51.85,44.02,1.22,57.38,63.33,68.84,58.28,18.65,10.72,44.57,63.85,73.72,-0.56,59.98
16,"birgermoell/WestLake-Munin-Cat-NorskGPT (few-shot, val)",7242.0,32,32768,2856,44.59,38.62,45.91,49.25,51.85,44.02,1.22,57.38,63.33,68.84,58.28,18.65,10.72,44.57,63.85,73.72,-0.56,59.98
16,KBLab/bert-base-swedish-cased-new,135.0,64,512,15933,44.21,31.39,36.21,65.04,59.37,38.46,4.61,23.13,83.23,79.16,33.94,9.56,4.16,22.84,79.99,76.04,73.52,30.6
17,"merge-crew/da-sv-dare-ties-density-0.6 (few-shot, val)",7242.0,32,32768,2515,44.2,41.34,40.33,50.94,46.03,49.59,12.72,57.03,47.26,59.35,54.93,9.0,5.26,45.95,45.12,78.74,19.74,60.15
18,clips/mfaq,278.0,250,128,5591,43.83,39.17,42.81,49.51,68.49,45.6,28.26,14.34,89.46,79.71,52.91,27.55,15.2,12.36,76.31,73.32,32.29,16.12
18,sentence-transformers/paraphrase-xlm-r-multilingual-v1,278.0,250,512,14994,43.76,41.52,39.83,49.95,61.17,46.39,38.61,19.9,81.26,74.05,49.93,38.26,25.17,0.0,70.22,71.33,39.6,18.65
19,"ThatsGroes/munin-SkoleGPTOpenOrca-7b-16bit (few-shot, val)",7242.0,32,32768,3002,43.65,42.93,38.63,49.39,43.61,42.31,24.82,60.99,48.64,58.21,51.25,1.6,0.0,49.04,47.73,75.86,15.31,58.64
19,flax-community/swe-roberta-wiki-oscar,125.0,50,512,15437,43.53,35.03,33.88,61.67,55.98,36.66,22.69,24.81,79.25,75.39,36.56,22.02,19.72,0.78,75.4,76.22,65.73,29.34
19,bineric/NorskGPT-Mistral-7b (few-shot),7242.0,32,32768,2443,43.37,37.1,45.06,47.96,50.76,40.41,0.0,57.24,63.28,61.25,56.9,13.86,10.17,49.06,58.4,74.3,0.0,59.13
20,distilbert-base-multilingual-cased,135.0,120,512,26355,43.08,38.59,41.92,48.73,58.12,32.53,35.53,28.19,83.62,80.69,33.16,36.1,30.1,19.26,70.08,59.66,33.71,31.48
20,sentence-transformers/paraphrase-multilingual-mpnet-base-v2,278.0,250,512,15100,42.8,39.99,39.95,48.47,61.18,49.13,29.66,19.99,81.94,75.56,55.53,36.01,14.99,0.0,65.14,73.47,36.62,18.65
20,sentence-transformers/stsb-xlm-r-multilingual,278.0,250,512,15040,42.66,38.79,38.69,50.5,58.52,42.26,34.8,19.6,80.08,74.59,52.16,36.3,14.21,0.0,68.94,72.77,40.21,20.09
20,timpal0l/Mistral-7B-v0.1-flashback-v2 (few-shot),7242.0,32,32768,2505,42.66,39.45,35.76,52.77,41.66,47.52,17.36,51.28,48.28,50.51,49.76,14.54,9.16,32.04,44.16,80.29,34.8,51.82
20,DDSC/roberta-base-scandinavian,125.0,50,512,14491,42.6,36.91,41.07,49.83,43.9,44.48,30.37,28.89,71.73,79.8,46.74,8.02,17.04,29.26,58.84,72.28,37.61,30.59
20,Geotrend/distilbert-base-25lang-cased,109.0,85,512,26099,42.44,37.99,40.96,48.37,58.44,31.81,34.13,27.6,83.59,80.29,33.19,32.6,24.97,19.93,70.56,60.69,30.83,31.41
20,Geotrend/distilbert-base-en-fr-de-no-da-cased,76.0,42,512,26081,42.4,38.22,41.29,47.68,58.78,31.3,34.92,27.86,83.49,80.23,32.66,33.65,29.07,19.29,69.94,59.83,29.82,31.13
20,Geotrend/distilbert-base-en-no-cased,69.0,33,512,26597,42.23,37.83,41.71,47.15,57.53,32.95,33.63,27.21,83.93,79.39,32.32,36.15,30.17,19.71,69.28,59.53,29.36,30.42
20,Geotrend/distilbert-base-en-da-cased,69.0,33,512,26196,41.91,38.95,39.3,47.47,59.5,31.89,36.0,28.41,83.27,79.59,29.37,31.5,24.06,18.62,69.62,59.42,29.01,31.82
20,Geotrend/distilbert-base-da-cased,61.0,23,512,28950,41.63,38.19,39.67,47.03,58.36,32.13,34.75,27.5,82.84,78.83,30.7,34.24,27.2,16.44,69.25,58.47,29.8,30.61
20,"birgermoell/NeuralBeagle-Flashback (few-shot, val)",7242.0,32,32768,2904,41.63,43.36,39.98,41.56,48.28,44.2,22.79,58.16,51.78,61.22,53.06,10.27,8.06,41.18,51.73,36.06,19.42,59.03
21,sarnikowski/convbert-medium-small-da-cased,24.0,29,512,13821,40.91,47.3,36.92,38.5,64.28,36.85,63.55,24.52,79.5,73.03,32.4,41.65,25.53,5.41,58.01,57.67,13.4,24.92
21,RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,40.78,38.61,36.26,47.46,43.17,43.4,11.08,56.81,58.61,60.4,41.36,6.52,3.95,38.93,50.85,74.17,7.51,57.32
21,mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,40.76,40.88,35.59,45.82,44.89,48.09,19.06,51.49,53.42,54.34,38.79,17.06,11.0,35.68,47.92,62.9,19.95,52.5
21,Addedk/kbbert-distilled-cased,82.0,50,512,29698,40.23,31.25,31.65,57.79,57.84,31.18,13.25,22.73,81.82,75.89,33.42,14.99,13.63,0.0,80.12,71.28,51.58,28.16
21,Twitter/twhin-bert-large,561.0,250,512,5299,39.54,36.67,34.32,47.61,66.39,39.36,7.06,33.88,86.26,80.1,34.17,12.11,4.28,11.74,74.26,63.35,16.07,36.77
22,mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,39.39,36.98,35.7,45.5,37.93,44.49,14.09,51.42,50.08,51.27,43.65,14.09,8.28,37.31,45.01,73.33,11.59,52.05
22,sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118.0,250,512,17428,39.39,36.46,35.88,45.84,56.75,44.48,26.74,17.89,78.31,72.13,47.53,26.92,14.63,0.0,66.5,72.19,28.75,15.91
22,mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,39.19,36.47,34.5,46.6,45.42,43.16,8.79,48.51,52.0,55.12,47.25,8.66,6.8,29.44,53.34,80.0,4.61,48.43
22,neph1/bellman-7b-mistral-instruct-v0.2 (few-shot),7242.0,32,32768,2518,38.91,39.76,33.3,43.68,46.11,47.58,18.41,46.93,57.01,56.77,38.81,14.16,9.29,25.79,54.38,55.84,16.05,48.44
22,danish-foundation-models/encoder-medium-v1,111.0,32,512,16130,38.23,45.02,35.66,34.0,63.42,39.91,51.01,25.76,68.66,61.77,36.56,31.23,5.4,22.56,49.62,58.7,2.23,25.45
23,Addedk/mbert-swedish-distilled-cased,135.0,120,512,26091,38.07,32.06,35.05,47.12,56.36,31.16,21.08,19.63,82.98,76.65,30.38,21.99,19.06,9.47,73.41,62.1,34.86,18.1
24,jannikskytt/MeDa-Bert,111.0,32,511,16114,38.05,44.97,36.99,32.2,64.64,44.62,47.47,23.14,71.69,60.0,38.94,30.32,7.99,24.02,48.32,53.98,3.33,23.15
24,sarnikowski/electra-small-discriminator-da-256-cased,13.0,29,512,20340,37.93,43.66,33.65,36.49,60.63,24.38,68.58,21.03,73.15,66.34,29.97,40.79,25.08,1.93,52.79,57.93,14.72,20.54
24,birgermoell/roberta-swedish-scandi,125.0,50,512,15385,37.74,29.82,28.56,54.84,49.22,33.51,12.08,24.49,72.74,69.74,29.68,15.83,8.7,1.04,68.55,69.96,52.88,27.99
24,Maltehb/danish-bert-botxo,111.0,32,512,16091,37.33,45.69,32.11,34.2,66.71,43.79,45.96,26.29,72.62,58.73,40.65,29.47,12.95,0.91,50.29,57.42,4.94,24.16
24,sarnikowski/convbert-small-da-cased,13.0,29,512,14273,37.26,41.84,34.03,35.92,60.59,29.52,57.1,20.16,76.07,70.94,32.49,35.43,21.11,1.84,55.06,53.7,12.38,22.53
25,ltg/norbert3-xs,15.0,50,508,14208,36.87,31.49,40.7,38.44,59.94,39.16,2.16,24.69,87.63,80.19,49.92,7.93,5.06,22.46,67.53,59.27,2.83,24.11
25,DDSC/roberta-base-danish,125.0,50,512,15004,36.83,37.96,32.72,39.81,63.84,43.9,17.16,26.94,76.14,72.88,32.29,0.45,-0.08,23.91,65.95,64.02,0.8,28.46
25,meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,36.47,36.27,31.47,41.68,35.44,44.88,9.74,55.0,44.99,49.09,41.56,3.04,4.03,33.76,39.72,66.18,6.74,54.07
25,AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,35.39,30.45,31.58,44.14,27.41,30.24,11.34,52.8,30.82,39.56,34.51,15.17,12.46,42.81,31.86,78.88,12.26,53.58
25,Maltehb/aelaectra-danish-electra-small-cased,14.0,32,128,6035,35.23,40.94,31.55,33.19,63.31,32.72,67.74,0.0,71.85,67.14,29.0,33.57,21.79,0.03,57.82,55.68,19.26,0.0
26,danish-foundation-models/munin-7b-alpha (few-shot),7242.0,32,32768,3019,34.76,35.42,25.42,43.43,38.31,37.13,26.46,39.77,46.32,48.2,20.46,4.5,1.1,31.16,39.55,78.79,15.77,39.62
26,dbmdz/bert-base-historic-multilingual-cased,111.0,32,512,15165,34.75,26.28,30.36,47.62,47.61,24.17,8.14,25.19,68.63,67.7,25.68,6.73,3.35,22.57,68.83,64.25,28.62,28.78
26,sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking,135.0,120,512,26151,33.92,28.84,31.74,41.19,54.48,36.6,8.84,15.42,77.81,72.22,44.59,8.98,5.72,0.0,65.5,68.33,14.81,16.11
26,sentence-transformers/quora-distilbert-multilingual,135.0,120,512,26458,33.8,28.47,31.74,41.2,54.48,36.6,8.84,13.97,77.81,72.22,44.59,8.98,5.72,0.0,65.5,68.36,14.81,16.11
26,dbmdz/bert-medium-historic-multilingual-cased,42.0,32,512,24291,33.23,26.54,29.05,44.1,49.88,27.93,5.42,22.93,69.65,66.78,26.33,6.62,5.16,15.75,66.11,59.66,26.28,24.36
26,meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,33.23,30.35,25.85,43.48,31.77,43.91,0.31,45.42,42.13,43.8,41.74,0.0,0.02,18.67,44.11,79.05,7.34,43.42
26,Maltehb/aelaectra-danish-electra-small-uncased,14.0,32,128,5995,32.85,41.16,28.87,28.52,62.52,34.45,65.15,2.51,59.76,51.44,33.41,32.87,20.09,0.0,39.17,57.71,17.1,0.11
27,Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,31.97,27.79,25.65,42.46,33.41,26.08,-0.22,51.9,41.44,45.09,34.51,0.0,0.56,24.53,41.08,76.38,-0.21,52.58
28,jjzha/dajobbert-base-uncased,110.0,32,512,16243,31.59,38.38,27.03,29.35,60.78,39.65,37.67,15.41,65.95,55.29,33.31,20.34,8.07,0.0,42.99,55.49,4.69,14.22
29,AI-Sweden-Models/gpt-sw3-6.7b-v2 (few-shot),7111.0,64,2048,2351,28.15,22.16,24.59,37.69,20.84,18.07,10.54,39.18,29.62,32.3,34.67,8.37,7.76,24.67,28.73,77.47,8.78,35.78
29,sentence-transformers/distiluse-base-multilingual-cased-v1,135.0,120,512,26344,25.98,23.28,22.36,32.3,46.78,27.78,3.04,15.52,60.76,59.62,25.98,2.65,3.47,0.2,49.86,60.06,3.18,16.08
30,KBLab/albert-base-swedish-cased-alpha,14.0,50,512,15925,25.8,17.95,22.3,37.13,29.9,19.79,6.15,15.96,66.97,63.9,18.85,5.83,4.02,0.0,47.19,56.57,20.92,23.86
30,dbmdz/bert-mini-historic-multilingual-cased,12.0,32,512,47122,25.15,20.94,23.1,31.43,41.7,26.03,2.19,13.82,61.55,59.9,24.59,3.45,2.72,3.99,50.07,56.1,5.05,14.49
31,AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct (few-shot),7111.0,64,2048,2383,24.54,18.31,24.1,31.21,15.35,2.85,10.99,44.04,24.67,29.03,34.39,2.42,5.11,31.39,14.58,56.6,10.92,42.72
31,norallm/normistral-7b-scratch (few-shot),7248.0,33,2048,3192,24.06,23.0,18.49,30.7,14.88,34.66,0.29,42.16,14.58,21.06,32.02,1.49,0.98,22.87,13.79,71.59,-0.89,38.33
31,AI-Sweden-Models/gpt-sw3-1.3b (few-shot),1445.0,64,2048,4608,24.04,21.4,19.69,31.04,8.8,28.65,2.84,45.31,13.49,14.74,27.28,3.09,1.86,34.9,6.08,71.38,1.17,45.53
31,jannesg/bertsson,124.0,50,512,15314,23.36,18.76,18.1,33.23,32.63,24.11,2.91,15.37,49.3,46.11,23.21,2.26,-0.66,0.68,51.13,61.67,2.87,17.24
31,NbAiLab/nb-gpt-j-6B-alpaca (few-shot),6055.0,50,1024,2607,22.77,20.21,20.04,28.05,12.95,27.68,1.65,38.57,23.82,26.04,32.6,0.34,2.26,21.34,13.28,60.17,1.52,37.22
31,AI-Sweden-Models/gpt-sw3-356m (few-shot),471.0,64,2048,5758,21.42,20.13,20.78,23.34,16.13,27.61,1.96,34.81,27.37,31.22,34.21,0.92,1.25,18.54,23.77,34.29,1.57,33.71
32,3ebdola/Dialectal-Arabic-XLM-R-Base,278.0,250,512,15177,19.22,15.82,17.36,24.47,36.51,22.07,1.63,3.09,55.55,53.53,12.69,2.79,1.66,0.0,42.78,44.95,1.43,8.71
32,alexanderfalk/danbert-small-cased,83.0,52,512,30013,18.87,19.57,17.28,19.75,33.05,30.67,13.01,1.56,42.18,37.39,24.39,7.29,2.57,0.0,22.47,53.88,1.55,1.12
32,mhenrichsen/danskgpt-tiny-chat (few-shot),1100.0,32,2048,1745,18.72,18.96,15.36,21.84,22.31,34.05,0.7,18.78,28.74,30.34,27.49,-2.17,0.26,5.35,27.31,45.94,-0.97,15.08
32,RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,16.9,11.58,14.62,24.49,10.12,10.65,-0.66,26.21,21.04,18.71,12.22,-1.18,0.36,26.79,22.38,31.11,0.09,44.37
32,mhenrichsen/danskgpt-tiny (few-shot),1100.0,32,2048,8597,14.93,13.52,11.81,19.47,14.13,26.31,-0.54,14.16,27.37,27.59,18.09,-0.19,-0.8,2.15,23.92,31.93,0.46,21.56
32,RabotaRu/HRBert-mini,80.0,200,512,54951,14.62,11.54,12.03,20.27,22.21,20.33,0.9,2.73,31.87,32.47,15.07,1.26,0.49,0.0,24.61,52.31,1.32,2.86
32,fresh-xlm-roberta-base,278.0,250,512,1319,11.81,9.08,9.87,16.47,16.04,17.37,1.34,1.58,25.49,25.94,12.6,0.5,1.83,0.0,11.91,51.11,0.86,2.0
32,fresh-electra-small,14.0,31,512,7219,10.74,7.94,7.78,16.49,12.87,18.61,0.3,0.0,18.38,12.76,15.29,0.17,0.37,0.0,10.54,55.54,-0.15,0.02
33,AI-Sweden-Models/gpt-sw3-126m (few-shot),186.0,64,2048,8958,4.89,5.02,4.48,5.16,3.43,9.18,-0.22,7.7,13.55,9.38,7.78,-1.46,-2.97,0.9,5.66,8.15,-0.81,7.64
34,RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,4.05,3.25,0.24,8.66,0.0,13.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,34.63,0.0,0.0
34,"RJuro/kanelsnegl-v0.2 (few-shot, val)",7242.0,32,512,2982,2.75,1.15,0.06,7.03,0.0,4.6,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,28.13,0.0,0.0
34,peter-sk/gpt-neox-da (few-shot),1515.0,50,1024,6025,0.35,0.14,-0.2,1.12,0.64,-0.52,-0.02,0.48,0.29,0.25,-1.43,-0.42,1.11,0.0,0.26,4.75,-0.6,0.06
