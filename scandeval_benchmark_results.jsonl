
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.49355292320251465, "test_mcc": 0.6904183180455651, "test_macro_f1": 0.5806132747155517, "test_runtime": 15.6736, "test_samples_per_second": 130.666, "test_steps_per_second": 16.333}, {"test_loss": 0.48997074365615845, "test_mcc": 0.7044547364611713, "test_macro_f1": 0.6502224201204735, "test_runtime": 15.0135, "test_samples_per_second": 136.411, "test_steps_per_second": 17.051}, {"test_loss": 0.4662914276123047, "test_mcc": 0.697312920180609, "test_macro_f1": 0.6814617400340518, "test_runtime": 15.3152, "test_samples_per_second": 133.724, "test_steps_per_second": 16.715}, {"test_loss": 0.44507306814193726, "test_mcc": 0.7310951071444678, "test_macro_f1": 0.6461760327769115, "test_runtime": 15.0811, "test_samples_per_second": 135.799, "test_steps_per_second": 16.975}, {"test_loss": 0.43489935994148254, "test_mcc": 0.7425502499127342, "test_macro_f1": 0.7570816187505321, "test_runtime": 14.8752, "test_samples_per_second": 137.679, "test_steps_per_second": 17.21}, {"test_loss": 0.4599238634109497, "test_mcc": 0.705356588258819, "test_macro_f1": 0.651832371780268, "test_runtime": 15.2849, "test_samples_per_second": 133.989, "test_steps_per_second": 16.749}, {"test_loss": 0.43380361795425415, "test_mcc": 0.73203118118232, "test_macro_f1": 0.6871441669608317, "test_runtime": 14.7292, "test_samples_per_second": 139.043, "test_steps_per_second": 17.38}, {"test_loss": 0.4651029706001282, "test_mcc": 0.7175491487072214, "test_macro_f1": 0.7003382405375426, "test_runtime": 15.7925, "test_samples_per_second": 129.682, "test_steps_per_second": 16.21}, {"test_loss": 0.4459024965763092, "test_mcc": 0.6937392397173843, "test_macro_f1": 0.6838226733505542, "test_runtime": 15.6927, "test_samples_per_second": 130.506, "test_steps_per_second": 16.313}, {"test_loss": 0.4811949133872986, "test_mcc": 0.7068959405307896, "test_macro_f1": 0.7099707968179528, "test_runtime": 15.1586, "test_samples_per_second": 135.104, "test_steps_per_second": 16.888}]}, "total": {"test_mcc": 71.21403430141082, "test_mcc_se": 1.1071710622322732, "test_macro_f1": 67.4866333584467, "test_macro_f1_se": 2.9041833994899626}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.8711272478103638, "test_mcc": 0.4526249276034251, "test_macro_f1": 0.6295490500868849, "test_runtime": 4.7921, "test_samples_per_second": 427.368, "test_steps_per_second": 13.355}, {"test_loss": 0.8053810000419617, "test_mcc": 0.4693449829443956, "test_macro_f1": 0.6447482173981777, "test_runtime": 4.7965, "test_samples_per_second": 426.975, "test_steps_per_second": 13.343}, {"test_loss": 0.8175916075706482, "test_mcc": 0.47349392407243474, "test_macro_f1": 0.6508970857502604, "test_runtime": 4.7726, "test_samples_per_second": 429.115, "test_steps_per_second": 13.41}, {"test_loss": 0.8375738263130188, "test_mcc": 0.4754869729921364, "test_macro_f1": 0.6482648448387206, "test_runtime": 4.7935, "test_samples_per_second": 427.245, "test_steps_per_second": 13.351}, {"test_loss": 0.8542817831039429, "test_mcc": 0.467950044480052, "test_macro_f1": 0.6482044415423579, "test_runtime": 4.6987, "test_samples_per_second": 435.869, "test_steps_per_second": 13.621}, {"test_loss": 0.8563619256019592, "test_mcc": 0.4457737886538034, "test_macro_f1": 0.631989626594435, "test_runtime": 4.7852, "test_samples_per_second": 427.983, "test_steps_per_second": 13.374}, {"test_loss": 0.8531968593597412, "test_mcc": 0.4552875297966273, "test_macro_f1": 0.6370105190275591, "test_runtime": 4.7845, "test_samples_per_second": 428.047, "test_steps_per_second": 13.376}, {"test_loss": 0.8082606792449951, "test_mcc": 0.4977959103926406, "test_macro_f1": 0.6665336744580441, "test_runtime": 4.7554, "test_samples_per_second": 430.664, "test_steps_per_second": 13.458}, {"test_loss": 0.8248332738876343, "test_mcc": 0.4690177668134787, "test_macro_f1": 0.6389552807445917, "test_runtime": 4.707, "test_samples_per_second": 435.094, "test_steps_per_second": 13.597}, {"test_loss": 0.8850127458572388, "test_mcc": 0.42509878469908335, "test_macro_f1": 0.6165881104476086, "test_runtime": 4.6976, "test_samples_per_second": 435.969, "test_steps_per_second": 13.624}]}, "total": {"test_mcc": 46.31874632448078, "test_mcc_se": 1.218391340287412, "test_macro_f1": 64.12740850888639, "test_macro_f1_se": 0.8509021367191028}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.656842827796936, "test_mcc": 0.6191402328920296, "test_macro_f1": 0.7382008279528902, "test_runtime": 3.7681, "test_samples_per_second": 543.505, "test_steps_per_second": 16.985}, {"test_loss": 0.7109729647636414, "test_mcc": 0.5965532069886893, "test_macro_f1": 0.7009172650712214, "test_runtime": 3.5192, "test_samples_per_second": 581.958, "test_steps_per_second": 18.186}, {"test_loss": 0.6398826837539673, "test_mcc": 0.6070499935439078, "test_macro_f1": 0.7190659024362701, "test_runtime": 3.5677, "test_samples_per_second": 574.032, "test_steps_per_second": 17.938}, {"test_loss": 0.688225507736206, "test_mcc": 0.6370965587766236, "test_macro_f1": 0.7481715009010995, "test_runtime": 3.5981, "test_samples_per_second": 569.192, "test_steps_per_second": 17.787}, {"test_loss": 0.6733273267745972, "test_mcc": 0.6229938597965367, "test_macro_f1": 0.7291148188953627, "test_runtime": 3.6916, "test_samples_per_second": 554.775, "test_steps_per_second": 17.337}, {"test_loss": 0.7114343643188477, "test_mcc": 0.6068320555879718, "test_macro_f1": 0.7279307953576254, "test_runtime": 3.748, "test_samples_per_second": 546.427, "test_steps_per_second": 17.076}, {"test_loss": 0.6282294988632202, "test_mcc": 0.6383079462682613, "test_macro_f1": 0.743410846698367, "test_runtime": 3.6102, "test_samples_per_second": 567.285, "test_steps_per_second": 17.728}, {"test_loss": 0.6895173788070679, "test_mcc": 0.593096068569523, "test_macro_f1": 0.7170385749313078, "test_runtime": 3.6381, "test_samples_per_second": 562.938, "test_steps_per_second": 17.592}, {"test_loss": 0.7737005949020386, "test_mcc": 0.5563661311531409, "test_macro_f1": 0.6722541087306676, "test_runtime": 3.7687, "test_samples_per_second": 543.426, "test_steps_per_second": 16.982}, {"test_loss": 0.6743437051773071, "test_mcc": 0.6062763430208719, "test_macro_f1": 0.7202167362605661, "test_runtime": 3.7571, "test_samples_per_second": 545.105, "test_steps_per_second": 17.035}]}, "total": {"test_mcc": 60.83712396597555, "test_mcc_se": 1.4808018749747056, "test_macro_f1": 72.16321377235377, "test_macro_f1_se": 1.377560809247776}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.05351884663105011, "test_micro_f1": 0.742973939703628, "test_micro_f1_no_misc": 0.8041836141778036, "test_runtime": 7.6962, "test_samples_per_second": 266.105, "test_steps_per_second": 8.316}, {"test_loss": 0.051775604486465454, "test_micro_f1": 0.7374476987447699, "test_micro_f1_no_misc": 0.8108108108108107, "test_runtime": 7.1661, "test_samples_per_second": 285.789, "test_steps_per_second": 8.931}, {"test_loss": 0.04932161420583725, "test_micro_f1": 0.7441415590626496, "test_micro_f1_no_misc": 0.7896718665949435, "test_runtime": 7.1204, "test_samples_per_second": 287.625, "test_steps_per_second": 8.988}, {"test_loss": 0.048471033573150635, "test_micro_f1": 0.736842105263158, "test_micro_f1_no_misc": 0.7710583153347732, "test_runtime": 7.5575, "test_samples_per_second": 270.99, "test_steps_per_second": 8.468}, {"test_loss": 0.05121653527021408, "test_micro_f1": 0.7614942528735631, "test_micro_f1_no_misc": 0.8135048231511254, "test_runtime": 7.6352, "test_samples_per_second": 268.231, "test_steps_per_second": 8.382}, {"test_loss": 0.04682701826095581, "test_micro_f1": 0.7690883850069413, "test_micro_f1_no_misc": 0.8218142548596112, "test_runtime": 6.0438, "test_samples_per_second": 338.86, "test_steps_per_second": 10.589}, {"test_loss": 0.05135384202003479, "test_micro_f1": 0.7636544190665343, "test_micro_f1_no_misc": 0.8188446438586652, "test_runtime": 6.726, "test_samples_per_second": 304.489, "test_steps_per_second": 9.515}, {"test_loss": 0.05038463696837425, "test_micro_f1": 0.7508055853920514, "test_micro_f1_no_misc": 0.794887401095557, "test_runtime": 7.7529, "test_samples_per_second": 264.158, "test_steps_per_second": 8.255}, {"test_loss": 0.043807502835989, "test_micro_f1": 0.778846153846154, "test_micro_f1_no_misc": 0.8174946004319654, "test_runtime": 7.4502, "test_samples_per_second": 274.893, "test_steps_per_second": 8.59}, {"test_loss": 0.05090424790978432, "test_micro_f1": 0.74950884086444, "test_micro_f1_no_misc": 0.7955032119914347, "test_runtime": 7.5422, "test_samples_per_second": 271.539, "test_steps_per_second": 8.486}]}, "total": {"test_micro_f1": 75.34802939823891, "test_micro_f1_se": 0.8787688167166763, "test_micro_f1_no_misc": 80.3777354230669, "test_micro_f1_no_misc_se": 0.9912096009088749}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.05587580054998398, "test_micro_f1": 0.812111801242236, "test_micro_f1_no_misc": 0.8273504273504273, "test_runtime": 9.0534, "test_samples_per_second": 226.213, "test_steps_per_second": 7.069}, {"test_loss": 0.04901338368654251, "test_micro_f1": 0.820754716981132, "test_micro_f1_no_misc": 0.842143906020558, "test_runtime": 6.8383, "test_samples_per_second": 299.488, "test_steps_per_second": 9.359}, {"test_loss": 0.048904016613960266, "test_micro_f1": 0.8340425531914895, "test_micro_f1_no_misc": 0.8682284040995608, "test_runtime": 9.03, "test_samples_per_second": 226.8, "test_steps_per_second": 7.088}, {"test_loss": 0.05790286511182785, "test_micro_f1": 0.842687747035573, "test_micro_f1_no_misc": 0.8568368439842913, "test_runtime": 8.7617, "test_samples_per_second": 233.745, "test_steps_per_second": 7.305}, {"test_loss": 0.05761466175317764, "test_micro_f1": 0.8128704487722268, "test_micro_f1_no_misc": 0.8411073189230185, "test_runtime": 9.089, "test_samples_per_second": 225.326, "test_steps_per_second": 7.041}, {"test_loss": 0.0536787249147892, "test_micro_f1": 0.8273776800439802, "test_micro_f1_no_misc": 0.8604651162790699, "test_runtime": 8.7669, "test_samples_per_second": 233.605, "test_steps_per_second": 7.3}, {"test_loss": 0.05012232065200806, "test_micro_f1": 0.8505747126436781, "test_micro_f1_no_misc": 0.8734982332155475, "test_runtime": 9.2252, "test_samples_per_second": 222.001, "test_steps_per_second": 6.938}, {"test_loss": 0.04892244189977646, "test_micro_f1": 0.8362637362637364, "test_micro_f1_no_misc": 0.8554829339143064, "test_runtime": 8.9644, "test_samples_per_second": 228.46, "test_steps_per_second": 7.139}, {"test_loss": 0.05552119389176369, "test_micro_f1": 0.822866344605475, "test_micro_f1_no_misc": 0.8301340094168779, "test_runtime": 8.6104, "test_samples_per_second": 237.851, "test_steps_per_second": 7.433}, {"test_loss": 0.0527871809899807, "test_micro_f1": 0.8486299547752061, "test_micro_f1_no_misc": 0.8790731354091238, "test_runtime": 7.1212, "test_samples_per_second": 287.59, "test_steps_per_second": 8.987}]}, "total": {"test_micro_f1": 83.08179695554733, "test_micro_f1_se": 0.8610400106324436, "test_micro_f1_no_misc": 85.34320328612782, "test_micro_f1_no_misc_se": 1.1023115351267532}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.030843209475278854, "test_micro_f1": 0.8824833702882483, "test_micro_f1_no_misc": 0.9280723386765309, "test_runtime": 6.7562, "test_samples_per_second": 303.128, "test_steps_per_second": 9.473}, {"test_loss": 0.026531919836997986, "test_micro_f1": 0.8974263334576651, "test_micro_f1_no_misc": 0.930921052631579, "test_runtime": 6.7059, "test_samples_per_second": 305.404, "test_steps_per_second": 9.544}, {"test_loss": 0.03118470311164856, "test_micro_f1": 0.8940092165898617, "test_micro_f1_no_misc": 0.9387264717661192, "test_runtime": 6.448, "test_samples_per_second": 317.619, "test_steps_per_second": 9.926}, {"test_loss": 0.028877686709165573, "test_micro_f1": 0.8983768525052929, "test_micro_f1_no_misc": 0.9354712553773954, "test_runtime": 6.2923, "test_samples_per_second": 325.478, "test_steps_per_second": 10.171}, {"test_loss": 0.03422584384679794, "test_micro_f1": 0.8621035058430718, "test_micro_f1_no_misc": 0.9055374592833876, "test_runtime": 6.7607, "test_samples_per_second": 302.926, "test_steps_per_second": 9.466}, {"test_loss": 0.024625038728117943, "test_micro_f1": 0.9156045470203238, "test_micro_f1_no_misc": 0.9447619047619047, "test_runtime": 6.7192, "test_samples_per_second": 304.799, "test_steps_per_second": 9.525}, {"test_loss": 0.027442220598459244, "test_micro_f1": 0.9030913511635985, "test_micro_f1_no_misc": 0.9355958349402236, "test_runtime": 6.1228, "test_samples_per_second": 334.488, "test_steps_per_second": 10.453}, {"test_loss": 0.027296070009469986, "test_micro_f1": 0.8971568971568971, "test_micro_f1_no_misc": 0.9301623254058135, "test_runtime": 6.3852, "test_samples_per_second": 320.744, "test_steps_per_second": 10.023}, {"test_loss": 0.027264757081866264, "test_micro_f1": 0.8909679740913997, "test_micro_f1_no_misc": 0.9192897497982244, "test_runtime": 6.2245, "test_samples_per_second": 329.024, "test_steps_per_second": 10.282}, {"test_loss": 0.032980531454086304, "test_micro_f1": 0.8946280991735537, "test_micro_f1_no_misc": 0.9321646341463414, "test_runtime": 6.6834, "test_samples_per_second": 306.432, "test_steps_per_second": 9.576}]}, "total": {"test_micro_f1": 89.35848147289911, "test_micro_f1_se": 0.863822994263355, "test_micro_f1_no_misc": 93.00703026787518, "test_micro_f1_no_misc_se": 0.6782296366756485}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.03319142013788223, "test_micro_f1": 0.8529866914268027, "test_micro_f1_no_misc": 0.8900238338440586, "test_runtime": 6.2852, "test_samples_per_second": 325.846, "test_steps_per_second": 10.183}, {"test_loss": 0.037572916597127914, "test_micro_f1": 0.8331814038286236, "test_micro_f1_no_misc": 0.870414002019522, "test_runtime": 6.3593, "test_samples_per_second": 322.047, "test_steps_per_second": 10.064}, {"test_loss": 0.03980793058872223, "test_micro_f1": 0.83363802559415, "test_micro_f1_no_misc": 0.8752957080094628, "test_runtime": 6.1499, "test_samples_per_second": 333.015, "test_steps_per_second": 10.407}, {"test_loss": 0.04271823167800903, "test_micro_f1": 0.8598300970873787, "test_micro_f1_no_misc": 0.9023890784982935, "test_runtime": 6.2461, "test_samples_per_second": 327.885, "test_steps_per_second": 10.246}, {"test_loss": 0.04246502369642258, "test_micro_f1": 0.8395967002749771, "test_micro_f1_no_misc": 0.890547263681592, "test_runtime": 6.0633, "test_samples_per_second": 337.768, "test_steps_per_second": 10.555}, {"test_loss": 0.03633712977170944, "test_micro_f1": 0.8487775430123754, "test_micro_f1_no_misc": 0.8919463087248323, "test_runtime": 6.1788, "test_samples_per_second": 331.457, "test_steps_per_second": 10.358}, {"test_loss": 0.03801288455724716, "test_micro_f1": 0.8344741754822651, "test_micro_f1_no_misc": 0.8790240596407997, "test_runtime": 6.4346, "test_samples_per_second": 318.279, "test_steps_per_second": 9.946}, {"test_loss": 0.03496343642473221, "test_micro_f1": 0.8528044623489308, "test_micro_f1_no_misc": 0.8898071625344353, "test_runtime": 6.3381, "test_samples_per_second": 323.123, "test_steps_per_second": 10.098}, {"test_loss": 0.04370153695344925, "test_micro_f1": 0.8220783225408572, "test_micro_f1_no_misc": 0.8607594936708862, "test_runtime": 5.8607, "test_samples_per_second": 349.449, "test_steps_per_second": 10.92}, {"test_loss": 0.03478617966175079, "test_micro_f1": 0.8607516943930993, "test_micro_f1_no_misc": 0.8932885906040269, "test_runtime": 5.9233, "test_samples_per_second": 345.752, "test_steps_per_second": 10.805}]}, "total": {"test_micro_f1": 84.3811911598946, "test_micro_f1_se": 0.8073530614163213, "test_micro_f1_no_misc": 88.43495501227909, "test_micro_f1_no_misc_se": 0.7797580882730817}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.4449448585510254, "test_mcc": 0.6723305638973076, "test_macro_f1": 0.8359068276769873, "test_runtime": 3.6139, "test_samples_per_second": 566.694, "test_steps_per_second": 17.709}, {"test_loss": 0.5096756219863892, "test_mcc": 0.5747271466088397, "test_macro_f1": 0.7689312701640945, "test_runtime": 3.7594, "test_samples_per_second": 544.763, "test_steps_per_second": 17.024}, {"test_loss": 0.4127614498138428, "test_mcc": 0.6532086823854909, "test_macro_f1": 0.8251310759017014, "test_runtime": 3.8183, "test_samples_per_second": 536.362, "test_steps_per_second": 16.761}, {"test_loss": 0.4502687156200409, "test_mcc": 0.6396833077939018, "test_macro_f1": 0.8130720885960413, "test_runtime": 3.6752, "test_samples_per_second": 557.244, "test_steps_per_second": 17.414}, {"test_loss": 0.47466278076171875, "test_mcc": 0.6068651057490825, "test_macro_f1": 0.794706057828293, "test_runtime": 3.7493, "test_samples_per_second": 546.235, "test_steps_per_second": 17.07}, {"test_loss": 0.49001121520996094, "test_mcc": 0.6688244999738587, "test_macro_f1": 0.8339145243694753, "test_runtime": 3.7008, "test_samples_per_second": 553.395, "test_steps_per_second": 17.294}, {"test_loss": 0.412783682346344, "test_mcc": 0.6747601427406719, "test_macro_f1": 0.8332049409970144, "test_runtime": 3.7596, "test_samples_per_second": 544.74, "test_steps_per_second": 17.023}, {"test_loss": 0.44407665729522705, "test_mcc": 0.6449916498893838, "test_macro_f1": 0.8169787881946067, "test_runtime": 3.7354, "test_samples_per_second": 548.264, "test_steps_per_second": 17.133}, {"test_loss": 0.4431625008583069, "test_mcc": 0.6404842042977803, "test_macro_f1": 0.8126395954402544, "test_runtime": 3.7241, "test_samples_per_second": 549.935, "test_steps_per_second": 17.185}, {"test_loss": 0.46999818086624146, "test_mcc": 0.6271888070178055, "test_macro_f1": 0.8043046638953494, "test_runtime": 3.7689, "test_samples_per_second": 543.387, "test_steps_per_second": 16.981}]}, "total": {"test_mcc": 64.03064110354123, "test_mcc_se": 1.9387340201993266, "test_macro_f1": 81.38789833063818, "test_macro_f1_se": 1.2866043741438788}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.5142257213592529, "test_mcc": 0.6663156454735005, "test_macro_f1": 0.8329000858860579, "test_runtime": 3.9982, "test_samples_per_second": 512.225, "test_steps_per_second": 16.007}, {"test_loss": 0.46564799547195435, "test_mcc": 0.6268752562708879, "test_macro_f1": 0.7944881546225331, "test_runtime": 4.2243, "test_samples_per_second": 484.813, "test_steps_per_second": 15.15}, {"test_loss": 0.44966912269592285, "test_mcc": 0.6856984506702954, "test_macro_f1": 0.8344608625471052, "test_runtime": 4.0866, "test_samples_per_second": 501.148, "test_steps_per_second": 15.661}, {"test_loss": 0.4477759599685669, "test_mcc": 0.6512175428298378, "test_macro_f1": 0.8153989659593031, "test_runtime": 4.2303, "test_samples_per_second": 484.125, "test_steps_per_second": 15.129}, {"test_loss": 0.42544907331466675, "test_mcc": 0.6825031495865794, "test_macro_f1": 0.8396228937707948, "test_runtime": 4.0416, "test_samples_per_second": 506.734, "test_steps_per_second": 15.835}, {"test_loss": 0.4031984210014343, "test_mcc": 0.689495854932878, "test_macro_f1": 0.8402205800981961, "test_runtime": 3.9645, "test_samples_per_second": 516.583, "test_steps_per_second": 16.143}, {"test_loss": 0.44587624073028564, "test_mcc": 0.6573395927576157, "test_macro_f1": 0.8229839235840507, "test_runtime": 3.9308, "test_samples_per_second": 521.019, "test_steps_per_second": 16.282}, {"test_loss": 0.39848339557647705, "test_mcc": 0.6885289541582483, "test_macro_f1": 0.8441175312659938, "test_runtime": 3.9751, "test_samples_per_second": 515.208, "test_steps_per_second": 16.1}, {"test_loss": 0.4937817454338074, "test_mcc": 0.6012152933642883, "test_macro_f1": 0.7761875076936284, "test_runtime": 4.0124, "test_samples_per_second": 510.418, "test_steps_per_second": 15.951}, {"test_loss": 0.43244296312332153, "test_mcc": 0.6916951562514768, "test_macro_f1": 0.8439435665585304, "test_runtime": 4.1096, "test_samples_per_second": 498.351, "test_steps_per_second": 15.573}]}, "total": {"test_mcc": 66.40884896295609, "test_mcc_se": 1.8896046055854931, "test_macro_f1": 82.44324071986193, "test_macro_f1_se": 1.4206669847557214}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.43349018692970276, "test_mcc": 0.7077139941828522, "test_macro_f1": 0.8378958692490446, "test_runtime": 3.6187, "test_samples_per_second": 565.95, "test_steps_per_second": 17.686}, {"test_loss": 0.396136999130249, "test_mcc": 0.7260710814449528, "test_macro_f1": 0.8504329424298043, "test_runtime": 3.6461, "test_samples_per_second": 561.698, "test_steps_per_second": 17.553}, {"test_loss": 0.345314085483551, "test_mcc": 0.7581379460848849, "test_macro_f1": 0.8738211568495408, "test_runtime": 3.583, "test_samples_per_second": 571.581, "test_steps_per_second": 17.862}, {"test_loss": 0.3451259136199951, "test_mcc": 0.74125421060464, "test_macro_f1": 0.8675090474145863, "test_runtime": 3.7085, "test_samples_per_second": 552.245, "test_steps_per_second": 17.258}, {"test_loss": 0.4107678532600403, "test_mcc": 0.7066314292475011, "test_macro_f1": 0.8396813713788264, "test_runtime": 3.6431, "test_samples_per_second": 562.157, "test_steps_per_second": 17.567}, {"test_loss": 0.37864428758621216, "test_mcc": 0.7403698469142965, "test_macro_f1": 0.8628703995406406, "test_runtime": 3.5001, "test_samples_per_second": 585.126, "test_steps_per_second": 18.285}, {"test_loss": 0.3769785761833191, "test_mcc": 0.7413611273380021, "test_macro_f1": 0.8651856727948756, "test_runtime": 3.5571, "test_samples_per_second": 575.756, "test_steps_per_second": 17.992}, {"test_loss": 0.3566293716430664, "test_mcc": 0.7393502098086189, "test_macro_f1": 0.8635086816837849, "test_runtime": 3.5519, "test_samples_per_second": 576.587, "test_steps_per_second": 18.018}, {"test_loss": 0.34473997354507446, "test_mcc": 0.7734655771421924, "test_macro_f1": 0.8848109521501613, "test_runtime": 3.4907, "test_samples_per_second": 586.706, "test_steps_per_second": 18.335}, {"test_loss": 0.3953227400779724, "test_mcc": 0.7544287946575955, "test_macro_f1": 0.8732738364724278, "test_runtime": 3.6372, "test_samples_per_second": 563.073, "test_steps_per_second": 17.596}]}, "total": {"test_mcc": 73.88784217425537, "test_mcc_se": 1.3064033243775246, "test_macro_f1": 86.18989929963693, "test_macro_f1_se": 0.9339549348873429}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_loss": 0.32882577180862427, "test_mcc": 0.7684508136230366, "test_macro_f1": 0.8830573456236235, "test_runtime": 3.685, "test_samples_per_second": 555.766, "test_steps_per_second": 17.368}, {"test_loss": 0.39529210329055786, "test_mcc": 0.6910992966642914, "test_macro_f1": 0.832339638579908, "test_runtime": 3.7821, "test_samples_per_second": 541.496, "test_steps_per_second": 16.922}, {"test_loss": 0.41885441541671753, "test_mcc": 0.7041319008584593, "test_macro_f1": 0.8383731964752591, "test_runtime": 3.7863, "test_samples_per_second": 540.898, "test_steps_per_second": 16.903}, {"test_loss": 0.41104593873023987, "test_mcc": 0.6747831709032999, "test_macro_f1": 0.8239332872221115, "test_runtime": 3.6193, "test_samples_per_second": 565.854, "test_steps_per_second": 17.683}, {"test_loss": 0.35545504093170166, "test_mcc": 0.7477649646420012, "test_macro_f1": 0.8723983869591765, "test_runtime": 3.6532, "test_samples_per_second": 560.598, "test_steps_per_second": 17.519}, {"test_loss": 0.3622192144393921, "test_mcc": 0.7361083696058098, "test_macro_f1": 0.8620342045370835, "test_runtime": 3.7791, "test_samples_per_second": 541.93, "test_steps_per_second": 16.935}, {"test_loss": 0.42525607347488403, "test_mcc": 0.673787982510165, "test_macro_f1": 0.8258576812226075, "test_runtime": 3.6989, "test_samples_per_second": 553.671, "test_steps_per_second": 17.302}, {"test_loss": 0.3857000470161438, "test_mcc": 0.7220804466060023, "test_macro_f1": 0.8606391461694167, "test_runtime": 3.6555, "test_samples_per_second": 560.253, "test_steps_per_second": 17.508}, {"test_loss": 0.35067451000213623, "test_mcc": 0.7484266012854299, "test_macro_f1": 0.8703781185771973, "test_runtime": 3.6549, "test_samples_per_second": 560.346, "test_steps_per_second": 17.511}, {"test_loss": 0.3552003800868988, "test_mcc": 0.7434042607427518, "test_macro_f1": 0.8682540901758968, "test_runtime": 3.7957, "test_samples_per_second": 539.565, "test_steps_per_second": 16.861}]}, "total": {"test_mcc": 72.10037807441248, "test_mcc_se": 2.0655148752926014, "test_macro_f1": 85.37265095542281, "test_macro_f1_se": 1.3343837342735012}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_em": 46.16576297443842, "test_f1": 50.00060344942736}, {"test_em": 46.27906976744186, "test_f1": 50.06680189978827}, {"test_em": 46.59969088098918, "test_f1": 50.73219800790129}, {"test_em": 45.01557632398754, "test_f1": 48.98607577251258}, {"test_em": 44.633204633204635, "test_f1": 48.64275638445396}, {"test_em": 48.342328450269854, "test_f1": 52.74281704640265}, {"test_em": 46.241457858769934, "test_f1": 50.47033196521549}, {"test_em": 43.366951124903025, "test_f1": 47.705579338850384}, {"test_em": 38.666666666666664, "test_f1": 42.77820577428659}, {"test_em": 48.75776397515528, "test_f1": 52.10783630817794}]}, "total": {"test_em": 45.40684726558264, "test_em_se": 1.7729869984633677, "test_f1": 49.42332059470165, "test_f1_se": 1.7247387168049806}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_em": 42.3702556158017, "test_f1": 46.33797506629301}, {"test_em": 38.992248062015506, "test_f1": 43.44562921685106}, {"test_em": 44.35857805255023, "test_f1": 49.19942967669076}, {"test_em": 40.18691588785047, "test_f1": 44.5411942267466}, {"test_em": 46.795366795366796, "test_f1": 50.706720225517195}, {"test_em": 45.41249036237471, "test_f1": 49.91536369644577}, {"test_em": 43.96355353075171, "test_f1": 48.98190279328913}, {"test_em": 41.34988363072149, "test_f1": 45.93150964941073}, {"test_em": 38.27450980392157, "test_f1": 43.0245353607011}, {"test_em": 45.65217391304348, "test_f1": 51.00862528699265}]}, "total": {"test_em": 42.73559756543976, "test_em_se": 1.8335199793655161, "test_f1": 47.3092885198938, "test_f1_se": 1.8729207974293902}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_em": 38.264910921766074, "test_f1": 43.12641284265015}, {"test_em": 42.093023255813954, "test_f1": 46.24274223185938}, {"test_em": 41.65378670788253, "test_f1": 45.24986411588513}, {"test_em": 44.781931464174455, "test_f1": 48.173879694097415}, {"test_em": 37.83783783783784, "test_f1": 42.71404868880976}, {"test_em": 46.106399383191984, "test_f1": 49.98895449715122}, {"test_em": 44.874715261959, "test_f1": 49.2606928609806}, {"test_em": 40.8844065166796, "test_f1": 45.479477122218455}, {"test_em": 41.64705882352941, "test_f1": 45.603472312304966}, {"test_em": 47.98136645962733, "test_f1": 51.50886073853138}]}, "total": {"test_em": 42.61254366324622, "test_em_se": 2.0417310716043664, "test_f1": 46.73484051044885, "test_f1_se": 1.8049278400668776}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.44755125045776367, "test_mcc": 0.72116423344263, "test_macro_f1": 0.6008809827709503, "test_runtime": 14.1168, "test_samples_per_second": 145.076, "test_steps_per_second": 18.134}, {"test_loss": 0.4415445327758789, "test_mcc": 0.6993437295717284, "test_macro_f1": 0.6783449648655777, "test_runtime": 13.3325, "test_samples_per_second": 153.609, "test_steps_per_second": 19.201}, {"test_loss": 0.459534615278244, "test_mcc": 0.7039706858021713, "test_macro_f1": 0.5855283605124962, "test_runtime": 16.8687, "test_samples_per_second": 121.408, "test_steps_per_second": 60.704}, {"test_loss": 0.35699647665023804, "test_mcc": 0.7799124210227197, "test_macro_f1": 0.7666908167678527, "test_runtime": 16.6528, "test_samples_per_second": 122.982, "test_steps_per_second": 61.491}, {"test_loss": 0.3939070701599121, "test_mcc": 0.7321307107034702, "test_macro_f1": 0.6618645396501569, "test_runtime": 16.7932, "test_samples_per_second": 121.954, "test_steps_per_second": 60.977}, {"test_loss": 0.3687898516654968, "test_mcc": 0.7503738541766438, "test_macro_f1": 0.7177732254880714, "test_runtime": 16.9394, "test_samples_per_second": 120.901, "test_steps_per_second": 60.451}, {"test_loss": 0.4251662492752075, "test_mcc": 0.7260572906431252, "test_macro_f1": 0.6030701616569153, "test_runtime": 16.8489, "test_samples_per_second": 121.551, "test_steps_per_second": 60.776}, {"test_loss": 0.3938140273094177, "test_mcc": 0.7442409752652289, "test_macro_f1": 0.7446072591120317, "test_runtime": 16.8797, "test_samples_per_second": 121.329, "test_steps_per_second": 60.665}, {"test_loss": 0.3994675278663635, "test_mcc": 0.7580789610660091, "test_macro_f1": 0.7349272441787984, "test_runtime": 17.0451, "test_samples_per_second": 120.152, "test_steps_per_second": 60.076}, {"test_loss": 0.3753126263618469, "test_mcc": 0.7472560824743587, "test_macro_f1": 0.7480111651287352, "test_runtime": 16.8623, "test_samples_per_second": 121.455, "test_steps_per_second": 60.727}]}, "total": {"test_mcc": 73.62528944168086, "test_mcc_se": 1.5349649764969868, "test_macro_f1": 68.41698720131588, "test_macro_f1_se": 4.23506159416458}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.8078209161758423, "test_mcc": 0.48646104474529533, "test_macro_f1": 0.6473632659217787, "test_runtime": 4.1756, "test_samples_per_second": 490.467, "test_steps_per_second": 15.327}, {"test_loss": 0.7873448729515076, "test_mcc": 0.5067160160676889, "test_macro_f1": 0.6703161394391636, "test_runtime": 4.154, "test_samples_per_second": 493.014, "test_steps_per_second": 15.407}, {"test_loss": 0.8211378455162048, "test_mcc": 0.49750328487826034, "test_macro_f1": 0.6607668531510401, "test_runtime": 4.2124, "test_samples_per_second": 486.187, "test_steps_per_second": 15.193}, {"test_loss": 0.8094490766525269, "test_mcc": 0.5130290348885311, "test_macro_f1": 0.6709465620797955, "test_runtime": 4.0616, "test_samples_per_second": 504.229, "test_steps_per_second": 15.757}, {"test_loss": 0.7831029891967773, "test_mcc": 0.5122741960574482, "test_macro_f1": 0.67840630359807, "test_runtime": 4.0726, "test_samples_per_second": 502.869, "test_steps_per_second": 15.715}, {"test_loss": 0.8236861228942871, "test_mcc": 0.4921235878638196, "test_macro_f1": 0.6627086528397911, "test_runtime": 4.1173, "test_samples_per_second": 497.419, "test_steps_per_second": 15.544}, {"test_loss": 0.8112776279449463, "test_mcc": 0.506071533630589, "test_macro_f1": 0.6717490905123583, "test_runtime": 4.1395, "test_samples_per_second": 494.751, "test_steps_per_second": 15.461}, {"test_loss": 0.8236333131790161, "test_mcc": 0.47229682972398485, "test_macro_f1": 0.648819780447515, "test_runtime": 4.2044, "test_samples_per_second": 487.112, "test_steps_per_second": 15.222}, {"test_loss": 0.8306598663330078, "test_mcc": 0.5098153685610676, "test_macro_f1": 0.6646956630479225, "test_runtime": 4.1685, "test_samples_per_second": 491.306, "test_steps_per_second": 15.353}, {"test_loss": 0.8016659617424011, "test_mcc": 0.4699212333091441, "test_macro_f1": 0.644811617124744, "test_runtime": 4.0538, "test_samples_per_second": 505.199, "test_steps_per_second": 15.787}]}, "total": {"test_mcc": 49.66212129725829, "test_mcc_se": 0.9926221471859278, "test_macro_f1": 66.20583928162179, "test_macro_f1_se": 0.7174952747402011}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.6678948402404785, "test_mcc": 0.5823603019202156, "test_macro_f1": 0.7138205592640231, "test_runtime": 3.5095, "test_samples_per_second": 583.561, "test_steps_per_second": 18.236}, {"test_loss": 0.6632141470909119, "test_mcc": 0.5698072262164052, "test_macro_f1": 0.6977842095723604, "test_runtime": 3.2725, "test_samples_per_second": 625.828, "test_steps_per_second": 19.557}, {"test_loss": 0.7066759467124939, "test_mcc": 0.5444793972680627, "test_macro_f1": 0.6831524277301892, "test_runtime": 3.3996, "test_samples_per_second": 602.43, "test_steps_per_second": 18.826}, {"test_loss": 0.7001028656959534, "test_mcc": 0.5564306593153283, "test_macro_f1": 0.6922800331014946, "test_runtime": 3.4001, "test_samples_per_second": 602.337, "test_steps_per_second": 18.823}, {"test_loss": 0.6803404092788696, "test_mcc": 0.5945162342562995, "test_macro_f1": 0.7214295074295074, "test_runtime": 3.468, "test_samples_per_second": 590.547, "test_steps_per_second": 18.455}, {"test_loss": 0.6888090372085571, "test_mcc": 0.5437119547589949, "test_macro_f1": 0.6761879953864108, "test_runtime": 3.4878, "test_samples_per_second": 587.19, "test_steps_per_second": 18.35}, {"test_loss": 0.6545683741569519, "test_mcc": 0.579894628173636, "test_macro_f1": 0.7021769455528037, "test_runtime": 3.3578, "test_samples_per_second": 609.915, "test_steps_per_second": 19.06}, {"test_loss": 0.7173488736152649, "test_mcc": 0.5677140392338267, "test_macro_f1": 0.7020743925928169, "test_runtime": 3.5146, "test_samples_per_second": 582.706, "test_steps_per_second": 18.21}, {"test_loss": 0.6550979614257812, "test_mcc": 0.6050488412859558, "test_macro_f1": 0.7306865066128374, "test_runtime": 3.5091, "test_samples_per_second": 583.62, "test_steps_per_second": 18.238}, {"test_loss": 0.6939433217048645, "test_mcc": 0.5930936330308251, "test_macro_f1": 0.7257826706675745, "test_runtime": 3.5653, "test_samples_per_second": 574.43, "test_steps_per_second": 17.951}]}, "total": {"test_mcc": 57.370569154595486, "test_mcc_se": 1.3079554509757436, "test_macro_f1": 70.45375247910019, "test_macro_f1_se": 1.1269100821061917}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.0730617493391037, "test_micro_f1": 0.588293162813576, "test_micro_f1_no_misc": 0.6744868035190615, "test_runtime": 7.0537, "test_samples_per_second": 290.345, "test_steps_per_second": 9.073}, {"test_loss": 0.06766016781330109, "test_micro_f1": 0.6532556908417153, "test_micro_f1_no_misc": 0.7149817295980512, "test_runtime": 6.798, "test_samples_per_second": 301.266, "test_steps_per_second": 9.415}, {"test_loss": 0.05024893209338188, "test_micro_f1": 0.7720515361744301, "test_micro_f1_no_misc": 0.8175750834260289, "test_runtime": 6.359, "test_samples_per_second": 322.064, "test_steps_per_second": 10.065}, {"test_loss": 0.06377432495355606, "test_micro_f1": 0.6679192108971349, "test_micro_f1_no_misc": 0.7245444801714898, "test_runtime": 7.0742, "test_samples_per_second": 289.503, "test_steps_per_second": 9.047}, {"test_loss": 0.07000311464071274, "test_micro_f1": 0.696969696969697, "test_micro_f1_no_misc": 0.7624664879356567, "test_runtime": 6.9676, "test_samples_per_second": 293.932, "test_steps_per_second": 9.185}, {"test_loss": 0.06642617285251617, "test_micro_f1": 0.6364909006066263, "test_micro_f1_no_misc": 0.689058524173028, "test_runtime": 5.7981, "test_samples_per_second": 353.216, "test_steps_per_second": 11.038}, {"test_loss": 0.06732459366321564, "test_micro_f1": 0.6780321480759863, "test_micro_f1_no_misc": 0.7382256297918948, "test_runtime": 5.7992, "test_samples_per_second": 353.149, "test_steps_per_second": 11.036}, {"test_loss": 0.06339949369430542, "test_micro_f1": 0.6347871781397793, "test_micro_f1_no_misc": 0.6859163229228049, "test_runtime": 6.9148, "test_samples_per_second": 296.175, "test_steps_per_second": 9.255}, {"test_loss": 0.05657413974404335, "test_micro_f1": 0.7133458646616543, "test_micro_f1_no_misc": 0.7719298245614036, "test_runtime": 6.5129, "test_samples_per_second": 314.453, "test_steps_per_second": 9.827}, {"test_loss": 0.06059562414884567, "test_micro_f1": 0.6894230769230769, "test_micro_f1_no_misc": 0.76457399103139, "test_runtime": 7.0815, "test_samples_per_second": 289.203, "test_steps_per_second": 9.038}]}, "total": {"test_micro_f1": 67.30568466103676, "test_micro_f1_se": 3.1122666145088385, "test_micro_f1_no_misc": 73.4375887713081, "test_micro_f1_no_misc_se": 2.810830839581628}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.05982609838247299, "test_micro_f1": 0.804544280919184, "test_micro_f1_no_misc": 0.835530881332408, "test_runtime": 7.8833, "test_samples_per_second": 259.791, "test_steps_per_second": 8.118}, {"test_loss": 0.06295717507600784, "test_micro_f1": 0.7988980716253443, "test_micro_f1_no_misc": 0.8175553137468263, "test_runtime": 6.4471, "test_samples_per_second": 317.66, "test_steps_per_second": 9.927}, {"test_loss": 0.051967471837997437, "test_micro_f1": 0.8380394246137453, "test_micro_f1_no_misc": 0.856218547807333, "test_runtime": 7.8136, "test_samples_per_second": 262.107, "test_steps_per_second": 8.191}, {"test_loss": 0.06779168546199799, "test_micro_f1": 0.8038451545856067, "test_micro_f1_no_misc": 0.8297797972736806, "test_runtime": 7.5822, "test_samples_per_second": 270.107, "test_steps_per_second": 8.441}, {"test_loss": 0.06653749197721481, "test_micro_f1": 0.7917139614074915, "test_micro_f1_no_misc": 0.8178694158075602, "test_runtime": 7.8302, "test_samples_per_second": 261.552, "test_steps_per_second": 8.173}, {"test_loss": 0.0663997083902359, "test_micro_f1": 0.8108561835478456, "test_micro_f1_no_misc": 0.8216463414634146, "test_runtime": 7.8463, "test_samples_per_second": 261.014, "test_steps_per_second": 8.157}, {"test_loss": 0.05767769366502762, "test_micro_f1": 0.8054908054908054, "test_micro_f1_no_misc": 0.8304668304668306, "test_runtime": 7.8651, "test_samples_per_second": 260.391, "test_steps_per_second": 8.137}, {"test_loss": 0.056707240641117096, "test_micro_f1": 0.8069402368493529, "test_micro_f1_no_misc": 0.8386863948033202, "test_runtime": 7.8147, "test_samples_per_second": 262.069, "test_steps_per_second": 8.19}, {"test_loss": 0.0658375471830368, "test_micro_f1": 0.8040966386554622, "test_micro_f1_no_misc": 0.8343023255813954, "test_runtime": 7.6125, "test_samples_per_second": 269.032, "test_steps_per_second": 8.407}, {"test_loss": 0.06645851582288742, "test_micro_f1": 0.8054516301443079, "test_micro_f1_no_misc": 0.8353442157558553, "test_runtime": 6.8393, "test_samples_per_second": 299.448, "test_steps_per_second": 9.358}]}, "total": {"test_micro_f1": 80.69876387839146, "test_micro_f1_se": 0.7468347394652903, "test_micro_f1_no_misc": 83.17400064038625, "test_micro_f1_no_misc_se": 0.7103996187939816}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.03722444176673889, "test_micro_f1": 0.8608247422680413, "test_micro_f1_no_misc": 0.8903599503516756, "test_runtime": 6.2676, "test_samples_per_second": 326.758, "test_steps_per_second": 10.211}, {"test_loss": 0.03337235748767853, "test_micro_f1": 0.8565121412803531, "test_micro_f1_no_misc": 0.8842192006592501, "test_runtime": 6.121, "test_samples_per_second": 334.586, "test_steps_per_second": 10.456}, {"test_loss": 0.03398088365793228, "test_micro_f1": 0.8734491315136477, "test_micro_f1_no_misc": 0.9030448717948718, "test_runtime": 5.7505, "test_samples_per_second": 356.145, "test_steps_per_second": 11.13}, {"test_loss": 0.033254094421863556, "test_micro_f1": 0.8592540464461645, "test_micro_f1_no_misc": 0.8959491660047656, "test_runtime": 5.6809, "test_samples_per_second": 360.509, "test_steps_per_second": 11.266}, {"test_loss": 0.028245139867067337, "test_micro_f1": 0.8987170830519918, "test_micro_f1_no_misc": 0.919774011299435, "test_runtime": 6.17, "test_samples_per_second": 331.928, "test_steps_per_second": 10.373}, {"test_loss": 0.03011258691549301, "test_micro_f1": 0.8539944903581268, "test_micro_f1_no_misc": 0.883952508617388, "test_runtime": 6.2492, "test_samples_per_second": 327.72, "test_steps_per_second": 10.241}, {"test_loss": 0.03669353574514389, "test_micro_f1": 0.8695950583390528, "test_micro_f1_no_misc": 0.8929523809523809, "test_runtime": 5.6907, "test_samples_per_second": 359.883, "test_steps_per_second": 11.246}, {"test_loss": 0.04175791144371033, "test_micro_f1": 0.8333910633875996, "test_micro_f1_no_misc": 0.8596096096096095, "test_runtime": 5.6426, "test_samples_per_second": 362.954, "test_steps_per_second": 11.342}, {"test_loss": 0.03511500358581543, "test_micro_f1": 0.845360824742268, "test_micro_f1_no_misc": 0.8813694267515924, "test_runtime": 5.7374, "test_samples_per_second": 356.958, "test_steps_per_second": 11.155}, {"test_loss": 0.04689906910061836, "test_micro_f1": 0.8620102214650767, "test_micro_f1_no_misc": 0.8878856282919488, "test_runtime": 6.1484, "test_samples_per_second": 333.092, "test_steps_per_second": 10.409}]}, "total": {"test_micro_f1": 86.13108802852322, "test_micro_f1_se": 1.0796069195761746, "test_micro_f1_no_misc": 88.99116754332917, "test_micro_f1_no_misc_se": 0.963161384360981}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.04319256171584129, "test_micro_f1": 0.8327687095780721, "test_micro_f1_no_misc": 0.8668264293050325, "test_runtime": 5.7051, "test_samples_per_second": 358.975, "test_steps_per_second": 11.218}, {"test_loss": 0.0528394877910614, "test_micro_f1": 0.7722597707904789, "test_micro_f1_no_misc": 0.8232603724273112, "test_runtime": 5.9682, "test_samples_per_second": 343.152, "test_steps_per_second": 10.724}, {"test_loss": 0.04926095902919769, "test_micro_f1": 0.8289273776967487, "test_micro_f1_no_misc": 0.86815834767642, "test_runtime": 5.6184, "test_samples_per_second": 364.52, "test_steps_per_second": 11.391}, {"test_loss": 0.0680333822965622, "test_micro_f1": 0.7369358669833729, "test_micro_f1_no_misc": 0.7872892347600519, "test_runtime": 6.0021, "test_samples_per_second": 341.212, "test_steps_per_second": 10.663}, {"test_loss": 0.06062622740864754, "test_micro_f1": 0.7621330137807071, "test_micro_f1_no_misc": 0.8127183787561146, "test_runtime": 5.6321, "test_samples_per_second": 363.632, "test_steps_per_second": 11.364}, {"test_loss": 0.05606549233198166, "test_micro_f1": 0.7742711151187256, "test_micro_f1_no_misc": 0.8203771088322858, "test_runtime": 5.9453, "test_samples_per_second": 344.472, "test_steps_per_second": 10.765}, {"test_loss": 0.045319415628910065, "test_micro_f1": 0.79764121663563, "test_micro_f1_no_misc": 0.8392484342379959, "test_runtime": 6.0265, "test_samples_per_second": 339.833, "test_steps_per_second": 10.62}, {"test_loss": 0.048611484467983246, "test_micro_f1": 0.7756232686980609, "test_micro_f1_no_misc": 0.8168449197860962, "test_runtime": 5.8564, "test_samples_per_second": 349.701, "test_steps_per_second": 10.928}, {"test_loss": 0.05518193542957306, "test_micro_f1": 0.779030783297775, "test_micro_f1_no_misc": 0.8235294117647058, "test_runtime": 5.2109, "test_samples_per_second": 393.024, "test_steps_per_second": 12.282}, {"test_loss": 0.052548374980688095, "test_micro_f1": 0.806421735103427, "test_micro_f1_no_misc": 0.8406574974840658, "test_runtime": 5.5324, "test_samples_per_second": 370.185, "test_steps_per_second": 11.568}]}, "total": {"test_micro_f1": 78.66012857682999, "test_micro_f1_se": 1.8523527893832035, "test_micro_f1_no_misc": 82.98910135030079, "test_micro_f1_no_misc_se": 1.5303980951333362}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.6952304840087891, "test_mcc": 0.018640968929988174, "test_macro_f1": 0.3484896868683653, "test_runtime": 3.0556, "test_samples_per_second": 670.252, "test_steps_per_second": 20.945}, {"test_loss": 0.37644749879837036, "test_mcc": 0.7188890673011366, "test_macro_f1": 0.8514668969565047, "test_runtime": 3.2406, "test_samples_per_second": 631.986, "test_steps_per_second": 19.75}, {"test_loss": 0.3206194043159485, "test_mcc": 0.750749702246198, "test_macro_f1": 0.8730861464674415, "test_runtime": 3.2021, "test_samples_per_second": 639.588, "test_steps_per_second": 19.987}, {"test_loss": 0.689250111579895, "test_mcc": 0.09402042246210586, "test_macro_f1": 0.5468594426535944, "test_runtime": 3.1021, "test_samples_per_second": 660.208, "test_steps_per_second": 20.631}, {"test_loss": 0.373942494392395, "test_mcc": 0.6897571684410485, "test_macro_f1": 0.8357832908261844, "test_runtime": 3.153, "test_samples_per_second": 649.532, "test_steps_per_second": 20.298}, {"test_loss": 0.38980966806411743, "test_mcc": 0.7432739506674451, "test_macro_f1": 0.8641852382947803, "test_runtime": 3.137, "test_samples_per_second": 652.848, "test_steps_per_second": 20.402}, {"test_loss": 0.354247510433197, "test_mcc": 0.733405685930713, "test_macro_f1": 0.8603660053142503, "test_runtime": 3.1492, "test_samples_per_second": 650.328, "test_steps_per_second": 20.323}, {"test_loss": 0.4221605658531189, "test_mcc": 0.7307425177494048, "test_macro_f1": 0.8556783201208902, "test_runtime": 3.1843, "test_samples_per_second": 643.147, "test_steps_per_second": 20.098}, {"test_loss": 0.4006233811378479, "test_mcc": 0.685325472278856, "test_macro_f1": 0.825352598616557, "test_runtime": 3.1507, "test_samples_per_second": 650.022, "test_steps_per_second": 20.313}, {"test_loss": 0.3859003186225891, "test_mcc": 0.7259223021960222, "test_macro_f1": 0.8513585623122988, "test_runtime": 3.1781, "test_samples_per_second": 644.416, "test_steps_per_second": 20.138}]}, "total": {"test_mcc": 58.907272582029194, "test_mcc_se": 17.48531667865022, "test_macro_f1": 77.12626188430868, "test_macro_f1_se": 10.99268106025549}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.693589448928833, "test_mcc": -0.01709070797821307, "test_macro_f1": 0.47283249620530926, "test_runtime": 28.8651, "test_samples_per_second": 70.951, "test_steps_per_second": 2.217}, {"test_loss": 0.4110756516456604, "test_mcc": 0.6844707775836166, "test_macro_f1": 0.8281667103862238, "test_runtime": 3.6241, "test_samples_per_second": 565.112, "test_steps_per_second": 17.66}, {"test_loss": 0.45245301723480225, "test_mcc": 0.7035793058798574, "test_macro_f1": 0.846733231618996, "test_runtime": 3.5481, "test_samples_per_second": 577.209, "test_steps_per_second": 18.038}, {"test_loss": 0.43626683950424194, "test_mcc": 0.6556894373384312, "test_macro_f1": 0.8115460379934312, "test_runtime": 3.7024, "test_samples_per_second": 553.148, "test_steps_per_second": 17.286}, {"test_loss": 0.46818703413009644, "test_mcc": 0.6837514022450857, "test_macro_f1": 0.8335583895973994, "test_runtime": 3.5362, "test_samples_per_second": 579.158, "test_steps_per_second": 18.099}, {"test_loss": 0.4312282204627991, "test_mcc": 0.6744742814562245, "test_macro_f1": 0.8233823551918236, "test_runtime": 3.5507, "test_samples_per_second": 576.785, "test_steps_per_second": 18.025}, {"test_loss": 0.4868271052837372, "test_mcc": 0.6132673585710378, "test_macro_f1": 0.7971910717307367, "test_runtime": 3.4542, "test_samples_per_second": 592.901, "test_steps_per_second": 18.528}, {"test_loss": 0.47373077273368835, "test_mcc": 0.6740891768826286, "test_macro_f1": 0.8212037648500194, "test_runtime": 3.5192, "test_samples_per_second": 581.944, "test_steps_per_second": 18.186}, {"test_loss": 0.4260556697845459, "test_mcc": 0.6991838819202605, "test_macro_f1": 0.8488356177635921, "test_runtime": 3.5201, "test_samples_per_second": 581.796, "test_steps_per_second": 18.181}, {"test_loss": 0.48228776454925537, "test_mcc": 0.6418449421729733, "test_macro_f1": 0.8089869830629042, "test_runtime": 3.6345, "test_samples_per_second": 563.493, "test_steps_per_second": 17.609}]}, "total": {"test_mcc": 60.13259856071903, "test_mcc_se": 13.572409067612345, "test_macro_f1": 78.92436658400436, "test_macro_f1_se": 6.963084664033188}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.3909507393836975, "test_mcc": 0.7070270678462978, "test_macro_f1": 0.8386344060762665, "test_runtime": 3.1904, "test_samples_per_second": 641.923, "test_steps_per_second": 20.06}, {"test_loss": 0.4460335671901703, "test_mcc": 0.6377006366086908, "test_macro_f1": 0.7957632241064312, "test_runtime": 3.1719, "test_samples_per_second": 645.675, "test_steps_per_second": 20.177}, {"test_loss": 0.43309956789016724, "test_mcc": 0.6626909304085944, "test_macro_f1": 0.8078666516368554, "test_runtime": 3.2362, "test_samples_per_second": 632.842, "test_steps_per_second": 19.776}, {"test_loss": 0.3771904706954956, "test_mcc": 0.7421425413327367, "test_macro_f1": 0.8674143789796547, "test_runtime": 3.2457, "test_samples_per_second": 630.986, "test_steps_per_second": 19.718}, {"test_loss": 0.43165767192840576, "test_mcc": 0.7239184280698205, "test_macro_f1": 0.8499027279000764, "test_runtime": 3.238, "test_samples_per_second": 632.482, "test_steps_per_second": 19.765}, {"test_loss": 0.426570862531662, "test_mcc": 0.7221825356792875, "test_macro_f1": 0.8461415401940979, "test_runtime": 3.1233, "test_samples_per_second": 655.724, "test_steps_per_second": 20.491}, {"test_loss": 0.40930354595184326, "test_mcc": 0.6827015238431356, "test_macro_f1": 0.8255487095033931, "test_runtime": 3.1022, "test_samples_per_second": 660.167, "test_steps_per_second": 20.63}, {"test_loss": 0.43444761633872986, "test_mcc": 0.728024406438683, "test_macro_f1": 0.8526968025168558, "test_runtime": 3.1631, "test_samples_per_second": 647.466, "test_steps_per_second": 20.233}, {"test_loss": 0.4407561123371124, "test_mcc": 0.7002225687897331, "test_macro_f1": 0.8373127609795108, "test_runtime": 3.107, "test_samples_per_second": 659.149, "test_steps_per_second": 20.598}, {"test_loss": 0.4553881883621216, "test_mcc": 0.6857634529746891, "test_macro_f1": 0.8297701333028802, "test_runtime": 3.1954, "test_samples_per_second": 640.922, "test_steps_per_second": 20.029}]}, "total": {"test_mcc": 69.92374091991668, "test_mcc_se": 2.0077885682905388, "test_macro_f1": 83.51051335196023, "test_macro_f1_se": 1.326276774734772}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_loss": 0.402448445558548, "test_mcc": 0.6797586816722272, "test_macro_f1": 0.8309654639969674, "test_runtime": 3.3667, "test_samples_per_second": 608.31, "test_steps_per_second": 19.01}, {"test_loss": 0.39485272765159607, "test_mcc": 0.6812186291672195, "test_macro_f1": 0.8261659800907077, "test_runtime": 3.4944, "test_samples_per_second": 586.086, "test_steps_per_second": 18.315}, {"test_loss": 0.3923960328102112, "test_mcc": 0.7089136497377307, "test_macro_f1": 0.8486387701900078, "test_runtime": 3.4859, "test_samples_per_second": 587.504, "test_steps_per_second": 18.36}, {"test_loss": 0.4222625195980072, "test_mcc": 0.6943862006541383, "test_macro_f1": 0.8359986905053116, "test_runtime": 3.3061, "test_samples_per_second": 619.462, "test_steps_per_second": 19.358}, {"test_loss": 0.3622880280017853, "test_mcc": 0.7145106936097793, "test_macro_f1": 0.8491687945461681, "test_runtime": 3.3464, "test_samples_per_second": 611.997, "test_steps_per_second": 19.125}, {"test_loss": 0.36338964104652405, "test_mcc": 0.7301237198725322, "test_macro_f1": 0.8570958641932237, "test_runtime": 3.5088, "test_samples_per_second": 583.668, "test_steps_per_second": 18.24}, {"test_loss": 0.38734135031700134, "test_mcc": 0.6937298824131124, "test_macro_f1": 0.8450389457752314, "test_runtime": 3.3743, "test_samples_per_second": 606.932, "test_steps_per_second": 18.967}, {"test_loss": 0.46786969900131226, "test_mcc": 0.6416561661752449, "test_macro_f1": 0.7991709110023534, "test_runtime": 3.3873, "test_samples_per_second": 604.606, "test_steps_per_second": 18.894}, {"test_loss": 0.3554382026195526, "test_mcc": 0.7279044845119401, "test_macro_f1": 0.8606072366763307, "test_runtime": 3.3691, "test_samples_per_second": 607.871, "test_steps_per_second": 18.996}, {"test_loss": 0.3789689838886261, "test_mcc": 0.7328471458117531, "test_macro_f1": 0.8597388817347436, "test_runtime": 3.4271, "test_samples_per_second": 597.595, "test_steps_per_second": 18.675}]}, "total": {"test_mcc": 70.05049253625678, "test_mcc_se": 1.7639734488543592, "test_macro_f1": 84.12589538711046, "test_macro_f1_se": 1.1743318425990115}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_em": 46.39814097598761, "test_f1": 50.68101799710238}, {"test_em": 45.42635658914729, "test_f1": 49.27412329019717}, {"test_em": 40.1854714064915, "test_f1": 44.02561773368212}, {"test_em": 41.04361370716511, "test_f1": 44.657914535865835}, {"test_em": 46.71814671814672, "test_f1": 50.69086876651435}, {"test_em": 35.774865073245955, "test_f1": 39.72081438509785}, {"test_em": 43.28018223234624, "test_f1": 46.431444449597166}, {"test_em": 43.59968968192397, "test_f1": 47.069896816046054}, {"test_em": 34.03921568627451, "test_f1": 38.613969195444355}, {"test_em": 42.77950310559006, "test_f1": 45.633597225728934}]}, "total": {"test_em": 41.924518517631896, "test_em_se": 2.649237074405564, "test_f1": 45.67992643952762, "test_f1_se": 2.570164407717265}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_em": 35.9411309062742, "test_f1": 40.581179929407455}, {"test_em": 40.310077519379846, "test_f1": 46.62529517905714}, {"test_em": 40.108191653786704, "test_f1": 44.73567556948808}, {"test_em": 42.834890965732086, "test_f1": 47.18188284744156}, {"test_em": 44.55598455598456, "test_f1": 48.56624192004843}, {"test_em": 42.79105628373169, "test_f1": 47.068589735329596}, {"test_em": 47.911921032649964, "test_f1": 51.678143531638305}, {"test_em": 35.2211016291699, "test_f1": 39.740055951545415}, {"test_em": 39.68627450980392, "test_f1": 44.86868886187769}, {"test_em": 36.18012422360248, "test_f1": 42.16207928683396}]}, "total": {"test_em": 40.554075328011535, "test_em_se": 2.532221838537326, "test_f1": 45.320783281266756, "test_f1_se": 2.2941380227504906}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_em": 40.66615027110767, "test_f1": 45.19509866459339}, {"test_em": 40.07751937984496, "test_f1": 45.92019812559449}, {"test_em": 43.431221020092735, "test_f1": 47.85711764614152}, {"test_em": 43.06853582554517, "test_f1": 47.64992495874125}, {"test_em": 40.38610038610039, "test_f1": 44.71009023463687}, {"test_em": 42.63685427910563, "test_f1": 46.729571618747855}, {"test_em": 39.78739559605163, "test_f1": 43.70944057448358}, {"test_em": 44.22032583397983, "test_f1": 48.599113095710884}, {"test_em": 40.627450980392155, "test_f1": 45.879960593983554}, {"test_em": 40.91614906832298, "test_f1": 44.66420883503672}]}, "total": {"test_em": 41.58177026405431, "test_em_se": 0.9867373638104722, "test_f1": 46.09147243476702, "test_f1_se": 0.9851833751889032}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.45528551936149597, "test_mcc": 0.7107338282716527, "test_macro_f1": 0.593840468185803, "test_runtime": 13.9862, "test_samples_per_second": 146.431, "test_steps_per_second": 18.304}, {"test_loss": 0.5383003950119019, "test_mcc": 0.6495876661424917, "test_macro_f1": 0.562475562270854, "test_runtime": 13.3655, "test_samples_per_second": 153.231, "test_steps_per_second": 19.154}, {"test_loss": 0.4486860930919647, "test_mcc": 0.728838812905568, "test_macro_f1": 0.6842881906667547, "test_runtime": 17.0337, "test_samples_per_second": 120.232, "test_steps_per_second": 60.116}, {"test_loss": 0.39429789781570435, "test_mcc": 0.755003721843709, "test_macro_f1": 0.7639788634959382, "test_runtime": 16.8561, "test_samples_per_second": 121.499, "test_steps_per_second": 60.75}, {"test_loss": 0.39544597268104553, "test_mcc": 0.7608345370027532, "test_macro_f1": 0.7315408997548115, "test_runtime": 16.8046, "test_samples_per_second": 121.871, "test_steps_per_second": 60.936}, {"test_loss": 0.46094489097595215, "test_mcc": 0.724115116201663, "test_macro_f1": 0.5927983726672933, "test_runtime": 16.9237, "test_samples_per_second": 121.014, "test_steps_per_second": 60.507}, {"test_loss": 0.41264164447784424, "test_mcc": 0.7775859291776334, "test_macro_f1": 0.7731774175685757, "test_runtime": 16.9608, "test_samples_per_second": 120.749, "test_steps_per_second": 60.375}, {"test_loss": 0.4429439902305603, "test_mcc": 0.7351172377362356, "test_macro_f1": 0.7383303846319266, "test_runtime": 17.1746, "test_samples_per_second": 119.246, "test_steps_per_second": 59.623}, {"test_loss": 0.4477124810218811, "test_mcc": 0.7341642978614674, "test_macro_f1": 0.7027686356715447, "test_runtime": 16.9661, "test_samples_per_second": 120.712, "test_steps_per_second": 60.356}, {"test_loss": 0.42583346366882324, "test_mcc": 0.7617450689332345, "test_macro_f1": 0.7427009506731563, "test_runtime": 17.104, "test_samples_per_second": 119.738, "test_steps_per_second": 59.869}]}, "total": {"test_mcc": 73.37726216076408, "test_mcc_se": 2.2273430397515512, "test_macro_f1": 68.85899745586659, "test_macro_f1_se": 4.817122539423988}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.7989287376403809, "test_mcc": 0.49660880863296314, "test_macro_f1": 0.663843805558801, "test_runtime": 4.2093, "test_samples_per_second": 486.543, "test_steps_per_second": 15.204}, {"test_loss": 0.8545639514923096, "test_mcc": 0.49123460549930686, "test_macro_f1": 0.6451859198662908, "test_runtime": 4.1365, "test_samples_per_second": 495.11, "test_steps_per_second": 15.472}, {"test_loss": 0.7974459528923035, "test_mcc": 0.48536625414924994, "test_macro_f1": 0.6622504758799964, "test_runtime": 4.1431, "test_samples_per_second": 494.32, "test_steps_per_second": 15.448}, {"test_loss": 0.819511890411377, "test_mcc": 0.5069487526195661, "test_macro_f1": 0.6705589363494783, "test_runtime": 4.092, "test_samples_per_second": 500.488, "test_steps_per_second": 15.64}, {"test_loss": 0.8427640199661255, "test_mcc": 0.4503972476794781, "test_macro_f1": 0.6391311431623931, "test_runtime": 4.1053, "test_samples_per_second": 498.866, "test_steps_per_second": 15.59}, {"test_loss": 0.8833284378051758, "test_mcc": 0.4101531464369897, "test_macro_f1": 0.5903764386691749, "test_runtime": 4.1759, "test_samples_per_second": 490.428, "test_steps_per_second": 15.326}, {"test_loss": 0.8204983472824097, "test_mcc": 0.4755806909466, "test_macro_f1": 0.6501684342703159, "test_runtime": 4.0898, "test_samples_per_second": 500.761, "test_steps_per_second": 15.649}, {"test_loss": 0.921208381652832, "test_mcc": 0.4047029371218654, "test_macro_f1": 0.5879584685734139, "test_runtime": 4.1867, "test_samples_per_second": 489.173, "test_steps_per_second": 15.287}, {"test_loss": 0.8670607805252075, "test_mcc": 0.4860555490217323, "test_macro_f1": 0.6511889763541201, "test_runtime": 4.1089, "test_samples_per_second": 498.431, "test_steps_per_second": 15.576}, {"test_loss": 0.8309393525123596, "test_mcc": 0.49277932830548016, "test_macro_f1": 0.6647464530010745, "test_runtime": 4.0518, "test_samples_per_second": 505.458, "test_steps_per_second": 15.796}]}, "total": {"test_mcc": 46.99827320413232, "test_mcc_se": 2.2440558280775367, "test_macro_f1": 64.25409051685058, "test_macro_f1_se": 1.8447086236508745}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.7414011359214783, "test_mcc": 0.5813391433884889, "test_macro_f1": 0.7093126473906551, "test_runtime": 3.5141, "test_samples_per_second": 582.789, "test_steps_per_second": 18.212}, {"test_loss": 0.7502887845039368, "test_mcc": 0.5553897576927, "test_macro_f1": 0.6869541690459903, "test_runtime": 3.2758, "test_samples_per_second": 625.19, "test_steps_per_second": 19.537}, {"test_loss": 0.7647362947463989, "test_mcc": 0.4903377970365718, "test_macro_f1": 0.642310268925256, "test_runtime": 3.3617, "test_samples_per_second": 609.214, "test_steps_per_second": 19.038}, {"test_loss": 0.7505526542663574, "test_mcc": 0.5366876047646499, "test_macro_f1": 0.6660107154971432, "test_runtime": 3.4511, "test_samples_per_second": 593.426, "test_steps_per_second": 18.545}, {"test_loss": 0.8397967219352722, "test_mcc": 0.5207426621192761, "test_macro_f1": 0.6666124437576605, "test_runtime": 3.4286, "test_samples_per_second": 597.323, "test_steps_per_second": 18.666}, {"test_loss": 0.7763066291809082, "test_mcc": 0.5540650581369017, "test_macro_f1": 0.6929378317595729, "test_runtime": 3.4846, "test_samples_per_second": 587.733, "test_steps_per_second": 18.367}, {"test_loss": 0.7799040675163269, "test_mcc": 0.526637489792988, "test_macro_f1": 0.6581296424916148, "test_runtime": 3.3524, "test_samples_per_second": 610.903, "test_steps_per_second": 19.091}, {"test_loss": 0.79535311460495, "test_mcc": 0.5493891165267463, "test_macro_f1": 0.6794572757289935, "test_runtime": 3.4803, "test_samples_per_second": 588.455, "test_steps_per_second": 18.389}, {"test_loss": 0.8573936820030212, "test_mcc": 0.5689842689091711, "test_macro_f1": 0.7002106697148034, "test_runtime": 3.5367, "test_samples_per_second": 579.072, "test_steps_per_second": 18.096}, {"test_loss": 0.7945677638053894, "test_mcc": 0.439027482825142, "test_macro_f1": 0.49722758892077695, "test_runtime": 3.5526, "test_samples_per_second": 576.477, "test_steps_per_second": 18.015}]}, "total": {"test_mcc": 53.22600381192635, "test_mcc_se": 2.588299038159453, "test_macro_f1": 65.99163253232466, "test_macro_f1_se": 3.7604832879772085}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.0599471777677536, "test_micro_f1": 0.7118473895582328, "test_micro_f1_no_misc": 0.7910628019323672, "test_runtime": 7.0052, "test_samples_per_second": 292.353, "test_steps_per_second": 9.136}, {"test_loss": 0.05672464519739151, "test_micro_f1": 0.7291666666666667, "test_micro_f1_no_misc": 0.7906698564593302, "test_runtime": 6.7606, "test_samples_per_second": 302.931, "test_steps_per_second": 9.467}, {"test_loss": 0.05885225534439087, "test_micro_f1": 0.6571155682903534, "test_micro_f1_no_misc": 0.7306233062330623, "test_runtime": 6.3774, "test_samples_per_second": 321.132, "test_steps_per_second": 10.035}, {"test_loss": 0.05517078936100006, "test_micro_f1": 0.7336633663366335, "test_micro_f1_no_misc": 0.7856736782262649, "test_runtime": 6.9963, "test_samples_per_second": 292.727, "test_steps_per_second": 9.148}, {"test_loss": 0.06364477425813675, "test_micro_f1": 0.7306590257879656, "test_micro_f1_no_misc": 0.788657035848047, "test_runtime": 7.0416, "test_samples_per_second": 290.844, "test_steps_per_second": 9.089}, {"test_loss": 0.05150267481803894, "test_micro_f1": 0.7687969924812029, "test_micro_f1_no_misc": 0.8248337028824834, "test_runtime": 5.7925, "test_samples_per_second": 353.559, "test_steps_per_second": 11.049}, {"test_loss": 0.06034604460000992, "test_micro_f1": 0.6980952380952381, "test_micro_f1_no_misc": 0.7674418604651163, "test_runtime": 5.8075, "test_samples_per_second": 352.647, "test_steps_per_second": 11.02}, {"test_loss": 0.05091797560453415, "test_micro_f1": 0.7237687366167024, "test_micro_f1_no_misc": 0.7811531308121513, "test_runtime": 6.8466, "test_samples_per_second": 299.127, "test_steps_per_second": 9.348}, {"test_loss": 0.05737478286027908, "test_micro_f1": 0.6990384615384615, "test_micro_f1_no_misc": 0.7426431246655966, "test_runtime": 6.4836, "test_samples_per_second": 315.873, "test_steps_per_second": 9.871}, {"test_loss": 0.05619584396481514, "test_micro_f1": 0.7400581959262851, "test_micro_f1_no_misc": 0.8184438040345822, "test_runtime": 6.976, "test_samples_per_second": 293.579, "test_steps_per_second": 9.174}]}, "total": {"test_micro_f1": 71.92209641297742, "test_micro_f1_se": 1.8612621363083144, "test_micro_f1_no_misc": 78.21202301559, "test_micro_f1_no_misc_se": 1.8222062999573487}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.058937013149261475, "test_micro_f1": 0.8303571428571429, "test_micro_f1_no_misc": 0.8560420315236428, "test_runtime": 7.8491, "test_samples_per_second": 260.923, "test_steps_per_second": 8.154}, {"test_loss": 0.05894394591450691, "test_micro_f1": 0.8451414169700363, "test_micro_f1_no_misc": 0.8583055863854976, "test_runtime": 6.514, "test_samples_per_second": 314.402, "test_steps_per_second": 9.825}, {"test_loss": 0.06269772350788116, "test_micro_f1": 0.8210862619808307, "test_micro_f1_no_misc": 0.8335115864527629, "test_runtime": 7.7952, "test_samples_per_second": 262.725, "test_steps_per_second": 8.21}, {"test_loss": 0.058625973761081696, "test_micro_f1": 0.8252326783867631, "test_micro_f1_no_misc": 0.843441466854725, "test_runtime": 7.6086, "test_samples_per_second": 269.168, "test_steps_per_second": 8.412}, {"test_loss": 0.06547902524471283, "test_micro_f1": 0.8281913388055476, "test_micro_f1_no_misc": 0.8464476699770818, "test_runtime": 7.8176, "test_samples_per_second": 261.972, "test_steps_per_second": 8.187}, {"test_loss": 0.0601065456867218, "test_micro_f1": 0.8296013107591479, "test_micro_f1_no_misc": 0.8485768500948766, "test_runtime": 7.767, "test_samples_per_second": 263.681, "test_steps_per_second": 8.24}, {"test_loss": 0.05791466683149338, "test_micro_f1": 0.8202306079664569, "test_micro_f1_no_misc": 0.8398451249560014, "test_runtime": 7.9268, "test_samples_per_second": 258.363, "test_steps_per_second": 8.074}, {"test_loss": 0.05370170623064041, "test_micro_f1": 0.8267911062311282, "test_micro_f1_no_misc": 0.8383763837638376, "test_runtime": 7.7889, "test_samples_per_second": 262.937, "test_steps_per_second": 8.217}, {"test_loss": 0.05877326428890228, "test_micro_f1": 0.839347767976477, "test_micro_f1_no_misc": 0.85459940652819, "test_runtime": 7.5945, "test_samples_per_second": 269.669, "test_steps_per_second": 8.427}, {"test_loss": 0.06130455434322357, "test_micro_f1": 0.8548827059465356, "test_micro_f1_no_misc": 0.8755458515283843, "test_runtime": 6.7961, "test_samples_per_second": 301.348, "test_steps_per_second": 9.417}]}, "total": {"test_micro_f1": 83.20862337880065, "test_micro_f1_se": 0.6863876827543411, "test_micro_f1_no_misc": 84.94691958064999, "test_micro_f1_no_misc_se": 0.7574646851717056}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.04235035926103592, "test_micro_f1": 0.8521229868228404, "test_micro_f1_no_misc": 0.8803312629399586, "test_runtime": 6.1812, "test_samples_per_second": 331.328, "test_steps_per_second": 10.354}, {"test_loss": 0.031883955001831055, "test_micro_f1": 0.8646449704142011, "test_micro_f1_no_misc": 0.890625, "test_runtime": 6.1501, "test_samples_per_second": 333.003, "test_steps_per_second": 10.406}, {"test_loss": 0.03604809567332268, "test_micro_f1": 0.8615600843288828, "test_micro_f1_no_misc": 0.8865331762858264, "test_runtime": 5.7574, "test_samples_per_second": 355.718, "test_steps_per_second": 11.116}, {"test_loss": 0.03372696042060852, "test_micro_f1": 0.8774787535410766, "test_micro_f1_no_misc": 0.8998410174880764, "test_runtime": 5.723, "test_samples_per_second": 357.855, "test_steps_per_second": 11.183}, {"test_loss": 0.03105601854622364, "test_micro_f1": 0.8797319932998325, "test_micro_f1_no_misc": 0.901990236575291, "test_runtime": 6.1888, "test_samples_per_second": 330.92, "test_steps_per_second": 10.341}, {"test_loss": 0.02847607433795929, "test_micro_f1": 0.8895747599451304, "test_micro_f1_no_misc": 0.9109062980030722, "test_runtime": 6.1969, "test_samples_per_second": 330.487, "test_steps_per_second": 10.328}, {"test_loss": 0.02903357520699501, "test_micro_f1": 0.877543980682994, "test_micro_f1_no_misc": 0.8981161091887737, "test_runtime": 5.684, "test_samples_per_second": 360.312, "test_steps_per_second": 11.26}, {"test_loss": 0.03362293541431427, "test_micro_f1": 0.874869292436389, "test_micro_f1_no_misc": 0.9010654490106544, "test_runtime": 5.6472, "test_samples_per_second": 362.659, "test_steps_per_second": 11.333}, {"test_loss": 0.03035132586956024, "test_micro_f1": 0.8661818181818182, "test_micro_f1_no_misc": 0.8878923766816144, "test_runtime": 5.8115, "test_samples_per_second": 352.405, "test_steps_per_second": 11.013}, {"test_loss": 0.044591426849365234, "test_micro_f1": 0.8711111111111112, "test_micro_f1_no_misc": 0.8977879481311976, "test_runtime": 6.1101, "test_samples_per_second": 335.182, "test_steps_per_second": 10.474}]}, "total": {"test_micro_f1": 87.14819750764275, "test_micro_f1_se": 0.6623469443785034, "test_micro_f1_no_misc": 89.55088874304465, "test_micro_f1_no_misc_se": 0.5595485749022706}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.04728900268673897, "test_micro_f1": 0.796416434970652, "test_micro_f1_no_misc": 0.834257975034674, "test_runtime": 5.6671, "test_samples_per_second": 361.384, "test_steps_per_second": 11.293}, {"test_loss": 0.054925866425037384, "test_micro_f1": 0.8083814151229881, "test_micro_f1_no_misc": 0.8420343550016841, "test_runtime": 5.8359, "test_samples_per_second": 350.93, "test_steps_per_second": 10.967}, {"test_loss": 0.05460143834352493, "test_micro_f1": 0.7598460171750075, "test_micro_f1_no_misc": 0.80513495720869, "test_runtime": 5.5836, "test_samples_per_second": 366.791, "test_steps_per_second": 11.462}, {"test_loss": 0.056213442236185074, "test_micro_f1": 0.8133942161339421, "test_micro_f1_no_misc": 0.8458362009635237, "test_runtime": 5.968, "test_samples_per_second": 343.165, "test_steps_per_second": 10.724}, {"test_loss": 0.06411319971084595, "test_micro_f1": 0.7212728344136712, "test_micro_f1_no_misc": 0.7643020594965676, "test_runtime": 5.5697, "test_samples_per_second": 367.702, "test_steps_per_second": 11.491}, {"test_loss": 0.05532092601060867, "test_micro_f1": 0.824165915238954, "test_micro_f1_no_misc": 0.8560734943858456, "test_runtime": 5.942, "test_samples_per_second": 344.665, "test_steps_per_second": 10.771}, {"test_loss": 0.048552583903074265, "test_micro_f1": 0.8205756276791182, "test_micro_f1_no_misc": 0.8521387672617042, "test_runtime": 5.9142, "test_samples_per_second": 346.285, "test_steps_per_second": 10.821}, {"test_loss": 0.05337672308087349, "test_micro_f1": 0.8160291438979963, "test_micro_f1_no_misc": 0.8516042780748663, "test_runtime": 5.9345, "test_samples_per_second": 345.099, "test_steps_per_second": 10.784}, {"test_loss": 0.0714384913444519, "test_micro_f1": 0.6674655482324745, "test_micro_f1_no_misc": 0.7157083199486026, "test_runtime": 5.2401, "test_samples_per_second": 390.834, "test_steps_per_second": 12.214}, {"test_loss": 0.05112951993942261, "test_micro_f1": 0.7942437232088182, "test_micro_f1_no_misc": 0.8265609514370664, "test_runtime": 5.5799, "test_samples_per_second": 367.028, "test_steps_per_second": 11.47}]}, "total": {"test_micro_f1": 78.21790876073622, "test_micro_f1_se": 3.184606423240273, "test_micro_f1_no_misc": 81.93651358813223, "test_micro_f1_no_misc_se": 2.842438513865268}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.3916631042957306, "test_mcc": 0.6869273634124125, "test_macro_f1": 0.8412449676491304, "test_runtime": 3.1165, "test_samples_per_second": 657.15, "test_steps_per_second": 20.536}, {"test_loss": 0.4376944899559021, "test_mcc": 0.6570157975714982, "test_macro_f1": 0.8246130734526527, "test_runtime": 3.2256, "test_samples_per_second": 634.922, "test_steps_per_second": 19.841}, {"test_loss": 0.4206198751926422, "test_mcc": 0.6657128207591343, "test_macro_f1": 0.8300959725945112, "test_runtime": 3.2001, "test_samples_per_second": 639.971, "test_steps_per_second": 19.999}, {"test_loss": 0.41626930236816406, "test_mcc": 0.6824729950282825, "test_macro_f1": 0.8396352176287853, "test_runtime": 3.1095, "test_samples_per_second": 658.636, "test_steps_per_second": 20.582}, {"test_loss": 0.4203227758407593, "test_mcc": 0.6628497675105324, "test_macro_f1": 0.8127540568422391, "test_runtime": 3.1604, "test_samples_per_second": 648.018, "test_steps_per_second": 20.251}, {"test_loss": 0.5004531145095825, "test_mcc": 0.6664322239769144, "test_macro_f1": 0.8299924189196399, "test_runtime": 3.1564, "test_samples_per_second": 648.836, "test_steps_per_second": 20.276}, {"test_loss": 0.38097721338272095, "test_mcc": 0.6992363451815052, "test_macro_f1": 0.8448931070846515, "test_runtime": 3.1489, "test_samples_per_second": 650.385, "test_steps_per_second": 20.325}, {"test_loss": 0.7020025849342346, "test_mcc": 0.17469523853563138, "test_macro_f1": 0.5031751888815137, "test_runtime": 3.2137, "test_samples_per_second": 637.281, "test_steps_per_second": 19.915}, {"test_loss": 0.4131940007209778, "test_mcc": 0.690131348033937, "test_macro_f1": 0.8418320405627748, "test_runtime": 3.1593, "test_samples_per_second": 648.249, "test_steps_per_second": 20.258}, {"test_loss": 0.4365346133708954, "test_mcc": 0.669711662460665, "test_macro_f1": 0.8200509621298655, "test_runtime": 3.164, "test_samples_per_second": 647.285, "test_steps_per_second": 20.228}]}, "total": {"test_mcc": 62.551855624705134, "test_mcc_se": 9.854161325397882, "test_macro_f1": 79.88287005745764, "test_macro_f1_se": 6.471116796610513}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.4937288761138916, "test_mcc": 0.6343570526036032, "test_macro_f1": 0.8167098997417471, "test_runtime": 3.5454, "test_samples_per_second": 577.653, "test_steps_per_second": 18.052}, {"test_loss": 0.48775988817214966, "test_mcc": 0.5739359891122954, "test_macro_f1": 0.7725718920798007, "test_runtime": 3.659, "test_samples_per_second": 559.71, "test_steps_per_second": 17.491}, {"test_loss": 0.4146574139595032, "test_mcc": 0.6423418449293337, "test_macro_f1": 0.8197414414382005, "test_runtime": 3.6062, "test_samples_per_second": 567.908, "test_steps_per_second": 17.747}, {"test_loss": 0.4695666432380676, "test_mcc": 0.6323128223751177, "test_macro_f1": 0.8059734245926442, "test_runtime": 3.7103, "test_samples_per_second": 551.982, "test_steps_per_second": 17.249}, {"test_loss": 0.43203192949295044, "test_mcc": 0.6774853578490191, "test_macro_f1": 0.8330403290854911, "test_runtime": 3.5529, "test_samples_per_second": 576.433, "test_steps_per_second": 18.014}, {"test_loss": 0.4336709976196289, "test_mcc": 0.6557778133257565, "test_macro_f1": 0.8274520474054343, "test_runtime": 3.562, "test_samples_per_second": 574.959, "test_steps_per_second": 17.967}, {"test_loss": 0.4840931296348572, "test_mcc": 0.5800175015368944, "test_macro_f1": 0.7719444446466146, "test_runtime": 3.4967, "test_samples_per_second": 585.703, "test_steps_per_second": 18.303}, {"test_loss": 0.47161340713500977, "test_mcc": 0.5837208134301358, "test_macro_f1": 0.7759840301115216, "test_runtime": 3.4987, "test_samples_per_second": 585.361, "test_steps_per_second": 18.293}, {"test_loss": 0.4620055556297302, "test_mcc": 0.6085549468411541, "test_macro_f1": 0.8032228303735749, "test_runtime": 3.5049, "test_samples_per_second": 584.318, "test_steps_per_second": 18.26}, {"test_loss": 0.4195026159286499, "test_mcc": 0.6555966066538307, "test_macro_f1": 0.821538678694293, "test_runtime": 3.5976, "test_samples_per_second": 569.272, "test_steps_per_second": 17.79}]}, "total": {"test_mcc": 62.4410074865714, "test_mcc_se": 2.23300498316183, "test_macro_f1": 80.48179018169321, "test_macro_f1_se": 1.4474344473665162}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.47511449456214905, "test_mcc": 0.5869455314242051, "test_macro_f1": 0.7764482363908851, "test_runtime": 3.1994, "test_samples_per_second": 640.121, "test_steps_per_second": 20.004}, {"test_loss": 0.45092400908470154, "test_mcc": 0.6931784639203163, "test_macro_f1": 0.8341263895357077, "test_runtime": 3.2247, "test_samples_per_second": 635.1, "test_steps_per_second": 19.847}, {"test_loss": 0.3737092614173889, "test_mcc": 0.6915663177445583, "test_macro_f1": 0.8400021024188569, "test_runtime": 3.1977, "test_samples_per_second": 640.46, "test_steps_per_second": 20.014}, {"test_loss": 0.41596394777297974, "test_mcc": 0.6546910472645094, "test_macro_f1": 0.8126496884339561, "test_runtime": 3.2454, "test_samples_per_second": 631.056, "test_steps_per_second": 19.72}, {"test_loss": 0.3988734781742096, "test_mcc": 0.682944699310992, "test_macro_f1": 0.8363400357900582, "test_runtime": 3.2069, "test_samples_per_second": 638.62, "test_steps_per_second": 19.957}, {"test_loss": 0.4521040916442871, "test_mcc": 0.6422517067730653, "test_macro_f1": 0.8048095122602221, "test_runtime": 3.0924, "test_samples_per_second": 662.265, "test_steps_per_second": 20.696}, {"test_loss": 0.4164695739746094, "test_mcc": 0.6801788701147025, "test_macro_f1": 0.8325048393341077, "test_runtime": 3.0888, "test_samples_per_second": 663.05, "test_steps_per_second": 20.72}, {"test_loss": 0.41920235753059387, "test_mcc": 0.7024712511931999, "test_macro_f1": 0.8471524057979223, "test_runtime": 3.1613, "test_samples_per_second": 647.844, "test_steps_per_second": 20.245}, {"test_loss": 0.44046157598495483, "test_mcc": 0.7208121901167379, "test_macro_f1": 0.8545840701489372, "test_runtime": 3.0785, "test_samples_per_second": 665.255, "test_steps_per_second": 20.789}, {"test_loss": 0.4899471402168274, "test_mcc": 0.6054118034567767, "test_macro_f1": 0.7730416328323899, "test_runtime": 3.1965, "test_samples_per_second": 640.708, "test_steps_per_second": 20.022}]}, "total": {"test_mcc": 66.60451881319062, "test_mcc_se": 2.6800517760805858, "test_macro_f1": 82.11658912943044, "test_macro_f1_se": 1.7687541119337675}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6923224925994873, "test_mcc": 0.052585050949081176, "test_macro_f1": 0.41778125964437485, "test_runtime": 3.3515, "test_samples_per_second": 611.066, "test_steps_per_second": 19.096}, {"test_loss": 0.6935327649116516, "test_mcc": -0.003936465585365058, "test_macro_f1": 0.49448741155175246, "test_runtime": 3.4835, "test_samples_per_second": 587.911, "test_steps_per_second": 18.372}, {"test_loss": 0.691634476184845, "test_mcc": 0.0, "test_macro_f1": 0.33376707872478856, "test_runtime": 3.4758, "test_samples_per_second": 589.218, "test_steps_per_second": 18.413}, {"test_loss": 0.5402577519416809, "test_mcc": 0.5011860257429853, "test_macro_f1": 0.739988980684031, "test_runtime": 3.3272, "test_samples_per_second": 615.527, "test_steps_per_second": 19.235}, {"test_loss": 0.5149775147438049, "test_mcc": 0.5767746390336577, "test_macro_f1": 0.7852611367792441, "test_runtime": 3.3515, "test_samples_per_second": 611.073, "test_steps_per_second": 19.096}, {"test_loss": 0.499950110912323, "test_mcc": 0.5414267265772491, "test_macro_f1": 0.7706719193004445, "test_runtime": 3.465, "test_samples_per_second": 591.051, "test_steps_per_second": 18.47}, {"test_loss": 0.5290317535400391, "test_mcc": 0.5125977092246703, "test_macro_f1": 0.7562192650691361, "test_runtime": 3.3766, "test_samples_per_second": 606.52, "test_steps_per_second": 18.954}, {"test_loss": 0.6107171177864075, "test_mcc": 0.39606585797679794, "test_macro_f1": 0.6962044824942302, "test_runtime": 3.364, "test_samples_per_second": 608.807, "test_steps_per_second": 19.025}, {"test_loss": 0.5509685277938843, "test_mcc": 0.49966214977007856, "test_macro_f1": 0.7496906271484226, "test_runtime": 3.3556, "test_samples_per_second": 610.325, "test_steps_per_second": 19.073}, {"test_loss": 0.5699065923690796, "test_mcc": 0.5424621012107729, "test_macro_f1": 0.7639284363608243, "test_runtime": 3.4552, "test_samples_per_second": 592.734, "test_steps_per_second": 18.523}]}, "total": {"test_mcc": 36.18823794899928, "test_mcc_se": 15.093886415986798, "test_macro_f1": 65.08000597757248, "test_macro_f1_se": 10.441018262864064}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_em": 45.158791634391946, "test_f1": 49.7848853912828}, {"test_em": 35.03875968992248, "test_f1": 38.80664592645297}, {"test_em": 43.276661514683155, "test_f1": 47.593500436731404}, {"test_em": 40.965732087227416, "test_f1": 45.58071682190994}, {"test_em": 41.62162162162162, "test_f1": 45.33573445851198}, {"test_em": 40.01542020046261, "test_f1": 45.27276065654106}, {"test_em": 42.67274107820805, "test_f1": 47.268680080393295}, {"test_em": 45.15128006206361, "test_f1": 49.68172294471632}, {"test_em": 46.35294117647059, "test_f1": 50.78134374626926}, {"test_em": 43.7888198757764, "test_f1": 48.56526298490463}]}, "total": {"test_em": 42.4042768940828, "test_em_se": 2.0254898650167545, "test_f1": 46.86712534477137, "test_f1_se": 2.1355333044474967}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_em": 33.15259488768397, "test_f1": 38.41658697689854}, {"test_em": 46.12403100775194, "test_f1": 50.46663160605245}, {"test_em": 39.258114374034, "test_f1": 44.19787127131445}, {"test_em": 45.95015576323988, "test_f1": 51.43096123380617}, {"test_em": 40.38610038610039, "test_f1": 45.41686827423228}, {"test_em": 41.094834232845024, "test_f1": 46.29999683698263}, {"test_em": 39.863325740318906, "test_f1": 44.81215485771295}, {"test_em": 35.60899922420481, "test_f1": 40.862949387037474}, {"test_em": 48.0, "test_f1": 53.27646280257216}, {"test_em": 44.642857142857146, "test_f1": 50.046104153603956}]}, "total": {"test_em": 41.408101275903604, "test_em_se": 2.9704861317822533, "test_f1": 46.522658740021306, "test_f1_se": 2.958225321307603}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_em": 45.62354763749032, "test_f1": 50.98587012891928}, {"test_em": 38.68217054263566, "test_f1": 43.835511459764476}, {"test_em": 47.60432766615147, "test_f1": 52.25189788858853}, {"test_em": 42.601246105919, "test_f1": 48.03073661682825}, {"test_em": 43.397683397683394, "test_f1": 49.31258362085427}, {"test_em": 45.48959136468774, "test_f1": 50.30812659373311}, {"test_em": 43.20425208807897, "test_f1": 48.32406985058999}, {"test_em": 37.393328161365396, "test_f1": 41.50707780340635}, {"test_em": 47.529411764705884, "test_f1": 52.69190837690911}, {"test_em": 34.54968944099379, "test_f1": 39.37635238295177}]}, "total": {"test_em": 42.60752481697116, "test_em_se": 2.7338791563305573, "test_f1": 47.662413472254514, "test_f1_se": 2.8395057665634873}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.4329885244369507, "test_mcc": 0.7144309663534643, "test_macro_f1": 0.5949108739492598, "test_runtime": 14.0162, "test_samples_per_second": 146.117, "test_steps_per_second": 18.265}, {"test_loss": 0.47945287823677063, "test_mcc": 0.6930252870744045, "test_macro_f1": 0.5901301847887827, "test_runtime": 13.2665, "test_samples_per_second": 154.373, "test_steps_per_second": 19.297}, {"test_loss": 0.46433141827583313, "test_mcc": 0.7056534386883972, "test_macro_f1": 0.585723823133895, "test_runtime": 13.7439, "test_samples_per_second": 149.011, "test_steps_per_second": 18.626}, {"test_loss": 0.40865617990493774, "test_mcc": 0.7204433260715568, "test_macro_f1": 0.6005737275313978, "test_runtime": 13.0068, "test_samples_per_second": 157.456, "test_steps_per_second": 19.682}, {"test_loss": 0.4435397684574127, "test_mcc": 0.7220203451625067, "test_macro_f1": 0.7007315377426804, "test_runtime": 12.9305, "test_samples_per_second": 158.385, "test_steps_per_second": 19.798}, {"test_loss": 0.46108922362327576, "test_mcc": 0.6845297670173625, "test_macro_f1": 0.6586280524691885, "test_runtime": 13.3825, "test_samples_per_second": 153.036, "test_steps_per_second": 19.13}, {"test_loss": 0.4307393431663513, "test_mcc": 0.7151458145608747, "test_macro_f1": 0.6990219250009141, "test_runtime": 12.8378, "test_samples_per_second": 159.529, "test_steps_per_second": 19.941}, {"test_loss": 0.4336739778518677, "test_mcc": 0.7265735659423105, "test_macro_f1": 0.6881303126165949, "test_runtime": 13.9061, "test_samples_per_second": 147.273, "test_steps_per_second": 18.409}, {"test_loss": 0.47187674045562744, "test_mcc": 0.7018594240427907, "test_macro_f1": 0.6171401294929306, "test_runtime": 13.758, "test_samples_per_second": 148.859, "test_steps_per_second": 18.607}, {"test_loss": 0.45186659693717957, "test_mcc": 0.7377774411236586, "test_macro_f1": 0.7122084504028431, "test_runtime": 13.3344, "test_samples_per_second": 153.588, "test_steps_per_second": 19.199}]}, "total": {"test_mcc": 71.21459376037326, "test_mcc_se": 0.9955390964377229, "test_macro_f1": 64.47199017128487, "test_macro_f1_se": 3.2252215402546534}}, "num_model_parameters": 124448259, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.7920043468475342, "test_mcc": 0.4814645711355255, "test_macro_f1": 0.6571582413918433, "test_runtime": 4.2178, "test_samples_per_second": 485.558, "test_steps_per_second": 15.174}, {"test_loss": 0.8558233380317688, "test_mcc": 0.4899279179416368, "test_macro_f1": 0.657949278053093, "test_runtime": 4.1875, "test_samples_per_second": 489.079, "test_steps_per_second": 15.284}, {"test_loss": 0.8309663534164429, "test_mcc": 0.45212188589094554, "test_macro_f1": 0.6279179012816645, "test_runtime": 4.1947, "test_samples_per_second": 488.234, "test_steps_per_second": 15.257}, {"test_loss": 0.9414997696876526, "test_mcc": 0.43272362432454486, "test_macro_f1": 0.6224747490030372, "test_runtime": 4.1398, "test_samples_per_second": 494.71, "test_steps_per_second": 15.46}, {"test_loss": 0.9106993675231934, "test_mcc": 0.4564711642249148, "test_macro_f1": 0.6289731557131024, "test_runtime": 4.1176, "test_samples_per_second": 497.38, "test_steps_per_second": 15.543}, {"test_loss": 0.8704608678817749, "test_mcc": 0.47084139487555937, "test_macro_f1": 0.649817129067267, "test_runtime": 4.1701, "test_samples_per_second": 491.12, "test_steps_per_second": 15.348}, {"test_loss": 0.8886626958847046, "test_mcc": 0.4914275308354232, "test_macro_f1": 0.6625998501666645, "test_runtime": 4.0884, "test_samples_per_second": 500.926, "test_steps_per_second": 15.654}, {"test_loss": 0.8548339009284973, "test_mcc": 0.5026231162214001, "test_macro_f1": 0.6666360677638704, "test_runtime": 4.1957, "test_samples_per_second": 488.121, "test_steps_per_second": 15.254}, {"test_loss": 0.8656649589538574, "test_mcc": 0.48658849609223204, "test_macro_f1": 0.6616216948815077, "test_runtime": 4.179, "test_samples_per_second": 490.066, "test_steps_per_second": 15.315}, {"test_loss": 0.8292018175125122, "test_mcc": 0.4967116322476511, "test_macro_f1": 0.6668640695972446, "test_runtime": 4.0578, "test_samples_per_second": 504.702, "test_steps_per_second": 15.772}]}, "total": {"test_mcc": 47.60901333789834, "test_mcc_se": 1.395543526999615, "test_macro_f1": 65.02012136919295, "test_macro_f1_se": 1.0648375998150925}}, "num_model_parameters": 124448259, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.8540896773338318, "test_mcc": 0.5614891574693615, "test_macro_f1": 0.6963565913155568, "test_runtime": 3.3404, "test_samples_per_second": 613.092, "test_steps_per_second": 19.159}, {"test_loss": 0.7740040421485901, "test_mcc": 0.5214431030498472, "test_macro_f1": 0.6228270863606217, "test_runtime": 3.1497, "test_samples_per_second": 650.215, "test_steps_per_second": 20.319}, {"test_loss": 0.777366042137146, "test_mcc": 0.4860652383738535, "test_macro_f1": 0.6044027336706312, "test_runtime": 3.1987, "test_samples_per_second": 640.268, "test_steps_per_second": 20.008}, {"test_loss": 0.7450740933418274, "test_mcc": 0.5435809981699242, "test_macro_f1": 0.6812717458459336, "test_runtime": 3.231, "test_samples_per_second": 633.865, "test_steps_per_second": 19.808}, {"test_loss": 0.8833751082420349, "test_mcc": 0.4348636033469183, "test_macro_f1": 0.47752344664767293, "test_runtime": 3.2589, "test_samples_per_second": 628.432, "test_steps_per_second": 19.639}, {"test_loss": 0.8561118245124817, "test_mcc": 0.44710145041948646, "test_macro_f1": 0.4834638077268279, "test_runtime": 3.3715, "test_samples_per_second": 607.439, "test_steps_per_second": 18.982}, {"test_loss": 0.8133945465087891, "test_mcc": 0.4582366014413677, "test_macro_f1": 0.5103442715934636, "test_runtime": 3.2231, "test_samples_per_second": 635.416, "test_steps_per_second": 19.857}, {"test_loss": 0.8874830007553101, "test_mcc": 0.5218152829240374, "test_macro_f1": 0.6510836278864655, "test_runtime": 3.2572, "test_samples_per_second": 628.755, "test_steps_per_second": 19.649}, {"test_loss": 0.7539317607879639, "test_mcc": 0.45462077465198053, "test_macro_f1": 0.5583437931604679, "test_runtime": 3.3632, "test_samples_per_second": 608.949, "test_steps_per_second": 19.03}, {"test_loss": 0.8297734260559082, "test_mcc": 0.40914949291341635, "test_macro_f1": 0.467764433543846, "test_runtime": 3.3526, "test_samples_per_second": 610.864, "test_steps_per_second": 19.089}]}, "total": {"test_mcc": 48.38365702760193, "test_mcc_se": 3.1533621153120417, "test_macro_f1": 57.53381537751488, "test_macro_f1_se": 5.419062068257931}}, "num_model_parameters": 124448259, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.052533626556396484, "test_micro_f1": 0.746987951807229, "test_micro_f1_no_misc": 0.8126463700234192, "test_runtime": 6.6317, "test_samples_per_second": 308.818, "test_steps_per_second": 9.651}, {"test_loss": 0.0540371872484684, "test_micro_f1": 0.7448648648648648, "test_micro_f1_no_misc": 0.8021390374331552, "test_runtime": 6.088, "test_samples_per_second": 336.402, "test_steps_per_second": 10.513}, {"test_loss": 0.046655964106321335, "test_micro_f1": 0.7317784256559766, "test_micro_f1_no_misc": 0.7973273942093542, "test_runtime": 6.1424, "test_samples_per_second": 333.418, "test_steps_per_second": 10.419}, {"test_loss": 0.04786151275038719, "test_micro_f1": 0.7509727626459144, "test_micro_f1_no_misc": 0.804432132963989, "test_runtime": 6.5918, "test_samples_per_second": 310.69, "test_steps_per_second": 9.709}, {"test_loss": 0.059222958981990814, "test_micro_f1": 0.7604961832061069, "test_micro_f1_no_misc": 0.8155759870200109, "test_runtime": 6.6193, "test_samples_per_second": 309.396, "test_steps_per_second": 9.669}, {"test_loss": 0.05002523586153984, "test_micro_f1": 0.7304429783223374, "test_micro_f1_no_misc": 0.804416403785489, "test_runtime": 5.6024, "test_samples_per_second": 365.559, "test_steps_per_second": 11.424}, {"test_loss": 0.06102742254734039, "test_micro_f1": 0.7357107962872496, "test_micro_f1_no_misc": 0.8004471771939632, "test_runtime": 5.7268, "test_samples_per_second": 357.614, "test_steps_per_second": 11.175}, {"test_loss": 0.04978146031498909, "test_micro_f1": 0.714440825190011, "test_micro_f1_no_misc": 0.7876884422110553, "test_runtime": 6.5, "test_samples_per_second": 315.077, "test_steps_per_second": 9.846}, {"test_loss": 0.046294063329696655, "test_micro_f1": 0.7532097004279601, "test_micro_f1_no_misc": 0.8043933054393304, "test_runtime": 6.3571, "test_samples_per_second": 322.161, "test_steps_per_second": 10.068}, {"test_loss": 0.050416622310876846, "test_micro_f1": 0.7565691621219633, "test_micro_f1_no_misc": 0.8156301596037423, "test_runtime": 6.4884, "test_samples_per_second": 315.641, "test_steps_per_second": 9.864}]}, "total": {"test_micro_f1": 74.25473650529612, "test_micro_f1_se": 0.8832659995731906, "test_micro_f1_no_misc": 80.44696409883508, "test_micro_f1_no_misc_se": 0.5343808647529982}}, "num_model_parameters": 123862281, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.05425475537776947, "test_micro_f1": 0.8355416991426345, "test_micro_f1_no_misc": 0.8608573436401967, "test_runtime": 7.2095, "test_samples_per_second": 284.069, "test_steps_per_second": 8.877}, {"test_loss": 0.05438031628727913, "test_micro_f1": 0.8351831298557159, "test_micro_f1_no_misc": 0.8454444854297308, "test_runtime": 6.1213, "test_samples_per_second": 334.568, "test_steps_per_second": 10.455}, {"test_loss": 0.052501749247312546, "test_micro_f1": 0.8424437299035369, "test_micro_f1_no_misc": 0.868840579710145, "test_runtime": 6.9991, "test_samples_per_second": 292.61, "test_steps_per_second": 9.144}, {"test_loss": 0.061284247785806656, "test_micro_f1": 0.8491794738213075, "test_micro_f1_no_misc": 0.8635553972212326, "test_runtime": 6.8794, "test_samples_per_second": 297.701, "test_steps_per_second": 9.303}, {"test_loss": 0.06929920613765717, "test_micro_f1": 0.8032786885245903, "test_micro_f1_no_misc": 0.8177641653905053, "test_runtime": 7.1946, "test_samples_per_second": 284.658, "test_steps_per_second": 8.896}, {"test_loss": 0.060067322105169296, "test_micro_f1": 0.8221621621621622, "test_micro_f1_no_misc": 0.8303571428571428, "test_runtime": 7.0236, "test_samples_per_second": 291.59, "test_steps_per_second": 9.112}, {"test_loss": 0.05872173607349396, "test_micro_f1": 0.8024300052826202, "test_micro_f1_no_misc": 0.818848167539267, "test_runtime": 7.2038, "test_samples_per_second": 284.293, "test_steps_per_second": 8.884}, {"test_loss": 0.05347893387079239, "test_micro_f1": 0.8359116022099448, "test_micro_f1_no_misc": 0.8502594514455152, "test_runtime": 7.1516, "test_samples_per_second": 286.368, "test_steps_per_second": 8.949}, {"test_loss": 0.059116728603839874, "test_micro_f1": 0.8168264110756124, "test_micro_f1_no_misc": 0.8286238532110091, "test_runtime": 6.9638, "test_samples_per_second": 294.093, "test_steps_per_second": 9.19}, {"test_loss": 0.05270574986934662, "test_micro_f1": 0.852202107538503, "test_micro_f1_no_misc": 0.8707635009310987, "test_runtime": 6.5428, "test_samples_per_second": 313.017, "test_steps_per_second": 9.782}]}, "total": {"test_micro_f1": 82.95159009516627, "test_micro_f1_se": 1.0961444423040523, "test_micro_f1_no_misc": 84.55314087375842, "test_micro_f1_no_misc_se": 1.2670667325420468}}, "num_model_parameters": 123862281, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.034875087440013885, "test_micro_f1": 0.8937269372693727, "test_micro_f1_no_misc": 0.9227574750830566, "test_runtime": 5.4548, "test_samples_per_second": 375.452, "test_steps_per_second": 11.733}, {"test_loss": 0.0329875648021698, "test_micro_f1": 0.8916292974588939, "test_micro_f1_no_misc": 0.915043514297555, "test_runtime": 5.4325, "test_samples_per_second": 376.99, "test_steps_per_second": 11.781}, {"test_loss": 0.03585762530565262, "test_micro_f1": 0.8757608306480487, "test_micro_f1_no_misc": 0.902633679169992, "test_runtime": 5.105, "test_samples_per_second": 401.177, "test_steps_per_second": 12.537}, {"test_loss": 0.034623462706804276, "test_micro_f1": 0.8844256518675123, "test_micro_f1_no_misc": 0.9136291600633916, "test_runtime": 5.0644, "test_samples_per_second": 404.394, "test_steps_per_second": 12.637}, {"test_loss": 0.03328223526477814, "test_micro_f1": 0.8802171700033933, "test_micro_f1_no_misc": 0.9091586001489204, "test_runtime": 5.4591, "test_samples_per_second": 375.151, "test_steps_per_second": 11.723}, {"test_loss": 0.027720514684915543, "test_micro_f1": 0.8951336531871144, "test_micro_f1_no_misc": 0.9196802436239057, "test_runtime": 5.4494, "test_samples_per_second": 375.821, "test_steps_per_second": 11.744}, {"test_loss": 0.028451798483729362, "test_micro_f1": 0.8908901974367855, "test_micro_f1_no_misc": 0.9205734211545912, "test_runtime": 5.0338, "test_samples_per_second": 406.847, "test_steps_per_second": 12.714}, {"test_loss": 0.02887631580233574, "test_micro_f1": 0.9066296424852481, "test_micro_f1_no_misc": 0.9220338983050848, "test_runtime": 4.9645, "test_samples_per_second": 412.53, "test_steps_per_second": 12.892}, {"test_loss": 0.03705887869000435, "test_micro_f1": 0.8561020036429873, "test_micro_f1_no_misc": 0.8866148178469094, "test_runtime": 5.031, "test_samples_per_second": 407.077, "test_steps_per_second": 12.721}, {"test_loss": 0.034891895949840546, "test_micro_f1": 0.8990318118948825, "test_micro_f1_no_misc": 0.9232558139534883, "test_runtime": 5.3546, "test_samples_per_second": 382.473, "test_steps_per_second": 11.952}]}, "total": {"test_micro_f1": 88.73547195894238, "test_micro_f1_se": 0.8790770043773708, "test_micro_f1_no_misc": 91.35380623646896, "test_micro_f1_no_misc_se": 0.7168990677264059}}, "num_model_parameters": 123862281, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.04293625429272652, "test_micro_f1": 0.8564325668116842, "test_micro_f1_no_misc": 0.8834096512856641, "test_runtime": 5.2535, "test_samples_per_second": 389.833, "test_steps_per_second": 12.182}, {"test_loss": 0.04391992464661598, "test_micro_f1": 0.7906558849955077, "test_micro_f1_no_misc": 0.8309905197777051, "test_runtime": 5.3204, "test_samples_per_second": 384.936, "test_steps_per_second": 12.029}, {"test_loss": 0.04866369068622589, "test_micro_f1": 0.8115326251896814, "test_micro_f1_no_misc": 0.8536096256684492, "test_runtime": 5.185, "test_samples_per_second": 394.988, "test_steps_per_second": 12.343}, {"test_loss": 0.05301839858293533, "test_micro_f1": 0.8277727682596934, "test_micro_f1_no_misc": 0.857623695725345, "test_runtime": 5.2725, "test_samples_per_second": 388.434, "test_steps_per_second": 12.139}, {"test_loss": 0.056965310126543045, "test_micro_f1": 0.7874015748031497, "test_micro_f1_no_misc": 0.830344827586207, "test_runtime": 5.1802, "test_samples_per_second": 395.351, "test_steps_per_second": 12.355}, {"test_loss": 0.0479113906621933, "test_micro_f1": 0.8203753351206435, "test_micro_f1_no_misc": 0.8598068598068598, "test_runtime": 5.2344, "test_samples_per_second": 391.255, "test_steps_per_second": 12.227}, {"test_loss": 0.04682562127709389, "test_micro_f1": 0.8290441176470588, "test_micro_f1_no_misc": 0.8642735042735042, "test_runtime": 5.4013, "test_samples_per_second": 379.169, "test_steps_per_second": 11.849}, {"test_loss": 0.0447414368391037, "test_micro_f1": 0.7788898999090083, "test_micro_f1_no_misc": 0.8209054593874834, "test_runtime": 5.4514, "test_samples_per_second": 375.682, "test_steps_per_second": 11.74}, {"test_loss": 0.05242745578289032, "test_micro_f1": 0.786915316416998, "test_micro_f1_no_misc": 0.815514333895447, "test_runtime": 4.9719, "test_samples_per_second": 411.918, "test_steps_per_second": 12.872}, {"test_loss": 0.040084972977638245, "test_micro_f1": 0.8287292817679557, "test_micro_f1_no_misc": 0.8611388611388611, "test_runtime": 5.097, "test_samples_per_second": 401.807, "test_steps_per_second": 12.556}]}, "total": {"test_micro_f1": 81.1774937092138, "test_micro_f1_se": 1.5528780951019396, "test_micro_f1_no_misc": 84.77617338545525, "test_micro_f1_no_misc_se": 1.3618008647945594}}, "num_model_parameters": 123862281, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.3898777961730957, "test_mcc": 0.703260129570426, "test_macro_f1": 0.8490346747050206, "test_runtime": 3.0667, "test_samples_per_second": 667.823, "test_steps_per_second": 20.869}, {"test_loss": 0.46598488092422485, "test_mcc": 0.690035744106696, "test_macro_f1": 0.8324503418339113, "test_runtime": 3.1451, "test_samples_per_second": 651.166, "test_steps_per_second": 20.349}, {"test_loss": 0.472226619720459, "test_mcc": 0.6205869569590502, "test_macro_f1": 0.7776491024898669, "test_runtime": 3.1569, "test_samples_per_second": 648.728, "test_steps_per_second": 20.273}, {"test_loss": 0.42593562602996826, "test_mcc": 0.6649887753914133, "test_macro_f1": 0.8307633827491034, "test_runtime": 3.116, "test_samples_per_second": 657.248, "test_steps_per_second": 20.539}, {"test_loss": 0.37342575192451477, "test_mcc": 0.7080675774050826, "test_macro_f1": 0.8489437116299475, "test_runtime": 3.156, "test_samples_per_second": 648.924, "test_steps_per_second": 20.279}, {"test_loss": 0.41297560930252075, "test_mcc": 0.7195764215976966, "test_macro_f1": 0.858753059122958, "test_runtime": 3.0963, "test_samples_per_second": 661.443, "test_steps_per_second": 20.67}, {"test_loss": 0.49658840894699097, "test_mcc": 0.5968820603331747, "test_macro_f1": 0.7878751663200836, "test_runtime": 3.1052, "test_samples_per_second": 659.534, "test_steps_per_second": 20.61}, {"test_loss": 0.4313879609107971, "test_mcc": 0.6779022269962199, "test_macro_f1": 0.8372175676440128, "test_runtime": 3.1567, "test_samples_per_second": 648.769, "test_steps_per_second": 20.274}, {"test_loss": 0.43547573685646057, "test_mcc": 0.6367921096019955, "test_macro_f1": 0.7938320147804254, "test_runtime": 3.1299, "test_samples_per_second": 654.333, "test_steps_per_second": 20.448}, {"test_loss": 0.40009987354278564, "test_mcc": 0.7209611267121321, "test_macro_f1": 0.8482990415181291, "test_runtime": 3.1479, "test_samples_per_second": 650.598, "test_steps_per_second": 20.331}]}, "total": {"test_mcc": 67.39053128673888, "test_mcc_se": 2.680845245817655, "test_macro_f1": 82.64818062793458, "test_macro_f1_se": 1.8059581007648224}}, "num_model_parameters": 124447490, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.5081484317779541, "test_mcc": 0.5729684978210182, "test_macro_f1": 0.7773669975562549, "test_runtime": 3.4808, "test_samples_per_second": 588.368, "test_steps_per_second": 18.387}, {"test_loss": 0.4477061629295349, "test_mcc": 0.7060922908499441, "test_macro_f1": 0.8448257176206329, "test_runtime": 3.6105, "test_samples_per_second": 567.237, "test_steps_per_second": 17.726}, {"test_loss": 0.6749442219734192, "test_mcc": 0.3154249691543793, "test_macro_f1": 0.6338461538461538, "test_runtime": 3.4726, "test_samples_per_second": 589.753, "test_steps_per_second": 18.43}, {"test_loss": 0.5354505777359009, "test_mcc": 0.5896549737875204, "test_macro_f1": 0.7770522533781146, "test_runtime": 3.6585, "test_samples_per_second": 559.789, "test_steps_per_second": 17.493}, {"test_loss": 0.45243221521377563, "test_mcc": 0.6917539126165589, "test_macro_f1": 0.8362980618755267, "test_runtime": 3.4563, "test_samples_per_second": 592.542, "test_steps_per_second": 18.517}, {"test_loss": 0.5319144129753113, "test_mcc": 0.5816214539798852, "test_macro_f1": 0.7789578742740446, "test_runtime": 3.4973, "test_samples_per_second": 585.6, "test_steps_per_second": 18.3}, {"test_loss": 0.40681666135787964, "test_mcc": 0.6800650736480887, "test_macro_f1": 0.8393352051552598, "test_runtime": 3.4025, "test_samples_per_second": 601.905, "test_steps_per_second": 18.81}, {"test_loss": 0.41782936453819275, "test_mcc": 0.6588543729021903, "test_macro_f1": 0.8202229366750056, "test_runtime": 3.468, "test_samples_per_second": 590.534, "test_steps_per_second": 18.454}, {"test_loss": 0.39389729499816895, "test_mcc": 0.704911882572537, "test_macro_f1": 0.8511485568922976, "test_runtime": 3.4831, "test_samples_per_second": 587.98, "test_steps_per_second": 18.374}, {"test_loss": 0.40959224104881287, "test_mcc": 0.6494103599865849, "test_macro_f1": 0.8247049833641493, "test_runtime": 3.584, "test_samples_per_second": 571.424, "test_steps_per_second": 17.857}]}, "total": {"test_mcc": 61.50757787318707, "test_mcc_se": 7.2423449705753455, "test_macro_f1": 79.83758740637441, "test_macro_f1_se": 4.004670954093891}}, "num_model_parameters": 124447490, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.43927621841430664, "test_mcc": 0.6609283374658979, "test_macro_f1": 0.8161127863237407, "test_runtime": 2.9229, "test_samples_per_second": 700.665, "test_steps_per_second": 21.896}, {"test_loss": 0.38342154026031494, "test_mcc": 0.7149956748416036, "test_macro_f1": 0.8479067201978459, "test_runtime": 2.9618, "test_samples_per_second": 691.461, "test_steps_per_second": 21.608}, {"test_loss": 0.4986947178840637, "test_mcc": 0.7027948363134756, "test_macro_f1": 0.8392632515003906, "test_runtime": 2.97, "test_samples_per_second": 689.555, "test_steps_per_second": 21.549}, {"test_loss": 0.45982062816619873, "test_mcc": 0.6209117086806843, "test_macro_f1": 0.789505857130417, "test_runtime": 3.0581, "test_samples_per_second": 669.691, "test_steps_per_second": 20.928}, {"test_loss": 0.3718363046646118, "test_mcc": 0.7213840548974718, "test_macro_f1": 0.8495648778526501, "test_runtime": 3.0462, "test_samples_per_second": 672.312, "test_steps_per_second": 21.01}, {"test_loss": 0.37290874123573303, "test_mcc": 0.7034865303785942, "test_macro_f1": 0.8464702693767083, "test_runtime": 2.9008, "test_samples_per_second": 706.02, "test_steps_per_second": 22.063}, {"test_loss": 0.42240777611732483, "test_mcc": 0.7052567901204237, "test_macro_f1": 0.8521578166353053, "test_runtime": 2.9285, "test_samples_per_second": 699.329, "test_steps_per_second": 21.854}, {"test_loss": 0.4378243088722229, "test_mcc": 0.6840569294481045, "test_macro_f1": 0.8339868082663051, "test_runtime": 2.9549, "test_samples_per_second": 693.084, "test_steps_per_second": 21.659}, {"test_loss": 0.3907936215400696, "test_mcc": 0.7290641833459134, "test_macro_f1": 0.8603198633630706, "test_runtime": 2.9716, "test_samples_per_second": 689.189, "test_steps_per_second": 21.537}, {"test_loss": 0.6905275583267212, "test_mcc": 0.0, "test_macro_f1": 0.3380736910148675, "test_runtime": 2.9751, "test_samples_per_second": 688.376, "test_steps_per_second": 21.512}]}, "total": {"test_mcc": 62.4287904549217, "test_mcc_se": 13.7400053500424, "test_macro_f1": 78.733619416613, "test_macro_f1_se": 9.867470297302908}}, "num_model_parameters": 124447490, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_loss": 0.5481298565864563, "test_mcc": 0.5527213162922084, "test_macro_f1": 0.7566920765545729, "test_runtime": 3.1831, "test_samples_per_second": 643.399, "test_steps_per_second": 20.106}, {"test_loss": 0.37550652027130127, "test_mcc": 0.724446891866397, "test_macro_f1": 0.8584558063007963, "test_runtime": 3.231, "test_samples_per_second": 633.865, "test_steps_per_second": 19.808}, {"test_loss": 0.4100179672241211, "test_mcc": 0.6784574825641978, "test_macro_f1": 0.8241824758678691, "test_runtime": 3.1715, "test_samples_per_second": 645.741, "test_steps_per_second": 20.179}, {"test_loss": 0.42773494124412537, "test_mcc": 0.6671633749480095, "test_macro_f1": 0.8329320312726143, "test_runtime": 3.0109, "test_samples_per_second": 680.195, "test_steps_per_second": 21.256}, {"test_loss": 0.3945156931877136, "test_mcc": 0.7046008206743894, "test_macro_f1": 0.8448373309825012, "test_runtime": 3.0932, "test_samples_per_second": 662.105, "test_steps_per_second": 20.691}, {"test_loss": 0.4520661234855652, "test_mcc": 0.6560601640304675, "test_macro_f1": 0.8144989009289636, "test_runtime": 3.2085, "test_samples_per_second": 638.296, "test_steps_per_second": 19.947}, {"test_loss": 0.4235547184944153, "test_mcc": 0.6601052562184272, "test_macro_f1": 0.8189148954265419, "test_runtime": 3.1651, "test_samples_per_second": 647.062, "test_steps_per_second": 20.221}, {"test_loss": 0.4389244318008423, "test_mcc": 0.6712987096749344, "test_macro_f1": 0.8294897172782495, "test_runtime": 3.1079, "test_samples_per_second": 658.968, "test_steps_per_second": 20.593}, {"test_loss": 0.425411581993103, "test_mcc": 0.6410702790834286, "test_macro_f1": 0.8116298264160224, "test_runtime": 3.089, "test_samples_per_second": 663.002, "test_steps_per_second": 20.719}, {"test_loss": 0.37905141711235046, "test_mcc": 0.7217001090746795, "test_macro_f1": 0.8586956834222138, "test_runtime": 3.2093, "test_samples_per_second": 638.153, "test_steps_per_second": 19.942}]}, "total": {"test_mcc": 66.77624404427138, "test_mcc_se": 3.0468892490155994, "test_macro_f1": 82.50328744450344, "test_macro_f1_se": 1.8157469224208627}}, "num_model_parameters": 124447490, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_em": 35.16653756777692, "test_f1": 39.102130829053}, {"test_em": 42.01550387596899, "test_f1": 46.23858670003101}, {"test_em": 34.54404945904173, "test_f1": 38.954925520785416}, {"test_em": 28.81619937694704, "test_f1": 32.76136164292959}, {"test_em": 35.5984555984556, "test_f1": 38.73710974826809}, {"test_em": 31.61141094834233, "test_f1": 35.37061993830531}, {"test_em": 26.80334092634776, "test_f1": 31.7811140198483}, {"test_em": 28.161365399534525, "test_f1": 31.584717946124428}, {"test_em": 31.529411764705884, "test_f1": 35.955756194442074}, {"test_em": 42.08074534161491, "test_f1": 45.66282551023216}]}, "total": {"test_em": 33.63270202587357, "test_em_se": 3.311904088422934, "test_f1": 37.61491480500194, "test_f1_se": 3.2413926700545344}}, "num_model_parameters": 123856898, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_em": 38.49728892331526, "test_f1": 43.77302030566777}, {"test_em": 35.58139534883721, "test_f1": 39.876591975609195}, {"test_em": 38.09891808346213, "test_f1": 42.59247952283913}, {"test_em": 39.25233644859813, "test_f1": 43.68675385278556}, {"test_em": 38.61003861003861, "test_f1": 42.931013710314915}, {"test_em": 35.851966075558984, "test_f1": 41.01480674196707}, {"test_em": 39.63553530751708, "test_f1": 44.64881673068802}, {"test_em": 38.86733902249806, "test_f1": 42.982308493885064}, {"test_em": 36.15686274509804, "test_f1": 40.63035195242445}, {"test_em": 45.108695652173914, "test_f1": 49.58764760538216}]}, "total": {"test_em": 38.56603762170974, "test_em_se": 1.6887781874936911, "test_f1": 43.17237908915634, "test_f1_se": 1.6831518965029997}}, "num_model_parameters": 123856898, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_em": 44.61657629744384, "test_f1": 49.60917458397633}, {"test_em": 37.51937984496124, "test_f1": 42.58811384101871}, {"test_em": 35.239567233384854, "test_f1": 39.710513065612126}, {"test_em": 43.30218068535826, "test_f1": 47.43642843754586}, {"test_em": 34.5945945945946, "test_f1": 39.44818049439899}, {"test_em": 42.63685427910563, "test_f1": 47.39031049014555}, {"test_em": 43.05239179954442, "test_f1": 47.76256296780818}, {"test_em": 40.49650892164468, "test_f1": 45.091943304172474}, {"test_em": 41.80392156862745, "test_f1": 46.06579436307213}, {"test_em": 45.88509316770186, "test_f1": 50.04968404459177}]}, "total": {"test_em": 40.91470683923669, "test_em_se": 2.411932567595042, "test_f1": 45.51527055923422, "test_f1_se": 2.3477605976813916}}, "num_model_parameters": 123856898, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.5043877363204956, "test_mcc": 0.6916443917914769, "test_macro_f1": 0.645902403844526, "test_runtime": 14.7542, "test_samples_per_second": 138.808, "test_steps_per_second": 17.351}, {"test_loss": 0.5095164179801941, "test_mcc": 0.6500339596181286, "test_macro_f1": 0.6168883136493556, "test_runtime": 14.103, "test_samples_per_second": 145.218, "test_steps_per_second": 18.152}, {"test_loss": 0.5455628037452698, "test_mcc": 0.6649129203023597, "test_macro_f1": 0.6136751729851434, "test_runtime": 14.4528, "test_samples_per_second": 141.702, "test_steps_per_second": 17.713}, {"test_loss": 0.5246076583862305, "test_mcc": 0.674252662991675, "test_macro_f1": 0.7038078249913245, "test_runtime": 13.8914, "test_samples_per_second": 147.43, "test_steps_per_second": 18.429}, {"test_loss": 0.5201155543327332, "test_mcc": 0.6807310870147648, "test_macro_f1": 0.6879924337886689, "test_runtime": 13.7041, "test_samples_per_second": 149.444, "test_steps_per_second": 18.681}, {"test_loss": 0.5370044708251953, "test_mcc": 0.6548698131354077, "test_macro_f1": 0.6349484705194315, "test_runtime": 14.152, "test_samples_per_second": 144.715, "test_steps_per_second": 18.089}, {"test_loss": 0.4911099672317505, "test_mcc": 0.6526886959510918, "test_macro_f1": 0.6518872939925572, "test_runtime": 13.6048, "test_samples_per_second": 150.535, "test_steps_per_second": 18.817}, {"test_loss": 0.5485337376594543, "test_mcc": 0.6579922177426694, "test_macro_f1": 0.6773779723413554, "test_runtime": 14.7158, "test_samples_per_second": 139.171, "test_steps_per_second": 17.396}, {"test_loss": 0.549136221408844, "test_mcc": 0.664980554981456, "test_macro_f1": 0.6263089830896056, "test_runtime": 14.5157, "test_samples_per_second": 141.089, "test_steps_per_second": 17.636}, {"test_loss": 0.5089681148529053, "test_mcc": 0.6830859088844311, "test_macro_f1": 0.6954542732580196, "test_runtime": 14.1833, "test_samples_per_second": 144.395, "test_steps_per_second": 18.049}]}, "total": {"test_mcc": 66.75192212413461, "test_mcc_se": 0.8847605043876211, "test_macro_f1": 65.54243142459988, "test_macro_f1_se": 2.074697147134215}}, "num_model_parameters": 124523523, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.8985486030578613, "test_mcc": 0.4040989233926668, "test_macro_f1": 0.6031417233039748, "test_runtime": 4.4065, "test_samples_per_second": 464.767, "test_steps_per_second": 14.524}, {"test_loss": 0.8972108364105225, "test_mcc": 0.40574370492406364, "test_macro_f1": 0.5940040607409619, "test_runtime": 4.3809, "test_samples_per_second": 467.479, "test_steps_per_second": 14.609}, {"test_loss": 0.8978711366653442, "test_mcc": 0.40793433532983897, "test_macro_f1": 0.6058548163493146, "test_runtime": 4.3682, "test_samples_per_second": 468.841, "test_steps_per_second": 14.651}, {"test_loss": 0.9274897575378418, "test_mcc": 0.37938787630635445, "test_macro_f1": 0.5860506962634009, "test_runtime": 4.3485, "test_samples_per_second": 470.967, "test_steps_per_second": 14.718}, {"test_loss": 0.8794248104095459, "test_mcc": 0.39188837349211186, "test_macro_f1": 0.5985253246540676, "test_runtime": 4.3974, "test_samples_per_second": 465.734, "test_steps_per_second": 14.554}, {"test_loss": 0.938705325126648, "test_mcc": 0.38624092430350215, "test_macro_f1": 0.5858537247809266, "test_runtime": 4.3283, "test_samples_per_second": 473.162, "test_steps_per_second": 14.786}, {"test_loss": 0.9127233028411865, "test_mcc": 0.3962925885132415, "test_macro_f1": 0.5924605147813058, "test_runtime": 4.3329, "test_samples_per_second": 472.667, "test_steps_per_second": 14.771}, {"test_loss": 0.962467610836029, "test_mcc": 0.37637397259943867, "test_macro_f1": 0.5763707531879759, "test_runtime": 4.2994, "test_samples_per_second": 476.347, "test_steps_per_second": 14.886}, {"test_loss": 0.8833483457565308, "test_mcc": 0.40491317210089267, "test_macro_f1": 0.6045225585168035, "test_runtime": 4.288, "test_samples_per_second": 477.613, "test_steps_per_second": 14.925}, {"test_loss": 0.9240673780441284, "test_mcc": 0.3899069721971703, "test_macro_f1": 0.5958640337788986, "test_runtime": 4.3615, "test_samples_per_second": 469.565, "test_steps_per_second": 14.674}]}, "total": {"test_mcc": 39.42780843159281, "test_mcc_se": 0.704647982882353, "test_macro_f1": 59.4264820635763, "test_macro_f1_se": 0.5846502931769052}}, "num_model_parameters": 124523523, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.6327028274536133, "test_mcc": 0.590819886585775, "test_macro_f1": 0.7132074160814432, "test_runtime": 3.2402, "test_samples_per_second": 632.054, "test_steps_per_second": 19.752}, {"test_loss": 0.6616007089614868, "test_mcc": 0.5843780296535828, "test_macro_f1": 0.7039614464764167, "test_runtime": 3.0185, "test_samples_per_second": 678.482, "test_steps_per_second": 21.203}, {"test_loss": 0.6766276359558105, "test_mcc": 0.5355499686394238, "test_macro_f1": 0.6510677647644926, "test_runtime": 3.0912, "test_samples_per_second": 662.536, "test_steps_per_second": 20.704}, {"test_loss": 0.6755083799362183, "test_mcc": 0.6073085157945094, "test_macro_f1": 0.7228529625975262, "test_runtime": 3.1373, "test_samples_per_second": 652.784, "test_steps_per_second": 20.4}, {"test_loss": 0.6736558079719543, "test_mcc": 0.5979987467297487, "test_macro_f1": 0.714127399187388, "test_runtime": 3.1875, "test_samples_per_second": 642.509, "test_steps_per_second": 20.078}, {"test_loss": 0.674370288848877, "test_mcc": 0.5976483862640142, "test_macro_f1": 0.7221153798969092, "test_runtime": 3.2706, "test_samples_per_second": 626.186, "test_steps_per_second": 19.568}, {"test_loss": 0.6237615942955017, "test_mcc": 0.5921109164491823, "test_macro_f1": 0.7141908335509636, "test_runtime": 3.097, "test_samples_per_second": 661.281, "test_steps_per_second": 20.665}, {"test_loss": 0.6866145133972168, "test_mcc": 0.5708088484027255, "test_macro_f1": 0.6886590629825982, "test_runtime": 3.1772, "test_samples_per_second": 644.595, "test_steps_per_second": 20.144}, {"test_loss": 0.649295449256897, "test_mcc": 0.6037249564590216, "test_macro_f1": 0.7322338751249781, "test_runtime": 3.2599, "test_samples_per_second": 628.249, "test_steps_per_second": 19.633}, {"test_loss": 0.6635257005691528, "test_mcc": 0.6309725702630078, "test_macro_f1": 0.7409657221214747, "test_runtime": 3.2585, "test_samples_per_second": 628.514, "test_steps_per_second": 19.641}]}, "total": {"test_mcc": 59.11320825240992, "test_mcc_se": 1.5524351077430598, "test_macro_f1": 71.0338186278419, "test_macro_f1_se": 1.5698843641302034}}, "num_model_parameters": 124523523, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.09354129433631897, "test_micro_f1": 0.589881593110872, "test_micro_f1_no_misc": 0.6521212121212121, "test_runtime": 6.9283, "test_samples_per_second": 295.597, "test_steps_per_second": 9.237}, {"test_loss": 0.08405517786741257, "test_micro_f1": 0.5818181818181818, "test_micro_f1_no_misc": 0.6467532467532469, "test_runtime": 6.7275, "test_samples_per_second": 304.422, "test_steps_per_second": 9.513}, {"test_loss": 0.08076318353414536, "test_micro_f1": 0.6172839506172838, "test_micro_f1_no_misc": 0.6740654205607477, "test_runtime": 6.4295, "test_samples_per_second": 318.534, "test_steps_per_second": 9.954}, {"test_loss": 0.08096738159656525, "test_micro_f1": 0.5953878406708595, "test_micro_f1_no_misc": 0.6438275251033668, "test_runtime": 6.8909, "test_samples_per_second": 297.202, "test_steps_per_second": 9.288}, {"test_loss": 0.08184970170259476, "test_micro_f1": 0.62729912875121, "test_micro_f1_no_misc": 0.6812366737739872, "test_runtime": 6.8175, "test_samples_per_second": 300.401, "test_steps_per_second": 9.388}, {"test_loss": 0.0791751816868782, "test_micro_f1": 0.6114039290848108, "test_micro_f1_no_misc": 0.6608884073672806, "test_runtime": 5.4742, "test_samples_per_second": 374.118, "test_steps_per_second": 11.691}, {"test_loss": 0.08632488548755646, "test_micro_f1": 0.5948026948989413, "test_micro_f1_no_misc": 0.6493787142085359, "test_runtime": 5.5341, "test_samples_per_second": 370.066, "test_steps_per_second": 11.565}, {"test_loss": 0.07078452408313751, "test_micro_f1": 0.6274738067520372, "test_micro_f1_no_misc": 0.6696600384862091, "test_runtime": 6.8001, "test_samples_per_second": 301.173, "test_steps_per_second": 9.412}, {"test_loss": 0.07852897047996521, "test_micro_f1": 0.6146616541353384, "test_micro_f1_no_misc": 0.6546610169491526, "test_runtime": 6.1946, "test_samples_per_second": 330.611, "test_steps_per_second": 10.332}, {"test_loss": 0.09507301449775696, "test_micro_f1": 0.5976562499999999, "test_micro_f1_no_misc": 0.664013644115975, "test_runtime": 6.6953, "test_samples_per_second": 305.887, "test_steps_per_second": 9.559}]}, "total": {"test_micro_f1": 60.576690298395356, "test_micro_f1_se": 0.9903911151009569, "test_micro_f1_no_misc": 65.96605899439713, "test_micro_f1_no_misc_se": 0.772568391340382}}, "num_model_parameters": 123937545, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.06045982241630554, "test_micro_f1": 0.7963152507676562, "test_micro_f1_no_misc": 0.8122866894197953, "test_runtime": 8.5141, "test_samples_per_second": 240.543, "test_steps_per_second": 7.517}, {"test_loss": 0.059230949729681015, "test_micro_f1": 0.8074361820199777, "test_micro_f1_no_misc": 0.822742474916388, "test_runtime": 6.7298, "test_samples_per_second": 304.318, "test_steps_per_second": 9.51}, {"test_loss": 0.060067035257816315, "test_micro_f1": 0.7955032119914347, "test_micro_f1_no_misc": 0.8143160878809356, "test_runtime": 8.3125, "test_samples_per_second": 246.375, "test_steps_per_second": 7.699}, {"test_loss": 0.06336455792188644, "test_micro_f1": 0.7833675564681725, "test_micro_f1_no_misc": 0.7937823834196891, "test_runtime": 8.2146, "test_samples_per_second": 249.311, "test_steps_per_second": 7.791}, {"test_loss": 0.06638926267623901, "test_micro_f1": 0.7896658242066835, "test_micro_f1_no_misc": 0.8068441064638784, "test_runtime": 8.4569, "test_samples_per_second": 242.169, "test_steps_per_second": 7.568}, {"test_loss": 0.061500340700149536, "test_micro_f1": 0.8066610217329947, "test_micro_f1_no_misc": 0.8178353658536585, "test_runtime": 8.2558, "test_samples_per_second": 248.069, "test_steps_per_second": 7.752}, {"test_loss": 0.05931546539068222, "test_micro_f1": 0.8026212319790302, "test_micro_f1_no_misc": 0.8218410920546028, "test_runtime": 8.5455, "test_samples_per_second": 239.659, "test_steps_per_second": 7.489}, {"test_loss": 0.05406409874558449, "test_micro_f1": 0.8046040010961907, "test_micro_f1_no_misc": 0.8295748613678374, "test_runtime": 8.5508, "test_samples_per_second": 239.51, "test_steps_per_second": 7.485}, {"test_loss": 0.06149521470069885, "test_micro_f1": 0.7930848190167478, "test_micro_f1_no_misc": 0.805223880597015, "test_runtime": 8.1371, "test_samples_per_second": 251.687, "test_steps_per_second": 7.865}, {"test_loss": 0.06360215693712234, "test_micro_f1": 0.802919708029197, "test_micro_f1_no_misc": 0.8153511947863867, "test_runtime": 6.8829, "test_samples_per_second": 297.549, "test_steps_per_second": 9.298}]}, "total": {"test_micro_f1": 79.82178807308087, "test_micro_f1_se": 0.49306131081330756, "test_micro_f1_no_misc": 81.39798136760186, "test_micro_f1_no_misc_se": 0.6324307268915407}}, "num_model_parameters": 123937545, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.03237110376358032, "test_micro_f1": 0.8595403137541044, "test_micro_f1_no_misc": 0.8949545078577336, "test_runtime": 5.5389, "test_samples_per_second": 369.752, "test_steps_per_second": 11.555}, {"test_loss": 0.03076220117509365, "test_micro_f1": 0.8637379002233804, "test_micro_f1_no_misc": 0.891286307053942, "test_runtime": 5.4972, "test_samples_per_second": 372.555, "test_steps_per_second": 11.642}, {"test_loss": 0.03147489205002785, "test_micro_f1": 0.8733997155049787, "test_micro_f1_no_misc": 0.9062870699881376, "test_runtime": 5.1782, "test_samples_per_second": 395.507, "test_steps_per_second": 12.36}, {"test_loss": 0.026792118325829506, "test_micro_f1": 0.878917378917379, "test_micro_f1_no_misc": 0.9046669325887515, "test_runtime": 5.1481, "test_samples_per_second": 397.815, "test_steps_per_second": 12.432}, {"test_loss": 0.03177788853645325, "test_micro_f1": 0.8819374369323916, "test_micro_f1_no_misc": 0.9103808812546678, "test_runtime": 5.5851, "test_samples_per_second": 366.689, "test_steps_per_second": 11.459}, {"test_loss": 0.029782187193632126, "test_micro_f1": 0.8732970027247956, "test_micro_f1_no_misc": 0.9072872949256009, "test_runtime": 5.5668, "test_samples_per_second": 367.895, "test_steps_per_second": 11.497}, {"test_loss": 0.02765822224318981, "test_micro_f1": 0.8801939058171746, "test_micro_f1_no_misc": 0.9043611323641928, "test_runtime": 5.1079, "test_samples_per_second": 400.945, "test_steps_per_second": 12.53}, {"test_loss": 0.030363235622644424, "test_micro_f1": 0.8814147018030513, "test_micro_f1_no_misc": 0.9054912215166231, "test_runtime": 4.9612, "test_samples_per_second": 412.8, "test_steps_per_second": 12.9}, {"test_loss": 0.03189539164304733, "test_micro_f1": 0.8629294755877035, "test_micro_f1_no_misc": 0.8936170212765958, "test_runtime": 5.11, "test_samples_per_second": 400.785, "test_steps_per_second": 12.525}, {"test_loss": 0.03534846752882004, "test_micro_f1": 0.8803301237964237, "test_micro_f1_no_misc": 0.9108910891089109, "test_runtime": 5.5561, "test_samples_per_second": 368.605, "test_steps_per_second": 11.519}]}, "total": {"test_micro_f1": 87.35697955061383, "test_micro_f1_se": 0.5293813602076645, "test_micro_f1_no_misc": 90.29223457935156, "test_micro_f1_no_misc_se": 0.43665472933134014}}, "num_model_parameters": 123937545, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.03820590674877167, "test_micro_f1": 0.8248198057035411, "test_micro_f1_no_misc": 0.8581363004172462, "test_runtime": 5.1979, "test_samples_per_second": 394.002, "test_steps_per_second": 12.313}, {"test_loss": 0.03547021746635437, "test_micro_f1": 0.8507417499243112, "test_micro_f1_no_misc": 0.8838951310861423, "test_runtime": 5.2693, "test_samples_per_second": 388.665, "test_steps_per_second": 12.146}, {"test_loss": 0.040180571377277374, "test_micro_f1": 0.8209500609013398, "test_micro_f1_no_misc": 0.8584161810078849, "test_runtime": 5.1217, "test_samples_per_second": 399.869, "test_steps_per_second": 12.496}, {"test_loss": 0.0454375296831131, "test_micro_f1": 0.8288721804511279, "test_micro_f1_no_misc": 0.8673050615595075, "test_runtime": 5.2515, "test_samples_per_second": 389.984, "test_steps_per_second": 12.187}, {"test_loss": 0.04900071397423744, "test_micro_f1": 0.8103130755064457, "test_micro_f1_no_misc": 0.8503329828250964, "test_runtime": 5.084, "test_samples_per_second": 402.832, "test_steps_per_second": 12.589}, {"test_loss": 0.03691516071557999, "test_micro_f1": 0.8448430493273542, "test_micro_f1_no_misc": 0.8833276969901929, "test_runtime": 5.2335, "test_samples_per_second": 391.322, "test_steps_per_second": 12.229}, {"test_loss": 0.03918781876564026, "test_micro_f1": 0.8247678018575851, "test_micro_f1_no_misc": 0.8673957621326042, "test_runtime": 5.298, "test_samples_per_second": 386.56, "test_steps_per_second": 12.08}, {"test_loss": 0.03829693794250488, "test_micro_f1": 0.8217913204062789, "test_micro_f1_no_misc": 0.8574338085539714, "test_runtime": 5.3225, "test_samples_per_second": 384.78, "test_steps_per_second": 12.024}, {"test_loss": 0.04680291563272476, "test_micro_f1": 0.8083255669462566, "test_micro_f1_no_misc": 0.849965588437715, "test_runtime": 4.7728, "test_samples_per_second": 429.097, "test_steps_per_second": 13.409}, {"test_loss": 0.039523154497146606, "test_micro_f1": 0.8512977099236642, "test_micro_f1_no_misc": 0.8797319932998325, "test_runtime": 5.0702, "test_samples_per_second": 403.927, "test_steps_per_second": 12.623}]}, "total": {"test_micro_f1": 82.86722320947904, "test_micro_f1_se": 0.9576674961131767, "test_micro_f1_no_misc": 86.55940506310193, "test_micro_f1_no_misc_se": 0.8018573029442928}}, "num_model_parameters": 123937545, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.6263693571090698, "test_mcc": 0.2937785949757377, "test_macro_f1": 0.6464722375875026, "test_runtime": 3.0572, "test_samples_per_second": 669.902, "test_steps_per_second": 20.934}, {"test_loss": 0.5870946645736694, "test_mcc": 0.38939504659831886, "test_macro_f1": 0.6764650814454221, "test_runtime": 3.2168, "test_samples_per_second": 636.649, "test_steps_per_second": 19.895}, {"test_loss": 0.6093283891677856, "test_mcc": 0.3271457173283779, "test_macro_f1": 0.6246895202329903, "test_runtime": 3.2529, "test_samples_per_second": 629.584, "test_steps_per_second": 19.675}, {"test_loss": 0.6352335214614868, "test_mcc": 0.31669726472783455, "test_macro_f1": 0.6576853810364136, "test_runtime": 3.1577, "test_samples_per_second": 648.575, "test_steps_per_second": 20.268}, {"test_loss": 0.6045518517494202, "test_mcc": 0.40833334295946266, "test_macro_f1": 0.6823338080354115, "test_runtime": 3.2043, "test_samples_per_second": 639.139, "test_steps_per_second": 19.973}, {"test_loss": 0.6155597567558289, "test_mcc": 0.32203897016883615, "test_macro_f1": 0.6438650582447256, "test_runtime": 3.1832, "test_samples_per_second": 643.386, "test_steps_per_second": 20.106}, {"test_loss": 0.5849834680557251, "test_mcc": 0.39621818139414045, "test_macro_f1": 0.6899100405820359, "test_runtime": 3.1849, "test_samples_per_second": 643.03, "test_steps_per_second": 20.095}, {"test_loss": 0.6147795915603638, "test_mcc": 0.3663355063423895, "test_macro_f1": 0.6506163486029257, "test_runtime": 3.1907, "test_samples_per_second": 641.87, "test_steps_per_second": 20.058}, {"test_loss": 0.6067720651626587, "test_mcc": 0.37581260022049306, "test_macro_f1": 0.6556290061086097, "test_runtime": 3.1897, "test_samples_per_second": 642.064, "test_steps_per_second": 20.065}, {"test_loss": 0.5951977372169495, "test_mcc": 0.3708657913359537, "test_macro_f1": 0.6842221840331482, "test_runtime": 3.1947, "test_samples_per_second": 641.052, "test_steps_per_second": 20.033}]}, "total": {"test_mcc": 35.66621016051544, "test_mcc_se": 2.408453696239913, "test_macro_f1": 66.11888665909184, "test_macro_f1_se": 1.3131465657390717}}, "num_model_parameters": 124522754, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.555411696434021, "test_mcc": 0.5560249879199508, "test_macro_f1": 0.7703712009143486, "test_runtime": 3.7013, "test_samples_per_second": 553.315, "test_steps_per_second": 17.291}, {"test_loss": 0.5139200687408447, "test_mcc": 0.5775031786776538, "test_macro_f1": 0.7834110953194463, "test_runtime": 3.8538, "test_samples_per_second": 531.425, "test_steps_per_second": 16.607}, {"test_loss": 0.6788836717605591, "test_mcc": 0.12574965717342662, "test_macro_f1": 0.5411001642861091, "test_runtime": 3.7653, "test_samples_per_second": 543.911, "test_steps_per_second": 16.997}, {"test_loss": 0.5648770332336426, "test_mcc": 0.5692348409629877, "test_macro_f1": 0.7698630136986302, "test_runtime": 3.9395, "test_samples_per_second": 519.86, "test_steps_per_second": 16.246}, {"test_loss": 0.4859235882759094, "test_mcc": 0.5612408146477328, "test_macro_f1": 0.7770012963426959, "test_runtime": 3.7105, "test_samples_per_second": 551.947, "test_steps_per_second": 17.248}, {"test_loss": 0.4856087267398834, "test_mcc": 0.5742461328422828, "test_macro_f1": 0.7871042991709513, "test_runtime": 3.6983, "test_samples_per_second": 553.768, "test_steps_per_second": 17.305}, {"test_loss": 0.5381925702095032, "test_mcc": 0.5488388999909807, "test_macro_f1": 0.7683861865914249, "test_runtime": 3.6436, "test_samples_per_second": 562.087, "test_steps_per_second": 17.565}, {"test_loss": 0.5906420350074768, "test_mcc": 0.5051917782638741, "test_macro_f1": 0.7413970619660195, "test_runtime": 3.6964, "test_samples_per_second": 554.054, "test_steps_per_second": 17.314}, {"test_loss": 0.5209059119224548, "test_mcc": 0.5114985976981661, "test_macro_f1": 0.753087591557543, "test_runtime": 3.7441, "test_samples_per_second": 547.001, "test_steps_per_second": 17.094}, {"test_loss": 0.590167760848999, "test_mcc": 0.5460031255432491, "test_macro_f1": 0.7655172413793103, "test_runtime": 3.8234, "test_samples_per_second": 535.653, "test_steps_per_second": 16.739}]}, "total": {"test_mcc": 50.75532013720305, "test_mcc_se": 8.451907451201647, "test_macro_f1": 74.57239151226479, "test_macro_f1_se": 4.533507172513819}}, "num_model_parameters": 124522754, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.3591737151145935, "test_mcc": 0.7190401481065467, "test_macro_f1": 0.8472196217936716, "test_runtime": 2.8764, "test_samples_per_second": 712.013, "test_steps_per_second": 22.25}, {"test_loss": 0.4147511422634125, "test_mcc": 0.680552402702104, "test_macro_f1": 0.8270695919440678, "test_runtime": 2.8831, "test_samples_per_second": 710.345, "test_steps_per_second": 22.198}, {"test_loss": 0.3565037250518799, "test_mcc": 0.7410806514607985, "test_macro_f1": 0.8601191795709966, "test_runtime": 2.9345, "test_samples_per_second": 697.914, "test_steps_per_second": 21.81}, {"test_loss": 0.3875819444656372, "test_mcc": 0.7159136187803582, "test_macro_f1": 0.8449615713480163, "test_runtime": 2.9777, "test_samples_per_second": 687.776, "test_steps_per_second": 21.493}, {"test_loss": 0.38388457894325256, "test_mcc": 0.7221373117660377, "test_macro_f1": 0.8482889512927279, "test_runtime": 2.9604, "test_samples_per_second": 691.795, "test_steps_per_second": 21.619}, {"test_loss": 0.4263758063316345, "test_mcc": 0.6557682514479132, "test_macro_f1": 0.8119088319504748, "test_runtime": 2.8312, "test_samples_per_second": 723.375, "test_steps_per_second": 22.605}, {"test_loss": 0.3864770233631134, "test_mcc": 0.7086818640910199, "test_macro_f1": 0.8437592324796691, "test_runtime": 2.8441, "test_samples_per_second": 720.075, "test_steps_per_second": 22.502}, {"test_loss": 0.40383386611938477, "test_mcc": 0.6889511673845857, "test_macro_f1": 0.827040537374053, "test_runtime": 2.875, "test_samples_per_second": 712.342, "test_steps_per_second": 22.261}, {"test_loss": 0.4283636808395386, "test_mcc": 0.6785267294563184, "test_macro_f1": 0.823727183641981, "test_runtime": 2.9055, "test_samples_per_second": 704.86, "test_steps_per_second": 22.027}, {"test_loss": 0.40523916482925415, "test_mcc": 0.6973699241296627, "test_macro_f1": 0.8392110755587611, "test_runtime": 2.9232, "test_samples_per_second": 700.613, "test_steps_per_second": 21.894}]}, "total": {"test_mcc": 70.08022069325345, "test_mcc_se": 1.5716900366563775, "test_macro_f1": 83.73305776954419, "test_macro_f1_se": 0.8964689720627854}}, "num_model_parameters": 124522754, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_loss": 0.4665471911430359, "test_mcc": 0.6510132484849387, "test_macro_f1": 0.8121441920467756, "test_runtime": 3.0597, "test_samples_per_second": 669.35, "test_steps_per_second": 20.917}, {"test_loss": 0.41471248865127563, "test_mcc": 0.6735571778708587, "test_macro_f1": 0.8264025614252744, "test_runtime": 3.1381, "test_samples_per_second": 652.616, "test_steps_per_second": 20.394}, {"test_loss": 0.44670653343200684, "test_mcc": 0.6475388409301273, "test_macro_f1": 0.808088311693356, "test_runtime": 3.1621, "test_samples_per_second": 647.674, "test_steps_per_second": 20.24}, {"test_loss": 0.4210062623023987, "test_mcc": 0.6685450726322546, "test_macro_f1": 0.825649918809415, "test_runtime": 2.9377, "test_samples_per_second": 697.143, "test_steps_per_second": 21.786}, {"test_loss": 0.3819934129714966, "test_mcc": 0.6925208594226748, "test_macro_f1": 0.844957763754929, "test_runtime": 3.0427, "test_samples_per_second": 673.084, "test_steps_per_second": 21.034}, {"test_loss": 0.41829249262809753, "test_mcc": 0.6794428691139761, "test_macro_f1": 0.8358199296663643, "test_runtime": 3.1458, "test_samples_per_second": 651.024, "test_steps_per_second": 20.345}, {"test_loss": 0.43708890676498413, "test_mcc": 0.6215977009136926, "test_macro_f1": 0.8039642710374741, "test_runtime": 3.0598, "test_samples_per_second": 669.329, "test_steps_per_second": 20.917}, {"test_loss": 0.4077926278114319, "test_mcc": 0.6627425240614723, "test_macro_f1": 0.8234606573472346, "test_runtime": 3.0694, "test_samples_per_second": 667.239, "test_steps_per_second": 20.851}, {"test_loss": 0.4046103358268738, "test_mcc": 0.6671670740451918, "test_macro_f1": 0.8321262649098731, "test_runtime": 3.042, "test_samples_per_second": 673.232, "test_steps_per_second": 21.039}, {"test_loss": 0.405392050743103, "test_mcc": 0.6731701536934317, "test_macro_f1": 0.8248985916998217, "test_runtime": 3.2153, "test_samples_per_second": 636.952, "test_steps_per_second": 19.905}]}, "total": {"test_mcc": 66.37295521168619, "test_mcc_se": 1.2216584432006687, "test_macro_f1": 82.37512462390517, "test_macro_f1_se": 0.7864791088320576}}, "num_model_parameters": 124522754, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_em": 38.41982958946553, "test_f1": 42.502525610787565}, {"test_em": 42.7906976744186, "test_f1": 47.845624464209855}, {"test_em": 43.508500772797525, "test_f1": 47.49209542688375}, {"test_em": 44.00311526479751, "test_f1": 48.14154080001296}, {"test_em": 45.945945945945944, "test_f1": 50.13349399085797}, {"test_em": 43.02235929067078, "test_f1": 49.15463055235108}, {"test_em": 39.10402429764616, "test_f1": 43.516986357102866}, {"test_em": 43.44453064391001, "test_f1": 48.04237151268592}, {"test_em": 43.6078431372549, "test_f1": 48.34323426794251}, {"test_em": 40.29503105590062, "test_f1": 45.35555318138415}]}, "total": {"test_em": 42.41418776728076, "test_em_se": 1.4695859300471001, "test_f1": 47.05280561642187, "test_f1_se": 1.5272827465895573}}, "num_model_parameters": 123932162, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_em": 44.07436096049574, "test_f1": 47.648378889423576}, {"test_em": 45.58139534883721, "test_f1": 50.309573944060254}, {"test_em": 43.585780525502315, "test_f1": 48.52200949413837}, {"test_em": 44.626168224299064, "test_f1": 49.37201380684137}, {"test_em": 39.922779922779924, "test_f1": 44.77644262936459}, {"test_em": 47.417116422513494, "test_f1": 52.56819643777031}, {"test_em": 43.12832194381169, "test_f1": 48.18970360374929}, {"test_em": 43.366951124903025, "test_f1": 48.77067421033021}, {"test_em": 44.86274509803921, "test_f1": 49.40549092678031}, {"test_em": 46.350931677018636, "test_f1": 51.895399193522486}]}, "total": {"test_em": 44.29165512482003, "test_em_se": 1.2727692738703966, "test_f1": 49.145788313598075, "test_f1_se": 1.3630040214501813}}, "num_model_parameters": 123932162, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_em": 36.793183578621225, "test_f1": 41.74835678553367}, {"test_em": 37.906976744186046, "test_f1": 42.758171041293124}, {"test_em": 36.6306027820711, "test_f1": 41.13976356350665}, {"test_em": 37.53894080996885, "test_f1": 42.99230061344512}, {"test_em": 37.76061776061776, "test_f1": 42.18724531528599}, {"test_em": 41.017733230531995, "test_f1": 44.72871984924684}, {"test_em": 38.4206529992407, "test_f1": 42.50048762918571}, {"test_em": 39.95345228859581, "test_f1": 44.648893282941316}, {"test_em": 41.254901960784316, "test_f1": 46.50563868734929}, {"test_em": 38.89751552795031, "test_f1": 43.16879698013592}]}, "total": {"test_em": 38.61745776825681, "test_em_se": 1.01838732209406, "test_f1": 43.23783737479236, "test_f1_se": 1.0005894145656498}}, "num_model_parameters": 123932162, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.5130348205566406, "test_mcc": 0.6906981857848061, "test_macro_f1": 0.5822592395494105, "test_runtime": 14.055, "test_samples_per_second": 145.713, "test_steps_per_second": 18.214}, {"test_loss": 0.45853471755981445, "test_mcc": 0.710797376380031, "test_macro_f1": 0.6788031018601478, "test_runtime": 13.2778, "test_samples_per_second": 154.242, "test_steps_per_second": 19.28}, {"test_loss": 0.48000311851501465, "test_mcc": 0.6979268422304299, "test_macro_f1": 0.6931830481560092, "test_runtime": 16.8095, "test_samples_per_second": 121.836, "test_steps_per_second": 60.918}, {"test_loss": 0.4123348593711853, "test_mcc": 0.7426670407866836, "test_macro_f1": 0.7377863289628867, "test_runtime": 16.7122, "test_samples_per_second": 122.545, "test_steps_per_second": 61.273}, {"test_loss": 0.41838711500167847, "test_mcc": 0.7180130285964866, "test_macro_f1": 0.7351318115124458, "test_runtime": 16.838, "test_samples_per_second": 121.63, "test_steps_per_second": 60.815}, {"test_loss": 0.46009770035743713, "test_mcc": 0.6870674844027184, "test_macro_f1": 0.5956077333911775, "test_runtime": 16.961, "test_samples_per_second": 120.747, "test_steps_per_second": 60.374}, {"test_loss": 0.45536598563194275, "test_mcc": 0.7060454900320539, "test_macro_f1": 0.6267478426709574, "test_runtime": 16.8663, "test_samples_per_second": 121.425, "test_steps_per_second": 60.713}, {"test_loss": 0.46848148107528687, "test_mcc": 0.6868228287422271, "test_macro_f1": 0.6743885136397871, "test_runtime": 17.055, "test_samples_per_second": 120.082, "test_steps_per_second": 60.041}, {"test_loss": 0.44189465045928955, "test_mcc": 0.709507309702327, "test_macro_f1": 0.6605127544177911, "test_runtime": 17.0026, "test_samples_per_second": 120.452, "test_steps_per_second": 60.226}, {"test_loss": 0.42214900255203247, "test_mcc": 0.7195831740272947, "test_macro_f1": 0.7186730978927575, "test_runtime": 16.9857, "test_samples_per_second": 120.572, "test_steps_per_second": 60.286}]}, "total": {"test_mcc": 70.6912876068506, "test_mcc_se": 1.0786526359494892, "test_macro_f1": 67.03093472053372, "test_macro_f1_se": 3.396885234013448}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.8538779020309448, "test_mcc": 0.4813111480989568, "test_macro_f1": 0.6541012600694752, "test_runtime": 4.1999, "test_samples_per_second": 487.632, "test_steps_per_second": 15.238}, {"test_loss": 0.7944682836532593, "test_mcc": 0.49117360726627446, "test_macro_f1": 0.662602208862575, "test_runtime": 4.1455, "test_samples_per_second": 494.029, "test_steps_per_second": 15.438}, {"test_loss": 0.9477254748344421, "test_mcc": 0.4674195539571664, "test_macro_f1": 0.6448296655394011, "test_runtime": 4.1628, "test_samples_per_second": 491.977, "test_steps_per_second": 15.374}, {"test_loss": 0.819892168045044, "test_mcc": 0.47466829801018645, "test_macro_f1": 0.646482217692707, "test_runtime": 4.1077, "test_samples_per_second": 498.58, "test_steps_per_second": 15.581}, {"test_loss": 0.8356254696846008, "test_mcc": 0.4311420069494181, "test_macro_f1": 0.618434586034532, "test_runtime": 4.0653, "test_samples_per_second": 503.771, "test_steps_per_second": 15.743}, {"test_loss": 0.9065182209014893, "test_mcc": 0.4148835153123266, "test_macro_f1": 0.6003854699504285, "test_runtime": 4.0913, "test_samples_per_second": 500.579, "test_steps_per_second": 15.643}, {"test_loss": 0.8503685593605042, "test_mcc": 0.4657490243871844, "test_macro_f1": 0.6422961708948912, "test_runtime": 4.1514, "test_samples_per_second": 493.33, "test_steps_per_second": 15.417}, {"test_loss": 0.8920067548751831, "test_mcc": 0.41529156381625626, "test_macro_f1": 0.6120209279434897, "test_runtime": 4.2271, "test_samples_per_second": 484.489, "test_steps_per_second": 15.14}, {"test_loss": 0.8519011735916138, "test_mcc": 0.4833897014671685, "test_macro_f1": 0.645914387881451, "test_runtime": 4.1381, "test_samples_per_second": 494.913, "test_steps_per_second": 15.466}, {"test_loss": 0.9213606715202332, "test_mcc": 0.4052145763927757, "test_macro_f1": 0.5945755536925, "test_runtime": 4.061, "test_samples_per_second": 504.31, "test_steps_per_second": 15.76}]}, "total": {"test_mcc": 45.30242995657714, "test_mcc_se": 2.030412519639847, "test_macro_f1": 63.21642448561451, "test_macro_f1_se": 1.4728137342679084}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.8077886700630188, "test_mcc": 0.4925822031999456, "test_macro_f1": 0.6089223581574176, "test_runtime": 3.5078, "test_samples_per_second": 583.845, "test_steps_per_second": 18.245}, {"test_loss": 0.7598905563354492, "test_mcc": 0.5156390717941053, "test_macro_f1": 0.6529347798505931, "test_runtime": 3.288, "test_samples_per_second": 622.88, "test_steps_per_second": 19.465}, {"test_loss": 0.7655611038208008, "test_mcc": 0.49949746425082786, "test_macro_f1": 0.623320697534029, "test_runtime": 3.3736, "test_samples_per_second": 607.059, "test_steps_per_second": 18.971}, {"test_loss": 0.8448761701583862, "test_mcc": 0.48413081469038555, "test_macro_f1": 0.6232022856980399, "test_runtime": 3.3943, "test_samples_per_second": 603.362, "test_steps_per_second": 18.855}, {"test_loss": 0.7915302515029907, "test_mcc": 0.43622670230042815, "test_macro_f1": 0.5464490554995654, "test_runtime": 3.4174, "test_samples_per_second": 599.292, "test_steps_per_second": 18.728}, {"test_loss": 0.7756813764572144, "test_mcc": 0.4543336282145347, "test_macro_f1": 0.5920783250180542, "test_runtime": 3.5704, "test_samples_per_second": 573.61, "test_steps_per_second": 17.925}, {"test_loss": 0.7794616222381592, "test_mcc": 0.519728111591544, "test_macro_f1": 0.655909729780883, "test_runtime": 3.3671, "test_samples_per_second": 608.242, "test_steps_per_second": 19.008}, {"test_loss": 0.8819303512573242, "test_mcc": 0.48306847669452907, "test_macro_f1": 0.6195476371964239, "test_runtime": 3.4333, "test_samples_per_second": 596.508, "test_steps_per_second": 18.641}, {"test_loss": 0.7756279706954956, "test_mcc": 0.4273071330051015, "test_macro_f1": 0.47481681157806505, "test_runtime": 3.4984, "test_samples_per_second": 585.411, "test_steps_per_second": 18.294}, {"test_loss": 0.8725284337997437, "test_mcc": 0.5212614072017223, "test_macro_f1": 0.670693147204562, "test_runtime": 3.5482, "test_samples_per_second": 577.195, "test_steps_per_second": 18.037}]}, "total": {"test_mcc": 48.337750129431235, "test_mcc_se": 2.1021947445376146, "test_macro_f1": 60.67874827517633, "test_macro_f1_se": 3.614652944468665}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.07163175940513611, "test_micro_f1": 0.6382765531062125, "test_micro_f1_no_misc": 0.6860592755214051, "test_runtime": 7.0411, "test_samples_per_second": 290.866, "test_steps_per_second": 9.09}, {"test_loss": 0.06708105653524399, "test_micro_f1": 0.6997907949790796, "test_micro_f1_no_misc": 0.7556094602789568, "test_runtime": 6.8672, "test_samples_per_second": 298.227, "test_steps_per_second": 9.32}, {"test_loss": 0.06914928555488586, "test_micro_f1": 0.6364922206506365, "test_micro_f1_no_misc": 0.692468619246862, "test_runtime": 6.3666, "test_samples_per_second": 321.676, "test_steps_per_second": 10.052}, {"test_loss": 0.060603756457567215, "test_micro_f1": 0.6663551401869159, "test_micro_f1_no_misc": 0.7144340602284528, "test_runtime": 7.0218, "test_samples_per_second": 291.662, "test_steps_per_second": 9.114}, {"test_loss": 0.07166819274425507, "test_micro_f1": 0.6712128592303945, "test_micro_f1_no_misc": 0.7302452316076294, "test_runtime": 6.9819, "test_samples_per_second": 293.328, "test_steps_per_second": 9.166}, {"test_loss": 0.06525823473930359, "test_micro_f1": 0.7002854424357755, "test_micro_f1_no_misc": 0.7531199131850245, "test_runtime": 5.7872, "test_samples_per_second": 353.883, "test_steps_per_second": 11.059}, {"test_loss": 0.06413264572620392, "test_micro_f1": 0.6961113778204513, "test_micro_f1_no_misc": 0.7601108033240997, "test_runtime": 5.8465, "test_samples_per_second": 350.298, "test_steps_per_second": 10.947}, {"test_loss": 0.06237315759062767, "test_micro_f1": 0.6441393875395988, "test_micro_f1_no_misc": 0.6960142772159429, "test_runtime": 6.8712, "test_samples_per_second": 298.055, "test_steps_per_second": 9.314}, {"test_loss": 0.05845886841416359, "test_micro_f1": 0.6865234374999999, "test_micro_f1_no_misc": 0.729021913415286, "test_runtime": 6.4151, "test_samples_per_second": 319.247, "test_steps_per_second": 9.976}, {"test_loss": 0.06227904558181763, "test_micro_f1": 0.6640701071080818, "test_micro_f1_no_misc": 0.7322834645669292, "test_runtime": 7.0485, "test_samples_per_second": 290.559, "test_steps_per_second": 9.08}]}, "total": {"test_micro_f1": 67.03257320557147, "test_micro_f1_se": 1.5469390709178132, "test_micro_f1_no_misc": 72.49367018590588, "test_micro_f1_no_misc_se": 1.6763591349720928}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.06456772983074188, "test_micro_f1": 0.78580546336482, "test_micro_f1_no_misc": 0.8045267489711935, "test_runtime": 7.8768, "test_samples_per_second": 260.006, "test_steps_per_second": 8.125}, {"test_loss": 0.07042557001113892, "test_micro_f1": 0.8027249503264262, "test_micro_f1_no_misc": 0.8269158878504671, "test_runtime": 6.5245, "test_samples_per_second": 313.893, "test_steps_per_second": 9.809}, {"test_loss": 0.06380701065063477, "test_micro_f1": 0.7989333333333334, "test_micro_f1_no_misc": 0.8198005698005698, "test_runtime": 7.8685, "test_samples_per_second": 260.279, "test_steps_per_second": 8.134}, {"test_loss": 0.07005341351032257, "test_micro_f1": 0.7911857292759706, "test_micro_f1_no_misc": 0.8113804004214962, "test_runtime": 7.5848, "test_samples_per_second": 270.015, "test_steps_per_second": 8.438}, {"test_loss": 0.07650284469127655, "test_micro_f1": 0.7893845285149633, "test_micro_f1_no_misc": 0.8157492354740061, "test_runtime": 7.8264, "test_samples_per_second": 261.678, "test_steps_per_second": 8.177}, {"test_loss": 0.06974364817142487, "test_micro_f1": 0.8034617532104968, "test_micro_f1_no_misc": 0.8080207946528036, "test_runtime": 7.7912, "test_samples_per_second": 262.859, "test_steps_per_second": 8.214}, {"test_loss": 0.06599462032318115, "test_micro_f1": 0.7977677385065108, "test_micro_f1_no_misc": 0.814866760168303, "test_runtime": 7.914, "test_samples_per_second": 258.782, "test_steps_per_second": 8.087}, {"test_loss": 0.06570494174957275, "test_micro_f1": 0.7931605074462217, "test_micro_f1_no_misc": 0.812989921612542, "test_runtime": 7.8676, "test_samples_per_second": 260.309, "test_steps_per_second": 8.135}, {"test_loss": 0.06447809189558029, "test_micro_f1": 0.8245140388768899, "test_micro_f1_no_misc": 0.8376694759985341, "test_runtime": 7.5438, "test_samples_per_second": 271.481, "test_steps_per_second": 8.484}, {"test_loss": 0.06824061274528503, "test_micro_f1": 0.777399947685064, "test_micro_f1_no_misc": 0.8086175942549371, "test_runtime": 6.8886, "test_samples_per_second": 297.303, "test_steps_per_second": 9.291}]}, "total": {"test_micro_f1": 79.64337990540696, "test_micro_f1_se": 0.7863635633829383, "test_micro_f1_no_misc": 81.60537389204853, "test_micro_f1_no_misc_se": 0.6145119271996032}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.046860471367836, "test_micro_f1": 0.8323741007194245, "test_micro_f1_no_misc": 0.8650205761316871, "test_runtime": 6.1199, "test_samples_per_second": 334.645, "test_steps_per_second": 10.458}, {"test_loss": 0.03921027481555939, "test_micro_f1": 0.8392330383480825, "test_micro_f1_no_misc": 0.8645108473188702, "test_runtime": 6.1428, "test_samples_per_second": 333.396, "test_steps_per_second": 10.419}, {"test_loss": 0.04216829687356949, "test_micro_f1": 0.854004252303331, "test_micro_f1_no_misc": 0.8762886597938145, "test_runtime": 5.7944, "test_samples_per_second": 353.445, "test_steps_per_second": 11.045}, {"test_loss": 0.04031423479318619, "test_micro_f1": 0.8431786216596343, "test_micro_f1_no_misc": 0.875195007800312, "test_runtime": 5.751, "test_samples_per_second": 356.11, "test_steps_per_second": 11.128}, {"test_loss": 0.03599749505519867, "test_micro_f1": 0.87346396545998, "test_micro_f1_no_misc": 0.8917910447761195, "test_runtime": 6.2224, "test_samples_per_second": 329.131, "test_steps_per_second": 10.285}, {"test_loss": 0.039375729858875275, "test_micro_f1": 0.8698060941828254, "test_micro_f1_no_misc": 0.8849283223556761, "test_runtime": 6.1885, "test_samples_per_second": 330.939, "test_steps_per_second": 10.342}, {"test_loss": 0.0355772040784359, "test_micro_f1": 0.8719194724054148, "test_micro_f1_no_misc": 0.8916408668730651, "test_runtime": 5.6782, "test_samples_per_second": 360.675, "test_steps_per_second": 11.271}, {"test_loss": 0.03883112221956253, "test_micro_f1": 0.8530120481927711, "test_micro_f1_no_misc": 0.8731762065095398, "test_runtime": 5.6746, "test_samples_per_second": 360.906, "test_steps_per_second": 11.278}, {"test_loss": 0.04322194308042526, "test_micro_f1": 0.8588957055214724, "test_micro_f1_no_misc": 0.883169934640523, "test_runtime": 5.6715, "test_samples_per_second": 361.102, "test_steps_per_second": 11.284}, {"test_loss": 0.052123911678791046, "test_micro_f1": 0.8363883231500339, "test_micro_f1_no_misc": 0.8638249717087891, "test_runtime": 6.1257, "test_samples_per_second": 334.328, "test_steps_per_second": 10.448}]}, "total": {"test_micro_f1": 85.3227562194297, "test_micro_f1_se": 0.9426537131511118, "test_micro_f1_no_misc": 87.69546437908396, "test_micro_f1_no_misc_se": 0.6616070589973234}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.052347421646118164, "test_micro_f1": 0.7950617283950617, "test_micro_f1_no_misc": 0.8358310626702997, "test_runtime": 5.6849, "test_samples_per_second": 360.252, "test_steps_per_second": 11.258}, {"test_loss": 0.055227555334568024, "test_micro_f1": 0.8002432350258436, "test_micro_f1_no_misc": 0.8381658799730276, "test_runtime": 5.8718, "test_samples_per_second": 348.784, "test_steps_per_second": 10.899}, {"test_loss": 0.055536262691020966, "test_micro_f1": 0.7909228441754916, "test_micro_f1_no_misc": 0.8274683976768021, "test_runtime": 5.5795, "test_samples_per_second": 367.057, "test_steps_per_second": 11.471}, {"test_loss": 0.06354310363531113, "test_micro_f1": 0.761533852606351, "test_micro_f1_no_misc": 0.8049983558040119, "test_runtime": 5.9214, "test_samples_per_second": 345.863, "test_steps_per_second": 10.808}, {"test_loss": 0.06563258171081543, "test_micro_f1": 0.7567067530064755, "test_micro_f1_no_misc": 0.8028698325930986, "test_runtime": 5.6091, "test_samples_per_second": 365.124, "test_steps_per_second": 11.41}, {"test_loss": 0.070527583360672, "test_micro_f1": 0.7219892150988616, "test_micro_f1_no_misc": 0.7652060170045781, "test_runtime": 5.9315, "test_samples_per_second": 345.276, "test_steps_per_second": 10.79}, {"test_loss": 0.05539444088935852, "test_micro_f1": 0.7918441874619598, "test_micro_f1_no_misc": 0.8369713506139154, "test_runtime": 5.9109, "test_samples_per_second": 346.479, "test_steps_per_second": 10.827}, {"test_loss": 0.058720238506793976, "test_micro_f1": 0.7691835481890731, "test_micro_f1_no_misc": 0.8098897427330437, "test_runtime": 5.9176, "test_samples_per_second": 346.085, "test_steps_per_second": 10.815}, {"test_loss": 0.06530970335006714, "test_micro_f1": 0.7564062982401977, "test_micro_f1_no_misc": 0.7932343803935106, "test_runtime": 5.2898, "test_samples_per_second": 387.16, "test_steps_per_second": 12.099}, {"test_loss": 0.05371292680501938, "test_micro_f1": 0.7968369829683698, "test_micro_f1_no_misc": 0.8266666666666668, "test_runtime": 5.6348, "test_samples_per_second": 363.456, "test_steps_per_second": 11.358}]}, "total": {"test_micro_f1": 77.40728645167685, "test_micro_f1_se": 1.5667603115921438, "test_micro_f1_no_misc": 81.41301686128955, "test_micro_f1_no_misc_se": 1.4556009959379534}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.44705930352211, "test_mcc": 0.6250381210955898, "test_macro_f1": 0.8018735193217632, "test_runtime": 3.0607, "test_samples_per_second": 669.127, "test_steps_per_second": 20.91}, {"test_loss": 0.572522759437561, "test_mcc": 0.43739810588777894, "test_macro_f1": 0.6706460339079756, "test_runtime": 3.218, "test_samples_per_second": 636.423, "test_steps_per_second": 19.888}, {"test_loss": 0.45172595977783203, "test_mcc": 0.6049475344293872, "test_macro_f1": 0.8010770675271695, "test_runtime": 3.2058, "test_samples_per_second": 638.841, "test_steps_per_second": 19.964}, {"test_loss": 0.5011588335037231, "test_mcc": 0.582531189210902, "test_macro_f1": 0.7732764344687333, "test_runtime": 3.1334, "test_samples_per_second": 653.601, "test_steps_per_second": 20.425}, {"test_loss": 0.48974403738975525, "test_mcc": 0.5714166570033161, "test_macro_f1": 0.7725116455994643, "test_runtime": 3.1858, "test_samples_per_second": 642.861, "test_steps_per_second": 20.089}, {"test_loss": 0.5117969512939453, "test_mcc": 0.5812991941132948, "test_macro_f1": 0.7800121898968686, "test_runtime": 3.1899, "test_samples_per_second": 642.03, "test_steps_per_second": 20.063}, {"test_loss": 0.5012770891189575, "test_mcc": 0.5781228718165259, "test_macro_f1": 0.779776875954758, "test_runtime": 3.1515, "test_samples_per_second": 649.839, "test_steps_per_second": 20.307}, {"test_loss": 0.5150951147079468, "test_mcc": 0.5465675635779176, "test_macro_f1": 0.7631822386679001, "test_runtime": 3.1636, "test_samples_per_second": 647.372, "test_steps_per_second": 20.23}, {"test_loss": 0.47124022245407104, "test_mcc": 0.5987466470529991, "test_macro_f1": 0.7982671231566666, "test_runtime": 3.1518, "test_samples_per_second": 649.786, "test_steps_per_second": 20.306}, {"test_loss": 0.5548469424247742, "test_mcc": 0.5334760596187803, "test_macro_f1": 0.7295085208865254, "test_runtime": 3.1557, "test_samples_per_second": 648.991, "test_steps_per_second": 20.281}]}, "total": {"test_mcc": 56.59543943806491, "test_mcc_se": 3.2491269365464053, "test_macro_f1": 76.70131649387824, "test_macro_f1_se": 2.4845271734814602}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.5477375984191895, "test_mcc": 0.5060250757078802, "test_macro_f1": 0.7395858431116933, "test_runtime": 3.5265, "test_samples_per_second": 580.753, "test_steps_per_second": 18.149}, {"test_loss": 0.5415741205215454, "test_mcc": 0.5509132996656354, "test_macro_f1": 0.7682882513176554, "test_runtime": 3.6673, "test_samples_per_second": 558.453, "test_steps_per_second": 17.452}, {"test_loss": 0.5447213649749756, "test_mcc": 0.5576490395008539, "test_macro_f1": 0.7722931359618046, "test_runtime": 3.5854, "test_samples_per_second": 571.202, "test_steps_per_second": 17.85}, {"test_loss": 0.5987377166748047, "test_mcc": 0.5088505796413294, "test_macro_f1": 0.7245254212218586, "test_runtime": 3.7078, "test_samples_per_second": 552.356, "test_steps_per_second": 17.261}, {"test_loss": 0.5691858530044556, "test_mcc": 0.4823860265056403, "test_macro_f1": 0.7199995401937889, "test_runtime": 3.5265, "test_samples_per_second": 580.752, "test_steps_per_second": 18.149}, {"test_loss": 0.5327144861221313, "test_mcc": 0.5565911767363901, "test_macro_f1": 0.7715465846934304, "test_runtime": 3.5797, "test_samples_per_second": 572.113, "test_steps_per_second": 17.879}, {"test_loss": 0.5756881237030029, "test_mcc": 0.5622375753962293, "test_macro_f1": 0.7746862913020124, "test_runtime": 3.4634, "test_samples_per_second": 591.322, "test_steps_per_second": 18.479}, {"test_loss": 0.5407482981681824, "test_mcc": 0.4848676340528422, "test_macro_f1": 0.7298600159647995, "test_runtime": 3.5469, "test_samples_per_second": 577.401, "test_steps_per_second": 18.044}, {"test_loss": 0.6036801338195801, "test_mcc": 0.4386809063246975, "test_macro_f1": 0.6770390923214844, "test_runtime": 3.5385, "test_samples_per_second": 578.772, "test_steps_per_second": 18.087}, {"test_loss": 0.5809844732284546, "test_mcc": 0.5262930643964775, "test_macro_f1": 0.7527955348693486, "test_runtime": 3.6101, "test_samples_per_second": 567.29, "test_steps_per_second": 17.728}]}, "total": {"test_mcc": 51.744943779279765, "test_mcc_se": 2.534735933456956, "test_macro_f1": 74.30619710957876, "test_macro_f1_se": 1.9400715813926623}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.5219081044197083, "test_mcc": 0.5522865798756919, "test_macro_f1": 0.7436788264813742, "test_runtime": 3.1858, "test_samples_per_second": 642.856, "test_steps_per_second": 20.089}, {"test_loss": 0.5032487511634827, "test_mcc": 0.5755767450489986, "test_macro_f1": 0.7678704856787049, "test_runtime": 3.1718, "test_samples_per_second": 645.684, "test_steps_per_second": 20.178}, {"test_loss": 0.5177899599075317, "test_mcc": 0.5904582563335733, "test_macro_f1": 0.7757026156471738, "test_runtime": 3.1606, "test_samples_per_second": 647.975, "test_steps_per_second": 20.249}, {"test_loss": 0.5149871110916138, "test_mcc": 0.5242282199403548, "test_macro_f1": 0.7573398480826472, "test_runtime": 3.2361, "test_samples_per_second": 632.856, "test_steps_per_second": 19.777}, {"test_loss": 0.5399996042251587, "test_mcc": 0.6146506603990025, "test_macro_f1": 0.7984981117879415, "test_runtime": 3.2229, "test_samples_per_second": 635.447, "test_steps_per_second": 19.858}, {"test_loss": 0.4882320165634155, "test_mcc": 0.5782070174009305, "test_macro_f1": 0.7733258440991075, "test_runtime": 3.1133, "test_samples_per_second": 657.825, "test_steps_per_second": 20.557}, {"test_loss": 0.54764324426651, "test_mcc": 0.4818117597308861, "test_macro_f1": 0.7345127949137655, "test_runtime": 3.1411, "test_samples_per_second": 651.991, "test_steps_per_second": 20.375}, {"test_loss": 0.49720561504364014, "test_mcc": 0.6036571343207541, "test_macro_f1": 0.7959442612692835, "test_runtime": 3.2066, "test_samples_per_second": 638.685, "test_steps_per_second": 19.959}, {"test_loss": 0.5796788334846497, "test_mcc": 0.5045597150501092, "test_macro_f1": 0.7160171420245878, "test_runtime": 3.1306, "test_samples_per_second": 654.197, "test_steps_per_second": 20.444}, {"test_loss": 0.5742006301879883, "test_mcc": 0.5042057754731079, "test_macro_f1": 0.7141383060828268, "test_runtime": 3.2199, "test_samples_per_second": 636.054, "test_steps_per_second": 19.877}]}, "total": {"test_mcc": 55.29641863573408, "test_mcc_se": 2.8878950267192662, "test_macro_f1": 75.77028236067413, "test_macro_f1_se": 1.8672377125556594}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6139063239097595, "test_mcc": 0.37414935953726414, "test_macro_f1": 0.6583353554962388, "test_runtime": 3.3432, "test_samples_per_second": 612.582, "test_steps_per_second": 19.143}, {"test_loss": 0.5921933054924011, "test_mcc": 0.3808350772491547, "test_macro_f1": 0.674312609239909, "test_runtime": 3.4625, "test_samples_per_second": 591.483, "test_steps_per_second": 18.484}, {"test_loss": 0.6222715973854065, "test_mcc": 0.34067864440595846, "test_macro_f1": 0.6695992179863147, "test_runtime": 3.4742, "test_samples_per_second": 589.482, "test_steps_per_second": 18.421}, {"test_loss": 0.5830454230308533, "test_mcc": 0.4301919772549209, "test_macro_f1": 0.711349356470101, "test_runtime": 3.3044, "test_samples_per_second": 619.775, "test_steps_per_second": 19.368}, {"test_loss": 0.5961358547210693, "test_mcc": 0.3474318146170541, "test_macro_f1": 0.6578997161778619, "test_runtime": 3.3664, "test_samples_per_second": 608.371, "test_steps_per_second": 19.012}, {"test_loss": 0.6169918775558472, "test_mcc": 0.3444212611543566, "test_macro_f1": 0.6692878039239538, "test_runtime": 3.4562, "test_samples_per_second": 592.566, "test_steps_per_second": 18.518}, {"test_loss": 0.6175004243850708, "test_mcc": 0.3390660271609194, "test_macro_f1": 0.6468320228226327, "test_runtime": 3.3722, "test_samples_per_second": 607.322, "test_steps_per_second": 18.979}, {"test_loss": 0.5950223207473755, "test_mcc": 0.39045504944909515, "test_macro_f1": 0.6925450397612682, "test_runtime": 3.4401, "test_samples_per_second": 595.335, "test_steps_per_second": 18.604}, {"test_loss": 0.6130435466766357, "test_mcc": 0.46387815953275613, "test_macro_f1": 0.7309456372597407, "test_runtime": 3.3968, "test_samples_per_second": 602.915, "test_steps_per_second": 18.841}, {"test_loss": 0.6038089990615845, "test_mcc": 0.3353324178904946, "test_macro_f1": 0.6568952888556423, "test_runtime": 3.4235, "test_samples_per_second": 598.219, "test_steps_per_second": 18.694}]}, "total": {"test_mcc": 37.46439788251975, "test_mcc_se": 2.690244795918328, "test_macro_f1": 67.68002047993663, "test_macro_f1_se": 1.6631442555058176}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_em": 31.44848954298993, "test_f1": 35.852253535980694}, {"test_em": 35.1937984496124, "test_f1": 39.75844115711275}, {"test_em": 20.479134466769708, "test_f1": 25.733375101779316}, {"test_em": 35.981308411214954, "test_f1": 41.48300183342903}, {"test_em": 37.683397683397686, "test_f1": 42.02820161813296}, {"test_em": 37.31688511950655, "test_f1": 42.34559497122165}, {"test_em": 31.05542900531511, "test_f1": 34.99639072332783}, {"test_em": 41.427463149728474, "test_f1": 46.30315965208374}, {"test_em": 33.490196078431374, "test_f1": 37.63190665682476}, {"test_em": 40.45031055900621, "test_f1": 44.29125140692261}]}, "total": {"test_em": 34.45264124659724, "test_em_se": 3.7125155239491248, "test_f1": 39.04235766568153, "test_f1_se": 3.6506738124010836}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_em": 44.2292796281952, "test_f1": 48.23209789166051}, {"test_em": 40.07751937984496, "test_f1": 44.346437902692166}, {"test_em": 26.120556414219475, "test_f1": 31.88681997766318}, {"test_em": 38.78504672897196, "test_f1": 43.766514780663684}, {"test_em": 35.907335907335906, "test_f1": 41.24678068065951}, {"test_em": 43.48496530454896, "test_f1": 48.24510789607537}, {"test_em": 44.34320425208808, "test_f1": 48.43438635533409}, {"test_em": 44.45306439100077, "test_f1": 48.17982927530973}, {"test_em": 44.0, "test_f1": 48.7239897445142}, {"test_em": 44.099378881987576, "test_f1": 48.930595322119615}]}, "total": {"test_em": 40.550035088819286, "test_em_se": 3.6339401397091895, "test_f1": 45.19925598266921, "test_f1_se": 3.3300453860677757}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_em": 34.546862896979086, "test_f1": 40.036556979831715}, {"test_em": 39.14728682170543, "test_f1": 44.11836968647865}, {"test_em": 44.12673879443586, "test_f1": 48.806864163346326}, {"test_em": 41.1993769470405, "test_f1": 46.09652297186658}, {"test_em": 43.397683397683394, "test_f1": 48.56259848118971}, {"test_em": 38.010794140323824, "test_f1": 42.9050662914663}, {"test_em": 41.53378891419894, "test_f1": 46.67572076553461}, {"test_em": 42.35841737781226, "test_f1": 46.923356898103854}, {"test_em": 39.372549019607845, "test_f1": 44.83203880550685}, {"test_em": 38.50931677018634, "test_f1": 43.51417596296723}]}, "total": {"test_em": 40.22028150799735, "test_em_se": 1.7829983454284133, "test_f1": 45.24712710062918, "test_f1_se": 1.6825201766241873}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.5695202350616455, "test_mcc": 0.634988357379025, "test_macro_f1": 0.6492843396485267, "test_runtime": 16.5702, "test_samples_per_second": 123.595, "test_steps_per_second": 15.449}, {"test_loss": 0.6840258240699768, "test_mcc": 0.6024862320018812, "test_macro_f1": 0.6568690120452234, "test_runtime": 15.8977, "test_samples_per_second": 128.824, "test_steps_per_second": 16.103}, {"test_loss": 0.6216177940368652, "test_mcc": 0.5678278303049947, "test_macro_f1": 0.5336299720064366, "test_runtime": 16.3107, "test_samples_per_second": 125.562, "test_steps_per_second": 15.695}, {"test_loss": 0.6098176836967468, "test_mcc": 0.6012211395610945, "test_macro_f1": 0.6430068137855427, "test_runtime": 15.8785, "test_samples_per_second": 128.98, "test_steps_per_second": 16.122}, {"test_loss": 0.588391900062561, "test_mcc": 0.614932996992532, "test_macro_f1": 0.615391587221, "test_runtime": 15.7662, "test_samples_per_second": 129.898, "test_steps_per_second": 16.237}, {"test_loss": 0.6465872526168823, "test_mcc": 0.6112014771989009, "test_macro_f1": 0.5813609355969898, "test_runtime": 16.1026, "test_samples_per_second": 127.184, "test_steps_per_second": 15.898}, {"test_loss": 0.5755754709243774, "test_mcc": 0.6289384483318139, "test_macro_f1": 0.5776888595550421, "test_runtime": 15.6209, "test_samples_per_second": 131.106, "test_steps_per_second": 16.388}, {"test_loss": 0.5709626078605652, "test_mcc": 0.6178547957811161, "test_macro_f1": 0.5968137919302162, "test_runtime": 16.6151, "test_samples_per_second": 123.261, "test_steps_per_second": 15.408}, {"test_loss": 0.5942418575286865, "test_mcc": 0.6385225230929101, "test_macro_f1": 0.686784887577061, "test_runtime": 16.4778, "test_samples_per_second": 124.288, "test_steps_per_second": 15.536}, {"test_loss": 0.552470326423645, "test_mcc": 0.6418580484300671, "test_macro_f1": 0.6870852579673142, "test_runtime": 16.0712, "test_samples_per_second": 127.433, "test_steps_per_second": 15.929}]}, "total": {"test_mcc": 61.59831849074335, "test_mcc_se": 1.3786819829867214, "test_macro_f1": 62.27915457333353, "test_macro_f1_se": 3.1285571326935213}}, "num_model_parameters": 118076931, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.9884039163589478, "test_mcc": 0.36820977496714796, "test_macro_f1": 0.5636694403259132, "test_runtime": 4.8127, "test_samples_per_second": 425.538, "test_steps_per_second": 13.298}, {"test_loss": 0.9130740165710449, "test_mcc": 0.3876291741587915, "test_macro_f1": 0.5804021638632086, "test_runtime": 4.7913, "test_samples_per_second": 427.444, "test_steps_per_second": 13.358}, {"test_loss": 0.9517959356307983, "test_mcc": 0.36147260580338525, "test_macro_f1": 0.5638979366913978, "test_runtime": 4.7822, "test_samples_per_second": 428.256, "test_steps_per_second": 13.383}, {"test_loss": 0.9588104486465454, "test_mcc": 0.36049562933286455, "test_macro_f1": 0.5664834074915043, "test_runtime": 4.7469, "test_samples_per_second": 431.438, "test_steps_per_second": 13.482}, {"test_loss": 0.9608330726623535, "test_mcc": 0.30578315865767536, "test_macro_f1": 0.5245197510822511, "test_runtime": 4.7258, "test_samples_per_second": 433.369, "test_steps_per_second": 13.543}, {"test_loss": 0.9881669878959656, "test_mcc": 0.33183329916618304, "test_macro_f1": 0.5482076098172058, "test_runtime": 4.7979, "test_samples_per_second": 426.856, "test_steps_per_second": 13.339}, {"test_loss": 0.9216564893722534, "test_mcc": 0.3605004689157459, "test_macro_f1": 0.5596341352129889, "test_runtime": 4.8489, "test_samples_per_second": 422.368, "test_steps_per_second": 13.199}, {"test_loss": 0.9830759763717651, "test_mcc": 0.3262402774666902, "test_macro_f1": 0.5489916260994442, "test_runtime": 4.7743, "test_samples_per_second": 428.96, "test_steps_per_second": 13.405}, {"test_loss": 0.9661401510238647, "test_mcc": 0.33712744274807765, "test_macro_f1": 0.5535827796194014, "test_runtime": 4.7282, "test_samples_per_second": 433.142, "test_steps_per_second": 13.536}, {"test_loss": 0.9651764631271362, "test_mcc": 0.3390555739155582, "test_macro_f1": 0.549701667577982, "test_runtime": 4.6897, "test_samples_per_second": 436.703, "test_steps_per_second": 13.647}]}, "total": {"test_mcc": 34.78347405132119, "test_mcc_se": 1.4880907829327552, "test_macro_f1": 55.59090517781298, "test_macro_f1_se": 0.9207240193279768}}, "num_model_parameters": 118076931, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.8447198867797852, "test_mcc": 0.35609721240191416, "test_macro_f1": 0.4779700975360777, "test_runtime": 3.7813, "test_samples_per_second": 541.608, "test_steps_per_second": 16.925}, {"test_loss": 0.9108909368515015, "test_mcc": 0.320562343304415, "test_macro_f1": 0.516834424948553, "test_runtime": 3.5825, "test_samples_per_second": 571.669, "test_steps_per_second": 17.865}, {"test_loss": 0.8404167890548706, "test_mcc": 0.4043296248402281, "test_macro_f1": 0.5319563925702033, "test_runtime": 3.5741, "test_samples_per_second": 573.014, "test_steps_per_second": 17.907}, {"test_loss": 0.9279729723930359, "test_mcc": 0.3585676710276953, "test_macro_f1": 0.47929125343703866, "test_runtime": 3.6209, "test_samples_per_second": 565.603, "test_steps_per_second": 17.675}, {"test_loss": 0.8515956401824951, "test_mcc": 0.34467548265568054, "test_macro_f1": 0.49131539558919024, "test_runtime": 3.6987, "test_samples_per_second": 553.704, "test_steps_per_second": 17.303}, {"test_loss": 0.8660087585449219, "test_mcc": 0.36188304610597005, "test_macro_f1": 0.4370024703870394, "test_runtime": 3.7341, "test_samples_per_second": 548.459, "test_steps_per_second": 17.139}, {"test_loss": 0.8388108015060425, "test_mcc": 0.3557146750131673, "test_macro_f1": 0.4483200221250094, "test_runtime": 3.6038, "test_samples_per_second": 568.288, "test_steps_per_second": 17.759}, {"test_loss": 0.9085226655006409, "test_mcc": 0.29183849053734817, "test_macro_f1": 0.424094105011286, "test_runtime": 3.7827, "test_samples_per_second": 541.409, "test_steps_per_second": 16.919}, {"test_loss": 0.8696051239967346, "test_mcc": 0.3627737102024031, "test_macro_f1": 0.5047869389893761, "test_runtime": 3.7738, "test_samples_per_second": 542.684, "test_steps_per_second": 16.959}, {"test_loss": 0.909092903137207, "test_mcc": 0.37742864727127134, "test_macro_f1": 0.5190463053057429, "test_runtime": 3.7749, "test_samples_per_second": 542.525, "test_steps_per_second": 16.954}]}, "total": {"test_mcc": 35.33870903360093, "test_mcc_se": 1.883891540335647, "test_macro_f1": 48.30617405899516, "test_macro_f1_se": 2.2831213570629316}}, "num_model_parameters": 118076931, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.06295688450336456, "test_micro_f1": 0.7118644067796609, "test_micro_f1_no_misc": 0.7799274486094318, "test_runtime": 8.1692, "test_samples_per_second": 250.699, "test_steps_per_second": 7.834}, {"test_loss": 0.060582444071769714, "test_micro_f1": 0.6900891452543261, "test_micro_f1_no_misc": 0.7675276752767528, "test_runtime": 7.3463, "test_samples_per_second": 278.779, "test_steps_per_second": 8.712}, {"test_loss": 0.06122542545199394, "test_micro_f1": 0.7072936660268714, "test_micro_f1_no_misc": 0.7680355160932296, "test_runtime": 7.3123, "test_samples_per_second": 280.076, "test_steps_per_second": 8.752}, {"test_loss": 0.062387727200984955, "test_micro_f1": 0.6913700633837153, "test_micro_f1_no_misc": 0.7321041214750542, "test_runtime": 8.0032, "test_samples_per_second": 255.897, "test_steps_per_second": 7.997}, {"test_loss": 0.06673242896795273, "test_micro_f1": 0.7211079274116523, "test_micro_f1_no_misc": 0.7833698030634574, "test_runtime": 8.0757, "test_samples_per_second": 253.6, "test_steps_per_second": 7.925}, {"test_loss": 0.05957639962434769, "test_micro_f1": 0.7324209532798489, "test_micro_f1_no_misc": 0.7851690294438386, "test_runtime": 6.7876, "test_samples_per_second": 301.727, "test_steps_per_second": 9.429}, {"test_loss": 0.06274852156639099, "test_micro_f1": 0.6886171213546567, "test_micro_f1_no_misc": 0.7633423180592992, "test_runtime": 7.1876, "test_samples_per_second": 284.937, "test_steps_per_second": 8.904}, {"test_loss": 0.05499463900923729, "test_micro_f1": 0.7153439153439154, "test_micro_f1_no_misc": 0.7707959305804907, "test_runtime": 8.0424, "test_samples_per_second": 254.65, "test_steps_per_second": 7.958}, {"test_loss": 0.0596829392015934, "test_micro_f1": 0.6827682303762193, "test_micro_f1_no_misc": 0.7256819351518272, "test_runtime": 7.783, "test_samples_per_second": 263.139, "test_steps_per_second": 8.223}, {"test_loss": 0.05729416757822037, "test_micro_f1": 0.6970993818354733, "test_micro_f1_no_misc": 0.7786429365962181, "test_runtime": 8.0662, "test_samples_per_second": 253.9, "test_steps_per_second": 7.934}]}, "total": {"test_micro_f1": 70.3797481104634, "test_micro_f1_se": 1.009916799913299, "test_micro_f1_no_misc": 76.545967143496, "test_micro_f1_no_misc_se": 1.2787784882906237}}, "num_model_parameters": 117490953, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.06128765642642975, "test_micro_f1": 0.8037909836065574, "test_micro_f1_no_misc": 0.8295025728987994, "test_runtime": 9.0523, "test_samples_per_second": 226.241, "test_steps_per_second": 7.07}, {"test_loss": 0.05704609304666519, "test_micro_f1": 0.8032556834128544, "test_micro_f1_no_misc": 0.8239178283198826, "test_runtime": 6.7803, "test_samples_per_second": 302.051, "test_steps_per_second": 9.439}, {"test_loss": 0.05704161524772644, "test_micro_f1": 0.8198030343359063, "test_micro_f1_no_misc": 0.8386396526772794, "test_runtime": 9.0647, "test_samples_per_second": 225.932, "test_steps_per_second": 7.06}, {"test_loss": 0.06436518579721451, "test_micro_f1": 0.805348418616611, "test_micro_f1_no_misc": 0.8208695652173912, "test_runtime": 8.6182, "test_samples_per_second": 237.637, "test_steps_per_second": 7.426}, {"test_loss": 0.06630142778158188, "test_micro_f1": 0.7915859396623305, "test_micro_f1_no_misc": 0.8170406998858881, "test_runtime": 9.1523, "test_samples_per_second": 223.769, "test_steps_per_second": 6.993}, {"test_loss": 0.0644620954990387, "test_micro_f1": 0.7900492072170585, "test_micro_f1_no_misc": 0.8105065666041277, "test_runtime": 8.8322, "test_samples_per_second": 231.878, "test_steps_per_second": 7.246}, {"test_loss": 0.06151854246854782, "test_micro_f1": 0.7805263157894737, "test_micro_f1_no_misc": 0.8074179743223965, "test_runtime": 9.1634, "test_samples_per_second": 223.499, "test_steps_per_second": 6.984}, {"test_loss": 0.05587621405720711, "test_micro_f1": 0.7878453038674034, "test_micro_f1_no_misc": 0.8083547086844999, "test_runtime": 8.9856, "test_samples_per_second": 227.92, "test_steps_per_second": 7.123}, {"test_loss": 0.06162550300359726, "test_micro_f1": 0.7898493259318002, "test_micro_f1_no_misc": 0.8161337209302326, "test_runtime": 8.647, "test_samples_per_second": 236.844, "test_steps_per_second": 7.401}, {"test_loss": 0.06319712102413177, "test_micro_f1": 0.8254477412456563, "test_micro_f1_no_misc": 0.8421818181818181, "test_runtime": 7.1735, "test_samples_per_second": 285.494, "test_steps_per_second": 8.922}]}, "total": {"test_micro_f1": 79.97501953685651, "test_micro_f1_se": 0.8987815697210374, "test_micro_f1_no_misc": 82.14565107722315, "test_micro_f1_no_misc_se": 0.7541433532861949}}, "num_model_parameters": 117490953, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.04316219687461853, "test_micro_f1": 0.8185498711814501, "test_micro_f1_no_misc": 0.8636552009946125, "test_runtime": 6.6438, "test_samples_per_second": 308.255, "test_steps_per_second": 9.633}, {"test_loss": 0.03522808849811554, "test_micro_f1": 0.828928046989721, "test_micro_f1_no_misc": 0.8624746450304259, "test_runtime": 6.6678, "test_samples_per_second": 307.147, "test_steps_per_second": 9.598}, {"test_loss": 0.04281250759959221, "test_micro_f1": 0.8578607322325915, "test_micro_f1_no_misc": 0.8872060581905141, "test_runtime": 6.3098, "test_samples_per_second": 324.575, "test_steps_per_second": 10.143}, {"test_loss": 0.03595702350139618, "test_micro_f1": 0.8451096414897321, "test_micro_f1_no_misc": 0.872138910812944, "test_runtime": 6.1476, "test_samples_per_second": 333.14, "test_steps_per_second": 10.411}, {"test_loss": 0.03473123908042908, "test_micro_f1": 0.8745399799263968, "test_micro_f1_no_misc": 0.9019022752704214, "test_runtime": 6.7026, "test_samples_per_second": 305.553, "test_steps_per_second": 9.549}, {"test_loss": 0.03739570081233978, "test_micro_f1": 0.8618107556160653, "test_micro_f1_no_misc": 0.8933231005372217, "test_runtime": 6.7233, "test_samples_per_second": 304.614, "test_steps_per_second": 9.519}, {"test_loss": 0.03828093782067299, "test_micro_f1": 0.858695652173913, "test_micro_f1_no_misc": 0.8862003780718337, "test_runtime": 6.0886, "test_samples_per_second": 336.366, "test_steps_per_second": 10.511}, {"test_loss": 0.039389170706272125, "test_micro_f1": 0.8352021746517159, "test_micro_f1_no_misc": 0.8648648648648649, "test_runtime": 6.2194, "test_samples_per_second": 329.293, "test_steps_per_second": 10.29}, {"test_loss": 0.03465454280376434, "test_micro_f1": 0.8560283687943262, "test_micro_f1_no_misc": 0.8852988691437803, "test_runtime": 6.2279, "test_samples_per_second": 328.844, "test_steps_per_second": 10.276}, {"test_loss": 0.04045707732439041, "test_micro_f1": 0.8514579759862778, "test_micro_f1_no_misc": 0.8877824588280352, "test_runtime": 6.5663, "test_samples_per_second": 311.897, "test_steps_per_second": 9.747}]}, "total": {"test_micro_f1": 84.88183199042189, "test_micro_f1_se": 1.0493359801113924, "test_micro_f1_no_misc": 88.04846761744655, "test_micro_f1_no_misc_se": 0.8516023351567172}}, "num_model_parameters": 117490953, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.052055586129426956, "test_micro_f1": 0.7948003714020427, "test_micro_f1_no_misc": 0.8438991138377641, "test_runtime": 6.1692, "test_samples_per_second": 331.972, "test_steps_per_second": 10.374}, {"test_loss": 0.05109700560569763, "test_micro_f1": 0.8089955022488755, "test_micro_f1_no_misc": 0.8421750663129973, "test_runtime": 6.3634, "test_samples_per_second": 321.838, "test_steps_per_second": 10.057}, {"test_loss": 0.059670597314834595, "test_micro_f1": 0.7749253731343284, "test_micro_f1_no_misc": 0.8135144087446174, "test_runtime": 6.0857, "test_samples_per_second": 336.527, "test_steps_per_second": 10.516}, {"test_loss": 0.05811375007033348, "test_micro_f1": 0.7437275985663081, "test_micro_f1_no_misc": 0.7829560585885487, "test_runtime": 6.3132, "test_samples_per_second": 324.399, "test_steps_per_second": 10.137}, {"test_loss": 0.058403290808200836, "test_micro_f1": 0.8043152532214564, "test_micro_f1_no_misc": 0.8486543166724921, "test_runtime": 6.0299, "test_samples_per_second": 339.64, "test_steps_per_second": 10.614}, {"test_loss": 0.055155038833618164, "test_micro_f1": 0.8153892036981808, "test_micro_f1_no_misc": 0.8489989820156092, "test_runtime": 6.1237, "test_samples_per_second": 334.441, "test_steps_per_second": 10.451}, {"test_loss": 0.05412697046995163, "test_micro_f1": 0.771136574790957, "test_micro_f1_no_misc": 0.8234100135317998, "test_runtime": 6.3964, "test_samples_per_second": 320.178, "test_steps_per_second": 10.006}, {"test_loss": 0.057089950889348984, "test_micro_f1": 0.7636808315499847, "test_micro_f1_no_misc": 0.8067954696868753, "test_runtime": 6.4215, "test_samples_per_second": 318.928, "test_steps_per_second": 9.967}, {"test_loss": 0.059040993452072144, "test_micro_f1": 0.7924411400247832, "test_micro_f1_no_misc": 0.83298392732355, "test_runtime": 5.8358, "test_samples_per_second": 350.937, "test_steps_per_second": 10.967}, {"test_loss": 0.049208126962184906, "test_micro_f1": 0.8362305580969808, "test_micro_f1_no_misc": 0.8641806363325351, "test_runtime": 6.1042, "test_samples_per_second": 335.505, "test_steps_per_second": 10.485}]}, "total": {"test_micro_f1": 79.05642406733897, "test_micro_f1_se": 1.702476572906601, "test_micro_f1_no_misc": 83.07567993046789, "test_micro_f1_no_misc_se": 1.5024734969762008}}, "num_model_parameters": 117490953, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.5755955576896667, "test_mcc": 0.44193550283246175, "test_macro_f1": 0.7113666708042592, "test_runtime": 3.8029, "test_samples_per_second": 538.535, "test_steps_per_second": 16.829}, {"test_loss": 0.6350294947624207, "test_mcc": 0.2978339109451032, "test_macro_f1": 0.6124811908130074, "test_runtime": 4.0119, "test_samples_per_second": 510.476, "test_steps_per_second": 15.952}, {"test_loss": 0.5710071325302124, "test_mcc": 0.3949316609918551, "test_macro_f1": 0.6923748977754041, "test_runtime": 4.0282, "test_samples_per_second": 508.421, "test_steps_per_second": 15.888}, {"test_loss": 0.690133810043335, "test_mcc": 0.4360567189548938, "test_macro_f1": 0.7179033057012754, "test_runtime": 3.9473, "test_samples_per_second": 518.84, "test_steps_per_second": 16.214}, {"test_loss": 0.6027272939682007, "test_mcc": 0.42531997167848523, "test_macro_f1": 0.693847779581948, "test_runtime": 3.9854, "test_samples_per_second": 513.878, "test_steps_per_second": 16.059}, {"test_loss": 0.5886103510856628, "test_mcc": 0.42451721587461083, "test_macro_f1": 0.7030219021250671, "test_runtime": 3.913, "test_samples_per_second": 523.389, "test_steps_per_second": 16.356}, {"test_loss": 0.6160414814949036, "test_mcc": 0.44674320082741986, "test_macro_f1": 0.6909220331077535, "test_runtime": 4.0251, "test_samples_per_second": 508.805, "test_steps_per_second": 15.9}, {"test_loss": 0.691138505935669, "test_mcc": 0.09993636319271168, "test_macro_f1": 0.45983262738846964, "test_runtime": 3.9375, "test_samples_per_second": 520.127, "test_steps_per_second": 16.254}, {"test_loss": 0.6000868082046509, "test_mcc": 0.42634501123246277, "test_macro_f1": 0.7119665675480189, "test_runtime": 3.9409, "test_samples_per_second": 519.677, "test_steps_per_second": 16.24}, {"test_loss": 0.6021992564201355, "test_mcc": 0.3505068796320246, "test_macro_f1": 0.6730795517002413, "test_runtime": 3.9761, "test_samples_per_second": 515.081, "test_steps_per_second": 16.096}]}, "total": {"test_mcc": 37.44126436162029, "test_mcc_se": 6.6493825930753605, "test_macro_f1": 66.66796526545444, "test_macro_f1_se": 4.877850965562963}}, "num_model_parameters": 118076162, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6452609300613403, "test_mcc": 0.44902528931769786, "test_macro_f1": 0.7209956491914787, "test_runtime": 3.9703, "test_samples_per_second": 515.827, "test_steps_per_second": 16.12}, {"test_loss": 0.5903297662734985, "test_mcc": 0.4397306149330887, "test_macro_f1": 0.7105027564434812, "test_runtime": 4.1431, "test_samples_per_second": 494.319, "test_steps_per_second": 15.447}, {"test_loss": 0.6907427310943604, "test_mcc": 0.09880215167017825, "test_macro_f1": 0.542225889367324, "test_runtime": 4.0711, "test_samples_per_second": 503.058, "test_steps_per_second": 15.721}, {"test_loss": 0.561152458190918, "test_mcc": 0.4803879734197273, "test_macro_f1": 0.7313864804837664, "test_runtime": 4.2761, "test_samples_per_second": 478.936, "test_steps_per_second": 14.967}, {"test_loss": 0.5486229062080383, "test_mcc": 0.5088268199351444, "test_macro_f1": 0.7489752395225452, "test_runtime": 4.0298, "test_samples_per_second": 508.213, "test_steps_per_second": 15.882}, {"test_loss": 0.6004543304443359, "test_mcc": 0.4755092221125316, "test_macro_f1": 0.7377248722042633, "test_runtime": 4.0359, "test_samples_per_second": 507.449, "test_steps_per_second": 15.858}, {"test_loss": 0.5888437032699585, "test_mcc": 0.4026209209347964, "test_macro_f1": 0.6839923185017628, "test_runtime": 3.9236, "test_samples_per_second": 521.963, "test_steps_per_second": 16.311}, {"test_loss": 0.5556464195251465, "test_mcc": 0.4783585991514, "test_macro_f1": 0.739168014195561, "test_runtime": 3.9675, "test_samples_per_second": 516.201, "test_steps_per_second": 16.131}, {"test_loss": 0.5886222124099731, "test_mcc": 0.39685009162151713, "test_macro_f1": 0.693305405080053, "test_runtime": 3.9603, "test_samples_per_second": 517.132, "test_steps_per_second": 16.16}, {"test_loss": 0.594761073589325, "test_mcc": 0.377943188161411, "test_macro_f1": 0.6689288684973944, "test_runtime": 4.1187, "test_samples_per_second": 497.247, "test_steps_per_second": 15.539}]}, "total": {"test_mcc": 41.080548712574924, "test_mcc_se": 7.2806391702755215, "test_macro_f1": 69.7720549348763, "test_macro_f1_se": 3.753074425407163}}, "num_model_parameters": 118076162, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.5630568265914917, "test_mcc": 0.4790432156752981, "test_macro_f1": 0.7034489811830489, "test_runtime": 3.593, "test_samples_per_second": 569.995, "test_steps_per_second": 17.812}, {"test_loss": 0.5417424440383911, "test_mcc": 0.4714866992988028, "test_macro_f1": 0.7221627203159178, "test_runtime": 3.6477, "test_samples_per_second": 561.451, "test_steps_per_second": 17.545}, {"test_loss": 0.693795919418335, "test_mcc": 0.023276747474163847, "test_macro_f1": 0.49998635576485834, "test_runtime": 3.6011, "test_samples_per_second": 568.712, "test_steps_per_second": 17.772}, {"test_loss": 0.5552384853363037, "test_mcc": 0.44286395873636414, "test_macro_f1": 0.7170280350341207, "test_runtime": 3.6748, "test_samples_per_second": 557.306, "test_steps_per_second": 17.416}, {"test_loss": 0.5695903301239014, "test_mcc": 0.4203679196968095, "test_macro_f1": 0.6839693750370942, "test_runtime": 3.6504, "test_samples_per_second": 561.038, "test_steps_per_second": 17.532}, {"test_loss": 0.5354016423225403, "test_mcc": 0.5228407970668815, "test_macro_f1": 0.7593284149179965, "test_runtime": 3.513, "test_samples_per_second": 582.981, "test_steps_per_second": 18.218}, {"test_loss": 0.6901466250419617, "test_mcc": 0.10447815145368765, "test_macro_f1": 0.5136664587148578, "test_runtime": 3.5467, "test_samples_per_second": 577.441, "test_steps_per_second": 18.045}, {"test_loss": 0.6933090090751648, "test_mcc": 0.022827578426587346, "test_macro_f1": 0.4999979351205148, "test_runtime": 3.6047, "test_samples_per_second": 568.139, "test_steps_per_second": 17.754}, {"test_loss": 0.6039864420890808, "test_mcc": 0.3871152416099301, "test_macro_f1": 0.6683486480069067, "test_runtime": 3.567, "test_samples_per_second": 574.156, "test_steps_per_second": 17.942}, {"test_loss": 0.6458853483200073, "test_mcc": 0.27071089732299924, "test_macro_f1": 0.6004074802824959, "test_runtime": 3.6585, "test_samples_per_second": 559.785, "test_steps_per_second": 17.493}]}, "total": {"test_mcc": 31.450112067615244, "test_mcc_se": 12.117421145726622, "test_macro_f1": 63.683444043778124, "test_macro_f1_se": 6.209002709911021}}, "num_model_parameters": 118076162, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6087548732757568, "test_mcc": 0.4011708289874253, "test_macro_f1": 0.6788019004007784, "test_runtime": 3.855, "test_samples_per_second": 531.259, "test_steps_per_second": 16.602}, {"test_loss": 0.5440487265586853, "test_mcc": 0.4762791756805845, "test_macro_f1": 0.7371219271515783, "test_runtime": 3.8667, "test_samples_per_second": 529.651, "test_steps_per_second": 16.552}, {"test_loss": 0.6864145398139954, "test_mcc": 0.1299620281503185, "test_macro_f1": 0.5508393083087305, "test_runtime": 3.9027, "test_samples_per_second": 524.765, "test_steps_per_second": 16.399}, {"test_loss": 0.6009655594825745, "test_mcc": 0.38992757309066256, "test_macro_f1": 0.6849994942102304, "test_runtime": 3.6684, "test_samples_per_second": 558.276, "test_steps_per_second": 17.446}, {"test_loss": 0.5608117580413818, "test_mcc": 0.4452763863097528, "test_macro_f1": 0.7197302530675307, "test_runtime": 3.7197, "test_samples_per_second": 550.585, "test_steps_per_second": 17.206}, {"test_loss": 0.5692715644836426, "test_mcc": 0.44110587516442207, "test_macro_f1": 0.718479704509229, "test_runtime": 3.8481, "test_samples_per_second": 532.205, "test_steps_per_second": 16.631}, {"test_loss": 0.6915356516838074, "test_mcc": 0.07690372338885451, "test_macro_f1": 0.4985679537412829, "test_runtime": 3.74, "test_samples_per_second": 547.588, "test_steps_per_second": 17.112}, {"test_loss": 0.5709046125411987, "test_mcc": 0.40711949155110017, "test_macro_f1": 0.6966150655507, "test_runtime": 3.7368, "test_samples_per_second": 548.066, "test_steps_per_second": 17.127}, {"test_loss": 0.5688865780830383, "test_mcc": 0.42162034824298206, "test_macro_f1": 0.7079451443266616, "test_runtime": 3.7445, "test_samples_per_second": 546.937, "test_steps_per_second": 17.092}, {"test_loss": 0.5787106156349182, "test_mcc": 0.4222439908627711, "test_macro_f1": 0.7046735337915443, "test_runtime": 3.8248, "test_samples_per_second": 535.455, "test_steps_per_second": 16.733}]}, "total": {"test_mcc": 36.11609421428874, "test_mcc_se": 8.5907964701538, "test_macro_f1": 66.97774285058266, "test_macro_f1_se": 4.913890318344801}}, "num_model_parameters": 118076162, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_em": 46.940356312935705, "test_f1": 51.580822097269596}, {"test_em": 51.31782945736434, "test_f1": 55.17214115477363}, {"test_em": 52.16383307573416, "test_f1": 56.166276423046185}, {"test_em": 47.50778816199377, "test_f1": 51.08272212849595}, {"test_em": 48.648648648648646, "test_f1": 52.59844346022062}, {"test_em": 45.02698535080956, "test_f1": 49.5624555498019}, {"test_em": 51.93621867881549, "test_f1": 55.8526549444069}, {"test_em": 46.625290923196275, "test_f1": 50.70849437606613}, {"test_em": 47.76470588235294, "test_f1": 52.27483179049379}, {"test_em": 51.24223602484472, "test_f1": 55.17633949719595}]}, "total": {"test_em": 48.917389251669555, "test_em_se": 1.580273376418575, "test_f1": 53.01751814217706, "test_f1_se": 1.4762930169634443}}, "num_model_parameters": 117485570, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_em": 48.56700232378002, "test_f1": 52.736419843377035}, {"test_em": 47.36434108527132, "test_f1": 52.40653717261102}, {"test_em": 47.913446676970636, "test_f1": 52.79918793377758}, {"test_em": 47.19626168224299, "test_f1": 52.118687031413785}, {"test_em": 48.88030888030888, "test_f1": 54.11258651836116}, {"test_em": 46.954510408635315, "test_f1": 51.954191814531484}, {"test_em": 46.16552771450266, "test_f1": 51.38648332266781}, {"test_em": 46.702870442203256, "test_f1": 51.85974970773467}, {"test_em": 45.01960784313726, "test_f1": 49.99707658927472}, {"test_em": 47.98136645962733, "test_f1": 52.87600633755779}]}, "total": {"test_em": 47.27452435166797, "test_em_se": 0.7131456393172504, "test_f1": 52.22469262713071, "test_f1_se": 0.6693331986162788}}, "num_model_parameters": 117485570, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_em": 44.69403563129357, "test_f1": 49.397108741210445}, {"test_em": 47.82945736434109, "test_f1": 52.64704915860506}, {"test_em": 47.990726429675426, "test_f1": 52.84516287241416}, {"test_em": 46.88473520249221, "test_f1": 51.307349684628086}, {"test_em": 44.633204633204635, "test_f1": 49.22447975566063}, {"test_em": 43.02235929067078, "test_f1": 45.863342089248036}, {"test_em": 45.86180713743356, "test_f1": 49.448894618238825}, {"test_em": 48.87509697439876, "test_f1": 53.62161110476817}, {"test_em": 46.431372549019606, "test_f1": 50.91435142085296}, {"test_em": 47.43788819875776, "test_f1": 52.21732438541445}]}, "total": {"test_em": 46.366068341128745, "test_em_se": 1.1265312706733897, "test_f1": 50.74866738310408, "test_f1_se": 1.4381520533148833}}, "num_model_parameters": 117485570, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6142253875732422, "test_mcc": 0.6170467066959637, "test_macro_f1": 0.5520954672298609, "test_runtime": 15.7914, "test_samples_per_second": 129.69, "test_steps_per_second": 16.211}, {"test_loss": 0.5780060291290283, "test_mcc": 0.6098426564216917, "test_macro_f1": 0.6403759760791754, "test_runtime": 15.1443, "test_samples_per_second": 135.232, "test_steps_per_second": 16.904}, {"test_loss": 0.6096426248550415, "test_mcc": 0.5848325437763399, "test_macro_f1": 0.5399362898372014, "test_runtime": 15.4477, "test_samples_per_second": 132.576, "test_steps_per_second": 16.572}, {"test_loss": 0.5719095468521118, "test_mcc": 0.6433577714212622, "test_macro_f1": 0.65941777801706, "test_runtime": 15.0635, "test_samples_per_second": 135.958, "test_steps_per_second": 16.995}, {"test_loss": 0.5499847531318665, "test_mcc": 0.6244060356910531, "test_macro_f1": 0.6312801405210194, "test_runtime": 14.9594, "test_samples_per_second": 136.904, "test_steps_per_second": 17.113}, {"test_loss": 0.5690419673919678, "test_mcc": 0.6336532030976725, "test_macro_f1": 0.637144101002537, "test_runtime": 15.3715, "test_samples_per_second": 133.233, "test_steps_per_second": 16.654}, {"test_loss": 0.5803875923156738, "test_mcc": 0.6168047861539963, "test_macro_f1": 0.5655081425144292, "test_runtime": 14.7901, "test_samples_per_second": 138.471, "test_steps_per_second": 17.309}, {"test_loss": 0.5976974368095398, "test_mcc": 0.5898787469542077, "test_macro_f1": 0.6243491296021305, "test_runtime": 15.8322, "test_samples_per_second": 129.357, "test_steps_per_second": 16.17}, {"test_loss": 0.5689308643341064, "test_mcc": 0.6167770162298705, "test_macro_f1": 0.5513604791858554, "test_runtime": 15.7697, "test_samples_per_second": 129.87, "test_steps_per_second": 16.234}, {"test_loss": 0.5386260747909546, "test_mcc": 0.6410861816481682, "test_macro_f1": 0.6926419636936204, "test_runtime": 15.2995, "test_samples_per_second": 133.861, "test_steps_per_second": 16.733}]}, "total": {"test_mcc": 61.77685648090227, "test_mcc_se": 1.208714882692485, "test_macro_f1": 60.94109467682889, "test_macro_f1_se": 3.2840358954338233}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.9213424921035767, "test_mcc": 0.34364977850865, "test_macro_f1": 0.550834034000959, "test_runtime": 4.7765, "test_samples_per_second": 428.763, "test_steps_per_second": 13.399}, {"test_loss": 0.9640015363693237, "test_mcc": 0.29696991553625585, "test_macro_f1": 0.479861891288672, "test_runtime": 4.7477, "test_samples_per_second": 431.371, "test_steps_per_second": 13.48}, {"test_loss": 1.0423901081085205, "test_mcc": 0.30426586765372443, "test_macro_f1": 0.5311233616562409, "test_runtime": 4.7241, "test_samples_per_second": 433.521, "test_steps_per_second": 13.548}, {"test_loss": 0.9583628177642822, "test_mcc": 0.3614944383160173, "test_macro_f1": 0.5736563614972895, "test_runtime": 4.7402, "test_samples_per_second": 432.053, "test_steps_per_second": 13.502}, {"test_loss": 0.987755537033081, "test_mcc": 0.2779865977163312, "test_macro_f1": 0.50371598850773, "test_runtime": 4.6918, "test_samples_per_second": 436.503, "test_steps_per_second": 13.641}, {"test_loss": 0.9872732758522034, "test_mcc": 0.34508755694028787, "test_macro_f1": 0.543150828513843, "test_runtime": 4.771, "test_samples_per_second": 429.263, "test_steps_per_second": 13.414}, {"test_loss": 0.9372848272323608, "test_mcc": 0.3206074257935042, "test_macro_f1": 0.5338339738624028, "test_runtime": 4.8603, "test_samples_per_second": 421.376, "test_steps_per_second": 13.168}, {"test_loss": 0.993547260761261, "test_mcc": 0.30001715113404687, "test_macro_f1": 0.505760822910584, "test_runtime": 4.7801, "test_samples_per_second": 428.443, "test_steps_per_second": 13.389}, {"test_loss": 0.9159544706344604, "test_mcc": 0.34899310439708986, "test_macro_f1": 0.5626877897607909, "test_runtime": 4.7496, "test_samples_per_second": 431.196, "test_steps_per_second": 13.475}, {"test_loss": 1.0315821170806885, "test_mcc": 0.3388050861075529, "test_macro_f1": 0.5451326370370121, "test_runtime": 4.701, "test_samples_per_second": 435.653, "test_steps_per_second": 13.614}]}, "total": {"test_mcc": 32.37876922103461, "test_mcc_se": 1.7166646431474142, "test_macro_f1": 53.297576890355245, "test_macro_f1_se": 1.792801150152672}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.8770800828933716, "test_mcc": 0.3832475204746717, "test_macro_f1": 0.5657725623597055, "test_runtime": 3.7883, "test_samples_per_second": 540.61, "test_steps_per_second": 16.894}, {"test_loss": 0.8393889665603638, "test_mcc": 0.37579616690645085, "test_macro_f1": 0.5169437211100653, "test_runtime": 3.5391, "test_samples_per_second": 578.684, "test_steps_per_second": 18.084}, {"test_loss": 0.8699749708175659, "test_mcc": 0.36779858917408165, "test_macro_f1": 0.5451925852938194, "test_runtime": 3.5489, "test_samples_per_second": 577.083, "test_steps_per_second": 18.034}, {"test_loss": 0.9468273520469666, "test_mcc": 0.31608065697296694, "test_macro_f1": 0.4277866426728713, "test_runtime": 3.6013, "test_samples_per_second": 568.688, "test_steps_per_second": 17.771}, {"test_loss": 0.8440003395080566, "test_mcc": 0.37155942220067567, "test_macro_f1": 0.471566709710332, "test_runtime": 3.6506, "test_samples_per_second": 561.006, "test_steps_per_second": 17.531}, {"test_loss": 0.8506660461425781, "test_mcc": 0.3863238179156828, "test_macro_f1": 0.4482439295071698, "test_runtime": 3.7357, "test_samples_per_second": 548.218, "test_steps_per_second": 17.132}, {"test_loss": 0.8919626474380493, "test_mcc": 0.3776733686152667, "test_macro_f1": 0.5263925523169067, "test_runtime": 3.6133, "test_samples_per_second": 566.793, "test_steps_per_second": 17.712}, {"test_loss": 0.8659400939941406, "test_mcc": 0.33863844221228195, "test_macro_f1": 0.4357180367089792, "test_runtime": 3.658, "test_samples_per_second": 559.862, "test_steps_per_second": 17.496}, {"test_loss": 0.891690194606781, "test_mcc": 0.3000542258581273, "test_macro_f1": 0.4208057168392722, "test_runtime": 3.7726, "test_samples_per_second": 542.858, "test_steps_per_second": 16.964}, {"test_loss": 0.8690339922904968, "test_mcc": 0.37010885645162356, "test_macro_f1": 0.5354696734404062, "test_runtime": 3.7804, "test_samples_per_second": 541.737, "test_steps_per_second": 16.929}]}, "total": {"test_mcc": 35.872810667818285, "test_mcc_se": 1.8541812036068348, "test_macro_f1": 48.93892129959528, "test_macro_f1_se": 3.3689507605271207}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.06505447626113892, "test_micro_f1": 0.6597938144329897, "test_micro_f1_no_misc": 0.7328072153325818, "test_runtime": 7.8789, "test_samples_per_second": 259.935, "test_steps_per_second": 8.123}, {"test_loss": 0.056556329131126404, "test_micro_f1": 0.723607427055703, "test_micro_f1_no_misc": 0.8088607594936709, "test_runtime": 7.1167, "test_samples_per_second": 287.776, "test_steps_per_second": 8.993}, {"test_loss": 0.058472611010074615, "test_micro_f1": 0.7018393030009681, "test_micro_f1_no_misc": 0.7494600431965442, "test_runtime": 7.0612, "test_samples_per_second": 290.037, "test_steps_per_second": 9.064}, {"test_loss": 0.05704586207866669, "test_micro_f1": 0.7044334975369458, "test_micro_f1_no_misc": 0.750411409764125, "test_runtime": 7.5149, "test_samples_per_second": 272.527, "test_steps_per_second": 8.516}, {"test_loss": 0.06475205719470978, "test_micro_f1": 0.7113253012048192, "test_micro_f1_no_misc": 0.7664670658682636, "test_runtime": 7.6408, "test_samples_per_second": 268.036, "test_steps_per_second": 8.376}, {"test_loss": 0.060328058898448944, "test_micro_f1": 0.7141509433962264, "test_micro_f1_no_misc": 0.7602591792656587, "test_runtime": 5.9849, "test_samples_per_second": 342.196, "test_steps_per_second": 10.694}, {"test_loss": 0.06197626516222954, "test_micro_f1": 0.6851106639839033, "test_micro_f1_no_misc": 0.7573487031700289, "test_runtime": 6.6455, "test_samples_per_second": 308.18, "test_steps_per_second": 9.631}, {"test_loss": 0.060290850698947906, "test_micro_f1": 0.7104166666666667, "test_micro_f1_no_misc": 0.7575577949021932, "test_runtime": 7.7036, "test_samples_per_second": 265.849, "test_steps_per_second": 8.308}, {"test_loss": 0.0628461167216301, "test_micro_f1": 0.7205607476635515, "test_micro_f1_no_misc": 0.7827027027027027, "test_runtime": 7.3946, "test_samples_per_second": 276.959, "test_steps_per_second": 8.655}, {"test_loss": 0.056882865726947784, "test_micro_f1": 0.7014997581035317, "test_micro_f1_no_misc": 0.7627302275189599, "test_runtime": 7.4858, "test_samples_per_second": 273.583, "test_steps_per_second": 8.549}]}, "total": {"test_micro_f1": 70.32738123045306, "test_micro_f1_se": 1.163852953463262, "test_micro_f1_no_misc": 76.28605101214728, "test_micro_f1_no_misc_se": 1.2778937185306216}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.05777750909328461, "test_micro_f1": 0.8071979434447301, "test_micro_f1_no_misc": 0.8288659793814434, "test_runtime": 9.0028, "test_samples_per_second": 227.484, "test_steps_per_second": 7.109}, {"test_loss": 0.06148834899067879, "test_micro_f1": 0.8056022408963586, "test_micro_f1_no_misc": 0.8229243203526819, "test_runtime": 6.845, "test_samples_per_second": 299.197, "test_steps_per_second": 9.35}, {"test_loss": 0.06486859917640686, "test_micro_f1": 0.7357648911046969, "test_micro_f1_no_misc": 0.7643865363735071, "test_runtime": 9.09, "test_samples_per_second": 225.303, "test_steps_per_second": 7.041}, {"test_loss": 0.06865698099136353, "test_micro_f1": 0.8186555497655028, "test_micro_f1_no_misc": 0.8304011259676285, "test_runtime": 8.6111, "test_samples_per_second": 237.832, "test_steps_per_second": 7.432}, {"test_loss": 0.06283745169639587, "test_micro_f1": 0.792156862745098, "test_micro_f1_no_misc": 0.8136882129277566, "test_runtime": 9.1101, "test_samples_per_second": 224.805, "test_steps_per_second": 7.025}, {"test_loss": 0.06485484540462494, "test_micro_f1": 0.8419580419580419, "test_micro_f1_no_misc": 0.8504708097928436, "test_runtime": 8.8269, "test_samples_per_second": 232.017, "test_steps_per_second": 7.251}, {"test_loss": 0.06527524441480637, "test_micro_f1": 0.8271571544495536, "test_micro_f1_no_misc": 0.8506819813352477, "test_runtime": 9.1231, "test_samples_per_second": 224.485, "test_steps_per_second": 7.015}, {"test_loss": 0.05344543606042862, "test_micro_f1": 0.8061589221886171, "test_micro_f1_no_misc": 0.826930113428467, "test_runtime": 8.9406, "test_samples_per_second": 229.067, "test_steps_per_second": 7.158}, {"test_loss": 0.06686302274465561, "test_micro_f1": 0.7957860615883307, "test_micro_f1_no_misc": 0.8182481751824817, "test_runtime": 8.5809, "test_samples_per_second": 238.671, "test_steps_per_second": 7.458}, {"test_loss": 0.06425094604492188, "test_micro_f1": 0.7937784928935372, "test_micro_f1_no_misc": 0.8109647561409754, "test_runtime": 7.2218, "test_samples_per_second": 283.584, "test_steps_per_second": 8.862}]}, "total": {"test_micro_f1": 80.24216161034467, "test_micro_f1_se": 1.7473011127497688, "test_micro_f1_no_misc": 82.17562010883033, "test_micro_f1_no_misc_se": 1.5040549911519088}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.03891776129603386, "test_micro_f1": 0.8385454545454546, "test_micro_f1_no_misc": 0.8734125358459648, "test_runtime": 6.6528, "test_samples_per_second": 307.839, "test_steps_per_second": 9.62}, {"test_loss": 0.03781013935804367, "test_micro_f1": 0.8586309523809523, "test_micro_f1_no_misc": 0.8816666666666666, "test_runtime": 6.7304, "test_samples_per_second": 304.29, "test_steps_per_second": 9.509}, {"test_loss": 0.03972809016704559, "test_micro_f1": 0.8573431475639678, "test_micro_f1_no_misc": 0.8990019960079839, "test_runtime": 6.3437, "test_samples_per_second": 322.839, "test_steps_per_second": 10.089}, {"test_loss": 0.03629952296614647, "test_micro_f1": 0.8684950773558368, "test_micro_f1_no_misc": 0.8909019298936589, "test_runtime": 6.177, "test_samples_per_second": 331.551, "test_steps_per_second": 10.361}, {"test_loss": 0.03440145030617714, "test_micro_f1": 0.8784604996623904, "test_micro_f1_no_misc": 0.9056745584366779, "test_runtime": 6.6655, "test_samples_per_second": 307.255, "test_steps_per_second": 9.602}, {"test_loss": 0.035941846668720245, "test_micro_f1": 0.8502546689303906, "test_micro_f1_no_misc": 0.8874573702159909, "test_runtime": 6.7043, "test_samples_per_second": 305.474, "test_steps_per_second": 9.546}, {"test_loss": 0.03528716042637825, "test_micro_f1": 0.8492307692307693, "test_micro_f1_no_misc": 0.8823753330795585, "test_runtime": 6.187, "test_samples_per_second": 331.018, "test_steps_per_second": 10.344}, {"test_loss": 0.036168165504932404, "test_micro_f1": 0.859009628610729, "test_micro_f1_no_misc": 0.8880569075252714, "test_runtime": 6.2515, "test_samples_per_second": 327.599, "test_steps_per_second": 10.237}, {"test_loss": 0.03937827795743942, "test_micro_f1": 0.8261787473610135, "test_micro_f1_no_misc": 0.8651014723438122, "test_runtime": 6.2649, "test_samples_per_second": 326.899, "test_steps_per_second": 10.216}, {"test_loss": 0.04286099597811699, "test_micro_f1": 0.8631217838765008, "test_micro_f1_no_misc": 0.8987823439878234, "test_runtime": 6.5402, "test_samples_per_second": 313.138, "test_steps_per_second": 9.786}]}, "total": {"test_micro_f1": 85.49270729518005, "test_micro_f1_se": 0.9217309663804727, "test_micro_f1_no_misc": 88.72431114003409, "test_micro_f1_no_misc_se": 0.7623500343983538}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.05488717928528786, "test_micro_f1": 0.7550397067806964, "test_micro_f1_no_misc": 0.7978253482840639, "test_runtime": 6.1064, "test_samples_per_second": 335.384, "test_steps_per_second": 10.481}, {"test_loss": 0.053838521242141724, "test_micro_f1": 0.7963691376701966, "test_micro_f1_no_misc": 0.8384279475982532, "test_runtime": 6.3495, "test_samples_per_second": 322.545, "test_steps_per_second": 10.08}, {"test_loss": 0.060319364070892334, "test_micro_f1": 0.7862362971985385, "test_micro_f1_no_misc": 0.8289738430583501, "test_runtime": 6.1232, "test_samples_per_second": 334.466, "test_steps_per_second": 10.452}, {"test_loss": 0.062212876975536346, "test_micro_f1": 0.7689996996094922, "test_micro_f1_no_misc": 0.8037258815701929, "test_runtime": 6.3543, "test_samples_per_second": 322.304, "test_steps_per_second": 10.072}, {"test_loss": 0.056380704045295715, "test_micro_f1": 0.8, "test_micro_f1_no_misc": 0.8350515463917526, "test_runtime": 6.1006, "test_samples_per_second": 335.704, "test_steps_per_second": 10.491}, {"test_loss": 0.05071951821446419, "test_micro_f1": 0.8285970685013461, "test_micro_f1_no_misc": 0.8635752688172043, "test_runtime": 6.1862, "test_samples_per_second": 331.059, "test_steps_per_second": 10.346}, {"test_loss": 0.05244777351617813, "test_micro_f1": 0.7899002493765587, "test_micro_f1_no_misc": 0.8302143586253827, "test_runtime": 6.392, "test_samples_per_second": 320.402, "test_steps_per_second": 10.013}, {"test_loss": 0.05583024397492409, "test_micro_f1": 0.8074418604651162, "test_micro_f1_no_misc": 0.8387538514207463, "test_runtime": 6.422, "test_samples_per_second": 318.904, "test_steps_per_second": 9.966}, {"test_loss": 0.05721787363290787, "test_micro_f1": 0.7830882352941176, "test_micro_f1_no_misc": 0.821625344352617, "test_runtime": 5.8702, "test_samples_per_second": 348.883, "test_steps_per_second": 10.903}, {"test_loss": 0.05029481649398804, "test_micro_f1": 0.8205445544554456, "test_micro_f1_no_misc": 0.8495634654130289, "test_runtime": 5.9962, "test_samples_per_second": 341.547, "test_steps_per_second": 10.673}]}, "total": {"test_micro_f1": 79.36216809351508, "test_micro_f1_se": 1.3799886014735432, "test_micro_f1_no_misc": 83.07736855531591, "test_micro_f1_no_misc_se": 1.2177249365318044}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.5152755975723267, "test_mcc": 0.5513867337425145, "test_macro_f1": 0.7721634786627668, "test_runtime": 3.6292, "test_samples_per_second": 564.316, "test_steps_per_second": 17.635}, {"test_loss": 0.5418097376823425, "test_mcc": 0.4857840703433363, "test_macro_f1": 0.725643976203715, "test_runtime": 3.7683, "test_samples_per_second": 543.474, "test_steps_per_second": 16.984}, {"test_loss": 0.5446720123291016, "test_mcc": 0.5191902317199898, "test_macro_f1": 0.7527270470308935, "test_runtime": 3.8058, "test_samples_per_second": 538.132, "test_steps_per_second": 16.817}, {"test_loss": 0.5256133079528809, "test_mcc": 0.5358830658391861, "test_macro_f1": 0.7649045587589709, "test_runtime": 3.6916, "test_samples_per_second": 554.769, "test_steps_per_second": 17.337}, {"test_loss": 0.5424727201461792, "test_mcc": 0.5079036455325067, "test_macro_f1": 0.7503913091462215, "test_runtime": 3.7232, "test_samples_per_second": 550.07, "test_steps_per_second": 17.19}, {"test_loss": 0.5572378635406494, "test_mcc": 0.5110616983610379, "test_macro_f1": 0.7553346357696906, "test_runtime": 3.6701, "test_samples_per_second": 558.02, "test_steps_per_second": 17.438}, {"test_loss": 0.6834044456481934, "test_mcc": 0.12839553860933345, "test_macro_f1": 0.5153764581124072, "test_runtime": 3.7682, "test_samples_per_second": 543.498, "test_steps_per_second": 16.984}, {"test_loss": 0.5852982997894287, "test_mcc": 0.49365156214670003, "test_macro_f1": 0.7433171452298672, "test_runtime": 3.7243, "test_samples_per_second": 549.901, "test_steps_per_second": 17.184}, {"test_loss": 0.5527313947677612, "test_mcc": 0.5139411371239287, "test_macro_f1": 0.7562987917146282, "test_runtime": 3.7119, "test_samples_per_second": 551.737, "test_steps_per_second": 17.242}, {"test_loss": 0.49938294291496277, "test_mcc": 0.526355045057058, "test_macro_f1": 0.7619817985912821, "test_runtime": 3.7819, "test_samples_per_second": 541.529, "test_steps_per_second": 16.923}]}, "total": {"test_mcc": 47.73552728475591, "test_mcc_se": 7.690892334436664, "test_macro_f1": 72.98139199220444, "test_macro_f1_se": 4.7358310806374915}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6928333044052124, "test_mcc": 0.0777299799075793, "test_macro_f1": 0.43026080518957377, "test_runtime": 4.0109, "test_samples_per_second": 510.614, "test_steps_per_second": 15.957}, {"test_loss": 0.6009801626205444, "test_mcc": 0.40621297419601277, "test_macro_f1": 0.6890896713905563, "test_runtime": 4.1908, "test_samples_per_second": 488.685, "test_steps_per_second": 15.271}, {"test_loss": 0.6928828954696655, "test_mcc": 0.028823621398927878, "test_macro_f1": 0.5074136955291455, "test_runtime": 4.1014, "test_samples_per_second": 499.347, "test_steps_per_second": 15.605}, {"test_loss": 0.5867140293121338, "test_mcc": 0.4322556300106786, "test_macro_f1": 0.7059619228166512, "test_runtime": 4.2739, "test_samples_per_second": 479.183, "test_steps_per_second": 14.974}, {"test_loss": 0.577628493309021, "test_mcc": 0.42418469185412894, "test_macro_f1": 0.7073724587648638, "test_runtime": 4.0434, "test_samples_per_second": 506.499, "test_steps_per_second": 15.828}, {"test_loss": 0.6921992301940918, "test_mcc": 0.014425998902907298, "test_macro_f1": 0.5051579604410945, "test_runtime": 4.0333, "test_samples_per_second": 507.768, "test_steps_per_second": 15.868}, {"test_loss": 0.5868165493011475, "test_mcc": 0.3762552150240203, "test_macro_f1": 0.6855809383443872, "test_runtime": 3.9376, "test_samples_per_second": 520.119, "test_steps_per_second": 16.254}, {"test_loss": 0.6211338639259338, "test_mcc": 0.38871307730605414, "test_macro_f1": 0.6621061996074408, "test_runtime": 4.0258, "test_samples_per_second": 508.723, "test_steps_per_second": 15.898}, {"test_loss": 0.6799426674842834, "test_mcc": 0.16471478166228978, "test_macro_f1": 0.5611090376191048, "test_runtime": 4.0317, "test_samples_per_second": 507.977, "test_steps_per_second": 15.874}, {"test_loss": 0.5685853362083435, "test_mcc": 0.4799049638833347, "test_macro_f1": 0.7368125189802807, "test_runtime": 4.0757, "test_samples_per_second": 502.496, "test_steps_per_second": 15.703}]}, "total": {"test_mcc": 27.932209341459334, "test_mcc_se": 11.480178088667802, "test_macro_f1": 61.90865208683098, "test_macro_f1_se": 6.689599626391998}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.5532769560813904, "test_mcc": 0.45511130809049466, "test_macro_f1": 0.7120008811161853, "test_runtime": 3.6022, "test_samples_per_second": 568.544, "test_steps_per_second": 17.767}, {"test_loss": 0.584441602230072, "test_mcc": 0.4099819349572317, "test_macro_f1": 0.6822801660010963, "test_runtime": 3.5811, "test_samples_per_second": 571.885, "test_steps_per_second": 17.871}, {"test_loss": 0.6100953817367554, "test_mcc": 0.37252492720582536, "test_macro_f1": 0.6548427672955974, "test_runtime": 3.5677, "test_samples_per_second": 574.043, "test_steps_per_second": 17.939}, {"test_loss": 0.555361807346344, "test_mcc": 0.4355063199563737, "test_macro_f1": 0.7165113301799847, "test_runtime": 3.6539, "test_samples_per_second": 560.494, "test_steps_per_second": 17.515}, {"test_loss": 0.565767765045166, "test_mcc": 0.44191981777718115, "test_macro_f1": 0.7006361990905836, "test_runtime": 3.6848, "test_samples_per_second": 555.798, "test_steps_per_second": 17.369}, {"test_loss": 0.5235373973846436, "test_mcc": 0.5170110531958841, "test_macro_f1": 0.7571619682013297, "test_runtime": 3.4973, "test_samples_per_second": 585.587, "test_steps_per_second": 18.3}, {"test_loss": 0.5407294034957886, "test_mcc": 0.47747323723397445, "test_macro_f1": 0.7376294844996945, "test_runtime": 3.5504, "test_samples_per_second": 576.831, "test_steps_per_second": 18.026}, {"test_loss": 0.5968109965324402, "test_mcc": 0.5017725117447991, "test_macro_f1": 0.7379825653798255, "test_runtime": 3.5873, "test_samples_per_second": 570.9, "test_steps_per_second": 17.841}, {"test_loss": 0.642433226108551, "test_mcc": 0.3502042346847449, "test_macro_f1": 0.602814752013565, "test_runtime": 3.5086, "test_samples_per_second": 583.71, "test_steps_per_second": 18.241}, {"test_loss": 0.5753657817840576, "test_mcc": 0.46086482589484296, "test_macro_f1": 0.7294261294261293, "test_runtime": 3.6379, "test_samples_per_second": 562.956, "test_steps_per_second": 17.592}]}, "total": {"test_mcc": 44.22370170741352, "test_mcc_se": 3.286569756168827, "test_macro_f1": 70.3128624320399, "test_macro_f1_se": 2.855997081997218}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.5859825611114502, "test_mcc": 0.38999945863990876, "test_macro_f1": 0.678531780103727, "test_runtime": 3.6869, "test_samples_per_second": 555.485, "test_steps_per_second": 17.359}, {"test_loss": 0.5758495330810547, "test_mcc": 0.4060250043430841, "test_macro_f1": 0.7018530200830497, "test_runtime": 3.8163, "test_samples_per_second": 536.639, "test_steps_per_second": 16.77}, {"test_loss": 0.5931164622306824, "test_mcc": 0.41948802647596956, "test_macro_f1": 0.7011728166241915, "test_runtime": 3.7823, "test_samples_per_second": 541.475, "test_steps_per_second": 16.921}, {"test_loss": 0.5739297866821289, "test_mcc": 0.41127251700922174, "test_macro_f1": 0.700849593528323, "test_runtime": 3.6023, "test_samples_per_second": 568.523, "test_steps_per_second": 17.766}, {"test_loss": 0.5876585245132446, "test_mcc": 0.46001818445169196, "test_macro_f1": 0.7231453531472428, "test_runtime": 3.6798, "test_samples_per_second": 556.547, "test_steps_per_second": 17.392}, {"test_loss": 0.5906895995140076, "test_mcc": 0.4207275373340495, "test_macro_f1": 0.6719313988050613, "test_runtime": 3.7763, "test_samples_per_second": 542.335, "test_steps_per_second": 16.948}, {"test_loss": 0.69121253490448, "test_mcc": 0.08213352594557807, "test_macro_f1": 0.5398978338684244, "test_runtime": 3.7062, "test_samples_per_second": 552.583, "test_steps_per_second": 17.268}, {"test_loss": 0.611038327217102, "test_mcc": 0.4436886705329554, "test_macro_f1": 0.7057972680042641, "test_runtime": 3.6996, "test_samples_per_second": 553.574, "test_steps_per_second": 17.299}, {"test_loss": 0.6073558926582336, "test_mcc": 0.4483139041374435, "test_macro_f1": 0.7205741480709709, "test_runtime": 3.651, "test_samples_per_second": 560.94, "test_steps_per_second": 17.529}, {"test_loss": 0.5838330388069153, "test_mcc": 0.47315290913066155, "test_macro_f1": 0.7213687260198889, "test_runtime": 3.7825, "test_samples_per_second": 541.441, "test_steps_per_second": 16.92}]}, "total": {"test_mcc": 39.54819738000565, "test_mcc_se": 7.009393736146692, "test_macro_f1": 68.65121938255143, "test_macro_f1_se": 3.3643171459545487}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_em": 43.14484895429899, "test_f1": 46.63913271008699}, {"test_em": 51.08527131782946, "test_f1": 54.893841895551866}, {"test_em": 46.59969088098918, "test_f1": 51.08445347620798}, {"test_em": 46.80685358255452, "test_f1": 51.41973506624051}, {"test_em": 44.01544401544402, "test_f1": 48.29038340669398}, {"test_em": 51.19506553585197, "test_f1": 55.505492619644855}, {"test_em": 49.73424449506454, "test_f1": 53.858222685101936}, {"test_em": 51.7455391776571, "test_f1": 55.68491557712087}, {"test_em": 45.568627450980394, "test_f1": 50.531329344087}, {"test_em": 48.75776397515528, "test_f1": 52.995402022164896}]}, "total": {"test_em": 47.86533493858255, "test_em_se": 1.914858416964625, "test_f1": 52.09029088029009, "test_f1_se": 1.8984451833810656}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_em": 43.29976762199845, "test_f1": 47.92935728049144}, {"test_em": 49.92248062015504, "test_f1": 54.69860797623773}, {"test_em": 46.36785162287481, "test_f1": 51.2043871564614}, {"test_em": 50.93457943925234, "test_f1": 55.354934286623894}, {"test_em": 47.49034749034749, "test_f1": 51.894098409357134}, {"test_em": 47.879722436391674, "test_f1": 52.875629665955515}, {"test_em": 43.28018223234624, "test_f1": 47.834658780134696}, {"test_em": 48.33204034134988, "test_f1": 53.008901988046766}, {"test_em": 49.01960784313726, "test_f1": 53.591828189752036}, {"test_em": 50.15527950310559, "test_f1": 55.31643486987879}]}, "total": {"test_em": 47.668185915095876, "test_em_se": 1.6567990755622901, "test_f1": 52.370883860293944, "test_f1_se": 1.6916691638107597}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_em": 50.65840433772269, "test_f1": 54.96797870345507}, {"test_em": 46.04651162790697, "test_f1": 50.57398012208275}, {"test_em": 49.61360123647604, "test_f1": 54.41590566397367}, {"test_em": 44.23676012461059, "test_f1": 48.098936328479745}, {"test_em": 45.63706563706564, "test_f1": 51.13898037604361}, {"test_em": 46.18350038550501, "test_f1": 50.55018838455234}, {"test_em": 48.13971146545178, "test_f1": 52.89838610468439}, {"test_em": 42.28083785880528, "test_f1": 47.68696150946411}, {"test_em": 50.666666666666664, "test_f1": 55.86043069145219}, {"test_em": 45.962732919254655, "test_f1": 51.16290107653584}]}, "total": {"test_em": 46.94257922594654, "test_em_se": 1.720396252425916, "test_f1": 51.73546489607237, "test_f1_se": 1.7168365243729362}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.5963630676269531, "test_mcc": 0.6107711743672342, "test_macro_f1": 0.5826765599635071, "test_runtime": 16.4478, "test_samples_per_second": 124.515, "test_steps_per_second": 15.564}, {"test_loss": 0.6036638021469116, "test_mcc": 0.6101802278939785, "test_macro_f1": 0.5760723260841419, "test_runtime": 15.872, "test_samples_per_second": 129.033, "test_steps_per_second": 16.129}, {"test_loss": 0.6073285341262817, "test_mcc": 0.5906648864497713, "test_macro_f1": 0.5448670938991852, "test_runtime": 16.1935, "test_samples_per_second": 126.47, "test_steps_per_second": 15.809}, {"test_loss": 0.5641547441482544, "test_mcc": 0.6392355986872454, "test_macro_f1": 0.5891203155219444, "test_runtime": 15.6971, "test_samples_per_second": 130.47, "test_steps_per_second": 16.309}, {"test_loss": 0.5660650730133057, "test_mcc": 0.628293889498181, "test_macro_f1": 0.6827796127147003, "test_runtime": 15.6269, "test_samples_per_second": 131.056, "test_steps_per_second": 16.382}, {"test_loss": 0.5548688769340515, "test_mcc": 0.641487810366787, "test_macro_f1": 0.6381428440772411, "test_runtime": 15.9805, "test_samples_per_second": 128.156, "test_steps_per_second": 16.019}, {"test_loss": 0.5534584522247314, "test_mcc": 0.6512812143594283, "test_macro_f1": 0.6310255444416825, "test_runtime": 15.4415, "test_samples_per_second": 132.629, "test_steps_per_second": 16.579}, {"test_loss": 0.6469855904579163, "test_mcc": 0.6266257285440643, "test_macro_f1": 0.6545195089672644, "test_runtime": 16.4394, "test_samples_per_second": 124.579, "test_steps_per_second": 15.572}, {"test_loss": 0.5527575016021729, "test_mcc": 0.6200584857012407, "test_macro_f1": 0.5579612699075566, "test_runtime": 16.3032, "test_samples_per_second": 125.619, "test_steps_per_second": 15.702}, {"test_loss": 0.551876425743103, "test_mcc": 0.6317695001590662, "test_macro_f1": 0.5997146759929707, "test_runtime": 15.8825, "test_samples_per_second": 128.947, "test_steps_per_second": 16.118}]}, "total": {"test_mcc": 62.503685160269974, "test_mcc_se": 1.1029364568946944, "test_macro_f1": 60.568797515701945, "test_macro_f1_se": 2.7499627906563804}}, "num_model_parameters": 151312131, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.928170919418335, "test_mcc": 0.34826609998372016, "test_macro_f1": 0.5616023085300484, "test_runtime": 4.8561, "test_samples_per_second": 421.741, "test_steps_per_second": 13.179}, {"test_loss": 0.9302829504013062, "test_mcc": 0.3353800541706581, "test_macro_f1": 0.539587181576095, "test_runtime": 4.8097, "test_samples_per_second": 425.804, "test_steps_per_second": 13.306}, {"test_loss": 0.9384738206863403, "test_mcc": 0.32104423413124145, "test_macro_f1": 0.5332950663026313, "test_runtime": 4.87, "test_samples_per_second": 420.534, "test_steps_per_second": 13.142}, {"test_loss": 0.9619055986404419, "test_mcc": 0.34756227336071294, "test_macro_f1": 0.5594234839071569, "test_runtime": 4.7442, "test_samples_per_second": 431.685, "test_steps_per_second": 13.49}, {"test_loss": 1.014394998550415, "test_mcc": 0.3161420247528365, "test_macro_f1": 0.5214771250906546, "test_runtime": 4.7036, "test_samples_per_second": 435.411, "test_steps_per_second": 13.607}, {"test_loss": 0.9822626709938049, "test_mcc": 0.3145655913931573, "test_macro_f1": 0.5307749811697854, "test_runtime": 4.8145, "test_samples_per_second": 425.382, "test_steps_per_second": 13.293}, {"test_loss": 0.9322720766067505, "test_mcc": 0.3540796040920286, "test_macro_f1": 0.5613063539595603, "test_runtime": 4.9998, "test_samples_per_second": 409.614, "test_steps_per_second": 12.8}, {"test_loss": 0.9958668947219849, "test_mcc": 0.3001148273399491, "test_macro_f1": 0.49662777695570254, "test_runtime": 4.7882, "test_samples_per_second": 427.719, "test_steps_per_second": 13.366}, {"test_loss": 0.9318208694458008, "test_mcc": 0.3463833564837823, "test_macro_f1": 0.5505860423356109, "test_runtime": 4.6997, "test_samples_per_second": 435.775, "test_steps_per_second": 13.618}, {"test_loss": 1.0087107419967651, "test_mcc": 0.30414010557960214, "test_macro_f1": 0.5010659216873145, "test_runtime": 4.8825, "test_samples_per_second": 419.458, "test_steps_per_second": 13.108}]}, "total": {"test_mcc": 32.876781712876884, "test_mcc_se": 1.2355456926539983, "test_macro_f1": 53.557462415145594, "test_macro_f1_se": 1.4731838846052614}}, "num_model_parameters": 151312131, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.8482414484024048, "test_mcc": 0.34864673787017214, "test_macro_f1": 0.48841967321337193, "test_runtime": 3.7698, "test_samples_per_second": 543.258, "test_steps_per_second": 16.977}, {"test_loss": 0.8549116849899292, "test_mcc": 0.34155010115436035, "test_macro_f1": 0.4878993655851567, "test_runtime": 3.5376, "test_samples_per_second": 578.927, "test_steps_per_second": 18.091}, {"test_loss": 0.8601347208023071, "test_mcc": 0.39363563642771104, "test_macro_f1": 0.5082694284682282, "test_runtime": 3.5609, "test_samples_per_second": 575.13, "test_steps_per_second": 17.973}, {"test_loss": 0.9197335243225098, "test_mcc": 0.34063353392503076, "test_macro_f1": 0.4539936801775337, "test_runtime": 3.5994, "test_samples_per_second": 568.989, "test_steps_per_second": 17.781}, {"test_loss": 0.8623231649398804, "test_mcc": 0.36480129175679243, "test_macro_f1": 0.4556299515489293, "test_runtime": 3.6447, "test_samples_per_second": 561.912, "test_steps_per_second": 17.56}, {"test_loss": 0.9478771090507507, "test_mcc": 0.36740134910712546, "test_macro_f1": 0.5299226415339257, "test_runtime": 3.7578, "test_samples_per_second": 545.003, "test_steps_per_second": 17.031}, {"test_loss": 0.843928337097168, "test_mcc": 0.4127009624565905, "test_macro_f1": 0.5670519771627384, "test_runtime": 3.6525, "test_samples_per_second": 560.719, "test_steps_per_second": 17.522}, {"test_loss": 0.8925704956054688, "test_mcc": 0.35260877307517147, "test_macro_f1": 0.4874945380131619, "test_runtime": 3.6647, "test_samples_per_second": 558.853, "test_steps_per_second": 17.464}, {"test_loss": 0.9013073444366455, "test_mcc": 0.3863904021137648, "test_macro_f1": 0.5432151293406644, "test_runtime": 3.7744, "test_samples_per_second": 542.607, "test_steps_per_second": 16.956}, {"test_loss": 0.8619292974472046, "test_mcc": 0.3125728326344989, "test_macro_f1": 0.42641073991944745, "test_runtime": 3.7646, "test_samples_per_second": 544.013, "test_steps_per_second": 17.0}]}, "total": {"test_mcc": 36.20941620521218, "test_mcc_se": 1.8231980222425423, "test_macro_f1": 49.48307124963158, "test_macro_f1_se": 2.6935741999336518}}, "num_model_parameters": 151312131, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.06281038373708725, "test_micro_f1": 0.673780487804878, "test_micro_f1_no_misc": 0.7379619260918253, "test_runtime": 7.8902, "test_samples_per_second": 259.563, "test_steps_per_second": 8.111}, {"test_loss": 0.05766606330871582, "test_micro_f1": 0.7123142250530785, "test_micro_f1_no_misc": 0.7595983461311282, "test_runtime": 7.3521, "test_samples_per_second": 278.559, "test_steps_per_second": 8.705}, {"test_loss": 0.059332430362701416, "test_micro_f1": 0.6729411764705882, "test_micro_f1_no_misc": 0.731525784157363, "test_runtime": 7.3758, "test_samples_per_second": 277.667, "test_steps_per_second": 8.677}, {"test_loss": 0.05751539394259453, "test_micro_f1": 0.6968810916179337, "test_micro_f1_no_misc": 0.7379162191192267, "test_runtime": 7.8444, "test_samples_per_second": 261.078, "test_steps_per_second": 8.159}, {"test_loss": 0.06084994971752167, "test_micro_f1": 0.6991272393201653, "test_micro_f1_no_misc": 0.7653167185877467, "test_runtime": 7.8099, "test_samples_per_second": 262.23, "test_steps_per_second": 8.195}, {"test_loss": 0.056074514985084534, "test_micro_f1": 0.7463666197843413, "test_micro_f1_no_misc": 0.8008634646519158, "test_runtime": 6.57, "test_samples_per_second": 311.722, "test_steps_per_second": 9.741}, {"test_loss": 0.06041131913661957, "test_micro_f1": 0.6940410615923887, "test_micro_f1_no_misc": 0.7429519071310117, "test_runtime": 7.2135, "test_samples_per_second": 283.911, "test_steps_per_second": 8.872}, {"test_loss": 0.055671997368335724, "test_micro_f1": 0.6824146981627297, "test_micro_f1_no_misc": 0.727485380116959, "test_runtime": 7.982, "test_samples_per_second": 256.576, "test_steps_per_second": 8.018}, {"test_loss": 0.060759998857975006, "test_micro_f1": 0.709090909090909, "test_micro_f1_no_misc": 0.7673649393605292, "test_runtime": 7.4739, "test_samples_per_second": 274.021, "test_steps_per_second": 8.563}, {"test_loss": 0.05633440241217613, "test_micro_f1": 0.7296094908551657, "test_micro_f1_no_misc": 0.7908571428571427, "test_runtime": 7.7824, "test_samples_per_second": 263.159, "test_steps_per_second": 8.224}]}, "total": {"test_micro_f1": 70.16566999752179, "test_micro_f1_se": 1.4621108731358932, "test_micro_f1_no_misc": 75.6184182820485, "test_micro_f1_no_misc_se": 1.5585857311230362}}, "num_model_parameters": 150726153, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.060955364257097244, "test_micro_f1": 0.8076923076923076, "test_micro_f1_no_misc": 0.8329281000347344, "test_runtime": 9.0099, "test_samples_per_second": 227.306, "test_steps_per_second": 7.103}, {"test_loss": 0.05946242809295654, "test_micro_f1": 0.8287075974208018, "test_micro_f1_no_misc": 0.844136926438456, "test_runtime": 6.9381, "test_samples_per_second": 295.181, "test_steps_per_second": 9.224}, {"test_loss": 0.05519044026732445, "test_micro_f1": 0.8184977278802459, "test_micro_f1_no_misc": 0.8465184104994531, "test_runtime": 9.1619, "test_samples_per_second": 223.534, "test_steps_per_second": 6.985}, {"test_loss": 0.06485049426555634, "test_micro_f1": 0.7600205549845838, "test_micro_f1_no_misc": 0.7852760736196319, "test_runtime": 8.6249, "test_samples_per_second": 237.453, "test_steps_per_second": 7.42}, {"test_loss": 0.06706783175468445, "test_micro_f1": 0.8087276848965712, "test_micro_f1_no_misc": 0.8276923076923077, "test_runtime": 9.2101, "test_samples_per_second": 222.364, "test_steps_per_second": 6.949}, {"test_loss": 0.0656881257891655, "test_micro_f1": 0.8023159636062863, "test_micro_f1_no_misc": 0.8312476298824422, "test_runtime": 8.898, "test_samples_per_second": 230.164, "test_steps_per_second": 7.193}, {"test_loss": 0.06827116012573242, "test_micro_f1": 0.7979553403282217, "test_micro_f1_no_misc": 0.8186114140312614, "test_runtime": 9.1328, "test_samples_per_second": 224.246, "test_steps_per_second": 7.008}, {"test_loss": 0.05605117976665497, "test_micro_f1": 0.7963424771404821, "test_micro_f1_no_misc": 0.8221574344023322, "test_runtime": 8.989, "test_samples_per_second": 227.833, "test_steps_per_second": 7.12}, {"test_loss": 0.06007864698767662, "test_micro_f1": 0.7968, "test_micro_f1_no_misc": 0.8050724637681159, "test_runtime": 8.6921, "test_samples_per_second": 235.617, "test_steps_per_second": 7.363}, {"test_loss": 0.06309795379638672, "test_micro_f1": 0.784178391292806, "test_micro_f1_no_misc": 0.8109258602341256, "test_runtime": 7.1417, "test_samples_per_second": 286.765, "test_steps_per_second": 8.961}]}, "total": {"test_micro_f1": 80.01238045242307, "test_micro_f1_se": 1.1656689793338801, "test_micro_f1_no_misc": 82.24566620602859, "test_micro_f1_no_misc_se": 1.1495301289522406}}, "num_model_parameters": 150726153, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.04494032263755798, "test_micro_f1": 0.7989877078814173, "test_micro_f1_no_misc": 0.8400646203554119, "test_runtime": 6.6381, "test_samples_per_second": 308.522, "test_steps_per_second": 9.641}, {"test_loss": 0.03505922481417656, "test_micro_f1": 0.858955223880597, "test_micro_f1_no_misc": 0.8803347280334728, "test_runtime": 6.6795, "test_samples_per_second": 306.611, "test_steps_per_second": 9.582}, {"test_loss": 0.04216469079256058, "test_micro_f1": 0.8469601677148848, "test_micro_f1_no_misc": 0.876280535855004, "test_runtime": 6.379, "test_samples_per_second": 321.052, "test_steps_per_second": 10.033}, {"test_loss": 0.040491215884685516, "test_micro_f1": 0.8480222068008327, "test_micro_f1_no_misc": 0.883116883116883, "test_runtime": 6.141, "test_samples_per_second": 333.495, "test_steps_per_second": 10.422}, {"test_loss": 0.034642551094293594, "test_micro_f1": 0.8806970509383378, "test_micro_f1_no_misc": 0.906855439642325, "test_runtime": 6.6832, "test_samples_per_second": 306.441, "test_steps_per_second": 9.576}, {"test_loss": 0.03840453922748566, "test_micro_f1": 0.8409321175278622, "test_micro_f1_no_misc": 0.8780126065999257, "test_runtime": 6.9287, "test_samples_per_second": 295.584, "test_steps_per_second": 9.237}, {"test_loss": 0.03576064854860306, "test_micro_f1": 0.8669882839421089, "test_micro_f1_no_misc": 0.8959938366718029, "test_runtime": 6.0979, "test_samples_per_second": 335.855, "test_steps_per_second": 10.495}, {"test_loss": 0.03731820359826088, "test_micro_f1": 0.836488812392427, "test_micro_f1_no_misc": 0.8669690098261527, "test_runtime": 6.2366, "test_samples_per_second": 328.383, "test_steps_per_second": 10.262}, {"test_loss": 0.03548238426446915, "test_micro_f1": 0.8369759942672877, "test_micro_f1_no_misc": 0.8657556270096464, "test_runtime": 6.3458, "test_samples_per_second": 322.735, "test_steps_per_second": 10.085}, {"test_loss": 0.039452485740184784, "test_micro_f1": 0.8690921455287318, "test_micro_f1_no_misc": 0.9055028462998104, "test_runtime": 6.5364, "test_samples_per_second": 313.322, "test_steps_per_second": 9.791}]}, "total": {"test_micro_f1": 84.84099710874489, "test_micro_f1_se": 1.4164146826649053, "test_micro_f1_no_misc": 87.98886133410434, "test_micro_f1_no_misc_se": 1.2434708352105521}}, "num_model_parameters": 150726153, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.056520480662584305, "test_micro_f1": 0.7966728280961183, "test_micro_f1_no_misc": 0.8342318059299192, "test_runtime": 6.2997, "test_samples_per_second": 325.095, "test_steps_per_second": 10.159}, {"test_loss": 0.05837664380669594, "test_micro_f1": 0.8256315465187923, "test_micro_f1_no_misc": 0.8576341127922972, "test_runtime": 6.3725, "test_samples_per_second": 321.382, "test_steps_per_second": 10.043}, {"test_loss": 0.05305171385407448, "test_micro_f1": 0.7809754619812178, "test_micro_f1_no_misc": 0.8292519288829252, "test_runtime": 6.1024, "test_samples_per_second": 335.608, "test_steps_per_second": 10.488}, {"test_loss": 0.06043282896280289, "test_micro_f1": 0.7369661266568481, "test_micro_f1_no_misc": 0.7853910795087266, "test_runtime": 6.3183, "test_samples_per_second": 324.139, "test_steps_per_second": 10.129}, {"test_loss": 0.06079074367880821, "test_micro_f1": 0.7792528558196975, "test_micro_f1_no_misc": 0.8299130434782608, "test_runtime": 6.0843, "test_samples_per_second": 336.602, "test_steps_per_second": 10.519}, {"test_loss": 0.05753500759601593, "test_micro_f1": 0.8064709406830437, "test_micro_f1_no_misc": 0.8375041708375043, "test_runtime": 6.0441, "test_samples_per_second": 338.841, "test_steps_per_second": 10.589}, {"test_loss": 0.05008258298039436, "test_micro_f1": 0.7902529302899445, "test_micro_f1_no_misc": 0.8401888064733649, "test_runtime": 6.4124, "test_samples_per_second": 319.38, "test_steps_per_second": 9.981}, {"test_loss": 0.055298514664173126, "test_micro_f1": 0.794989306446685, "test_micro_f1_no_misc": 0.8301634968301634, "test_runtime": 6.4671, "test_samples_per_second": 316.68, "test_steps_per_second": 9.896}, {"test_loss": 0.0606093592941761, "test_micro_f1": 0.8022249690976514, "test_micro_f1_no_misc": 0.833391304347826, "test_runtime": 5.7858, "test_samples_per_second": 353.969, "test_steps_per_second": 11.062}, {"test_loss": 0.0494706854224205, "test_micro_f1": 0.8048411497730712, "test_micro_f1_no_misc": 0.8327332242225859, "test_runtime": 6.1073, "test_samples_per_second": 335.337, "test_steps_per_second": 10.479}]}, "total": {"test_micro_f1": 79.18278115363069, "test_micro_f1_se": 1.454487659240351, "test_micro_f1_no_misc": 83.10402973303574, "test_micro_f1_no_misc_se": 1.1203048823150459}}, "num_model_parameters": 150726153, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.6125656366348267, "test_mcc": 0.3999052921891072, "test_macro_f1": 0.6537962560078421, "test_runtime": 3.7665, "test_samples_per_second": 543.743, "test_steps_per_second": 16.992}, {"test_loss": 0.5872130393981934, "test_mcc": 0.35838441658645437, "test_macro_f1": 0.6633567642907928, "test_runtime": 3.9664, "test_samples_per_second": 516.34, "test_steps_per_second": 16.136}, {"test_loss": 0.5459171533584595, "test_mcc": 0.4506333352371356, "test_macro_f1": 0.7191761108984578, "test_runtime": 4.012, "test_samples_per_second": 510.468, "test_steps_per_second": 15.952}, {"test_loss": 0.6202934980392456, "test_mcc": 0.4634697525129441, "test_macro_f1": 0.7316955659868806, "test_runtime": 3.893, "test_samples_per_second": 526.068, "test_steps_per_second": 16.44}, {"test_loss": 0.5807281136512756, "test_mcc": 0.39548018947355157, "test_macro_f1": 0.6866925943049851, "test_runtime": 3.9646, "test_samples_per_second": 516.569, "test_steps_per_second": 16.143}, {"test_loss": 0.6914458870887756, "test_mcc": 0.07124142614773367, "test_macro_f1": 0.45407608665965293, "test_runtime": 3.88, "test_samples_per_second": 527.832, "test_steps_per_second": 16.495}, {"test_loss": 0.5650139451026917, "test_mcc": 0.4434596557448675, "test_macro_f1": 0.6960255626343714, "test_runtime": 3.949, "test_samples_per_second": 518.608, "test_steps_per_second": 16.206}, {"test_loss": 0.5890892744064331, "test_mcc": 0.41202715100665016, "test_macro_f1": 0.7058187423346552, "test_runtime": 3.9308, "test_samples_per_second": 521.018, "test_steps_per_second": 16.282}, {"test_loss": 0.6170871257781982, "test_mcc": 0.4251393262020125, "test_macro_f1": 0.6993426436863458, "test_runtime": 3.9022, "test_samples_per_second": 524.835, "test_steps_per_second": 16.401}, {"test_loss": 0.612336277961731, "test_mcc": 0.39810038811170795, "test_macro_f1": 0.6891859840876327, "test_runtime": 3.9766, "test_samples_per_second": 515.014, "test_steps_per_second": 16.094}]}, "total": {"test_mcc": 38.178409332121646, "test_mcc_se": 7.0298616320817136, "test_macro_f1": 66.99166310891617, "test_macro_f1_se": 4.916195117116053}}, "num_model_parameters": 151311362, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.6188441514968872, "test_mcc": 0.333500600386393, "test_macro_f1": 0.6602836113382813, "test_runtime": 3.9581, "test_samples_per_second": 517.415, "test_steps_per_second": 16.169}, {"test_loss": 0.689950704574585, "test_mcc": 0.0961468030397537, "test_macro_f1": 0.5414580240329409, "test_runtime": 4.1492, "test_samples_per_second": 493.591, "test_steps_per_second": 15.425}, {"test_loss": 0.6892677545547485, "test_mcc": 0.08674509129459573, "test_macro_f1": 0.4903791420097805, "test_runtime": 4.1048, "test_samples_per_second": 498.933, "test_steps_per_second": 15.592}, {"test_loss": 0.6043540835380554, "test_mcc": 0.43541077718145565, "test_macro_f1": 0.6989274289656904, "test_runtime": 4.234, "test_samples_per_second": 483.7, "test_steps_per_second": 15.116}, {"test_loss": 0.5723592042922974, "test_mcc": 0.44175692717234777, "test_macro_f1": 0.7108656341381656, "test_runtime": 4.0593, "test_samples_per_second": 504.526, "test_steps_per_second": 15.766}, {"test_loss": 0.5636586546897888, "test_mcc": 0.4797144484059684, "test_macro_f1": 0.7312026081514886, "test_runtime": 4.0246, "test_samples_per_second": 508.872, "test_steps_per_second": 15.902}, {"test_loss": 0.6027781367301941, "test_mcc": 0.37299850892003533, "test_macro_f1": 0.667027991502732, "test_runtime": 3.918, "test_samples_per_second": 522.72, "test_steps_per_second": 16.335}, {"test_loss": 0.690508246421814, "test_mcc": 0.08570062593305418, "test_macro_f1": 0.4461963157615332, "test_runtime": 3.9661, "test_samples_per_second": 516.371, "test_steps_per_second": 16.137}, {"test_loss": 0.691893994808197, "test_mcc": 0.07610699106570676, "test_macro_f1": 0.5013570800643106, "test_runtime": 3.9521, "test_samples_per_second": 518.208, "test_steps_per_second": 16.194}, {"test_loss": 0.5595729947090149, "test_mcc": 0.49267767941451046, "test_macro_f1": 0.741741465285769, "test_runtime": 4.0572, "test_samples_per_second": 504.787, "test_steps_per_second": 15.775}]}, "total": {"test_mcc": 29.00758452813821, "test_mcc_se": 11.248065349265746, "test_macro_f1": 61.894393012506924, "test_macro_f1_se": 6.937361089989569}}, "num_model_parameters": 151311362, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.5612972974777222, "test_mcc": 0.4276487569281909, "test_macro_f1": 0.6982473902469681, "test_runtime": 3.6176, "test_samples_per_second": 566.127, "test_steps_per_second": 17.691}, {"test_loss": 0.5549731254577637, "test_mcc": 0.4610502060274636, "test_macro_f1": 0.7273376763841533, "test_runtime": 3.6068, "test_samples_per_second": 567.814, "test_steps_per_second": 17.744}, {"test_loss": 0.5833070874214172, "test_mcc": 0.4153484110623274, "test_macro_f1": 0.6817193618753481, "test_runtime": 3.5954, "test_samples_per_second": 569.622, "test_steps_per_second": 17.801}, {"test_loss": 0.5531294941902161, "test_mcc": 0.47986022370075493, "test_macro_f1": 0.7351198689908042, "test_runtime": 3.6724, "test_samples_per_second": 557.673, "test_steps_per_second": 17.427}, {"test_loss": 0.597675085067749, "test_mcc": 0.50113413435369, "test_macro_f1": 0.7353048773809132, "test_runtime": 3.6799, "test_samples_per_second": 556.537, "test_steps_per_second": 17.392}, {"test_loss": 0.5319464206695557, "test_mcc": 0.5077700535916393, "test_macro_f1": 0.7450632471418355, "test_runtime": 3.5325, "test_samples_per_second": 579.755, "test_steps_per_second": 18.117}, {"test_loss": 0.551837146282196, "test_mcc": 0.47383938923577507, "test_macro_f1": 0.7333727991490784, "test_runtime": 3.5014, "test_samples_per_second": 584.904, "test_steps_per_second": 18.278}, {"test_loss": 0.6368288993835449, "test_mcc": 0.4590591089503252, "test_macro_f1": 0.6850260691604269, "test_runtime": 3.5786, "test_samples_per_second": 572.287, "test_steps_per_second": 17.884}, {"test_loss": 0.5832870006561279, "test_mcc": 0.47035936285317415, "test_macro_f1": 0.7119898054387965, "test_runtime": 3.5162, "test_samples_per_second": 582.45, "test_steps_per_second": 18.202}, {"test_loss": 0.5884969234466553, "test_mcc": 0.44728173157274564, "test_macro_f1": 0.7115757286376416, "test_runtime": 3.652, "test_samples_per_second": 560.784, "test_steps_per_second": 17.525}]}, "total": {"test_mcc": 46.43351378276086, "test_mcc_se": 1.8109763968506438, "test_macro_f1": 71.64756824405967, "test_macro_f1_se": 1.385370474335647}}, "num_model_parameters": 151311362, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.5739725828170776, "test_mcc": 0.43148817825258196, "test_macro_f1": 0.7073335368774063, "test_runtime": 3.7314, "test_samples_per_second": 548.863, "test_steps_per_second": 17.152}, {"test_loss": 0.61597740650177, "test_mcc": 0.37029346419739984, "test_macro_f1": 0.6754884967307335, "test_runtime": 3.9625, "test_samples_per_second": 516.851, "test_steps_per_second": 16.152}, {"test_loss": 0.6261383295059204, "test_mcc": 0.4040975641503797, "test_macro_f1": 0.6634160967819234, "test_runtime": 3.8854, "test_samples_per_second": 527.102, "test_steps_per_second": 16.472}, {"test_loss": 0.6223430633544922, "test_mcc": 0.2945538931810256, "test_macro_f1": 0.6308455706604403, "test_runtime": 3.6678, "test_samples_per_second": 558.372, "test_steps_per_second": 17.449}, {"test_loss": 0.5744689702987671, "test_mcc": 0.439646200984617, "test_macro_f1": 0.7197320614203839, "test_runtime": 3.7658, "test_samples_per_second": 543.844, "test_steps_per_second": 16.995}, {"test_loss": 0.5665851831436157, "test_mcc": 0.43069873317482776, "test_macro_f1": 0.6988136867217882, "test_runtime": 3.8158, "test_samples_per_second": 536.723, "test_steps_per_second": 16.773}, {"test_loss": 0.6975480914115906, "test_mcc": 0.39343552031134826, "test_macro_f1": 0.6948468732807629, "test_runtime": 3.7394, "test_samples_per_second": 547.688, "test_steps_per_second": 17.115}, {"test_loss": 0.5989184975624084, "test_mcc": 0.3699250391804052, "test_macro_f1": 0.6575634615097605, "test_runtime": 3.723, "test_samples_per_second": 550.089, "test_steps_per_second": 17.19}, {"test_loss": 0.5646464824676514, "test_mcc": 0.44547828354854024, "test_macro_f1": 0.7209177801853859, "test_runtime": 3.7085, "test_samples_per_second": 552.241, "test_steps_per_second": 17.258}, {"test_loss": 0.5644674301147461, "test_mcc": 0.4021256653403009, "test_macro_f1": 0.6991335336035822, "test_runtime": 3.8242, "test_samples_per_second": 535.533, "test_steps_per_second": 16.735}]}, "total": {"test_mcc": 39.81742542321426, "test_mcc_se": 2.8109239395422536, "test_macro_f1": 68.68091097772167, "test_macro_f1_se": 1.8119603924428134}}, "num_model_parameters": 151311362, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_em": 47.48257164988381, "test_f1": 52.23107346795143}, {"test_em": 49.92248062015504, "test_f1": 53.32541011909812}, {"test_em": 50.38639876352396, "test_f1": 53.97950356669925}, {"test_em": 52.64797507788162, "test_f1": 56.35996188882988}, {"test_em": 46.33204633204633, "test_f1": 49.37523068902028}, {"test_em": 47.031611410948344, "test_f1": 50.488767827464414}, {"test_em": 50.949126803340924, "test_f1": 55.846272367372954}, {"test_em": 52.055857253685026, "test_f1": 55.47573040560859}, {"test_em": 41.80392156862745, "test_f1": 45.999601984889374}, {"test_em": 45.108695652173914, "test_f1": 49.15609909718422}]}, "total": {"test_em": 48.372068513226644, "test_em_se": 2.1220371973355685, "test_f1": 52.22376514141185, "test_f1_se": 2.1107560927600297}}, "num_model_parameters": 150720770, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_em": 45.70100697134005, "test_f1": 49.75454463824169}, {"test_em": 45.50387596899225, "test_f1": 50.53118997312711}, {"test_em": 44.667697063369395, "test_f1": 49.84480617817498}, {"test_em": 45.482866043613704, "test_f1": 49.968809339226866}, {"test_em": 40.69498069498069, "test_f1": 45.09573982616885}, {"test_em": 46.87740940632228, "test_f1": 50.8060955013304}, {"test_em": 50.11389521640091, "test_f1": 54.67239168909512}, {"test_em": 45.228859581070594, "test_f1": 50.160938231718134}, {"test_em": 50.27450980392157, "test_f1": 55.15223800145052}, {"test_em": 46.350931677018636, "test_f1": 51.022059616227246}]}, "total": {"test_em": 46.08960324270301, "test_em_se": 1.6926776403812407, "test_f1": 50.700881299476094, "test_f1_se": 1.723661097176301}}, "num_model_parameters": 150720770, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_em": 50.65840433772269, "test_f1": 55.808063182191766}, {"test_em": 49.14728682170543, "test_f1": 54.116698675468186}, {"test_em": 47.913446676970636, "test_f1": 53.20860208949915}, {"test_em": 43.769470404984425, "test_f1": 47.97770358243146}, {"test_em": 42.084942084942085, "test_f1": 46.67654973205612}, {"test_em": 44.1017733230532, "test_f1": 48.297659139235684}, {"test_em": 43.35611237661352, "test_f1": 48.13711603081266}, {"test_em": 49.65089216446858, "test_f1": 54.892527991031145}, {"test_em": 49.80392156862745, "test_f1": 54.28994679211396}, {"test_em": 47.515527950310556, "test_f1": 51.89451327476416}]}, "total": {"test_em": 46.80017777093986, "test_em_se": 1.9584377337242291, "test_f1": 51.529938048960425, "test_f1_se": 2.117059993443529}}, "num_model_parameters": 150720770, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6322500109672546, "test_mcc": 0.5919349269717162, "test_macro_f1": 0.5622191663898005, "test_runtime": 16.8179, "test_samples_per_second": 121.775, "test_steps_per_second": 15.222}, {"test_loss": 0.6069031953811646, "test_mcc": 0.611120320823467, "test_macro_f1": 0.5578882655475103, "test_runtime": 16.2352, "test_samples_per_second": 126.146, "test_steps_per_second": 15.768}, {"test_loss": 0.5831344127655029, "test_mcc": 0.61333534190263, "test_macro_f1": 0.6461104388282237, "test_runtime": 16.5105, "test_samples_per_second": 124.042, "test_steps_per_second": 15.505}, {"test_loss": 0.5984889268875122, "test_mcc": 0.6376005820146186, "test_macro_f1": 0.6660439750285142, "test_runtime": 16.1254, "test_samples_per_second": 127.005, "test_steps_per_second": 15.876}, {"test_loss": 0.6040552854537964, "test_mcc": 0.6147992303263341, "test_macro_f1": 0.6732825926733614, "test_runtime": 16.0946, "test_samples_per_second": 127.248, "test_steps_per_second": 15.906}, {"test_loss": 0.583979606628418, "test_mcc": 0.631275835730468, "test_macro_f1": 0.5970177198759449, "test_runtime": 16.4389, "test_samples_per_second": 124.583, "test_steps_per_second": 15.573}, {"test_loss": 0.5944003462791443, "test_mcc": 0.6255466332427121, "test_macro_f1": 0.5547087624664372, "test_runtime": 15.9742, "test_samples_per_second": 128.206, "test_steps_per_second": 16.026}, {"test_loss": 0.5611878037452698, "test_mcc": 0.6259168440420397, "test_macro_f1": 0.5596222799992115, "test_runtime": 16.9242, "test_samples_per_second": 121.01, "test_steps_per_second": 15.126}, {"test_loss": 0.6331818103790283, "test_mcc": 0.6037203369544694, "test_macro_f1": 0.5597642140569912, "test_runtime": 16.7211, "test_samples_per_second": 122.48, "test_steps_per_second": 15.31}, {"test_loss": 0.5831730961799622, "test_mcc": 0.6337791504907608, "test_macro_f1": 0.640197699779839, "test_runtime": 16.4299, "test_samples_per_second": 124.651, "test_steps_per_second": 15.581}]}, "total": {"test_mcc": 61.89029202499216, "test_mcc_se": 0.8966433923845267, "test_macro_f1": 60.16855114645834, "test_macro_f1_se": 3.061340535526697}}, "num_model_parameters": 111181059, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 1.0271395444869995, "test_mcc": 0.36609331192730804, "test_macro_f1": 0.5590644452862931, "test_runtime": 4.7919, "test_samples_per_second": 427.392, "test_steps_per_second": 13.356}, {"test_loss": 0.9227069020271301, "test_mcc": 0.35028576215053625, "test_macro_f1": 0.5425729282799748, "test_runtime": 4.7432, "test_samples_per_second": 431.772, "test_steps_per_second": 13.493}, {"test_loss": 1.0692856311798096, "test_mcc": 0.3435441468552883, "test_macro_f1": 0.557152818343288, "test_runtime": 4.7385, "test_samples_per_second": 432.205, "test_steps_per_second": 13.506}, {"test_loss": 0.9823250770568848, "test_mcc": 0.35036475421895885, "test_macro_f1": 0.5655495514307854, "test_runtime": 4.7602, "test_samples_per_second": 430.236, "test_steps_per_second": 13.445}, {"test_loss": 0.9726104736328125, "test_mcc": 0.3306138141999072, "test_macro_f1": 0.5455194186881341, "test_runtime": 4.7082, "test_samples_per_second": 434.988, "test_steps_per_second": 13.593}, {"test_loss": 1.0372326374053955, "test_mcc": 0.34656827300212506, "test_macro_f1": 0.5500328141129555, "test_runtime": 4.9072, "test_samples_per_second": 417.342, "test_steps_per_second": 13.042}, {"test_loss": 0.9440577626228333, "test_mcc": 0.3624875748893326, "test_macro_f1": 0.5617156294176059, "test_runtime": 4.8379, "test_samples_per_second": 423.32, "test_steps_per_second": 13.229}, {"test_loss": 1.050316333770752, "test_mcc": 0.28821860784733927, "test_macro_f1": 0.5134698637535248, "test_runtime": 4.7779, "test_samples_per_second": 428.639, "test_steps_per_second": 13.395}, {"test_loss": 0.9708961844444275, "test_mcc": 0.30693127433726897, "test_macro_f1": 0.5100257561106939, "test_runtime": 4.7324, "test_samples_per_second": 432.764, "test_steps_per_second": 13.524}, {"test_loss": 0.9443848729133606, "test_mcc": 0.3222682600168397, "test_macro_f1": 0.5427655607512584, "test_runtime": 4.6664, "test_samples_per_second": 438.879, "test_steps_per_second": 13.715}]}, "total": {"test_mcc": 33.673757794449045, "test_mcc_se": 1.5358773763387745, "test_macro_f1": 54.47868786174512, "test_macro_f1_se": 1.1869416814160056}}, "num_model_parameters": 111181059, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.9022699594497681, "test_mcc": 0.38971256258792586, "test_macro_f1": 0.5428740196638139, "test_runtime": 3.8633, "test_samples_per_second": 530.115, "test_steps_per_second": 16.566}, {"test_loss": 0.8675874471664429, "test_mcc": 0.35997053504327303, "test_macro_f1": 0.5384110583612253, "test_runtime": 3.6893, "test_samples_per_second": 555.117, "test_steps_per_second": 17.347}, {"test_loss": 0.867717981338501, "test_mcc": 0.37899538902768365, "test_macro_f1": 0.49885909837434467, "test_runtime": 3.7209, "test_samples_per_second": 550.404, "test_steps_per_second": 17.2}, {"test_loss": 0.886836051940918, "test_mcc": 0.32771834714892684, "test_macro_f1": 0.4545755235656486, "test_runtime": 3.7369, "test_samples_per_second": 548.052, "test_steps_per_second": 17.127}, {"test_loss": 0.8647224307060242, "test_mcc": 0.3501063377543208, "test_macro_f1": 0.5097243007748844, "test_runtime": 3.8393, "test_samples_per_second": 533.433, "test_steps_per_second": 16.67}, {"test_loss": 0.843688428401947, "test_mcc": 0.39025982211533294, "test_macro_f1": 0.5245864333962792, "test_runtime": 3.8519, "test_samples_per_second": 531.688, "test_steps_per_second": 16.615}, {"test_loss": 0.8367660045623779, "test_mcc": 0.3459698797804597, "test_macro_f1": 0.4612148849245454, "test_runtime": 3.694, "test_samples_per_second": 554.419, "test_steps_per_second": 17.326}, {"test_loss": 0.8597915172576904, "test_mcc": 0.34351352674437663, "test_macro_f1": 0.44523389042181566, "test_runtime": 3.8458, "test_samples_per_second": 532.531, "test_steps_per_second": 16.642}, {"test_loss": 0.9221330881118774, "test_mcc": 0.3101589447288632, "test_macro_f1": 0.4246437941771777, "test_runtime": 3.8625, "test_samples_per_second": 530.22, "test_steps_per_second": 16.569}, {"test_loss": 0.8830083608627319, "test_mcc": 0.3199392284829081, "test_macro_f1": 0.44054055756011284, "test_runtime": 3.9308, "test_samples_per_second": 521.016, "test_steps_per_second": 16.282}]}, "total": {"test_mcc": 35.16344573414071, "test_mcc_se": 1.7478504189204724, "test_macro_f1": 48.40663561219848, "test_macro_f1_se": 2.7139780673641636}}, "num_model_parameters": 111181059, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.06487006694078445, "test_micro_f1": 0.6423135464231354, "test_micro_f1_no_misc": 0.7251043530113297, "test_runtime": 8.411, "test_samples_per_second": 243.489, "test_steps_per_second": 7.609}, {"test_loss": 0.05663210153579712, "test_micro_f1": 0.7019587083112758, "test_micro_f1_no_misc": 0.7534493101379725, "test_runtime": 7.8488, "test_samples_per_second": 260.93, "test_steps_per_second": 8.154}, {"test_loss": 0.059317417442798615, "test_micro_f1": 0.683020683020683, "test_micro_f1_no_misc": 0.7325769854132901, "test_runtime": 7.8095, "test_samples_per_second": 262.244, "test_steps_per_second": 8.195}, {"test_loss": 0.05816316977143288, "test_micro_f1": 0.7038883349950149, "test_micro_f1_no_misc": 0.743175487465181, "test_runtime": 8.3305, "test_samples_per_second": 245.845, "test_steps_per_second": 7.683}, {"test_loss": 0.06998953223228455, "test_micro_f1": 0.6835322195704057, "test_micro_f1_no_misc": 0.7343251859723697, "test_runtime": 8.3117, "test_samples_per_second": 246.4, "test_steps_per_second": 7.7}, {"test_loss": 0.05393863469362259, "test_micro_f1": 0.754302103250478, "test_micro_f1_no_misc": 0.8035417819590482, "test_runtime": 6.6744, "test_samples_per_second": 306.843, "test_steps_per_second": 9.589}, {"test_loss": 0.06922052800655365, "test_micro_f1": 0.6762452107279693, "test_micro_f1_no_misc": 0.7284277395447326, "test_runtime": 7.5248, "test_samples_per_second": 272.167, "test_steps_per_second": 8.505}, {"test_loss": 0.05631611496210098, "test_micro_f1": 0.6854709952102181, "test_micro_f1_no_misc": 0.7447193723596862, "test_runtime": 8.3695, "test_samples_per_second": 244.699, "test_steps_per_second": 7.647}, {"test_loss": 0.062048375606536865, "test_micro_f1": 0.7102892366050261, "test_micro_f1_no_misc": 0.753468516542156, "test_runtime": 7.9191, "test_samples_per_second": 258.616, "test_steps_per_second": 8.082}, {"test_loss": 0.06327348947525024, "test_micro_f1": 0.7159647404505387, "test_micro_f1_no_misc": 0.7692307692307693, "test_runtime": 8.3422, "test_samples_per_second": 245.499, "test_steps_per_second": 7.672}]}, "total": {"test_micro_f1": 69.56985778564744, "test_micro_f1_se": 1.8253608396635483, "test_micro_f1_no_misc": 74.88019501636536, "test_micro_f1_no_misc_se": 1.4543082460752605}}, "num_model_parameters": 110595081, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.059128664433956146, "test_micro_f1": 0.810561394514227, "test_micro_f1_no_misc": 0.8300854700854702, "test_runtime": 8.9964, "test_samples_per_second": 227.646, "test_steps_per_second": 7.114}, {"test_loss": 0.05472144857048988, "test_micro_f1": 0.8017992690469496, "test_micro_f1_no_misc": 0.8225686711210096, "test_runtime": 6.8194, "test_samples_per_second": 300.318, "test_steps_per_second": 9.385}, {"test_loss": 0.05837156996130943, "test_micro_f1": 0.7966457023060796, "test_micro_f1_no_misc": 0.8226093138997512, "test_runtime": 9.1004, "test_samples_per_second": 225.045, "test_steps_per_second": 7.033}, {"test_loss": 0.07009561359882355, "test_micro_f1": 0.8125967991739804, "test_micro_f1_no_misc": 0.8381831085876508, "test_runtime": 8.6814, "test_samples_per_second": 235.906, "test_steps_per_second": 7.372}, {"test_loss": 0.07063133269548416, "test_micro_f1": 0.7866554527614241, "test_micro_f1_no_misc": 0.8074626865671641, "test_runtime": 9.1265, "test_samples_per_second": 224.402, "test_steps_per_second": 7.013}, {"test_loss": 0.06505800038576126, "test_micro_f1": 0.8015456803753795, "test_micro_f1_no_misc": 0.8294544067149943, "test_runtime": 8.8846, "test_samples_per_second": 230.51, "test_steps_per_second": 7.203}, {"test_loss": 0.0624917671084404, "test_micro_f1": 0.7996807661612131, "test_micro_f1_no_misc": 0.8141977544367983, "test_runtime": 9.2409, "test_samples_per_second": 221.625, "test_steps_per_second": 6.926}, {"test_loss": 0.051277268677949905, "test_micro_f1": 0.8323153803442531, "test_micro_f1_no_misc": 0.857904761904762, "test_runtime": 8.9954, "test_samples_per_second": 227.671, "test_steps_per_second": 7.115}, {"test_loss": 0.06367126107215881, "test_micro_f1": 0.7963607171527963, "test_micro_f1_no_misc": 0.8196841718692618, "test_runtime": 8.6745, "test_samples_per_second": 236.094, "test_steps_per_second": 7.378}, {"test_loss": 0.06289269030094147, "test_micro_f1": 0.8121800053893828, "test_micro_f1_no_misc": 0.8377777777777777, "test_runtime": 7.2108, "test_samples_per_second": 284.018, "test_steps_per_second": 8.876}]}, "total": {"test_micro_f1": 80.50341167225685, "test_micro_f1_se": 0.7779157641987566, "test_micro_f1_no_misc": 82.7992812296464, "test_micro_f1_no_misc_se": 0.8862375623964938}}, "num_model_parameters": 110595081, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.03981660306453705, "test_micro_f1": 0.8593350383631714, "test_micro_f1_no_misc": 0.8906249999999999, "test_runtime": 6.7769, "test_samples_per_second": 302.202, "test_steps_per_second": 9.444}, {"test_loss": 0.039707355201244354, "test_micro_f1": 0.8445269016697589, "test_micro_f1_no_misc": 0.8846317581949766, "test_runtime": 6.9413, "test_samples_per_second": 295.045, "test_steps_per_second": 9.22}, {"test_loss": 0.04684855788946152, "test_micro_f1": 0.8228980322003578, "test_micro_f1_no_misc": 0.8582739509105305, "test_runtime": 6.704, "test_samples_per_second": 305.49, "test_steps_per_second": 9.547}, {"test_loss": 0.03492985665798187, "test_micro_f1": 0.8621659634317862, "test_micro_f1_no_misc": 0.8901098901098901, "test_runtime": 6.271, "test_samples_per_second": 326.583, "test_steps_per_second": 10.206}, {"test_loss": 0.036654889583587646, "test_micro_f1": 0.8727272727272727, "test_micro_f1_no_misc": 0.9000751314800902, "test_runtime": 6.7673, "test_samples_per_second": 302.632, "test_steps_per_second": 9.457}, {"test_loss": 0.03240940719842911, "test_micro_f1": 0.8782161234991422, "test_micro_f1_no_misc": 0.9083998479665526, "test_runtime": 6.8358, "test_samples_per_second": 299.597, "test_steps_per_second": 9.362}, {"test_loss": 0.038010820746421814, "test_micro_f1": 0.8533795493934142, "test_micro_f1_no_misc": 0.8827852998065763, "test_runtime": 6.17, "test_samples_per_second": 331.926, "test_steps_per_second": 10.373}, {"test_loss": 0.040935955941677094, "test_micro_f1": 0.8573412009718848, "test_micro_f1_no_misc": 0.8830387363670552, "test_runtime": 6.5339, "test_samples_per_second": 313.443, "test_steps_per_second": 9.795}, {"test_loss": 0.03837769478559494, "test_micro_f1": 0.8394004282655245, "test_micro_f1_no_misc": 0.8741287412874129, "test_runtime": 6.4783, "test_samples_per_second": 316.13, "test_steps_per_second": 9.879}, {"test_loss": 0.046072475612163544, "test_micro_f1": 0.8393711551606289, "test_micro_f1_no_misc": 0.8833709556057185, "test_runtime": 6.7301, "test_samples_per_second": 304.302, "test_steps_per_second": 9.509}]}, "total": {"test_micro_f1": 85.29361665682941, "test_micro_f1_se": 1.036461543186911, "test_micro_f1_no_misc": 88.55439311728801, "test_micro_f1_no_misc_se": 0.8452053595038124}}, "num_model_parameters": 110595081, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.05576679855585098, "test_micro_f1": 0.8133249528598365, "test_micro_f1_no_misc": 0.8554633471645919, "test_runtime": 6.6634, "test_samples_per_second": 307.351, "test_steps_per_second": 9.605}, {"test_loss": 0.058687448501586914, "test_micro_f1": 0.7888987304399172, "test_micro_f1_no_misc": 0.8217821782178217, "test_runtime": 6.818, "test_samples_per_second": 300.382, "test_steps_per_second": 9.387}, {"test_loss": 0.062015600502491, "test_micro_f1": 0.7847642079806529, "test_micro_f1_no_misc": 0.8197267577474175, "test_runtime": 6.4442, "test_samples_per_second": 317.803, "test_steps_per_second": 9.931}, {"test_loss": 0.06325206160545349, "test_micro_f1": 0.8005988023952096, "test_micro_f1_no_misc": 0.8343970440040309, "test_runtime": 6.6673, "test_samples_per_second": 307.173, "test_steps_per_second": 9.599}, {"test_loss": 0.06973713636398315, "test_micro_f1": 0.7521883489284636, "test_micro_f1_no_misc": 0.8016359918200409, "test_runtime": 6.3504, "test_samples_per_second": 322.502, "test_steps_per_second": 10.078}, {"test_loss": 0.05721336975693703, "test_micro_f1": 0.8070701018573997, "test_micro_f1_no_misc": 0.8410774410774411, "test_runtime": 6.3899, "test_samples_per_second": 320.507, "test_steps_per_second": 10.016}, {"test_loss": 0.05543298274278641, "test_micro_f1": 0.799632915264607, "test_micro_f1_no_misc": 0.8471555860178204, "test_runtime": 6.8357, "test_samples_per_second": 299.605, "test_steps_per_second": 9.363}, {"test_loss": 0.05607517808675766, "test_micro_f1": 0.7769960232487, "test_micro_f1_no_misc": 0.817786693413574, "test_runtime": 6.8354, "test_samples_per_second": 299.616, "test_steps_per_second": 9.363}, {"test_loss": 0.0634162649512291, "test_micro_f1": 0.7851110416015015, "test_micro_f1_no_misc": 0.8213408213408212, "test_runtime": 6.5004, "test_samples_per_second": 315.057, "test_steps_per_second": 9.846}, {"test_loss": 0.05154015123844147, "test_micro_f1": 0.8184064237183447, "test_micro_f1_no_misc": 0.8486069150721719, "test_runtime": 6.4147, "test_samples_per_second": 319.267, "test_steps_per_second": 9.977}]}, "total": {"test_micro_f1": 79.26991548294632, "test_micro_f1_se": 1.2092832221065415, "test_micro_f1_no_misc": 83.08972775875732, "test_micro_f1_no_misc_se": 1.058448674055269}}, "num_model_parameters": 110595081, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.5926597714424133, "test_mcc": 0.4296044380875023, "test_macro_f1": 0.7082790797442176, "test_runtime": 3.8821, "test_samples_per_second": 527.553, "test_steps_per_second": 16.486}, {"test_loss": 0.6240630149841309, "test_mcc": 0.42071360121912654, "test_macro_f1": 0.7098986885117675, "test_runtime": 4.1813, "test_samples_per_second": 489.795, "test_steps_per_second": 15.306}, {"test_loss": 0.63951176404953, "test_mcc": 0.38828883295974204, "test_macro_f1": 0.6717666485957665, "test_runtime": 4.1571, "test_samples_per_second": 492.654, "test_steps_per_second": 15.395}, {"test_loss": 0.638931393623352, "test_mcc": 0.4233153259346117, "test_macro_f1": 0.7037581928575218, "test_runtime": 4.0636, "test_samples_per_second": 503.992, "test_steps_per_second": 15.75}, {"test_loss": 0.6306064128875732, "test_mcc": 0.3242523536637972, "test_macro_f1": 0.602695533319324, "test_runtime": 4.0909, "test_samples_per_second": 500.622, "test_steps_per_second": 15.644}, {"test_loss": 0.569983959197998, "test_mcc": 0.40136655795555376, "test_macro_f1": 0.6999546641087679, "test_runtime": 4.1092, "test_samples_per_second": 498.395, "test_steps_per_second": 15.575}, {"test_loss": 0.5560390949249268, "test_mcc": 0.43876848835769866, "test_macro_f1": 0.7176282798015243, "test_runtime": 4.073, "test_samples_per_second": 502.826, "test_steps_per_second": 15.713}, {"test_loss": 0.6466702222824097, "test_mcc": 0.41622080028556635, "test_macro_f1": 0.7014831757466606, "test_runtime": 4.0676, "test_samples_per_second": 503.493, "test_steps_per_second": 15.734}, {"test_loss": 0.6113927364349365, "test_mcc": 0.38950949633450366, "test_macro_f1": 0.694306784323151, "test_runtime": 4.0765, "test_samples_per_second": 502.392, "test_steps_per_second": 15.7}, {"test_loss": 0.6140622496604919, "test_mcc": 0.38967160896624303, "test_macro_f1": 0.6794696192749066, "test_runtime": 4.152, "test_samples_per_second": 493.257, "test_steps_per_second": 15.414}]}, "total": {"test_mcc": 40.217115037643445, "test_mcc_se": 2.0307532510629236, "test_macro_f1": 68.89240666283607, "test_macro_f1_se": 2.064578500509353}}, "num_model_parameters": 111180290, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6901534795761108, "test_mcc": 0.0992117579953502, "test_macro_f1": 0.5235127003642681, "test_runtime": 3.9703, "test_samples_per_second": 515.833, "test_steps_per_second": 16.12}, {"test_loss": 0.6490659117698669, "test_mcc": 0.44811054835835984, "test_macro_f1": 0.6926594257521236, "test_runtime": 4.1469, "test_samples_per_second": 493.864, "test_steps_per_second": 15.433}, {"test_loss": 0.6892120838165283, "test_mcc": 0.07469839602315362, "test_macro_f1": 0.5024763503630015, "test_runtime": 4.0828, "test_samples_per_second": 501.618, "test_steps_per_second": 15.676}, {"test_loss": 0.5898141860961914, "test_mcc": 0.4691796339421142, "test_macro_f1": 0.7308197460509338, "test_runtime": 4.2204, "test_samples_per_second": 485.267, "test_steps_per_second": 15.165}, {"test_loss": 0.5665204524993896, "test_mcc": 0.4866540916673319, "test_macro_f1": 0.7389795263215896, "test_runtime": 4.0852, "test_samples_per_second": 501.322, "test_steps_per_second": 15.666}, {"test_loss": 0.5995720624923706, "test_mcc": 0.4561228515697402, "test_macro_f1": 0.7133267067707018, "test_runtime": 4.0399, "test_samples_per_second": 506.94, "test_steps_per_second": 15.842}, {"test_loss": 0.5989769697189331, "test_mcc": 0.3760935930400509, "test_macro_f1": 0.6784501990036333, "test_runtime": 3.9256, "test_samples_per_second": 521.705, "test_steps_per_second": 16.303}, {"test_loss": 0.554796576499939, "test_mcc": 0.4882297837829838, "test_macro_f1": 0.7438582421569189, "test_runtime": 3.9731, "test_samples_per_second": 515.469, "test_steps_per_second": 16.108}, {"test_loss": 0.6060936450958252, "test_mcc": 0.38128638131905, "test_macro_f1": 0.6645822848671694, "test_runtime": 3.9802, "test_samples_per_second": 514.546, "test_steps_per_second": 16.08}, {"test_loss": 0.636259913444519, "test_mcc": 0.2994008059181543, "test_macro_f1": 0.5982524341461666, "test_runtime": 4.0627, "test_samples_per_second": 504.101, "test_steps_per_second": 15.753}]}, "total": {"test_mcc": 35.78987843616289, "test_mcc_se": 9.583202761961154, "test_macro_f1": 65.86917615796507, "test_macro_f1_se": 5.458181431395891}}, "num_model_parameters": 111180290, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.5802867412567139, "test_mcc": 0.43842532943267726, "test_macro_f1": 0.7078893174366852, "test_runtime": 3.6926, "test_samples_per_second": 554.616, "test_steps_per_second": 17.332}, {"test_loss": 0.6251224279403687, "test_mcc": 0.30610741103327105, "test_macro_f1": 0.6496975462569247, "test_runtime": 3.7003, "test_samples_per_second": 553.473, "test_steps_per_second": 17.296}, {"test_loss": 0.5928081274032593, "test_mcc": 0.405016376829003, "test_macro_f1": 0.6812647938817276, "test_runtime": 3.7201, "test_samples_per_second": 550.525, "test_steps_per_second": 17.204}, {"test_loss": 0.6907224059104919, "test_mcc": 0.09187626687200433, "test_macro_f1": 0.5449517777588442, "test_runtime": 3.8187, "test_samples_per_second": 536.302, "test_steps_per_second": 16.759}, {"test_loss": 0.6104879975318909, "test_mcc": 0.3412365161612357, "test_macro_f1": 0.6399637629751465, "test_runtime": 3.8188, "test_samples_per_second": 536.294, "test_steps_per_second": 16.759}, {"test_loss": 0.5838260054588318, "test_mcc": 0.4227895248068984, "test_macro_f1": 0.6949547763470794, "test_runtime": 3.6373, "test_samples_per_second": 563.055, "test_steps_per_second": 17.595}, {"test_loss": 0.6150616407394409, "test_mcc": 0.3526904014574796, "test_macro_f1": 0.6532460871167416, "test_runtime": 3.6678, "test_samples_per_second": 558.367, "test_steps_per_second": 17.449}, {"test_loss": 0.6926491260528564, "test_mcc": 0.04121482393350718, "test_macro_f1": 0.3669591326332179, "test_runtime": 3.792, "test_samples_per_second": 540.085, "test_steps_per_second": 16.878}, {"test_loss": 0.6436070203781128, "test_mcc": 0.3099584249153773, "test_macro_f1": 0.6324479540559943, "test_runtime": 3.7158, "test_samples_per_second": 551.153, "test_steps_per_second": 17.224}, {"test_loss": 0.5889292359352112, "test_mcc": 0.47244465193828944, "test_macro_f1": 0.7267255462712188, "test_runtime": 3.8048, "test_samples_per_second": 538.272, "test_steps_per_second": 16.821}]}, "total": {"test_mcc": 31.81759727379744, "test_mcc_se": 8.924620183572502, "test_macro_f1": 62.98100694733579, "test_macro_f1_se": 6.524401366685585}}, "num_model_parameters": 111180290, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6054725646972656, "test_mcc": 0.3820021235169485, "test_macro_f1": 0.6828140110315593, "test_runtime": 3.9154, "test_samples_per_second": 523.063, "test_steps_per_second": 16.346}, {"test_loss": 0.6187032461166382, "test_mcc": 0.3441204657950434, "test_macro_f1": 0.6442981854746561, "test_runtime": 4.0793, "test_samples_per_second": 502.05, "test_steps_per_second": 15.689}, {"test_loss": 0.6205286979675293, "test_mcc": 0.32652439763267316, "test_macro_f1": 0.6597219541609176, "test_runtime": 4.0873, "test_samples_per_second": 501.067, "test_steps_per_second": 15.658}, {"test_loss": 0.6377055644989014, "test_mcc": 0.2746012498053529, "test_macro_f1": 0.5969046745416777, "test_runtime": 3.9324, "test_samples_per_second": 520.807, "test_steps_per_second": 16.275}, {"test_loss": 0.5785256028175354, "test_mcc": 0.42980819402114834, "test_macro_f1": 0.7128181486390441, "test_runtime": 4.005, "test_samples_per_second": 511.359, "test_steps_per_second": 15.98}, {"test_loss": 0.6125511527061462, "test_mcc": 0.34549296191748696, "test_macro_f1": 0.6643209329195384, "test_runtime": 4.0491, "test_samples_per_second": 505.796, "test_steps_per_second": 15.806}, {"test_loss": 0.6527470350265503, "test_mcc": 0.29652364395690056, "test_macro_f1": 0.6418864908073542, "test_runtime": 3.9561, "test_samples_per_second": 517.687, "test_steps_per_second": 16.178}, {"test_loss": 0.6098760366439819, "test_mcc": 0.3553262124004371, "test_macro_f1": 0.6735298250374296, "test_runtime": 3.914, "test_samples_per_second": 523.251, "test_steps_per_second": 16.352}, {"test_loss": 0.686747133731842, "test_mcc": 0.10273157543577356, "test_macro_f1": 0.45515219164059295, "test_runtime": 3.9454, "test_samples_per_second": 519.082, "test_steps_per_second": 16.221}, {"test_loss": 0.5922778248786926, "test_mcc": 0.43691391353577963, "test_macro_f1": 0.7048881802870619, "test_runtime": 4.0447, "test_samples_per_second": 506.344, "test_steps_per_second": 15.823}]}, "total": {"test_mcc": 32.94044738017544, "test_mcc_se": 5.880960896695938, "test_macro_f1": 64.36334594539834, "test_macro_f1_se": 4.590411451592481}}, "num_model_parameters": 111180290, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_em": 50.19364833462432, "test_f1": 53.92032061365475}, {"test_em": 49.92248062015504, "test_f1": 53.473132950635474}, {"test_em": 46.831530139103556, "test_f1": 51.178919435465474}, {"test_em": 45.32710280373832, "test_f1": 49.677477222144624}, {"test_em": 50.656370656370655, "test_f1": 54.73034393531284}, {"test_em": 50.34695451040864, "test_f1": 54.84567840948723}, {"test_em": 50.18982536066819, "test_f1": 53.46097306461419}, {"test_em": 47.09076803723817, "test_f1": 50.96548668275495}, {"test_em": 47.76470588235294, "test_f1": 51.11682808379221}, {"test_em": 47.59316770186335, "test_f1": 51.07220137645666}]}, "total": {"test_em": 48.591655404652315, "test_em_se": 1.1673401052539356, "test_f1": 52.44413617743184, "test_f1_se": 1.138218322108048}}, "num_model_parameters": 110589698, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_em": 44.69403563129357, "test_f1": 49.13887161257617}, {"test_em": 45.58139534883721, "test_f1": 49.85165028525479}, {"test_em": 47.44976816074188, "test_f1": 51.63549205463977}, {"test_em": 45.95015576323988, "test_f1": 50.12715815501108}, {"test_em": 48.41698841698842, "test_f1": 52.77736555620523}, {"test_em": 46.33770239013107, "test_f1": 51.318044372509185}, {"test_em": 43.583902809415335, "test_f1": 48.33559913581001}, {"test_em": 42.97905352986812, "test_f1": 47.47795420601395}, {"test_em": 48.0, "test_f1": 52.46383135869169}, {"test_em": 49.61180124223603, "test_f1": 54.82076226659714}]}, "total": {"test_em": 46.260480329275154, "test_em_se": 1.3272674061006267, "test_f1": 50.79467290033091, "test_f1_se": 1.386416781920205}}, "num_model_parameters": 110589698, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_em": 47.405112316034085, "test_f1": 52.04266991052979}, {"test_em": 42.713178294573645, "test_f1": 47.59781249821933}, {"test_em": 47.14064914992272, "test_f1": 51.79013925331772}, {"test_em": 47.1183800623053, "test_f1": 52.0414420518403}, {"test_em": 46.33204633204633, "test_f1": 51.00197571626143}, {"test_em": 46.491904394757135, "test_f1": 50.94988127850442}, {"test_em": 47.228549734244496, "test_f1": 51.80910717207326}, {"test_em": 48.17688130333592, "test_f1": 53.15917630947522}, {"test_em": 48.705882352941174, "test_f1": 53.169156333862226}, {"test_em": 48.99068322981366, "test_f1": 53.619137505007075}]}, "total": {"test_em": 47.03032671699745, "test_em_se": 1.085005861977617, "test_f1": 51.71804980290908, "test_f1_se": 1.0554789516298042}}, "num_model_parameters": 110589698, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.6023232936859131, "test_mcc": 0.6824370473152047, "test_macro_f1": 0.5776262444131178, "test_runtime": 1.7709, "test_samples_per_second": 1156.463, "test_steps_per_second": 36.139}, {"test_loss": 0.5825810432434082, "test_mcc": 0.6489911371261903, "test_macro_f1": 0.5641570728350342, "test_runtime": 1.7515, "test_samples_per_second": 1169.258, "test_steps_per_second": 36.539}, {"test_loss": 0.5610504150390625, "test_mcc": 0.6667796989860042, "test_macro_f1": 0.630774864348575, "test_runtime": 1.7648, "test_samples_per_second": 1160.454, "test_steps_per_second": 36.264}, {"test_loss": 0.5571348071098328, "test_mcc": 0.6785606510508234, "test_macro_f1": 0.5747964376313613, "test_runtime": 1.7661, "test_samples_per_second": 1159.585, "test_steps_per_second": 36.237}, {"test_loss": 0.6101529598236084, "test_mcc": 0.6626575731528729, "test_macro_f1": 0.5692746918489119, "test_runtime": 1.7658, "test_samples_per_second": 1159.789, "test_steps_per_second": 36.243}, {"test_loss": 0.5677564144134521, "test_mcc": 0.6730471912390941, "test_macro_f1": 0.573092019979513, "test_runtime": 1.7624, "test_samples_per_second": 1162.061, "test_steps_per_second": 36.314}, {"test_loss": 0.595612645149231, "test_mcc": 0.6608921929758602, "test_macro_f1": 0.5678147690695411, "test_runtime": 1.7668, "test_samples_per_second": 1159.155, "test_steps_per_second": 36.224}, {"test_loss": 0.5701655745506287, "test_mcc": 0.6584546485325753, "test_macro_f1": 0.5663441347102921, "test_runtime": 1.809, "test_samples_per_second": 1132.097, "test_steps_per_second": 35.378}, {"test_loss": 0.582237720489502, "test_mcc": 0.64688151698931, "test_macro_f1": 0.5634561691620915, "test_runtime": 1.7671, "test_samples_per_second": 1158.93, "test_steps_per_second": 36.217}, {"test_loss": 0.5940218567848206, "test_mcc": 0.6630636221556475, "test_macro_f1": 0.5700654984725739, "test_runtime": 1.7689, "test_samples_per_second": 1157.802, "test_steps_per_second": 36.181}]}, "total": {"test_mcc": 66.41765279523581, "test_mcc_se": 0.7164659510393828, "test_macro_f1": 57.57401902471012, "test_macro_f1_se": 1.2310514305490137}}, "num_model_parameters": 21944195, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.9321277737617493, "test_mcc": 0.3703682488710889, "test_macro_f1": 0.575783281617191, "test_runtime": 1.4684, "test_samples_per_second": 1394.742, "test_steps_per_second": 43.586}, {"test_loss": 0.944737434387207, "test_mcc": 0.2865070613048073, "test_macro_f1": 0.41694533911378767, "test_runtime": 1.4668, "test_samples_per_second": 1396.2, "test_steps_per_second": 43.631}, {"test_loss": 0.8984164595603943, "test_mcc": 0.40604967688187915, "test_macro_f1": 0.6068597172856537, "test_runtime": 1.4821, "test_samples_per_second": 1381.85, "test_steps_per_second": 43.183}, {"test_loss": 0.9936826229095459, "test_mcc": 0.26465339642637803, "test_macro_f1": 0.4000171014726595, "test_runtime": 1.4624, "test_samples_per_second": 1400.463, "test_steps_per_second": 43.764}, {"test_loss": 0.8968337178230286, "test_mcc": 0.3900574175382687, "test_macro_f1": 0.5932633105817463, "test_runtime": 1.4457, "test_samples_per_second": 1416.58, "test_steps_per_second": 44.268}, {"test_loss": 0.9184441566467285, "test_mcc": 0.4119941165874004, "test_macro_f1": 0.6103223589581941, "test_runtime": 1.4569, "test_samples_per_second": 1405.772, "test_steps_per_second": 43.93}, {"test_loss": 0.9133937358856201, "test_mcc": 0.40591269509215255, "test_macro_f1": 0.6037876617686533, "test_runtime": 1.4489, "test_samples_per_second": 1413.474, "test_steps_per_second": 44.171}, {"test_loss": 0.9740085601806641, "test_mcc": 0.27224428133993966, "test_macro_f1": 0.40236158395224025, "test_runtime": 1.4892, "test_samples_per_second": 1375.21, "test_steps_per_second": 42.975}, {"test_loss": 0.9229181408882141, "test_mcc": 0.38302896857206237, "test_macro_f1": 0.5832322026045991, "test_runtime": 1.4296, "test_samples_per_second": 1432.569, "test_steps_per_second": 44.768}, {"test_loss": 0.9749138355255127, "test_mcc": 0.25185802864242535, "test_macro_f1": 0.3970407767560808, "test_runtime": 1.4576, "test_samples_per_second": 1405.064, "test_steps_per_second": 43.908}]}, "total": {"test_mcc": 34.42673891256402, "test_mcc_se": 4.126150825961409, "test_macro_f1": 51.89613334110804, "test_macro_f1_se": 6.169205236746115}}, "num_model_parameters": 21944195, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.8736479878425598, "test_mcc": 0.40423668935328555, "test_macro_f1": 0.46258310703995514, "test_runtime": 1.3584, "test_samples_per_second": 1507.645, "test_steps_per_second": 47.114}, {"test_loss": 0.8686469793319702, "test_mcc": 0.38417800076126785, "test_macro_f1": 0.45516942097525553, "test_runtime": 1.3282, "test_samples_per_second": 1541.881, "test_steps_per_second": 48.184}, {"test_loss": 0.8722004890441895, "test_mcc": 0.3961978162563391, "test_macro_f1": 0.4627724032631033, "test_runtime": 1.3114, "test_samples_per_second": 1561.685, "test_steps_per_second": 48.803}, {"test_loss": 0.8579935431480408, "test_mcc": 0.3852164035364059, "test_macro_f1": 0.4553112631079887, "test_runtime": 1.3234, "test_samples_per_second": 1547.559, "test_steps_per_second": 48.361}, {"test_loss": 0.880089282989502, "test_mcc": 0.4198145433950831, "test_macro_f1": 0.4712014478556779, "test_runtime": 1.3312, "test_samples_per_second": 1538.466, "test_steps_per_second": 48.077}, {"test_loss": 0.9049941897392273, "test_mcc": 0.38481210264616794, "test_macro_f1": 0.45616649804885095, "test_runtime": 1.3243, "test_samples_per_second": 1546.532, "test_steps_per_second": 48.329}, {"test_loss": 0.8288689851760864, "test_mcc": 0.4394472245587273, "test_macro_f1": 0.47854025271964834, "test_runtime": 1.3282, "test_samples_per_second": 1541.966, "test_steps_per_second": 48.186}, {"test_loss": 0.8539559841156006, "test_mcc": 0.414857615355247, "test_macro_f1": 0.46393488166135244, "test_runtime": 1.2848, "test_samples_per_second": 1594.065, "test_steps_per_second": 49.815}, {"test_loss": 0.8745488524436951, "test_mcc": 0.38521818276290376, "test_macro_f1": 0.45680897513680546, "test_runtime": 1.3555, "test_samples_per_second": 1510.845, "test_steps_per_second": 47.214}, {"test_loss": 0.88334059715271, "test_mcc": 0.400706176233116, "test_macro_f1": 0.4632071632071632, "test_runtime": 1.3299, "test_samples_per_second": 1539.933, "test_steps_per_second": 48.123}]}, "total": {"test_mcc": 40.14684754858543, "test_mcc_se": 1.1500993450161536, "test_macro_f1": 46.25695413015801, "test_macro_f1_se": 0.46817747941909316}}, "num_model_parameters": 21944195, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.08527276664972305, "test_micro_f1": 0.6490264603095356, "test_micro_f1_no_misc": 0.7356051703877791, "test_runtime": 2.9032, "test_samples_per_second": 705.419, "test_steps_per_second": 22.044}, {"test_loss": 0.08493853360414505, "test_micro_f1": 0.673992673992674, "test_micro_f1_no_misc": 0.7147613762486127, "test_runtime": 2.7603, "test_samples_per_second": 741.942, "test_steps_per_second": 23.186}, {"test_loss": 0.08184445649385452, "test_micro_f1": 0.6341463414634146, "test_micro_f1_no_misc": 0.6697341513292434, "test_runtime": 2.8446, "test_samples_per_second": 719.968, "test_steps_per_second": 22.499}, {"test_loss": 0.08227979391813278, "test_micro_f1": 0.6705998033431662, "test_micro_f1_no_misc": 0.7119363395225465, "test_runtime": 2.876, "test_samples_per_second": 712.099, "test_steps_per_second": 22.253}, {"test_loss": 0.08497130125761032, "test_micro_f1": 0.6365330848089469, "test_micro_f1_no_misc": 0.6974093264248704, "test_runtime": 2.9883, "test_samples_per_second": 685.35, "test_steps_per_second": 21.417}, {"test_loss": 0.07759259641170502, "test_micro_f1": 0.6855025474756831, "test_micro_f1_no_misc": 0.7452196382428941, "test_runtime": 2.6046, "test_samples_per_second": 786.301, "test_steps_per_second": 24.572}, {"test_loss": 0.08476321399211884, "test_micro_f1": 0.6255380200860832, "test_micro_f1_no_misc": 0.6950276243093921, "test_runtime": 2.7656, "test_samples_per_second": 740.531, "test_steps_per_second": 23.142}, {"test_loss": 0.07518573105335236, "test_micro_f1": 0.6422018348623854, "test_micro_f1_no_misc": 0.6766398158803223, "test_runtime": 2.9442, "test_samples_per_second": 695.601, "test_steps_per_second": 21.738}, {"test_loss": 0.07084658741950989, "test_micro_f1": 0.6765550239234449, "test_micro_f1_no_misc": 0.7372380440623321, "test_runtime": 2.921, "test_samples_per_second": 701.129, "test_steps_per_second": 21.91}, {"test_loss": 0.07883334904909134, "test_micro_f1": 0.6514285714285715, "test_micro_f1_no_misc": 0.7231516459794927, "test_runtime": 2.9671, "test_samples_per_second": 690.243, "test_steps_per_second": 21.57}]}, "total": {"test_micro_f1": 65.45524361693906, "test_micro_f1_se": 1.2824716090014925, "test_micro_f1_no_misc": 71.06723132387486, "test_micro_f1_no_misc_se": 1.59361943557043}}, "num_model_parameters": 21879945, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.08904259651899338, "test_micro_f1": 0.7624451895795717, "test_micro_f1_no_misc": 0.7874445581712727, "test_runtime": 3.1809, "test_samples_per_second": 643.845, "test_steps_per_second": 20.12}, {"test_loss": 0.08289045095443726, "test_micro_f1": 0.7636264037250069, "test_micro_f1_no_misc": 0.7928519328956966, "test_runtime": 2.8728, "test_samples_per_second": 712.891, "test_steps_per_second": 22.278}, {"test_loss": 0.1033698320388794, "test_micro_f1": 0.7474907554146857, "test_micro_f1_no_misc": 0.787666433076384, "test_runtime": 3.1288, "test_samples_per_second": 654.563, "test_steps_per_second": 20.455}, {"test_loss": 0.09165708720684052, "test_micro_f1": 0.7505791505791506, "test_micro_f1_no_misc": 0.7743484224965708, "test_runtime": 3.2379, "test_samples_per_second": 632.511, "test_steps_per_second": 19.766}, {"test_loss": 0.09196756780147552, "test_micro_f1": 0.7428896473265074, "test_micro_f1_no_misc": 0.7749351130886171, "test_runtime": 3.0867, "test_samples_per_second": 663.501, "test_steps_per_second": 20.734}, {"test_loss": 0.08824783563613892, "test_micro_f1": 0.7662125340599455, "test_micro_f1_no_misc": 0.7813303932377802, "test_runtime": 2.9574, "test_samples_per_second": 692.512, "test_steps_per_second": 21.641}, {"test_loss": 0.11242461949586868, "test_micro_f1": 0.7155149934810952, "test_micro_f1_no_misc": 0.7420349434737924, "test_runtime": 3.2109, "test_samples_per_second": 637.825, "test_steps_per_second": 19.932}, {"test_loss": 0.09412944316864014, "test_micro_f1": 0.7249524843877274, "test_micro_f1_no_misc": 0.7690058479532165, "test_runtime": 3.0715, "test_samples_per_second": 666.781, "test_steps_per_second": 20.837}, {"test_loss": 0.08548387140035629, "test_micro_f1": 0.772060783790989, "test_micro_f1_no_misc": 0.7900612171407995, "test_runtime": 3.0987, "test_samples_per_second": 660.927, "test_steps_per_second": 20.654}, {"test_loss": 0.0827198326587677, "test_micro_f1": 0.7693527080581241, "test_micro_f1_no_misc": 0.7977448907681466, "test_runtime": 2.9993, "test_samples_per_second": 682.829, "test_steps_per_second": 21.338}]}, "total": {"test_micro_f1": 75.15124650402804, "test_micro_f1_se": 1.1896266102721602, "test_micro_f1_no_misc": 77.97423752302277, "test_micro_f1_no_misc_se": 0.9943539317365335}}, "num_model_parameters": 21879945, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.061686448752880096, "test_micro_f1": 0.8116575591985429, "test_micro_f1_no_misc": 0.8509240246406571, "test_runtime": 2.7466, "test_samples_per_second": 745.642, "test_steps_per_second": 23.301}, {"test_loss": 0.059388697147369385, "test_micro_f1": 0.8093126385809313, "test_micro_f1_no_misc": 0.840227088402271, "test_runtime": 2.6989, "test_samples_per_second": 758.841, "test_steps_per_second": 23.714}, {"test_loss": 0.06596580892801285, "test_micro_f1": 0.801959412176347, "test_micro_f1_no_misc": 0.8403232012312428, "test_runtime": 2.7843, "test_samples_per_second": 735.546, "test_steps_per_second": 22.986}, {"test_loss": 0.04916372522711754, "test_micro_f1": 0.8347398030942335, "test_micro_f1_no_misc": 0.8645874457165417, "test_runtime": 2.5643, "test_samples_per_second": 798.669, "test_steps_per_second": 24.958}, {"test_loss": 0.05680960416793823, "test_micro_f1": 0.8248663101604277, "test_micro_f1_no_misc": 0.8516605166051661, "test_runtime": 2.7403, "test_samples_per_second": 747.357, "test_steps_per_second": 23.355}, {"test_loss": 0.055996522307395935, "test_micro_f1": 0.8283378746594005, "test_micro_f1_no_misc": 0.8639760837070254, "test_runtime": 2.7017, "test_samples_per_second": 758.034, "test_steps_per_second": 23.689}, {"test_loss": 0.05839774012565613, "test_micro_f1": 0.8172780253685293, "test_micro_f1_no_misc": 0.8488327592805204, "test_runtime": 2.7302, "test_samples_per_second": 750.135, "test_steps_per_second": 23.442}, {"test_loss": 0.05585725978016853, "test_micro_f1": 0.8049620951068228, "test_micro_f1_no_misc": 0.8371396480718832, "test_runtime": 2.6763, "test_samples_per_second": 765.239, "test_steps_per_second": 23.914}, {"test_loss": 0.05229731276631355, "test_micro_f1": 0.8202929617720613, "test_micro_f1_no_misc": 0.8445158698272398, "test_runtime": 2.6232, "test_samples_per_second": 780.718, "test_steps_per_second": 24.397}, {"test_loss": 0.06239272654056549, "test_micro_f1": 0.8150170648464165, "test_micro_f1_no_misc": 0.8524220803604956, "test_runtime": 2.6842, "test_samples_per_second": 762.974, "test_steps_per_second": 23.843}]}, "total": {"test_micro_f1": 81.68423744963714, "test_micro_f1_se": 0.6462714934383157, "test_micro_f1_no_misc": 84.94608717843043, "test_micro_f1_no_misc_se": 0.5846046702041483}}, "num_model_parameters": 21879945, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.06714180111885071, "test_micro_f1": 0.7450030284675955, "test_micro_f1_no_misc": 0.7900262467191601, "test_runtime": 2.7719, "test_samples_per_second": 738.833, "test_steps_per_second": 23.089}, {"test_loss": 0.06478620320558548, "test_micro_f1": 0.8113035551504103, "test_micro_f1_no_misc": 0.8427843803056028, "test_runtime": 2.8405, "test_samples_per_second": 720.99, "test_steps_per_second": 22.531}, {"test_loss": 0.06420374661684036, "test_micro_f1": 0.7720144752714112, "test_micro_f1_no_misc": 0.8236850810453192, "test_runtime": 2.7903, "test_samples_per_second": 733.975, "test_steps_per_second": 22.937}, {"test_loss": 0.08031615614891052, "test_micro_f1": 0.7422985781990522, "test_micro_f1_no_misc": 0.7910592808551992, "test_runtime": 2.8693, "test_samples_per_second": 713.77, "test_steps_per_second": 22.305}, {"test_loss": 0.07793356478214264, "test_micro_f1": 0.7156511350059737, "test_micro_f1_no_misc": 0.7835186396337475, "test_runtime": 2.8162, "test_samples_per_second": 727.224, "test_steps_per_second": 22.726}, {"test_loss": 0.07878845930099487, "test_micro_f1": 0.704822777454968, "test_micro_f1_no_misc": 0.760501567398119, "test_runtime": 2.7741, "test_samples_per_second": 738.26, "test_steps_per_second": 23.071}, {"test_loss": 0.06427142769098282, "test_micro_f1": 0.7396757418170695, "test_micro_f1_no_misc": 0.7920265780730896, "test_runtime": 2.8563, "test_samples_per_second": 717.013, "test_steps_per_second": 22.407}, {"test_loss": 0.06824278831481934, "test_micro_f1": 0.7275449101796407, "test_micro_f1_no_misc": 0.7757891311422063, "test_runtime": 2.8731, "test_samples_per_second": 712.807, "test_steps_per_second": 22.275}, {"test_loss": 0.07530102878808975, "test_micro_f1": 0.7342700061087356, "test_micro_f1_no_misc": 0.7858572381587725, "test_runtime": 2.6964, "test_samples_per_second": 759.539, "test_steps_per_second": 23.736}, {"test_loss": 0.06798277795314789, "test_micro_f1": 0.7689508793208005, "test_micro_f1_no_misc": 0.8115471942912748, "test_runtime": 2.8196, "test_samples_per_second": 726.335, "test_steps_per_second": 22.698}]}, "total": {"test_micro_f1": 74.61535086975657, "test_micro_f1_se": 1.917876166720266, "test_micro_f1_no_misc": 79.5679533762249, "test_micro_f1_no_misc_se": 1.4896992352447815}}, "num_model_parameters": 21879945, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.4118046760559082, "test_mcc": 0.6891146661303742, "test_macro_f1": 0.8406008029551193, "test_runtime": 1.278, "test_samples_per_second": 1602.543, "test_steps_per_second": 50.079}, {"test_loss": 0.41224655508995056, "test_mcc": 0.7080578834249277, "test_macro_f1": 0.8523763151362396, "test_runtime": 1.3311, "test_samples_per_second": 1538.583, "test_steps_per_second": 48.081}, {"test_loss": 0.4017490744590759, "test_mcc": 0.7000348200629705, "test_macro_f1": 0.8480866438472081, "test_runtime": 1.2955, "test_samples_per_second": 1580.804, "test_steps_per_second": 49.4}, {"test_loss": 0.4372713565826416, "test_mcc": 0.6773462785784095, "test_macro_f1": 0.8351947825773636, "test_runtime": 1.2645, "test_samples_per_second": 1619.606, "test_steps_per_second": 50.613}, {"test_loss": 0.41989415884017944, "test_mcc": 0.6952805967075585, "test_macro_f1": 0.8419153831966322, "test_runtime": 1.2777, "test_samples_per_second": 1602.84, "test_steps_per_second": 50.089}, {"test_loss": 0.40842440724372864, "test_mcc": 0.681635061009715, "test_macro_f1": 0.8390782691226986, "test_runtime": 1.2978, "test_samples_per_second": 1578.028, "test_steps_per_second": 49.313}, {"test_loss": 0.40997493267059326, "test_mcc": 0.6928505559656148, "test_macro_f1": 0.8413999872928952, "test_runtime": 1.2589, "test_samples_per_second": 1626.832, "test_steps_per_second": 50.838}, {"test_loss": 0.4288644790649414, "test_mcc": 0.6803296834413826, "test_macro_f1": 0.8352531075826932, "test_runtime": 1.3055, "test_samples_per_second": 1568.756, "test_steps_per_second": 49.024}, {"test_loss": 0.41544169187545776, "test_mcc": 0.6880492940262725, "test_macro_f1": 0.8421568627450979, "test_runtime": 1.2753, "test_samples_per_second": 1605.933, "test_steps_per_second": 50.185}, {"test_loss": 0.41019406914711, "test_mcc": 0.7059379246716314, "test_macro_f1": 0.8496718289852557, "test_runtime": 1.2933, "test_samples_per_second": 1583.593, "test_steps_per_second": 49.487}]}, "total": {"test_mcc": 69.18636764018856, "test_mcc_se": 0.6566804903622303, "test_macro_f1": 84.25733983441204, "test_macro_f1_se": 0.3596312716617566}}, "num_model_parameters": 21943938, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.45298874378204346, "test_mcc": 0.6406951721067939, "test_macro_f1": 0.812365948122888, "test_runtime": 1.3501, "test_samples_per_second": 1516.917, "test_steps_per_second": 47.404}, {"test_loss": 0.43499356508255005, "test_mcc": 0.6690319761687472, "test_macro_f1": 0.8307130707337118, "test_runtime": 1.3685, "test_samples_per_second": 1496.482, "test_steps_per_second": 46.765}, {"test_loss": 0.42070722579956055, "test_mcc": 0.6929617744146424, "test_macro_f1": 0.8462984296947824, "test_runtime": 1.342, "test_samples_per_second": 1526.075, "test_steps_per_second": 47.69}, {"test_loss": 0.4319998621940613, "test_mcc": 0.6771398473302088, "test_macro_f1": 0.8376428877070725, "test_runtime": 1.3541, "test_samples_per_second": 1512.419, "test_steps_per_second": 47.263}, {"test_loss": 0.46071046590805054, "test_mcc": 0.682626646171437, "test_macro_f1": 0.839611099703454, "test_runtime": 1.373, "test_samples_per_second": 1491.667, "test_steps_per_second": 46.615}, {"test_loss": 0.43013548851013184, "test_mcc": 0.6549980152988542, "test_macro_f1": 0.8255928886847608, "test_runtime": 1.3152, "test_samples_per_second": 1557.163, "test_steps_per_second": 48.661}, {"test_loss": 0.42045027017593384, "test_mcc": 0.6667218691918761, "test_macro_f1": 0.8302458231843575, "test_runtime": 1.3322, "test_samples_per_second": 1537.347, "test_steps_per_second": 48.042}, {"test_loss": 0.4008127450942993, "test_mcc": 0.6971993589689025, "test_macro_f1": 0.8478441231689362, "test_runtime": 1.3419, "test_samples_per_second": 1526.154, "test_steps_per_second": 47.692}, {"test_loss": 0.45982688665390015, "test_mcc": 0.6749333183773815, "test_macro_f1": 0.8326628504414613, "test_runtime": 1.3597, "test_samples_per_second": 1506.228, "test_steps_per_second": 47.07}, {"test_loss": 0.4260125458240509, "test_mcc": 0.6706713465798105, "test_macro_f1": 0.83371780360017, "test_runtime": 1.3638, "test_samples_per_second": 1501.699, "test_steps_per_second": 46.928}]}, "total": {"test_mcc": 67.26979324608654, "test_mcc_se": 1.0381574516250103, "test_macro_f1": 83.36694925041594, "test_macro_f1_se": 0.6374775619579053}}, "num_model_parameters": 21943938, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.39100712537765503, "test_mcc": 0.716538609111444, "test_macro_f1": 0.8507496437905767, "test_runtime": 1.3103, "test_samples_per_second": 1562.96, "test_steps_per_second": 48.843}, {"test_loss": 0.41419950127601624, "test_mcc": 0.702214784411003, "test_macro_f1": 0.8455399887229251, "test_runtime": 1.3206, "test_samples_per_second": 1550.775, "test_steps_per_second": 48.462}, {"test_loss": 0.375224769115448, "test_mcc": 0.742241234473579, "test_macro_f1": 0.8691255227930621, "test_runtime": 1.3173, "test_samples_per_second": 1554.704, "test_steps_per_second": 48.585}, {"test_loss": 0.3557837903499603, "test_mcc": 0.7556441499192627, "test_macro_f1": 0.8737313725730098, "test_runtime": 1.2738, "test_samples_per_second": 1607.781, "test_steps_per_second": 50.243}, {"test_loss": 0.3967108726501465, "test_mcc": 0.727672083122965, "test_macro_f1": 0.8542908775274982, "test_runtime": 1.3469, "test_samples_per_second": 1520.531, "test_steps_per_second": 47.517}, {"test_loss": 0.36456629633903503, "test_mcc": 0.7507339693277704, "test_macro_f1": 0.8689411807726766, "test_runtime": 1.26, "test_samples_per_second": 1625.437, "test_steps_per_second": 50.795}, {"test_loss": 0.3764584958553314, "test_mcc": 0.7374798456207102, "test_macro_f1": 0.8650739607978918, "test_runtime": 1.2646, "test_samples_per_second": 1619.512, "test_steps_per_second": 50.61}, {"test_loss": 0.40178972482681274, "test_mcc": 0.7099917471342857, "test_macro_f1": 0.8492887794826804, "test_runtime": 1.3069, "test_samples_per_second": 1567.011, "test_steps_per_second": 48.969}, {"test_loss": 0.40478378534317017, "test_mcc": 0.7145868619654263, "test_macro_f1": 0.8485751731016806, "test_runtime": 1.2948, "test_samples_per_second": 1581.693, "test_steps_per_second": 49.428}, {"test_loss": 0.3866497278213501, "test_mcc": 0.7299561838281464, "test_macro_f1": 0.8610353728663079, "test_runtime": 1.3104, "test_samples_per_second": 1562.849, "test_steps_per_second": 48.839}]}, "total": {"test_mcc": 72.87059468914593, "test_mcc_se": 1.107417048259467, "test_macro_f1": 85.8635187242831, "test_macro_f1_se": 0.6308887950919564}}, "num_model_parameters": 21943938, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_loss": 0.4549486041069031, "test_mcc": 0.6363248716673467, "test_macro_f1": 0.8125, "test_runtime": 1.3279, "test_samples_per_second": 1542.26, "test_steps_per_second": 48.196}, {"test_loss": 0.4310624599456787, "test_mcc": 0.6560296619082888, "test_macro_f1": 0.8276149769598988, "test_runtime": 1.3546, "test_samples_per_second": 1511.923, "test_steps_per_second": 47.248}, {"test_loss": 0.4458950161933899, "test_mcc": 0.6592411093260105, "test_macro_f1": 0.8283831250854984, "test_runtime": 1.3803, "test_samples_per_second": 1483.698, "test_steps_per_second": 46.366}, {"test_loss": 0.44194507598876953, "test_mcc": 0.6465345964958888, "test_macro_f1": 0.8218360076641116, "test_runtime": 1.3089, "test_samples_per_second": 1564.715, "test_steps_per_second": 48.897}, {"test_loss": 0.4543665051460266, "test_mcc": 0.6199671625404471, "test_macro_f1": 0.8094785766470926, "test_runtime": 1.3667, "test_samples_per_second": 1498.54, "test_steps_per_second": 46.829}, {"test_loss": 0.4371407628059387, "test_mcc": 0.6481870881513997, "test_macro_f1": 0.8222163655264305, "test_runtime": 1.3285, "test_samples_per_second": 1541.583, "test_steps_per_second": 48.174}, {"test_loss": 0.4790181815624237, "test_mcc": 0.5986928502961438, "test_macro_f1": 0.7987905148896393, "test_runtime": 1.3171, "test_samples_per_second": 1554.873, "test_steps_per_second": 48.59}, {"test_loss": 0.4638766050338745, "test_mcc": 0.6206838944855948, "test_macro_f1": 0.8047875159319091, "test_runtime": 1.3543, "test_samples_per_second": 1512.264, "test_steps_per_second": 47.258}, {"test_loss": 0.4616134762763977, "test_mcc": 0.6294283107672347, "test_macro_f1": 0.8093316989153878, "test_runtime": 1.3333, "test_samples_per_second": 1535.981, "test_steps_per_second": 47.999}, {"test_loss": 0.4357273578643799, "test_mcc": 0.6619643402687728, "test_macro_f1": 0.826695527666846, "test_runtime": 1.3185, "test_samples_per_second": 1553.234, "test_steps_per_second": 48.539}]}, "total": {"test_mcc": 63.770538859071266, "test_mcc_se": 1.2689902820206944, "test_macro_f1": 81.61634309286814, "test_macro_f1_se": 0.652094175321914}}, "num_model_parameters": 21943938, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_em": 18.512780790085205, "test_f1": 20.03225219063376}, {"test_em": 14.883720930232558, "test_f1": 16.300877973928593}, {"test_em": 15.069551777434313, "test_f1": 16.407508014741456}, {"test_em": 4.283489096573208, "test_f1": 4.651644346531647}, {"test_em": 16.91119691119691, "test_f1": 18.70361721135716}, {"test_em": 3.9321511179645334, "test_f1": 4.250864056750945}, {"test_em": 20.72892938496583, "test_f1": 22.800005848060472}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 4.9411764705882355, "test_f1": 5.02237600922722}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 9.926299647904079, "test_em_se": 4.9753285387619535, "test_f1": 10.816914565123124, "test_f1_se": 5.4691341791509345}}, "num_model_parameters": 21878146, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_em": 5.267234701781565, "test_f1": 5.76186787650769}, {"test_em": 3.255813953488372, "test_f1": 3.4008859357696566}, {"test_em": 16.306027820710973, "test_f1": 17.819460903898023}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 10.81081081081081, "test_f1": 12.537946710215618}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 1.366742596810934, "test_f1": 1.5021930739470604}, {"test_em": 13.886733902249807, "test_f1": 14.789869211901795}, {"test_em": 16.0, "test_f1": 17.64683695133522}, {"test_em": 13.74223602484472, "test_f1": 15.36303288164359}]}, "total": {"test_em": 8.06355998106972, "test_em_se": 4.185683284630362, "test_f1": 8.882209354521866, "test_f1_se": 4.615107359484933}}, "num_model_parameters": 21878146, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_em": 19.907048799380327, "test_f1": 22.243190151788145}, {"test_em": 19.92248062015504, "test_f1": 22.35917524112722}, {"test_em": 20.633693972179287, "test_f1": 23.03368277693679}, {"test_em": 13.940809968847352, "test_f1": 15.13089222631771}, {"test_em": 2.0849420849420848, "test_f1": 2.4028314028314033}, {"test_em": 10.33153430994603, "test_f1": 11.243467831748479}, {"test_em": 20.804859529233106, "test_f1": 23.112353823153853}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 11.450980392156863, "test_f1": 12.776077952548539}, {"test_em": 17.31366459627329, "test_f1": 18.84782731309014}]}, "total": {"test_em": 13.639001427311339, "test_em_se": 4.746840686677812, "test_f1": 15.114949871954229, "test_f1_se": 5.285173507556847}}, "num_model_parameters": 21878146, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.3781386613845825, "test_mcc": 0.7514661696093663, "test_macro_f1": 0.7152663231023405, "test_runtime": 13.2805, "test_samples_per_second": 154.211, "test_steps_per_second": 19.276}, {"test_loss": 0.405578076839447, "test_mcc": 0.7273668165192013, "test_macro_f1": 0.6811715751067879, "test_runtime": 12.5531, "test_samples_per_second": 163.148, "test_steps_per_second": 20.393}, {"test_loss": 0.41450735926628113, "test_mcc": 0.7524610645116582, "test_macro_f1": 0.7310707148907455, "test_runtime": 13.0527, "test_samples_per_second": 156.903, "test_steps_per_second": 19.613}, {"test_loss": 0.3598492741584778, "test_mcc": 0.7708808932438764, "test_macro_f1": 0.7291105097870137, "test_runtime": 12.3701, "test_samples_per_second": 165.56, "test_steps_per_second": 20.695}, {"test_loss": 0.36654791235923767, "test_mcc": 0.7745992763368763, "test_macro_f1": 0.7623254191425919, "test_runtime": 12.1511, "test_samples_per_second": 168.544, "test_steps_per_second": 21.068}, {"test_loss": 0.41108399629592896, "test_mcc": 0.7420095095973651, "test_macro_f1": 0.686576397089062, "test_runtime": 12.6701, "test_samples_per_second": 161.64, "test_steps_per_second": 20.205}, {"test_loss": 0.36370131373405457, "test_mcc": 0.7856322035948391, "test_macro_f1": 0.786481117386829, "test_runtime": 12.0589, "test_samples_per_second": 169.833, "test_steps_per_second": 21.229}, {"test_loss": 0.3873511254787445, "test_mcc": 0.7716175118654532, "test_macro_f1": 0.7838508708069192, "test_runtime": 13.104, "test_samples_per_second": 156.288, "test_steps_per_second": 19.536}, {"test_loss": 0.40680158138275146, "test_mcc": 0.7445182300909116, "test_macro_f1": 0.7240541004796873, "test_runtime": 13.0541, "test_samples_per_second": 156.886, "test_steps_per_second": 19.611}, {"test_loss": 0.3972923159599304, "test_mcc": 0.7370019693305851, "test_macro_f1": 0.7352721711220228, "test_runtime": 12.6251, "test_samples_per_second": 162.216, "test_steps_per_second": 20.277}]}, "total": {"test_mcc": 75.57553644700133, "test_mcc_se": 1.1742162586535727, "test_macro_f1": 73.35179198914, "test_macro_f1_se": 2.2216408362370688}}, "num_model_parameters": 124693251, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.9615168571472168, "test_mcc": 0.29489875456228776, "test_macro_f1": 0.5047777842450831, "test_runtime": 5.0883, "test_samples_per_second": 402.493, "test_steps_per_second": 12.578}, {"test_loss": 0.9094290733337402, "test_mcc": 0.3508761580078752, "test_macro_f1": 0.5424597635882911, "test_runtime": 4.9988, "test_samples_per_second": 409.697, "test_steps_per_second": 12.803}, {"test_loss": 0.987464427947998, "test_mcc": 0.3198564099194696, "test_macro_f1": 0.5263350740852327, "test_runtime": 4.9768, "test_samples_per_second": 411.509, "test_steps_per_second": 12.86}, {"test_loss": 0.9529597759246826, "test_mcc": 0.356011357444607, "test_macro_f1": 0.5644418060479324, "test_runtime": 5.1025, "test_samples_per_second": 401.374, "test_steps_per_second": 12.543}, {"test_loss": 0.9817847609519958, "test_mcc": 0.3381418786097192, "test_macro_f1": 0.5336526028446914, "test_runtime": 4.9474, "test_samples_per_second": 413.951, "test_steps_per_second": 12.936}, {"test_loss": 0.9612485766410828, "test_mcc": 0.3082107366988027, "test_macro_f1": 0.5394065227194761, "test_runtime": 5.0206, "test_samples_per_second": 407.918, "test_steps_per_second": 12.747}, {"test_loss": 0.9229481220245361, "test_mcc": 0.31634474432768855, "test_macro_f1": 0.5343794453527867, "test_runtime": 5.0352, "test_samples_per_second": 406.734, "test_steps_per_second": 12.71}, {"test_loss": 0.9343096613883972, "test_mcc": 0.3871929381575063, "test_macro_f1": 0.5917074755370203, "test_runtime": 5.1004, "test_samples_per_second": 401.538, "test_steps_per_second": 12.548}, {"test_loss": 0.9746894240379333, "test_mcc": 0.3236574575484104, "test_macro_f1": 0.5478094732439928, "test_runtime": 5.0441, "test_samples_per_second": 406.019, "test_steps_per_second": 12.688}, {"test_loss": 0.9769160747528076, "test_mcc": 0.33291921722471024, "test_macro_f1": 0.5523467293848341, "test_runtime": 4.9827, "test_samples_per_second": 411.019, "test_steps_per_second": 12.844}]}, "total": {"test_mcc": 33.281096525010774, "test_mcc_se": 1.6548417884423718, "test_macro_f1": 54.373166770493405, "test_macro_f1_se": 1.4389447512631055}}, "num_model_parameters": 124693251, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.845862865447998, "test_mcc": 0.36557362448541, "test_macro_f1": 0.47623756362201614, "test_runtime": 4.0346, "test_samples_per_second": 507.607, "test_steps_per_second": 15.863}, {"test_loss": 0.8795698285102844, "test_mcc": 0.4098878232609586, "test_macro_f1": 0.5636187352337615, "test_runtime": 3.8134, "test_samples_per_second": 537.056, "test_steps_per_second": 16.783}, {"test_loss": 0.833829402923584, "test_mcc": 0.4305641633060027, "test_macro_f1": 0.5336380141337815, "test_runtime": 3.7719, "test_samples_per_second": 542.962, "test_steps_per_second": 16.968}, {"test_loss": 0.8858659863471985, "test_mcc": 0.29927853709368535, "test_macro_f1": 0.4189541128405783, "test_runtime": 3.8654, "test_samples_per_second": 529.829, "test_steps_per_second": 16.557}, {"test_loss": 0.8684579730033875, "test_mcc": 0.3754776877315237, "test_macro_f1": 0.5179222359273418, "test_runtime": 3.9771, "test_samples_per_second": 514.949, "test_steps_per_second": 16.092}, {"test_loss": 0.8333405256271362, "test_mcc": 0.3680067463517807, "test_macro_f1": 0.45976698274045386, "test_runtime": 4.0354, "test_samples_per_second": 507.51, "test_steps_per_second": 15.86}, {"test_loss": 0.8720055818557739, "test_mcc": 0.4315320304420727, "test_macro_f1": 0.5838902979604165, "test_runtime": 3.8675, "test_samples_per_second": 529.536, "test_steps_per_second": 16.548}, {"test_loss": 0.8982617855072021, "test_mcc": 0.4259487968838951, "test_macro_f1": 0.5546380589272747, "test_runtime": 3.9075, "test_samples_per_second": 524.122, "test_steps_per_second": 16.379}, {"test_loss": 0.8223052620887756, "test_mcc": 0.39530182430503424, "test_macro_f1": 0.5289192044085408, "test_runtime": 4.0595, "test_samples_per_second": 504.501, "test_steps_per_second": 15.766}, {"test_loss": 0.8578101396560669, "test_mcc": 0.3687962218550026, "test_macro_f1": 0.45062886091893345, "test_runtime": 4.0348, "test_samples_per_second": 507.581, "test_steps_per_second": 15.862}]}, "total": {"test_mcc": 38.703674557153654, "test_mcc_se": 2.527795180855096, "test_macro_f1": 50.88214066713098, "test_macro_f1_se": 3.38035500508709}}, "num_model_parameters": 124693251, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.05042233318090439, "test_micro_f1": 0.7640449438202247, "test_micro_f1_no_misc": 0.8319526627218935, "test_runtime": 6.4498, "test_samples_per_second": 317.528, "test_steps_per_second": 9.923}, {"test_loss": 0.048688050359487534, "test_micro_f1": 0.7924528301886792, "test_micro_f1_no_misc": 0.8462013588634961, "test_runtime": 5.9823, "test_samples_per_second": 342.343, "test_steps_per_second": 10.698}, {"test_loss": 0.04794241860508919, "test_micro_f1": 0.7403100775193799, "test_micro_f1_no_misc": 0.7903225806451613, "test_runtime": 5.9082, "test_samples_per_second": 346.639, "test_steps_per_second": 10.832}, {"test_loss": 0.05371470749378204, "test_micro_f1": 0.7215909090909092, "test_micro_f1_no_misc": 0.7748132337246533, "test_runtime": 6.445, "test_samples_per_second": 317.765, "test_steps_per_second": 9.93}, {"test_loss": 0.05015813559293747, "test_micro_f1": 0.7632575757575757, "test_micro_f1_no_misc": 0.8172506738544475, "test_runtime": 6.4223, "test_samples_per_second": 318.89, "test_steps_per_second": 9.965}, {"test_loss": 0.042423177510499954, "test_micro_f1": 0.7912920018930429, "test_micro_f1_no_misc": 0.8411924119241191, "test_runtime": 5.0044, "test_samples_per_second": 409.24, "test_steps_per_second": 12.789}, {"test_loss": 0.04988863691687584, "test_micro_f1": 0.7442988840368754, "test_micro_f1_no_misc": 0.8052805280528053, "test_runtime": 5.3404, "test_samples_per_second": 383.49, "test_steps_per_second": 11.984}, {"test_loss": 0.04577796161174774, "test_micro_f1": 0.7630566245189665, "test_micro_f1_no_misc": 0.8040201005025126, "test_runtime": 6.3801, "test_samples_per_second": 320.997, "test_steps_per_second": 10.031}, {"test_loss": 0.036836255341768265, "test_micro_f1": 0.7988281249999999, "test_micro_f1_no_misc": 0.843886462882096, "test_runtime": 5.9585, "test_samples_per_second": 343.709, "test_steps_per_second": 10.741}, {"test_loss": 0.04633473977446556, "test_micro_f1": 0.787109375, "test_micro_f1_no_misc": 0.8403083700440529, "test_runtime": 6.424, "test_samples_per_second": 318.804, "test_steps_per_second": 9.963}]}, "total": {"test_micro_f1": 76.66241346825655, "test_micro_f1_se": 1.5979200633652435, "test_micro_f1_no_misc": 81.95228383215237, "test_micro_f1_no_misc_se": 1.5545192828862906}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06982472538948059, "test_micro_f1": 0.7998981670061099, "test_micro_f1_no_misc": 0.8318339100346022, "test_runtime": 9.0745, "test_samples_per_second": 225.689, "test_steps_per_second": 7.053}, {"test_loss": 0.06563049554824829, "test_micro_f1": 0.7862339115836596, "test_micro_f1_no_misc": 0.8146788990825687, "test_runtime": 7.6076, "test_samples_per_second": 269.205, "test_steps_per_second": 8.413}, {"test_loss": 0.06765903532505035, "test_micro_f1": 0.797979797979798, "test_micro_f1_no_misc": 0.8315098468271336, "test_runtime": 9.4322, "test_samples_per_second": 217.129, "test_steps_per_second": 6.785}, {"test_loss": 0.08081944286823273, "test_micro_f1": 0.7730660498586482, "test_micro_f1_no_misc": 0.8012640449438202, "test_runtime": 8.7611, "test_samples_per_second": 233.761, "test_steps_per_second": 7.305}, {"test_loss": 0.07803845405578613, "test_micro_f1": 0.7742651136993898, "test_micro_f1_no_misc": 0.800304298212248, "test_runtime": 9.4899, "test_samples_per_second": 215.809, "test_steps_per_second": 6.744}, {"test_loss": 0.07129403203725815, "test_micro_f1": 0.8005540166204986, "test_micro_f1_no_misc": 0.8171322160148976, "test_runtime": 9.0709, "test_samples_per_second": 225.776, "test_steps_per_second": 7.056}, {"test_loss": 0.08478260040283203, "test_micro_f1": 0.7817069928210583, "test_micro_f1_no_misc": 0.8075526506899058, "test_runtime": 9.5047, "test_samples_per_second": 215.472, "test_steps_per_second": 6.733}, {"test_loss": 0.0647832453250885, "test_micro_f1": 0.7795039520305261, "test_micro_f1_no_misc": 0.8121526491293073, "test_runtime": 9.0237, "test_samples_per_second": 226.958, "test_steps_per_second": 7.092}, {"test_loss": 0.07227785885334015, "test_micro_f1": 0.7910328262610088, "test_micro_f1_no_misc": 0.8080882352941177, "test_runtime": 8.7407, "test_samples_per_second": 234.306, "test_steps_per_second": 7.322}, {"test_loss": 0.07561728358268738, "test_micro_f1": 0.8151125401929261, "test_micro_f1_no_misc": 0.8397058823529412, "test_runtime": 7.5212, "test_samples_per_second": 272.296, "test_steps_per_second": 8.509}]}, "total": {"test_micro_f1": 78.99353368053623, "test_micro_f1_se": 0.834675836438913, "test_micro_f1_no_misc": 81.64222632581544, "test_micro_f1_no_misc_se": 0.8434683476552244}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.054984454065561295, "test_micro_f1": 0.7911764705882353, "test_micro_f1_no_misc": 0.8316993464052287, "test_runtime": 7.0106, "test_samples_per_second": 292.13, "test_steps_per_second": 9.129}, {"test_loss": 0.043405238538980484, "test_micro_f1": 0.8179104477611941, "test_micro_f1_no_misc": 0.8460264900662253, "test_runtime": 6.9335, "test_samples_per_second": 295.376, "test_steps_per_second": 9.231}, {"test_loss": 0.0514991357922554, "test_micro_f1": 0.8208647906657516, "test_micro_f1_no_misc": 0.8565861262665628, "test_runtime": 6.682, "test_samples_per_second": 306.497, "test_steps_per_second": 9.578}, {"test_loss": 0.04234390705823898, "test_micro_f1": 0.8495636998254799, "test_micro_f1_no_misc": 0.875735005880047, "test_runtime": 6.6966, "test_samples_per_second": 305.828, "test_steps_per_second": 9.557}, {"test_loss": 0.0457116924226284, "test_micro_f1": 0.8549413735343384, "test_micro_f1_no_misc": 0.8773234200743495, "test_runtime": 7.0707, "test_samples_per_second": 289.645, "test_steps_per_second": 9.051}, {"test_loss": 0.04191185161471367, "test_micro_f1": 0.8513836692859582, "test_micro_f1_no_misc": 0.8745762711864407, "test_runtime": 6.933, "test_samples_per_second": 295.399, "test_steps_per_second": 9.231}, {"test_loss": 0.04568038508296013, "test_micro_f1": 0.8451767936834877, "test_micro_f1_no_misc": 0.867590454195535, "test_runtime": 6.4289, "test_samples_per_second": 318.56, "test_steps_per_second": 9.955}, {"test_loss": 0.051316313445568085, "test_micro_f1": 0.82930200414651, "test_micro_f1_no_misc": 0.8532934131736527, "test_runtime": 6.5701, "test_samples_per_second": 311.716, "test_steps_per_second": 9.741}, {"test_loss": 0.04737057536840439, "test_micro_f1": 0.8087774294670846, "test_micro_f1_no_misc": 0.8415124698310539, "test_runtime": 6.6838, "test_samples_per_second": 306.414, "test_steps_per_second": 9.575}, {"test_loss": 0.04939356818795204, "test_micro_f1": 0.8354517347990381, "test_micro_f1_no_misc": 0.8669724770642202, "test_runtime": 6.654, "test_samples_per_second": 307.784, "test_steps_per_second": 9.618}]}, "total": {"test_micro_f1": 83.0454841375708, "test_micro_f1_se": 1.2915228285835354, "test_micro_f1_no_misc": 85.91315474143316, "test_micro_f1_no_misc_se": 0.9807521104050815}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06128117814660072, "test_micro_f1": 0.7646877883728085, "test_micro_f1_no_misc": 0.8055461616503212, "test_runtime": 6.6872, "test_samples_per_second": 306.256, "test_steps_per_second": 9.57}, {"test_loss": 0.061653587967157364, "test_micro_f1": 0.787583688374924, "test_micro_f1_no_misc": 0.8218623481781377, "test_runtime": 6.7929, "test_samples_per_second": 301.49, "test_steps_per_second": 9.422}, {"test_loss": 0.06796877831220627, "test_micro_f1": 0.7407862407862409, "test_micro_f1_no_misc": 0.7816013628620103, "test_runtime": 6.4057, "test_samples_per_second": 319.714, "test_steps_per_second": 9.991}, {"test_loss": 0.07700859010219574, "test_micro_f1": 0.6949203486624587, "test_micro_f1_no_misc": 0.7421018697614442, "test_runtime": 6.5878, "test_samples_per_second": 310.877, "test_steps_per_second": 9.715}, {"test_loss": 0.07046996057033539, "test_micro_f1": 0.7236686390532543, "test_micro_f1_no_misc": 0.7707349966284558, "test_runtime": 6.3467, "test_samples_per_second": 322.689, "test_steps_per_second": 10.084}, {"test_loss": 0.06333931535482407, "test_micro_f1": 0.7908378541289933, "test_micro_f1_no_misc": 0.8236096895257592, "test_runtime": 6.2187, "test_samples_per_second": 329.33, "test_steps_per_second": 10.292}, {"test_loss": 0.062341075390577316, "test_micro_f1": 0.7563329312424608, "test_micro_f1_no_misc": 0.7954239569313594, "test_runtime": 6.7529, "test_samples_per_second": 303.279, "test_steps_per_second": 9.477}, {"test_loss": 0.057342544198036194, "test_micro_f1": 0.7967731926776295, "test_micro_f1_no_misc": 0.8223140495867769, "test_runtime": 6.7766, "test_samples_per_second": 302.219, "test_steps_per_second": 9.444}, {"test_loss": 0.07135243713855743, "test_micro_f1": 0.7623456790123457, "test_micro_f1_no_misc": 0.7936288088642659, "test_runtime": 6.2513, "test_samples_per_second": 327.611, "test_steps_per_second": 10.238}, {"test_loss": 0.06349527835845947, "test_micro_f1": 0.7817351598173516, "test_micro_f1_no_misc": 0.809950248756219, "test_runtime": 6.528, "test_samples_per_second": 313.724, "test_steps_per_second": 9.804}]}, "total": {"test_micro_f1": 75.99671522128467, "test_micro_f1_se": 2.0139130620228216, "test_micro_f1_no_misc": 79.6677349274475, "test_micro_f1_no_misc_se": 1.6217070216041827}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.30675774812698364, "test_mcc": 0.7787409878485776, "test_macro_f1": 0.883500083654007, "test_runtime": 2.7224, "test_samples_per_second": 752.278, "test_steps_per_second": 23.509}, {"test_loss": 0.30865755677223206, "test_mcc": 0.8057315679122093, "test_macro_f1": 0.9012707722385143, "test_runtime": 2.8306, "test_samples_per_second": 723.522, "test_steps_per_second": 22.61}, {"test_loss": 0.2911263704299927, "test_mcc": 0.800490021398163, "test_macro_f1": 0.8988569236670503, "test_runtime": 2.8751, "test_samples_per_second": 712.315, "test_steps_per_second": 22.26}, {"test_loss": 0.2896273136138916, "test_mcc": 0.8024387151216387, "test_macro_f1": 0.8988715673123666, "test_runtime": 2.7479, "test_samples_per_second": 745.296, "test_steps_per_second": 23.29}, {"test_loss": 0.32368946075439453, "test_mcc": 0.7992748319316393, "test_macro_f1": 0.8964678935899786, "test_runtime": 2.7977, "test_samples_per_second": 732.024, "test_steps_per_second": 22.876}, {"test_loss": 0.3302435278892517, "test_mcc": 0.7689499020254252, "test_macro_f1": 0.8826054931228486, "test_runtime": 2.7263, "test_samples_per_second": 751.192, "test_steps_per_second": 23.475}, {"test_loss": 0.31995561718940735, "test_mcc": 0.7907267794910602, "test_macro_f1": 0.8916732784050452, "test_runtime": 2.764, "test_samples_per_second": 740.959, "test_steps_per_second": 23.155}, {"test_loss": 0.3203262686729431, "test_mcc": 0.7817427971455725, "test_macro_f1": 0.8879525426725327, "test_runtime": 2.8043, "test_samples_per_second": 730.309, "test_steps_per_second": 22.822}, {"test_loss": 0.3478674292564392, "test_mcc": 0.7702310982618706, "test_macro_f1": 0.8774925806289775, "test_runtime": 2.7667, "test_samples_per_second": 740.23, "test_steps_per_second": 23.132}, {"test_loss": 0.2927153706550598, "test_mcc": 0.7871745989776666, "test_macro_f1": 0.8886907220320762, "test_runtime": 2.799, "test_samples_per_second": 731.697, "test_steps_per_second": 22.866}]}, "total": {"test_mcc": 78.85501300113823, "test_mcc_se": 0.8301755383557837, "test_macro_f1": 89.07381857323398, "test_macro_f1_se": 0.4986923379561413}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6074061393737793, "test_mcc": 0.35611459268326706, "test_macro_f1": 0.6607915699680109, "test_runtime": 4.193, "test_samples_per_second": 488.439, "test_steps_per_second": 15.264}, {"test_loss": 0.6045507192611694, "test_mcc": 0.3948940208897633, "test_macro_f1": 0.6868033193337924, "test_runtime": 4.4864, "test_samples_per_second": 456.494, "test_steps_per_second": 14.265}, {"test_loss": 0.6913429498672485, "test_mcc": 0.040632426405793114, "test_macro_f1": 0.4636591763184459, "test_runtime": 4.3531, "test_samples_per_second": 470.466, "test_steps_per_second": 14.702}, {"test_loss": 0.6238039135932922, "test_mcc": 0.36273564018656546, "test_macro_f1": 0.6669292676747911, "test_runtime": 4.5537, "test_samples_per_second": 449.749, "test_steps_per_second": 14.055}, {"test_loss": 0.643959105014801, "test_mcc": 0.30766930745564947, "test_macro_f1": 0.6363433022509775, "test_runtime": 4.3502, "test_samples_per_second": 470.782, "test_steps_per_second": 14.712}, {"test_loss": 0.5690291523933411, "test_mcc": 0.4280461351078341, "test_macro_f1": 0.7097212813084066, "test_runtime": 4.251, "test_samples_per_second": 481.77, "test_steps_per_second": 15.055}, {"test_loss": 0.6311786770820618, "test_mcc": 0.2847760284781498, "test_macro_f1": 0.6249785715398881, "test_runtime": 4.1914, "test_samples_per_second": 488.621, "test_steps_per_second": 15.269}, {"test_loss": 0.5945572853088379, "test_mcc": 0.45892800886359814, "test_macro_f1": 0.7236007480671718, "test_runtime": 4.2654, "test_samples_per_second": 480.145, "test_steps_per_second": 15.005}, {"test_loss": 0.6192147135734558, "test_mcc": 0.3589305938581061, "test_macro_f1": 0.6652174454856064, "test_runtime": 4.2528, "test_samples_per_second": 481.566, "test_steps_per_second": 15.049}, {"test_loss": 0.6257343292236328, "test_mcc": 0.322401018877095, "test_macro_f1": 0.6305312382503684, "test_runtime": 4.3524, "test_samples_per_second": 470.547, "test_steps_per_second": 14.705}]}, "total": {"test_mcc": 33.15127772805822, "test_mcc_se": 7.137486602062718, "test_macro_f1": 64.68575920197459, "test_macro_f1_se": 4.468942310519629}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.597326397895813, "test_mcc": 0.38920878741011544, "test_macro_f1": 0.6713260573341293, "test_runtime": 3.8253, "test_samples_per_second": 535.378, "test_steps_per_second": 16.731}, {"test_loss": 0.595130205154419, "test_mcc": 0.3545652957051935, "test_macro_f1": 0.6697262435364224, "test_runtime": 3.847, "test_samples_per_second": 532.368, "test_steps_per_second": 16.637}, {"test_loss": 0.5911221504211426, "test_mcc": 0.4113909281861549, "test_macro_f1": 0.6886306455382805, "test_runtime": 3.8489, "test_samples_per_second": 532.094, "test_steps_per_second": 16.628}, {"test_loss": 0.6064886450767517, "test_mcc": 0.3472194957800798, "test_macro_f1": 0.6605883356486558, "test_runtime": 3.9197, "test_samples_per_second": 522.489, "test_steps_per_second": 16.328}, {"test_loss": 0.6127200126647949, "test_mcc": 0.4263197839905232, "test_macro_f1": 0.7049984618447006, "test_runtime": 3.8701, "test_samples_per_second": 529.185, "test_steps_per_second": 16.537}, {"test_loss": 0.5986846685409546, "test_mcc": 0.3568910139731004, "test_macro_f1": 0.6569555704830106, "test_runtime": 3.6983, "test_samples_per_second": 553.775, "test_steps_per_second": 17.305}, {"test_loss": 0.6068108081817627, "test_mcc": 0.3219689965408393, "test_macro_f1": 0.644651604819239, "test_runtime": 3.7335, "test_samples_per_second": 548.548, "test_steps_per_second": 17.142}, {"test_loss": 0.53499436378479, "test_mcc": 0.48420056969914493, "test_macro_f1": 0.7360732562438952, "test_runtime": 3.8338, "test_samples_per_second": 534.194, "test_steps_per_second": 16.694}, {"test_loss": 0.6151467561721802, "test_mcc": 0.39579201790416896, "test_macro_f1": 0.6675503463559156, "test_runtime": 3.7184, "test_samples_per_second": 550.772, "test_steps_per_second": 17.212}, {"test_loss": 0.5747926831245422, "test_mcc": 0.42536607127215315, "test_macro_f1": 0.6961223951463993, "test_runtime": 3.8609, "test_samples_per_second": 530.449, "test_steps_per_second": 16.577}]}, "total": {"test_mcc": 39.12922960461474, "test_mcc_se": 2.9745607472769926, "test_macro_f1": 67.96622916950648, "test_macro_f1_se": 1.6778791978921945}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6982431411743164, "test_mcc": -0.05575649422688902, "test_macro_f1": 0.4624397498680373, "test_runtime": 3.8659, "test_samples_per_second": 529.757, "test_steps_per_second": 16.555}, {"test_loss": 0.6380012631416321, "test_mcc": 0.27703748825357605, "test_macro_f1": 0.6159004827348371, "test_runtime": 3.9985, "test_samples_per_second": 512.188, "test_steps_per_second": 16.006}, {"test_loss": 0.6408523321151733, "test_mcc": 0.3087838858441002, "test_macro_f1": 0.6368509242227136, "test_runtime": 4.024, "test_samples_per_second": 508.947, "test_steps_per_second": 15.905}, {"test_loss": 0.6134862899780273, "test_mcc": 0.3133703176405389, "test_macro_f1": 0.6411836645480458, "test_runtime": 3.7706, "test_samples_per_second": 543.152, "test_steps_per_second": 16.973}, {"test_loss": 0.6197689771652222, "test_mcc": 0.3396204518439436, "test_macro_f1": 0.6428613546006667, "test_runtime": 3.8686, "test_samples_per_second": 529.388, "test_steps_per_second": 16.543}, {"test_loss": 0.6410730481147766, "test_mcc": 0.2699476102432432, "test_macro_f1": 0.6349731977403721, "test_runtime": 3.9693, "test_samples_per_second": 515.955, "test_steps_per_second": 16.124}, {"test_loss": 0.6489200592041016, "test_mcc": 0.24673345605220515, "test_macro_f1": 0.6229951012559709, "test_runtime": 3.8895, "test_samples_per_second": 526.546, "test_steps_per_second": 16.455}, {"test_loss": 0.6430045366287231, "test_mcc": 0.25268762742159895, "test_macro_f1": 0.6099837119806186, "test_runtime": 3.8902, "test_samples_per_second": 526.45, "test_steps_per_second": 16.452}, {"test_loss": 0.6616464853286743, "test_mcc": 0.21164906870650196, "test_macro_f1": 0.6049594340585759, "test_runtime": 3.8826, "test_samples_per_second": 527.478, "test_steps_per_second": 16.484}, {"test_loss": 0.644878625869751, "test_mcc": 0.24867886297623215, "test_macro_f1": 0.6041923734483015, "test_runtime": 4.0195, "test_samples_per_second": 509.515, "test_steps_per_second": 15.922}]}, "total": {"test_mcc": 24.127522747550515, "test_mcc_se": 6.878590172151898, "test_macro_f1": 60.763399944581394, "test_macro_f1_se": 3.2912566944602095}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_em": 38.342370255615805, "test_f1": 42.28986766808616}, {"test_em": 31.31782945736434, "test_f1": 35.005221370150466}, {"test_em": 36.78516228748068, "test_f1": 40.627201704458734}, {"test_em": 33.87850467289719, "test_f1": 38.17814077251}, {"test_em": 43.86100386100386, "test_f1": 47.44260555538748}, {"test_em": 39.244410177332306, "test_f1": 42.67624467481364}, {"test_em": 41.381928625664386, "test_f1": 45.04613762168578}, {"test_em": 39.64313421256788, "test_f1": 44.02250971047555}, {"test_em": 37.88235294117647, "test_f1": 41.43118204296496}, {"test_em": 36.10248447204969, "test_f1": 39.242411455903905}]}, "total": {"test_em": 37.84391809631526, "test_em_se": 2.2312956522787597, "test_f1": 41.596152257643666, "test_f1_se": 2.217947013457062}}, "num_model_parameters": 124101890, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_em": 38.729666924864446, "test_f1": 43.59044556962616}, {"test_em": 37.44186046511628, "test_f1": 41.65010587541007}, {"test_em": 35.85780525502319, "test_f1": 39.5484787747661}, {"test_em": 35.202492211838006, "test_f1": 38.89758127401354}, {"test_em": 42.00772200772201, "test_f1": 46.362528037873695}, {"test_em": 40.169622205088665, "test_f1": 44.72641796102581}, {"test_em": 41.913439635535305, "test_f1": 46.25899149700781}, {"test_em": 41.272304111714504, "test_f1": 45.47324721645661}, {"test_em": 40.549019607843135, "test_f1": 45.36858249344372}, {"test_em": 40.993788819875775, "test_f1": 44.91693761217875}]}, "total": {"test_em": 39.41377212446213, "test_em_se": 1.5394815138367213, "test_f1": 43.67933163118023, "test_f1_se": 1.6861657174217686}}, "num_model_parameters": 124101890, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_em": 49.57397366382649, "test_f1": 54.76333299678864}, {"test_em": 49.689922480620154, "test_f1": 54.81979299274264}, {"test_em": 43.97217928902627, "test_f1": 49.13354894173125}, {"test_em": 46.728971962616825, "test_f1": 51.688000955008235}, {"test_em": 48.41698841698842, "test_f1": 53.990996453825495}, {"test_em": 42.48265227447957, "test_f1": 47.08146285766465}, {"test_em": 49.35459377372817, "test_f1": 54.43966040550108}, {"test_em": 45.15128006206361, "test_f1": 50.15394924272613}, {"test_em": 44.627450980392155, "test_f1": 50.21391198713456}, {"test_em": 40.52795031055901, "test_f1": 45.92243718896509}]}, "total": {"test_em": 46.05259632143007, "test_em_se": 1.992602622427245, "test_f1": 51.220709402208776, "test_f1_se": 2.018694167719301}}, "num_model_parameters": 124101890, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.47231265902519226, "test_mcc": 0.702359271824429, "test_macro_f1": 0.6800506481843188, "test_runtime": 20.2641, "test_samples_per_second": 101.065, "test_steps_per_second": 50.533}, {"test_loss": 0.587748110294342, "test_mcc": 0.6550516527890282, "test_macro_f1": 0.5661908988941874, "test_runtime": 19.8237, "test_samples_per_second": 103.311, "test_steps_per_second": 51.655}, {"test_loss": 0.5249948501586914, "test_mcc": 0.6628432059972622, "test_macro_f1": 0.6397224356912738, "test_runtime": 20.9603, "test_samples_per_second": 97.709, "test_steps_per_second": 48.854}, {"test_loss": 0.5511886477470398, "test_mcc": 0.6244919869852754, "test_macro_f1": 0.63727278204006, "test_runtime": 19.9516, "test_samples_per_second": 102.649, "test_steps_per_second": 51.324}, {"test_loss": 0.5127785205841064, "test_mcc": 0.7016830960152951, "test_macro_f1": 0.6239855989580373, "test_runtime": 20.0666, "test_samples_per_second": 102.06, "test_steps_per_second": 51.03}, {"test_loss": 0.5328298807144165, "test_mcc": 0.6778487138982109, "test_macro_f1": 0.6086408366625288, "test_runtime": 20.2336, "test_samples_per_second": 101.218, "test_steps_per_second": 50.609}, {"test_loss": 0.5579805374145508, "test_mcc": 0.6487607490438232, "test_macro_f1": 0.6253083130924457, "test_runtime": 20.2205, "test_samples_per_second": 101.283, "test_steps_per_second": 50.642}, {"test_loss": 0.5144312381744385, "test_mcc": 0.6905876901960893, "test_macro_f1": 0.5789627629896433, "test_runtime": 20.4428, "test_samples_per_second": 100.182, "test_steps_per_second": 50.091}, {"test_loss": 0.6106745004653931, "test_mcc": 0.628853234470883, "test_macro_f1": 0.5563705915020156, "test_runtime": 20.2883, "test_samples_per_second": 100.945, "test_steps_per_second": 50.472}, {"test_loss": 0.5056608319282532, "test_mcc": 0.6694361008430734, "test_macro_f1": 0.6730680859377457, "test_runtime": 20.1935, "test_samples_per_second": 101.419, "test_steps_per_second": 50.709}]}, "total": {"test_mcc": 66.61915702063371, "test_mcc_se": 1.7138624592246163, "test_macro_f1": 61.89572953952256, "test_macro_f1_se": 2.605155735722233}}, "num_model_parameters": 278830851, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.8865978717803955, "test_mcc": 0.4282030447943043, "test_macro_f1": 0.6047051314588646, "test_runtime": 4.492, "test_samples_per_second": 455.923, "test_steps_per_second": 14.248}, {"test_loss": 0.8963916301727295, "test_mcc": 0.4377960458243339, "test_macro_f1": 0.6283073896703129, "test_runtime": 4.4216, "test_samples_per_second": 463.182, "test_steps_per_second": 14.474}, {"test_loss": 0.9273947477340698, "test_mcc": 0.4094989990590186, "test_macro_f1": 0.6075061844118105, "test_runtime": 4.4336, "test_samples_per_second": 461.93, "test_steps_per_second": 14.435}, {"test_loss": 0.9318925738334656, "test_mcc": 0.4348994506930951, "test_macro_f1": 0.6197986711516076, "test_runtime": 4.3555, "test_samples_per_second": 470.207, "test_steps_per_second": 14.694}, {"test_loss": 0.8745513558387756, "test_mcc": 0.4505627694928613, "test_macro_f1": 0.6338295346909952, "test_runtime": 4.3742, "test_samples_per_second": 468.197, "test_steps_per_second": 14.631}, {"test_loss": 0.9592210054397583, "test_mcc": 0.41526847991992705, "test_macro_f1": 0.6125889357615938, "test_runtime": 4.3979, "test_samples_per_second": 465.68, "test_steps_per_second": 14.552}, {"test_loss": 0.9616742134094238, "test_mcc": 0.4341988123378546, "test_macro_f1": 0.6265855777507721, "test_runtime": 4.4018, "test_samples_per_second": 465.269, "test_steps_per_second": 14.54}, {"test_loss": 0.9645081162452698, "test_mcc": 0.35473223763842715, "test_macro_f1": 0.5516190682440126, "test_runtime": 4.4454, "test_samples_per_second": 460.705, "test_steps_per_second": 14.397}, {"test_loss": 0.9985477924346924, "test_mcc": 0.4189235258889864, "test_macro_f1": 0.6129614085899489, "test_runtime": 4.4404, "test_samples_per_second": 461.22, "test_steps_per_second": 14.413}, {"test_loss": 0.9781078100204468, "test_mcc": 0.4332779952682769, "test_macro_f1": 0.626732709617964, "test_runtime": 4.3428, "test_samples_per_second": 471.588, "test_steps_per_second": 14.737}]}, "total": {"test_mcc": 42.17361360917086, "test_mcc_se": 1.6374485068583275, "test_macro_f1": 61.246346113478836, "test_macro_f1_se": 1.4537892855983}}, "num_model_parameters": 278830851, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.898627519607544, "test_mcc": 0.345758787598071, "test_macro_f1": 0.4372494624220147, "test_runtime": 3.8084, "test_samples_per_second": 537.766, "test_steps_per_second": 16.805}, {"test_loss": 0.8929541707038879, "test_mcc": 0.362594344772967, "test_macro_f1": 0.4766561953741757, "test_runtime": 3.5396, "test_samples_per_second": 578.591, "test_steps_per_second": 18.081}, {"test_loss": 0.854568362236023, "test_mcc": 0.3920494643843034, "test_macro_f1": 0.5136679238150009, "test_runtime": 3.6095, "test_samples_per_second": 567.387, "test_steps_per_second": 17.731}, {"test_loss": 0.9258437752723694, "test_mcc": 0.36140882188622814, "test_macro_f1": 0.48214726089668997, "test_runtime": 3.6534, "test_samples_per_second": 560.573, "test_steps_per_second": 17.518}, {"test_loss": 0.8851175904273987, "test_mcc": 0.36136675164336585, "test_macro_f1": 0.4471774694187575, "test_runtime": 3.7348, "test_samples_per_second": 548.359, "test_steps_per_second": 17.136}, {"test_loss": 0.8833885192871094, "test_mcc": 0.37460839479187313, "test_macro_f1": 0.4565478106743688, "test_runtime": 3.7648, "test_samples_per_second": 543.98, "test_steps_per_second": 16.999}, {"test_loss": 0.8512037396430969, "test_mcc": 0.398482078321994, "test_macro_f1": 0.5569402251117007, "test_runtime": 3.6568, "test_samples_per_second": 560.052, "test_steps_per_second": 17.502}, {"test_loss": 0.8692595362663269, "test_mcc": 0.34887608335187936, "test_macro_f1": 0.4425802669241645, "test_runtime": 3.6972, "test_samples_per_second": 553.932, "test_steps_per_second": 17.31}, {"test_loss": 0.8594843149185181, "test_mcc": 0.37213624828903125, "test_macro_f1": 0.45155427680872745, "test_runtime": 3.8035, "test_samples_per_second": 538.449, "test_steps_per_second": 16.827}, {"test_loss": 0.9445512294769287, "test_mcc": 0.38519505087997985, "test_macro_f1": 0.5233283187211212, "test_runtime": 3.8419, "test_samples_per_second": 533.07, "test_steps_per_second": 16.658}]}, "total": {"test_mcc": 37.02476025919693, "test_mcc_se": 1.0913847401335592, "test_macro_f1": 47.878492101667206, "test_macro_f1_se": 2.496043380541604}}, "num_model_parameters": 278830851, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.06885723024606705, "test_micro_f1": 0.644559585492228, "test_micro_f1_no_misc": 0.7235079171741778, "test_runtime": 7.5193, "test_samples_per_second": 272.367, "test_steps_per_second": 8.511}, {"test_loss": 0.06722618639469147, "test_micro_f1": 0.6449948400412796, "test_micro_f1_no_misc": 0.707117852975496, "test_runtime": 7.2487, "test_samples_per_second": 282.534, "test_steps_per_second": 8.829}, {"test_loss": 0.06533512473106384, "test_micro_f1": 0.6047619047619048, "test_micro_f1_no_misc": 0.6677542142468732, "test_runtime": 6.7854, "test_samples_per_second": 301.826, "test_steps_per_second": 9.432}, {"test_loss": 0.06047980859875679, "test_micro_f1": 0.649546827794562, "test_micro_f1_no_misc": 0.6928104575163399, "test_runtime": 7.578, "test_samples_per_second": 270.254, "test_steps_per_second": 8.445}, {"test_loss": 0.06841880083084106, "test_micro_f1": 0.6537530266343826, "test_micro_f1_no_misc": 0.7138157894736842, "test_runtime": 7.5229, "test_samples_per_second": 272.237, "test_steps_per_second": 8.507}, {"test_loss": 0.06641243398189545, "test_micro_f1": 0.5977653631284916, "test_micro_f1_no_misc": 0.6910523353967362, "test_runtime": 6.1879, "test_samples_per_second": 330.967, "test_steps_per_second": 10.343}, {"test_loss": 0.06834731996059418, "test_micro_f1": 0.6402378592666006, "test_micro_f1_no_misc": 0.6947023484434736, "test_runtime": 6.1431, "test_samples_per_second": 333.381, "test_steps_per_second": 10.418}, {"test_loss": 0.05261404067277908, "test_micro_f1": 0.6634666666666668, "test_micro_f1_no_misc": 0.7048158640226628, "test_runtime": 7.3642, "test_samples_per_second": 278.102, "test_steps_per_second": 8.691}, {"test_loss": 0.061489444226026535, "test_micro_f1": 0.6549019607843138, "test_micro_f1_no_misc": 0.7045454545454545, "test_runtime": 6.9131, "test_samples_per_second": 296.247, "test_steps_per_second": 9.258}, {"test_loss": 0.06044921651482582, "test_micro_f1": 0.6649823143001515, "test_micro_f1_no_misc": 0.716794731064764, "test_runtime": 7.5082, "test_samples_per_second": 272.769, "test_steps_per_second": 8.524}]}, "total": {"test_micro_f1": 64.18970348870582, "test_micro_f1_se": 1.4182679253565378, "test_micro_f1_no_misc": 70.16916964859661, "test_micro_f1_no_misc_se": 0.9889029092722699}}, "num_model_parameters": 278244873, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.07001656293869019, "test_micro_f1": 0.7582529202640935, "test_micro_f1_no_misc": 0.7734322319622388, "test_runtime": 8.4611, "test_samples_per_second": 242.05, "test_steps_per_second": 7.564}, {"test_loss": 0.06992445886135101, "test_micro_f1": 0.7456017872102765, "test_micro_f1_no_misc": 0.7662807525325614, "test_runtime": 6.9035, "test_samples_per_second": 296.662, "test_steps_per_second": 9.271}, {"test_loss": 0.06766493618488312, "test_micro_f1": 0.7794000530926466, "test_micro_f1_no_misc": 0.8096437567470313, "test_runtime": 8.3877, "test_samples_per_second": 244.166, "test_steps_per_second": 7.63}, {"test_loss": 0.07147921621799469, "test_micro_f1": 0.7640391550747038, "test_micro_f1_no_misc": 0.7833972793861179, "test_runtime": 8.1198, "test_samples_per_second": 252.223, "test_steps_per_second": 7.882}, {"test_loss": 0.0813702866435051, "test_micro_f1": 0.6934225195094761, "test_micro_f1_no_misc": 0.7137628111273792, "test_runtime": 8.4259, "test_samples_per_second": 243.061, "test_steps_per_second": 7.596}, {"test_loss": 0.08135206997394562, "test_micro_f1": 0.7608213096559379, "test_micro_f1_no_misc": 0.765659543109801, "test_runtime": 8.3814, "test_samples_per_second": 244.351, "test_steps_per_second": 7.636}, {"test_loss": 0.08169638365507126, "test_micro_f1": 0.7480463486930746, "test_micro_f1_no_misc": 0.7523775977456851, "test_runtime": 8.522, "test_samples_per_second": 240.319, "test_steps_per_second": 7.51}, {"test_loss": 0.07169093191623688, "test_micro_f1": 0.7570093457943926, "test_micro_f1_no_misc": 0.777445855115758, "test_runtime": 8.4411, "test_samples_per_second": 242.623, "test_steps_per_second": 7.582}, {"test_loss": 0.07850783318281174, "test_micro_f1": 0.7367292225201073, "test_micro_f1_no_misc": 0.740311481347338, "test_runtime": 8.169, "test_samples_per_second": 250.703, "test_steps_per_second": 7.834}, {"test_loss": 0.07340756058692932, "test_micro_f1": 0.7180170575692963, "test_micro_f1_no_misc": 0.7334035827186512, "test_runtime": 7.2182, "test_samples_per_second": 283.727, "test_steps_per_second": 8.866}]}, "total": {"test_micro_f1": 74.61339719384006, "test_micro_f1_se": 1.5418578218127907, "test_micro_f1_no_misc": 76.15714891792562, "test_micro_f1_no_misc_se": 1.707999564534908}}, "num_model_parameters": 278244873, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.050872161984443665, "test_micro_f1": 0.8063469166967184, "test_micro_f1_no_misc": 0.8415478615071283, "test_runtime": 6.5875, "test_samples_per_second": 310.891, "test_steps_per_second": 9.715}, {"test_loss": 0.04713808745145798, "test_micro_f1": 0.7645739910313902, "test_micro_f1_no_misc": 0.8028404344193817, "test_runtime": 6.4957, "test_samples_per_second": 315.285, "test_steps_per_second": 9.853}, {"test_loss": 0.04998321086168289, "test_micro_f1": 0.8310502283105023, "test_micro_f1_no_misc": 0.8586057502953919, "test_runtime": 6.1845, "test_samples_per_second": 331.15, "test_steps_per_second": 10.348}, {"test_loss": 0.03983089327812195, "test_micro_f1": 0.8340965128566398, "test_micro_f1_no_misc": 0.8563425370148059, "test_runtime": 6.0597, "test_samples_per_second": 337.97, "test_steps_per_second": 10.562}, {"test_loss": 0.04815328121185303, "test_micro_f1": 0.8234106962663976, "test_micro_f1_no_misc": 0.8489425981873111, "test_runtime": 6.6211, "test_samples_per_second": 309.316, "test_steps_per_second": 9.666}, {"test_loss": 0.041551463305950165, "test_micro_f1": 0.8259829059829059, "test_micro_f1_no_misc": 0.8488372093023255, "test_runtime": 6.5861, "test_samples_per_second": 310.958, "test_steps_per_second": 9.717}, {"test_loss": 0.0454898476600647, "test_micro_f1": 0.8099344601586754, "test_micro_f1_no_misc": 0.8336534767575874, "test_runtime": 6.0255, "test_samples_per_second": 339.887, "test_steps_per_second": 10.621}, {"test_loss": 0.046912193298339844, "test_micro_f1": 0.8149417409184373, "test_micro_f1_no_misc": 0.8335187245087133, "test_runtime": 5.9802, "test_samples_per_second": 342.462, "test_steps_per_second": 10.702}, {"test_loss": 0.04524019733071327, "test_micro_f1": 0.8148148148148149, "test_micro_f1_no_misc": 0.8355048859934855, "test_runtime": 6.0443, "test_samples_per_second": 338.834, "test_steps_per_second": 10.589}, {"test_loss": 0.05270880460739136, "test_micro_f1": 0.8101604278074865, "test_micro_f1_no_misc": 0.8509505703422054, "test_runtime": 6.4458, "test_samples_per_second": 317.728, "test_steps_per_second": 9.929}]}, "total": {"test_micro_f1": 81.35312694843968, "test_micro_f1_se": 1.215069334398311, "test_micro_f1_no_misc": 84.10744048328334, "test_micro_f1_no_misc_se": 1.0048196262482012}}, "num_model_parameters": 278244873, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.05915149301290512, "test_micro_f1": 0.7640866873065015, "test_micro_f1_no_misc": 0.7945392491467576, "test_runtime": 6.0742, "test_samples_per_second": 337.166, "test_steps_per_second": 10.536}, {"test_loss": 0.06710106134414673, "test_micro_f1": 0.7408737283064033, "test_micro_f1_no_misc": 0.7814826804791194, "test_runtime": 6.2136, "test_samples_per_second": 329.597, "test_steps_per_second": 10.3}, {"test_loss": 0.07068480551242828, "test_micro_f1": 0.6989886972040453, "test_micro_f1_no_misc": 0.7435567010309279, "test_runtime": 5.8876, "test_samples_per_second": 347.848, "test_steps_per_second": 10.87}, {"test_loss": 0.07041904330253601, "test_micro_f1": 0.777344920587354, "test_micro_f1_no_misc": 0.8057892965331538, "test_runtime": 6.3855, "test_samples_per_second": 320.728, "test_steps_per_second": 10.023}, {"test_loss": 0.07195042073726654, "test_micro_f1": 0.7627793082338535, "test_micro_f1_no_misc": 0.796793307772743, "test_runtime": 5.9616, "test_samples_per_second": 343.534, "test_steps_per_second": 10.735}, {"test_loss": 0.06385306268930435, "test_micro_f1": 0.7560543414057884, "test_micro_f1_no_misc": 0.7931488801054019, "test_runtime": 6.2711, "test_samples_per_second": 326.577, "test_steps_per_second": 10.206}, {"test_loss": 0.06348669528961182, "test_micro_f1": 0.7121351766513057, "test_micro_f1_no_misc": 0.7558330594807756, "test_runtime": 6.3198, "test_samples_per_second": 324.06, "test_steps_per_second": 10.127}, {"test_loss": 0.07390260696411133, "test_micro_f1": 0.6708898944193064, "test_micro_f1_no_misc": 0.7104420243433696, "test_runtime": 6.3073, "test_samples_per_second": 324.701, "test_steps_per_second": 10.147}, {"test_loss": 0.0701461061835289, "test_micro_f1": 0.709776279497395, "test_micro_f1_no_misc": 0.742087542087542, "test_runtime": 5.5189, "test_samples_per_second": 371.088, "test_steps_per_second": 11.596}, {"test_loss": 0.0600721575319767, "test_micro_f1": 0.7738785474519377, "test_micro_f1_no_misc": 0.7981283422459894, "test_runtime": 5.889, "test_samples_per_second": 347.768, "test_steps_per_second": 10.868}]}, "total": {"test_micro_f1": 73.66807581063891, "test_micro_f1_se": 2.257344799013194, "test_micro_f1_no_misc": 77.21801083225779, "test_micro_f1_no_misc_se": 1.9858039945593358}}, "num_model_parameters": 278244873, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.48916882276535034, "test_mcc": 0.5369110199445252, "test_macro_f1": 0.7648042498582386, "test_runtime": 3.3209, "test_samples_per_second": 616.693, "test_steps_per_second": 19.272}, {"test_loss": 0.5818790197372437, "test_mcc": 0.4527728815589294, "test_macro_f1": 0.7233082965664854, "test_runtime": 3.4637, "test_samples_per_second": 591.275, "test_steps_per_second": 18.477}, {"test_loss": 0.6066032648086548, "test_mcc": 0.36967133670010227, "test_macro_f1": 0.632751062110668, "test_runtime": 3.4566, "test_samples_per_second": 592.495, "test_steps_per_second": 18.515}, {"test_loss": 0.5771731734275818, "test_mcc": 0.44413156667610165, "test_macro_f1": 0.715229169664265, "test_runtime": 3.35, "test_samples_per_second": 611.339, "test_steps_per_second": 19.104}, {"test_loss": 0.6057440042495728, "test_mcc": 0.4256933469483284, "test_macro_f1": 0.7097198689100178, "test_runtime": 3.4052, "test_samples_per_second": 601.437, "test_steps_per_second": 18.795}, {"test_loss": 0.6143077611923218, "test_mcc": 0.4759744599649409, "test_macro_f1": 0.731132783195799, "test_runtime": 3.3781, "test_samples_per_second": 606.262, "test_steps_per_second": 18.946}, {"test_loss": 0.5319277048110962, "test_mcc": 0.5055589859575959, "test_macro_f1": 0.7465555444218647, "test_runtime": 3.4446, "test_samples_per_second": 594.555, "test_steps_per_second": 18.58}, {"test_loss": 0.6184996962547302, "test_mcc": 0.40110252251187517, "test_macro_f1": 0.6718680374052346, "test_runtime": 3.437, "test_samples_per_second": 595.877, "test_steps_per_second": 18.621}, {"test_loss": 0.5461954474449158, "test_mcc": 0.5459646285840158, "test_macro_f1": 0.7655983333188454, "test_runtime": 3.3905, "test_samples_per_second": 604.034, "test_steps_per_second": 18.876}, {"test_loss": 0.5345089435577393, "test_mcc": 0.5140242168713112, "test_macro_f1": 0.7542244113650556, "test_runtime": 3.422, "test_samples_per_second": 598.474, "test_steps_per_second": 18.702}]}, "total": {"test_mcc": 46.71804965717726, "test_mcc_se": 3.646291481682182, "test_macro_f1": 72.15191756816475, "test_macro_f1_se": 2.6241274420862033}}, "num_model_parameters": 278830082, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.6916766166687012, "test_mcc": 0.048369223706598935, "test_macro_f1": 0.5169844069477658, "test_runtime": 3.7482, "test_samples_per_second": 546.394, "test_steps_per_second": 17.075}, {"test_loss": 0.5915874242782593, "test_mcc": 0.41404594690937374, "test_macro_f1": 0.7053690866862541, "test_runtime": 3.9348, "test_samples_per_second": 520.483, "test_steps_per_second": 16.265}, {"test_loss": 0.6920771598815918, "test_mcc": 0.04788094450515778, "test_macro_f1": 0.4267693538012204, "test_runtime": 3.8712, "test_samples_per_second": 529.029, "test_steps_per_second": 16.532}, {"test_loss": 0.643394947052002, "test_mcc": 0.45226461833013487, "test_macro_f1": 0.6951883370035721, "test_runtime": 3.9917, "test_samples_per_second": 513.065, "test_steps_per_second": 16.033}, {"test_loss": 0.5519908666610718, "test_mcc": 0.5179854525947052, "test_macro_f1": 0.7519472841838133, "test_runtime": 3.7997, "test_samples_per_second": 538.987, "test_steps_per_second": 16.843}, {"test_loss": 0.5792202949523926, "test_mcc": 0.4547603552194906, "test_macro_f1": 0.6953010872832098, "test_runtime": 3.876, "test_samples_per_second": 528.382, "test_steps_per_second": 16.512}, {"test_loss": 0.5932892560958862, "test_mcc": 0.37520538261286396, "test_macro_f1": 0.6826619822370068, "test_runtime": 3.7246, "test_samples_per_second": 549.853, "test_steps_per_second": 17.183}, {"test_loss": 0.6908079981803894, "test_mcc": 0.054725589277270066, "test_macro_f1": 0.5183954304276575, "test_runtime": 3.7915, "test_samples_per_second": 540.154, "test_steps_per_second": 16.88}, {"test_loss": 0.5678553581237793, "test_mcc": 0.5088109046143046, "test_macro_f1": 0.7541313876627012, "test_runtime": 3.7611, "test_samples_per_second": 544.519, "test_steps_per_second": 17.016}, {"test_loss": 0.6919853091239929, "test_mcc": 0.06925438404448539, "test_macro_f1": 0.4612514102230322, "test_runtime": 3.8631, "test_samples_per_second": 530.138, "test_steps_per_second": 16.567}]}, "total": {"test_mcc": 29.433028018143855, "test_mcc_se": 13.015622398848329, "test_macro_f1": 62.079997664562335, "test_macro_f1_se": 7.769112953877534}}, "num_model_parameters": 278830082, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.5291556715965271, "test_mcc": 0.5081015687929519, "test_macro_f1": 0.7537472399043909, "test_runtime": 3.4177, "test_samples_per_second": 599.227, "test_steps_per_second": 18.726}, {"test_loss": 0.6913884878158569, "test_mcc": 0.03477152032195475, "test_macro_f1": 0.4668103061316097, "test_runtime": 3.4266, "test_samples_per_second": 597.68, "test_steps_per_second": 18.677}, {"test_loss": 0.6930227875709534, "test_mcc": 0.051102721665839616, "test_macro_f1": 0.5000589957422071, "test_runtime": 3.4128, "test_samples_per_second": 600.088, "test_steps_per_second": 18.753}, {"test_loss": 0.589842677116394, "test_mcc": 0.39558608816402024, "test_macro_f1": 0.692319248826291, "test_runtime": 3.497, "test_samples_per_second": 585.646, "test_steps_per_second": 18.301}, {"test_loss": 0.5789533257484436, "test_mcc": 0.4876541874299724, "test_macro_f1": 0.7219046861352834, "test_runtime": 3.4505, "test_samples_per_second": 593.531, "test_steps_per_second": 18.548}, {"test_loss": 0.5204727053642273, "test_mcc": 0.5198408047531532, "test_macro_f1": 0.7586669200312164, "test_runtime": 3.3163, "test_samples_per_second": 617.56, "test_steps_per_second": 19.299}, {"test_loss": 0.5461782217025757, "test_mcc": 0.48185838460048663, "test_macro_f1": 0.7354032644255186, "test_runtime": 3.3196, "test_samples_per_second": 616.941, "test_steps_per_second": 19.279}, {"test_loss": 0.6091969013214111, "test_mcc": 0.45601792447550843, "test_macro_f1": 0.7156063994202242, "test_runtime": 3.4249, "test_samples_per_second": 597.975, "test_steps_per_second": 18.687}, {"test_loss": 0.68868088722229, "test_mcc": 0.13191978213166114, "test_macro_f1": 0.564862110053548, "test_runtime": 3.3389, "test_samples_per_second": 613.373, "test_steps_per_second": 19.168}, {"test_loss": 0.5784839391708374, "test_mcc": 0.4753750739500178, "test_macro_f1": 0.7204166069563652, "test_runtime": 3.4308, "test_samples_per_second": 596.94, "test_steps_per_second": 18.654}]}, "total": {"test_mcc": 35.42228056285566, "test_mcc_se": 12.31500151143508, "test_macro_f1": 66.29795777626654, "test_macro_f1_se": 6.780018168967413}}, "num_model_parameters": 278830082, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_loss": 0.692900538444519, "test_mcc": 0.01579217077388553, "test_macro_f1": 0.482846109164257, "test_runtime": 3.6141, "test_samples_per_second": 566.663, "test_steps_per_second": 17.708}, {"test_loss": 0.6929259300231934, "test_mcc": 0.05296059315405429, "test_macro_f1": 0.44188314044810717, "test_runtime": 3.695, "test_samples_per_second": 554.269, "test_steps_per_second": 17.321}, {"test_loss": 0.6919867396354675, "test_mcc": 0.0654869767641402, "test_macro_f1": 0.531908521429856, "test_runtime": 3.7584, "test_samples_per_second": 544.915, "test_steps_per_second": 17.029}, {"test_loss": 0.6933304071426392, "test_mcc": 0.012974702338190819, "test_macro_f1": 0.45149235138771243, "test_runtime": 3.5619, "test_samples_per_second": 574.97, "test_steps_per_second": 17.968}, {"test_loss": 0.6920708417892456, "test_mcc": 0.05022362001633367, "test_macro_f1": 0.4831087347642095, "test_runtime": 3.5959, "test_samples_per_second": 569.53, "test_steps_per_second": 17.798}, {"test_loss": 0.6918197870254517, "test_mcc": 0.02341703325529812, "test_macro_f1": 0.5116437646837096, "test_runtime": 3.776, "test_samples_per_second": 542.377, "test_steps_per_second": 16.949}, {"test_loss": 0.6905241012573242, "test_mcc": 0.03391853225404753, "test_macro_f1": 0.5069880769892112, "test_runtime": 3.6824, "test_samples_per_second": 556.153, "test_steps_per_second": 17.38}, {"test_loss": 0.6924759745597839, "test_mcc": 0.04872763055360908, "test_macro_f1": 0.5058336571216542, "test_runtime": 3.6588, "test_samples_per_second": 559.752, "test_steps_per_second": 17.492}, {"test_loss": 0.6932320594787598, "test_mcc": 0.0052706043191624195, "test_macro_f1": 0.5006469804360841, "test_runtime": 3.6296, "test_samples_per_second": 564.246, "test_steps_per_second": 17.633}, {"test_loss": 0.5977345705032349, "test_mcc": 0.377944285490179, "test_macro_f1": 0.6534991495052586, "test_runtime": 3.7316, "test_samples_per_second": 548.824, "test_steps_per_second": 17.151}]}, "total": {"test_mcc": 6.867161489189007, "test_mcc_se": 6.846561698179662, "test_macro_f1": 50.698504859300606, "test_macro_f1_se": 3.6153146966998206}}, "num_model_parameters": 278830082, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_em": 38.342370255615805, "test_f1": 42.47405110639027}, {"test_em": 39.457364341085274, "test_f1": 43.176787702349834}, {"test_em": 39.18083462132921, "test_f1": 43.5388092856236}, {"test_em": 41.58878504672897, "test_f1": 45.39626825646472}, {"test_em": 41.15830115830116, "test_f1": 44.414198461301496}, {"test_em": 35.851966075558984, "test_f1": 39.87190381995487}, {"test_em": 42.065299924069855, "test_f1": 45.09837431033101}, {"test_em": 40.108611326609775, "test_f1": 43.597643185444944}, {"test_em": 39.372549019607845, "test_f1": 42.960344336050035}, {"test_em": 38.74223602484472, "test_f1": 41.59495351217464}]}, "total": {"test_em": 39.58683177937516, "test_em_se": 1.118920877395878, "test_f1": 43.21233339760854, "test_f1_se": 1.0207580507471046}}, "num_model_parameters": 278239490, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_em": 42.52517428350116, "test_f1": 46.33341582523582}, {"test_em": 33.41085271317829, "test_f1": 37.47810852678014}, {"test_em": 40.88098918083462, "test_f1": 45.241650037085975}, {"test_em": 42.36760124610592, "test_f1": 46.418608312017795}, {"test_em": 40.38610038610039, "test_f1": 43.97364151322575}, {"test_em": 35.46646106399383, "test_f1": 39.46060369421854}, {"test_em": 35.231586940015184, "test_f1": 39.348613642389246}, {"test_em": 30.411171450737005, "test_f1": 34.61389752507604}, {"test_em": 35.529411764705884, "test_f1": 39.928753834245036}, {"test_em": 43.7888198757764, "test_f1": 48.02887043969389}]}, "total": {"test_em": 37.99981689049487, "test_em_se": 2.8168781669776837, "test_f1": 42.08261633499682, "test_f1_se": 2.78534342894509}}, "num_model_parameters": 278239490, "max_sequence_length": 512, "vocabulary_size": 250002}

{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.37468457221984863, "test_mcc": 0.7882361213978111, "test_macro_f1": 0.7965411830472071, "test_runtime": 33.1259, "test_samples_per_second": 61.825, "test_steps_per_second": 7.728}, {"test_loss": 0.4203752875328064, "test_mcc": 0.719776138840522, "test_macro_f1": 0.5917704215875804, "test_runtime": 31.4392, "test_samples_per_second": 65.142, "test_steps_per_second": 8.143}, {"test_loss": 0.37206608057022095, "test_mcc": 0.7730117991348974, "test_macro_f1": 0.7731433084523894, "test_runtime": 32.4126, "test_samples_per_second": 63.185, "test_steps_per_second": 7.898}, {"test_loss": 0.36100149154663086, "test_mcc": 0.7827988231562908, "test_macro_f1": 0.7324121976519841, "test_runtime": 31.1318, "test_samples_per_second": 65.785, "test_steps_per_second": 8.223}, {"test_loss": 0.35739099979400635, "test_mcc": 0.7592835971316836, "test_macro_f1": 0.7046854048982435, "test_runtime": 30.8773, "test_samples_per_second": 66.327, "test_steps_per_second": 8.291}, {"test_loss": 0.3699440360069275, "test_mcc": 0.7643275565928012, "test_macro_f1": 0.7591411535253546, "test_runtime": 31.6251, "test_samples_per_second": 64.759, "test_steps_per_second": 8.095}, {"test_loss": 0.44972169399261475, "test_mcc": 0.7294590762219949, "test_macro_f1": 0.604990091271673, "test_runtime": 31.2095, "test_samples_per_second": 65.621, "test_steps_per_second": 8.203}, {"test_loss": 0.4305199086666107, "test_mcc": 0.7452893473780356, "test_macro_f1": 0.7537057488897078, "test_runtime": 32.5427, "test_samples_per_second": 62.933, "test_steps_per_second": 7.867}, {"test_loss": 0.3754863142967224, "test_mcc": 0.7662570982947814, "test_macro_f1": 0.7432992801478996, "test_runtime": 32.9194, "test_samples_per_second": 62.213, "test_steps_per_second": 7.777}, {"test_loss": 0.4086742699146271, "test_mcc": 0.7578461143555603, "test_macro_f1": 0.7540959941939415, "test_runtime": 31.9235, "test_samples_per_second": 64.153, "test_steps_per_second": 8.019}]}, "total": {"test_mcc": 75.86285672504378, "test_mcc_se": 1.354419303229637, "test_macro_f1": 72.13784783665982, "test_macro_f1_se": 4.288971163861347}}, "num_model_parameters": 355090435, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.7994025945663452, "test_mcc": 0.5026989198022933, "test_macro_f1": 0.6686128354514036, "test_runtime": 8.2657, "test_samples_per_second": 247.772, "test_steps_per_second": 7.743}, {"test_loss": 0.8122825622558594, "test_mcc": 0.5081795007096725, "test_macro_f1": 0.6688420526217866, "test_runtime": 8.3428, "test_samples_per_second": 245.482, "test_steps_per_second": 7.671}, {"test_loss": 0.8286997079849243, "test_mcc": 0.4592454705573411, "test_macro_f1": 0.6275618246931401, "test_runtime": 8.3089, "test_samples_per_second": 246.481, "test_steps_per_second": 7.703}, {"test_loss": 0.832514762878418, "test_mcc": 0.4582336042072738, "test_macro_f1": 0.6202829218459683, "test_runtime": 8.4317, "test_samples_per_second": 242.894, "test_steps_per_second": 7.59}, {"test_loss": 0.8743034601211548, "test_mcc": 0.4861444919819939, "test_macro_f1": 0.6479135865766736, "test_runtime": 8.3401, "test_samples_per_second": 245.56, "test_steps_per_second": 7.674}, {"test_loss": 0.8080312609672546, "test_mcc": 0.49998971243684415, "test_macro_f1": 0.6568876983203296, "test_runtime": 8.5163, "test_samples_per_second": 240.48, "test_steps_per_second": 7.515}, {"test_loss": 0.8026942610740662, "test_mcc": 0.5133163439836697, "test_macro_f1": 0.674443625208168, "test_runtime": 8.2878, "test_samples_per_second": 247.111, "test_steps_per_second": 7.722}, {"test_loss": 0.8809462785720825, "test_mcc": 0.5006084612333465, "test_macro_f1": 0.6643218010044906, "test_runtime": 8.5552, "test_samples_per_second": 239.388, "test_steps_per_second": 7.481}, {"test_loss": 0.7944632172584534, "test_mcc": 0.5025673586349104, "test_macro_f1": 0.6668742248769738, "test_runtime": 8.4482, "test_samples_per_second": 242.419, "test_steps_per_second": 7.576}, {"test_loss": 0.8439698815345764, "test_mcc": 0.4760869641207498, "test_macro_f1": 0.6426867680962387, "test_runtime": 8.2194, "test_samples_per_second": 249.165, "test_steps_per_second": 7.786}]}, "total": {"test_mcc": 49.07070827668095, "test_mcc_se": 1.233410253093405, "test_macro_f1": 65.38427338695173, "test_macro_f1_se": 1.1564170035706696}}, "num_model_parameters": 355090435, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.6588935852050781, "test_mcc": 0.6424518024497679, "test_macro_f1": 0.7546325138727563, "test_runtime": 6.8513, "test_samples_per_second": 298.921, "test_steps_per_second": 9.341}, {"test_loss": 0.6213361024856567, "test_mcc": 0.6212504480494182, "test_macro_f1": 0.7373536179402956, "test_runtime": 6.4856, "test_samples_per_second": 315.777, "test_steps_per_second": 9.868}, {"test_loss": 0.652184784412384, "test_mcc": 0.6480656610843893, "test_macro_f1": 0.7526349810677425, "test_runtime": 6.6302, "test_samples_per_second": 308.89, "test_steps_per_second": 9.653}, {"test_loss": 0.6313056945800781, "test_mcc": 0.6357039142556556, "test_macro_f1": 0.7440090932635316, "test_runtime": 6.6925, "test_samples_per_second": 306.016, "test_steps_per_second": 9.563}, {"test_loss": 0.6088356971740723, "test_mcc": 0.6407428179256007, "test_macro_f1": 0.7530505135532718, "test_runtime": 6.8187, "test_samples_per_second": 300.351, "test_steps_per_second": 9.386}, {"test_loss": 0.6411044001579285, "test_mcc": 0.5844407352232069, "test_macro_f1": 0.7135881812743029, "test_runtime": 6.8392, "test_samples_per_second": 299.451, "test_steps_per_second": 9.358}, {"test_loss": 0.6059059500694275, "test_mcc": 0.6231808283201536, "test_macro_f1": 0.7268776768671333, "test_runtime": 6.6472, "test_samples_per_second": 308.099, "test_steps_per_second": 9.628}, {"test_loss": 0.6466434597969055, "test_mcc": 0.6300816359688723, "test_macro_f1": 0.737815639640528, "test_runtime": 6.7934, "test_samples_per_second": 301.471, "test_steps_per_second": 9.421}, {"test_loss": 0.6072953939437866, "test_mcc": 0.6446739065333345, "test_macro_f1": 0.7639101897073158, "test_runtime": 6.7806, "test_samples_per_second": 302.039, "test_steps_per_second": 9.439}, {"test_loss": 0.5942301750183105, "test_mcc": 0.6697436924605348, "test_macro_f1": 0.7759381771172476, "test_runtime": 6.7561, "test_samples_per_second": 303.135, "test_steps_per_second": 9.473}]}, "total": {"test_mcc": 63.403354422709334, "test_mcc_se": 1.3797956294893974, "test_macro_f1": 74.59810584304127, "test_macro_f1_se": 1.1216071128427876}}, "num_model_parameters": 355090435, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.05983690172433853, "test_micro_f1": 0.7335490830636461, "test_micro_f1_no_misc": 0.7985212569316081, "test_runtime": 14.6734, "test_samples_per_second": 139.573, "test_steps_per_second": 4.362}, {"test_loss": 0.06484460830688477, "test_micro_f1": 0.7113733905579399, "test_micro_f1_no_misc": 0.768955223880597, "test_runtime": 13.1668, "test_samples_per_second": 155.542, "test_steps_per_second": 4.861}, {"test_loss": 0.05108625441789627, "test_micro_f1": 0.7215253386853989, "test_micro_f1_no_misc": 0.772344013490725, "test_runtime": 13.2612, "test_samples_per_second": 154.435, "test_steps_per_second": 4.826}, {"test_loss": 0.053311802446842194, "test_micro_f1": 0.728549924736578, "test_micro_f1_no_misc": 0.7906178489702518, "test_runtime": 14.5132, "test_samples_per_second": 141.113, "test_steps_per_second": 4.41}, {"test_loss": 0.06835876405239105, "test_micro_f1": 0.7462686567164178, "test_micro_f1_no_misc": 0.7921866521975041, "test_runtime": 14.4711, "test_samples_per_second": 141.523, "test_steps_per_second": 4.423}, {"test_loss": 0.06113516539335251, "test_micro_f1": 0.7364729458917837, "test_micro_f1_no_misc": 0.7908020190689848, "test_runtime": 12.2129, "test_samples_per_second": 167.692, "test_steps_per_second": 5.24}, {"test_loss": 0.06606415659189224, "test_micro_f1": 0.7096774193548389, "test_micro_f1_no_misc": 0.7649667405764966, "test_runtime": 12.4343, "test_samples_per_second": 164.706, "test_steps_per_second": 5.147}, {"test_loss": 0.055892214179039, "test_micro_f1": 0.7365045430251203, "test_micro_f1_no_misc": 0.7921760391198044, "test_runtime": 14.9501, "test_samples_per_second": 136.989, "test_steps_per_second": 4.281}, {"test_loss": 0.05580693483352661, "test_micro_f1": 0.696969696969697, "test_micro_f1_no_misc": 0.7653230259525123, "test_runtime": 13.9913, "test_samples_per_second": 146.377, "test_steps_per_second": 4.574}, {"test_loss": 0.051618412137031555, "test_micro_f1": 0.7556650246305419, "test_micro_f1_no_misc": 0.8035126234906695, "test_runtime": 14.8014, "test_samples_per_second": 138.366, "test_steps_per_second": 4.324}]}, "total": {"test_micro_f1": 72.76556023631963, "test_micro_f1_se": 1.1106832230189996, "test_micro_f1_no_misc": 78.39405443679154, "test_micro_f1_no_misc_se": 0.8979015403397903}}, "num_model_parameters": 354046985, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.04898546263575554, "test_micro_f1": 0.8309305373525558, "test_micro_f1_no_misc": 0.8516038068382094, "test_runtime": 15.1815, "test_samples_per_second": 134.901, "test_steps_per_second": 4.216}, {"test_loss": 0.04902965575456619, "test_micro_f1": 0.8231724137931035, "test_micro_f1_no_misc": 0.8506086315012911, "test_runtime": 11.8416, "test_samples_per_second": 172.95, "test_steps_per_second": 5.405}, {"test_loss": 0.05215761438012123, "test_micro_f1": 0.8253706754530478, "test_micro_f1_no_misc": 0.85200146896805, "test_runtime": 14.9307, "test_samples_per_second": 137.167, "test_steps_per_second": 4.286}, {"test_loss": 0.05490652471780777, "test_micro_f1": 0.8157068062827225, "test_micro_f1_no_misc": 0.8430335097001763, "test_runtime": 14.7914, "test_samples_per_second": 138.459, "test_steps_per_second": 4.327}, {"test_loss": 0.06388199329376221, "test_micro_f1": 0.8225157955198161, "test_micro_f1_no_misc": 0.8520988622989408, "test_runtime": 15.2392, "test_samples_per_second": 134.39, "test_steps_per_second": 4.2}, {"test_loss": 0.056779779493808746, "test_micro_f1": 0.7989010989010988, "test_micro_f1_no_misc": 0.8234426833763362, "test_runtime": 15.2088, "test_samples_per_second": 134.659, "test_steps_per_second": 4.208}, {"test_loss": 0.05067228525876999, "test_micro_f1": 0.8290850550040245, "test_micro_f1_no_misc": 0.8581687612208259, "test_runtime": 15.1544, "test_samples_per_second": 135.142, "test_steps_per_second": 4.223}, {"test_loss": 0.053840771317481995, "test_micro_f1": 0.8183034519668184, "test_micro_f1_no_misc": 0.8584005869405723, "test_runtime": 15.0973, "test_samples_per_second": 135.653, "test_steps_per_second": 4.239}, {"test_loss": 0.05760715529322624, "test_micro_f1": 0.8180092215893681, "test_micro_f1_no_misc": 0.8386611508085746, "test_runtime": 14.6056, "test_samples_per_second": 140.22, "test_steps_per_second": 4.382}, {"test_loss": 0.057388342916965485, "test_micro_f1": 0.801062416998672, "test_micro_f1_no_misc": 0.830215319449347, "test_runtime": 12.5651, "test_samples_per_second": 162.992, "test_steps_per_second": 5.093}]}, "total": {"test_micro_f1": 81.83057472861229, "test_micro_f1_se": 0.668707078176139, "test_micro_f1_no_misc": 84.58234781102323, "test_micro_f1_no_misc_se": 0.7298774493284689}}, "num_model_parameters": 354046985, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.03686847537755966, "test_micro_f1": 0.8590795576168392, "test_micro_f1_no_misc": 0.9006462035541196, "test_runtime": 10.7686, "test_samples_per_second": 190.182, "test_steps_per_second": 5.943}, {"test_loss": 0.030175557360053062, "test_micro_f1": 0.8659947741694662, "test_micro_f1_no_misc": 0.904268545379196, "test_runtime": 10.3639, "test_samples_per_second": 197.609, "test_steps_per_second": 6.175}, {"test_loss": 0.039269305765628815, "test_micro_f1": 0.8798862828713574, "test_micro_f1_no_misc": 0.9244833068362481, "test_runtime": 9.7876, "test_samples_per_second": 209.244, "test_steps_per_second": 6.539}, {"test_loss": 0.03367482125759125, "test_micro_f1": 0.8678710591569252, "test_micro_f1_no_misc": 0.9119496855345912, "test_runtime": 9.5589, "test_samples_per_second": 214.251, "test_steps_per_second": 6.695}, {"test_loss": 0.03781771659851074, "test_micro_f1": 0.8535031847133758, "test_micro_f1_no_misc": 0.8913282107574094, "test_runtime": 10.4396, "test_samples_per_second": 196.177, "test_steps_per_second": 6.131}, {"test_loss": 0.03420291095972061, "test_micro_f1": 0.8516390672524501, "test_micro_f1_no_misc": 0.9007803790412485, "test_runtime": 10.4925, "test_samples_per_second": 195.187, "test_steps_per_second": 6.1}, {"test_loss": 0.03268714249134064, "test_micro_f1": 0.8727396792903446, "test_micro_f1_no_misc": 0.9182341650671785, "test_runtime": 9.5011, "test_samples_per_second": 215.554, "test_steps_per_second": 6.736}, {"test_loss": 0.033032797276973724, "test_micro_f1": 0.9084604715672677, "test_micro_f1_no_misc": 0.9390382430897387, "test_runtime": 9.4783, "test_samples_per_second": 216.073, "test_steps_per_second": 6.752}, {"test_loss": 0.03770212084054947, "test_micro_f1": 0.8704553476879633, "test_micro_f1_no_misc": 0.9149277688603532, "test_runtime": 9.7187, "test_samples_per_second": 210.728, "test_steps_per_second": 6.585}, {"test_loss": 0.04186819866299629, "test_micro_f1": 0.8790240596407998, "test_micro_f1_no_misc": 0.9267552182163187, "test_runtime": 10.617, "test_samples_per_second": 192.899, "test_steps_per_second": 6.028}]}, "total": {"test_micro_f1": 87.0865348396679, "test_micro_f1_se": 1.013762845354981, "test_micro_f1_no_misc": 91.324117263364, "test_micro_f1_no_misc_se": 0.895456896730295}}, "num_model_parameters": 354046985, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.03922795504331589, "test_micro_f1": 0.8366849482023156, "test_micro_f1_no_misc": 0.8707070707070708, "test_runtime": 10.1046, "test_samples_per_second": 202.679, "test_steps_per_second": 6.334}, {"test_loss": 0.03986587002873421, "test_micro_f1": 0.8625534514355528, "test_micro_f1_no_misc": 0.8955532574974148, "test_runtime": 10.0803, "test_samples_per_second": 203.169, "test_steps_per_second": 6.349}, {"test_loss": 0.05026077851653099, "test_micro_f1": 0.8388467374810319, "test_micro_f1_no_misc": 0.8797274275979557, "test_runtime": 9.7778, "test_samples_per_second": 209.453, "test_steps_per_second": 6.545}, {"test_loss": 0.04815205931663513, "test_micro_f1": 0.8156259248298313, "test_micro_f1_no_misc": 0.8621503201887429, "test_runtime": 9.93, "test_samples_per_second": 206.243, "test_steps_per_second": 6.445}, {"test_loss": 0.05063992738723755, "test_micro_f1": 0.7911488329796909, "test_micro_f1_no_misc": 0.8518647612408504, "test_runtime": 9.9129, "test_samples_per_second": 206.6, "test_steps_per_second": 6.456}, {"test_loss": 0.04793783277273178, "test_micro_f1": 0.8202348690153569, "test_micro_f1_no_misc": 0.8659517426273458, "test_runtime": 10.1298, "test_samples_per_second": 202.175, "test_steps_per_second": 6.318}, {"test_loss": 0.04070994257926941, "test_micro_f1": 0.8268573204849237, "test_micro_f1_no_misc": 0.8748280605226959, "test_runtime": 9.914, "test_samples_per_second": 206.577, "test_steps_per_second": 6.456}, {"test_loss": 0.042358383536338806, "test_micro_f1": 0.8258024306637582, "test_micro_f1_no_misc": 0.8684389911383777, "test_runtime": 9.83, "test_samples_per_second": 208.341, "test_steps_per_second": 6.511}, {"test_loss": 0.048408519476652145, "test_micro_f1": 0.8371659415786202, "test_micro_f1_no_misc": 0.8788401794960304, "test_runtime": 9.3346, "test_samples_per_second": 219.399, "test_steps_per_second": 6.856}, {"test_loss": 0.04393504187464714, "test_micro_f1": 0.8509600731484305, "test_micro_f1_no_misc": 0.8808013355592654, "test_runtime": 9.8382, "test_samples_per_second": 208.167, "test_steps_per_second": 6.505}]}, "total": {"test_micro_f1": 83.05880529819511, "test_micro_f1_se": 1.2238066656772537, "test_micro_f1_no_misc": 87.28863146575749, "test_micro_f1_no_misc_se": 0.7426882665319016}}, "num_model_parameters": 354046985, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.34290146827697754, "test_mcc": 0.7719770869560745, "test_macro_f1": 0.8852532223059076, "test_runtime": 7.3322, "test_samples_per_second": 279.318, "test_steps_per_second": 8.729}, {"test_loss": 0.3701882064342499, "test_mcc": 0.733519696365474, "test_macro_f1": 0.863410496885338, "test_runtime": 7.7693, "test_samples_per_second": 263.602, "test_steps_per_second": 8.238}, {"test_loss": 0.3488004505634308, "test_mcc": 0.732283700122683, "test_macro_f1": 0.8658096112641568, "test_runtime": 7.871, "test_samples_per_second": 260.196, "test_steps_per_second": 8.131}, {"test_loss": 0.38690292835235596, "test_mcc": 0.7378699018055118, "test_macro_f1": 0.8633226867388342, "test_runtime": 7.5269, "test_samples_per_second": 272.089, "test_steps_per_second": 8.503}, {"test_loss": 0.40584099292755127, "test_mcc": 0.74514637150323, "test_macro_f1": 0.871268943427062, "test_runtime": 7.9396, "test_samples_per_second": 257.949, "test_steps_per_second": 8.061}, {"test_loss": 0.3446861803531647, "test_mcc": 0.7424886745574268, "test_macro_f1": 0.8710814553695077, "test_runtime": 7.786, "test_samples_per_second": 263.036, "test_steps_per_second": 8.22}, {"test_loss": 0.33152657747268677, "test_mcc": 0.7497233827508205, "test_macro_f1": 0.8727673109860534, "test_runtime": 7.6201, "test_samples_per_second": 268.763, "test_steps_per_second": 8.399}, {"test_loss": 0.3313615322113037, "test_mcc": 0.7599870431080864, "test_macro_f1": 0.8766471473983604, "test_runtime": 7.749, "test_samples_per_second": 264.294, "test_steps_per_second": 8.259}, {"test_loss": 0.3449089527130127, "test_mcc": 0.751484802710542, "test_macro_f1": 0.873465446687204, "test_runtime": 7.6783, "test_samples_per_second": 266.727, "test_steps_per_second": 8.335}, {"test_loss": 0.35134419798851013, "test_mcc": 0.7505216587588975, "test_macro_f1": 0.8749903433015895, "test_runtime": 7.6939, "test_samples_per_second": 266.187, "test_steps_per_second": 8.318}]}, "total": {"test_mcc": 74.75002318638747, "test_mcc_se": 0.7549839686250015, "test_macro_f1": 87.18016664364015, "test_macro_f1_se": 0.4118091076358868}}, "num_model_parameters": 355089410, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.407362163066864, "test_mcc": 0.6653664464322041, "test_macro_f1": 0.8279158516196747, "test_runtime": 7.566, "test_samples_per_second": 270.685, "test_steps_per_second": 8.459}, {"test_loss": 0.3885762393474579, "test_mcc": 0.748608185539469, "test_macro_f1": 0.8735283717831734, "test_runtime": 7.6472, "test_samples_per_second": 267.81, "test_steps_per_second": 8.369}, {"test_loss": 0.3723141551017761, "test_mcc": 0.6904252597768086, "test_macro_f1": 0.843843601909371, "test_runtime": 7.3663, "test_samples_per_second": 278.022, "test_steps_per_second": 8.688}, {"test_loss": 0.39314529299736023, "test_mcc": 0.676205410921868, "test_macro_f1": 0.8302806043786617, "test_runtime": 7.8616, "test_samples_per_second": 260.506, "test_steps_per_second": 8.141}, {"test_loss": 0.3599510192871094, "test_mcc": 0.7494393701514387, "test_macro_f1": 0.8744338518258568, "test_runtime": 7.325, "test_samples_per_second": 279.589, "test_steps_per_second": 8.737}, {"test_loss": 0.34736472368240356, "test_mcc": 0.7286314160167758, "test_macro_f1": 0.8599306612617615, "test_runtime": 7.313, "test_samples_per_second": 280.05, "test_steps_per_second": 8.752}, {"test_loss": 0.3676050305366516, "test_mcc": 0.7363074826738909, "test_macro_f1": 0.8660801564027371, "test_runtime": 7.3534, "test_samples_per_second": 278.511, "test_steps_per_second": 8.703}, {"test_loss": 0.38282305002212524, "test_mcc": 0.7522116959407543, "test_macro_f1": 0.8752197882148358, "test_runtime": 7.2721, "test_samples_per_second": 281.624, "test_steps_per_second": 8.801}, {"test_loss": 0.3579784035682678, "test_mcc": 0.7577448128505148, "test_macro_f1": 0.8764081107177342, "test_runtime": 7.3354, "test_samples_per_second": 279.195, "test_steps_per_second": 8.725}, {"test_loss": 0.42762404680252075, "test_mcc": 0.6972213143373006, "test_macro_f1": 0.8463278132243648, "test_runtime": 7.7249, "test_samples_per_second": 265.115, "test_steps_per_second": 8.285}]}, "total": {"test_mcc": 72.02161394641024, "test_mcc_se": 2.145447809521807, "test_macro_f1": 85.73968811338173, "test_macro_f1_se": 1.1727332873945548}}, "num_model_parameters": 355089410, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.3179406523704529, "test_mcc": 0.7856489549926361, "test_macro_f1": 0.8867427057073715, "test_runtime": 6.0665, "test_samples_per_second": 337.59, "test_steps_per_second": 10.55}, {"test_loss": 0.3147212862968445, "test_mcc": 0.8168224639404196, "test_macro_f1": 0.9040199856343689, "test_runtime": 6.0806, "test_samples_per_second": 336.81, "test_steps_per_second": 10.525}, {"test_loss": 0.3731310963630676, "test_mcc": 0.7578915657814723, "test_macro_f1": 0.8668322242177106, "test_runtime": 6.1506, "test_samples_per_second": 332.978, "test_steps_per_second": 10.406}, {"test_loss": 0.3117690086364746, "test_mcc": 0.8000200419711523, "test_macro_f1": 0.894712464745761, "test_runtime": 6.2908, "test_samples_per_second": 325.555, "test_steps_per_second": 10.174}, {"test_loss": 0.3098423480987549, "test_mcc": 0.8099714912702812, "test_macro_f1": 0.9047506155219576, "test_runtime": 6.3051, "test_samples_per_second": 324.817, "test_steps_per_second": 10.151}, {"test_loss": 0.4020155072212219, "test_mcc": 0.7579814581340045, "test_macro_f1": 0.8711913369928017, "test_runtime": 6.027, "test_samples_per_second": 339.803, "test_steps_per_second": 10.619}, {"test_loss": 0.3637085556983948, "test_mcc": 0.765907631505763, "test_macro_f1": 0.8812323447850796, "test_runtime": 6.0619, "test_samples_per_second": 337.849, "test_steps_per_second": 10.558}, {"test_loss": 0.33773624897003174, "test_mcc": 0.812568126330051, "test_macro_f1": 0.9044839860715379, "test_runtime": 6.0615, "test_samples_per_second": 337.868, "test_steps_per_second": 10.558}, {"test_loss": 0.3634260892868042, "test_mcc": 0.7700790297378802, "test_macro_f1": 0.8786790628142542, "test_runtime": 5.9941, "test_samples_per_second": 341.667, "test_steps_per_second": 10.677}, {"test_loss": 0.32615000009536743, "test_mcc": 0.765826540433632, "test_macro_f1": 0.8823219461626146, "test_runtime": 6.2229, "test_samples_per_second": 329.106, "test_steps_per_second": 10.285}]}, "total": {"test_mcc": 78.42717304097293, "test_mcc_se": 1.4662362595521732, "test_macro_f1": 88.74966672653457, "test_macro_f1_se": 0.8639271994340854}}, "num_model_parameters": 355089410, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_loss": 0.27213963866233826, "test_mcc": 0.8187314053910535, "test_macro_f1": 0.9056793534938508, "test_runtime": 6.3499, "test_samples_per_second": 322.524, "test_steps_per_second": 10.079}, {"test_loss": 0.26510798931121826, "test_mcc": 0.8457078989245426, "test_macro_f1": 0.9218355665347071, "test_runtime": 6.6258, "test_samples_per_second": 309.095, "test_steps_per_second": 9.659}, {"test_loss": 0.32893359661102295, "test_mcc": 0.7575832261177021, "test_macro_f1": 0.8755492949120363, "test_runtime": 6.4902, "test_samples_per_second": 315.553, "test_steps_per_second": 9.861}, {"test_loss": 0.3155610263347626, "test_mcc": 0.8006476634794353, "test_macro_f1": 0.9003160932704201, "test_runtime": 6.2181, "test_samples_per_second": 329.36, "test_steps_per_second": 10.292}, {"test_loss": 0.29549795389175415, "test_mcc": 0.8030075103936534, "test_macro_f1": 0.8968959075793909, "test_runtime": 6.2852, "test_samples_per_second": 325.847, "test_steps_per_second": 10.183}, {"test_loss": 0.29288744926452637, "test_mcc": 0.8072152554498252, "test_macro_f1": 0.9027705445850801, "test_runtime": 6.698, "test_samples_per_second": 305.763, "test_steps_per_second": 9.555}, {"test_loss": 0.3465038537979126, "test_mcc": 0.7822985186302144, "test_macro_f1": 0.8884752184667063, "test_runtime": 6.2789, "test_samples_per_second": 326.174, "test_steps_per_second": 10.193}, {"test_loss": 0.3146410584449768, "test_mcc": 0.7999175362482642, "test_macro_f1": 0.8967468772486933, "test_runtime": 6.3767, "test_samples_per_second": 321.172, "test_steps_per_second": 10.037}, {"test_loss": 0.3094998896121979, "test_mcc": 0.7936479062805738, "test_macro_f1": 0.8951027309061764, "test_runtime": 6.2514, "test_samples_per_second": 327.605, "test_steps_per_second": 10.238}, {"test_loss": 0.348523885011673, "test_mcc": 0.7502987322681083, "test_macro_f1": 0.872915566065424, "test_runtime": 6.6292, "test_samples_per_second": 308.934, "test_steps_per_second": 9.654}]}, "total": {"test_mcc": 79.59055653183373, "test_mcc_se": 1.7232470371366877, "test_macro_f1": 89.56287153062486, "test_macro_f1_se": 0.884818652975517}}, "num_model_parameters": 355089410, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_em": 54.6862896979086, "test_f1": 60.463284039491455}, {"test_em": 56.666666666666664, "test_f1": 60.232801809218245}, {"test_em": 55.87326120556414, "test_f1": 60.79602343755542}, {"test_em": 53.504672897196265, "test_f1": 58.38263988162935}, {"test_em": 50.656370656370655, "test_f1": 55.99448179365681}, {"test_em": 54.97301464919044, "test_f1": 60.33227821818899}, {"test_em": 56.71981776765376, "test_f1": 61.155878205992074}, {"test_em": 53.840186190845614, "test_f1": 59.060677187702204}, {"test_em": 55.6078431372549, "test_f1": 59.9746762605586}, {"test_em": 54.037267080745345, "test_f1": 58.56682151345439}]}, "total": {"test_em": 54.65653899493964, "test_em_se": 1.115694386541147, "test_f1": 59.49595623474475, "test_f1_se": 0.9558635801987942}}, "num_model_parameters": 354039810, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_em": 54.6862896979086, "test_f1": 58.6655906252398}, {"test_em": 54.8062015503876, "test_f1": 59.557410556632924}, {"test_em": 55.71870170015456, "test_f1": 60.53869967410427}, {"test_em": 53.97196261682243, "test_f1": 58.52975315738616}, {"test_em": 48.03088803088803, "test_f1": 52.96608826572481}, {"test_em": 56.36083269082498, "test_f1": 60.03913841906254}, {"test_em": 52.619589977220954, "test_f1": 57.14911773636569}, {"test_em": 50.659425911559346, "test_f1": 56.24011595579056}, {"test_em": 53.72549019607843, "test_f1": 59.304391604267735}, {"test_em": 53.57142857142857, "test_f1": 59.23207757530284}]}, "total": {"test_em": 53.415081094327356, "test_em_se": 1.5347382638113711, "test_f1": 58.222238356987724, "test_f1_se": 1.3957388620030617}}, "num_model_parameters": 354039810, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_em": 55.92563903950426, "test_f1": 61.27331840333122}, {"test_em": 53.02325581395349, "test_f1": 57.95370405468322}, {"test_em": 57.03245749613601, "test_f1": 61.999987787284226}, {"test_em": 54.4392523364486, "test_f1": 60.134947324680674}, {"test_em": 52.664092664092664, "test_f1": 58.67048322510505}, {"test_em": 52.968388589051656, "test_f1": 58.80605385677819}, {"test_em": 52.771450265755504, "test_f1": 57.96350347109533}, {"test_em": 53.141970519782774, "test_f1": 58.745516359351676}, {"test_em": 55.21568627450981, "test_f1": 61.21774382224206}, {"test_em": 50.62111801242236, "test_f1": 56.45815946475881}]}, "total": {"test_em": 53.780331101165714, "test_em_se": 1.1606088856405814, "test_f1": 59.32234177693103, "test_f1_se": 1.096672615076921}}, "num_model_parameters": 354039810, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.3871352970600128, "test_mcc": 0.7578602015554144, "test_macro_f1": 0.7423823405411377, "test_runtime": 29.2823, "test_samples_per_second": 69.94, "test_steps_per_second": 8.742}, {"test_loss": 0.4182717204093933, "test_mcc": 0.759826891724121, "test_macro_f1": 0.7422081890155813, "test_runtime": 49.557, "test_samples_per_second": 41.326, "test_steps_per_second": 20.663}, {"test_loss": 0.4033617079257965, "test_mcc": 0.7516992246549881, "test_macro_f1": 0.6124699285927733, "test_runtime": 46.6192, "test_samples_per_second": 43.93, "test_steps_per_second": 21.965}, {"test_loss": 0.30399608612060547, "test_mcc": 0.8006704739433481, "test_macro_f1": 0.7939671951165047, "test_runtime": 48.4032, "test_samples_per_second": 42.311, "test_steps_per_second": 21.156}, {"test_loss": 0.4274510145187378, "test_mcc": 0.7496473729904897, "test_macro_f1": 0.7248625534127074, "test_runtime": 46.3523, "test_samples_per_second": 44.183, "test_steps_per_second": 22.092}, {"test_loss": 0.4115060567855835, "test_mcc": 0.754064529595564, "test_macro_f1": 0.7479164202460633, "test_runtime": 47.9209, "test_samples_per_second": 42.737, "test_steps_per_second": 21.369}, {"test_loss": 0.3983955681324005, "test_mcc": 0.773278122707727, "test_macro_f1": 0.7852466966509938, "test_runtime": 47.7283, "test_samples_per_second": 42.91, "test_steps_per_second": 21.455}, {"test_loss": 0.39282405376434326, "test_mcc": 0.7763123176244795, "test_macro_f1": 0.7645108546149751, "test_runtime": 46.5416, "test_samples_per_second": 44.004, "test_steps_per_second": 22.002}, {"test_loss": 0.3405522108078003, "test_mcc": 0.7781423152178991, "test_macro_f1": 0.781694243813669, "test_runtime": 48.9677, "test_samples_per_second": 41.824, "test_steps_per_second": 20.912}, {"test_loss": 0.41104811429977417, "test_mcc": 0.7619875115823851, "test_macro_f1": 0.7292810515517356, "test_runtime": 47.516, "test_samples_per_second": 43.101, "test_steps_per_second": 21.551}]}, "total": {"test_mcc": 76.63488961596417, "test_mcc_se": 0.9783467499634256, "test_macro_f1": 74.2453947355614, "test_macro_f1_se": 3.1953192645656143}}, "num_model_parameters": 559893507, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.8204175233840942, "test_mcc": 0.5097540600009944, "test_macro_f1": 0.6743952700061762, "test_runtime": 8.9783, "test_samples_per_second": 228.106, "test_steps_per_second": 7.128}, {"test_loss": 0.8414379358291626, "test_mcc": 0.5187110104683985, "test_macro_f1": 0.6777736176850507, "test_runtime": 8.9085, "test_samples_per_second": 229.892, "test_steps_per_second": 7.184}, {"test_loss": 0.8096485733985901, "test_mcc": 0.4756444881561292, "test_macro_f1": 0.6369768535046899, "test_runtime": 8.6716, "test_samples_per_second": 236.174, "test_steps_per_second": 7.38}, {"test_loss": 0.8294230699539185, "test_mcc": 0.48722927028003915, "test_macro_f1": 0.6510445644197014, "test_runtime": 8.6593, "test_samples_per_second": 236.509, "test_steps_per_second": 7.391}, {"test_loss": 0.8320653438568115, "test_mcc": 0.47755990638641876, "test_macro_f1": 0.6518249092915566, "test_runtime": 8.8222, "test_samples_per_second": 232.141, "test_steps_per_second": 7.254}, {"test_loss": 0.9873138666152954, "test_mcc": 0.29277588072421057, "test_macro_f1": 0.4096416992887438, "test_runtime": 8.6982, "test_samples_per_second": 235.451, "test_steps_per_second": 7.358}, {"test_loss": 0.7715890407562256, "test_mcc": 0.5310429005388745, "test_macro_f1": 0.6830754270633248, "test_runtime": 8.707, "test_samples_per_second": 235.214, "test_steps_per_second": 7.35}, {"test_loss": 0.8162652254104614, "test_mcc": 0.544170073346548, "test_macro_f1": 0.6980361768789148, "test_runtime": 8.665, "test_samples_per_second": 236.353, "test_steps_per_second": 7.386}, {"test_loss": 0.7662374973297119, "test_mcc": 0.5248150206465906, "test_macro_f1": 0.6750320927633654, "test_runtime": 8.7421, "test_samples_per_second": 234.27, "test_steps_per_second": 7.321}, {"test_loss": 0.8399264812469482, "test_mcc": 0.4717184290460108, "test_macro_f1": 0.6363326491911935, "test_runtime": 8.5575, "test_samples_per_second": 239.323, "test_steps_per_second": 7.479}]}, "total": {"test_mcc": 48.33421039594216, "test_mcc_se": 4.440857816930505, "test_macro_f1": 63.94133260092717, "test_macro_f1_se": 5.161197833576061}}, "num_model_parameters": 559893507, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.7023526430130005, "test_mcc": 0.6022252561413951, "test_macro_f1": 0.7274421143891893, "test_runtime": 7.459, "test_samples_per_second": 274.568, "test_steps_per_second": 8.58}, {"test_loss": 0.8028318881988525, "test_mcc": 0.5885224311567069, "test_macro_f1": 0.7140274690404174, "test_runtime": 7.0236, "test_samples_per_second": 291.586, "test_steps_per_second": 9.112}, {"test_loss": 0.6797469854354858, "test_mcc": 0.6219387655349154, "test_macro_f1": 0.7273169616792098, "test_runtime": 7.3536, "test_samples_per_second": 278.503, "test_steps_per_second": 8.703}, {"test_loss": 0.6951190233230591, "test_mcc": 0.6426711208972515, "test_macro_f1": 0.747443882282592, "test_runtime": 7.4068, "test_samples_per_second": 276.503, "test_steps_per_second": 8.641}, {"test_loss": 0.7360069751739502, "test_mcc": 0.6110987794037621, "test_macro_f1": 0.7262416236836547, "test_runtime": 7.6139, "test_samples_per_second": 268.981, "test_steps_per_second": 8.406}, {"test_loss": 0.970531165599823, "test_mcc": 0.06877388745656685, "test_macro_f1": 0.2575405907046212, "test_runtime": 7.6629, "test_samples_per_second": 267.263, "test_steps_per_second": 8.352}, {"test_loss": 0.8157010078430176, "test_mcc": 0.6095399734384349, "test_macro_f1": 0.7249538048932499, "test_runtime": 7.2857, "test_samples_per_second": 281.099, "test_steps_per_second": 8.784}, {"test_loss": 0.9970867037773132, "test_mcc": 0.0, "test_macro_f1": 0.2173960732697159, "test_runtime": 7.5512, "test_samples_per_second": 271.214, "test_steps_per_second": 8.475}, {"test_loss": 0.6940078139305115, "test_mcc": 0.6366804545841002, "test_macro_f1": 0.7550743058698229, "test_runtime": 7.754, "test_samples_per_second": 264.123, "test_steps_per_second": 8.254}, {"test_loss": 0.6889348030090332, "test_mcc": 0.6433911251691263, "test_macro_f1": 0.7579711649380054, "test_runtime": 7.4668, "test_samples_per_second": 274.282, "test_steps_per_second": 8.571}]}, "total": {"test_mcc": 50.24841793782259, "test_mcc_se": 15.363603770102493, "test_macro_f1": 63.55407990750479, "test_macro_f1_se": 13.046710409399775}}, "num_model_parameters": 559893507, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.054815612733364105, "test_micro_f1": 0.7487019730010385, "test_micro_f1_no_misc": 0.808227465214761, "test_runtime": 13.9687, "test_samples_per_second": 146.614, "test_steps_per_second": 4.582}, {"test_loss": 0.0418294221162796, "test_micro_f1": 0.7810335641981886, "test_micro_f1_no_misc": 0.826863832409119, "test_runtime": 13.1458, "test_samples_per_second": 155.791, "test_steps_per_second": 4.868}, {"test_loss": 0.05729703605175018, "test_micro_f1": 0.7259615384615385, "test_micro_f1_no_misc": 0.7651715039577837, "test_runtime": 12.8073, "test_samples_per_second": 159.909, "test_steps_per_second": 4.997}, {"test_loss": 0.06815772503614426, "test_micro_f1": 0.5951648351648352, "test_micro_f1_no_misc": 0.7093872962338392, "test_runtime": 13.9158, "test_samples_per_second": 147.17, "test_steps_per_second": 4.599}, {"test_loss": 0.058903779834508896, "test_micro_f1": 0.7836372597338591, "test_micro_f1_no_misc": 0.8236582694414021, "test_runtime": 14.4676, "test_samples_per_second": 141.558, "test_steps_per_second": 4.424}, {"test_loss": 0.04450201243162155, "test_micro_f1": 0.7757404795486601, "test_micro_f1_no_misc": 0.8314855875831486, "test_runtime": 11.351, "test_samples_per_second": 180.425, "test_steps_per_second": 5.638}, {"test_loss": 0.04923862963914871, "test_micro_f1": 0.7471772214040255, "test_micro_f1_no_misc": 0.7966480446927374, "test_runtime": 11.6535, "test_samples_per_second": 175.742, "test_steps_per_second": 5.492}, {"test_loss": 0.05275505408644676, "test_micro_f1": 0.7348277747402953, "test_micro_f1_no_misc": 0.794904458598726, "test_runtime": 13.3583, "test_samples_per_second": 153.313, "test_steps_per_second": 4.791}, {"test_loss": 0.04796348139643669, "test_micro_f1": 0.8057768924302788, "test_micro_f1_no_misc": 0.8331491712707182, "test_runtime": 12.6699, "test_samples_per_second": 161.643, "test_steps_per_second": 5.051}, {"test_loss": 0.04460867494344711, "test_micro_f1": 0.8053624627606752, "test_micro_f1_no_misc": 0.8434540389972145, "test_runtime": 14.3604, "test_samples_per_second": 142.615, "test_steps_per_second": 4.457}]}, "total": {"test_micro_f1": 75.03384001443395, "test_micro_f1_se": 3.7940425049855113, "test_micro_f1_no_misc": 80.32949668399449, "test_micro_f1_no_misc_se": 2.503200603579184}}, "num_model_parameters": 558850057, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.05627206712961197, "test_micro_f1": 0.8580231065468549, "test_micro_f1_no_misc": 0.8774284705051218, "test_runtime": 15.2389, "test_samples_per_second": 134.393, "test_steps_per_second": 4.2}, {"test_loss": 0.04973550885915756, "test_micro_f1": 0.8454469507101086, "test_micro_f1_no_misc": 0.8585220943186038, "test_runtime": 12.8285, "test_samples_per_second": 159.645, "test_steps_per_second": 4.989}, {"test_loss": 0.053817592561244965, "test_micro_f1": 0.8428040361125863, "test_micro_f1_no_misc": 0.8612983327421071, "test_runtime": 15.7546, "test_samples_per_second": 129.993, "test_steps_per_second": 4.062}, {"test_loss": 0.05904737114906311, "test_micro_f1": 0.8606600314300681, "test_micro_f1_no_misc": 0.8757479760647658, "test_runtime": 15.0512, "test_samples_per_second": 136.069, "test_steps_per_second": 4.252}, {"test_loss": 0.0583924725651741, "test_micro_f1": 0.827114782113358, "test_micro_f1_no_misc": 0.8341593595120091, "test_runtime": 15.4848, "test_samples_per_second": 132.259, "test_steps_per_second": 4.133}, {"test_loss": 0.06297972798347473, "test_micro_f1": 0.8458321717312517, "test_micro_f1_no_misc": 0.8521671826625388, "test_runtime": 15.1256, "test_samples_per_second": 135.4, "test_steps_per_second": 4.231}, {"test_loss": 0.05564668029546738, "test_micro_f1": 0.8054180776243813, "test_micro_f1_no_misc": 0.8306731436502429, "test_runtime": 15.5523, "test_samples_per_second": 131.685, "test_steps_per_second": 4.115}, {"test_loss": 0.05402311682701111, "test_micro_f1": 0.8703234880450071, "test_micro_f1_no_misc": 0.8893044128646223, "test_runtime": 15.6346, "test_samples_per_second": 130.992, "test_steps_per_second": 4.093}, {"test_loss": 0.05665120854973793, "test_micro_f1": 0.8218884120171673, "test_micro_f1_no_misc": 0.8366619115549216, "test_runtime": 15.0378, "test_samples_per_second": 136.19, "test_steps_per_second": 4.256}, {"test_loss": 0.06088666245341301, "test_micro_f1": 0.8502517890272993, "test_micro_f1_no_misc": 0.8683834048640915, "test_runtime": 13.014, "test_samples_per_second": 157.37, "test_steps_per_second": 4.918}]}, "total": {"test_micro_f1": 84.27762845358083, "test_micro_f1_se": 1.2153964666769046, "test_micro_f1_no_misc": 85.84346288739026, "test_micro_f1_no_misc_se": 1.2385740654976645}}, "num_model_parameters": 558850057, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.042795971035957336, "test_micro_f1": 0.8450398262128892, "test_micro_f1_no_misc": 0.8804878048780488, "test_runtime": 12.3928, "test_samples_per_second": 165.258, "test_steps_per_second": 5.164}, {"test_loss": 0.030020616948604584, "test_micro_f1": 0.9005891016200295, "test_micro_f1_no_misc": 0.9232026143790849, "test_runtime": 12.7061, "test_samples_per_second": 161.183, "test_steps_per_second": 5.037}, {"test_loss": 0.034155458211898804, "test_micro_f1": 0.9122681883024252, "test_micro_f1_no_misc": 0.9308426073131957, "test_runtime": 11.618, "test_samples_per_second": 176.278, "test_steps_per_second": 5.509}, {"test_loss": 0.030795494094491005, "test_micro_f1": 0.9005971197752021, "test_micro_f1_no_misc": 0.918961447678993, "test_runtime": 11.4039, "test_samples_per_second": 179.588, "test_steps_per_second": 5.612}, {"test_loss": 0.034748680889606476, "test_micro_f1": 0.8842454394693202, "test_micro_f1_no_misc": 0.9089557785209958, "test_runtime": 12.1358, "test_samples_per_second": 168.757, "test_steps_per_second": 5.274}, {"test_loss": 0.0278865285217762, "test_micro_f1": 0.9269643475250952, "test_micro_f1_no_misc": 0.9396284829721363, "test_runtime": 12.3165, "test_samples_per_second": 166.281, "test_steps_per_second": 5.196}, {"test_loss": 0.034885358065366745, "test_micro_f1": 0.8533241946538725, "test_micro_f1_no_misc": 0.8843484965304549, "test_runtime": 11.1216, "test_samples_per_second": 184.146, "test_steps_per_second": 5.755}, {"test_loss": 0.029208429157733917, "test_micro_f1": 0.9155866900175131, "test_micro_f1_no_misc": 0.9355333844973139, "test_runtime": 11.0374, "test_samples_per_second": 185.55, "test_steps_per_second": 5.798}, {"test_loss": 0.035437967628240585, "test_micro_f1": 0.8990298239310097, "test_micro_f1_no_misc": 0.9213020189534403, "test_runtime": 11.3104, "test_samples_per_second": 181.073, "test_steps_per_second": 5.659}, {"test_loss": 0.03651275485754013, "test_micro_f1": 0.8962912087912088, "test_micro_f1_no_misc": 0.9228395061728394, "test_runtime": 12.1319, "test_samples_per_second": 168.811, "test_steps_per_second": 5.275}]}, "total": {"test_micro_f1": 89.33935940298564, "test_micro_f1_se": 1.61981098695257, "test_micro_f1_no_misc": 91.66102141896502, "test_micro_f1_no_misc_se": 1.2403926070771838}}, "num_model_parameters": 558850057, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.04843294620513916, "test_micro_f1": 0.8386095592799503, "test_micro_f1_no_misc": 0.8619505494505495, "test_runtime": 11.1896, "test_samples_per_second": 183.027, "test_steps_per_second": 5.72}, {"test_loss": 0.04747091606259346, "test_micro_f1": 0.8369963369963369, "test_micro_f1_no_misc": 0.869120654396728, "test_runtime": 11.7128, "test_samples_per_second": 174.851, "test_steps_per_second": 5.464}, {"test_loss": 0.049063339829444885, "test_micro_f1": 0.7945945945945946, "test_micro_f1_no_misc": 0.8395484091686624, "test_runtime": 11.25, "test_samples_per_second": 182.045, "test_steps_per_second": 5.689}, {"test_loss": 0.04988551884889603, "test_micro_f1": 0.8310911808669658, "test_micro_f1_no_misc": 0.8614864864864865, "test_runtime": 11.7047, "test_samples_per_second": 174.973, "test_steps_per_second": 5.468}, {"test_loss": 0.05634063482284546, "test_micro_f1": 0.8137313432835821, "test_micro_f1_no_misc": 0.8514084507042253, "test_runtime": 11.2616, "test_samples_per_second": 181.857, "test_steps_per_second": 5.683}, {"test_loss": 0.04502735659480095, "test_micro_f1": 0.8190760059612519, "test_micro_f1_no_misc": 0.8572397422855205, "test_runtime": 11.7115, "test_samples_per_second": 174.871, "test_steps_per_second": 5.465}, {"test_loss": 0.043321218341588974, "test_micro_f1": 0.8467516319552378, "test_micro_f1_no_misc": 0.8750882145377559, "test_runtime": 11.8541, "test_samples_per_second": 172.767, "test_steps_per_second": 5.399}, {"test_loss": 0.04270794987678528, "test_micro_f1": 0.8621216753286457, "test_micro_f1_no_misc": 0.8932309839497559, "test_runtime": 11.5763, "test_samples_per_second": 176.914, "test_steps_per_second": 5.529}, {"test_loss": 0.05245381221175194, "test_micro_f1": 0.8029785913744959, "test_micro_f1_no_misc": 0.8435049437436072, "test_runtime": 10.7926, "test_samples_per_second": 189.76, "test_steps_per_second": 5.93}, {"test_loss": 0.04777101054787636, "test_micro_f1": 0.8400362866646508, "test_micro_f1_no_misc": 0.8661311914323961, "test_runtime": 11.2014, "test_samples_per_second": 182.835, "test_steps_per_second": 5.714}]}, "total": {"test_micro_f1": 82.85987206305713, "test_micro_f1_se": 1.2878253082498867, "test_micro_f1_no_misc": 86.18709626155686, "test_micro_f1_no_misc_se": 0.968064488210388}}, "num_model_parameters": 558850057, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.33640894293785095, "test_mcc": 0.7614896234025008, "test_macro_f1": 0.8741285197899815, "test_runtime": 6.8672, "test_samples_per_second": 298.229, "test_steps_per_second": 9.32}, {"test_loss": 0.6850171089172363, "test_mcc": 0.11884248150855557, "test_macro_f1": 0.5233522047545376, "test_runtime": 7.0655, "test_samples_per_second": 289.861, "test_steps_per_second": 9.058}, {"test_loss": 0.6940895318984985, "test_mcc": 0.21075230649785034, "test_macro_f1": 0.47761815826672804, "test_runtime": 6.857, "test_samples_per_second": 298.672, "test_steps_per_second": 9.333}, {"test_loss": 0.37930941581726074, "test_mcc": 0.727284230715222, "test_macro_f1": 0.8597197904737413, "test_runtime": 6.8145, "test_samples_per_second": 300.535, "test_steps_per_second": 9.392}, {"test_loss": 0.34006714820861816, "test_mcc": 0.7804123303710547, "test_macro_f1": 0.885431744970004, "test_runtime": 6.8811, "test_samples_per_second": 297.629, "test_steps_per_second": 9.301}, {"test_loss": 0.37238603830337524, "test_mcc": 0.6924926931894964, "test_macro_f1": 0.8361010753745683, "test_runtime": 6.621, "test_samples_per_second": 309.319, "test_steps_per_second": 9.666}, {"test_loss": 0.3458500802516937, "test_mcc": 0.741261954565952, "test_macro_f1": 0.8683321132390862, "test_runtime": 6.7274, "test_samples_per_second": 304.428, "test_steps_per_second": 9.513}, {"test_loss": 0.3484962582588196, "test_mcc": 0.7571408205735055, "test_macro_f1": 0.878417707862704, "test_runtime": 7.0249, "test_samples_per_second": 291.536, "test_steps_per_second": 9.111}, {"test_loss": 0.6915184855461121, "test_mcc": 0.12786053361151978, "test_macro_f1": 0.37692844217478044, "test_runtime": 6.9933, "test_samples_per_second": 292.851, "test_steps_per_second": 9.152}, {"test_loss": 0.6909475922584534, "test_mcc": 0.05436318072624609, "test_macro_f1": 0.4137270682288781, "test_runtime": 7.0493, "test_samples_per_second": 290.525, "test_steps_per_second": 9.079}]}, "total": {"test_mcc": 49.71900155161902, "test_mcc_se": 19.881036046470488, "test_macro_f1": 69.93756825135009, "test_macro_f1_se": 13.640276666336238}}, "num_model_parameters": 559892482, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.3977276682853699, "test_mcc": 0.7105285491105332, "test_macro_f1": 0.8517858186987357, "test_runtime": 7.4232, "test_samples_per_second": 275.892, "test_steps_per_second": 8.622}, {"test_loss": 0.3525018095970154, "test_mcc": 0.7181011262988629, "test_macro_f1": 0.8484385992564941, "test_runtime": 7.8862, "test_samples_per_second": 259.694, "test_steps_per_second": 8.115}, {"test_loss": 0.38912296295166016, "test_mcc": 0.674354351410597, "test_macro_f1": 0.8371721729787807, "test_runtime": 7.7048, "test_samples_per_second": 265.808, "test_steps_per_second": 8.307}, {"test_loss": 0.45814746618270874, "test_mcc": 0.6605386218896162, "test_macro_f1": 0.8069910381123195, "test_runtime": 7.9866, "test_samples_per_second": 256.431, "test_steps_per_second": 8.013}, {"test_loss": 0.446727454662323, "test_mcc": 0.6571933514682806, "test_macro_f1": 0.8274836699332766, "test_runtime": 7.3649, "test_samples_per_second": 278.076, "test_steps_per_second": 8.69}, {"test_loss": 0.6855068802833557, "test_mcc": 0.17616099306312138, "test_macro_f1": 0.48836718352910047, "test_runtime": 7.6524, "test_samples_per_second": 267.629, "test_steps_per_second": 8.363}, {"test_loss": 0.39876335859298706, "test_mcc": 0.6759679759298836, "test_macro_f1": 0.8276178850292097, "test_runtime": 7.3036, "test_samples_per_second": 280.408, "test_steps_per_second": 8.763}, {"test_loss": 0.6902431845664978, "test_mcc": 0.06711448335972106, "test_macro_f1": 0.5217628415696466, "test_runtime": 7.4472, "test_samples_per_second": 275.002, "test_steps_per_second": 8.594}, {"test_loss": 0.43092915415763855, "test_mcc": 0.6677359336320362, "test_macro_f1": 0.8118238993710692, "test_runtime": 7.3461, "test_samples_per_second": 278.789, "test_steps_per_second": 8.712}, {"test_loss": 0.3608528971672058, "test_mcc": 0.7223580621330147, "test_macro_f1": 0.8607991883768467, "test_runtime": 7.7276, "test_samples_per_second": 265.025, "test_steps_per_second": 8.282}]}, "total": {"test_mcc": 57.300534482956664, "test_mcc_se": 14.902290715510095, "test_macro_f1": 76.82242296855479, "test_macro_f1_se": 8.673528246518865}}, "num_model_parameters": 559892482, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.40482527017593384, "test_mcc": 0.6784941980118312, "test_macro_f1": 0.8332537262516613, "test_runtime": 6.8409, "test_samples_per_second": 299.377, "test_steps_per_second": 9.356}, {"test_loss": 0.6906373500823975, "test_mcc": 0.0, "test_macro_f1": 0.33678756476683935, "test_runtime": 7.0252, "test_samples_per_second": 291.522, "test_steps_per_second": 9.11}, {"test_loss": 0.3898025155067444, "test_mcc": 0.6971233204674413, "test_macro_f1": 0.8396557978171317, "test_runtime": 7.0381, "test_samples_per_second": 290.986, "test_steps_per_second": 9.093}, {"test_loss": 0.3666995167732239, "test_mcc": 0.7149424466795036, "test_macro_f1": 0.8511759700935155, "test_runtime": 7.134, "test_samples_per_second": 287.076, "test_steps_per_second": 8.971}, {"test_loss": 0.3509388566017151, "test_mcc": 0.717705330147853, "test_macro_f1": 0.8553095591343385, "test_runtime": 7.0522, "test_samples_per_second": 290.405, "test_steps_per_second": 9.075}, {"test_loss": 0.5135200023651123, "test_mcc": 0.6178721964535415, "test_macro_f1": 0.8083297998724135, "test_runtime": 6.8764, "test_samples_per_second": 297.831, "test_steps_per_second": 9.307}, {"test_loss": 0.6937406659126282, "test_mcc": 0.0, "test_macro_f1": 0.3272010512483574, "test_runtime": 6.6487, "test_samples_per_second": 308.031, "test_steps_per_second": 9.626}, {"test_loss": 0.46649423241615295, "test_mcc": 0.6524198489115535, "test_macro_f1": 0.8226884478452053, "test_runtime": 6.8027, "test_samples_per_second": 301.058, "test_steps_per_second": 9.408}, {"test_loss": 0.32812827825546265, "test_mcc": 0.7411680647918047, "test_macro_f1": 0.8705372850567556, "test_runtime": 6.6684, "test_samples_per_second": 307.118, "test_steps_per_second": 9.597}, {"test_loss": 0.43824729323387146, "test_mcc": 0.7313371227347822, "test_macro_f1": 0.8553526384824941, "test_runtime": 6.9337, "test_samples_per_second": 295.368, "test_steps_per_second": 9.23}]}, "total": {"test_mcc": 55.5106252819831, "test_mcc_se": 18.27875845317467, "test_macro_f1": 74.00291840568714, "test_macro_f1_se": 13.375310124451179}}, "num_model_parameters": 559892482, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_loss": 0.4735826551914215, "test_mcc": 0.604787679828942, "test_macro_f1": 0.8016987824753139, "test_runtime": 7.1701, "test_samples_per_second": 285.632, "test_steps_per_second": 8.926}, {"test_loss": 0.6945286989212036, "test_mcc": 0.0, "test_macro_f1": 0.33093760209082, "test_runtime": 7.3184, "test_samples_per_second": 279.842, "test_steps_per_second": 8.745}, {"test_loss": 0.4705820679664612, "test_mcc": 0.6376238114749413, "test_macro_f1": 0.8169287028848682, "test_runtime": 7.4691, "test_samples_per_second": 274.198, "test_steps_per_second": 8.569}, {"test_loss": 0.5239646434783936, "test_mcc": 0.5640589868704627, "test_macro_f1": 0.7779833487511563, "test_runtime": 7.2448, "test_samples_per_second": 282.686, "test_steps_per_second": 8.834}, {"test_loss": 0.6869348287582397, "test_mcc": 0.14976771945785589, "test_macro_f1": 0.49678260605074775, "test_runtime": 7.1282, "test_samples_per_second": 287.308, "test_steps_per_second": 8.978}, {"test_loss": 0.5470249652862549, "test_mcc": 0.5750262025506626, "test_macro_f1": 0.7732676229314608, "test_runtime": 7.3895, "test_samples_per_second": 277.149, "test_steps_per_second": 8.661}, {"test_loss": 0.4958789050579071, "test_mcc": 0.5573841580472291, "test_macro_f1": 0.7782991694611989, "test_runtime": 7.1946, "test_samples_per_second": 284.658, "test_steps_per_second": 8.896}, {"test_loss": 0.5282105207443237, "test_mcc": 0.5410386454294053, "test_macro_f1": 0.7468928001024724, "test_runtime": 7.2208, "test_samples_per_second": 283.625, "test_steps_per_second": 8.863}, {"test_loss": 0.48014315962791443, "test_mcc": 0.6085659208447253, "test_macro_f1": 0.802729671708863, "test_runtime": 7.1333, "test_samples_per_second": 287.103, "test_steps_per_second": 8.972}, {"test_loss": 0.6878487467765808, "test_mcc": 0.15108154818260883, "test_macro_f1": 0.5624991664805645, "test_runtime": 7.2955, "test_samples_per_second": 280.723, "test_steps_per_second": 8.773}]}, "total": {"test_mcc": 43.89334672686833, "test_mcc_se": 14.80535285379094, "test_macro_f1": 68.88019472937465, "test_macro_f1_se": 10.31986417648999}}, "num_model_parameters": 559892482, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_em": 52.8272656855151, "test_f1": 57.8786425451331}, {"test_em": 53.02325581395349, "test_f1": 57.28541659089447}, {"test_em": 53.32302936630603, "test_f1": 58.279384602031094}, {"test_em": 45.32710280373832, "test_f1": 51.26547383412057}, {"test_em": 49.343629343629345, "test_f1": 54.47868150234358}, {"test_em": 53.12259059367772, "test_f1": 57.76949236248021}, {"test_em": 54.21412300683371, "test_f1": 59.13761042321588}, {"test_em": 53.06439100077579, "test_f1": 57.57433238795512}, {"test_em": 48.15686274509804, "test_f1": 53.812751278076334}, {"test_em": 55.590062111801245, "test_f1": 59.6375075062963}]}, "total": {"test_em": 51.79923124713288, "test_em_se": 1.955817877427544, "test_f1": 56.71192930325467, "test_f1_se": 1.646460213590106}}, "num_model_parameters": 558842882, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_em": 54.76374903175833, "test_f1": 59.28178785460429}, {"test_em": 54.57364341085271, "test_f1": 59.55120732660509}, {"test_em": 53.40030911901082, "test_f1": 57.902570803171805}, {"test_em": 53.58255451713396, "test_f1": 57.414512765573186}, {"test_em": 58.22393822393823, "test_f1": 62.711857385010816}, {"test_em": 55.05011565150347, "test_f1": 60.7053332215232}, {"test_em": 51.48063781321184, "test_f1": 56.78155942895321}, {"test_em": 52.90923196276183, "test_f1": 56.96927149468778}, {"test_em": 52.627450980392155, "test_f1": 57.57828507672362}, {"test_em": 55.357142857142854, "test_f1": 61.12061317728778}]}, "total": {"test_em": 54.19687735677062, "test_em_se": 1.1552320397282883, "test_f1": 59.001699853414074, "test_f1_se": 1.2456409998073277}}, "num_model_parameters": 558842882, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_em": 56.23547637490318, "test_f1": 61.221829438142414}, {"test_em": 49.53488372093023, "test_f1": 55.97075456314155}, {"test_em": 52.16383307573416, "test_f1": 57.26805912306626}, {"test_em": 52.64797507788162, "test_f1": 57.997661430866444}, {"test_em": 51.81467181467181, "test_f1": 57.121637325131324}, {"test_em": 51.19506553585197, "test_f1": 55.98002553120459}, {"test_em": 51.48063781321184, "test_f1": 57.85903595552585}, {"test_em": 50.814584949573316, "test_f1": 56.37998566161852}, {"test_em": 48.549019607843135, "test_f1": 55.033729995157785}, {"test_em": 52.484472049689444, "test_f1": 57.93960029790773}]}, "total": {"test_em": 51.69206200202907, "test_em_se": 1.2738442634336191, "test_f1": 57.27723193217624, "test_f1_se": 1.0556615134972727}}, "num_model_parameters": 558842882, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.3965367078781128, "test_mcc": 0.7507224145409094, "test_macro_f1": 0.7626155158965277, "test_runtime": 21.3066, "test_samples_per_second": 96.12, "test_steps_per_second": 12.015}, {"test_loss": 0.44517096877098083, "test_mcc": 0.7308622702738079, "test_macro_f1": 0.6498793809556225, "test_runtime": 21.0297, "test_samples_per_second": 97.386, "test_steps_per_second": 12.173}, {"test_loss": 0.4417114853858948, "test_mcc": 0.7288168568079741, "test_macro_f1": 0.6459133496965808, "test_runtime": 20.9388, "test_samples_per_second": 97.809, "test_steps_per_second": 12.226}, {"test_loss": 0.3613370358943939, "test_mcc": 0.7736311302707327, "test_macro_f1": 0.7599894907579365, "test_runtime": 20.3447, "test_samples_per_second": 100.665, "test_steps_per_second": 12.583}, {"test_loss": 0.37723052501678467, "test_mcc": 0.7662899238777604, "test_macro_f1": 0.7548247140507905, "test_runtime": 20.8179, "test_samples_per_second": 98.377, "test_steps_per_second": 12.297}, {"test_loss": 0.38657575845718384, "test_mcc": 0.7435340566815193, "test_macro_f1": 0.7284409129128582, "test_runtime": 21.3519, "test_samples_per_second": 95.917, "test_steps_per_second": 11.99}, {"test_loss": 0.39786776900291443, "test_mcc": 0.7579571167524491, "test_macro_f1": 0.7438340753703195, "test_runtime": 20.1933, "test_samples_per_second": 101.42, "test_steps_per_second": 12.678}, {"test_loss": 0.415341317653656, "test_mcc": 0.7611470808723811, "test_macro_f1": 0.726219214763387, "test_runtime": 21.2621, "test_samples_per_second": 96.322, "test_steps_per_second": 12.04}, {"test_loss": 0.37897828221321106, "test_mcc": 0.7698448611709681, "test_macro_f1": 0.7389564074677125, "test_runtime": 21.5824, "test_samples_per_second": 94.892, "test_steps_per_second": 11.861}, {"test_loss": 0.42677366733551025, "test_mcc": 0.7409368488101594, "test_macro_f1": 0.6952952906177033, "test_runtime": 20.6594, "test_samples_per_second": 99.132, "test_steps_per_second": 12.391}]}, "total": {"test_mcc": 75.23742560058662, "test_mcc_se": 0.9882974706139681, "test_macro_f1": 72.05968352489438, "test_macro_f1_se": 2.668115424458521}}, "num_model_parameters": 278811651, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.9064520597457886, "test_mcc": 0.3407789850007355, "test_macro_f1": 0.4314972937738963, "test_runtime": 5.2929, "test_samples_per_second": 386.933, "test_steps_per_second": 12.092}, {"test_loss": 0.9186975955963135, "test_mcc": 0.49561741561807443, "test_macro_f1": 0.6610837484661481, "test_runtime": 5.4463, "test_samples_per_second": 376.035, "test_steps_per_second": 11.751}, {"test_loss": 0.9044456481933594, "test_mcc": 0.46968754164891374, "test_macro_f1": 0.6436936182740013, "test_runtime": 5.2774, "test_samples_per_second": 388.069, "test_steps_per_second": 12.127}, {"test_loss": 0.864311933517456, "test_mcc": 0.5016351166601891, "test_macro_f1": 0.6691914010239067, "test_runtime": 5.1758, "test_samples_per_second": 395.69, "test_steps_per_second": 12.365}, {"test_loss": 0.8845715522766113, "test_mcc": 0.3986636591143172, "test_macro_f1": 0.6001093279324068, "test_runtime": 5.3343, "test_samples_per_second": 383.932, "test_steps_per_second": 11.998}, {"test_loss": 0.9163232445716858, "test_mcc": 0.3814259794437524, "test_macro_f1": 0.5708585824658461, "test_runtime": 5.3067, "test_samples_per_second": 385.927, "test_steps_per_second": 12.06}, {"test_loss": 0.9140094518661499, "test_mcc": 0.4417973300765649, "test_macro_f1": 0.6207910456494816, "test_runtime": 5.2176, "test_samples_per_second": 392.52, "test_steps_per_second": 12.266}, {"test_loss": 0.9226231575012207, "test_mcc": 0.4488003969881103, "test_macro_f1": 0.6234819158786025, "test_runtime": 5.3248, "test_samples_per_second": 384.614, "test_steps_per_second": 12.019}, {"test_loss": 0.9119685292243958, "test_mcc": 0.45482954796472047, "test_macro_f1": 0.6316624627062173, "test_runtime": 5.1935, "test_samples_per_second": 394.341, "test_steps_per_second": 12.323}, {"test_loss": 0.9212614297866821, "test_mcc": 0.40463935800568807, "test_macro_f1": 0.553068850028894, "test_runtime": 5.1735, "test_samples_per_second": 395.867, "test_steps_per_second": 12.371}]}, "total": {"test_mcc": 43.37875330521066, "test_mcc_se": 3.195526323643996, "test_macro_f1": 60.05438246199402, "test_macro_f1_se": 4.326623611207948}}, "num_model_parameters": 278811651, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.8291269540786743, "test_mcc": 0.5833622397062029, "test_macro_f1": 0.718954383916064, "test_runtime": 4.8527, "test_samples_per_second": 422.036, "test_steps_per_second": 13.189}, {"test_loss": 0.8028779625892639, "test_mcc": 0.444123450987926, "test_macro_f1": 0.4798790977255473, "test_runtime": 4.7628, "test_samples_per_second": 430.001, "test_steps_per_second": 13.438}, {"test_loss": 0.8781883120536804, "test_mcc": 0.4241566847120703, "test_macro_f1": 0.4726838384372631, "test_runtime": 4.7791, "test_samples_per_second": 428.537, "test_steps_per_second": 13.392}, {"test_loss": 0.7373631000518799, "test_mcc": 0.5935668084365852, "test_macro_f1": 0.7170149230333355, "test_runtime": 4.7445, "test_samples_per_second": 431.655, "test_steps_per_second": 13.489}, {"test_loss": 0.9399011731147766, "test_mcc": 0.5762518991658975, "test_macro_f1": 0.6925241064666068, "test_runtime": 4.8407, "test_samples_per_second": 423.078, "test_steps_per_second": 13.221}, {"test_loss": 0.824440598487854, "test_mcc": 0.44765638733491875, "test_macro_f1": 0.4748198169798321, "test_runtime": 4.8795, "test_samples_per_second": 419.717, "test_steps_per_second": 13.116}, {"test_loss": 0.8682910799980164, "test_mcc": 0.5551422258566872, "test_macro_f1": 0.6859819269595896, "test_runtime": 4.7065, "test_samples_per_second": 435.14, "test_steps_per_second": 13.598}, {"test_loss": 0.7787796258926392, "test_mcc": 0.5692478157760904, "test_macro_f1": 0.6850569124987759, "test_runtime": 4.7488, "test_samples_per_second": 431.267, "test_steps_per_second": 13.477}, {"test_loss": 0.787330150604248, "test_mcc": 0.5784991603093494, "test_macro_f1": 0.7154325752841769, "test_runtime": 4.9621, "test_samples_per_second": 412.727, "test_steps_per_second": 12.898}, {"test_loss": 0.7389636039733887, "test_mcc": 0.5970713301474658, "test_macro_f1": 0.7266370186875095, "test_runtime": 4.9393, "test_samples_per_second": 414.637, "test_steps_per_second": 12.957}]}, "total": {"test_mcc": 53.69078002433193, "test_mcc_se": 4.280786526163719, "test_macro_f1": 63.689845999887005, "test_macro_f1_se": 6.947673439623476}}, "num_model_parameters": 278811651, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.05604847893118858, "test_micro_f1": 0.7558733401430031, "test_micro_f1_no_misc": 0.8212974296205631, "test_runtime": 9.4736, "test_samples_per_second": 216.18, "test_steps_per_second": 6.756}, {"test_loss": 0.0527629628777504, "test_micro_f1": 0.7154213036565977, "test_micro_f1_no_misc": 0.7771836007130126, "test_runtime": 8.927, "test_samples_per_second": 229.417, "test_steps_per_second": 7.169}, {"test_loss": 0.057269833981990814, "test_micro_f1": 0.640076886112446, "test_micro_f1_no_misc": 0.6960257787325457, "test_runtime": 8.5673, "test_samples_per_second": 239.048, "test_steps_per_second": 7.47}, {"test_loss": 0.0476156547665596, "test_micro_f1": 0.7427427427427427, "test_micro_f1_no_misc": 0.7938496583143507, "test_runtime": 9.3479, "test_samples_per_second": 219.087, "test_steps_per_second": 6.846}, {"test_loss": 0.05898095667362213, "test_micro_f1": 0.7344578313253013, "test_micro_f1_no_misc": 0.784623486045287, "test_runtime": 9.2774, "test_samples_per_second": 220.75, "test_steps_per_second": 6.898}, {"test_loss": 0.05133838206529617, "test_micro_f1": 0.7466788822721026, "test_micro_f1_no_misc": 0.8188976377952756, "test_runtime": 7.756, "test_samples_per_second": 264.054, "test_steps_per_second": 8.252}, {"test_loss": 0.0583660788834095, "test_micro_f1": 0.7419354838709677, "test_micro_f1_no_misc": 0.7993254637436763, "test_runtime": 7.9107, "test_samples_per_second": 258.891, "test_steps_per_second": 8.09}, {"test_loss": 0.046933844685554504, "test_micro_f1": 0.7304625199362041, "test_micro_f1_no_misc": 0.7900485436893204, "test_runtime": 9.1481, "test_samples_per_second": 223.872, "test_steps_per_second": 6.996}, {"test_loss": 0.044735539704561234, "test_micro_f1": 0.7386419149975575, "test_micro_f1_no_misc": 0.8065241844769403, "test_runtime": 8.6228, "test_samples_per_second": 237.511, "test_steps_per_second": 7.422}, {"test_loss": 0.05085994303226471, "test_micro_f1": 0.7401960784313727, "test_micro_f1_no_misc": 0.7966101694915254, "test_runtime": 9.2702, "test_samples_per_second": 220.923, "test_steps_per_second": 6.904}]}, "total": {"test_micro_f1": 72.86486983488295, "test_micro_f1_se": 2.0381090829555344, "test_micro_f1_no_misc": 78.84385952622497, "test_micro_f1_no_misc_se": 2.1896974709322876}}, "num_model_parameters": 278225673, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.053501494228839874, "test_micro_f1": 0.8331627430910952, "test_micro_f1_no_misc": 0.8500173190162799, "test_runtime": 9.4486, "test_samples_per_second": 216.753, "test_steps_per_second": 6.774}, {"test_loss": 0.050497621297836304, "test_micro_f1": 0.8639417693169094, "test_micro_f1_no_misc": 0.8823529411764706, "test_runtime": 8.6711, "test_samples_per_second": 236.187, "test_steps_per_second": 7.381}, {"test_loss": 0.055469200015068054, "test_micro_f1": 0.8322884012539185, "test_micro_f1_no_misc": 0.8594982078853046, "test_runtime": 9.2555, "test_samples_per_second": 221.274, "test_steps_per_second": 6.915}, {"test_loss": 0.05601537972688675, "test_micro_f1": 0.8373899533920248, "test_micro_f1_no_misc": 0.8420684835779175, "test_runtime": 9.096, "test_samples_per_second": 225.153, "test_steps_per_second": 7.036}, {"test_loss": 0.0602436363697052, "test_micro_f1": 0.8332859982959386, "test_micro_f1_no_misc": 0.859735349716446, "test_runtime": 9.3384, "test_samples_per_second": 219.309, "test_steps_per_second": 6.853}, {"test_loss": 0.053097959607839584, "test_micro_f1": 0.8255342169326482, "test_micro_f1_no_misc": 0.8448722695298038, "test_runtime": 9.2269, "test_samples_per_second": 221.959, "test_steps_per_second": 6.936}, {"test_loss": 0.052796073257923126, "test_micro_f1": 0.83078545071165, "test_micro_f1_no_misc": 0.8439388553146107, "test_runtime": 9.5864, "test_samples_per_second": 213.635, "test_steps_per_second": 6.676}, {"test_loss": 0.0478082150220871, "test_micro_f1": 0.8462800875273522, "test_micro_f1_no_misc": 0.8742603550295857, "test_runtime": 9.4994, "test_samples_per_second": 215.592, "test_steps_per_second": 6.737}, {"test_loss": 0.056595928966999054, "test_micro_f1": 0.8001061852933369, "test_micro_f1_no_misc": 0.8234442836468886, "test_runtime": 9.1108, "test_samples_per_second": 224.787, "test_steps_per_second": 7.025}, {"test_loss": 0.052943576127290726, "test_micro_f1": 0.8279512969825303, "test_micro_f1_no_misc": 0.8505415162454874, "test_runtime": 9.2453, "test_samples_per_second": 221.517, "test_steps_per_second": 6.922}]}, "total": {"test_micro_f1": 83.30726102797404, "test_micro_f1_se": 0.9954969358131452, "test_micro_f1_no_misc": 85.30729581138795, "test_micro_f1_no_misc_se": 1.0447777622466201}}, "num_model_parameters": 278225673, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.03298938274383545, "test_micro_f1": 0.8917525773195876, "test_micro_f1_no_misc": 0.9217970049916805, "test_runtime": 8.2366, "test_samples_per_second": 248.646, "test_steps_per_second": 7.77}, {"test_loss": 0.028412777930498123, "test_micro_f1": 0.8927231807951989, "test_micro_f1_no_misc": 0.9113817723645526, "test_runtime": 8.4686, "test_samples_per_second": 241.835, "test_steps_per_second": 7.557}, {"test_loss": 0.03433497995138168, "test_micro_f1": 0.894550601556971, "test_micro_f1_no_misc": 0.925984251968504, "test_runtime": 7.8507, "test_samples_per_second": 260.868, "test_steps_per_second": 8.152}, {"test_loss": 0.024927649646997452, "test_micro_f1": 0.917788802267895, "test_micro_f1_no_misc": 0.9349722442505948, "test_runtime": 7.7846, "test_samples_per_second": 263.084, "test_steps_per_second": 8.221}, {"test_loss": 0.03078523278236389, "test_micro_f1": 0.8848848848848849, "test_micro_f1_no_misc": 0.914349276974416, "test_runtime": 8.3876, "test_samples_per_second": 244.169, "test_steps_per_second": 7.63}, {"test_loss": 0.027476739138364792, "test_micro_f1": 0.8957902001380262, "test_micro_f1_no_misc": 0.9193983802545314, "test_runtime": 8.2352, "test_samples_per_second": 248.687, "test_steps_per_second": 7.771}, {"test_loss": 0.02869700826704502, "test_micro_f1": 0.8849862258953168, "test_micro_f1_no_misc": 0.9033244172716852, "test_runtime": 7.5306, "test_samples_per_second": 271.957, "test_steps_per_second": 8.499}, {"test_loss": 0.029206160455942154, "test_micro_f1": 0.8982752551918338, "test_micro_f1_no_misc": 0.9141549027088898, "test_runtime": 7.5603, "test_samples_per_second": 270.89, "test_steps_per_second": 8.465}, {"test_loss": 0.02471258118748665, "test_micro_f1": 0.897445124145376, "test_micro_f1_no_misc": 0.9217181854676836, "test_runtime": 8.0117, "test_samples_per_second": 255.625, "test_steps_per_second": 7.988}, {"test_loss": 0.03904218226671219, "test_micro_f1": 0.8971767166260021, "test_micro_f1_no_misc": 0.9233152594887685, "test_runtime": 154.9636, "test_samples_per_second": 13.216, "test_steps_per_second": 0.413}]}, "total": {"test_micro_f1": 89.5537356882109, "test_micro_f1_se": 0.5684500375484635, "test_micro_f1_no_misc": 91.90395695741307, "test_micro_f1_no_misc_se": 0.5414135622812308}}, "num_model_parameters": 278225673, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.041397836059331894, "test_micro_f1": 0.8136112814224402, "test_micro_f1_no_misc": 0.8413886997957796, "test_runtime": 7.9375, "test_samples_per_second": 258.016, "test_steps_per_second": 8.063}, {"test_loss": 0.03865866735577583, "test_micro_f1": 0.8853057499239428, "test_micro_f1_no_misc": 0.9053583855254002, "test_runtime": 7.9177, "test_samples_per_second": 258.661, "test_steps_per_second": 8.083}, {"test_loss": 0.04576251655817032, "test_micro_f1": 0.8550811785929044, "test_micro_f1_no_misc": 0.8850340136054421, "test_runtime": 7.8025, "test_samples_per_second": 262.481, "test_steps_per_second": 8.203}, {"test_loss": 0.04710959643125534, "test_micro_f1": 0.8593891744783791, "test_micro_f1_no_misc": 0.8881878724150017, "test_runtime": 8.1715, "test_samples_per_second": 250.628, "test_steps_per_second": 7.832}, {"test_loss": 0.05076109990477562, "test_micro_f1": 0.7923513594263519, "test_micro_f1_no_misc": 0.8404588112617309, "test_runtime": 7.6773, "test_samples_per_second": 266.76, "test_steps_per_second": 8.336}, {"test_loss": 0.04882076382637024, "test_micro_f1": 0.8400352216025828, "test_micro_f1_no_misc": 0.8793694311172037, "test_runtime": 7.8189, "test_samples_per_second": 261.928, "test_steps_per_second": 8.185}, {"test_loss": 0.04309312254190445, "test_micro_f1": 0.8180442022403875, "test_micro_f1_no_misc": 0.8494260634706279, "test_runtime": 8.0996, "test_samples_per_second": 252.851, "test_steps_per_second": 7.902}, {"test_loss": 0.03976117819547653, "test_micro_f1": 0.8357384095793676, "test_micro_f1_no_misc": 0.8699271592091572, "test_runtime": 8.1392, "test_samples_per_second": 251.623, "test_steps_per_second": 7.863}, {"test_loss": 0.048015493899583817, "test_micro_f1": 0.8124808810033649, "test_micro_f1_no_misc": 0.8523809523809524, "test_runtime": 7.221, "test_samples_per_second": 283.619, "test_steps_per_second": 8.863}, {"test_loss": 0.04342276602983475, "test_micro_f1": 0.8335336538461539, "test_micro_f1_no_misc": 0.8697689989956477, "test_runtime": 7.6379, "test_samples_per_second": 268.138, "test_steps_per_second": 8.379}]}, "total": {"test_micro_f1": 83.45571112115874, "test_micro_f1_se": 1.6817255646356315, "test_micro_f1_no_misc": 86.81300387776943, "test_micro_f1_no_misc_se": 1.3524030120802006}}, "num_model_parameters": 278225673, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.3704644739627838, "test_mcc": 0.7173524304125735, "test_macro_f1": 0.8569049017482687, "test_runtime": 4.6034, "test_samples_per_second": 444.885, "test_steps_per_second": 13.903}, {"test_loss": 0.36888396739959717, "test_mcc": 0.7037869431297671, "test_macro_f1": 0.8475948004091716, "test_runtime": 4.8894, "test_samples_per_second": 418.865, "test_steps_per_second": 13.09}, {"test_loss": 0.38597798347473145, "test_mcc": 0.7167779681739639, "test_macro_f1": 0.8505246868452325, "test_runtime": 4.7006, "test_samples_per_second": 435.686, "test_steps_per_second": 13.615}, {"test_loss": 0.3663833737373352, "test_mcc": 0.7441739194453115, "test_macro_f1": 0.8712036849504171, "test_runtime": 4.6309, "test_samples_per_second": 442.25, "test_steps_per_second": 13.82}, {"test_loss": 0.3744499087333679, "test_mcc": 0.7220156143684932, "test_macro_f1": 0.8588575826144887, "test_runtime": 4.8516, "test_samples_per_second": 422.131, "test_steps_per_second": 13.192}, {"test_loss": 0.3492131233215332, "test_mcc": 0.7331833474503144, "test_macro_f1": 0.8638931999192937, "test_runtime": 4.6392, "test_samples_per_second": 441.459, "test_steps_per_second": 13.796}, {"test_loss": 0.3521704077720642, "test_mcc": 0.7234757131052075, "test_macro_f1": 0.8612640875037687, "test_runtime": 4.8568, "test_samples_per_second": 421.679, "test_steps_per_second": 13.177}, {"test_loss": 0.3731198310852051, "test_mcc": 0.7020988995011518, "test_macro_f1": 0.840781880196972, "test_runtime": 4.6079, "test_samples_per_second": 444.457, "test_steps_per_second": 13.889}, {"test_loss": 0.3721510171890259, "test_mcc": 0.7127411200620652, "test_macro_f1": 0.8518959517935316, "test_runtime": 4.7933, "test_samples_per_second": 427.266, "test_steps_per_second": 13.352}, {"test_loss": 0.3324239253997803, "test_mcc": 0.7543616352627587, "test_macro_f1": 0.8742057736150377, "test_runtime": 4.9441, "test_samples_per_second": 414.229, "test_steps_per_second": 12.945}]}, "total": {"test_mcc": 72.29967590911606, "test_mcc_se": 1.036853318847553, "test_macro_f1": 85.77126549596184, "test_macro_f1_se": 0.6472054091541872}}, "num_model_parameters": 278810882, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.44487497210502625, "test_mcc": 0.6695615038370623, "test_macro_f1": 0.831744464588239, "test_runtime": 4.8961, "test_samples_per_second": 418.293, "test_steps_per_second": 13.072}, {"test_loss": 0.4327709674835205, "test_mcc": 0.7026984572247758, "test_macro_f1": 0.8510713426539314, "test_runtime": 5.1182, "test_samples_per_second": 400.14, "test_steps_per_second": 12.504}, {"test_loss": 0.4226399064064026, "test_mcc": 0.6768965018378849, "test_macro_f1": 0.83266291230893, "test_runtime": 4.8982, "test_samples_per_second": 418.112, "test_steps_per_second": 13.066}, {"test_loss": 0.44612377882003784, "test_mcc": 0.6347359929115485, "test_macro_f1": 0.8114497344882152, "test_runtime": 5.0493, "test_samples_per_second": 405.605, "test_steps_per_second": 12.675}, {"test_loss": 0.4028400778770447, "test_mcc": 0.6712587266756658, "test_macro_f1": 0.835437879931283, "test_runtime": 5.1851, "test_samples_per_second": 394.978, "test_steps_per_second": 12.343}, {"test_loss": 0.41254764795303345, "test_mcc": 0.6588749460585043, "test_macro_f1": 0.821766171762881, "test_runtime": 5.0597, "test_samples_per_second": 404.765, "test_steps_per_second": 12.649}, {"test_loss": 0.46285295486450195, "test_mcc": 0.6427936896871106, "test_macro_f1": 0.8173725840365014, "test_runtime": 4.746, "test_samples_per_second": 431.523, "test_steps_per_second": 13.485}, {"test_loss": 0.42263269424438477, "test_mcc": 0.7072000650006398, "test_macro_f1": 0.8514241796287185, "test_runtime": 4.821, "test_samples_per_second": 424.811, "test_steps_per_second": 13.275}, {"test_loss": 0.4403086304664612, "test_mcc": 0.6668782950005396, "test_macro_f1": 0.8306942814031846, "test_runtime": 4.9829, "test_samples_per_second": 411.009, "test_steps_per_second": 12.844}, {"test_loss": 0.46708810329437256, "test_mcc": 0.6744713210701263, "test_macro_f1": 0.8338928282016995, "test_runtime": 5.1193, "test_samples_per_second": 400.056, "test_steps_per_second": 12.502}]}, "total": {"test_mcc": 67.05369499303859, "test_mcc_se": 1.4068266723101013, "test_macro_f1": 83.17516379003584, "test_macro_f1_se": 0.799904004168721}}, "num_model_parameters": 278810882, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.3773841857910156, "test_mcc": 0.6899183974034488, "test_macro_f1": 0.8353227030098412, "test_runtime": 4.5487, "test_samples_per_second": 450.238, "test_steps_per_second": 14.07}, {"test_loss": 0.3703681230545044, "test_mcc": 0.7216670389660718, "test_macro_f1": 0.8559340769771882, "test_runtime": 4.7236, "test_samples_per_second": 433.566, "test_steps_per_second": 13.549}, {"test_loss": 0.37773919105529785, "test_mcc": 0.7311488250815106, "test_macro_f1": 0.8611659319559537, "test_runtime": 4.8426, "test_samples_per_second": 422.912, "test_steps_per_second": 13.216}, {"test_loss": 0.34854546189308167, "test_mcc": 0.7124636656363781, "test_macro_f1": 0.853921568627451, "test_runtime": 4.7715, "test_samples_per_second": 429.219, "test_steps_per_second": 13.413}, {"test_loss": 0.4029753804206848, "test_mcc": 0.6665898648680578, "test_macro_f1": 0.8241797249914392, "test_runtime": 4.8093, "test_samples_per_second": 425.838, "test_steps_per_second": 13.307}, {"test_loss": 0.38031989336013794, "test_mcc": 0.735832467298882, "test_macro_f1": 0.8627443114599536, "test_runtime": 4.5985, "test_samples_per_second": 445.366, "test_steps_per_second": 13.918}, {"test_loss": 0.3837168514728546, "test_mcc": 0.705093224189881, "test_macro_f1": 0.8487824036761545, "test_runtime": 4.4966, "test_samples_per_second": 455.455, "test_steps_per_second": 14.233}, {"test_loss": 0.390633225440979, "test_mcc": 0.7284960888339339, "test_macro_f1": 0.8611007993634809, "test_runtime": 4.7345, "test_samples_per_second": 432.567, "test_steps_per_second": 13.518}, {"test_loss": 0.4096047282218933, "test_mcc": 0.6591303324698902, "test_macro_f1": 0.8295602200986033, "test_runtime": 4.7436, "test_samples_per_second": 431.736, "test_steps_per_second": 13.492}, {"test_loss": 0.3861730098724365, "test_mcc": 0.7046392952004888, "test_macro_f1": 0.8466147026626067, "test_runtime": 4.5846, "test_samples_per_second": 446.717, "test_steps_per_second": 13.96}]}, "total": {"test_mcc": 70.54979199948542, "test_mcc_se": 1.6430318815036644, "test_macro_f1": 84.7932644282267, "test_macro_f1_se": 0.8595773016378147}}, "num_model_parameters": 278810882, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_loss": 0.437004417181015, "test_mcc": 0.6216225867598116, "test_macro_f1": 0.8065347387667643, "test_runtime": 4.7717, "test_samples_per_second": 429.195, "test_steps_per_second": 13.412}, {"test_loss": 0.4263010025024414, "test_mcc": 0.6253322500721517, "test_macro_f1": 0.8033933718116613, "test_runtime": 4.8649, "test_samples_per_second": 420.972, "test_steps_per_second": 13.155}, {"test_loss": 0.48553308844566345, "test_mcc": 0.5788388057499886, "test_macro_f1": 0.7789748236481989, "test_runtime": 4.8059, "test_samples_per_second": 426.145, "test_steps_per_second": 13.317}, {"test_loss": 0.488391637802124, "test_mcc": 0.5950199406330111, "test_macro_f1": 0.7791564741612602, "test_runtime": 4.623, "test_samples_per_second": 442.999, "test_steps_per_second": 13.844}, {"test_loss": 0.46835100650787354, "test_mcc": 0.610031370783992, "test_macro_f1": 0.8050139554927518, "test_runtime": 4.6179, "test_samples_per_second": 443.487, "test_steps_per_second": 13.859}, {"test_loss": 0.4532277584075928, "test_mcc": 0.6250756735584709, "test_macro_f1": 0.8002225457468763, "test_runtime": 4.8546, "test_samples_per_second": 421.868, "test_steps_per_second": 13.183}, {"test_loss": 0.46378228068351746, "test_mcc": 0.5942836183794735, "test_macro_f1": 0.7951205419763034, "test_runtime": 4.7612, "test_samples_per_second": 430.141, "test_steps_per_second": 13.442}, {"test_loss": 0.4167032837867737, "test_mcc": 0.6470482091290735, "test_macro_f1": 0.8199146380232818, "test_runtime": 4.629, "test_samples_per_second": 442.429, "test_steps_per_second": 13.826}, {"test_loss": 0.45537692308425903, "test_mcc": 0.6110041523935258, "test_macro_f1": 0.7989219350730781, "test_runtime": 4.613, "test_samples_per_second": 443.963, "test_steps_per_second": 13.874}, {"test_loss": 0.4293414056301117, "test_mcc": 0.6131084699838711, "test_macro_f1": 0.7998300544033454, "test_runtime": 4.8181, "test_samples_per_second": 425.063, "test_steps_per_second": 13.283}]}, "total": {"test_mcc": 61.2136507744337, "test_mcc_se": 1.200687362005872, "test_macro_f1": 79.87083079103522, "test_macro_f1_se": 0.7621423892993394}}, "num_model_parameters": 278810882, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_em": 50.735863671572424, "test_f1": 56.243291755062906}, {"test_em": 50.23255813953488, "test_f1": 54.97815374919558}, {"test_em": 49.92272024729521, "test_f1": 54.8524959877128}, {"test_em": 52.72585669781932, "test_f1": 57.6272244767103}, {"test_em": 47.027027027027025, "test_f1": 53.14297483071395}, {"test_em": 49.961449498843486, "test_f1": 54.34428839945498}, {"test_em": 52.16400911161731, "test_f1": 57.06814892411662}, {"test_em": 52.28859581070597, "test_f1": 57.09278056293284}, {"test_em": 49.490196078431374, "test_f1": 54.626771824531765}, {"test_em": 54.58074534161491, "test_f1": 58.09286641584777}]}, "total": {"test_em": 50.912902162446194, "test_em_se": 1.301785816142632, "test_f1": 55.806899692627965, "test_f1_se": 1.0163489651224136}}, "num_model_parameters": 278220290, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_em": 45.39116963594113, "test_f1": 50.82893927758826}, {"test_em": 52.093023255813954, "test_f1": 57.5252849059458}, {"test_em": 49.381761978361666, "test_f1": 54.56728799098436}, {"test_em": 51.86915887850467, "test_f1": 56.864204415400096}, {"test_em": 50.656370656370655, "test_f1": 55.9571363857078}, {"test_em": 49.80724749421743, "test_f1": 55.335766666934546}, {"test_em": 48.747152619589976, "test_f1": 54.52091485221595}, {"test_em": 49.80605120248254, "test_f1": 55.7255014905244}, {"test_em": 51.76470588235294, "test_f1": 57.338147014094204}, {"test_em": 52.01863354037267, "test_f1": 57.764274315744686}]}, "total": {"test_em": 50.15352751440076, "test_em_se": 1.2823756205119463, "test_f1": 55.64274573151401, "test_f1_se": 1.2769108210686735}}, "num_model_parameters": 278220290, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_em": 51.04570100697134, "test_f1": 56.87472463385}, {"test_em": 48.372093023255815, "test_f1": 54.770236223724574}, {"test_em": 52.009273570324574, "test_f1": 57.22774573935681}, {"test_em": 50.700934579439256, "test_f1": 56.23432829116494}, {"test_em": 54.44015444015444, "test_f1": 58.51205670953567}, {"test_em": 48.88203546646106, "test_f1": 54.2849853770984}, {"test_em": 47.83599088838269, "test_f1": 54.01624380061866}, {"test_em": 52.52133436772692, "test_f1": 57.31898582986242}, {"test_em": 52.15686274509804, "test_f1": 57.16186702375959}, {"test_em": 51.16459627329193, "test_f1": 55.92569896468462}]}, "total": {"test_em": 50.9128976361106, "test_em_se": 1.2727674567797667, "test_f1": 56.23268725936557, "test_f1_se": 0.9142108494441089}}, "num_model_parameters": 278220290, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.39160189032554626, "test_mcc": 0.7567870831601035, "test_macro_f1": 0.7289763219565746, "test_runtime": 11.5486, "test_samples_per_second": 177.337, "test_steps_per_second": 22.167}, {"test_loss": 0.4390621781349182, "test_mcc": 0.723739133752698, "test_macro_f1": 0.6969478456198573, "test_runtime": 10.7608, "test_samples_per_second": 190.32, "test_steps_per_second": 23.79}, {"test_loss": 0.4432726502418518, "test_mcc": 0.6964579219036385, "test_macro_f1": 0.6671826181759957, "test_runtime": 11.4002, "test_samples_per_second": 179.646, "test_steps_per_second": 22.456}, {"test_loss": 0.3569955825805664, "test_mcc": 0.7751174997239167, "test_macro_f1": 0.7789615238707869, "test_runtime": 10.6461, "test_samples_per_second": 192.371, "test_steps_per_second": 24.046}, {"test_loss": 0.4175899922847748, "test_mcc": 0.7212307127188395, "test_macro_f1": 0.695020012932253, "test_runtime": 10.6259, "test_samples_per_second": 192.736, "test_steps_per_second": 24.092}, {"test_loss": 0.42545294761657715, "test_mcc": 0.718500794543388, "test_macro_f1": 0.6465026491283783, "test_runtime": 11.4216, "test_samples_per_second": 179.309, "test_steps_per_second": 22.414}, {"test_loss": 0.3952180743217468, "test_mcc": 0.7470259055064282, "test_macro_f1": 0.7239874029964369, "test_runtime": 10.772, "test_samples_per_second": 190.123, "test_steps_per_second": 23.765}, {"test_loss": 0.40563833713531494, "test_mcc": 0.7431716847512082, "test_macro_f1": 0.7183025991854014, "test_runtime": 11.1195, "test_samples_per_second": 184.182, "test_steps_per_second": 23.023}, {"test_loss": 0.41585657000541687, "test_mcc": 0.736429291012297, "test_macro_f1": 0.6572166533245158, "test_runtime": 11.3178, "test_samples_per_second": 180.953, "test_steps_per_second": 22.619}, {"test_loss": 0.3966815769672394, "test_mcc": 0.739975281053016, "test_macro_f1": 0.7299728016968468, "test_runtime": 10.7781, "test_samples_per_second": 190.015, "test_steps_per_second": 23.752}]}, "total": {"test_mcc": 73.58435308125533, "test_mcc_se": 1.3687740934352473, "test_macro_f1": 70.43070428887049, "test_macro_f1_se": 2.487928208964444}}, "num_model_parameters": 470929155, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.7705158591270447, "test_mcc": 0.4996337688004109, "test_macro_f1": 0.6724454926019893, "test_runtime": 3.2546, "test_samples_per_second": 629.27, "test_steps_per_second": 19.665}, {"test_loss": 0.8581838011741638, "test_mcc": 0.4677113971825856, "test_macro_f1": 0.6381615990274545, "test_runtime": 3.2003, "test_samples_per_second": 639.948, "test_steps_per_second": 19.998}, {"test_loss": 0.8210647702217102, "test_mcc": 0.4764334456159978, "test_macro_f1": 0.6531000027153717, "test_runtime": 3.2619, "test_samples_per_second": 627.86, "test_steps_per_second": 19.621}, {"test_loss": 0.8513509035110474, "test_mcc": 0.4241281223657969, "test_macro_f1": 0.605699478699686, "test_runtime": 3.3351, "test_samples_per_second": 614.07, "test_steps_per_second": 19.19}, {"test_loss": 0.7952379584312439, "test_mcc": 0.45942518815062355, "test_macro_f1": 0.6434500301548973, "test_runtime": 3.1889, "test_samples_per_second": 642.234, "test_steps_per_second": 20.07}, {"test_loss": 0.8428276777267456, "test_mcc": 0.4752770320865033, "test_macro_f1": 0.6521346899371919, "test_runtime": 3.2185, "test_samples_per_second": 636.316, "test_steps_per_second": 19.885}, {"test_loss": 0.8545827865600586, "test_mcc": 0.4616575721305613, "test_macro_f1": 0.6435046747282894, "test_runtime": 3.1936, "test_samples_per_second": 641.275, "test_steps_per_second": 20.04}, {"test_loss": 0.800594687461853, "test_mcc": 0.5033382836042326, "test_macro_f1": 0.6652884805181345, "test_runtime": 3.3173, "test_samples_per_second": 617.378, "test_steps_per_second": 19.293}, {"test_loss": 0.8309443593025208, "test_mcc": 0.4398906600037691, "test_macro_f1": 0.6260346591337801, "test_runtime": 3.2584, "test_samples_per_second": 628.527, "test_steps_per_second": 19.641}, {"test_loss": 0.8471696972846985, "test_mcc": 0.4420103915892607, "test_macro_f1": 0.6307409541661563, "test_runtime": 3.2509, "test_samples_per_second": 629.985, "test_steps_per_second": 19.687}]}, "total": {"test_mcc": 46.49505861529741, "test_mcc_se": 1.5713654157917891, "test_macro_f1": 64.30560061682951, "test_macro_f1_se": 1.2051366688737288}}, "num_model_parameters": 470929155, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.742825448513031, "test_mcc": 0.5773020628929353, "test_macro_f1": 0.7055081974331158, "test_runtime": 2.8331, "test_samples_per_second": 722.881, "test_steps_per_second": 22.59}, {"test_loss": 0.6953660249710083, "test_mcc": 0.5123604087972256, "test_macro_f1": 0.6393876410253782, "test_runtime": 2.7486, "test_samples_per_second": 745.113, "test_steps_per_second": 23.285}, {"test_loss": 0.7022420167922974, "test_mcc": 0.5268086861618853, "test_macro_f1": 0.6706157002928341, "test_runtime": 3.0773, "test_samples_per_second": 665.528, "test_steps_per_second": 20.798}, {"test_loss": 0.7290580868721008, "test_mcc": 0.519277528697733, "test_macro_f1": 0.6530655112457232, "test_runtime": 2.7938, "test_samples_per_second": 733.057, "test_steps_per_second": 22.908}, {"test_loss": 0.7127423286437988, "test_mcc": 0.5042578004869992, "test_macro_f1": 0.6473463713624196, "test_runtime": 2.8611, "test_samples_per_second": 715.819, "test_steps_per_second": 22.369}, {"test_loss": 0.7168850898742676, "test_mcc": 0.5382801568654215, "test_macro_f1": 0.6801124091175433, "test_runtime": 2.841, "test_samples_per_second": 720.867, "test_steps_per_second": 22.527}, {"test_loss": 0.6752638220787048, "test_mcc": 0.5886949929293467, "test_macro_f1": 0.7098690551983523, "test_runtime": 2.7877, "test_samples_per_second": 734.649, "test_steps_per_second": 22.958}, {"test_loss": 0.6898441314697266, "test_mcc": 0.5494714948136711, "test_macro_f1": 0.6702245040419735, "test_runtime": 2.961, "test_samples_per_second": 691.657, "test_steps_per_second": 21.614}, {"test_loss": 0.6814467906951904, "test_mcc": 0.5421960420844218, "test_macro_f1": 0.6605435406212145, "test_runtime": 2.8264, "test_samples_per_second": 724.593, "test_steps_per_second": 22.644}, {"test_loss": 0.7135390043258667, "test_mcc": 0.5672467976739365, "test_macro_f1": 0.6887133711916427, "test_runtime": 2.891, "test_samples_per_second": 708.399, "test_steps_per_second": 22.137}]}, "total": {"test_mcc": 54.25895971403576, "test_mcc_se": 1.7506830940542677, "test_macro_f1": 67.25386301530196, "test_macro_f1_se": 1.4704083101710108}}, "num_model_parameters": 470929155, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.05363640561699867, "test_micro_f1": 0.6967545638945234, "test_micro_f1_no_misc": 0.7808219178082192, "test_runtime": 6.1658, "test_samples_per_second": 332.157, "test_steps_per_second": 10.38}, {"test_loss": 0.05508258193731308, "test_micro_f1": 0.7307898979043526, "test_micro_f1_no_misc": 0.7917189460476788, "test_runtime": 5.4622, "test_samples_per_second": 374.943, "test_steps_per_second": 11.717}, {"test_loss": 0.05452176183462143, "test_micro_f1": 0.7195301027900147, "test_micro_f1_no_misc": 0.7572192513368985, "test_runtime": 5.635, "test_samples_per_second": 363.444, "test_steps_per_second": 11.358}, {"test_loss": 0.052072539925575256, "test_micro_f1": 0.6940187839841819, "test_micro_f1_no_misc": 0.7383783783783784, "test_runtime": 5.8358, "test_samples_per_second": 350.935, "test_steps_per_second": 10.967}, {"test_loss": 0.056713271886110306, "test_micro_f1": 0.7537205952952473, "test_micro_f1_no_misc": 0.8060344827586208, "test_runtime": 5.888, "test_samples_per_second": 347.825, "test_steps_per_second": 10.87}, {"test_loss": 0.05259690433740616, "test_micro_f1": 0.7307146237576905, "test_micro_f1_no_misc": 0.7865290602933188, "test_runtime": 5.2057, "test_samples_per_second": 393.411, "test_steps_per_second": 12.294}, {"test_loss": 0.060233913362026215, "test_micro_f1": 0.6587419514611194, "test_micro_f1_no_misc": 0.7283105022831051, "test_runtime": 5.388, "test_samples_per_second": 380.102, "test_steps_per_second": 11.878}, {"test_loss": 0.04685961455106735, "test_micro_f1": 0.7400109469074986, "test_micro_f1_no_misc": 0.7893101305158484, "test_runtime": 5.9504, "test_samples_per_second": 344.178, "test_steps_per_second": 10.756}, {"test_loss": 0.05065387859940529, "test_micro_f1": 0.7451946771808773, "test_micro_f1_no_misc": 0.8066298342541437, "test_runtime": 5.8209, "test_samples_per_second": 351.838, "test_steps_per_second": 10.995}, {"test_loss": 0.050872787833213806, "test_micro_f1": 0.7383406971035836, "test_micro_f1_no_misc": 0.7931818181818181, "test_runtime": 5.9217, "test_samples_per_second": 345.845, "test_steps_per_second": 10.808}]}, "total": {"test_micro_f1": 72.0781684027909, "test_micro_f1_se": 1.8131533127377135, "test_micro_f1_no_misc": 77.7813432185803, "test_micro_f1_no_misc_se": 1.6915321575549511}}, "num_model_parameters": 470343177, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.05321505665779114, "test_micro_f1": 0.8304303278688525, "test_micro_f1_no_misc": 0.8429065743944636, "test_runtime": 7.0689, "test_samples_per_second": 289.72, "test_steps_per_second": 9.054}, {"test_loss": 0.05321386456489563, "test_micro_f1": 0.8141985579589573, "test_micro_f1_no_misc": 0.8295165394402035, "test_runtime": 5.822, "test_samples_per_second": 351.771, "test_steps_per_second": 10.993}, {"test_loss": 0.04887815937399864, "test_micro_f1": 0.8716707021791767, "test_micro_f1_no_misc": 0.88388969521045, "test_runtime": 7.0141, "test_samples_per_second": 291.983, "test_steps_per_second": 9.124}, {"test_loss": 0.05631473660469055, "test_micro_f1": 0.8130502330398758, "test_micro_f1_no_misc": 0.8211640211640212, "test_runtime": 7.2319, "test_samples_per_second": 283.19, "test_steps_per_second": 8.85}, {"test_loss": 0.057721976190805435, "test_micro_f1": 0.8263439347030679, "test_micro_f1_no_misc": 0.8362528560548363, "test_runtime": 6.9948, "test_samples_per_second": 292.787, "test_steps_per_second": 9.15}, {"test_loss": 0.05034386366605759, "test_micro_f1": 0.8317653569452131, "test_micro_f1_no_misc": 0.8360225140712945, "test_runtime": 7.1633, "test_samples_per_second": 285.903, "test_steps_per_second": 8.934}, {"test_loss": 0.05615636706352234, "test_micro_f1": 0.8176234979973298, "test_micro_f1_no_misc": 0.8393819619116062, "test_runtime": 7.1964, "test_samples_per_second": 284.586, "test_steps_per_second": 8.893}, {"test_loss": 0.047936923801898956, "test_micro_f1": 0.8330091692136704, "test_micro_f1_no_misc": 0.843328335832084, "test_runtime": 7.0238, "test_samples_per_second": 291.58, "test_steps_per_second": 9.112}, {"test_loss": 0.05523692071437836, "test_micro_f1": 0.8442425861608336, "test_micro_f1_no_misc": 0.8550185873605947, "test_runtime": 6.9037, "test_samples_per_second": 296.652, "test_steps_per_second": 9.27}, {"test_loss": 0.05706475302577019, "test_micro_f1": 0.8033495407887629, "test_micro_f1_no_misc": 0.8219876228613032, "test_runtime": 6.0834, "test_samples_per_second": 336.653, "test_steps_per_second": 10.52}]}, "total": {"test_micro_f1": 82.85683906855739, "test_micro_f1_se": 1.194891504800262, "test_micro_f1_no_misc": 84.09468708300858, "test_micro_f1_no_misc_se": 1.1281706368404805}}, "num_model_parameters": 470343177, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.03195611387491226, "test_micro_f1": 0.8515140459686247, "test_micro_f1_no_misc": 0.8864105741429161, "test_runtime": 5.6213, "test_samples_per_second": 364.33, "test_steps_per_second": 11.385}, {"test_loss": 0.03032519854605198, "test_micro_f1": 0.8617219530376443, "test_micro_f1_no_misc": 0.8874172185430462, "test_runtime": 5.4323, "test_samples_per_second": 377.006, "test_steps_per_second": 11.781}, {"test_loss": 0.03588184341788292, "test_micro_f1": 0.8738002132954141, "test_micro_f1_no_misc": 0.9075029773719729, "test_runtime": 5.3816, "test_samples_per_second": 380.555, "test_steps_per_second": 11.892}, {"test_loss": 0.02729984000325203, "test_micro_f1": 0.894458171549594, "test_micro_f1_no_misc": 0.9158435401027262, "test_runtime": 5.2349, "test_samples_per_second": 391.221, "test_steps_per_second": 12.226}, {"test_loss": 0.030664779245853424, "test_micro_f1": 0.8929663608562691, "test_micro_f1_no_misc": 0.9151122953939855, "test_runtime": 5.5281, "test_samples_per_second": 370.471, "test_steps_per_second": 11.577}, {"test_loss": 0.024075591936707497, "test_micro_f1": 0.893587994542974, "test_micro_f1_no_misc": 0.9241326725123903, "test_runtime": 5.4734, "test_samples_per_second": 374.176, "test_steps_per_second": 11.693}, {"test_loss": 0.03023332543671131, "test_micro_f1": 0.8796136598827181, "test_micro_f1_no_misc": 0.9060092449922958, "test_runtime": 5.2601, "test_samples_per_second": 389.35, "test_steps_per_second": 12.167}, {"test_loss": 0.030707713216543198, "test_micro_f1": 0.8874956461163358, "test_micro_f1_no_misc": 0.9129447388342165, "test_runtime": 5.388, "test_samples_per_second": 380.104, "test_steps_per_second": 11.878}, {"test_loss": 0.03151465952396393, "test_micro_f1": 0.8586878154289835, "test_micro_f1_no_misc": 0.8838920686835651, "test_runtime": 5.3229, "test_samples_per_second": 384.749, "test_steps_per_second": 12.023}, {"test_loss": 0.03513474017381668, "test_micro_f1": 0.8903313973351554, "test_micro_f1_no_misc": 0.9190640583045647, "test_runtime": 5.5283, "test_samples_per_second": 370.459, "test_steps_per_second": 11.577}]}, "total": {"test_micro_f1": 87.84177258013713, "test_micro_f1_se": 0.998984439260425, "test_micro_f1_no_misc": 90.5832938888168, "test_micro_f1_no_misc_se": 0.9117284737793367}}, "num_model_parameters": 470343177, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.04383064806461334, "test_micro_f1": 0.8062924120913015, "test_micro_f1_no_misc": 0.8449931412894377, "test_runtime": 5.5148, "test_samples_per_second": 371.363, "test_steps_per_second": 11.605}, {"test_loss": 0.04602315276861191, "test_micro_f1": 0.8397553516819571, "test_micro_f1_no_misc": 0.874231032125769, "test_runtime": 5.4232, "test_samples_per_second": 377.637, "test_steps_per_second": 11.801}, {"test_loss": 0.048718035221099854, "test_micro_f1": 0.8018126888217523, "test_micro_f1_no_misc": 0.8450233800935204, "test_runtime": 5.4043, "test_samples_per_second": 378.954, "test_steps_per_second": 11.842}, {"test_loss": 0.05938190221786499, "test_micro_f1": 0.765505020673361, "test_micro_f1_no_misc": 0.8139915004903563, "test_runtime": 5.3836, "test_samples_per_second": 380.413, "test_steps_per_second": 11.888}, {"test_loss": 0.05208040773868561, "test_micro_f1": 0.827460510328068, "test_micro_f1_no_misc": 0.8539007092198583, "test_runtime": 5.3056, "test_samples_per_second": 386.007, "test_steps_per_second": 12.063}, {"test_loss": 0.050549477338790894, "test_micro_f1": 0.8258141619360623, "test_micro_f1_no_misc": 0.857912457912458, "test_runtime": 5.2797, "test_samples_per_second": 387.899, "test_steps_per_second": 12.122}, {"test_loss": 0.041689448058605194, "test_micro_f1": 0.8250232270052649, "test_micro_f1_no_misc": 0.867238421955403, "test_runtime": 5.5822, "test_samples_per_second": 366.882, "test_steps_per_second": 11.465}, {"test_loss": 0.045508936047554016, "test_micro_f1": 0.8233467867122012, "test_micro_f1_no_misc": 0.8608211551844119, "test_runtime": 5.4779, "test_samples_per_second": 373.863, "test_steps_per_second": 11.683}, {"test_loss": 0.054440323263406754, "test_micro_f1": 0.8117465224111282, "test_micro_f1_no_misc": 0.8417015341701534, "test_runtime": 5.4915, "test_samples_per_second": 372.939, "test_steps_per_second": 11.654}, {"test_loss": 0.04608859121799469, "test_micro_f1": 0.8298197372441186, "test_micro_f1_no_misc": 0.8613628734474655, "test_runtime": 5.3085, "test_samples_per_second": 385.793, "test_steps_per_second": 12.056}]}, "total": {"test_micro_f1": 81.56576418905213, "test_micro_f1_se": 1.3034838045182982, "test_micro_f1_no_misc": 85.21176205888834, "test_micro_f1_no_misc_se": 1.0491666200614682}}, "num_model_parameters": 470343177, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.43730783462524414, "test_mcc": 0.6319390402777431, "test_macro_f1": 0.8094151324488181, "test_runtime": 2.8062, "test_samples_per_second": 729.813, "test_steps_per_second": 22.807}, {"test_loss": 0.5408550500869751, "test_mcc": 0.6343984188043015, "test_macro_f1": 0.8115156744319816, "test_runtime": 2.8062, "test_samples_per_second": 729.801, "test_steps_per_second": 22.806}, {"test_loss": 0.5067269802093506, "test_mcc": 0.5913578462041897, "test_macro_f1": 0.7884773534842584, "test_runtime": 2.8769, "test_samples_per_second": 711.875, "test_steps_per_second": 22.246}, {"test_loss": 0.4609425663948059, "test_mcc": 0.6610884124467467, "test_macro_f1": 0.830300952088034, "test_runtime": 2.8299, "test_samples_per_second": 723.69, "test_steps_per_second": 22.615}, {"test_loss": 0.5004080533981323, "test_mcc": 0.5521277139055264, "test_macro_f1": 0.7725548647728737, "test_runtime": 2.7993, "test_samples_per_second": 731.618, "test_steps_per_second": 22.863}, {"test_loss": 0.4783003330230713, "test_mcc": 0.5349268084311963, "test_macro_f1": 0.7669871232964933, "test_runtime": 2.8316, "test_samples_per_second": 723.278, "test_steps_per_second": 22.602}, {"test_loss": 0.43661999702453613, "test_mcc": 0.671013686203257, "test_macro_f1": 0.8330403516258632, "test_runtime": 2.7374, "test_samples_per_second": 748.159, "test_steps_per_second": 23.38}, {"test_loss": 0.5084222555160522, "test_mcc": 0.5473623429085407, "test_macro_f1": 0.7677124240368569, "test_runtime": 2.799, "test_samples_per_second": 731.691, "test_steps_per_second": 22.865}, {"test_loss": 0.469752699136734, "test_mcc": 0.5887325875913761, "test_macro_f1": 0.7847753928288814, "test_runtime": 2.7919, "test_samples_per_second": 733.552, "test_steps_per_second": 22.924}, {"test_loss": 0.4435339868068695, "test_mcc": 0.6225861951833582, "test_macro_f1": 0.8067900471895542, "test_runtime": 2.7346, "test_samples_per_second": 748.911, "test_steps_per_second": 23.403}]}, "total": {"test_mcc": 60.355330519562344, "test_mcc_se": 2.9839964263686296, "test_macro_f1": 79.71569316203615, "test_macro_f1_se": 1.5247287595592094}}, "num_model_parameters": 470928386, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.5419899225234985, "test_mcc": 0.4652160189309518, "test_macro_f1": 0.7181127057082712, "test_runtime": 2.9743, "test_samples_per_second": 688.571, "test_steps_per_second": 21.518}, {"test_loss": 0.5408096313476562, "test_mcc": 0.4902648591114864, "test_macro_f1": 0.728038647792524, "test_runtime": 2.9712, "test_samples_per_second": 689.279, "test_steps_per_second": 21.54}, {"test_loss": 0.4902965724468231, "test_mcc": 0.5765922770301396, "test_macro_f1": 0.7841529270492094, "test_runtime": 2.901, "test_samples_per_second": 705.964, "test_steps_per_second": 22.061}, {"test_loss": 0.5086987614631653, "test_mcc": 0.5567129670928425, "test_macro_f1": 0.773905213370235, "test_runtime": 2.9995, "test_samples_per_second": 682.771, "test_steps_per_second": 21.337}, {"test_loss": 0.4693358540534973, "test_mcc": 0.6086818000175002, "test_macro_f1": 0.8005023724473006, "test_runtime": 2.9753, "test_samples_per_second": 688.324, "test_steps_per_second": 21.51}, {"test_loss": 0.5207833051681519, "test_mcc": 0.5168082698188097, "test_macro_f1": 0.7396150343979134, "test_runtime": 2.8928, "test_samples_per_second": 707.957, "test_steps_per_second": 22.124}, {"test_loss": 0.5815753936767578, "test_mcc": 0.571062420883831, "test_macro_f1": 0.778483351740132, "test_runtime": 2.9164, "test_samples_per_second": 702.229, "test_steps_per_second": 21.945}, {"test_loss": 0.5113295316696167, "test_mcc": 0.5657927222874594, "test_macro_f1": 0.7785243608784047, "test_runtime": 2.9448, "test_samples_per_second": 695.453, "test_steps_per_second": 21.733}, {"test_loss": 0.6289982795715332, "test_mcc": 0.3686974636622219, "test_macro_f1": 0.6251389681878549, "test_runtime": 2.9887, "test_samples_per_second": 685.259, "test_steps_per_second": 21.414}, {"test_loss": 0.5512924194335938, "test_mcc": 0.5719217431623536, "test_macro_f1": 0.7849328917685852, "test_runtime": 2.9848, "test_samples_per_second": 686.134, "test_steps_per_second": 21.442}]}, "total": {"test_mcc": 52.91750541997595, "test_mcc_se": 4.419619772617659, "test_macro_f1": 75.1140647334043, "test_macro_f1_se": 3.221790188124053}}, "num_model_parameters": 470928386, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.49817293882369995, "test_mcc": 0.590613300922386, "test_macro_f1": 0.7763521396773654, "test_runtime": 2.7735, "test_samples_per_second": 738.42, "test_steps_per_second": 23.076}, {"test_loss": 0.5570639371871948, "test_mcc": 0.6334429491930968, "test_macro_f1": 0.8147311055167592, "test_runtime": 2.8194, "test_samples_per_second": 726.396, "test_steps_per_second": 22.7}, {"test_loss": 0.4625279903411865, "test_mcc": 0.5862525329192286, "test_macro_f1": 0.7817343882018588, "test_runtime": 2.7913, "test_samples_per_second": 733.72, "test_steps_per_second": 22.929}, {"test_loss": 0.47816017270088196, "test_mcc": 0.5994602683520049, "test_macro_f1": 0.7982460922518366, "test_runtime": 2.8782, "test_samples_per_second": 711.556, "test_steps_per_second": 22.236}, {"test_loss": 0.5543542504310608, "test_mcc": 0.6012473921664125, "test_macro_f1": 0.7867941739388085, "test_runtime": 2.775, "test_samples_per_second": 738.029, "test_steps_per_second": 23.063}, {"test_loss": 0.497185617685318, "test_mcc": 0.6215720018655735, "test_macro_f1": 0.8055765517092204, "test_runtime": 2.9985, "test_samples_per_second": 683.012, "test_steps_per_second": 21.344}, {"test_loss": 0.5037530064582825, "test_mcc": 0.5550452153939812, "test_macro_f1": 0.7763864505544078, "test_runtime": 2.7099, "test_samples_per_second": 755.747, "test_steps_per_second": 23.617}, {"test_loss": 0.45943954586982727, "test_mcc": 0.6080987267497464, "test_macro_f1": 0.800570833753064, "test_runtime": 2.7903, "test_samples_per_second": 733.97, "test_steps_per_second": 22.937}, {"test_loss": 0.5307962894439697, "test_mcc": 0.5689682250037352, "test_macro_f1": 0.7639021315893035, "test_runtime": 2.6637, "test_samples_per_second": 768.844, "test_steps_per_second": 24.026}, {"test_loss": 0.519232988357544, "test_mcc": 0.5788842890565244, "test_macro_f1": 0.7756362737830491, "test_runtime": 2.7431, "test_samples_per_second": 746.595, "test_steps_per_second": 23.331}]}, "total": {"test_mcc": 59.435849016226896, "test_mcc_se": 1.4667053070903617, "test_macro_f1": 78.79930140975674, "test_macro_f1_se": 0.9975531478556338}}, "num_model_parameters": 470928386, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_loss": 0.556105375289917, "test_mcc": 0.48562355502579674, "test_macro_f1": 0.7270290416693406, "test_runtime": 2.9388, "test_samples_per_second": 696.876, "test_steps_per_second": 21.777}, {"test_loss": 0.6086559891700745, "test_mcc": 0.4610289701564914, "test_macro_f1": 0.7091636494647253, "test_runtime": 3.0248, "test_samples_per_second": 677.065, "test_steps_per_second": 21.158}, {"test_loss": 0.5659254193305969, "test_mcc": 0.4672793898522141, "test_macro_f1": 0.7226253081188594, "test_runtime": 2.9843, "test_samples_per_second": 686.252, "test_steps_per_second": 21.445}, {"test_loss": 0.5294291377067566, "test_mcc": 0.5234721879293563, "test_macro_f1": 0.7586206896551724, "test_runtime": 2.82, "test_samples_per_second": 726.248, "test_steps_per_second": 22.695}, {"test_loss": 0.5251428484916687, "test_mcc": 0.5133113496661715, "test_macro_f1": 0.7559120319890639, "test_runtime": 2.882, "test_samples_per_second": 710.607, "test_steps_per_second": 22.206}, {"test_loss": 0.5347574353218079, "test_mcc": 0.5043759305867732, "test_macro_f1": 0.7518990251096512, "test_runtime": 2.9921, "test_samples_per_second": 684.46, "test_steps_per_second": 21.389}, {"test_loss": 0.5883792638778687, "test_mcc": 0.4872980846717755, "test_macro_f1": 0.743634679418171, "test_runtime": 2.8531, "test_samples_per_second": 717.817, "test_steps_per_second": 22.432}, {"test_loss": 0.5789304971694946, "test_mcc": 0.4953838764456102, "test_macro_f1": 0.7397576373975472, "test_runtime": 2.8298, "test_samples_per_second": 723.717, "test_steps_per_second": 22.616}, {"test_loss": 0.5565324425697327, "test_mcc": 0.4714598118239107, "test_macro_f1": 0.7352179816363198, "test_runtime": 2.8255, "test_samples_per_second": 724.824, "test_steps_per_second": 22.651}, {"test_loss": 0.5322972536087036, "test_mcc": 0.5210139409207544, "test_macro_f1": 0.758605125846282, "test_runtime": 2.9321, "test_samples_per_second": 698.477, "test_steps_per_second": 21.827}]}, "total": {"test_mcc": 49.30247097078855, "test_mcc_se": 1.3852476508972735, "test_macro_f1": 74.02465170305132, "test_macro_f1_se": 1.0421017230746958}}, "num_model_parameters": 470928386, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_em": 49.57397366382649, "test_f1": 53.69796158136606}, {"test_em": 48.372093023255815, "test_f1": 52.82501689037436}, {"test_em": 48.145285935085006, "test_f1": 52.58629682731635}, {"test_em": 47.66355140186916, "test_f1": 52.134236490771485}, {"test_em": 47.49034749034749, "test_f1": 52.602875317382164}, {"test_em": 46.491904394757135, "test_f1": 51.200756211424675}, {"test_em": 36.75018982536067, "test_f1": 41.838007682551826}, {"test_em": 50.50426687354538, "test_f1": 55.3535940752433}, {"test_em": 46.19607843137255, "test_f1": 51.31167174803037}, {"test_em": 44.254658385093165, "test_f1": 48.123931451205785}]}, "total": {"test_em": 46.54423494245128, "test_em_se": 2.393403800231716, "test_f1": 51.16743482756664, "test_f1_se": 2.3374955186789483}}, "num_model_parameters": 470337794, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_em": 53.98915569326104, "test_f1": 58.18444415113301}, {"test_em": 51.55038759689923, "test_f1": 56.04939450128083}, {"test_em": 47.68160741885626, "test_f1": 52.84559542755496}, {"test_em": 46.10591900311527, "test_f1": 50.89477048646939}, {"test_em": 50.5019305019305, "test_f1": 55.40846616742236}, {"test_em": 49.88434849653046, "test_f1": 54.9220327113608}, {"test_em": 47.380410022779046, "test_f1": 52.91407640933721}, {"test_em": 48.48719937936385, "test_f1": 53.96941702681134}, {"test_em": 48.549019607843135, "test_f1": 53.61869560715909}, {"test_em": 50.31055900621118, "test_f1": 55.383720890728895}]}, "total": {"test_em": 49.444053672679, "test_em_se": 1.422152710673248, "test_f1": 54.41906133792579, "test_f1_se": 1.2567581211133987}}, "num_model_parameters": 470337794, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_em": 52.13013168086754, "test_f1": 57.34245507370465}, {"test_em": 47.5968992248062, "test_f1": 53.17804141393186}, {"test_em": 51.777434312210204, "test_f1": 56.49198438823556}, {"test_em": 50.62305295950156, "test_f1": 55.43783440368698}, {"test_em": 51.50579150579151, "test_f1": 56.085937830491}, {"test_em": 52.35158057054742, "test_f1": 56.517724877126525}, {"test_em": 51.63249810174639, "test_f1": 57.31995027023931}, {"test_em": 50.73700543056633, "test_f1": 55.69853248538918}, {"test_em": 47.6078431372549, "test_f1": 52.768028885901586}, {"test_em": 44.56521739130435, "test_f1": 49.45473634947891}]}, "total": {"test_em": 50.05274543145965, "test_em_se": 1.6016243000452983, "test_f1": 55.02952259781856, "test_f1_se": 1.5502065027814456}}, "num_model_parameters": 470337794, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.36397793889045715, "test_mcc": 0.75648834881098, "test_macro_f1": 0.6885371348043917, "test_runtime": 28.9048, "test_samples_per_second": 70.853, "test_steps_per_second": 8.857}, {"test_loss": 0.3642803430557251, "test_mcc": 0.7631000705105653, "test_macro_f1": 0.7382602533521224, "test_runtime": 27.6473, "test_samples_per_second": 74.076, "test_steps_per_second": 9.26}, {"test_loss": 0.3420686721801758, "test_mcc": 0.7757984176292881, "test_macro_f1": 0.7597748305744322, "test_runtime": 27.6822, "test_samples_per_second": 73.983, "test_steps_per_second": 9.248}, {"test_loss": 0.32263287901878357, "test_mcc": 0.7900366373056203, "test_macro_f1": 0.7091183772847646, "test_runtime": 27.2999, "test_samples_per_second": 75.018, "test_steps_per_second": 9.377}, {"test_loss": 0.3383079767227173, "test_mcc": 0.7704184771029796, "test_macro_f1": 0.7384391483521721, "test_runtime": 26.6242, "test_samples_per_second": 76.922, "test_steps_per_second": 9.615}, {"test_loss": 0.327705979347229, "test_mcc": 0.803247495022191, "test_macro_f1": 0.7901122658661417, "test_runtime": 27.7294, "test_samples_per_second": 73.857, "test_steps_per_second": 9.232}, {"test_loss": 0.35441917181015015, "test_mcc": 0.7928725269825374, "test_macro_f1": 0.7893568027439507, "test_runtime": 26.8769, "test_samples_per_second": 76.199, "test_steps_per_second": 9.525}, {"test_loss": 0.33791980147361755, "test_mcc": 0.7863606287694439, "test_macro_f1": 0.7573094980497476, "test_runtime": 28.646, "test_samples_per_second": 71.493, "test_steps_per_second": 8.937}, {"test_loss": 0.3505605459213257, "test_mcc": 0.7757414899478503, "test_macro_f1": 0.7364000120247506, "test_runtime": 28.2955, "test_samples_per_second": 72.379, "test_steps_per_second": 9.047}, {"test_loss": 0.33291685581207275, "test_mcc": 0.7860782066855653, "test_macro_f1": 0.7938129596129722, "test_runtime": 27.1453, "test_samples_per_second": 75.446, "test_steps_per_second": 9.431}]}, "total": {"test_mcc": 78.00142298767021, "test_mcc_se": 0.8886969820531024, "test_macro_f1": 75.01121282665444, "test_macro_f1_se": 2.1798046456785536}}, "num_model_parameters": 369557507, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.8871846199035645, "test_mcc": 0.4403871201587251, "test_macro_f1": 0.6285632263102292, "test_runtime": 10.6159, "test_samples_per_second": 192.918, "test_steps_per_second": 6.029}, {"test_loss": 0.926957368850708, "test_mcc": 0.4217322918672366, "test_macro_f1": 0.6053138877754597, "test_runtime": 10.4198, "test_samples_per_second": 196.549, "test_steps_per_second": 6.142}, {"test_loss": 0.9644876718521118, "test_mcc": 0.36411504319884974, "test_macro_f1": 0.5766063349297776, "test_runtime": 10.496, "test_samples_per_second": 195.121, "test_steps_per_second": 6.098}, {"test_loss": 0.9184226989746094, "test_mcc": 0.44814947904297664, "test_macro_f1": 0.6324246207399434, "test_runtime": 10.5036, "test_samples_per_second": 194.98, "test_steps_per_second": 6.093}, {"test_loss": 0.9316778182983398, "test_mcc": 0.4105635624580694, "test_macro_f1": 0.6089748694156779, "test_runtime": 10.4951, "test_samples_per_second": 195.139, "test_steps_per_second": 6.098}, {"test_loss": 0.9668661952018738, "test_mcc": 0.40565359446651417, "test_macro_f1": 0.6050467709111652, "test_runtime": 10.6083, "test_samples_per_second": 193.056, "test_steps_per_second": 6.033}, {"test_loss": 0.892956554889679, "test_mcc": 0.40331739478199374, "test_macro_f1": 0.5963941789733643, "test_runtime": 10.5039, "test_samples_per_second": 194.976, "test_steps_per_second": 6.093}, {"test_loss": 1.0182231664657593, "test_mcc": 0.38166478836593926, "test_macro_f1": 0.5487580375103578, "test_runtime": 10.5054, "test_samples_per_second": 194.947, "test_steps_per_second": 6.092}, {"test_loss": 0.9741840362548828, "test_mcc": 0.4334072592099229, "test_macro_f1": 0.6144215138213626, "test_runtime": 10.3346, "test_samples_per_second": 198.17, "test_steps_per_second": 6.193}, {"test_loss": 0.9356030821800232, "test_mcc": 0.39310029350327763, "test_macro_f1": 0.5968444238895346, "test_runtime": 10.3642, "test_samples_per_second": 197.603, "test_steps_per_second": 6.175}]}, "total": {"test_mcc": 41.020908270535045, "test_mcc_se": 1.6426687564971727, "test_macro_f1": 60.13347864276872, "test_macro_f1_se": 1.5164646244472673}}, "num_model_parameters": 369557507, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.8374572992324829, "test_mcc": 0.39838019350303544, "test_macro_f1": 0.4636662444883048, "test_runtime": 8.5697, "test_samples_per_second": 238.981, "test_steps_per_second": 7.468}, {"test_loss": 0.8337740302085876, "test_mcc": 0.39077746359942434, "test_macro_f1": 0.5312822791297488, "test_runtime": 8.2982, "test_samples_per_second": 246.801, "test_steps_per_second": 7.713}, {"test_loss": 0.805956244468689, "test_mcc": 0.404916258319191, "test_macro_f1": 0.5553131032905031, "test_runtime": 8.1906, "test_samples_per_second": 250.044, "test_steps_per_second": 7.814}, {"test_loss": 0.8541359305381775, "test_mcc": 0.37386719413111397, "test_macro_f1": 0.4678807975107558, "test_runtime": 8.1985, "test_samples_per_second": 249.802, "test_steps_per_second": 7.806}, {"test_loss": 0.83487468957901, "test_mcc": 0.38138031519895416, "test_macro_f1": 0.5049987427915964, "test_runtime": 8.5002, "test_samples_per_second": 240.937, "test_steps_per_second": 7.529}, {"test_loss": 0.8452868461608887, "test_mcc": 0.3766877544221019, "test_macro_f1": 0.4731166377003926, "test_runtime": 8.4985, "test_samples_per_second": 240.985, "test_steps_per_second": 7.531}, {"test_loss": 0.8110982775688171, "test_mcc": 0.4175862931821305, "test_macro_f1": 0.53322785324247, "test_runtime": 8.4606, "test_samples_per_second": 242.064, "test_steps_per_second": 7.565}, {"test_loss": 0.8392766714096069, "test_mcc": 0.41088401469864516, "test_macro_f1": 0.5594238420615548, "test_runtime": 8.3157, "test_samples_per_second": 246.283, "test_steps_per_second": 7.696}, {"test_loss": 0.8112209439277649, "test_mcc": 0.4132439812784369, "test_macro_f1": 0.4947560863695879, "test_runtime": 8.53, "test_samples_per_second": 240.093, "test_steps_per_second": 7.503}, {"test_loss": 0.8489441871643066, "test_mcc": 0.38522481228800215, "test_macro_f1": 0.5063039493852024, "test_runtime": 8.7395, "test_samples_per_second": 234.339, "test_steps_per_second": 7.323}]}, "total": {"test_mcc": 39.52948280621035, "test_mcc_se": 0.9875901745737405, "test_macro_f1": 50.899695359701155, "test_macro_f1_se": 2.169881000417274}}, "num_model_parameters": 369557507, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.04628734663128853, "test_micro_f1": 0.7384926656550329, "test_micro_f1_no_misc": 0.7919621749408982, "test_runtime": 12.6676, "test_samples_per_second": 161.673, "test_steps_per_second": 5.052}, {"test_loss": 0.04272636026144028, "test_micro_f1": 0.7607296137339056, "test_micro_f1_no_misc": 0.8123861566484517, "test_runtime": 12.2288, "test_samples_per_second": 167.474, "test_steps_per_second": 5.234}, {"test_loss": 0.04224998131394386, "test_micro_f1": 0.7654802535348609, "test_micro_f1_no_misc": 0.8052373158756138, "test_runtime": 12.5377, "test_samples_per_second": 163.348, "test_steps_per_second": 5.105}, {"test_loss": 0.042582716792821884, "test_micro_f1": 0.7472100921882581, "test_micro_f1_no_misc": 0.8043230944254836, "test_runtime": 12.7612, "test_samples_per_second": 160.486, "test_steps_per_second": 5.015}, {"test_loss": 0.0471489354968071, "test_micro_f1": 0.7453237410071942, "test_micro_f1_no_misc": 0.7924324324324324, "test_runtime": 12.5466, "test_samples_per_second": 163.231, "test_steps_per_second": 5.101}, {"test_loss": 0.044103674590587616, "test_micro_f1": 0.7638190954773869, "test_micro_f1_no_misc": 0.8119978575254418, "test_runtime": 10.8353, "test_samples_per_second": 189.012, "test_steps_per_second": 5.907}, {"test_loss": 0.047823771834373474, "test_micro_f1": 0.7866732968672302, "test_micro_f1_no_misc": 0.827313769751693, "test_runtime": 11.3456, "test_samples_per_second": 180.511, "test_steps_per_second": 5.641}, {"test_loss": 0.04623258858919144, "test_micro_f1": 0.7347803070407624, "test_micro_f1_no_misc": 0.7801932367149759, "test_runtime": 12.4918, "test_samples_per_second": 163.947, "test_steps_per_second": 5.123}, {"test_loss": 0.04148184135556221, "test_micro_f1": 0.7534441805225653, "test_micro_f1_no_misc": 0.8222222222222223, "test_runtime": 11.9881, "test_samples_per_second": 170.837, "test_steps_per_second": 5.339}, {"test_loss": 0.045993223786354065, "test_micro_f1": 0.8116370808678502, "test_micro_f1_no_misc": 0.8566572237960342, "test_runtime": 12.7144, "test_samples_per_second": 161.077, "test_steps_per_second": 5.034}]}, "total": {"test_micro_f1": 76.07590326895048, "test_micro_f1_se": 1.451781644847572, "test_micro_f1_no_misc": 81.04725484333247, "test_micro_f1_no_misc_se": 1.340660718505403}}, "num_model_parameters": 368514057, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.06294388324022293, "test_micro_f1": 0.7714570858283434, "test_micro_f1_no_misc": 0.7925549915397632, "test_runtime": 18.0326, "test_samples_per_second": 113.572, "test_steps_per_second": 3.549}, {"test_loss": 0.06640183925628662, "test_micro_f1": 0.7825154196835613, "test_micro_f1_no_misc": 0.8161630870040044, "test_runtime": 14.8547, "test_samples_per_second": 137.869, "test_steps_per_second": 4.308}, {"test_loss": 0.06297235935926437, "test_micro_f1": 0.7777483443708609, "test_micro_f1_no_misc": 0.7968413496051686, "test_runtime": 18.119, "test_samples_per_second": 113.031, "test_steps_per_second": 3.532}, {"test_loss": 0.06604467332363129, "test_micro_f1": 0.782360570687419, "test_micro_f1_no_misc": 0.7963215258855586, "test_runtime": 17.3476, "test_samples_per_second": 118.057, "test_steps_per_second": 3.689}, {"test_loss": 0.07329890877008438, "test_micro_f1": 0.7347838061140182, "test_micro_f1_no_misc": 0.7647498132935027, "test_runtime": 18.4106, "test_samples_per_second": 111.24, "test_steps_per_second": 3.476}, {"test_loss": 0.06720372289419174, "test_micro_f1": 0.7897806164954179, "test_micro_f1_no_misc": 0.8059369202226346, "test_runtime": 17.9553, "test_samples_per_second": 114.061, "test_steps_per_second": 3.564}, {"test_loss": 0.06573764979839325, "test_micro_f1": 0.8008553862603582, "test_micro_f1_no_misc": 0.8148672566371681, "test_runtime": 18.5872, "test_samples_per_second": 110.183, "test_steps_per_second": 3.443}, {"test_loss": 0.062190063297748566, "test_micro_f1": 0.7862869781586951, "test_micro_f1_no_misc": 0.8157894736842105, "test_runtime": 18.3209, "test_samples_per_second": 111.785, "test_steps_per_second": 3.493}, {"test_loss": 0.08155903220176697, "test_micro_f1": 0.7361148020196653, "test_micro_f1_no_misc": 0.7596843615494978, "test_runtime": 17.0267, "test_samples_per_second": 120.282, "test_steps_per_second": 3.759}, {"test_loss": 0.0681605190038681, "test_micro_f1": 0.7789418543740179, "test_micro_f1_no_misc": 0.812068338785896, "test_runtime": 16.2466, "test_samples_per_second": 126.057, "test_steps_per_second": 3.939}]}, "total": {"test_micro_f1": 77.40844863992358, "test_micro_f1_se": 1.3518927204745932, "test_micro_f1_no_misc": 79.74977118207404, "test_micro_f1_no_misc_se": 1.2730327503663772}}, "num_model_parameters": 368514057, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.04823543131351471, "test_micro_f1": 0.802735781137509, "test_micro_f1_no_misc": 0.8366013071895426, "test_runtime": 13.9307, "test_samples_per_second": 147.013, "test_steps_per_second": 4.594}, {"test_loss": 0.04166388511657715, "test_micro_f1": 0.8302163549688303, "test_micro_f1_no_misc": 0.8564376799670917, "test_runtime": 14.0796, "test_samples_per_second": 145.458, "test_steps_per_second": 4.546}, {"test_loss": 0.04633758217096329, "test_micro_f1": 0.8389619623178102, "test_micro_f1_no_misc": 0.8730600875447672, "test_runtime": 13.5222, "test_samples_per_second": 151.454, "test_steps_per_second": 4.733}, {"test_loss": 0.04581701010465622, "test_micro_f1": 0.8374384236453202, "test_micro_f1_no_misc": 0.8609375, "test_runtime": 13.3407, "test_samples_per_second": 153.515, "test_steps_per_second": 4.797}, {"test_loss": 0.042554453015327454, "test_micro_f1": 0.8488724335240658, "test_micro_f1_no_misc": 0.8762190547636909, "test_runtime": 14.1077, "test_samples_per_second": 145.169, "test_steps_per_second": 4.537}, {"test_loss": 0.045450542122125626, "test_micro_f1": 0.8361923982509251, "test_micro_f1_no_misc": 0.8610800744878957, "test_runtime": 14.0178, "test_samples_per_second": 146.1, "test_steps_per_second": 4.566}, {"test_loss": 0.040750473737716675, "test_micro_f1": 0.8529005524861878, "test_micro_f1_no_misc": 0.8801225584067408, "test_runtime": 13.2405, "test_samples_per_second": 154.677, "test_steps_per_second": 4.834}, {"test_loss": 0.049047961831092834, "test_micro_f1": 0.8228064185728918, "test_micro_f1_no_misc": 0.8508449669360765, "test_runtime": 13.1735, "test_samples_per_second": 155.463, "test_steps_per_second": 4.858}, {"test_loss": 0.0441073514521122, "test_micro_f1": 0.8180839612486543, "test_micro_f1_no_misc": 0.8535394629780308, "test_runtime": 13.326, "test_samples_per_second": 153.684, "test_steps_per_second": 4.803}, {"test_loss": 0.05224005877971649, "test_micro_f1": 0.8205128205128205, "test_micro_f1_no_misc": 0.850352766431489, "test_runtime": 13.3261, "test_samples_per_second": 153.683, "test_steps_per_second": 4.803}]}, "total": {"test_micro_f1": 83.08721106665014, "test_micro_f1_se": 0.940918318419189, "test_micro_f1_no_misc": 85.99195458705327, "test_micro_f1_no_misc_se": 0.8313863571072679}}, "num_model_parameters": 368514057, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.06576177477836609, "test_micro_f1": 0.7174447174447174, "test_micro_f1_no_misc": 0.7622540846948982, "test_runtime": 13.1413, "test_samples_per_second": 155.844, "test_steps_per_second": 4.87}, {"test_loss": 0.06221150979399681, "test_micro_f1": 0.7675610491407898, "test_micro_f1_no_misc": 0.796916890080429, "test_runtime": 13.0929, "test_samples_per_second": 156.421, "test_steps_per_second": 4.888}, {"test_loss": 0.06159721687436104, "test_micro_f1": 0.7614761476147615, "test_micro_f1_no_misc": 0.796957671957672, "test_runtime": 12.5842, "test_samples_per_second": 162.743, "test_steps_per_second": 5.086}, {"test_loss": 0.06562440097332001, "test_micro_f1": 0.7547396930484502, "test_micro_f1_no_misc": 0.7905111927831607, "test_runtime": 12.9659, "test_samples_per_second": 157.953, "test_steps_per_second": 4.936}, {"test_loss": 0.06174217537045479, "test_micro_f1": 0.7562669888251284, "test_micro_f1_no_misc": 0.8024776324845149, "test_runtime": 12.4261, "test_samples_per_second": 164.814, "test_steps_per_second": 5.15}, {"test_loss": 0.06581846624612808, "test_micro_f1": 0.7382789317507418, "test_micro_f1_no_misc": 0.7784313725490196, "test_runtime": 12.4695, "test_samples_per_second": 164.24, "test_steps_per_second": 5.133}, {"test_loss": 0.06282803416252136, "test_micro_f1": 0.7793398533007335, "test_micro_f1_no_misc": 0.8166042871725075, "test_runtime": 13.0824, "test_samples_per_second": 156.546, "test_steps_per_second": 4.892}, {"test_loss": 0.05766395479440689, "test_micro_f1": 0.7928703134603564, "test_micro_f1_no_misc": 0.8249828414550446, "test_runtime": 13.1361, "test_samples_per_second": 155.906, "test_steps_per_second": 4.872}, {"test_loss": 0.06755472719669342, "test_micro_f1": 0.7560975609756097, "test_micro_f1_no_misc": 0.7982155113246397, "test_runtime": 12.4393, "test_samples_per_second": 164.64, "test_steps_per_second": 5.145}, {"test_loss": 0.06435370445251465, "test_micro_f1": 0.7369696969696969, "test_micro_f1_no_misc": 0.7800261096605744, "test_runtime": 12.526, "test_samples_per_second": 163.499, "test_steps_per_second": 5.109}]}, "total": {"test_micro_f1": 75.61044952530985, "test_micro_f1_se": 1.344037565986681, "test_micro_f1_no_misc": 79.47377594162461, "test_micro_f1_no_misc_se": 1.137245028017527}}, "num_model_parameters": 368514057, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.3304181694984436, "test_mcc": 0.7530720122026923, "test_macro_f1": 0.8686112236211772, "test_runtime": 6.2485, "test_samples_per_second": 327.76, "test_steps_per_second": 10.242}, {"test_loss": 0.2950146198272705, "test_mcc": 0.8032086932750634, "test_macro_f1": 0.8981749200667004, "test_runtime": 6.3803, "test_samples_per_second": 320.988, "test_steps_per_second": 10.031}, {"test_loss": 0.3282589316368103, "test_mcc": 0.775242626070078, "test_macro_f1": 0.8768743968231367, "test_runtime": 6.3812, "test_samples_per_second": 320.94, "test_steps_per_second": 10.029}, {"test_loss": 0.33431029319763184, "test_mcc": 0.7668152113208975, "test_macro_f1": 0.8764248552095129, "test_runtime": 6.3059, "test_samples_per_second": 324.775, "test_steps_per_second": 10.149}, {"test_loss": 0.29900994896888733, "test_mcc": 0.7958230070704484, "test_macro_f1": 0.8927627129065978, "test_runtime": 6.4067, "test_samples_per_second": 319.664, "test_steps_per_second": 9.99}, {"test_loss": 0.3403007984161377, "test_mcc": 0.7667844834710061, "test_macro_f1": 0.8737473174001995, "test_runtime": 6.4701, "test_samples_per_second": 316.531, "test_steps_per_second": 9.892}, {"test_loss": 0.37037163972854614, "test_mcc": 0.7035160814183369, "test_macro_f1": 0.8354113054209857, "test_runtime": 6.4771, "test_samples_per_second": 316.191, "test_steps_per_second": 9.881}, {"test_loss": 0.3257352113723755, "test_mcc": 0.7620768192630512, "test_macro_f1": 0.872604972669603, "test_runtime": 6.4537, "test_samples_per_second": 317.338, "test_steps_per_second": 9.917}, {"test_loss": 0.30855292081832886, "test_mcc": 0.7673814069069562, "test_macro_f1": 0.875997445882402, "test_runtime": 6.4836, "test_samples_per_second": 315.875, "test_steps_per_second": 9.871}, {"test_loss": 0.2847570776939392, "test_mcc": 0.7847877224259756, "test_macro_f1": 0.8888335987975082, "test_runtime": 6.433, "test_samples_per_second": 318.36, "test_steps_per_second": 9.949}]}, "total": {"test_mcc": 76.78708063424506, "test_mcc_se": 1.6995781561520322, "test_macro_f1": 87.59442748797824, "test_macro_f1_se": 1.0649469291753313}}, "num_model_parameters": 369556482, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.6435476541519165, "test_mcc": 0.2715123933646485, "test_macro_f1": 0.6209424262984493, "test_runtime": 9.0897, "test_samples_per_second": 225.311, "test_steps_per_second": 7.041}, {"test_loss": 0.6295243501663208, "test_mcc": 0.35615378572007517, "test_macro_f1": 0.6641784980439047, "test_runtime": 9.479, "test_samples_per_second": 216.056, "test_steps_per_second": 6.752}, {"test_loss": 0.6361004114151001, "test_mcc": 0.260846512706386, "test_macro_f1": 0.6268436816654959, "test_runtime": 9.2677, "test_samples_per_second": 220.983, "test_steps_per_second": 6.906}, {"test_loss": 0.6749860048294067, "test_mcc": 0.15558745599231802, "test_macro_f1": 0.5453371221906484, "test_runtime": 9.936, "test_samples_per_second": 206.12, "test_steps_per_second": 6.441}, {"test_loss": 0.6576968431472778, "test_mcc": 0.2602806721258685, "test_macro_f1": 0.5913934504694143, "test_runtime": 9.3061, "test_samples_per_second": 220.071, "test_steps_per_second": 6.877}, {"test_loss": 0.6429619193077087, "test_mcc": 0.30344688376102263, "test_macro_f1": 0.6140465640314245, "test_runtime": 9.2962, "test_samples_per_second": 220.306, "test_steps_per_second": 6.885}, {"test_loss": 0.6701751947402954, "test_mcc": 0.20937256424620274, "test_macro_f1": 0.5452139629596022, "test_runtime": 9.0599, "test_samples_per_second": 226.051, "test_steps_per_second": 7.064}, {"test_loss": 0.6424070596694946, "test_mcc": 0.32153567952972034, "test_macro_f1": 0.6371054441926329, "test_runtime": 9.2345, "test_samples_per_second": 221.778, "test_steps_per_second": 6.931}, {"test_loss": 0.6607750654220581, "test_mcc": 0.25789119299653357, "test_macro_f1": 0.6247361965306206, "test_runtime": 9.3063, "test_samples_per_second": 220.065, "test_steps_per_second": 6.877}, {"test_loss": 0.6343151330947876, "test_mcc": 0.3134993581806087, "test_macro_f1": 0.632840506266684, "test_runtime": 9.5219, "test_samples_per_second": 215.083, "test_steps_per_second": 6.721}]}, "total": {"test_mcc": 27.101264986233844, "test_mcc_se": 3.5887043391834204, "test_macro_f1": 61.02637852648878, "test_macro_f1_se": 2.4051813525397208}}, "num_model_parameters": 369556482, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.6331095099449158, "test_mcc": 0.30662157947507385, "test_macro_f1": 0.6439588723420182, "test_runtime": 8.1574, "test_samples_per_second": 251.061, "test_steps_per_second": 7.846}, {"test_loss": 0.6651097536087036, "test_mcc": 0.28462440052270027, "test_macro_f1": 0.5765230261920422, "test_runtime": 8.4402, "test_samples_per_second": 242.648, "test_steps_per_second": 7.583}, {"test_loss": 0.6663562059402466, "test_mcc": 0.2093020557942333, "test_macro_f1": 0.6008586766176854, "test_runtime": 8.1962, "test_samples_per_second": 249.873, "test_steps_per_second": 7.809}, {"test_loss": 0.6328203082084656, "test_mcc": 0.27162002604232666, "test_macro_f1": 0.6348363966634001, "test_runtime": 8.6213, "test_samples_per_second": 237.55, "test_steps_per_second": 7.423}, {"test_loss": 0.6803508996963501, "test_mcc": 0.305964797065859, "test_macro_f1": 0.6141945754192879, "test_runtime": 8.2887, "test_samples_per_second": 247.084, "test_steps_per_second": 7.721}, {"test_loss": 0.6213598251342773, "test_mcc": 0.31617059816314735, "test_macro_f1": 0.6405602009870162, "test_runtime": 8.1697, "test_samples_per_second": 250.684, "test_steps_per_second": 7.834}, {"test_loss": 0.642636775970459, "test_mcc": 0.278361793958673, "test_macro_f1": 0.6347516301335119, "test_runtime": 8.3097, "test_samples_per_second": 246.46, "test_steps_per_second": 7.702}, {"test_loss": 0.6505048274993896, "test_mcc": 0.3003067217366347, "test_macro_f1": 0.5975092575353235, "test_runtime": 8.0531, "test_samples_per_second": 254.312, "test_steps_per_second": 7.947}, {"test_loss": 0.674746036529541, "test_mcc": 0.20019033287661198, "test_macro_f1": 0.5270351542094908, "test_runtime": 8.0596, "test_samples_per_second": 254.108, "test_steps_per_second": 7.941}, {"test_loss": 0.6492588520050049, "test_mcc": 0.2658266902604207, "test_macro_f1": 0.632606954499863, "test_runtime": 8.2136, "test_samples_per_second": 249.342, "test_steps_per_second": 7.792}]}, "total": {"test_mcc": 27.389889958956804, "test_mcc_se": 2.4787330446470945, "test_macro_f1": 61.02834744599639, "test_macro_f1_se": 2.2714908782537133}}, "num_model_parameters": 369556482, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_loss": 0.6662812829017639, "test_mcc": 0.19052390940907046, "test_macro_f1": 0.584397490740816, "test_runtime": 8.5685, "test_samples_per_second": 239.014, "test_steps_per_second": 7.469}, {"test_loss": 0.6518527269363403, "test_mcc": 0.28614178440270227, "test_macro_f1": 0.6120776314049439, "test_runtime": 8.7124, "test_samples_per_second": 235.066, "test_steps_per_second": 7.346}, {"test_loss": 0.6576693654060364, "test_mcc": 0.24904768278142556, "test_macro_f1": 0.5978886253600768, "test_runtime": 8.9117, "test_samples_per_second": 229.811, "test_steps_per_second": 7.182}, {"test_loss": 0.6408601999282837, "test_mcc": 0.2901258727381242, "test_macro_f1": 0.6366050011500674, "test_runtime": 8.2662, "test_samples_per_second": 247.756, "test_steps_per_second": 7.742}, {"test_loss": 0.648722231388092, "test_mcc": 0.2367107383117906, "test_macro_f1": 0.5967190898506669, "test_runtime": 8.5375, "test_samples_per_second": 239.882, "test_steps_per_second": 7.496}, {"test_loss": 0.6568772792816162, "test_mcc": 0.25473111569978524, "test_macro_f1": 0.60568156173413, "test_runtime": 8.763, "test_samples_per_second": 233.71, "test_steps_per_second": 7.303}, {"test_loss": 0.6727008819580078, "test_mcc": 0.18106778293550524, "test_macro_f1": 0.5894914076489296, "test_runtime": 8.4169, "test_samples_per_second": 243.32, "test_steps_per_second": 7.604}, {"test_loss": 0.6563899517059326, "test_mcc": 0.21634087530662685, "test_macro_f1": 0.5744818237640816, "test_runtime": 8.5635, "test_samples_per_second": 239.154, "test_steps_per_second": 7.474}, {"test_loss": 0.6505526900291443, "test_mcc": 0.23029688424590228, "test_macro_f1": 0.6028080733963087, "test_runtime": 8.4952, "test_samples_per_second": 241.078, "test_steps_per_second": 7.534}, {"test_loss": 0.6663151383399963, "test_mcc": 0.2211973802320256, "test_macro_f1": 0.6053045636851587, "test_runtime": 8.6811, "test_samples_per_second": 235.914, "test_steps_per_second": 7.372}]}, "total": {"test_mcc": 23.561840260629584, "test_mcc_se": 2.2335690327527837, "test_macro_f1": 60.0545526873518, "test_macro_f1_se": 1.0476565185475637}}, "num_model_parameters": 369556482, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_em": 48.17970565453137, "test_f1": 53.51114721123198}, {"test_em": 48.44961240310077, "test_f1": 54.060387881865296}, {"test_em": 43.81761978361669, "test_f1": 49.50325876000937}, {"test_em": 47.429906542056074, "test_f1": 52.85438584934402}, {"test_em": 50.965250965250966, "test_f1": 56.078380221237325}, {"test_em": 46.491904394757135, "test_f1": 51.642173525771284}, {"test_em": 46.84889901290813, "test_f1": 52.49031446070169}, {"test_em": 46.23739332816137, "test_f1": 52.41018426086409}, {"test_em": 46.8235294117647, "test_f1": 52.36866488631192}, {"test_em": 43.32298136645963, "test_f1": 49.20751694820015}]}, "total": {"test_em": 46.856680286260676, "test_em_se": 1.3663482934177231, "test_f1": 52.41264140055372, "test_f1_se": 1.2549015826142573}}, "num_model_parameters": 368506882, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_em": 48.876839659178934, "test_f1": 54.37340462894844}, {"test_em": 45.42635658914729, "test_f1": 50.946521457465344}, {"test_em": 46.908809891808346, "test_f1": 52.675315385789034}, {"test_em": 47.35202492211838, "test_f1": 52.61434707352793}, {"test_em": 46.56370656370656, "test_f1": 52.203700632272046}, {"test_em": 49.26754047802621, "test_f1": 54.545717408659016}, {"test_em": 46.69703872437358, "test_f1": 53.46146090327525}, {"test_em": 48.56477889837083, "test_f1": 53.628558707096545}, {"test_em": 48.94117647058823, "test_f1": 53.8507316648493}, {"test_em": 49.767080745341616, "test_f1": 56.186399811827656}]}, "total": {"test_em": 47.836535294266, "test_em_se": 0.8869590662354014, "test_f1": 53.44861576737107, "test_f1_se": 0.897063946836347}}, "num_model_parameters": 368506882, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_em": 52.285050348567005, "test_f1": 58.55506082188541}, {"test_em": 54.263565891472865, "test_f1": 59.93761892462301}, {"test_em": 52.47295208655332, "test_f1": 58.31838131865406}, {"test_em": 55.76323987538941, "test_f1": 60.456200466436}, {"test_em": 54.054054054054056, "test_f1": 59.91989241989238}, {"test_em": 52.197378565921355, "test_f1": 58.13004741034651}, {"test_em": 53.83447228549734, "test_f1": 59.35375151559433}, {"test_em": 53.45228859581071, "test_f1": 58.86695435841936}, {"test_em": 54.03921568627451, "test_f1": 60.149943226067755}, {"test_em": 53.41614906832298, "test_f1": 59.31716415663252}]}, "total": {"test_em": 53.57783664578636, "test_em_se": 0.6723737509294944, "test_f1": 59.30050146185514, "test_f1_se": 0.5030257695131011}}, "num_model_parameters": 368506882, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.3360247015953064, "test_mcc": 0.7876053942665454, "test_macro_f1": 0.7782065863601866, "test_runtime": 28.94, "test_samples_per_second": 70.767, "test_steps_per_second": 8.846}, {"test_loss": 0.365003764629364, "test_mcc": 0.7492550511953189, "test_macro_f1": 0.755366656214378, "test_runtime": 27.5527, "test_samples_per_second": 74.33, "test_steps_per_second": 9.291}, {"test_loss": 0.3439939320087433, "test_mcc": 0.7822974940165943, "test_macro_f1": 0.7611112926081774, "test_runtime": 27.7384, "test_samples_per_second": 73.833, "test_steps_per_second": 9.229}, {"test_loss": 0.3203432261943817, "test_mcc": 0.789846894742964, "test_macro_f1": 0.757918477495921, "test_runtime": 26.9443, "test_samples_per_second": 76.009, "test_steps_per_second": 9.501}, {"test_loss": 0.34189116954803467, "test_mcc": 0.7792076992113055, "test_macro_f1": 0.7667361675637955, "test_runtime": 26.2239, "test_samples_per_second": 78.097, "test_steps_per_second": 9.762}, {"test_loss": 0.3936038315296173, "test_mcc": 0.757693922489629, "test_macro_f1": 0.664434606972947, "test_runtime": 27.7259, "test_samples_per_second": 73.866, "test_steps_per_second": 9.233}, {"test_loss": 0.35171419382095337, "test_mcc": 0.7825183326531727, "test_macro_f1": 0.7858331775126102, "test_runtime": 26.9452, "test_samples_per_second": 76.006, "test_steps_per_second": 9.501}, {"test_loss": 0.37631189823150635, "test_mcc": 0.7700221323108102, "test_macro_f1": 0.7586602806821547, "test_runtime": 28.4632, "test_samples_per_second": 71.953, "test_steps_per_second": 8.994}, {"test_loss": 0.34264785051345825, "test_mcc": 0.7715414035600957, "test_macro_f1": 0.7690725185744721, "test_runtime": 27.6895, "test_samples_per_second": 73.963, "test_steps_per_second": 9.245}, {"test_loss": 0.3292694091796875, "test_mcc": 0.7773264982390141, "test_macro_f1": 0.7801365413454245, "test_runtime": 27.8382, "test_samples_per_second": 73.568, "test_steps_per_second": 9.196}]}, "total": {"test_mcc": 77.47314822685449, "test_mcc_se": 0.8029743267323549, "test_macro_f1": 75.77476305330066, "test_macro_f1_se": 2.13139351485218}}, "num_model_parameters": 335218691, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.9125361442565918, "test_mcc": 0.3660089390832198, "test_macro_f1": 0.5689453985292153, "test_runtime": 10.4409, "test_samples_per_second": 196.152, "test_steps_per_second": 6.13}, {"test_loss": 0.8972197771072388, "test_mcc": 0.3841110299923707, "test_macro_f1": 0.5703107641835812, "test_runtime": 10.292, "test_samples_per_second": 198.99, "test_steps_per_second": 6.218}, {"test_loss": 0.9239338636398315, "test_mcc": 0.3693341795345019, "test_macro_f1": 0.5560466047453733, "test_runtime": 10.3193, "test_samples_per_second": 198.463, "test_steps_per_second": 6.202}, {"test_loss": 0.9188588857650757, "test_mcc": 0.409604831897782, "test_macro_f1": 0.5939969216245614, "test_runtime": 10.2977, "test_samples_per_second": 198.878, "test_steps_per_second": 6.215}, {"test_loss": 0.9430339336395264, "test_mcc": 0.3659933647265237, "test_macro_f1": 0.5749797421812627, "test_runtime": 10.2398, "test_samples_per_second": 200.005, "test_steps_per_second": 6.25}, {"test_loss": 0.973961353302002, "test_mcc": 0.3631690035614772, "test_macro_f1": 0.5755901788830574, "test_runtime": 10.283, "test_samples_per_second": 199.163, "test_steps_per_second": 6.224}, {"test_loss": 0.8980293273925781, "test_mcc": 0.3841800418365193, "test_macro_f1": 0.5825334921822035, "test_runtime": 10.4722, "test_samples_per_second": 195.565, "test_steps_per_second": 6.111}, {"test_loss": 0.9146277904510498, "test_mcc": 0.3892059755433367, "test_macro_f1": 0.5905771162022183, "test_runtime": 10.5162, "test_samples_per_second": 194.747, "test_steps_per_second": 6.086}, {"test_loss": 0.9151780605316162, "test_mcc": 0.4156617428809931, "test_macro_f1": 0.6068706755238703, "test_runtime": 10.2762, "test_samples_per_second": 199.295, "test_steps_per_second": 6.228}, {"test_loss": 0.9706696271896362, "test_mcc": 0.39913931879490827, "test_macro_f1": 0.596186233602933, "test_runtime": 10.2936, "test_samples_per_second": 198.958, "test_steps_per_second": 6.217}]}, "total": {"test_mcc": 38.464084278516324, "test_mcc_se": 1.1700407238337147, "test_macro_f1": 58.160371276582765, "test_macro_f1_se": 0.9483502661394015}}, "num_model_parameters": 335218691, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.8504704236984253, "test_mcc": 0.37720902530852, "test_macro_f1": 0.5407505692998015, "test_runtime": 8.7593, "test_samples_per_second": 233.809, "test_steps_per_second": 7.307}, {"test_loss": 0.8386313915252686, "test_mcc": 0.38295314116242185, "test_macro_f1": 0.5448902828025829, "test_runtime": 8.3116, "test_samples_per_second": 246.401, "test_steps_per_second": 7.7}, {"test_loss": 0.8376614451408386, "test_mcc": 0.4172104807392975, "test_macro_f1": 0.5772071060583491, "test_runtime": 8.0375, "test_samples_per_second": 254.805, "test_steps_per_second": 7.963}, {"test_loss": 0.8402997255325317, "test_mcc": 0.389905665097813, "test_macro_f1": 0.5329377285110223, "test_runtime": 8.3665, "test_samples_per_second": 244.787, "test_steps_per_second": 7.65}, {"test_loss": 0.9181473255157471, "test_mcc": 0.3769050370087893, "test_macro_f1": 0.5207519366332066, "test_runtime": 8.3692, "test_samples_per_second": 244.708, "test_steps_per_second": 7.647}, {"test_loss": 0.875821590423584, "test_mcc": 0.33248096898007745, "test_macro_f1": 0.46220934552067044, "test_runtime": 8.5052, "test_samples_per_second": 240.795, "test_steps_per_second": 7.525}, {"test_loss": 0.8202284574508667, "test_mcc": 0.4008625125474902, "test_macro_f1": 0.5171125763162606, "test_runtime": 8.3945, "test_samples_per_second": 243.969, "test_steps_per_second": 7.624}, {"test_loss": 0.8392495512962341, "test_mcc": 0.36493682472138667, "test_macro_f1": 0.49313287108812726, "test_runtime": 8.3143, "test_samples_per_second": 246.322, "test_steps_per_second": 7.698}, {"test_loss": 0.8478572368621826, "test_mcc": 0.3735689490675447, "test_macro_f1": 0.5239511383313843, "test_runtime": 8.7445, "test_samples_per_second": 234.203, "test_steps_per_second": 7.319}, {"test_loss": 0.8099762797355652, "test_mcc": 0.42756333837221205, "test_macro_f1": 0.5471794825955223, "test_runtime": 8.6724, "test_samples_per_second": 236.151, "test_steps_per_second": 7.38}]}, "total": {"test_mcc": 38.435959430055526, "test_mcc_se": 1.6711294036434268, "test_macro_f1": 52.60123037156927, "test_macro_f1_se": 1.954931517971544}}, "num_model_parameters": 335218691, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.050845593214035034, "test_micro_f1": 0.7262512768130746, "test_micro_f1_no_misc": 0.8084592145015106, "test_runtime": 12.5144, "test_samples_per_second": 163.651, "test_steps_per_second": 5.114}, {"test_loss": 0.048052892088890076, "test_micro_f1": 0.6956521739130436, "test_micro_f1_no_misc": 0.7546268656716418, "test_runtime": 11.9294, "test_samples_per_second": 171.677, "test_steps_per_second": 5.365}, {"test_loss": 0.045852068811655045, "test_micro_f1": 0.7452322738386308, "test_micro_f1_no_misc": 0.7967123287671233, "test_runtime": 11.6333, "test_samples_per_second": 176.047, "test_steps_per_second": 5.501}, {"test_loss": 0.046340204775333405, "test_micro_f1": 0.7176755447941888, "test_micro_f1_no_misc": 0.7722439843312814, "test_runtime": 12.248, "test_samples_per_second": 167.211, "test_steps_per_second": 5.225}, {"test_loss": 0.054342929273843765, "test_micro_f1": 0.7269174401563263, "test_micro_f1_no_misc": 0.7785598267460747, "test_runtime": 12.2536, "test_samples_per_second": 167.135, "test_steps_per_second": 5.223}, {"test_loss": 0.04915516823530197, "test_micro_f1": 0.7146237576904874, "test_micro_f1_no_misc": 0.7804090419806243, "test_runtime": 9.9915, "test_samples_per_second": 204.975, "test_steps_per_second": 6.405}, {"test_loss": 0.04846235737204552, "test_micro_f1": 0.7439759036144579, "test_micro_f1_no_misc": 0.8016241299303944, "test_runtime": 10.8369, "test_samples_per_second": 188.984, "test_steps_per_second": 5.906}, {"test_loss": 0.047034986317157745, "test_micro_f1": 0.7300908605024051, "test_micro_f1_no_misc": 0.7787182587666263, "test_runtime": 12.3671, "test_samples_per_second": 165.601, "test_steps_per_second": 5.175}, {"test_loss": 0.04718625545501709, "test_micro_f1": 0.7023754075454123, "test_micro_f1_no_misc": 0.758839050131926, "test_runtime": 11.3879, "test_samples_per_second": 179.84, "test_steps_per_second": 5.62}, {"test_loss": 0.04962863400578499, "test_micro_f1": 0.7811579980372915, "test_micro_f1_no_misc": 0.8305647840531561, "test_runtime": 12.3165, "test_samples_per_second": 166.281, "test_steps_per_second": 5.196}]}, "total": {"test_micro_f1": 72.83952636905317, "test_micro_f1_se": 1.5144814394609711, "test_micro_f1_no_misc": 78.6075748488036, "test_micro_f1_no_misc_se": 1.4462303022019505}}, "num_model_parameters": 334175241, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06792193651199341, "test_micro_f1": 0.7613492264773015, "test_micro_f1_no_misc": 0.7781593406593406, "test_runtime": 18.2297, "test_samples_per_second": 112.344, "test_steps_per_second": 3.511}, {"test_loss": 0.06654605269432068, "test_micro_f1": 0.7737062937062937, "test_micro_f1_no_misc": 0.791651409740022, "test_runtime": 14.8941, "test_samples_per_second": 137.504, "test_steps_per_second": 4.297}, {"test_loss": 0.06720563024282455, "test_micro_f1": 0.7598230549050222, "test_micro_f1_no_misc": 0.784554312522555, "test_runtime": 18.3169, "test_samples_per_second": 111.809, "test_steps_per_second": 3.494}, {"test_loss": 0.07107007503509521, "test_micro_f1": 0.7735898102417468, "test_micro_f1_no_misc": 0.7887915936952714, "test_runtime": 17.5776, "test_samples_per_second": 116.512, "test_steps_per_second": 3.641}, {"test_loss": 0.07627896964550018, "test_micro_f1": 0.7639005308745459, "test_micro_f1_no_misc": 0.7889561270801815, "test_runtime": 18.7926, "test_samples_per_second": 108.979, "test_steps_per_second": 3.406}, {"test_loss": 0.0697631984949112, "test_micro_f1": 0.7581047381546134, "test_micro_f1_no_misc": 0.7769028871391075, "test_runtime": 18.2277, "test_samples_per_second": 112.356, "test_steps_per_second": 3.511}, {"test_loss": 0.07518865168094635, "test_micro_f1": 0.753225806451613, "test_micro_f1_no_misc": 0.765807135287884, "test_runtime": 18.8463, "test_samples_per_second": 108.668, "test_steps_per_second": 3.396}, {"test_loss": 0.0646396353840828, "test_micro_f1": 0.7464324917672889, "test_micro_f1_no_misc": 0.7696835908756439, "test_runtime": 18.0324, "test_samples_per_second": 113.573, "test_steps_per_second": 3.549}, {"test_loss": 0.07364357262849808, "test_micro_f1": 0.76473769605192, "test_micro_f1_no_misc": 0.7773641102010425, "test_runtime": 17.4286, "test_samples_per_second": 117.508, "test_steps_per_second": 3.672}, {"test_loss": 0.06979848444461823, "test_micro_f1": 0.776604386677498, "test_micro_f1_no_misc": 0.7926739926739926, "test_runtime": 15.3459, "test_samples_per_second": 133.456, "test_steps_per_second": 4.17}]}, "total": {"test_micro_f1": 76.31474035307843, "test_micro_f1_se": 0.5924332926228398, "test_micro_f1_no_misc": 78.1454449987504, "test_micro_f1_no_misc_se": 0.5774783146328243}}, "num_model_parameters": 334175241, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.04999012500047684, "test_micro_f1": 0.7862068965517242, "test_micro_f1_no_misc": 0.8225674570727718, "test_runtime": 14.4304, "test_samples_per_second": 141.922, "test_steps_per_second": 4.435}, {"test_loss": 0.039999254047870636, "test_micro_f1": 0.8218154650728428, "test_micro_f1_no_misc": 0.8508516825924387, "test_runtime": 14.313, "test_samples_per_second": 143.087, "test_steps_per_second": 4.471}, {"test_loss": 0.06011620908975601, "test_micro_f1": 0.8212153143659993, "test_micro_f1_no_misc": 0.8519827247742443, "test_runtime": 13.4322, "test_samples_per_second": 152.469, "test_steps_per_second": 4.765}, {"test_loss": 0.04153261333703995, "test_micro_f1": 0.8079331941544885, "test_micro_f1_no_misc": 0.8345717637856862, "test_runtime": 13.6311, "test_samples_per_second": 150.245, "test_steps_per_second": 4.695}, {"test_loss": 0.048797640949487686, "test_micro_f1": 0.7920458375463431, "test_micro_f1_no_misc": 0.8279730740463725, "test_runtime": 14.532, "test_samples_per_second": 140.93, "test_steps_per_second": 4.404}, {"test_loss": 0.0469837412238121, "test_micro_f1": 0.8144643460628591, "test_micro_f1_no_misc": 0.8468197214904027, "test_runtime": 14.5668, "test_samples_per_second": 140.594, "test_steps_per_second": 4.394}, {"test_loss": 0.044480107724666595, "test_micro_f1": 0.8115646258503402, "test_micro_f1_no_misc": 0.8376259798432251, "test_runtime": 13.1319, "test_samples_per_second": 155.956, "test_steps_per_second": 4.874}, {"test_loss": 0.047875434160232544, "test_micro_f1": 0.8119834710743802, "test_micro_f1_no_misc": 0.8325892857142857, "test_runtime": 13.2244, "test_samples_per_second": 154.865, "test_steps_per_second": 4.84}, {"test_loss": 0.04805348813533783, "test_micro_f1": 0.7812840043525572, "test_micro_f1_no_misc": 0.797898140662894, "test_runtime": 13.3381, "test_samples_per_second": 153.545, "test_steps_per_second": 4.798}, {"test_loss": 0.061784207820892334, "test_micro_f1": 0.7998643147896879, "test_micro_f1_no_misc": 0.8288830387363672, "test_runtime": 13.939, "test_samples_per_second": 146.926, "test_steps_per_second": 4.591}]}, "total": {"test_micro_f1": 80.4837746982122, "test_micro_f1_se": 0.8874971127978311, "test_micro_f1_no_misc": 83.31762868718687, "test_micro_f1_no_misc_se": 0.9858488255206423}}, "num_model_parameters": 334175241, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06657663732767105, "test_micro_f1": 0.7526427061310782, "test_micro_f1_no_misc": 0.7814078814415628, "test_runtime": 12.9669, "test_samples_per_second": 157.941, "test_steps_per_second": 4.936}, {"test_loss": 0.06772935390472412, "test_micro_f1": 0.781136638452237, "test_micro_f1_no_misc": 0.8047457627118644, "test_runtime": 13.1696, "test_samples_per_second": 155.51, "test_steps_per_second": 4.86}, {"test_loss": 0.071730837225914, "test_micro_f1": 0.7125530624620983, "test_micro_f1_no_misc": 0.7488926746166951, "test_runtime": 12.4865, "test_samples_per_second": 164.017, "test_steps_per_second": 5.126}, {"test_loss": 0.06894207745790482, "test_micro_f1": 0.7508982035928143, "test_micro_f1_no_misc": 0.7855227882037533, "test_runtime": 12.6979, "test_samples_per_second": 161.287, "test_steps_per_second": 5.04}, {"test_loss": 0.07175035774707794, "test_micro_f1": 0.7397094430992737, "test_micro_f1_no_misc": 0.7779702112919987, "test_runtime": 12.4302, "test_samples_per_second": 164.76, "test_steps_per_second": 5.149}, {"test_loss": 0.0730266273021698, "test_micro_f1": 0.7350680070963928, "test_micro_f1_no_misc": 0.7684140676841406, "test_runtime": 12.5532, "test_samples_per_second": 163.146, "test_steps_per_second": 5.098}, {"test_loss": 0.05919858068227768, "test_micro_f1": 0.7710180372974627, "test_micro_f1_no_misc": 0.807111707480711, "test_runtime": 13.0961, "test_samples_per_second": 156.383, "test_steps_per_second": 4.887}, {"test_loss": 0.05653617903590202, "test_micro_f1": 0.7542997542997545, "test_micro_f1_no_misc": 0.7832880434782608, "test_runtime": 13.1661, "test_samples_per_second": 155.551, "test_steps_per_second": 4.861}, {"test_loss": 0.07084628939628601, "test_micro_f1": 0.747581903276131, "test_micro_f1_no_misc": 0.7758559830568301, "test_runtime": 12.2028, "test_samples_per_second": 167.831, "test_steps_per_second": 5.245}, {"test_loss": 0.06781750917434692, "test_micro_f1": 0.7389728096676738, "test_micro_f1_no_misc": 0.7637075718015667, "test_runtime": 12.8758, "test_samples_per_second": 159.058, "test_steps_per_second": 4.971}]}, "total": {"test_micro_f1": 74.83880565374916, "test_micro_f1_se": 1.1814539932046926, "test_micro_f1_no_misc": 77.96916691767383, "test_micro_f1_no_misc_se": 1.089006326331484}}, "num_model_parameters": 334175241, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.323397696018219, "test_mcc": 0.7671774224128171, "test_macro_f1": 0.8776140866186302, "test_runtime": 6.4178, "test_samples_per_second": 319.112, "test_steps_per_second": 9.972}, {"test_loss": 0.3466435372829437, "test_mcc": 0.7118013946712058, "test_macro_f1": 0.8474544343166013, "test_runtime": 6.2952, "test_samples_per_second": 325.325, "test_steps_per_second": 10.166}, {"test_loss": 0.33610081672668457, "test_mcc": 0.7970385062811601, "test_macro_f1": 0.89621486190458, "test_runtime": 6.2961, "test_samples_per_second": 325.279, "test_steps_per_second": 10.165}, {"test_loss": 0.42962756752967834, "test_mcc": 0.7207608984285787, "test_macro_f1": 0.8474855440686876, "test_runtime": 6.1882, "test_samples_per_second": 330.95, "test_steps_per_second": 10.342}, {"test_loss": 0.37480050325393677, "test_mcc": 0.7479622356476957, "test_macro_f1": 0.8680045519652235, "test_runtime": 6.2687, "test_samples_per_second": 326.7, "test_steps_per_second": 10.209}, {"test_loss": 0.39158180356025696, "test_mcc": 0.7359816520371347, "test_macro_f1": 0.861349343304995, "test_runtime": 6.3826, "test_samples_per_second": 320.87, "test_steps_per_second": 10.027}, {"test_loss": 0.4138576090335846, "test_mcc": 0.6635614804402346, "test_macro_f1": 0.8173228041089183, "test_runtime": 6.1913, "test_samples_per_second": 330.784, "test_steps_per_second": 10.337}, {"test_loss": 0.39852389693260193, "test_mcc": 0.7256366231952375, "test_macro_f1": 0.8566733774326527, "test_runtime": 6.3392, "test_samples_per_second": 323.067, "test_steps_per_second": 10.096}, {"test_loss": 0.35411036014556885, "test_mcc": 0.7310704068925178, "test_macro_f1": 0.858867660481268, "test_runtime": 6.3835, "test_samples_per_second": 320.828, "test_steps_per_second": 10.026}, {"test_loss": 0.4009111523628235, "test_mcc": 0.6857815538583822, "test_macro_f1": 0.8261691145586277, "test_runtime": 6.2228, "test_samples_per_second": 329.114, "test_steps_per_second": 10.285}]}, "total": {"test_mcc": 72.86772173864964, "test_mcc_se": 2.357739564097828, "test_macro_f1": 85.57155778760185, "test_macro_f1_se": 1.4308337723506799}}, "num_model_parameters": 335217666, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6685818433761597, "test_mcc": 0.34809238149066446, "test_macro_f1": 0.6526006430107103, "test_runtime": 8.9917, "test_samples_per_second": 227.765, "test_steps_per_second": 7.118}, {"test_loss": 0.6466988921165466, "test_mcc": 0.3438733318792626, "test_macro_f1": 0.6288120488481723, "test_runtime": 9.6522, "test_samples_per_second": 212.18, "test_steps_per_second": 6.631}, {"test_loss": 0.6893141269683838, "test_mcc": 0.0791085321338471, "test_macro_f1": 0.5063204685109736, "test_runtime": 9.5431, "test_samples_per_second": 214.604, "test_steps_per_second": 6.706}, {"test_loss": 0.6487239003181458, "test_mcc": 0.3537126794820045, "test_macro_f1": 0.6484408818831819, "test_runtime": 9.7406, "test_samples_per_second": 210.253, "test_steps_per_second": 6.57}, {"test_loss": 0.6442687511444092, "test_mcc": 0.40142351198897086, "test_macro_f1": 0.7006835223873906, "test_runtime": 9.275, "test_samples_per_second": 220.807, "test_steps_per_second": 6.9}, {"test_loss": 0.6028919219970703, "test_mcc": 0.35236183585714564, "test_macro_f1": 0.6612140666573327, "test_runtime": 9.1042, "test_samples_per_second": 224.952, "test_steps_per_second": 7.03}, {"test_loss": 0.6559648513793945, "test_mcc": 0.2437413520327332, "test_macro_f1": 0.5822571002245747, "test_runtime": 9.0281, "test_samples_per_second": 226.848, "test_steps_per_second": 7.089}, {"test_loss": 0.6218799948692322, "test_mcc": 0.34640288621058524, "test_macro_f1": 0.656994578009982, "test_runtime": 9.2049, "test_samples_per_second": 222.489, "test_steps_per_second": 6.953}, {"test_loss": 0.7008314728736877, "test_mcc": 0.39166906216878183, "test_macro_f1": 0.6563562716149678, "test_runtime": 9.0589, "test_samples_per_second": 226.077, "test_steps_per_second": 7.065}, {"test_loss": 0.6894298195838928, "test_mcc": 0.3682972809908362, "test_macro_f1": 0.6798302781286476, "test_runtime": 9.5635, "test_samples_per_second": 214.148, "test_steps_per_second": 6.692}]}, "total": {"test_mcc": 32.28682854234832, "test_mcc_se": 5.91981809774047, "test_macro_f1": 63.73509859275934, "test_macro_f1_se": 3.4425647084441664}}, "num_model_parameters": 335217666, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.662380576133728, "test_mcc": 0.36968317890003694, "test_macro_f1": 0.6247170173928978, "test_runtime": 8.1542, "test_samples_per_second": 251.158, "test_steps_per_second": 7.849}, {"test_loss": 0.606283962726593, "test_mcc": 0.39259722773874256, "test_macro_f1": 0.6565839069188368, "test_runtime": 8.2368, "test_samples_per_second": 248.64, "test_steps_per_second": 7.77}, {"test_loss": 0.5986890196800232, "test_mcc": 0.4014856952153599, "test_macro_f1": 0.673775402010173, "test_runtime": 8.2504, "test_samples_per_second": 248.232, "test_steps_per_second": 7.757}, {"test_loss": 0.6157044768333435, "test_mcc": 0.3720311356726944, "test_macro_f1": 0.6655288740434746, "test_runtime": 8.4, "test_samples_per_second": 243.809, "test_steps_per_second": 7.619}, {"test_loss": 0.62789386510849, "test_mcc": 0.3715580666240254, "test_macro_f1": 0.6387794696925158, "test_runtime": 8.3, "test_samples_per_second": 246.746, "test_steps_per_second": 7.711}, {"test_loss": 0.648370623588562, "test_mcc": 0.36589427238109784, "test_macro_f1": 0.606477745240456, "test_runtime": 7.9735, "test_samples_per_second": 256.852, "test_steps_per_second": 8.027}, {"test_loss": 0.6063812971115112, "test_mcc": 0.3521252136452009, "test_macro_f1": 0.6662254869359885, "test_runtime": 8.0945, "test_samples_per_second": 253.012, "test_steps_per_second": 7.907}, {"test_loss": 0.6284428834915161, "test_mcc": 0.3470844770345157, "test_macro_f1": 0.6133614250422951, "test_runtime": 8.08, "test_samples_per_second": 253.464, "test_steps_per_second": 7.921}, {"test_loss": 0.677459716796875, "test_mcc": 0.3961751906095258, "test_macro_f1": 0.6510830492987218, "test_runtime": 8.2585, "test_samples_per_second": 247.986, "test_steps_per_second": 7.75}, {"test_loss": 0.6347081661224365, "test_mcc": 0.3857671231942674, "test_macro_f1": 0.6498220676205628, "test_runtime": 8.2916, "test_samples_per_second": 246.997, "test_steps_per_second": 7.719}]}, "total": {"test_mcc": 37.544015810154676, "test_mcc_se": 1.1330979299211448, "test_macro_f1": 64.46354444195923, "test_macro_f1_se": 1.4355729118355829}}, "num_model_parameters": 335217666, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6925424337387085, "test_mcc": 0.0964915089125523, "test_macro_f1": 0.4220120871398454, "test_runtime": 8.3053, "test_samples_per_second": 246.59, "test_steps_per_second": 7.706}, {"test_loss": 0.6578311324119568, "test_mcc": 0.25994830145303555, "test_macro_f1": 0.5731819817647533, "test_runtime": 8.5379, "test_samples_per_second": 239.871, "test_steps_per_second": 7.496}, {"test_loss": 0.6733843684196472, "test_mcc": 0.2080033798433198, "test_macro_f1": 0.6040015459152812, "test_runtime": 8.6404, "test_samples_per_second": 237.027, "test_steps_per_second": 7.407}, {"test_loss": 0.6482044458389282, "test_mcc": 0.2558563742933098, "test_macro_f1": 0.59352479768496, "test_runtime": 8.1142, "test_samples_per_second": 252.398, "test_steps_per_second": 7.887}, {"test_loss": 0.6617192625999451, "test_mcc": 0.23061087276595307, "test_macro_f1": 0.6047936264989254, "test_runtime": 8.3244, "test_samples_per_second": 246.025, "test_steps_per_second": 7.688}, {"test_loss": 0.6331490874290466, "test_mcc": 0.3151869481088134, "test_macro_f1": 0.6230065272463572, "test_runtime": 8.5626, "test_samples_per_second": 239.178, "test_steps_per_second": 7.474}, {"test_loss": 0.6669907569885254, "test_mcc": 0.20541172737111899, "test_macro_f1": 0.5709287465169387, "test_runtime": 8.5361, "test_samples_per_second": 239.922, "test_steps_per_second": 7.498}, {"test_loss": 0.6326461434364319, "test_mcc": 0.28888742125711986, "test_macro_f1": 0.6233343495284729, "test_runtime": 8.3415, "test_samples_per_second": 245.52, "test_steps_per_second": 7.673}, {"test_loss": 0.6478177309036255, "test_mcc": 0.23154194530471706, "test_macro_f1": 0.6126660552659786, "test_runtime": 8.402, "test_samples_per_second": 243.75, "test_steps_per_second": 7.617}, {"test_loss": 0.6643662452697754, "test_mcc": 0.2179475185095596, "test_macro_f1": 0.5863579366808829, "test_runtime": 8.5246, "test_samples_per_second": 240.247, "test_steps_per_second": 7.508}]}, "total": {"test_mcc": 23.098859978194994, "test_mcc_se": 3.6575691808481072, "test_macro_f1": 58.13807654242395, "test_macro_f1_se": 3.6539110732477016}}, "num_model_parameters": 335217666, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_em": 51.587916343919446, "test_f1": 55.38997384454619}, {"test_em": 45.968992248062015, "test_f1": 51.01699811309934}, {"test_em": 47.990726429675426, "test_f1": 52.93246145925335}, {"test_em": 47.35202492211838, "test_f1": 51.97915921046759}, {"test_em": 43.08880308880309, "test_f1": 48.31971877770193}, {"test_em": 49.88434849653046, "test_f1": 54.553081177871405}, {"test_em": 44.95064540622627, "test_f1": 49.77032222335367}, {"test_em": 44.91854150504267, "test_f1": 50.583021607863884}, {"test_em": 46.98039215686274, "test_f1": 51.62978348064854}, {"test_em": 40.52795031055901, "test_f1": 45.29730465460736}]}, "total": {"test_em": 46.32503409077995, "test_em_se": 1.989168658020617, "test_f1": 51.14718245494132, "test_f1_se": 1.8265349931767232}}, "num_model_parameters": 334168066, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_em": 47.56003098373354, "test_f1": 52.65673730128768}, {"test_em": 46.201550387596896, "test_f1": 51.16122081540364}, {"test_em": 44.97681607418856, "test_f1": 50.61718332379299}, {"test_em": 46.33956386292835, "test_f1": 52.01880091853615}, {"test_em": 48.262548262548265, "test_f1": 53.78480624936598}, {"test_em": 46.72320740169622, "test_f1": 51.167315579641226}, {"test_em": 43.583902809415335, "test_f1": 48.86657146274384}, {"test_em": 47.55624515128006, "test_f1": 53.255920613623395}, {"test_em": 48.94117647058823, "test_f1": 53.75666704785262}, {"test_em": 46.8944099378882, "test_f1": 52.1575999661038}]}, "total": {"test_em": 46.70394513418637, "test_em_se": 0.9697810069786651, "test_f1": 51.944282327835126, "test_f1_se": 0.9557815572865086}}, "num_model_parameters": 334168066, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_em": 49.57397366382649, "test_f1": 55.827511605864}, {"test_em": 54.8062015503876, "test_f1": 60.275360705741974}, {"test_em": 54.86862442040186, "test_f1": 60.496271025671916}, {"test_em": 49.37694704049844, "test_f1": 54.92041348818841}, {"test_em": 52.50965250965251, "test_f1": 58.280801958368635}, {"test_em": 52.582883577486506, "test_f1": 57.982387995856776}, {"test_em": 53.45482156416097, "test_f1": 58.54337771696741}, {"test_em": 50.8921644685803, "test_f1": 56.087341706595474}, {"test_em": 56.15686274509804, "test_f1": 61.48306854924953}, {"test_em": 51.630434782608695, "test_f1": 56.4629353565689}]}, "total": {"test_em": 52.585256632270145, "test_em_se": 1.4134353093539134, "test_f1": 58.03594701090731, "test_f1_se": 1.3724088581621967}}, "num_model_parameters": 334168066, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.37358516454696655, "test_mcc": 0.7815184504835923, "test_macro_f1": 0.7674294721921829, "test_runtime": 28.3205, "test_samples_per_second": 72.315, "test_steps_per_second": 9.039}, {"test_loss": 0.3528880476951599, "test_mcc": 0.7723620932445556, "test_macro_f1": 0.7508729193018587, "test_runtime": 27.4103, "test_samples_per_second": 74.717, "test_steps_per_second": 9.34}, {"test_loss": 0.3322420120239258, "test_mcc": 0.7990870762644419, "test_macro_f1": 0.7869063934838891, "test_runtime": 27.7596, "test_samples_per_second": 73.776, "test_steps_per_second": 9.222}, {"test_loss": 0.3057762086391449, "test_mcc": 0.8057753293834907, "test_macro_f1": 0.7985980530624648, "test_runtime": 26.8107, "test_samples_per_second": 76.387, "test_steps_per_second": 9.548}, {"test_loss": 0.33431774377822876, "test_mcc": 0.7820850472323003, "test_macro_f1": 0.7589816584556502, "test_runtime": 26.6911, "test_samples_per_second": 76.73, "test_steps_per_second": 9.591}, {"test_loss": 0.3511311411857605, "test_mcc": 0.782966972482633, "test_macro_f1": 0.765041583866084, "test_runtime": 27.6182, "test_samples_per_second": 74.154, "test_steps_per_second": 9.269}, {"test_loss": 0.3458167016506195, "test_mcc": 0.7864588441720013, "test_macro_f1": 0.7717834834732549, "test_runtime": 26.0323, "test_samples_per_second": 78.672, "test_steps_per_second": 9.834}, {"test_loss": 0.3948175609111786, "test_mcc": 0.7674230628248071, "test_macro_f1": 0.7625794119420242, "test_runtime": 27.9345, "test_samples_per_second": 73.314, "test_steps_per_second": 9.164}, {"test_loss": 0.35187312960624695, "test_mcc": 0.7964398348771665, "test_macro_f1": 0.7774339487382119, "test_runtime": 27.9811, "test_samples_per_second": 73.192, "test_steps_per_second": 9.149}, {"test_loss": 0.3466145396232605, "test_mcc": 0.7704368330798925, "test_macro_f1": 0.7724846973132816, "test_runtime": 27.5106, "test_samples_per_second": 74.444, "test_steps_per_second": 9.305}]}, "total": {"test_mcc": 78.44553544044881, "test_mcc_se": 0.7909366407554994, "test_macro_f1": 77.12111621828902, "test_macro_f1_se": 0.8586131091958776}}, "num_model_parameters": 369557507, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.8904056549072266, "test_mcc": 0.40640428806107787, "test_macro_f1": 0.6057815563093131, "test_runtime": 10.4746, "test_samples_per_second": 195.521, "test_steps_per_second": 6.11}, {"test_loss": 0.9634239673614502, "test_mcc": 0.4251503702150945, "test_macro_f1": 0.6150613322110764, "test_runtime": 10.4005, "test_samples_per_second": 196.913, "test_steps_per_second": 6.154}, {"test_loss": 0.9298973679542542, "test_mcc": 0.37228266894963974, "test_macro_f1": 0.5839026347558924, "test_runtime": 10.3843, "test_samples_per_second": 197.221, "test_steps_per_second": 6.163}, {"test_loss": 0.9115691184997559, "test_mcc": 0.43478059996443635, "test_macro_f1": 0.6247153658169435, "test_runtime": 10.3902, "test_samples_per_second": 197.109, "test_steps_per_second": 6.16}, {"test_loss": 0.9156320095062256, "test_mcc": 0.4023690469612278, "test_macro_f1": 0.6026356333872824, "test_runtime": 10.4296, "test_samples_per_second": 196.365, "test_steps_per_second": 6.136}, {"test_loss": 0.9542787075042725, "test_mcc": 0.36234464149946427, "test_macro_f1": 0.5755149918746304, "test_runtime": 10.5249, "test_samples_per_second": 194.587, "test_steps_per_second": 6.081}, {"test_loss": 1.0244414806365967, "test_mcc": 0.38536819316386517, "test_macro_f1": 0.5884950550989849, "test_runtime": 10.5474, "test_samples_per_second": 194.171, "test_steps_per_second": 6.068}, {"test_loss": 0.928479790687561, "test_mcc": 0.38132443990688786, "test_macro_f1": 0.5908769496357201, "test_runtime": 10.3031, "test_samples_per_second": 198.776, "test_steps_per_second": 6.212}, {"test_loss": 0.9791408777236938, "test_mcc": 0.4015558253038833, "test_macro_f1": 0.5893117329155086, "test_runtime": 10.4132, "test_samples_per_second": 196.673, "test_steps_per_second": 6.146}, {"test_loss": 0.9957837462425232, "test_mcc": 0.3482988597772571, "test_macro_f1": 0.5562669423119923, "test_runtime": 10.3243, "test_samples_per_second": 198.367, "test_steps_per_second": 6.199}]}, "total": {"test_mcc": 39.19878933802834, "test_mcc_se": 1.6874970548776413, "test_macro_f1": 59.325621943173445, "test_macro_f1_se": 1.2265163997895188}}, "num_model_parameters": 369557507, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.8671875596046448, "test_mcc": 0.39618498837677907, "test_macro_f1": 0.5170158011651788, "test_runtime": 8.6428, "test_samples_per_second": 236.96, "test_steps_per_second": 7.405}, {"test_loss": 0.8762722015380859, "test_mcc": 0.3083664989747766, "test_macro_f1": 0.43020569615583976, "test_runtime": 8.2043, "test_samples_per_second": 249.625, "test_steps_per_second": 7.801}, {"test_loss": 0.8052883148193359, "test_mcc": 0.4557450899159009, "test_macro_f1": 0.6082325267434712, "test_runtime": 8.01, "test_samples_per_second": 255.68, "test_steps_per_second": 7.99}, {"test_loss": 0.9077788591384888, "test_mcc": 0.3839165808877665, "test_macro_f1": 0.5248052368289141, "test_runtime": 8.2022, "test_samples_per_second": 249.69, "test_steps_per_second": 7.803}, {"test_loss": 0.8589420318603516, "test_mcc": 0.3462061063186116, "test_macro_f1": 0.44537746439455256, "test_runtime": 8.4704, "test_samples_per_second": 241.784, "test_steps_per_second": 7.556}, {"test_loss": 0.8755702972412109, "test_mcc": 0.39906517000366803, "test_macro_f1": 0.5488171543537209, "test_runtime": 8.5289, "test_samples_per_second": 240.124, "test_steps_per_second": 7.504}, {"test_loss": 0.793603777885437, "test_mcc": 0.45086004489374115, "test_macro_f1": 0.5912563700996843, "test_runtime": 8.2127, "test_samples_per_second": 249.369, "test_steps_per_second": 7.793}, {"test_loss": 0.8722985982894897, "test_mcc": 0.38392161261002716, "test_macro_f1": 0.560427603208411, "test_runtime": 8.3465, "test_samples_per_second": 245.374, "test_steps_per_second": 7.668}, {"test_loss": 0.8151431083679199, "test_mcc": 0.4607324236653665, "test_macro_f1": 0.5926532217002825, "test_runtime": 8.596, "test_samples_per_second": 238.25, "test_steps_per_second": 7.445}, {"test_loss": 0.8691478371620178, "test_mcc": 0.3299336238771071, "test_macro_f1": 0.4810687796305741, "test_runtime": 8.5491, "test_samples_per_second": 239.559, "test_steps_per_second": 7.486}]}, "total": {"test_mcc": 39.14932139523744, "test_mcc_se": 3.2921407747812057, "test_macro_f1": 52.998598542806285, "test_macro_f1_se": 3.8534337513804764}}, "num_model_parameters": 369557507, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.050251103937625885, "test_micro_f1": 0.7089627391742195, "test_micro_f1_no_misc": 0.7743830787309047, "test_runtime": 12.6109, "test_samples_per_second": 162.399, "test_steps_per_second": 5.075}, {"test_loss": 0.045958518981933594, "test_micro_f1": 0.7261474987106756, "test_micro_f1_no_misc": 0.8102372034956304, "test_runtime": 11.9998, "test_samples_per_second": 170.67, "test_steps_per_second": 5.333}, {"test_loss": 0.04213440418243408, "test_micro_f1": 0.7473170731707317, "test_micro_f1_no_misc": 0.8006607929515419, "test_runtime": 12.3153, "test_samples_per_second": 166.298, "test_steps_per_second": 5.197}, {"test_loss": 0.04238802567124367, "test_micro_f1": 0.7342899554675903, "test_micro_f1_no_misc": 0.7878090856814262, "test_runtime": 12.7242, "test_samples_per_second": 160.953, "test_steps_per_second": 5.03}, {"test_loss": 0.04686376824975014, "test_micro_f1": 0.7491764705882353, "test_micro_f1_no_misc": 0.801498127340824, "test_runtime": 12.5772, "test_samples_per_second": 162.835, "test_steps_per_second": 5.089}, {"test_loss": 0.04166721552610397, "test_micro_f1": 0.7876230661040787, "test_micro_f1_no_misc": 0.8431480462300495, "test_runtime": 10.8789, "test_samples_per_second": 188.255, "test_steps_per_second": 5.883}, {"test_loss": 0.053754694759845734, "test_micro_f1": 0.7493940862821133, "test_micro_f1_no_misc": 0.8015607580824972, "test_runtime": 11.0044, "test_samples_per_second": 186.108, "test_steps_per_second": 5.816}, {"test_loss": 0.04624007269740105, "test_micro_f1": 0.7390581717451524, "test_micro_f1_no_misc": 0.7756370416407706, "test_runtime": 12.7675, "test_samples_per_second": 160.407, "test_steps_per_second": 5.013}, {"test_loss": 0.03953973203897476, "test_micro_f1": 0.7709923664122139, "test_micro_f1_no_misc": 0.823982398239824, "test_runtime": 12.0911, "test_samples_per_second": 169.381, "test_steps_per_second": 5.293}, {"test_loss": 0.0485348254442215, "test_micro_f1": 0.7700587084148728, "test_micro_f1_no_misc": 0.8200557103064067, "test_runtime": 12.7826, "test_samples_per_second": 160.218, "test_steps_per_second": 5.007}]}, "total": {"test_micro_f1": 74.83020136069885, "test_micro_f1_se": 1.4399244168674763, "test_micro_f1_no_misc": 80.38972242699876, "test_micro_f1_no_misc_se": 1.3382291250109224}}, "num_model_parameters": 368514057, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.061571154743433, "test_micro_f1": 0.7879554655870445, "test_micro_f1_no_misc": 0.8132322536181944, "test_runtime": 17.9665, "test_samples_per_second": 113.99, "test_steps_per_second": 3.562}, {"test_loss": 0.06572064757347107, "test_micro_f1": 0.7741585233441911, "test_micro_f1_no_misc": 0.8024602026049203, "test_runtime": 14.8735, "test_samples_per_second": 137.695, "test_steps_per_second": 4.303}, {"test_loss": 0.06363089382648468, "test_micro_f1": 0.7657754010695188, "test_micro_f1_no_misc": 0.7954138301683984, "test_runtime": 17.7882, "test_samples_per_second": 115.133, "test_steps_per_second": 3.598}, {"test_loss": 0.07054780423641205, "test_micro_f1": 0.7824967824967826, "test_micro_f1_no_misc": 0.8062862999658352, "test_runtime": 17.2208, "test_samples_per_second": 118.926, "test_steps_per_second": 3.716}, {"test_loss": 0.07390852272510529, "test_micro_f1": 0.7486218302094818, "test_micro_f1_no_misc": 0.7760861492759004, "test_runtime": 18.6377, "test_samples_per_second": 109.885, "test_steps_per_second": 3.434}, {"test_loss": 0.07153961062431335, "test_micro_f1": 0.7910817506193228, "test_micro_f1_no_misc": 0.8004467609828742, "test_runtime": 17.6822, "test_samples_per_second": 115.823, "test_steps_per_second": 3.619}, {"test_loss": 0.06846560537815094, "test_micro_f1": 0.7903139968068121, "test_micro_f1_no_misc": 0.8207681365576103, "test_runtime": 18.7467, "test_samples_per_second": 109.246, "test_steps_per_second": 3.414}, {"test_loss": 0.06427405774593353, "test_micro_f1": 0.77289972899729, "test_micro_f1_no_misc": 0.8100890207715133, "test_runtime": 18.2458, "test_samples_per_second": 112.245, "test_steps_per_second": 3.508}, {"test_loss": 0.07955004274845123, "test_micro_f1": 0.7557554908706008, "test_micro_f1_no_misc": 0.7898230088495575, "test_runtime": 17.2844, "test_samples_per_second": 118.488, "test_steps_per_second": 3.703}, {"test_loss": 0.07525849342346191, "test_micro_f1": 0.7738158594997339, "test_micro_f1_no_misc": 0.8032246244045439, "test_runtime": 15.8974, "test_samples_per_second": 128.826, "test_steps_per_second": 4.026}]}, "total": {"test_micro_f1": 77.42874829500778, "test_micro_f1_se": 0.8933921474514557, "test_micro_f1_no_misc": 80.1783028719935, "test_micro_f1_no_misc_se": 0.781013144664136}}, "num_model_parameters": 368514057, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.05193699151277542, "test_micro_f1": 0.8284457478005867, "test_micro_f1_no_misc": 0.8577353795105767, "test_runtime": 14.0648, "test_samples_per_second": 145.612, "test_steps_per_second": 4.55}, {"test_loss": 0.043092865496873856, "test_micro_f1": 0.8149505313301576, "test_micro_f1_no_misc": 0.8473879062114357, "test_runtime": 14.0086, "test_samples_per_second": 146.196, "test_steps_per_second": 4.569}, {"test_loss": 0.05134263634681702, "test_micro_f1": 0.782878840179496, "test_micro_f1_no_misc": 0.8251968503937006, "test_runtime": 13.3265, "test_samples_per_second": 153.679, "test_steps_per_second": 4.802}, {"test_loss": 0.05227823555469513, "test_micro_f1": 0.8052126200274348, "test_micro_f1_no_misc": 0.8308740068104428, "test_runtime": 13.5142, "test_samples_per_second": 151.544, "test_steps_per_second": 4.736}, {"test_loss": 0.04747769981622696, "test_micro_f1": 0.8270324523251923, "test_micro_f1_no_misc": 0.8553505535055351, "test_runtime": 14.3091, "test_samples_per_second": 143.126, "test_steps_per_second": 4.473}, {"test_loss": 0.04607827961444855, "test_micro_f1": 0.8012008005336891, "test_micro_f1_no_misc": 0.8279450018580452, "test_runtime": 14.0365, "test_samples_per_second": 145.905, "test_steps_per_second": 4.56}, {"test_loss": 0.04557275027036667, "test_micro_f1": 0.7925824175824177, "test_micro_f1_no_misc": 0.8237968927624101, "test_runtime": 12.8499, "test_samples_per_second": 159.379, "test_steps_per_second": 4.981}, {"test_loss": 0.050866805016994476, "test_micro_f1": 0.8230395558639833, "test_micro_f1_no_misc": 0.8516177017478617, "test_runtime": 13.0513, "test_samples_per_second": 156.919, "test_steps_per_second": 4.904}, {"test_loss": 0.04447011277079582, "test_micro_f1": 0.8120085775553966, "test_micro_f1_no_misc": 0.8410543130990417, "test_runtime": 13.2711, "test_samples_per_second": 154.32, "test_steps_per_second": 4.823}, {"test_loss": 0.05197007209062576, "test_micro_f1": 0.810074880871341, "test_micro_f1_no_misc": 0.8415879017013231, "test_runtime": 13.4967, "test_samples_per_second": 151.741, "test_steps_per_second": 4.742}]}, "total": {"test_micro_f1": 80.97426424069695, "test_micro_f1_se": 0.916424285356523, "test_micro_f1_no_misc": 84.02546507600374, "test_micro_f1_no_misc_se": 0.787531079546124}}, "num_model_parameters": 368514057, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.062398046255111694, "test_micro_f1": 0.771668219944082, "test_micro_f1_no_misc": 0.8013651877133107, "test_runtime": 12.7633, "test_samples_per_second": 160.46, "test_steps_per_second": 5.014}, {"test_loss": 0.06786726415157318, "test_micro_f1": 0.7500746491489997, "test_micro_f1_no_misc": 0.7785190126751167, "test_runtime": 13.0571, "test_samples_per_second": 156.849, "test_steps_per_second": 4.902}, {"test_loss": 0.06740249693393707, "test_micro_f1": 0.7383877734492059, "test_micro_f1_no_misc": 0.7809139784946236, "test_runtime": 12.5898, "test_samples_per_second": 162.672, "test_steps_per_second": 5.083}, {"test_loss": 0.06924369931221008, "test_micro_f1": 0.7446487790171841, "test_micro_f1_no_misc": 0.7837201479986545, "test_runtime": 12.9271, "test_samples_per_second": 158.427, "test_steps_per_second": 4.951}, {"test_loss": 0.07345061749219894, "test_micro_f1": 0.7138167711131006, "test_micro_f1_no_misc": 0.7545887151597553, "test_runtime": 12.5619, "test_samples_per_second": 163.033, "test_steps_per_second": 5.095}, {"test_loss": 0.06868404895067215, "test_micro_f1": 0.7844905320108205, "test_micro_f1_no_misc": 0.8171390013495277, "test_runtime": 12.5456, "test_samples_per_second": 163.245, "test_steps_per_second": 5.101}, {"test_loss": 0.0700065866112709, "test_micro_f1": 0.7057010785824345, "test_micro_f1_no_misc": 0.7552447552447552, "test_runtime": 13.1039, "test_samples_per_second": 156.289, "test_steps_per_second": 4.884}, {"test_loss": 0.06099887937307358, "test_micro_f1": 0.7559055118110236, "test_micro_f1_no_misc": 0.7950435365036839, "test_runtime": 13.3975, "test_samples_per_second": 152.864, "test_steps_per_second": 4.777}, {"test_loss": 0.0695650577545166, "test_micro_f1": 0.7099120945741134, "test_micro_f1_no_misc": 0.7487420328748742, "test_runtime": 12.4429, "test_samples_per_second": 164.592, "test_steps_per_second": 5.143}, {"test_loss": 0.06804437935352325, "test_micro_f1": 0.7504531722054381, "test_micro_f1_no_misc": 0.7831285287279973, "test_runtime": 13.0679, "test_samples_per_second": 156.72, "test_steps_per_second": 4.897}]}, "total": {"test_micro_f1": 74.25058581856402, "test_micro_f1_se": 1.6234660228616697, "test_micro_f1_no_misc": 77.98404896742299, "test_micro_f1_no_misc_se": 1.3585724042597824}}, "num_model_parameters": 368514057, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.30303728580474854, "test_mcc": 0.7782256587299081, "test_macro_f1": 0.8845805930871768, "test_runtime": 6.5272, "test_samples_per_second": 313.763, "test_steps_per_second": 9.805}, {"test_loss": 0.32882827520370483, "test_mcc": 0.7937814467215324, "test_macro_f1": 0.8932578467188188, "test_runtime": 6.7194, "test_samples_per_second": 304.788, "test_steps_per_second": 9.525}, {"test_loss": 0.33656322956085205, "test_mcc": 0.7880859091644538, "test_macro_f1": 0.8881633631404569, "test_runtime": 6.6989, "test_samples_per_second": 305.721, "test_steps_per_second": 9.554}, {"test_loss": 0.3716959059238434, "test_mcc": 0.7675251243315416, "test_macro_f1": 0.8775440924591478, "test_runtime": 6.3692, "test_samples_per_second": 321.548, "test_steps_per_second": 10.048}, {"test_loss": 0.3513619899749756, "test_mcc": 0.7612234052006707, "test_macro_f1": 0.8696865333831725, "test_runtime": 6.5444, "test_samples_per_second": 312.938, "test_steps_per_second": 9.779}, {"test_loss": 0.3021395206451416, "test_mcc": 0.7905748607851241, "test_macro_f1": 0.8917118437539104, "test_runtime": 6.3837, "test_samples_per_second": 320.819, "test_steps_per_second": 10.026}, {"test_loss": 0.31415700912475586, "test_mcc": 0.7795686971870421, "test_macro_f1": 0.8835027235645032, "test_runtime": 6.3864, "test_samples_per_second": 320.681, "test_steps_per_second": 10.021}, {"test_loss": 0.384108304977417, "test_mcc": 0.7383638574282084, "test_macro_f1": 0.8585003068198752, "test_runtime": 6.5531, "test_samples_per_second": 312.524, "test_steps_per_second": 9.766}, {"test_loss": 0.3643631339073181, "test_mcc": 0.7191632845266883, "test_macro_f1": 0.8504857973884523, "test_runtime": 6.3697, "test_samples_per_second": 321.524, "test_steps_per_second": 10.048}, {"test_loss": 0.37822675704956055, "test_mcc": 0.7113079691413211, "test_macro_f1": 0.8391646427480695, "test_runtime": 6.5262, "test_samples_per_second": 313.814, "test_steps_per_second": 9.807}]}, "total": {"test_mcc": 76.27820213216492, "test_mcc_se": 1.8556664228507804, "test_macro_f1": 87.36597743063584, "test_macro_f1_se": 1.1547738299257697}}, "num_model_parameters": 369556482, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.6483071446418762, "test_mcc": 0.29185679623943867, "test_macro_f1": 0.5982207770060175, "test_runtime": 9.2008, "test_samples_per_second": 222.589, "test_steps_per_second": 6.956}, {"test_loss": 0.637812614440918, "test_mcc": 0.32470426643377426, "test_macro_f1": 0.6417469112474483, "test_runtime": 9.6331, "test_samples_per_second": 212.6, "test_steps_per_second": 6.644}, {"test_loss": 0.6513866782188416, "test_mcc": 0.236182696098665, "test_macro_f1": 0.5873006434451109, "test_runtime": 9.4522, "test_samples_per_second": 216.67, "test_steps_per_second": 6.771}, {"test_loss": 0.6778315305709839, "test_mcc": 0.18027443118299946, "test_macro_f1": 0.5389373323857889, "test_runtime": 9.8514, "test_samples_per_second": 207.888, "test_steps_per_second": 6.497}, {"test_loss": 0.6555874347686768, "test_mcc": 0.24420879076742466, "test_macro_f1": 0.594411967038825, "test_runtime": 9.4253, "test_samples_per_second": 217.289, "test_steps_per_second": 6.79}, {"test_loss": 0.6488063931465149, "test_mcc": 0.27802286552569366, "test_macro_f1": 0.5885338770057269, "test_runtime": 9.2253, "test_samples_per_second": 221.999, "test_steps_per_second": 6.937}, {"test_loss": 0.6644530892372131, "test_mcc": 0.2542779257874312, "test_macro_f1": 0.6000733707049932, "test_runtime": 9.1711, "test_samples_per_second": 223.309, "test_steps_per_second": 6.978}, {"test_loss": 0.6671463847160339, "test_mcc": 0.19717147403801544, "test_macro_f1": 0.5423079546110304, "test_runtime": 9.4307, "test_samples_per_second": 217.164, "test_steps_per_second": 6.786}, {"test_loss": 0.6377601027488708, "test_mcc": 0.3472538805733124, "test_macro_f1": 0.6462430598396052, "test_runtime": 9.2603, "test_samples_per_second": 221.159, "test_steps_per_second": 6.911}, {"test_loss": 0.6496981382369995, "test_mcc": 0.3141563385740707, "test_macro_f1": 0.6030289376767448, "test_runtime": 9.4395, "test_samples_per_second": 216.96, "test_steps_per_second": 6.78}]}, "total": {"test_mcc": 26.681094652208255, "test_mcc_se": 3.3797949619488414, "test_macro_f1": 59.40804830961292, "test_macro_f1_se": 2.1593785589697667}}, "num_model_parameters": 369556482, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.6411973237991333, "test_mcc": 0.27515033695386304, "test_macro_f1": 0.6220253604307799, "test_runtime": 8.2297, "test_samples_per_second": 248.855, "test_steps_per_second": 7.777}, {"test_loss": 0.6715602278709412, "test_mcc": 0.22522711919943111, "test_macro_f1": 0.5558993958186323, "test_runtime": 8.5399, "test_samples_per_second": 239.815, "test_steps_per_second": 7.494}, {"test_loss": 0.675910472869873, "test_mcc": 0.16862965534934932, "test_macro_f1": 0.5316487477535115, "test_runtime": 8.5539, "test_samples_per_second": 239.423, "test_steps_per_second": 7.482}, {"test_loss": 0.6566084623336792, "test_mcc": 0.22923375902928872, "test_macro_f1": 0.604040433518526, "test_runtime": 8.3986, "test_samples_per_second": 243.85, "test_steps_per_second": 7.62}, {"test_loss": 0.6800272464752197, "test_mcc": 0.16026703046053695, "test_macro_f1": 0.5796676441837731, "test_runtime": 8.4067, "test_samples_per_second": 243.615, "test_steps_per_second": 7.613}, {"test_loss": 0.6448954343795776, "test_mcc": 0.27556029207705107, "test_macro_f1": 0.6174064545583544, "test_runtime": 8.2702, "test_samples_per_second": 247.636, "test_steps_per_second": 7.739}, {"test_loss": 0.6645035743713379, "test_mcc": 0.2114412342903595, "test_macro_f1": 0.5953548307504885, "test_runtime": 8.2096, "test_samples_per_second": 249.464, "test_steps_per_second": 7.796}, {"test_loss": 0.6622041463851929, "test_mcc": 0.2421276238849002, "test_macro_f1": 0.5500081896591903, "test_runtime": 8.1817, "test_samples_per_second": 250.315, "test_steps_per_second": 7.822}, {"test_loss": 0.6798521876335144, "test_mcc": 0.1552921832687388, "test_macro_f1": 0.5547737290332875, "test_runtime": 8.3894, "test_samples_per_second": 244.117, "test_steps_per_second": 7.629}, {"test_loss": 0.6637200713157654, "test_mcc": 0.19557677446076696, "test_macro_f1": 0.5976424361493123, "test_runtime": 8.3366, "test_samples_per_second": 245.663, "test_steps_per_second": 7.677}]}, "total": {"test_mcc": 21.385060089742858, "test_mcc_se": 2.726550245201725, "test_macro_f1": 58.084672218558566, "test_macro_f1_se": 1.931242703629223}}, "num_model_parameters": 369556482, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_loss": 0.6916147470474243, "test_mcc": 0.07109430019040613, "test_macro_f1": 0.5192334368364331, "test_runtime": 8.4333, "test_samples_per_second": 242.846, "test_steps_per_second": 7.589}, {"test_loss": 0.6576751470565796, "test_mcc": 0.2208100535599022, "test_macro_f1": 0.5935332437410514, "test_runtime": 8.7161, "test_samples_per_second": 234.969, "test_steps_per_second": 7.343}, {"test_loss": 0.6687818765640259, "test_mcc": 0.21130570794212836, "test_macro_f1": 0.5790736716011368, "test_runtime": 8.8239, "test_samples_per_second": 232.097, "test_steps_per_second": 7.253}, {"test_loss": 0.6586220264434814, "test_mcc": 0.2211283960534366, "test_macro_f1": 0.6032642922161335, "test_runtime": 8.2074, "test_samples_per_second": 249.531, "test_steps_per_second": 7.798}, {"test_loss": 0.6675056219100952, "test_mcc": 0.19350240714440367, "test_macro_f1": 0.5911680483751398, "test_runtime": 8.4491, "test_samples_per_second": 242.394, "test_steps_per_second": 7.575}, {"test_loss": 0.6832980513572693, "test_mcc": 0.07935709185730867, "test_macro_f1": 0.5193354803335204, "test_runtime": 8.6989, "test_samples_per_second": 235.432, "test_steps_per_second": 7.357}, {"test_loss": 0.6736785173416138, "test_mcc": 0.15612165333888411, "test_macro_f1": 0.5727744126317922, "test_runtime": 8.6919, "test_samples_per_second": 235.622, "test_steps_per_second": 7.363}, {"test_loss": 0.6628535985946655, "test_mcc": 0.18258054202365345, "test_macro_f1": 0.5586633042014081, "test_runtime": 8.5234, "test_samples_per_second": 240.281, "test_steps_per_second": 7.509}, {"test_loss": 0.66150963306427, "test_mcc": 0.2112849053020862, "test_macro_f1": 0.5950475230843824, "test_runtime": 8.4459, "test_samples_per_second": 242.485, "test_steps_per_second": 7.578}, {"test_loss": 0.6682060360908508, "test_mcc": 0.16256427523385822, "test_macro_f1": 0.5674447984234997, "test_runtime": 8.6749, "test_samples_per_second": 236.082, "test_steps_per_second": 7.378}]}, "total": {"test_mcc": 17.09749332646068, "test_mcc_se": 3.429463623093699, "test_macro_f1": 56.99538211444497, "test_macro_f1_se": 1.8599914817831533}}, "num_model_parameters": 369556482, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_em": 47.94732765298218, "test_f1": 53.30956473344952}, {"test_em": 46.201550387596896, "test_f1": 50.902005186888886}, {"test_em": 45.749613601236476, "test_f1": 50.65725104364981}, {"test_em": 46.26168224299065, "test_f1": 51.443862872026095}, {"test_em": 44.092664092664094, "test_f1": 48.28849005739762}, {"test_em": 44.71858134155744, "test_f1": 50.10643179619095}, {"test_em": 50.26575550493546, "test_f1": 55.07083378951258}, {"test_em": 47.01318851823119, "test_f1": 52.88516556028987}, {"test_em": 47.450980392156865, "test_f1": 52.477383656968435}, {"test_em": 47.90372670807454, "test_f1": 52.48583696679238}]}, "total": {"test_em": 46.76050704424258, "test_em_se": 1.1012664140969037, "test_f1": 51.762682566316606, "test_f1_se": 1.1779583252658579}}, "num_model_parameters": 368506882, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_em": 47.01781564678544, "test_f1": 52.19984971839316}, {"test_em": 46.201550387596896, "test_f1": 51.60927745811463}, {"test_em": 45.98145285935085, "test_f1": 51.41691214050065}, {"test_em": 48.598130841121495, "test_f1": 53.3425038097935}, {"test_em": 52.04633204633205, "test_f1": 56.80458934057761}, {"test_em": 49.113338473400155, "test_f1": 54.095888611620296}, {"test_em": 48.747152619589976, "test_f1": 53.898996169037126}, {"test_em": 45.69433669511249, "test_f1": 51.38861114727608}, {"test_em": 49.254901960784316, "test_f1": 54.917706079643814}, {"test_em": 48.83540372670807, "test_f1": 53.70504509312004}]}, "total": {"test_em": 48.14904152567817, "test_em_se": 1.207670198493025, "test_f1": 53.337937956807686, "test_f1_se": 1.0797038594631285}}, "num_model_parameters": 368506882, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_em": 50.58094500387297, "test_f1": 56.9436301258418}, {"test_em": 53.02325581395349, "test_f1": 58.4641482548459}, {"test_em": 51.00463678516229, "test_f1": 57.37355593181001}, {"test_em": 55.60747663551402, "test_f1": 61.451778930566405}, {"test_em": 50.656370656370655, "test_f1": 57.23472043308397}, {"test_em": 52.120277563608326, "test_f1": 57.64146057399598}, {"test_em": 52.99924069855733, "test_f1": 58.71725974533157}, {"test_em": 47.944142746314974, "test_f1": 54.109958918724175}, {"test_em": 52.31372549019608, "test_f1": 58.574884451701024}, {"test_em": 50.85403726708075, "test_f1": 56.50986273969561}]}, "total": {"test_em": 51.71041086606309, "test_em_se": 1.2551264068087618, "test_f1": 57.70212601055964, "test_f1_se": 1.162554437613923}}, "num_model_parameters": 368506882, "max_sequence_length": 512, "vocabulary_size": 64128}

{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_em": 43.06738962044926, "test_f1": 47.75939490451483}, {"test_em": 39.76744186046512, "test_f1": 43.763594109695326}, {"test_em": 42.73570324574961, "test_f1": 47.18347108270713}, {"test_em": 38.78504672897196, "test_f1": 42.681795002097004}, {"test_em": 36.13899613899614, "test_f1": 40.2484007015188}, {"test_em": 43.3307632999229, "test_f1": 47.24025893146824}, {"test_em": 41.83750949126804, "test_f1": 46.036137675488284}, {"test_em": 41.970519782777345, "test_f1": 45.90380019257733}, {"test_em": 39.372549019607845, "test_f1": 43.425472894579954}, {"test_em": 39.20807453416149, "test_f1": 43.59716379344322}]}, "total": {"test_em": 40.62139937223697, "test_em_se": 1.4439012436854919, "test_f1": 44.78394892880901, "test_f1_se": 1.5005599875088151}}, "num_model_parameters": 278239490, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.5894886255264282, "test_mcc": 0.615926459673615, "test_macro_f1": 0.5643911890356073, "test_runtime": 13.8255, "test_samples_per_second": 148.132, "test_steps_per_second": 18.517}, {"test_loss": 0.631669819355011, "test_mcc": 0.5847249942284147, "test_macro_f1": 0.5609586618152416, "test_runtime": 13.0866, "test_samples_per_second": 156.497, "test_steps_per_second": 19.562}, {"test_loss": 0.619681715965271, "test_mcc": 0.5784130893718407, "test_macro_f1": 0.5737836195967229, "test_runtime": 13.5468, "test_samples_per_second": 151.18, "test_steps_per_second": 18.898}, {"test_loss": 0.5466675162315369, "test_mcc": 0.6322374279401098, "test_macro_f1": 0.6508790281124677, "test_runtime": 12.9632, "test_samples_per_second": 157.986, "test_steps_per_second": 19.748}, {"test_loss": 0.5995770692825317, "test_mcc": 0.6032919075817696, "test_macro_f1": 0.6257936475419698, "test_runtime": 12.7399, "test_samples_per_second": 160.755, "test_steps_per_second": 20.094}, {"test_loss": 0.5763957500457764, "test_mcc": 0.6140322396140909, "test_macro_f1": 0.6124147937245801, "test_runtime": 13.2117, "test_samples_per_second": 155.014, "test_steps_per_second": 19.377}, {"test_loss": 0.5920851230621338, "test_mcc": 0.6156516725304578, "test_macro_f1": 0.5532715043312985, "test_runtime": 12.6092, "test_samples_per_second": 162.421, "test_steps_per_second": 20.303}, {"test_loss": 0.5690732598304749, "test_mcc": 0.6403204499971051, "test_macro_f1": 0.5859124164261883, "test_runtime": 13.6759, "test_samples_per_second": 149.753, "test_steps_per_second": 18.719}, {"test_loss": 0.651846170425415, "test_mcc": 0.5954162939354382, "test_macro_f1": 0.5433152068548902, "test_runtime": 13.5459, "test_samples_per_second": 151.19, "test_steps_per_second": 18.899}, {"test_loss": 0.5672990083694458, "test_mcc": 0.6310532438010016, "test_macro_f1": 0.6259683525206561, "test_runtime": 13.0952, "test_samples_per_second": 156.393, "test_steps_per_second": 19.549}]}, "total": {"test_mcc": 61.110677786738435, "test_mcc_se": 1.2773272365324104, "test_macro_f1": 58.966884199596215, "test_macro_f1_se": 2.2716684794165243}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.9941985607147217, "test_mcc": 0.3209934680167463, "test_macro_f1": 0.5481807193012875, "test_runtime": 4.9207, "test_samples_per_second": 416.2, "test_steps_per_second": 13.006}, {"test_loss": 0.9714604616165161, "test_mcc": 0.3278373591026214, "test_macro_f1": 0.5499988738573518, "test_runtime": 4.923, "test_samples_per_second": 416.009, "test_steps_per_second": 13.0}, {"test_loss": 1.0189688205718994, "test_mcc": 0.3420074107230076, "test_macro_f1": 0.5625264269358602, "test_runtime": 4.9222, "test_samples_per_second": 416.072, "test_steps_per_second": 13.002}, {"test_loss": 0.9865684509277344, "test_mcc": 0.34105063161205035, "test_macro_f1": 0.5461057927940113, "test_runtime": 4.7543, "test_samples_per_second": 430.771, "test_steps_per_second": 13.462}, {"test_loss": 1.0120675563812256, "test_mcc": 0.3563494657310578, "test_macro_f1": 0.5689152274860746, "test_runtime": 4.7044, "test_samples_per_second": 435.335, "test_steps_per_second": 13.604}, {"test_loss": 0.9920424222946167, "test_mcc": 0.3565505508427542, "test_macro_f1": 0.5574084573513645, "test_runtime": 4.9549, "test_samples_per_second": 413.328, "test_steps_per_second": 12.916}, {"test_loss": 0.9743961095809937, "test_mcc": 0.3422723057923485, "test_macro_f1": 0.5458902861308547, "test_runtime": 4.7494, "test_samples_per_second": 431.213, "test_steps_per_second": 13.475}, {"test_loss": 0.9940730929374695, "test_mcc": 0.36021212238204925, "test_macro_f1": 0.5744510076831607, "test_runtime": 5.1273, "test_samples_per_second": 399.433, "test_steps_per_second": 12.482}, {"test_loss": 1.0241799354553223, "test_mcc": 0.34776600702284577, "test_macro_f1": 0.5611099098641963, "test_runtime": 4.8664, "test_samples_per_second": 420.845, "test_steps_per_second": 13.151}, {"test_loss": 0.9973233938217163, "test_mcc": 0.34975555998876234, "test_macro_f1": 0.5415861715076494, "test_runtime": 4.6189, "test_samples_per_second": 443.393, "test_steps_per_second": 13.856}]}, "total": {"test_mcc": 34.447948812142435, "test_mcc_se": 0.7796471481840905, "test_macro_f1": 55.56172872911811, "test_macro_f1_se": 0.6794296150694967}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.8769141435623169, "test_mcc": 0.4010006394603248, "test_macro_f1": 0.5130434229453903, "test_runtime": 3.304, "test_samples_per_second": 619.854, "test_steps_per_second": 19.37}, {"test_loss": 0.8924022912979126, "test_mcc": 0.32181858209186026, "test_macro_f1": 0.49686379675715914, "test_runtime": 3.1097, "test_samples_per_second": 658.584, "test_steps_per_second": 20.581}, {"test_loss": 0.8607218861579895, "test_mcc": 0.3750922928948273, "test_macro_f1": 0.5426774789730794, "test_runtime": 3.103, "test_samples_per_second": 660.002, "test_steps_per_second": 20.625}, {"test_loss": 0.9240704774856567, "test_mcc": 0.3897603504089888, "test_macro_f1": 0.5233365271726478, "test_runtime": 3.1793, "test_samples_per_second": 644.173, "test_steps_per_second": 20.13}, {"test_loss": 0.8554320335388184, "test_mcc": 0.3756043027109497, "test_macro_f1": 0.5373179492782877, "test_runtime": 3.2095, "test_samples_per_second": 638.102, "test_steps_per_second": 19.941}, {"test_loss": 0.8599997758865356, "test_mcc": 0.3546092597017852, "test_macro_f1": 0.49041763407825495, "test_runtime": 3.3213, "test_samples_per_second": 616.62, "test_steps_per_second": 19.269}, {"test_loss": 0.8696717023849487, "test_mcc": 0.3596788293145187, "test_macro_f1": 0.4909531922451425, "test_runtime": 3.222, "test_samples_per_second": 635.635, "test_steps_per_second": 19.864}, {"test_loss": 0.8479688167572021, "test_mcc": 0.3510309777088516, "test_macro_f1": 0.5241269624618888, "test_runtime": 3.2223, "test_samples_per_second": 635.572, "test_steps_per_second": 19.862}, {"test_loss": 0.8528756499290466, "test_mcc": 0.37108585859137877, "test_macro_f1": 0.5242988285091663, "test_runtime": 3.305, "test_samples_per_second": 619.671, "test_steps_per_second": 19.365}, {"test_loss": 0.9085524082183838, "test_mcc": 0.32685807694888014, "test_macro_f1": 0.45156504629207955, "test_runtime": 3.3192, "test_samples_per_second": 617.013, "test_steps_per_second": 19.282}]}, "total": {"test_mcc": 36.265391698323654, "test_mcc_se": 1.5674936253459115, "test_macro_f1": 50.94600838713096, "test_macro_f1_se": 1.6956208383617055}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.07057235389947891, "test_micro_f1": 0.6477211796246649, "test_micro_f1_no_misc": 0.7162162162162162, "test_runtime": 6.2674, "test_samples_per_second": 326.772, "test_steps_per_second": 10.212}, {"test_loss": 0.06539757549762726, "test_micro_f1": 0.6793032786885246, "test_micro_f1_no_misc": 0.743124634289058, "test_runtime": 5.9678, "test_samples_per_second": 343.175, "test_steps_per_second": 10.724}, {"test_loss": 0.060339685529470444, "test_micro_f1": 0.6516643225503985, "test_micro_f1_no_misc": 0.7149758454106279, "test_runtime": 5.8615, "test_samples_per_second": 349.401, "test_steps_per_second": 10.919}, {"test_loss": 0.064556784927845, "test_micro_f1": 0.6622579121398205, "test_micro_f1_no_misc": 0.7146724417975094, "test_runtime": 6.2528, "test_samples_per_second": 327.533, "test_steps_per_second": 10.235}, {"test_loss": 0.06391991674900055, "test_micro_f1": 0.6723404255319148, "test_micro_f1_no_misc": 0.7429805615550756, "test_runtime": 6.3398, "test_samples_per_second": 323.039, "test_steps_per_second": 10.095}, {"test_loss": 0.05527092516422272, "test_micro_f1": 0.716582452916858, "test_micro_f1_no_misc": 0.7698878804057662, "test_runtime": 4.9007, "test_samples_per_second": 417.904, "test_steps_per_second": 13.059}, {"test_loss": 0.06418199092149734, "test_micro_f1": 0.6762728146013449, "test_micro_f1_no_misc": 0.7322107550244432, "test_runtime": 5.4681, "test_samples_per_second": 374.537, "test_steps_per_second": 11.704}, {"test_loss": 0.057439565658569336, "test_micro_f1": 0.648381788261108, "test_micro_f1_no_misc": 0.6991473812423873, "test_runtime": 6.223, "test_samples_per_second": 329.1, "test_steps_per_second": 10.284}, {"test_loss": 0.05738631263375282, "test_micro_f1": 0.6814117647058823, "test_micro_f1_no_misc": 0.749034749034749, "test_runtime": 5.8646, "test_samples_per_second": 349.215, "test_steps_per_second": 10.913}, {"test_loss": 0.06433845311403275, "test_micro_f1": 0.6568771414586393, "test_micro_f1_no_misc": 0.7076591154261056, "test_runtime": 6.3154, "test_samples_per_second": 324.285, "test_steps_per_second": 10.134}]}, "total": {"test_micro_f1": 66.92813080479156, "test_micro_f1_se": 1.2998549352085675, "test_micro_f1_no_misc": 72.89909580401938, "test_micro_f1_no_misc_se": 1.368959038010059}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.07253949344158173, "test_micro_f1": 0.7726199842643587, "test_micro_f1_no_misc": 0.8025823989126741, "test_runtime": 7.6159, "test_samples_per_second": 268.91, "test_steps_per_second": 8.403}, {"test_loss": 0.06604856997728348, "test_micro_f1": 0.7914438502673797, "test_micro_f1_no_misc": 0.8122464035411286, "test_runtime": 5.9994, "test_samples_per_second": 341.369, "test_steps_per_second": 10.668}, {"test_loss": 0.06932325661182404, "test_micro_f1": 0.7761752136752137, "test_micro_f1_no_misc": 0.8092691622103386, "test_runtime": 7.4859, "test_samples_per_second": 273.58, "test_steps_per_second": 8.549}, {"test_loss": 0.06864814460277557, "test_micro_f1": 0.7756911841418884, "test_micro_f1_no_misc": 0.7991704113377117, "test_runtime": 7.4003, "test_samples_per_second": 276.747, "test_steps_per_second": 8.648}, {"test_loss": 0.08190532773733139, "test_micro_f1": 0.755357639855274, "test_micro_f1_no_misc": 0.7902621722846441, "test_runtime": 7.4118, "test_samples_per_second": 276.314, "test_steps_per_second": 8.635}, {"test_loss": 0.07145702093839645, "test_micro_f1": 0.7312060573282856, "test_micro_f1_no_misc": 0.7467718794835007, "test_runtime": 7.4705, "test_samples_per_second": 274.145, "test_steps_per_second": 8.567}, {"test_loss": 0.06973099708557129, "test_micro_f1": 0.7663601946998376, "test_micro_f1_no_misc": 0.7823321554770318, "test_runtime": 7.5925, "test_samples_per_second": 269.742, "test_steps_per_second": 8.429}, {"test_loss": 0.06636736541986465, "test_micro_f1": 0.7514514791263478, "test_micro_f1_no_misc": 0.7861818181818182, "test_runtime": 7.5641, "test_samples_per_second": 270.752, "test_steps_per_second": 8.461}, {"test_loss": 0.07318759709596634, "test_micro_f1": 0.752972972972973, "test_micro_f1_no_misc": 0.7674668577570763, "test_runtime": 7.3474, "test_samples_per_second": 278.736, "test_steps_per_second": 8.711}, {"test_loss": 0.07272545993328094, "test_micro_f1": 0.7632221318144833, "test_micro_f1_no_misc": 0.7891350964974981, "test_runtime": 6.2557, "test_samples_per_second": 327.382, "test_steps_per_second": 10.231}]}, "total": {"test_micro_f1": 76.36500708146042, "test_micro_f1_se": 1.042580301850971, "test_micro_f1_no_misc": 78.85418355683423, "test_micro_f1_no_misc_se": 1.2288847280617368}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.04503868520259857, "test_micro_f1": 0.8247347237467983, "test_micro_f1_no_misc": 0.8617152236356175, "test_runtime": 5.663, "test_samples_per_second": 361.646, "test_steps_per_second": 11.301}, {"test_loss": 0.03767244890332222, "test_micro_f1": 0.8182154757497223, "test_micro_f1_no_misc": 0.8455551003687013, "test_runtime": 5.3726, "test_samples_per_second": 381.191, "test_steps_per_second": 11.912}, {"test_loss": 0.04340145364403725, "test_micro_f1": 0.8318708318708318, "test_micro_f1_no_misc": 0.8636363636363635, "test_runtime": 5.3983, "test_samples_per_second": 379.382, "test_steps_per_second": 11.856}, {"test_loss": 0.037908636033535004, "test_micro_f1": 0.8293539325842696, "test_micro_f1_no_misc": 0.8526645768025078, "test_runtime": 5.3202, "test_samples_per_second": 384.951, "test_steps_per_second": 12.03}, {"test_loss": 0.0425458624958992, "test_micro_f1": 0.8116133289343452, "test_micro_f1_no_misc": 0.8468335787923417, "test_runtime": 5.3788, "test_samples_per_second": 380.756, "test_steps_per_second": 11.899}, {"test_loss": 0.03719789907336235, "test_micro_f1": 0.8437077131258458, "test_micro_f1_no_misc": 0.8749524895477006, "test_runtime": 5.4936, "test_samples_per_second": 372.799, "test_steps_per_second": 11.65}, {"test_loss": 0.040978919714689255, "test_micro_f1": 0.8114864864864866, "test_micro_f1_no_misc": 0.846942650968477, "test_runtime": 5.5768, "test_samples_per_second": 367.237, "test_steps_per_second": 11.476}, {"test_loss": 0.040413014590740204, "test_micro_f1": 0.8186528497409327, "test_micro_f1_no_misc": 0.8461538461538461, "test_runtime": 5.0723, "test_samples_per_second": 403.765, "test_steps_per_second": 12.618}, {"test_loss": 0.040318578481674194, "test_micro_f1": 0.827930174563591, "test_micro_f1_no_misc": 0.8558882235528942, "test_runtime": 5.3302, "test_samples_per_second": 384.224, "test_steps_per_second": 12.007}, {"test_loss": 0.05078303813934326, "test_micro_f1": 0.8130464021519839, "test_micro_f1_no_misc": 0.8478747203579418, "test_runtime": 5.7005, "test_samples_per_second": 359.267, "test_steps_per_second": 11.227}]}, "total": {"test_micro_f1": 82.30611918954807, "test_micro_f1_se": 0.6461835643051264, "test_micro_f1_no_misc": 85.4221677381639, "test_micro_f1_no_misc_se": 0.6086211560641599}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.055252544581890106, "test_micro_f1": 0.776711056054506, "test_micro_f1_no_misc": 0.8160054719562243, "test_runtime": 5.5384, "test_samples_per_second": 369.785, "test_steps_per_second": 11.556}, {"test_loss": 0.06518559157848358, "test_micro_f1": 0.7473396169048343, "test_micro_f1_no_misc": 0.7872696817420436, "test_runtime": 5.7414, "test_samples_per_second": 356.706, "test_steps_per_second": 11.147}, {"test_loss": 0.06381165981292725, "test_micro_f1": 0.7499247667770087, "test_micro_f1_no_misc": 0.7894039735099339, "test_runtime": 5.4502, "test_samples_per_second": 375.766, "test_steps_per_second": 11.743}, {"test_loss": 0.07306791841983795, "test_micro_f1": 0.7020702070207021, "test_micro_f1_no_misc": 0.7432343234323433, "test_runtime": 5.7363, "test_samples_per_second": 357.024, "test_steps_per_second": 11.157}, {"test_loss": 0.07193338871002197, "test_micro_f1": 0.7727965843244892, "test_micro_f1_no_misc": 0.8171368861024032, "test_runtime": 5.4177, "test_samples_per_second": 378.022, "test_steps_per_second": 11.813}, {"test_loss": 0.06783739477396011, "test_micro_f1": 0.7249555423829284, "test_micro_f1_no_misc": 0.7733683174811413, "test_runtime": 5.6231, "test_samples_per_second": 364.214, "test_steps_per_second": 11.382}, {"test_loss": 0.060120947659015656, "test_micro_f1": 0.7666874610106053, "test_micro_f1_no_misc": 0.8034364261168385, "test_runtime": 5.7162, "test_samples_per_second": 358.278, "test_steps_per_second": 11.196}, {"test_loss": 0.05999111384153366, "test_micro_f1": 0.745742092457421, "test_micro_f1_no_misc": 0.7853820598006646, "test_runtime": 5.7324, "test_samples_per_second": 357.269, "test_steps_per_second": 11.165}, {"test_loss": 0.0675966739654541, "test_micro_f1": 0.7298461538461539, "test_micro_f1_no_misc": 0.7703398558187435, "test_runtime": 5.0372, "test_samples_per_second": 406.576, "test_steps_per_second": 12.706}, {"test_loss": 0.05450902879238129, "test_micro_f1": 0.7704066034851728, "test_micro_f1_no_misc": 0.8064729194187582, "test_runtime": 5.2532, "test_samples_per_second": 389.854, "test_steps_per_second": 12.183}]}, "total": {"test_micro_f1": 74.86480084263822, "test_micro_f1_se": 1.4992067322697522, "test_micro_f1_no_misc": 78.92049915379094, "test_micro_f1_no_misc_se": 1.4220422911759503}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.46610090136528015, "test_mcc": 0.5844493952194733, "test_macro_f1": 0.7922017896334381, "test_runtime": 2.8241, "test_samples_per_second": 725.19, "test_steps_per_second": 22.662}, {"test_loss": 0.5038473606109619, "test_mcc": 0.5101079103853735, "test_macro_f1": 0.7468445511571822, "test_runtime": 2.9533, "test_samples_per_second": 693.458, "test_steps_per_second": 21.671}, {"test_loss": 0.5130860805511475, "test_mcc": 0.5556462662429521, "test_macro_f1": 0.7704837864586367, "test_runtime": 2.9181, "test_samples_per_second": 701.834, "test_steps_per_second": 21.932}, {"test_loss": 0.49695444107055664, "test_mcc": 0.5691547635276718, "test_macro_f1": 0.777886795096153, "test_runtime": 2.8656, "test_samples_per_second": 714.678, "test_steps_per_second": 22.334}, {"test_loss": 0.49812740087509155, "test_mcc": 0.5315865188455241, "test_macro_f1": 0.7584173348067513, "test_runtime": 2.8795, "test_samples_per_second": 711.244, "test_steps_per_second": 22.226}, {"test_loss": 0.5112472772598267, "test_mcc": 0.5254611329703213, "test_macro_f1": 0.7536832946286216, "test_runtime": 2.858, "test_samples_per_second": 716.573, "test_steps_per_second": 22.393}, {"test_loss": 0.51027911901474, "test_mcc": 0.5806814402338811, "test_macro_f1": 0.7766175593723186, "test_runtime": 2.8674, "test_samples_per_second": 714.236, "test_steps_per_second": 22.32}, {"test_loss": 0.5278738737106323, "test_mcc": 0.5336415182417766, "test_macro_f1": 0.7526320388506968, "test_runtime": 2.9203, "test_samples_per_second": 701.295, "test_steps_per_second": 21.915}, {"test_loss": 0.5247868895530701, "test_mcc": 0.5360159071706969, "test_macro_f1": 0.7629432835318055, "test_runtime": 2.8729, "test_samples_per_second": 712.872, "test_steps_per_second": 22.277}, {"test_loss": 0.4870665669441223, "test_mcc": 0.5781375476529349, "test_macro_f1": 0.7840888180089554, "test_runtime": 2.8991, "test_samples_per_second": 706.438, "test_steps_per_second": 22.076}]}, "total": {"test_mcc": 55.04882400490605, "test_mcc_se": 1.6414121484867565, "test_macro_f1": 76.7579925154456, "test_macro_f1_se": 0.9301882408512812}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.5787222385406494, "test_mcc": 0.41427011635405747, "test_macro_f1": 0.6940609273894922, "test_runtime": 3.3415, "test_samples_per_second": 612.893, "test_steps_per_second": 19.153}, {"test_loss": 0.5660455226898193, "test_mcc": 0.44291526776872076, "test_macro_f1": 0.7023646464695561, "test_runtime": 3.5435, "test_samples_per_second": 577.963, "test_steps_per_second": 18.061}, {"test_loss": 0.6927890777587891, "test_mcc": 0.04395741196566576, "test_macro_f1": 0.5146875609353123, "test_runtime": 3.3451, "test_samples_per_second": 612.242, "test_steps_per_second": 19.133}, {"test_loss": 0.5642729997634888, "test_mcc": 0.5607894261922484, "test_macro_f1": 0.7765521203737209, "test_runtime": 3.5378, "test_samples_per_second": 578.893, "test_steps_per_second": 18.09}, {"test_loss": 0.5490695834159851, "test_mcc": 0.5517916363271284, "test_macro_f1": 0.7733525029907772, "test_runtime": 3.4127, "test_samples_per_second": 600.108, "test_steps_per_second": 18.753}, {"test_loss": 0.600106954574585, "test_mcc": 0.5324999073061841, "test_macro_f1": 0.7605017267067833, "test_runtime": 3.3791, "test_samples_per_second": 606.072, "test_steps_per_second": 18.94}, {"test_loss": 0.6047341823577881, "test_mcc": 0.3555364258324043, "test_macro_f1": 0.6736081597960051, "test_runtime": 3.3078, "test_samples_per_second": 619.139, "test_steps_per_second": 19.348}, {"test_loss": 0.5509105920791626, "test_mcc": 0.46578633688697124, "test_macro_f1": 0.725388184183003, "test_runtime": 3.3824, "test_samples_per_second": 605.483, "test_steps_per_second": 18.921}, {"test_loss": 0.6360596418380737, "test_mcc": 0.294639497303447, "test_macro_f1": 0.6202310313802859, "test_runtime": 3.3602, "test_samples_per_second": 609.488, "test_steps_per_second": 19.047}, {"test_loss": 0.5710471868515015, "test_mcc": 0.5265620525069208, "test_macro_f1": 0.7631672752720244, "test_runtime": 3.4293, "test_samples_per_second": 597.205, "test_steps_per_second": 18.663}]}, "total": {"test_mcc": 41.88748078443748, "test_mcc_se": 9.802676195198911, "test_macro_f1": 70.03914135496962, "test_macro_f1_se": 5.101675398212643}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.5206384658813477, "test_mcc": 0.4972029298401935, "test_macro_f1": 0.7361118344244157, "test_runtime": 2.9632, "test_samples_per_second": 691.154, "test_steps_per_second": 21.599}, {"test_loss": 0.5545074343681335, "test_mcc": 0.5377010740157945, "test_macro_f1": 0.7535633653286267, "test_runtime": 3.0257, "test_samples_per_second": 676.867, "test_steps_per_second": 21.152}, {"test_loss": 0.563159167766571, "test_mcc": 0.4813887474072905, "test_macro_f1": 0.7137833516867457, "test_runtime": 3.0006, "test_samples_per_second": 682.535, "test_steps_per_second": 21.329}, {"test_loss": 0.5120773911476135, "test_mcc": 0.5165772931694684, "test_macro_f1": 0.7582841263085611, "test_runtime": 3.0457, "test_samples_per_second": 672.414, "test_steps_per_second": 21.013}, {"test_loss": 0.6082291603088379, "test_mcc": 0.3957387238050361, "test_macro_f1": 0.6597030878471745, "test_runtime": 3.0722, "test_samples_per_second": 666.618, "test_steps_per_second": 20.832}, {"test_loss": 0.5021204352378845, "test_mcc": 0.5959941375261217, "test_macro_f1": 0.7927423974400486, "test_runtime": 2.9319, "test_samples_per_second": 698.527, "test_steps_per_second": 21.829}, {"test_loss": 0.550582766532898, "test_mcc": 0.46703661547076714, "test_macro_f1": 0.717978003851351, "test_runtime": 2.9352, "test_samples_per_second": 697.749, "test_steps_per_second": 21.805}, {"test_loss": 0.49673551321029663, "test_mcc": 0.5458689189503998, "test_macro_f1": 0.7728191706726039, "test_runtime": 2.9449, "test_samples_per_second": 695.446, "test_steps_per_second": 21.733}, {"test_loss": 0.6380451917648315, "test_mcc": 0.26975313241522164, "test_macro_f1": 0.5648026621113753, "test_runtime": 2.9305, "test_samples_per_second": 698.847, "test_steps_per_second": 21.839}, {"test_loss": 0.5430971384048462, "test_mcc": 0.5000837669008055, "test_macro_f1": 0.7301626196504902, "test_runtime": 3.0427, "test_samples_per_second": 673.082, "test_steps_per_second": 21.034}]}, "total": {"test_mcc": 48.07345339501098, "test_mcc_se": 5.6439929464140635, "test_macro_f1": 71.99950619321392, "test_macro_f1_se": 4.069644289492143}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_loss": 0.6413817405700684, "test_mcc": 0.24337687238250905, "test_macro_f1": 0.6145540785121388, "test_runtime": 3.3295, "test_samples_per_second": 615.104, "test_steps_per_second": 19.222}, {"test_loss": 0.5957268476486206, "test_mcc": 0.3781033503701886, "test_macro_f1": 0.6889647695934223, "test_runtime": 3.4167, "test_samples_per_second": 599.406, "test_steps_per_second": 18.731}, {"test_loss": 0.6441964507102966, "test_mcc": 0.28012303003487815, "test_macro_f1": 0.6389818848887869, "test_runtime": 3.4672, "test_samples_per_second": 590.677, "test_steps_per_second": 18.459}, {"test_loss": 0.6595081686973572, "test_mcc": 0.22763380579668416, "test_macro_f1": 0.5844139019897576, "test_runtime": 3.2398, "test_samples_per_second": 632.134, "test_steps_per_second": 19.754}, {"test_loss": 0.6095603704452515, "test_mcc": 0.3253556690376217, "test_macro_f1": 0.662109052762082, "test_runtime": 3.2957, "test_samples_per_second": 621.408, "test_steps_per_second": 19.419}, {"test_loss": 0.6530808210372925, "test_mcc": 0.24981523295886857, "test_macro_f1": 0.5899476264315214, "test_runtime": 3.463, "test_samples_per_second": 591.401, "test_steps_per_second": 18.481}, {"test_loss": 0.6518999338150024, "test_mcc": 0.24395009173892324, "test_macro_f1": 0.614706779564786, "test_runtime": 3.3475, "test_samples_per_second": 611.795, "test_steps_per_second": 19.119}, {"test_loss": 0.6166648864746094, "test_mcc": 0.34046087121793195, "test_macro_f1": 0.6658766319162888, "test_runtime": 3.3135, "test_samples_per_second": 618.072, "test_steps_per_second": 19.315}, {"test_loss": 0.6220531463623047, "test_mcc": 0.31515996984010425, "test_macro_f1": 0.6567586776542, "test_runtime": 3.3136, "test_samples_per_second": 618.061, "test_steps_per_second": 19.314}, {"test_loss": 0.6088791489601135, "test_mcc": 0.3773357042599162, "test_macro_f1": 0.6870139775179269, "test_runtime": 3.4031, "test_samples_per_second": 601.8, "test_steps_per_second": 18.806}]}, "total": {"test_mcc": 29.81314597637626, "test_mcc_se": 3.52158717627705, "test_macro_f1": 64.0332738083091, "test_macro_f1_se": 2.349217335108081}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_em": 38.41982958946553, "test_f1": 42.60632610199132}, {"test_em": 37.82945736434109, "test_f1": 41.698526988540664}, {"test_em": 36.244204018547144, "test_f1": 40.62573057560641}, {"test_em": 37.850467289719624, "test_f1": 42.45864810423489}, {"test_em": 36.602316602316606, "test_f1": 39.95979402958615}, {"test_em": 34.46414803392444, "test_f1": 38.5122475531156}, {"test_em": 37.12984054669704, "test_f1": 40.86413157385485}, {"test_em": 37.548487199379366, "test_f1": 41.373272545534796}, {"test_em": 36.94117647058823, "test_f1": 40.88832553896953}, {"test_em": 31.133540372670808, "test_f1": 34.489928356272614}]}, "total": {"test_em": 36.41634674876499, "test_em_se": 1.337613315299676, "test_f1": 40.34769313677069, "test_f1_se": 1.4740327980215486}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_em": 31.216111541440743, "test_f1": 35.80720152670401}, {"test_em": 38.992248062015506, "test_f1": 43.21980914861973}, {"test_em": 33.15301391035549, "test_f1": 37.86407348636093}, {"test_em": 34.42367601246106, "test_f1": 37.65140676829508}, {"test_em": 31.89189189189189, "test_f1": 36.29144872458721}, {"test_em": 36.46877409406322, "test_f1": 40.06262366682571}, {"test_em": 34.16856492027335, "test_f1": 38.717199540916916}, {"test_em": 37.00543056633049, "test_f1": 40.707535249281676}, {"test_em": 37.09803921568628, "test_f1": 41.59281042114512}, {"test_em": 36.49068322981366, "test_f1": 40.74437058632321}]}, "total": {"test_em": 35.09084334443317, "test_em_se": 1.5607887575049118, "test_f1": 39.26584791190596, "test_f1_se": 1.4845136465215925}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_em": 36.018590240123935, "test_f1": 40.76184079545753}, {"test_em": 34.883720930232556, "test_f1": 39.05402187551733}, {"test_em": 35.78052550231839, "test_f1": 40.6538306326765}, {"test_em": 35.90342679127726, "test_f1": 40.262496516300146}, {"test_em": 37.52895752895753, "test_f1": 42.433164958301965}, {"test_em": 37.31688511950655, "test_f1": 40.86758942563837}, {"test_em": 36.370539104024296, "test_f1": 40.32241072720421}, {"test_em": 32.5833979829325, "test_f1": 37.32581322104605}, {"test_em": 40.705882352941174, "test_f1": 44.588853489199515}, {"test_em": 42.2360248447205, "test_f1": 46.38898260236795}]}, "total": {"test_em": 36.932795039703464, "test_em_se": 1.7226029408188397, "test_f1": 41.265900424370955, "test_f1_se": 1.6235239717486}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.39846938848495483, "test_mcc": 0.7659231677391403, "test_macro_f1": 0.7642104225475205, "test_runtime": 12.9132, "test_samples_per_second": 158.598, "test_steps_per_second": 19.825}, {"test_loss": 0.3824273645877838, "test_mcc": 0.7573675618714109, "test_macro_f1": 0.734862066876607, "test_runtime": 12.2051, "test_samples_per_second": 167.798, "test_steps_per_second": 20.975}, {"test_loss": 0.39538705348968506, "test_mcc": 0.7628821532745909, "test_macro_f1": 0.7611895714473657, "test_runtime": 12.5279, "test_samples_per_second": 163.475, "test_steps_per_second": 20.434}, {"test_loss": 0.3302834630012512, "test_mcc": 0.7751573108639657, "test_macro_f1": 0.7540360011034947, "test_runtime": 11.9989, "test_samples_per_second": 170.683, "test_steps_per_second": 21.335}, {"test_loss": 0.36305636167526245, "test_mcc": 0.7669331824790386, "test_macro_f1": 0.7724112241735502, "test_runtime": 11.724, "test_samples_per_second": 174.685, "test_steps_per_second": 21.836}, {"test_loss": 0.3594934940338135, "test_mcc": 0.7742509470038652, "test_macro_f1": 0.766638452797511, "test_runtime": 12.3429, "test_samples_per_second": 165.925, "test_steps_per_second": 20.741}, {"test_loss": 0.36923354864120483, "test_mcc": 0.7656186422962081, "test_macro_f1": 0.7459149112103404, "test_runtime": 11.6565, "test_samples_per_second": 175.696, "test_steps_per_second": 21.962}, {"test_loss": 0.37427401542663574, "test_mcc": 0.7657239806897795, "test_macro_f1": 0.7348088630297219, "test_runtime": 12.7341, "test_samples_per_second": 160.829, "test_steps_per_second": 20.104}, {"test_loss": 0.4182493984699249, "test_mcc": 0.7303614184481647, "test_macro_f1": 0.7172447942152308, "test_runtime": 12.6342, "test_samples_per_second": 162.099, "test_steps_per_second": 20.262}, {"test_loss": 0.3834857642650604, "test_mcc": 0.7577574070636639, "test_macro_f1": 0.773803804660087, "test_runtime": 12.1828, "test_samples_per_second": 168.105, "test_steps_per_second": 21.013}]}, "total": {"test_mcc": 76.21975771729828, "test_mcc_se": 0.7814744514485427, "test_macro_f1": 75.25120112061428, "test_macro_f1_se": 1.1642486588217893}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.927122175693512, "test_mcc": 0.3511159526684153, "test_macro_f1": 0.5613021249630958, "test_runtime": 5.0678, "test_samples_per_second": 404.117, "test_steps_per_second": 12.629}, {"test_loss": 0.9275848865509033, "test_mcc": 0.394549602611519, "test_macro_f1": 0.5889365143679798, "test_runtime": 5.0844, "test_samples_per_second": 402.804, "test_steps_per_second": 12.588}, {"test_loss": 0.968218982219696, "test_mcc": 0.3419335455588484, "test_macro_f1": 0.5604145180361225, "test_runtime": 5.0747, "test_samples_per_second": 403.569, "test_steps_per_second": 12.612}, {"test_loss": 0.9409409761428833, "test_mcc": 0.37474677208906926, "test_macro_f1": 0.5824330131802626, "test_runtime": 5.0336, "test_samples_per_second": 406.869, "test_steps_per_second": 12.715}, {"test_loss": 0.9205537438392639, "test_mcc": 0.37268518427110303, "test_macro_f1": 0.5828412215652546, "test_runtime": 5.0177, "test_samples_per_second": 408.153, "test_steps_per_second": 12.755}, {"test_loss": 0.9633595943450928, "test_mcc": 0.35242199372591176, "test_macro_f1": 0.5594716709387422, "test_runtime": 5.1288, "test_samples_per_second": 399.314, "test_steps_per_second": 12.479}, {"test_loss": 0.9259862899780273, "test_mcc": 0.37177570012242467, "test_macro_f1": 0.5824660600363657, "test_runtime": 5.0816, "test_samples_per_second": 403.02, "test_steps_per_second": 12.594}, {"test_loss": 0.9066605567932129, "test_mcc": 0.35530487694807833, "test_macro_f1": 0.5715093278732949, "test_runtime": 5.1884, "test_samples_per_second": 394.725, "test_steps_per_second": 12.335}, {"test_loss": 0.8959126472473145, "test_mcc": 0.40339214502107945, "test_macro_f1": 0.5956891794417215, "test_runtime": 5.0877, "test_samples_per_second": 402.538, "test_steps_per_second": 12.579}, {"test_loss": 0.9410055875778198, "test_mcc": 0.34847825555747763, "test_macro_f1": 0.5633770205716471, "test_runtime": 5.0187, "test_samples_per_second": 408.073, "test_steps_per_second": 12.752}]}, "total": {"test_mcc": 36.66404028573927, "test_mcc_se": 1.2685768668271524, "test_macro_f1": 57.484406509744865, "test_macro_f1_se": 0.8220785687019188}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.8484140634536743, "test_mcc": 0.39054911941486115, "test_macro_f1": 0.5431285095427266, "test_runtime": 3.9572, "test_samples_per_second": 517.535, "test_steps_per_second": 16.173}, {"test_loss": 0.8876748085021973, "test_mcc": 0.38110595004258363, "test_macro_f1": 0.5120290866095775, "test_runtime": 3.7308, "test_samples_per_second": 548.937, "test_steps_per_second": 17.154}, {"test_loss": 0.8684368133544922, "test_mcc": 0.3443623016149373, "test_macro_f1": 0.4856488565129487, "test_runtime": 3.699, "test_samples_per_second": 553.661, "test_steps_per_second": 17.302}, {"test_loss": 0.8822888731956482, "test_mcc": 0.39094064418651847, "test_macro_f1": 0.5658095774379712, "test_runtime": 3.8285, "test_samples_per_second": 534.939, "test_steps_per_second": 16.717}, {"test_loss": 0.9428098201751709, "test_mcc": 0.3704772152000017, "test_macro_f1": 0.5384882700077477, "test_runtime": 3.8581, "test_samples_per_second": 530.825, "test_steps_per_second": 16.588}, {"test_loss": 0.9524965882301331, "test_mcc": 0.23419567256317717, "test_macro_f1": 0.3946132434815737, "test_runtime": 3.8998, "test_samples_per_second": 525.16, "test_steps_per_second": 16.411}, {"test_loss": 0.817939043045044, "test_mcc": 0.4056614135262354, "test_macro_f1": 0.5565866895760766, "test_runtime": 3.7895, "test_samples_per_second": 540.445, "test_steps_per_second": 16.889}, {"test_loss": 0.8274735808372498, "test_mcc": 0.3716826199619605, "test_macro_f1": 0.5191231740132474, "test_runtime": 3.855, "test_samples_per_second": 531.253, "test_steps_per_second": 16.602}, {"test_loss": 0.835671603679657, "test_mcc": 0.39688567868786695, "test_macro_f1": 0.5097210473318978, "test_runtime": 3.9243, "test_samples_per_second": 521.87, "test_steps_per_second": 16.308}, {"test_loss": 0.8612326383590698, "test_mcc": 0.36970986622632696, "test_macro_f1": 0.4994794617971429, "test_runtime": 3.9419, "test_samples_per_second": 519.545, "test_steps_per_second": 16.236}]}, "total": {"test_mcc": 36.55570481424469, "test_mcc_se": 3.0563535954121575, "test_macro_f1": 51.24627916310909, "test_macro_f1_se": 3.010913133037696}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.06932070851325989, "test_micro_f1": 0.6690833764888658, "test_micro_f1_no_misc": 0.7203242617255357, "test_runtime": 6.1182, "test_samples_per_second": 334.738, "test_steps_per_second": 10.461}, {"test_loss": 0.06290052831172943, "test_micro_f1": 0.6616702355460387, "test_micro_f1_no_misc": 0.7295522388059702, "test_runtime": 5.6115, "test_samples_per_second": 364.967, "test_steps_per_second": 11.405}, {"test_loss": 0.0547260120511055, "test_micro_f1": 0.7400098667982239, "test_micro_f1_no_misc": 0.7850467289719627, "test_runtime": 5.5804, "test_samples_per_second": 366.998, "test_steps_per_second": 11.469}, {"test_loss": 0.0548492968082428, "test_micro_f1": 0.7235732009925558, "test_micro_f1_no_misc": 0.7695774647887326, "test_runtime": 6.0142, "test_samples_per_second": 340.529, "test_steps_per_second": 10.642}, {"test_loss": 0.06247129663825035, "test_micro_f1": 0.702363724071394, "test_micro_f1_no_misc": 0.7415966386554623, "test_runtime": 6.0813, "test_samples_per_second": 336.773, "test_steps_per_second": 10.524}, {"test_loss": 0.0632314458489418, "test_micro_f1": 0.7005960568546539, "test_micro_f1_no_misc": 0.7566137566137565, "test_runtime": 4.8698, "test_samples_per_second": 420.555, "test_steps_per_second": 13.142}, {"test_loss": 0.061526186764240265, "test_micro_f1": 0.7337986041874377, "test_micro_f1_no_misc": 0.7794361525704809, "test_runtime": 5.3245, "test_samples_per_second": 384.64, "test_steps_per_second": 12.02}, {"test_loss": 0.05456960201263428, "test_micro_f1": 0.7060109289617487, "test_micro_f1_no_misc": 0.7544080604534006, "test_runtime": 6.0664, "test_samples_per_second": 337.6, "test_steps_per_second": 10.55}, {"test_loss": 0.05968160927295685, "test_micro_f1": 0.6870078740157479, "test_micro_f1_no_misc": 0.7278514588859416, "test_runtime": 5.6347, "test_samples_per_second": 363.462, "test_steps_per_second": 11.358}, {"test_loss": 0.05489630252122879, "test_micro_f1": 0.7207920792079208, "test_micro_f1_no_misc": 0.7755102040816326, "test_runtime": 6.0071, "test_samples_per_second": 340.93, "test_steps_per_second": 10.654}]}, "total": {"test_micro_f1": 70.44905947124587, "test_micro_f1_se": 1.6222366090641638, "test_micro_f1_no_misc": 75.39916965552875, "test_micro_f1_no_misc_se": 1.4451194330060164}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.07797345519065857, "test_micro_f1": 0.7475477542591635, "test_micro_f1_no_misc": 0.7703498441288535, "test_runtime": 8.7832, "test_samples_per_second": 233.172, "test_steps_per_second": 7.287}, {"test_loss": 0.0701901987195015, "test_micro_f1": 0.7782122905027932, "test_micro_f1_no_misc": 0.8013148283418554, "test_runtime": 7.4024, "test_samples_per_second": 276.666, "test_steps_per_second": 8.646}, {"test_loss": 0.08401628583669662, "test_micro_f1": 0.7318098240084056, "test_micro_f1_no_misc": 0.7708553326293559, "test_runtime": 9.158, "test_samples_per_second": 223.63, "test_steps_per_second": 6.988}, {"test_loss": 0.08350181579589844, "test_micro_f1": 0.747598719316969, "test_micro_f1_no_misc": 0.7762362148701529, "test_runtime": 8.738, "test_samples_per_second": 234.377, "test_steps_per_second": 7.324}, {"test_loss": 0.09281983226537704, "test_micro_f1": 0.7280975333144315, "test_micro_f1_no_misc": 0.7551644988523335, "test_runtime": 9.293, "test_samples_per_second": 220.381, "test_steps_per_second": 6.887}, {"test_loss": 0.08018000423908234, "test_micro_f1": 0.7701441899915181, "test_micro_f1_no_misc": 0.7878086419753086, "test_runtime": 8.6967, "test_samples_per_second": 235.493, "test_steps_per_second": 7.359}, {"test_loss": 0.08172502368688583, "test_micro_f1": 0.7426606717799523, "test_micro_f1_no_misc": 0.7652482269503545, "test_runtime": 9.4255, "test_samples_per_second": 217.283, "test_steps_per_second": 6.79}, {"test_loss": 0.07371969521045685, "test_micro_f1": 0.7470010905125408, "test_micro_f1_no_misc": 0.7829660067239447, "test_runtime": 8.7373, "test_samples_per_second": 234.398, "test_steps_per_second": 7.325}, {"test_loss": 0.0790497288107872, "test_micro_f1": 0.7504051863857375, "test_micro_f1_no_misc": 0.7726586102719033, "test_runtime": 8.595, "test_samples_per_second": 238.277, "test_steps_per_second": 7.446}, {"test_loss": 0.08144780993461609, "test_micro_f1": 0.7329591018444267, "test_micro_f1_no_misc": 0.7657466383581033, "test_runtime": 7.2711, "test_samples_per_second": 281.664, "test_steps_per_second": 8.802}]}, "total": {"test_micro_f1": 74.76436361915938, "test_micro_f1_se": 0.9955550297795563, "test_micro_f1_no_misc": 77.48348843102167, "test_micro_f1_no_misc_se": 0.810685729727967}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.06729159504175186, "test_micro_f1": 0.7547445255474451, "test_micro_f1_no_misc": 0.7877049180327869, "test_runtime": 6.8319, "test_samples_per_second": 299.771, "test_steps_per_second": 9.368}, {"test_loss": 0.057667553424835205, "test_micro_f1": 0.777079482439926, "test_micro_f1_no_misc": 0.7957254418413482, "test_runtime": 6.731, "test_samples_per_second": 304.265, "test_steps_per_second": 9.508}, {"test_loss": 0.0709337443113327, "test_micro_f1": 0.7518796992481201, "test_micro_f1_no_misc": 0.7771384733410049, "test_runtime": 6.4133, "test_samples_per_second": 319.338, "test_steps_per_second": 9.979}, {"test_loss": 0.059905003756284714, "test_micro_f1": 0.7546247818499127, "test_micro_f1_no_misc": 0.7815289095847885, "test_runtime": 6.5304, "test_samples_per_second": 313.61, "test_steps_per_second": 9.8}, {"test_loss": 0.05998089537024498, "test_micro_f1": 0.7956421261142292, "test_micro_f1_no_misc": 0.819769602378298, "test_runtime": 6.8156, "test_samples_per_second": 300.486, "test_steps_per_second": 9.39}, {"test_loss": 0.05779770389199257, "test_micro_f1": 0.782726963617817, "test_micro_f1_no_misc": 0.8144212523719164, "test_runtime": 6.8257, "test_samples_per_second": 300.042, "test_steps_per_second": 9.376}, {"test_loss": 0.07037048041820526, "test_micro_f1": 0.7423521414004078, "test_micro_f1_no_misc": 0.7619405791650997, "test_runtime": 6.2328, "test_samples_per_second": 328.582, "test_steps_per_second": 10.268}, {"test_loss": 0.060804903507232666, "test_micro_f1": 0.7530949105914719, "test_micro_f1_no_misc": 0.7743589743589743, "test_runtime": 6.2975, "test_samples_per_second": 325.208, "test_steps_per_second": 10.163}, {"test_loss": 0.05140426382422447, "test_micro_f1": 0.7923987092147724, "test_micro_f1_no_misc": 0.8172730907636946, "test_runtime": 6.3547, "test_samples_per_second": 322.28, "test_steps_per_second": 10.071}, {"test_loss": 0.06833762675523758, "test_micro_f1": 0.7684964200477328, "test_micro_f1_no_misc": 0.795601061812666, "test_runtime": 6.4853, "test_samples_per_second": 315.791, "test_steps_per_second": 9.868}]}, "total": {"test_micro_f1": 76.73039760071835, "test_micro_f1_se": 1.1592845502047608, "test_micro_f1_no_misc": 79.25462303650576, "test_micro_f1_no_misc_se": 1.2223072903260654}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.07384791970252991, "test_micro_f1": 0.7239488117001828, "test_micro_f1_no_misc": 0.7601476014760148, "test_runtime": 6.3596, "test_samples_per_second": 322.034, "test_steps_per_second": 10.064}, {"test_loss": 0.06979462504386902, "test_micro_f1": 0.7153984421809468, "test_micro_f1_no_misc": 0.7519788918205804, "test_runtime": 6.5058, "test_samples_per_second": 314.797, "test_steps_per_second": 9.837}, {"test_loss": 0.07534341514110565, "test_micro_f1": 0.6938053097345132, "test_micro_f1_no_misc": 0.7371502927781393, "test_runtime": 6.1118, "test_samples_per_second": 335.087, "test_steps_per_second": 10.471}, {"test_loss": 0.07813134789466858, "test_micro_f1": 0.7048984468339307, "test_micro_f1_no_misc": 0.7436152570480928, "test_runtime": 6.3472, "test_samples_per_second": 322.66, "test_steps_per_second": 10.083}, {"test_loss": 0.07648029923439026, "test_micro_f1": 0.6914893617021276, "test_micro_f1_no_misc": 0.7395798599533178, "test_runtime": 6.077, "test_samples_per_second": 337.009, "test_steps_per_second": 10.532}, {"test_loss": 0.07009623944759369, "test_micro_f1": 0.75413782726452, "test_micro_f1_no_misc": 0.7831120190670753, "test_runtime": 6.0976, "test_samples_per_second": 335.868, "test_steps_per_second": 10.496}, {"test_loss": 0.0659579262137413, "test_micro_f1": 0.708680877355576, "test_micro_f1_no_misc": 0.7528696826468603, "test_runtime": 6.5302, "test_samples_per_second": 313.618, "test_steps_per_second": 9.801}, {"test_loss": 0.06591295450925827, "test_micro_f1": 0.7416974169741697, "test_micro_f1_no_misc": 0.7768195929630907, "test_runtime": 6.6167, "test_samples_per_second": 309.519, "test_steps_per_second": 9.672}, {"test_loss": 0.07865308225154877, "test_micro_f1": 0.6975308641975309, "test_micro_f1_no_misc": 0.7329700272479563, "test_runtime": 6.0523, "test_samples_per_second": 338.385, "test_steps_per_second": 10.575}, {"test_loss": 0.0660780519247055, "test_micro_f1": 0.7313797313797313, "test_micro_f1_no_misc": 0.7609627431585887, "test_runtime": 6.1182, "test_samples_per_second": 334.739, "test_steps_per_second": 10.461}]}, "total": {"test_micro_f1": 71.62967089323229, "test_micro_f1_se": 1.3108007972964515, "test_micro_f1_no_misc": 75.39205968159717, "test_micro_f1_no_misc_se": 1.033376619333123}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.45477327704429626, "test_mcc": 0.6229579414400814, "test_macro_f1": 0.7905699076066517, "test_runtime": 2.6862, "test_samples_per_second": 762.42, "test_steps_per_second": 23.826}, {"test_loss": 0.4496050775051117, "test_mcc": 0.6958460572283897, "test_macro_f1": 0.8360327772392073, "test_runtime": 2.7732, "test_samples_per_second": 738.493, "test_steps_per_second": 23.078}, {"test_loss": 0.4375540018081665, "test_mcc": 0.6696698763302898, "test_macro_f1": 0.8244580547633519, "test_runtime": 2.7803, "test_samples_per_second": 736.609, "test_steps_per_second": 23.019}, {"test_loss": 0.417968213558197, "test_mcc": 0.6592088490710649, "test_macro_f1": 0.8223682128318884, "test_runtime": 2.727, "test_samples_per_second": 751.014, "test_steps_per_second": 23.469}, {"test_loss": 0.4324163794517517, "test_mcc": 0.6551771405350196, "test_macro_f1": 0.8132266195842104, "test_runtime": 2.782, "test_samples_per_second": 736.156, "test_steps_per_second": 23.005}, {"test_loss": 0.4254652261734009, "test_mcc": 0.687585856212081, "test_macro_f1": 0.8342275670675301, "test_runtime": 2.7602, "test_samples_per_second": 741.966, "test_steps_per_second": 23.186}, {"test_loss": 0.4047740399837494, "test_mcc": 0.6730646907955161, "test_macro_f1": 0.8254543909347074, "test_runtime": 2.7646, "test_samples_per_second": 740.804, "test_steps_per_second": 23.15}, {"test_loss": 0.48004966974258423, "test_mcc": 0.6120252893655677, "test_macro_f1": 0.7881445161490852, "test_runtime": 2.787, "test_samples_per_second": 734.849, "test_steps_per_second": 22.964}, {"test_loss": 0.395865261554718, "test_mcc": 0.6687957079832814, "test_macro_f1": 0.8238428114981915, "test_runtime": 2.795, "test_samples_per_second": 732.732, "test_steps_per_second": 22.898}, {"test_loss": 0.45576852560043335, "test_mcc": 0.6287387155837393, "test_macro_f1": 0.79132387857623, "test_runtime": 2.7422, "test_samples_per_second": 746.844, "test_steps_per_second": 23.339}]}, "total": {"test_mcc": 65.7307012454503, "test_mcc_se": 1.7272971125314154, "test_macro_f1": 81.49648736251054, "test_macro_f1_se": 1.1363211093067667}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.6352417469024658, "test_mcc": 0.31258881515654974, "test_macro_f1": 0.6558706154169291, "test_runtime": 4.2003, "test_samples_per_second": 487.584, "test_steps_per_second": 15.237}, {"test_loss": 0.6804337501525879, "test_mcc": 0.16015397275830906, "test_macro_f1": 0.5691300635384171, "test_runtime": 4.4668, "test_samples_per_second": 458.498, "test_steps_per_second": 14.328}, {"test_loss": 0.6913511753082275, "test_mcc": 0.03270647940410246, "test_macro_f1": 0.47569549730089866, "test_runtime": 4.3726, "test_samples_per_second": 468.372, "test_steps_per_second": 14.637}, {"test_loss": 0.6580318808555603, "test_mcc": 0.27046519419660475, "test_macro_f1": 0.5988753098198375, "test_runtime": 4.603, "test_samples_per_second": 444.93, "test_steps_per_second": 13.904}, {"test_loss": 0.6636557579040527, "test_mcc": 0.25431360062584546, "test_macro_f1": 0.6104123998584643, "test_runtime": 4.3467, "test_samples_per_second": 471.166, "test_steps_per_second": 14.724}, {"test_loss": 0.6670974493026733, "test_mcc": 0.1948882734671796, "test_macro_f1": 0.5928742990541744, "test_runtime": 4.2928, "test_samples_per_second": 477.083, "test_steps_per_second": 14.909}, {"test_loss": 0.6482930779457092, "test_mcc": 0.2908431948057975, "test_macro_f1": 0.6347516301335118, "test_runtime": 4.1104, "test_samples_per_second": 498.25, "test_steps_per_second": 15.57}, {"test_loss": 0.6691251397132874, "test_mcc": 0.19090889681721152, "test_macro_f1": 0.5591449395283794, "test_runtime": 4.1619, "test_samples_per_second": 492.082, "test_steps_per_second": 15.378}, {"test_loss": 0.6658328175544739, "test_mcc": 0.24146579830793707, "test_macro_f1": 0.6074844400115387, "test_runtime": 4.2107, "test_samples_per_second": 486.375, "test_steps_per_second": 15.199}, {"test_loss": 0.6402430534362793, "test_mcc": 0.32021301744964914, "test_macro_f1": 0.6417456191320836, "test_runtime": 4.4609, "test_samples_per_second": 459.1, "test_steps_per_second": 14.347}]}, "total": {"test_mcc": 22.68547242989186, "test_mcc_se": 5.367142828906026, "test_macro_f1": 59.45984813794235, "test_macro_f1_se": 3.2053513409079484}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.6437262296676636, "test_mcc": 0.28109042384278843, "test_macro_f1": 0.6375522351402989, "test_runtime": 3.7919, "test_samples_per_second": 540.092, "test_steps_per_second": 16.878}, {"test_loss": 0.6854385137557983, "test_mcc": 0.14572010479616876, "test_macro_f1": 0.4857991484002438, "test_runtime": 3.8114, "test_samples_per_second": 537.338, "test_steps_per_second": 16.792}, {"test_loss": 0.6510283350944519, "test_mcc": 0.3276154709598297, "test_macro_f1": 0.6424410602970256, "test_runtime": 3.8266, "test_samples_per_second": 535.201, "test_steps_per_second": 16.725}, {"test_loss": 0.6853352785110474, "test_mcc": 0.12537780158114942, "test_macro_f1": 0.5400411332048544, "test_runtime": 3.9114, "test_samples_per_second": 523.596, "test_steps_per_second": 16.362}, {"test_loss": 0.6663923263549805, "test_mcc": 0.20739655876768173, "test_macro_f1": 0.5502277439798295, "test_runtime": 3.8528, "test_samples_per_second": 531.559, "test_steps_per_second": 16.611}, {"test_loss": 0.6898807287216187, "test_mcc": 0.06760052383327673, "test_macro_f1": 0.5336779534893923, "test_runtime": 3.7027, "test_samples_per_second": 553.115, "test_steps_per_second": 17.285}, {"test_loss": 0.6434842944145203, "test_mcc": 0.29531132263376, "test_macro_f1": 0.6469624715945871, "test_runtime": 3.7359, "test_samples_per_second": 548.193, "test_steps_per_second": 17.131}, {"test_loss": 0.6508033275604248, "test_mcc": 0.26480540038919786, "test_macro_f1": 0.5832518985333999, "test_runtime": 3.7648, "test_samples_per_second": 543.98, "test_steps_per_second": 16.999}, {"test_loss": 0.6767669916152954, "test_mcc": 0.19369342264449946, "test_macro_f1": 0.5141398353197565, "test_runtime": 3.764, "test_samples_per_second": 544.106, "test_steps_per_second": 17.003}, {"test_loss": 0.6515256762504578, "test_mcc": 0.2930843448432557, "test_macro_f1": 0.6110033624068131, "test_runtime": 3.8848, "test_samples_per_second": 527.179, "test_steps_per_second": 16.474}]}, "total": {"test_mcc": 22.01695374291608, "test_mcc_se": 5.343005739205402, "test_macro_f1": 57.450968423662005, "test_macro_f1_se": 3.5906987229970886}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_loss": 0.659905195236206, "test_mcc": 0.24625031601599345, "test_macro_f1": 0.6230821507267508, "test_runtime": 3.7968, "test_samples_per_second": 539.397, "test_steps_per_second": 16.856}, {"test_loss": 0.6684455871582031, "test_mcc": 0.24394353953097953, "test_macro_f1": 0.5617741993979617, "test_runtime": 3.9413, "test_samples_per_second": 519.619, "test_steps_per_second": 16.238}, {"test_loss": 0.6559387445449829, "test_mcc": 0.2452865141351858, "test_macro_f1": 0.6223424063009091, "test_runtime": 4.0283, "test_samples_per_second": 508.409, "test_steps_per_second": 15.888}, {"test_loss": 0.6644446849822998, "test_mcc": 0.22433386158384538, "test_macro_f1": 0.5690573673434051, "test_runtime": 3.7915, "test_samples_per_second": 540.159, "test_steps_per_second": 16.88}, {"test_loss": 0.6534299850463867, "test_mcc": 0.2607678806573326, "test_macro_f1": 0.6169072966726226, "test_runtime": 3.8731, "test_samples_per_second": 528.774, "test_steps_per_second": 16.524}, {"test_loss": 0.6726229786872864, "test_mcc": 0.19655765302455405, "test_macro_f1": 0.5612368778118975, "test_runtime": 3.95, "test_samples_per_second": 518.483, "test_steps_per_second": 16.203}, {"test_loss": 0.6699601411819458, "test_mcc": 0.2066445669171953, "test_macro_f1": 0.5739838731924444, "test_runtime": 3.8502, "test_samples_per_second": 531.925, "test_steps_per_second": 16.623}, {"test_loss": 0.6850478649139404, "test_mcc": 0.11747774551956165, "test_macro_f1": 0.5523993554214705, "test_runtime": 3.841, "test_samples_per_second": 533.193, "test_steps_per_second": 16.662}, {"test_loss": 0.6868271231651306, "test_mcc": 0.10723462638516698, "test_macro_f1": 0.4956868870953745, "test_runtime": 3.8621, "test_samples_per_second": 530.278, "test_steps_per_second": 16.571}, {"test_loss": 0.6848232746124268, "test_mcc": 0.12373848444279636, "test_macro_f1": 0.49357072205736896, "test_runtime": 3.9166, "test_samples_per_second": 522.901, "test_steps_per_second": 16.341}]}, "total": {"test_mcc": 19.72235188212611, "test_mcc_se": 3.6735658263260933, "test_macro_f1": 56.70041136020204, "test_macro_f1_se": 2.8852530917849624}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_em": 35.86367157242448, "test_f1": 39.71409776212255}, {"test_em": 34.34108527131783, "test_f1": 37.71904800119576}, {"test_em": 26.27511591962906, "test_f1": 29.3283614564377}, {"test_em": 30.218068535825545, "test_f1": 34.035087204754596}, {"test_em": 29.034749034749034, "test_f1": 32.24603422922752}, {"test_em": 31.688511950655357, "test_f1": 34.84742369215589}, {"test_em": 28.32194381169324, "test_f1": 32.415007117469095}, {"test_em": 26.842513576415826, "test_f1": 30.02912809465997}, {"test_em": 38.666666666666664, "test_f1": 42.485166685166675}, {"test_em": 34.70496894409938, "test_f1": 39.09953267497544}]}, "total": {"test_em": 31.595729528347647, "test_em_se": 2.5763433762050165, "test_f1": 35.191888691816516, "test_f1_se": 2.7266748959234555}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_em": 35.47637490317583, "test_f1": 39.59120901558185}, {"test_em": 31.085271317829456, "test_f1": 35.415534467266056}, {"test_em": 27.51159196290572, "test_f1": 31.852195479110147}, {"test_em": 31.230529595015575, "test_f1": 35.025723021549254}, {"test_em": 34.20849420849421, "test_f1": 39.164580048019474}, {"test_em": 35.08095605242868, "test_f1": 38.99036688539614}, {"test_em": 35.07972665148064, "test_f1": 39.01441702343696}, {"test_em": 27.075252133436774, "test_f1": 31.12763159914936}, {"test_em": 32.627450980392155, "test_f1": 37.17687816072448}, {"test_em": 37.34472049689441, "test_f1": 42.153443893439665}]}, "total": {"test_em": 32.67203683020534, "test_em_se": 2.1292131731094726, "test_f1": 36.95119795936734, "test_f1_se": 2.1998768835216813}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_em": 35.78621223857475, "test_f1": 40.222222243222454}, {"test_em": 36.58914728682171, "test_f1": 40.55233414919372}, {"test_em": 40.57187017001546, "test_f1": 45.1877858567844}, {"test_em": 39.953271028037385, "test_f1": 44.67205819237372}, {"test_em": 39.07335907335907, "test_f1": 43.98803434268694}, {"test_em": 39.4757131842714, "test_f1": 43.17027289266984}, {"test_em": 34.700075930144266, "test_f1": 39.05061878696249}, {"test_em": 41.34988363072149, "test_f1": 45.184190920737386}, {"test_em": 34.19607843137255, "test_f1": 39.51351915992195}, {"test_em": 35.714285714285715, "test_f1": 40.12236328858086}]}, "total": {"test_em": 37.74098966876038, "test_em_se": 1.623972195700287, "test_f1": 42.16633998331337, "test_f1_se": 1.5481279062936868}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.35086870193481445, "test_mcc": 0.7663461446596956, "test_macro_f1": 0.7714958848080754, "test_runtime": 13.5088, "test_samples_per_second": 151.605, "test_steps_per_second": 18.951}, {"test_loss": 0.41188696026802063, "test_mcc": 0.7372653811342081, "test_macro_f1": 0.6927973179376304, "test_runtime": 12.7166, "test_samples_per_second": 161.049, "test_steps_per_second": 20.131}, {"test_loss": 0.39059847593307495, "test_mcc": 0.7434807313283281, "test_macro_f1": 0.7263487100052334, "test_runtime": 13.2789, "test_samples_per_second": 154.23, "test_steps_per_second": 19.279}, {"test_loss": 0.38161700963974, "test_mcc": 0.7838280457483308, "test_macro_f1": 0.755876448096508, "test_runtime": 12.572, "test_samples_per_second": 162.901, "test_steps_per_second": 20.363}, {"test_loss": 0.3706563711166382, "test_mcc": 0.7719574149204476, "test_macro_f1": 0.7207513104990654, "test_runtime": 12.4603, "test_samples_per_second": 164.362, "test_steps_per_second": 20.545}, {"test_loss": 0.35743477940559387, "test_mcc": 0.759908600795751, "test_macro_f1": 0.7217970955909406, "test_runtime": 12.8368, "test_samples_per_second": 159.542, "test_steps_per_second": 19.943}, {"test_loss": 0.3675215244293213, "test_mcc": 0.7689010972811946, "test_macro_f1": 0.71123858168214, "test_runtime": 12.3527, "test_samples_per_second": 165.794, "test_steps_per_second": 20.724}, {"test_loss": 0.39567190408706665, "test_mcc": 0.7428220244555265, "test_macro_f1": 0.6768401104867247, "test_runtime": 13.2204, "test_samples_per_second": 154.913, "test_steps_per_second": 19.364}, {"test_loss": 0.3917893171310425, "test_mcc": 0.7530632340072331, "test_macro_f1": 0.7256549939137042, "test_runtime": 13.1165, "test_samples_per_second": 156.139, "test_steps_per_second": 19.517}, {"test_loss": 0.4102492928504944, "test_mcc": 0.7761024810793646, "test_macro_f1": 0.7579342375833485, "test_runtime": 12.82, "test_samples_per_second": 159.751, "test_steps_per_second": 19.969}]}, "total": {"test_mcc": 76.03675155410079, "test_mcc_se": 0.973698351716162, "test_macro_f1": 72.6073469060337, "test_macro_f1_se": 1.8205254160323794}}, "num_model_parameters": 135195651, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.8958637714385986, "test_mcc": 0.3776193269820467, "test_macro_f1": 0.5875036057578042, "test_runtime": 5.2475, "test_samples_per_second": 390.279, "test_steps_per_second": 12.196}, {"test_loss": 0.9137706756591797, "test_mcc": 0.40450096203628494, "test_macro_f1": 0.5897528155039721, "test_runtime": 5.1626, "test_samples_per_second": 396.698, "test_steps_per_second": 12.397}, {"test_loss": 0.9327965974807739, "test_mcc": 0.38082020614468876, "test_macro_f1": 0.5841670256364077, "test_runtime": 5.1391, "test_samples_per_second": 398.515, "test_steps_per_second": 12.454}, {"test_loss": 0.8932543396949768, "test_mcc": 0.40432938959533, "test_macro_f1": 0.6019910615603936, "test_runtime": 5.1313, "test_samples_per_second": 399.116, "test_steps_per_second": 12.472}, {"test_loss": 0.8930315971374512, "test_mcc": 0.38546158035787165, "test_macro_f1": 0.5941983870674359, "test_runtime": 5.1157, "test_samples_per_second": 400.336, "test_steps_per_second": 12.511}, {"test_loss": 0.9656027555465698, "test_mcc": 0.38263132616086076, "test_macro_f1": 0.5874410696241518, "test_runtime": 5.1703, "test_samples_per_second": 396.109, "test_steps_per_second": 12.378}, {"test_loss": 0.8944831490516663, "test_mcc": 0.3808110808334521, "test_macro_f1": 0.5741954484138693, "test_runtime": 5.1426, "test_samples_per_second": 398.243, "test_steps_per_second": 12.445}, {"test_loss": 0.9368463754653931, "test_mcc": 0.36291228281037297, "test_macro_f1": 0.5668544526930853, "test_runtime": 5.1255, "test_samples_per_second": 399.573, "test_steps_per_second": 12.487}, {"test_loss": 0.9163033366203308, "test_mcc": 0.37953330698734494, "test_macro_f1": 0.5756266778554756, "test_runtime": 5.1224, "test_samples_per_second": 399.815, "test_steps_per_second": 12.494}, {"test_loss": 0.9333057403564453, "test_mcc": 0.3878032112165278, "test_macro_f1": 0.5954866946802972, "test_runtime": 5.0964, "test_samples_per_second": 401.854, "test_steps_per_second": 12.558}]}, "total": {"test_mcc": 38.464226731247805, "test_mcc_se": 0.7656996424139845, "test_macro_f1": 58.57217238792893, "test_macro_f1_se": 0.6686498062901354}}, "num_model_parameters": 135195651, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.8782488703727722, "test_mcc": 0.3911475195909649, "test_macro_f1": 0.5802708388134054, "test_runtime": 4.1454, "test_samples_per_second": 494.047, "test_steps_per_second": 15.439}, {"test_loss": 0.8625814914703369, "test_mcc": 0.3922331493222545, "test_macro_f1": 0.5496861283592056, "test_runtime": 3.8798, "test_samples_per_second": 527.856, "test_steps_per_second": 16.495}, {"test_loss": 0.8436049222946167, "test_mcc": 0.3453700711304814, "test_macro_f1": 0.44915645609125665, "test_runtime": 3.8568, "test_samples_per_second": 531.011, "test_steps_per_second": 16.594}, {"test_loss": 0.9741745591163635, "test_mcc": 0.27838832019000764, "test_macro_f1": 0.4045012038260361, "test_runtime": 3.9575, "test_samples_per_second": 517.496, "test_steps_per_second": 16.172}, {"test_loss": 0.8962959051132202, "test_mcc": 0.30968419965047345, "test_macro_f1": 0.4268560306699834, "test_runtime": 4.0153, "test_samples_per_second": 510.048, "test_steps_per_second": 15.939}, {"test_loss": 0.9766219854354858, "test_mcc": 0.20101624780110094, "test_macro_f1": 0.37975491016421165, "test_runtime": 4.1156, "test_samples_per_second": 497.613, "test_steps_per_second": 15.55}, {"test_loss": 0.8536217212677002, "test_mcc": 0.3661273656960257, "test_macro_f1": 0.4653832848777342, "test_runtime": 3.9564, "test_samples_per_second": 517.644, "test_steps_per_second": 16.176}, {"test_loss": 0.8332208395004272, "test_mcc": 0.37073112798328484, "test_macro_f1": 0.5476715095810508, "test_runtime": 4.0158, "test_samples_per_second": 509.981, "test_steps_per_second": 15.937}, {"test_loss": 0.8611812591552734, "test_mcc": 0.3693239430154461, "test_macro_f1": 0.5021212121212123, "test_runtime": 4.1381, "test_samples_per_second": 494.909, "test_steps_per_second": 15.466}, {"test_loss": 0.8538035750389099, "test_mcc": 0.36992811738092035, "test_macro_f1": 0.49068297415510925, "test_runtime": 4.1125, "test_samples_per_second": 497.998, "test_steps_per_second": 15.562}]}, "total": {"test_mcc": 33.9395006176096, "test_mcc_se": 3.740794384875703, "test_macro_f1": 47.96084548659205, "test_macro_f1_se": 4.123261771648265}}, "num_model_parameters": 135195651, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.044086918234825134, "test_micro_f1": 0.7576227390180879, "test_micro_f1_no_misc": 0.8102932375822859, "test_runtime": 6.7157, "test_samples_per_second": 304.959, "test_steps_per_second": 9.53}, {"test_loss": 0.04787907004356384, "test_micro_f1": 0.7234479220112878, "test_micro_f1_no_misc": 0.7950383933845244, "test_runtime": 6.1459, "test_samples_per_second": 333.231, "test_steps_per_second": 10.413}, {"test_loss": 0.04439854621887207, "test_micro_f1": 0.7621383030897498, "test_micro_f1_no_misc": 0.8135781858653313, "test_runtime": 6.3294, "test_samples_per_second": 323.568, "test_steps_per_second": 10.111}, {"test_loss": 0.044525936245918274, "test_micro_f1": 0.736237434179033, "test_micro_f1_no_misc": 0.7977900552486189, "test_runtime": 6.6165, "test_samples_per_second": 309.529, "test_steps_per_second": 9.673}, {"test_loss": 0.053750552237033844, "test_micro_f1": 0.6857670979667284, "test_micro_f1_no_misc": 0.7481559536354058, "test_runtime": 6.443, "test_samples_per_second": 317.865, "test_steps_per_second": 9.933}, {"test_loss": 0.03870780020952225, "test_micro_f1": 0.7676674364896074, "test_micro_f1_no_misc": 0.8218451749734889, "test_runtime": 5.2687, "test_samples_per_second": 388.71, "test_steps_per_second": 12.147}, {"test_loss": 0.04944657161831856, "test_micro_f1": 0.7208313651393481, "test_micro_f1_no_misc": 0.7836956521739131, "test_runtime": 5.7279, "test_samples_per_second": 357.549, "test_steps_per_second": 11.173}, {"test_loss": 0.043073076754808426, "test_micro_f1": 0.7465968586387434, "test_micro_f1_no_misc": 0.8040380047505938, "test_runtime": 6.4717, "test_samples_per_second": 316.455, "test_steps_per_second": 9.889}, {"test_loss": 0.04054911434650421, "test_micro_f1": 0.753731343283582, "test_micro_f1_no_misc": 0.8081023454157783, "test_runtime": 6.1049, "test_samples_per_second": 335.471, "test_steps_per_second": 10.483}, {"test_loss": 0.04759756475687027, "test_micro_f1": 0.7531100478468898, "test_micro_f1_no_misc": 0.8164591229020033, "test_runtime": 6.5451, "test_samples_per_second": 312.905, "test_steps_per_second": 9.778}]}, "total": {"test_micro_f1": 74.07150547663058, "test_micro_f1_se": 1.540780186746415, "test_micro_f1_no_misc": 79.98996125931944, "test_micro_f1_no_misc_se": 1.323451331572655}}, "num_model_parameters": 134609673, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.06892938911914825, "test_micro_f1": 0.7765475591343735, "test_micro_f1_no_misc": 0.7965576592082615, "test_runtime": 9.5817, "test_samples_per_second": 213.742, "test_steps_per_second": 6.679}, {"test_loss": 0.06658737361431122, "test_micro_f1": 0.7744610281923714, "test_micro_f1_no_misc": 0.7930660888407368, "test_runtime": 7.6526, "test_samples_per_second": 267.623, "test_steps_per_second": 8.363}, {"test_loss": 0.07327018678188324, "test_micro_f1": 0.7496770860242832, "test_micro_f1_no_misc": 0.7811713977721884, "test_runtime": 9.392, "test_samples_per_second": 218.058, "test_steps_per_second": 6.814}, {"test_loss": 0.07930000126361847, "test_micro_f1": 0.7313508064516129, "test_micro_f1_no_misc": 0.7632388110693542, "test_runtime": 8.915, "test_samples_per_second": 229.726, "test_steps_per_second": 7.179}, {"test_loss": 0.07934798300266266, "test_micro_f1": 0.7614603348888278, "test_micro_f1_no_misc": 0.7898089171974523, "test_runtime": 9.8194, "test_samples_per_second": 208.566, "test_steps_per_second": 6.518}, {"test_loss": 0.0727744996547699, "test_micro_f1": 0.7698878804057661, "test_micro_f1_no_misc": 0.7952522255192879, "test_runtime": 9.3238, "test_samples_per_second": 219.652, "test_steps_per_second": 6.864}, {"test_loss": 0.07349997758865356, "test_micro_f1": 0.7593984962406016, "test_micro_f1_no_misc": 0.7798520605847128, "test_runtime": 9.7879, "test_samples_per_second": 209.237, "test_steps_per_second": 6.539}, {"test_loss": 0.07307006418704987, "test_micro_f1": 0.7585475748741054, "test_micro_f1_no_misc": 0.8005908419497784, "test_runtime": 9.534, "test_samples_per_second": 214.811, "test_steps_per_second": 6.713}, {"test_loss": 0.07806618511676788, "test_micro_f1": 0.7578891540705383, "test_micro_f1_no_misc": 0.7789776817854571, "test_runtime": 8.9834, "test_samples_per_second": 227.977, "test_steps_per_second": 7.124}, {"test_loss": 0.07009729743003845, "test_micro_f1": 0.7965966498271737, "test_micro_f1_no_misc": 0.8253275109170305, "test_runtime": 8.2266, "test_samples_per_second": 248.949, "test_steps_per_second": 7.78}]}, "total": {"test_micro_f1": 76.35816570109652, "test_micro_f1_se": 1.0791167751010673, "test_micro_f1_no_misc": 79.0384319484426, "test_micro_f1_no_misc_se": 1.0241561622503237}}, "num_model_parameters": 134609673, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.054553043097257614, "test_micro_f1": 0.7965492451473759, "test_micro_f1_no_misc": 0.8282258064516129, "test_runtime": 7.1749, "test_samples_per_second": 285.438, "test_steps_per_second": 8.92}, {"test_loss": 0.04156317561864853, "test_micro_f1": 0.8098929494278331, "test_micro_f1_no_misc": 0.8387096774193548, "test_runtime": 7.0844, "test_samples_per_second": 289.086, "test_steps_per_second": 9.034}, {"test_loss": 0.055627092719078064, "test_micro_f1": 0.7578070784177654, "test_micro_f1_no_misc": 0.793009708737864, "test_runtime": 6.8228, "test_samples_per_second": 300.168, "test_steps_per_second": 9.38}, {"test_loss": 0.04286891967058182, "test_micro_f1": 0.805066854327938, "test_micro_f1_no_misc": 0.8352941176470587, "test_runtime": 6.9407, "test_samples_per_second": 295.073, "test_steps_per_second": 9.221}, {"test_loss": 0.04999294504523277, "test_micro_f1": 0.8310471729675476, "test_micro_f1_no_misc": 0.851948051948052, "test_runtime": 7.1225, "test_samples_per_second": 287.541, "test_steps_per_second": 8.986}, {"test_loss": 0.04277394711971283, "test_micro_f1": 0.8329938900203666, "test_micro_f1_no_misc": 0.8624761904761904, "test_runtime": 7.1856, "test_samples_per_second": 285.016, "test_steps_per_second": 8.907}, {"test_loss": 0.050284791737794876, "test_micro_f1": 0.7791946308724833, "test_micro_f1_no_misc": 0.8164179104477612, "test_runtime": 6.6272, "test_samples_per_second": 309.028, "test_steps_per_second": 9.657}, {"test_loss": 0.04566539451479912, "test_micro_f1": 0.8235706769554543, "test_micro_f1_no_misc": 0.8425821064552662, "test_runtime": 6.8728, "test_samples_per_second": 297.988, "test_steps_per_second": 9.312}, {"test_loss": 0.049803927540779114, "test_micro_f1": 0.7964412811387901, "test_micro_f1_no_misc": 0.8239520958083831, "test_runtime": 6.861, "test_samples_per_second": 298.499, "test_steps_per_second": 9.328}, {"test_loss": 0.04982428625226021, "test_micro_f1": 0.8013769363166954, "test_micro_f1_no_misc": 0.8303053730189408, "test_runtime": 6.7993, "test_samples_per_second": 301.207, "test_steps_per_second": 9.413}]}, "total": {"test_micro_f1": 80.33940715592249, "test_micro_f1_se": 1.4397102352318238, "test_micro_f1_no_misc": 83.22921038410485, "test_micro_f1_no_misc_se": 1.1937690973430155}}, "num_model_parameters": 134609673, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.05811856687068939, "test_micro_f1": 0.7629513343799059, "test_micro_f1_no_misc": 0.799590303857972, "test_runtime": 6.6183, "test_samples_per_second": 309.444, "test_steps_per_second": 9.67}, {"test_loss": 0.06493597477674484, "test_micro_f1": 0.7975308641975308, "test_micro_f1_no_misc": 0.824469933958985, "test_runtime": 6.8049, "test_samples_per_second": 300.958, "test_steps_per_second": 9.405}, {"test_loss": 0.07605410367250443, "test_micro_f1": 0.7239411234604985, "test_micro_f1_no_misc": 0.7618110236220472, "test_runtime": 6.4585, "test_samples_per_second": 317.101, "test_steps_per_second": 9.909}, {"test_loss": 0.0701565146446228, "test_micro_f1": 0.7416974169741698, "test_micro_f1_no_misc": 0.7802047781569966, "test_runtime": 6.6565, "test_samples_per_second": 307.671, "test_steps_per_second": 9.615}, {"test_loss": 0.06373331695795059, "test_micro_f1": 0.7902587519025874, "test_micro_f1_no_misc": 0.825765575501584, "test_runtime": 6.4285, "test_samples_per_second": 318.581, "test_steps_per_second": 9.956}, {"test_loss": 0.06519225984811783, "test_micro_f1": 0.7738238841978288, "test_micro_f1_no_misc": 0.808038808038808, "test_runtime": 6.3599, "test_samples_per_second": 322.017, "test_steps_per_second": 10.063}, {"test_loss": 0.05908716470003128, "test_micro_f1": 0.7362875735977689, "test_micro_f1_no_misc": 0.7810044414075846, "test_runtime": 6.9128, "test_samples_per_second": 296.26, "test_steps_per_second": 9.258}, {"test_loss": 0.05894792079925537, "test_micro_f1": 0.7535877862595419, "test_micro_f1_no_misc": 0.7911200807265388, "test_runtime": 6.885, "test_samples_per_second": 297.459, "test_steps_per_second": 9.296}, {"test_loss": 0.0680934265255928, "test_micro_f1": 0.7138964577656676, "test_micro_f1_no_misc": 0.7518199867637325, "test_runtime": 6.33, "test_samples_per_second": 323.541, "test_steps_per_second": 10.111}, {"test_loss": 0.06496290862560272, "test_micro_f1": 0.760528742699047, "test_micro_f1_no_misc": 0.7916945746818486, "test_runtime": 6.5814, "test_samples_per_second": 311.179, "test_steps_per_second": 9.724}]}, "total": {"test_micro_f1": 75.54503935434546, "test_micro_f1_se": 1.6887646504502676, "test_micro_f1_no_misc": 79.15519506716097, "test_micro_f1_no_misc_se": 1.5032295871721144}}, "num_model_parameters": 134609673, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.42072978615760803, "test_mcc": 0.6750660206627984, "test_macro_f1": 0.8146738079590135, "test_runtime": 2.8914, "test_samples_per_second": 708.312, "test_steps_per_second": 22.135}, {"test_loss": 0.3911955654621124, "test_mcc": 0.6945329254541055, "test_macro_f1": 0.8289698943588459, "test_runtime": 2.967, "test_samples_per_second": 690.251, "test_steps_per_second": 21.57}, {"test_loss": 0.32708901166915894, "test_mcc": 0.7968605645119178, "test_macro_f1": 0.8932310749010192, "test_runtime": 2.9649, "test_samples_per_second": 690.758, "test_steps_per_second": 21.586}, {"test_loss": 0.3502137064933777, "test_mcc": 0.7585080588765436, "test_macro_f1": 0.8719055055816995, "test_runtime": 2.9011, "test_samples_per_second": 705.935, "test_steps_per_second": 22.06}, {"test_loss": 0.38143160939216614, "test_mcc": 0.7475503672684264, "test_macro_f1": 0.8639000419271, "test_runtime": 2.972, "test_samples_per_second": 689.097, "test_steps_per_second": 21.534}, {"test_loss": 0.37105754017829895, "test_mcc": 0.7324365764730854, "test_macro_f1": 0.8517413405095762, "test_runtime": 2.9001, "test_samples_per_second": 706.191, "test_steps_per_second": 22.068}, {"test_loss": 0.3394780158996582, "test_mcc": 0.7624154753230934, "test_macro_f1": 0.8768742291884781, "test_runtime": 2.8628, "test_samples_per_second": 715.385, "test_steps_per_second": 22.356}, {"test_loss": 0.3871532082557678, "test_mcc": 0.7082915441275908, "test_macro_f1": 0.8372202125473501, "test_runtime": 2.9954, "test_samples_per_second": 683.714, "test_steps_per_second": 21.366}, {"test_loss": 0.3816262483596802, "test_mcc": 0.7631339454292047, "test_macro_f1": 0.8758157101442581, "test_runtime": 2.9028, "test_samples_per_second": 705.521, "test_steps_per_second": 22.048}, {"test_loss": 0.3720971941947937, "test_mcc": 0.7134616582872462, "test_macro_f1": 0.8431138665123299, "test_runtime": 2.9241, "test_samples_per_second": 700.396, "test_steps_per_second": 21.887}]}, "total": {"test_mcc": 73.52257136414012, "test_mcc_se": 2.309232209194314, "test_macro_f1": 85.57445683629672, "test_macro_f1_se": 1.5328489153095803}}, "num_model_parameters": 135194882, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.6891046762466431, "test_mcc": 0.08252422515594003, "test_macro_f1": 0.5391736408301995, "test_runtime": 4.3901, "test_samples_per_second": 466.502, "test_steps_per_second": 14.578}, {"test_loss": 0.6944680213928223, "test_mcc": 0.014896077031721055, "test_macro_f1": 0.5070539319907402, "test_runtime": 4.6337, "test_samples_per_second": 441.979, "test_steps_per_second": 13.812}, {"test_loss": 0.6904834508895874, "test_mcc": 0.06004091494442301, "test_macro_f1": 0.5220966523748193, "test_runtime": 4.5025, "test_samples_per_second": 454.855, "test_steps_per_second": 14.214}, {"test_loss": 0.6902756690979004, "test_mcc": 0.10709927400565461, "test_macro_f1": 0.5142124813751207, "test_runtime": 4.7456, "test_samples_per_second": 431.561, "test_steps_per_second": 13.486}, {"test_loss": 0.6887547969818115, "test_mcc": 0.07978842977852627, "test_macro_f1": 0.5391490715693741, "test_runtime": 4.526, "test_samples_per_second": 452.498, "test_steps_per_second": 14.141}, {"test_loss": 0.6926499605178833, "test_mcc": 0.044940179101876074, "test_macro_f1": 0.5198324773780387, "test_runtime": 4.4329, "test_samples_per_second": 462.005, "test_steps_per_second": 14.438}, {"test_loss": 0.696793794631958, "test_mcc": -0.0248266881785241, "test_macro_f1": 0.475173997943996, "test_runtime": 4.3491, "test_samples_per_second": 470.905, "test_steps_per_second": 14.716}, {"test_loss": 0.7005319595336914, "test_mcc": 0.008326019547151363, "test_macro_f1": 0.470659101696995, "test_runtime": 4.3903, "test_samples_per_second": 466.48, "test_steps_per_second": 14.577}, {"test_loss": 0.6895376443862915, "test_mcc": 0.10182268715929493, "test_macro_f1": 0.45588942361700885, "test_runtime": 4.4422, "test_samples_per_second": 461.032, "test_steps_per_second": 14.407}, {"test_loss": 0.7003017663955688, "test_mcc": -0.01322277115135575, "test_macro_f1": 0.42714996330646093, "test_runtime": 4.5506, "test_samples_per_second": 450.054, "test_steps_per_second": 14.064}]}, "total": {"test_mcc": 4.613883473947075, "test_mcc_se": 2.953297034734665, "test_macro_f1": 49.703907420827534, "test_macro_f1_se": 2.341357841353005}}, "num_model_parameters": 135194882, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.6833317875862122, "test_mcc": 0.11371003502234793, "test_macro_f1": 0.5044635466411971, "test_runtime": 3.9211, "test_samples_per_second": 522.296, "test_steps_per_second": 16.322}, {"test_loss": 0.6895942091941833, "test_mcc": 0.07331687198748248, "test_macro_f1": 0.4732776793996122, "test_runtime": 3.9496, "test_samples_per_second": 518.53, "test_steps_per_second": 16.204}, {"test_loss": 0.6768815517425537, "test_mcc": 0.16530826727448864, "test_macro_f1": 0.5587157940099117, "test_runtime": 3.9549, "test_samples_per_second": 517.842, "test_steps_per_second": 16.183}, {"test_loss": 0.6881304979324341, "test_mcc": 0.06670124821893694, "test_macro_f1": 0.5319460812935903, "test_runtime": 4.0275, "test_samples_per_second": 508.499, "test_steps_per_second": 15.891}, {"test_loss": 0.6398398280143738, "test_mcc": 0.28663356321828376, "test_macro_f1": 0.6207317506785346, "test_runtime": 3.9978, "test_samples_per_second": 512.282, "test_steps_per_second": 16.009}, {"test_loss": 0.6901904344558716, "test_mcc": 0.07933904568998361, "test_macro_f1": 0.4679163412305823, "test_runtime": 3.8214, "test_samples_per_second": 535.925, "test_steps_per_second": 16.748}, {"test_loss": 0.6937158107757568, "test_mcc": 0.014014245805225837, "test_macro_f1": 0.5054896391650252, "test_runtime": 3.8685, "test_samples_per_second": 529.402, "test_steps_per_second": 16.544}, {"test_loss": 0.68826824426651, "test_mcc": 0.09900101093159346, "test_macro_f1": 0.5466067346664362, "test_runtime": 3.8637, "test_samples_per_second": 530.061, "test_steps_per_second": 16.564}, {"test_loss": 0.6946693658828735, "test_mcc": 0.03133986064213967, "test_macro_f1": 0.5089925541830752, "test_runtime": 3.8491, "test_samples_per_second": 532.075, "test_steps_per_second": 16.627}, {"test_loss": 0.6944069862365723, "test_mcc": 0.026785195145858618, "test_macro_f1": 0.50603133521283, "test_runtime": 4.0268, "test_samples_per_second": 508.587, "test_steps_per_second": 15.893}]}, "total": {"test_mcc": 9.56149343936341, "test_mcc_se": 5.010252074557087, "test_macro_f1": 52.24171456480795, "test_macro_f1_se": 2.779693541566052}}, "num_model_parameters": 135194882, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_loss": 0.6946293115615845, "test_mcc": 0.054467939851599756, "test_macro_f1": 0.5099482249688628, "test_runtime": 4.0459, "test_samples_per_second": 506.188, "test_steps_per_second": 15.818}, {"test_loss": 0.697843611240387, "test_mcc": 0.013969451450684723, "test_macro_f1": 0.47260854449634987, "test_runtime": 4.2354, "test_samples_per_second": 483.548, "test_steps_per_second": 15.111}, {"test_loss": 0.6981468796730042, "test_mcc": 0.005480207693392624, "test_macro_f1": 0.4727484742477246, "test_runtime": 4.1694, "test_samples_per_second": 491.193, "test_steps_per_second": 15.35}, {"test_loss": 0.6905488967895508, "test_mcc": 0.03101494421704383, "test_macro_f1": 0.4686136148698381, "test_runtime": 3.9759, "test_samples_per_second": 515.103, "test_steps_per_second": 16.097}, {"test_loss": 0.6728529334068298, "test_mcc": 0.16838823556465202, "test_macro_f1": 0.5756764656113957, "test_runtime": 4.0228, "test_samples_per_second": 509.1, "test_steps_per_second": 15.909}, {"test_loss": 0.6940213441848755, "test_mcc": 0.04201143650943149, "test_macro_f1": 0.5093913278192299, "test_runtime": 4.1534, "test_samples_per_second": 493.094, "test_steps_per_second": 15.409}, {"test_loss": 0.692461371421814, "test_mcc": 0.026321808776827656, "test_macro_f1": 0.5124145210886227, "test_runtime": 4.0704, "test_samples_per_second": 503.145, "test_steps_per_second": 15.723}, {"test_loss": 0.6992678642272949, "test_mcc": -0.0026263551035132044, "test_macro_f1": 0.46319822424055435, "test_runtime": 4.0789, "test_samples_per_second": 502.094, "test_steps_per_second": 15.69}, {"test_loss": 0.6940499544143677, "test_mcc": 0.041211066112128734, "test_macro_f1": 0.5170138759594444, "test_runtime": 4.0572, "test_samples_per_second": 504.782, "test_steps_per_second": 15.774}, {"test_loss": 0.6961230039596558, "test_mcc": 0.03551838662317829, "test_macro_f1": 0.5051067679398675, "test_runtime": 4.1399, "test_samples_per_second": 494.693, "test_steps_per_second": 15.459}]}, "total": {"test_mcc": 4.157571216954259, "test_mcc_se": 2.9687271739771752, "test_macro_f1": 50.0672004124189, "test_macro_f1_se": 2.0877716736085308}}, "num_model_parameters": 135194882, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_em": 30.673896204492642, "test_f1": 36.083708303259954}, {"test_em": 31.782945736434108, "test_f1": 35.96831742761976}, {"test_em": 26.27511591962906, "test_f1": 31.760946181234416}, {"test_em": 26.01246105919003, "test_f1": 30.625810189444056}, {"test_em": 30.965250965250966, "test_f1": 36.293539806144864}, {"test_em": 30.377794911333847, "test_f1": 34.53477187342669}, {"test_em": 39.25588458618071, "test_f1": 43.61418839075278}, {"test_em": 24.20480993017843, "test_f1": 30.136301606889866}, {"test_em": 26.980392156862745, "test_f1": 31.681535086725415}, {"test_em": 32.7639751552795, "test_f1": 37.03853326067432}]}, "total": {"test_em": 29.929252662483208, "test_em_se": 2.6972925335798514, "test_f1": 34.773765212617214, "test_f1_se": 2.4976016466004904}}, "num_model_parameters": 134604290, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_em": 31.3710302091402, "test_f1": 36.2257871137157}, {"test_em": 31.550387596899224, "test_f1": 36.67189506573193}, {"test_em": 32.92117465224111, "test_f1": 38.33011929782093}, {"test_em": 28.34890965732087, "test_f1": 33.256773681059755}, {"test_em": 31.274131274131275, "test_f1": 36.91224076562424}, {"test_em": 29.992289899768696, "test_f1": 34.36822787983243}, {"test_em": 27.638572513287777, "test_f1": 32.32427295237159}, {"test_em": 27.773467804499614, "test_f1": 32.97534520232175}, {"test_em": 36.15686274509804, "test_f1": 41.66443239467793}, {"test_em": 34.93788819875776, "test_f1": 39.30421422922666}]}, "total": {"test_em": 31.19647145511446, "test_em_se": 1.7972522054956064, "test_f1": 36.20333085823829, "test_f1_se": 1.8731618182501588}}, "num_model_parameters": 134604290, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_em": 34.70178156467854, "test_f1": 40.47646266527641}, {"test_em": 35.65891472868217, "test_f1": 39.9129757311592}, {"test_em": 34.15765069551777, "test_f1": 40.24488587694096}, {"test_em": 37.22741433021807, "test_f1": 43.23080232214806}, {"test_em": 40.463320463320464, "test_f1": 45.16900106572816}, {"test_em": 30.223592906707786, "test_f1": 36.06691844963418}, {"test_em": 34.92786636294609, "test_f1": 39.44661064087075}, {"test_em": 39.332816136539954, "test_f1": 43.66829887920939}, {"test_em": 44.0, "test_f1": 49.113386500183076}, {"test_em": 38.35403726708075, "test_f1": 43.76631242768772}]}, "total": {"test_em": 36.90473944556916, "test_em_se": 2.3880535970703747, "test_f1": 42.10956545588378, "test_f1_se": 2.2577300060353895}}, "num_model_parameters": 134604290, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.39526620507240295, "test_mcc": 0.7485013501026533, "test_macro_f1": 0.6565048054768423, "test_runtime": 13.514, "test_samples_per_second": 151.547, "test_steps_per_second": 18.943}, {"test_loss": 0.3867051303386688, "test_mcc": 0.7485190376013091, "test_macro_f1": 0.7280533720198719, "test_runtime": 12.7172, "test_samples_per_second": 161.042, "test_steps_per_second": 20.13}, {"test_loss": 0.3749030828475952, "test_mcc": 0.7576110322700681, "test_macro_f1": 0.713760974977531, "test_runtime": 13.1029, "test_samples_per_second": 156.301, "test_steps_per_second": 19.538}, {"test_loss": 0.35519084334373474, "test_mcc": 0.7605096879885556, "test_macro_f1": 0.6700477320680059, "test_runtime": 12.4524, "test_samples_per_second": 164.466, "test_steps_per_second": 20.558}, {"test_loss": 0.3648189604282379, "test_mcc": 0.765234495328692, "test_macro_f1": 0.6718881960592201, "test_runtime": 12.3607, "test_samples_per_second": 165.687, "test_steps_per_second": 20.711}, {"test_loss": 0.3671446442604065, "test_mcc": 0.77035127394683, "test_macro_f1": 0.7528051932800158, "test_runtime": 12.8417, "test_samples_per_second": 159.48, "test_steps_per_second": 19.935}, {"test_loss": 0.3722248375415802, "test_mcc": 0.7619761413182037, "test_macro_f1": 0.7243298456652155, "test_runtime": 12.2361, "test_samples_per_second": 167.373, "test_steps_per_second": 20.922}, {"test_loss": 0.3734614849090576, "test_mcc": 0.7673746522265437, "test_macro_f1": 0.6894987538360008, "test_runtime": 13.284, "test_samples_per_second": 154.17, "test_steps_per_second": 19.271}, {"test_loss": 0.387834757566452, "test_mcc": 0.7445912914431637, "test_macro_f1": 0.7270478397281762, "test_runtime": 13.185, "test_samples_per_second": 155.328, "test_steps_per_second": 19.416}, {"test_loss": 0.39001110196113586, "test_mcc": 0.7604176029992388, "test_macro_f1": 0.7238437954915965, "test_runtime": 12.7843, "test_samples_per_second": 160.196, "test_steps_per_second": 20.025}]}, "total": {"test_mcc": 75.85086565225258, "test_mcc_se": 0.5380387338540904, "test_macro_f1": 70.57780508602477, "test_macro_f1_se": 1.9613562247145209}}, "num_model_parameters": 135293955, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.913722038269043, "test_mcc": 0.3455722421708279, "test_macro_f1": 0.5560647354690792, "test_runtime": 5.1756, "test_samples_per_second": 395.701, "test_steps_per_second": 12.366}, {"test_loss": 0.9704508781433105, "test_mcc": 0.37194533211035946, "test_macro_f1": 0.579687560600306, "test_runtime": 5.1425, "test_samples_per_second": 398.249, "test_steps_per_second": 12.445}, {"test_loss": 0.9546425938606262, "test_mcc": 0.3376923484867595, "test_macro_f1": 0.5570177549349122, "test_runtime": 5.1253, "test_samples_per_second": 399.585, "test_steps_per_second": 12.487}, {"test_loss": 0.9517633318901062, "test_mcc": 0.3513542853021868, "test_macro_f1": 0.5691100863103343, "test_runtime": 5.1402, "test_samples_per_second": 398.43, "test_steps_per_second": 12.451}, {"test_loss": 0.9557435512542725, "test_mcc": 0.3985808473584611, "test_macro_f1": 0.5981093507288401, "test_runtime": 5.0846, "test_samples_per_second": 402.788, "test_steps_per_second": 12.587}, {"test_loss": 1.0023763179779053, "test_mcc": 0.34329597631842756, "test_macro_f1": 0.5596075134656137, "test_runtime": 5.2066, "test_samples_per_second": 393.344, "test_steps_per_second": 12.292}, {"test_loss": 0.9046574831008911, "test_mcc": 0.3822770831785539, "test_macro_f1": 0.5894413497945314, "test_runtime": 5.1603, "test_samples_per_second": 396.874, "test_steps_per_second": 12.402}, {"test_loss": 0.946894645690918, "test_mcc": 0.3850133889158511, "test_macro_f1": 0.5921235603442878, "test_runtime": 5.1405, "test_samples_per_second": 398.405, "test_steps_per_second": 12.45}, {"test_loss": 0.8972546458244324, "test_mcc": 0.39112785960598623, "test_macro_f1": 0.5908105051009188, "test_runtime": 5.0961, "test_samples_per_second": 401.873, "test_steps_per_second": 12.559}, {"test_loss": 0.9949873685836792, "test_mcc": 0.32386524060379346, "test_macro_f1": 0.5453424553920168, "test_runtime": 5.0996, "test_samples_per_second": 401.598, "test_steps_per_second": 12.55}]}, "total": {"test_mcc": 36.30724604051207, "test_mcc_se": 1.5993914193118957, "test_macro_f1": 57.373148721408405, "test_macro_f1_se": 1.1548967439218343}}, "num_model_parameters": 135293955, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.9011285305023193, "test_mcc": 0.3063553028957017, "test_macro_f1": 0.4246040439969714, "test_runtime": 4.1428, "test_samples_per_second": 494.349, "test_steps_per_second": 15.448}, {"test_loss": 0.9311989545822144, "test_mcc": 0.3287170809797409, "test_macro_f1": 0.48815898944945085, "test_runtime": 3.8727, "test_samples_per_second": 528.827, "test_steps_per_second": 16.526}, {"test_loss": 0.8750643730163574, "test_mcc": 0.36679416783622426, "test_macro_f1": 0.503299835606639, "test_runtime": 3.8829, "test_samples_per_second": 527.435, "test_steps_per_second": 16.482}, {"test_loss": 0.9612247943878174, "test_mcc": 0.3187744535315182, "test_macro_f1": 0.4814097395369119, "test_runtime": 3.9507, "test_samples_per_second": 518.394, "test_steps_per_second": 16.2}, {"test_loss": 0.8880867958068848, "test_mcc": 0.34025014550574595, "test_macro_f1": 0.5192767374843482, "test_runtime": 4.0306, "test_samples_per_second": 508.112, "test_steps_per_second": 15.879}, {"test_loss": 0.8873450756072998, "test_mcc": 0.3439346059882636, "test_macro_f1": 0.5209944655929841, "test_runtime": 4.0819, "test_samples_per_second": 501.725, "test_steps_per_second": 15.679}, {"test_loss": 0.8689380288124084, "test_mcc": 0.34346900159242083, "test_macro_f1": 0.4793480252110737, "test_runtime": 3.9659, "test_samples_per_second": 516.398, "test_steps_per_second": 16.137}, {"test_loss": 0.8999674320220947, "test_mcc": 0.33610205869368537, "test_macro_f1": 0.47813068362610106, "test_runtime": 4.0601, "test_samples_per_second": 504.417, "test_steps_per_second": 15.763}, {"test_loss": 0.9327083826065063, "test_mcc": 0.3213279175123729, "test_macro_f1": 0.48489176572766884, "test_runtime": 4.1334, "test_samples_per_second": 495.471, "test_steps_per_second": 15.483}, {"test_loss": 0.8952955603599548, "test_mcc": 0.3826117934261243, "test_macro_f1": 0.5408518540760986, "test_runtime": 4.1223, "test_samples_per_second": 496.811, "test_steps_per_second": 15.525}]}, "total": {"test_mcc": 33.88336527961798, "test_mcc_se": 1.4044844384671633, "test_macro_f1": 49.20966140308248, "test_macro_f1_se": 1.978518933322095}}, "num_model_parameters": 135293955, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.045813191682100296, "test_micro_f1": 0.7497446373850868, "test_micro_f1_no_misc": 0.8090963494913226, "test_runtime": 6.6675, "test_samples_per_second": 307.16, "test_steps_per_second": 9.599}, {"test_loss": 0.04421743005514145, "test_micro_f1": 0.7180823345492444, "test_micro_f1_no_misc": 0.7886129618413082, "test_runtime": 6.118, "test_samples_per_second": 334.748, "test_steps_per_second": 10.461}, {"test_loss": 0.04507851600646973, "test_micro_f1": 0.7396335583413692, "test_micro_f1_no_misc": 0.791101465002713, "test_runtime": 6.3082, "test_samples_per_second": 324.656, "test_steps_per_second": 10.146}, {"test_loss": 0.045302242040634155, "test_micro_f1": 0.7106796116504854, "test_micro_f1_no_misc": 0.7808676307007787, "test_runtime": 6.576, "test_samples_per_second": 311.434, "test_steps_per_second": 9.732}, {"test_loss": 0.04814012348651886, "test_micro_f1": 0.7355679702048417, "test_micro_f1_no_misc": 0.7978609625668448, "test_runtime": 6.4947, "test_samples_per_second": 315.336, "test_steps_per_second": 9.854}, {"test_loss": 0.04659583419561386, "test_micro_f1": 0.7423146473779384, "test_micro_f1_no_misc": 0.7972103004291845, "test_runtime": 5.3368, "test_samples_per_second": 383.747, "test_steps_per_second": 11.992}, {"test_loss": 0.047976769506931305, "test_micro_f1": 0.7132003798670464, "test_micro_f1_no_misc": 0.7838584853510228, "test_runtime": 5.6904, "test_samples_per_second": 359.907, "test_steps_per_second": 11.247}, {"test_loss": 0.04254002869129181, "test_micro_f1": 0.7172043010752688, "test_micro_f1_no_misc": 0.7616766467065869, "test_runtime": 6.4829, "test_samples_per_second": 315.907, "test_steps_per_second": 9.872}, {"test_loss": 0.04219437390565872, "test_micro_f1": 0.7482859941234083, "test_micro_f1_no_misc": 0.8122562674094708, "test_runtime": 6.1141, "test_samples_per_second": 334.965, "test_steps_per_second": 10.468}, {"test_loss": 0.04872529208660126, "test_micro_f1": 0.743371212121212, "test_micro_f1_no_misc": 0.8064343163538874, "test_runtime": 6.5939, "test_samples_per_second": 310.592, "test_steps_per_second": 9.706}]}, "total": {"test_micro_f1": 73.18084646695901, "test_micro_f1_se": 0.9483546271173587, "test_micro_f1_no_misc": 79.2897538585312, "test_micro_f1_no_misc_se": 0.9436975258485651}}, "num_model_parameters": 134707977, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.07678017765283585, "test_micro_f1": 0.7234363225320272, "test_micro_f1_no_misc": 0.7588747488278634, "test_runtime": 9.4567, "test_samples_per_second": 216.565, "test_steps_per_second": 6.768}, {"test_loss": 0.07370509952306747, "test_micro_f1": 0.7411894273127754, "test_micro_f1_no_misc": 0.7749814951887491, "test_runtime": 7.6258, "test_samples_per_second": 268.562, "test_steps_per_second": 8.393}, {"test_loss": 0.07507628202438354, "test_micro_f1": 0.7573075891659963, "test_micro_f1_no_misc": 0.7875946628200505, "test_runtime": 9.3816, "test_samples_per_second": 218.299, "test_steps_per_second": 6.822}, {"test_loss": 0.08259004354476929, "test_micro_f1": 0.7131822863027807, "test_micro_f1_no_misc": 0.7446524064171123, "test_runtime": 8.9636, "test_samples_per_second": 228.479, "test_steps_per_second": 7.14}, {"test_loss": 0.08358819782733917, "test_micro_f1": 0.7223749312809236, "test_micro_f1_no_misc": 0.7496350364963504, "test_runtime": 9.8526, "test_samples_per_second": 207.864, "test_steps_per_second": 6.496}, {"test_loss": 0.0830639898777008, "test_micro_f1": 0.6990765888104291, "test_micro_f1_no_misc": 0.7299703264094957, "test_runtime": 9.2497, "test_samples_per_second": 221.413, "test_steps_per_second": 6.919}, {"test_loss": 0.07724776864051819, "test_micro_f1": 0.7319455152916989, "test_micro_f1_no_misc": 0.7697740112994349, "test_runtime": 9.8146, "test_samples_per_second": 208.668, "test_steps_per_second": 6.521}, {"test_loss": 0.07194298505783081, "test_micro_f1": 0.7498631636562672, "test_micro_f1_no_misc": 0.7785870356882738, "test_runtime": 9.4776, "test_samples_per_second": 216.088, "test_steps_per_second": 6.753}, {"test_loss": 0.07649890333414078, "test_micro_f1": 0.7641534746444861, "test_micro_f1_no_misc": 0.7813178855901521, "test_runtime": 9.0235, "test_samples_per_second": 226.962, "test_steps_per_second": 7.093}, {"test_loss": 0.07810790091753006, "test_micro_f1": 0.7711286089238845, "test_micro_f1_no_misc": 0.805693950177936, "test_runtime": 8.2985, "test_samples_per_second": 246.791, "test_steps_per_second": 7.712}]}, "total": {"test_micro_f1": 73.73657907921269, "test_micro_f1_se": 1.449903729131529, "test_micro_f1_no_misc": 76.81081558915417, "test_micro_f1_no_misc_se": 1.3948193564912847}}, "num_model_parameters": 134707977, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.06022808328270912, "test_micro_f1": 0.7441187115454216, "test_micro_f1_no_misc": 0.7835218093699515, "test_runtime": 7.1687, "test_samples_per_second": 285.688, "test_steps_per_second": 8.928}, {"test_loss": 0.05146649852395058, "test_micro_f1": 0.7682119205298014, "test_micro_f1_no_misc": 0.8004866180048662, "test_runtime": 7.1149, "test_samples_per_second": 287.847, "test_steps_per_second": 8.995}, {"test_loss": 0.06275530904531479, "test_micro_f1": 0.7267080745341615, "test_micro_f1_no_misc": 0.7598784194528875, "test_runtime": 6.8834, "test_samples_per_second": 297.529, "test_steps_per_second": 9.298}, {"test_loss": 0.06853169947862625, "test_micro_f1": 0.7009186798230691, "test_micro_f1_no_misc": 0.7303030303030303, "test_runtime": 6.9444, "test_samples_per_second": 294.913, "test_steps_per_second": 9.216}, {"test_loss": 0.053871240466833115, "test_micro_f1": 0.7845595513032003, "test_micro_f1_no_misc": 0.8032069970845481, "test_runtime": 7.1207, "test_samples_per_second": 287.61, "test_steps_per_second": 8.988}, {"test_loss": 0.053365111351013184, "test_micro_f1": 0.7799461641991924, "test_micro_f1_no_misc": 0.8049143708116158, "test_runtime": 7.1061, "test_samples_per_second": 288.204, "test_steps_per_second": 9.006}, {"test_loss": 0.05519862473011017, "test_micro_f1": 0.7582714382174206, "test_micro_f1_no_misc": 0.7807964272422775, "test_runtime": 6.5973, "test_samples_per_second": 310.431, "test_steps_per_second": 9.701}, {"test_loss": 0.054429419338703156, "test_micro_f1": 0.7628795632889799, "test_micro_f1_no_misc": 0.7917586460632817, "test_runtime": 6.8168, "test_samples_per_second": 300.433, "test_steps_per_second": 9.389}, {"test_loss": 0.058646343648433685, "test_micro_f1": 0.7176799440950384, "test_micro_f1_no_misc": 0.748257164988381, "test_runtime": 6.8145, "test_samples_per_second": 300.536, "test_steps_per_second": 9.392}, {"test_loss": 0.06477885693311691, "test_micro_f1": 0.760122490643076, "test_micro_f1_no_misc": 0.7946127946127945, "test_runtime": 6.7474, "test_samples_per_second": 303.523, "test_steps_per_second": 9.485}]}, "total": {"test_micro_f1": 75.03416538179361, "test_micro_f1_se": 1.7023153988960074, "test_micro_f1_no_misc": 77.97736277933633, "test_micro_f1_no_misc_se": 1.5769023915747606}}, "num_model_parameters": 134707977, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.07034771144390106, "test_micro_f1": 0.7362000609942057, "test_micro_f1_no_misc": 0.766531713900135, "test_runtime": 6.6863, "test_samples_per_second": 306.297, "test_steps_per_second": 9.572}, {"test_loss": 0.0756341740489006, "test_micro_f1": 0.7157769161944526, "test_micro_f1_no_misc": 0.7520798668885191, "test_runtime": 6.8427, "test_samples_per_second": 299.298, "test_steps_per_second": 9.353}, {"test_loss": 0.07218195497989655, "test_micro_f1": 0.7142423322198604, "test_micro_f1_no_misc": 0.7549446865571573, "test_runtime": 6.4968, "test_samples_per_second": 315.23, "test_steps_per_second": 9.851}, {"test_loss": 0.07845516502857208, "test_micro_f1": 0.6960930509991052, "test_micro_f1_no_misc": 0.7493333333333333, "test_runtime": 6.6024, "test_samples_per_second": 310.19, "test_steps_per_second": 9.693}, {"test_loss": 0.0744769424200058, "test_micro_f1": 0.7299006323396567, "test_micro_f1_no_misc": 0.7764060356652949, "test_runtime": 6.3765, "test_samples_per_second": 321.178, "test_steps_per_second": 10.037}, {"test_loss": 0.08082586526870728, "test_micro_f1": 0.6757937663850859, "test_micro_f1_no_misc": 0.7216494845360825, "test_runtime": 6.3567, "test_samples_per_second": 322.179, "test_steps_per_second": 10.068}, {"test_loss": 0.06879143416881561, "test_micro_f1": 0.6971109040074557, "test_micro_f1_no_misc": 0.7392043522611356, "test_runtime": 6.8182, "test_samples_per_second": 300.372, "test_steps_per_second": 9.387}, {"test_loss": 0.06763467937707901, "test_micro_f1": 0.7259981712892413, "test_micro_f1_no_misc": 0.7563081009296149, "test_runtime": 6.8952, "test_samples_per_second": 297.016, "test_steps_per_second": 9.282}, {"test_loss": 0.08328589051961899, "test_micro_f1": 0.6637931034482759, "test_micro_f1_no_misc": 0.7124405166553366, "test_runtime": 6.4143, "test_samples_per_second": 319.288, "test_steps_per_second": 9.978}, {"test_loss": 0.07227221131324768, "test_micro_f1": 0.7450015379883114, "test_micro_f1_no_misc": 0.7714856762158562, "test_runtime": 6.5851, "test_samples_per_second": 311.003, "test_steps_per_second": 9.719}]}, "total": {"test_micro_f1": 70.9991047586565, "test_micro_f1_se": 1.6371929242743142, "test_micro_f1_no_misc": 75.00383766942466, "test_micro_f1_no_misc_se": 1.278969164397602}}, "num_model_parameters": 134707977, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.37124884128570557, "test_mcc": 0.7231309957437235, "test_macro_f1": 0.8517005275994656, "test_runtime": 2.9502, "test_samples_per_second": 694.194, "test_steps_per_second": 21.694}, {"test_loss": 0.3978767693042755, "test_mcc": 0.7163506812232592, "test_macro_f1": 0.8441036843892238, "test_runtime": 2.9365, "test_samples_per_second": 697.434, "test_steps_per_second": 21.795}, {"test_loss": 0.3637107312679291, "test_mcc": 0.7264802485824868, "test_macro_f1": 0.8529889481346585, "test_runtime": 2.9834, "test_samples_per_second": 686.459, "test_steps_per_second": 21.452}, {"test_loss": 0.4176567494869232, "test_mcc": 0.7042219927012376, "test_macro_f1": 0.8395563821163134, "test_runtime": 2.9214, "test_samples_per_second": 701.033, "test_steps_per_second": 21.907}, {"test_loss": 0.3794127404689789, "test_mcc": 0.6941740794954893, "test_macro_f1": 0.8327207383811157, "test_runtime": 3.0377, "test_samples_per_second": 674.19, "test_steps_per_second": 21.068}, {"test_loss": 0.40520980954170227, "test_mcc": 0.7158630202068235, "test_macro_f1": 0.8432539682539684, "test_runtime": 2.9175, "test_samples_per_second": 701.981, "test_steps_per_second": 21.937}, {"test_loss": 0.4041721522808075, "test_mcc": 0.6884890427103143, "test_macro_f1": 0.8273154874332468, "test_runtime": 2.9169, "test_samples_per_second": 702.112, "test_steps_per_second": 21.941}, {"test_loss": 0.40133965015411377, "test_mcc": 0.6922586559473344, "test_macro_f1": 0.8322641341225909, "test_runtime": 2.9894, "test_samples_per_second": 685.077, "test_steps_per_second": 21.409}, {"test_loss": 0.36994946002960205, "test_mcc": 0.7064367355124086, "test_macro_f1": 0.8409022273105544, "test_runtime": 2.9401, "test_samples_per_second": 696.563, "test_steps_per_second": 21.768}, {"test_loss": 0.4059790372848511, "test_mcc": 0.6752375181606737, "test_macro_f1": 0.8200206446450646, "test_runtime": 2.9147, "test_samples_per_second": 702.643, "test_steps_per_second": 21.958}]}, "total": {"test_mcc": 70.4264297028375, "test_mcc_se": 1.027249779334541, "test_macro_f1": 83.84826742386201, "test_macro_f1_se": 0.6480640079453872}}, "num_model_parameters": 135293186, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.6410505771636963, "test_mcc": 0.2735774633572744, "test_macro_f1": 0.593506488205304, "test_runtime": 4.3892, "test_samples_per_second": 466.604, "test_steps_per_second": 14.581}, {"test_loss": 0.6472731828689575, "test_mcc": 0.24852027461303486, "test_macro_f1": 0.6203850728484203, "test_runtime": 4.6932, "test_samples_per_second": 436.375, "test_steps_per_second": 13.637}, {"test_loss": 0.6555562615394592, "test_mcc": 0.2193125496482559, "test_macro_f1": 0.5742981830894476, "test_runtime": 4.5325, "test_samples_per_second": 451.843, "test_steps_per_second": 14.12}, {"test_loss": 0.6553122401237488, "test_mcc": 0.22570660924300176, "test_macro_f1": 0.5958874860476691, "test_runtime": 4.805, "test_samples_per_second": 426.225, "test_steps_per_second": 13.32}, {"test_loss": 0.6645114421844482, "test_mcc": 0.21962372841723463, "test_macro_f1": 0.5572083369367811, "test_runtime": 4.5627, "test_samples_per_second": 448.859, "test_steps_per_second": 14.027}, {"test_loss": 0.6498531103134155, "test_mcc": 0.21069765609415056, "test_macro_f1": 0.5781862392218969, "test_runtime": 4.4737, "test_samples_per_second": 457.789, "test_steps_per_second": 14.306}, {"test_loss": 0.6473955512046814, "test_mcc": 0.24386584943322293, "test_macro_f1": 0.6071224595252989, "test_runtime": 4.3401, "test_samples_per_second": 471.88, "test_steps_per_second": 14.746}, {"test_loss": 0.6521508693695068, "test_mcc": 0.22180525401389833, "test_macro_f1": 0.5648912197109162, "test_runtime": 4.4382, "test_samples_per_second": 461.444, "test_steps_per_second": 14.42}, {"test_loss": 0.6513805985450745, "test_mcc": 0.23784283309853005, "test_macro_f1": 0.5801798567105041, "test_runtime": 4.4318, "test_samples_per_second": 462.116, "test_steps_per_second": 14.441}, {"test_loss": 0.64719557762146, "test_mcc": 0.24473476648556727, "test_macro_f1": 0.6196078431372549, "test_runtime": 4.6334, "test_samples_per_second": 442.005, "test_steps_per_second": 13.813}]}, "total": {"test_mcc": 23.45686984404171, "test_mcc_se": 1.1658306595999457, "test_macro_f1": 58.91273185433492, "test_macro_f1_se": 1.358036132359165}}, "num_model_parameters": 135293186, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.6571789979934692, "test_mcc": 0.23381802675219193, "test_macro_f1": 0.5997042134716642, "test_runtime": 3.9396, "test_samples_per_second": 519.845, "test_steps_per_second": 16.245}, {"test_loss": 0.6663783192634583, "test_mcc": 0.2223029816019644, "test_macro_f1": 0.5565098847826416, "test_runtime": 3.9621, "test_samples_per_second": 516.902, "test_steps_per_second": 16.153}, {"test_loss": 0.6724082231521606, "test_mcc": 0.2492695622940286, "test_macro_f1": 0.588642844744216, "test_runtime": 3.9731, "test_samples_per_second": 515.471, "test_steps_per_second": 16.108}, {"test_loss": 0.6576477289199829, "test_mcc": 0.24509189668042775, "test_macro_f1": 0.6137965804259198, "test_runtime": 4.0875, "test_samples_per_second": 501.035, "test_steps_per_second": 15.657}, {"test_loss": 0.657056450843811, "test_mcc": 0.2669917164254673, "test_macro_f1": 0.5999341151137518, "test_runtime": 4.0313, "test_samples_per_second": 508.025, "test_steps_per_second": 15.876}, {"test_loss": 0.6584834456443787, "test_mcc": 0.19031299398224763, "test_macro_f1": 0.5842047504934432, "test_runtime": 3.89, "test_samples_per_second": 526.481, "test_steps_per_second": 16.453}, {"test_loss": 0.6703670024871826, "test_mcc": 0.20914652349761045, "test_macro_f1": 0.5437200572136526, "test_runtime": 3.9167, "test_samples_per_second": 522.886, "test_steps_per_second": 16.34}, {"test_loss": 0.6375139951705933, "test_mcc": 0.2916040704240465, "test_macro_f1": 0.6145100814648616, "test_runtime": 3.9357, "test_samples_per_second": 520.365, "test_steps_per_second": 16.261}, {"test_loss": 0.6570755839347839, "test_mcc": 0.25609874216655876, "test_macro_f1": 0.6009579658108755, "test_runtime": 3.848, "test_samples_per_second": 532.229, "test_steps_per_second": 16.632}, {"test_loss": 0.6584333181381226, "test_mcc": 0.25830673678634586, "test_macro_f1": 0.5870166259842481, "test_runtime": 3.9867, "test_samples_per_second": 513.714, "test_steps_per_second": 16.054}]}, "total": {"test_mcc": 24.22943250610889, "test_mcc_se": 1.8266700770112876, "test_macro_f1": 58.88997119505275, "test_macro_f1_se": 1.4277386837606887}}, "num_model_parameters": 135293186, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_loss": 0.6680695414543152, "test_mcc": 0.17300845698137282, "test_macro_f1": 0.5637362845132381, "test_runtime": 4.0133, "test_samples_per_second": 510.31, "test_steps_per_second": 15.947}, {"test_loss": 0.6705669164657593, "test_mcc": 0.22187390778686947, "test_macro_f1": 0.5775813079728778, "test_runtime": 4.1486, "test_samples_per_second": 493.662, "test_steps_per_second": 15.427}, {"test_loss": 0.6605601906776428, "test_mcc": 0.19916831889323647, "test_macro_f1": 0.5826497251361094, "test_runtime": 4.1779, "test_samples_per_second": 490.203, "test_steps_per_second": 15.319}, {"test_loss": 0.6654806137084961, "test_mcc": 0.18264827225592978, "test_macro_f1": 0.581318006283673, "test_runtime": 3.8798, "test_samples_per_second": 527.868, "test_steps_per_second": 16.496}, {"test_loss": 0.6538879871368408, "test_mcc": 0.2409399510107623, "test_macro_f1": 0.6164227505703282, "test_runtime": 4.0484, "test_samples_per_second": 505.873, "test_steps_per_second": 15.809}, {"test_loss": 0.6880000829696655, "test_mcc": 0.08311940100081222, "test_macro_f1": 0.4985117979591578, "test_runtime": 4.1694, "test_samples_per_second": 491.194, "test_steps_per_second": 15.35}, {"test_loss": 0.6716452240943909, "test_mcc": 0.18035969268490068, "test_macro_f1": 0.5679702451794262, "test_runtime": 4.1291, "test_samples_per_second": 495.988, "test_steps_per_second": 15.5}, {"test_loss": 0.6668797731399536, "test_mcc": 0.18432558787078324, "test_macro_f1": 0.5842225196312401, "test_runtime": 4.0459, "test_samples_per_second": 506.188, "test_steps_per_second": 15.818}, {"test_loss": 0.6652097105979919, "test_mcc": 0.20041019426496423, "test_macro_f1": 0.5807792958402235, "test_runtime": 4.0374, "test_samples_per_second": 507.259, "test_steps_per_second": 15.852}, {"test_loss": 0.6721025705337524, "test_mcc": 0.15210435613766127, "test_macro_f1": 0.5745860840877318, "test_runtime": 4.1332, "test_samples_per_second": 495.498, "test_steps_per_second": 15.484}]}, "total": {"test_mcc": 18.179581388872922, "test_mcc_se": 2.650440980859697, "test_macro_f1": 57.277780171740055, "test_macro_f1_se": 1.838285604207417}}, "num_model_parameters": 135293186, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.727545976638794, "test_mcc": 0.5608793698634428, "test_macro_f1": 0.530354831141833, "test_runtime": 1.7839, "test_samples_per_second": 1148.019, "test_steps_per_second": 35.876}, {"test_loss": 0.7483292818069458, "test_mcc": 0.5346828978658117, "test_macro_f1": 0.5198349555845314, "test_runtime": 1.798, "test_samples_per_second": 1139.058, "test_steps_per_second": 35.596}, {"test_loss": 0.7243731021881104, "test_mcc": 0.5460521340369183, "test_macro_f1": 0.5232549942532277, "test_runtime": 1.7793, "test_samples_per_second": 1151.046, "test_steps_per_second": 35.97}, {"test_loss": 0.7088980674743652, "test_mcc": 0.5656252780886217, "test_macro_f1": 0.5314811304399955, "test_runtime": 1.7954, "test_samples_per_second": 1140.683, "test_steps_per_second": 35.646}, {"test_loss": 0.6929397583007812, "test_mcc": 0.5853722446427153, "test_macro_f1": 0.5396545927974358, "test_runtime": 1.7958, "test_samples_per_second": 1140.436, "test_steps_per_second": 35.639}, {"test_loss": 0.738749623298645, "test_mcc": 0.5404166095128926, "test_macro_f1": 0.5204995082110085, "test_runtime": 1.7797, "test_samples_per_second": 1150.725, "test_steps_per_second": 35.96}, {"test_loss": 0.7179564237594604, "test_mcc": 0.5812055634475021, "test_macro_f1": 0.5376123260844299, "test_runtime": 1.786, "test_samples_per_second": 1146.688, "test_steps_per_second": 35.834}, {"test_loss": 0.7309684753417969, "test_mcc": 0.5374328559478886, "test_macro_f1": 0.5203013819312056, "test_runtime": 1.8282, "test_samples_per_second": 1120.234, "test_steps_per_second": 35.007}, {"test_loss": 0.7225275039672852, "test_mcc": 0.5576016827220205, "test_macro_f1": 0.5288881118032828, "test_runtime": 1.7925, "test_samples_per_second": 1142.543, "test_steps_per_second": 35.704}, {"test_loss": 0.7160806655883789, "test_mcc": 0.5588144353174263, "test_macro_f1": 0.529593996283789, "test_runtime": 1.7863, "test_samples_per_second": 1146.478, "test_steps_per_second": 35.827}]}, "total": {"test_mcc": 55.6808307144524, "test_mcc_se": 1.0852840171970612, "test_macro_f1": 52.814758285307384, "test_macro_f1_se": 0.4400726135692283}}, "num_model_parameters": 13738755, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.9282322525978088, "test_mcc": 0.3576822515397873, "test_macro_f1": 0.5573730639817305, "test_runtime": 1.5137, "test_samples_per_second": 1352.99, "test_steps_per_second": 42.281}, {"test_loss": 0.942695140838623, "test_mcc": 0.30331408432160945, "test_macro_f1": 0.417632845408785, "test_runtime": 1.4674, "test_samples_per_second": 1395.68, "test_steps_per_second": 43.615}, {"test_loss": 0.979779839515686, "test_mcc": 0.251780254375345, "test_macro_f1": 0.39327857202816113, "test_runtime": 1.4967, "test_samples_per_second": 1368.368, "test_steps_per_second": 42.762}, {"test_loss": 0.9530450105667114, "test_mcc": 0.3526999316735726, "test_macro_f1": 0.5483543339321785, "test_runtime": 1.4809, "test_samples_per_second": 1382.91, "test_steps_per_second": 43.216}, {"test_loss": 0.9758266806602478, "test_mcc": 0.2670272667854574, "test_macro_f1": 0.40292434403124955, "test_runtime": 1.4828, "test_samples_per_second": 1381.142, "test_steps_per_second": 43.161}, {"test_loss": 1.0001164674758911, "test_mcc": 0.34299535136795434, "test_macro_f1": 0.545368500477232, "test_runtime": 1.4766, "test_samples_per_second": 1386.97, "test_steps_per_second": 43.343}, {"test_loss": 0.9789570569992065, "test_mcc": 0.2829201119549164, "test_macro_f1": 0.41737041487062093, "test_runtime": 1.472, "test_samples_per_second": 1391.312, "test_steps_per_second": 43.478}, {"test_loss": 0.9818766713142395, "test_mcc": 0.37457577693550304, "test_macro_f1": 0.5742360825868782, "test_runtime": 1.4562, "test_samples_per_second": 1406.403, "test_steps_per_second": 43.95}, {"test_loss": 0.9309307336807251, "test_mcc": 0.3546034741982883, "test_macro_f1": 0.5465565835484641, "test_runtime": 1.4693, "test_samples_per_second": 1393.868, "test_steps_per_second": 43.558}, {"test_loss": 0.9488527774810791, "test_mcc": 0.38395711022841905, "test_macro_f1": 0.5809540480290766, "test_runtime": 1.4715, "test_samples_per_second": 1391.807, "test_steps_per_second": 43.494}]}, "total": {"test_mcc": 32.715556133808526, "test_mcc_se": 2.9134427790023647, "test_macro_f1": 49.84048788894377, "test_macro_f1_se": 4.903042664789784}}, "num_model_parameters": 13738755, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.9256848096847534, "test_mcc": 0.311937930900754, "test_macro_f1": 0.4258636294180566, "test_runtime": 1.3872, "test_samples_per_second": 1476.393, "test_steps_per_second": 46.137}, {"test_loss": 0.8991839289665222, "test_mcc": 0.30871109086462994, "test_macro_f1": 0.42464444830147235, "test_runtime": 1.3614, "test_samples_per_second": 1504.336, "test_steps_per_second": 47.01}, {"test_loss": 0.921480655670166, "test_mcc": 0.26663595032007403, "test_macro_f1": 0.405147613076654, "test_runtime": 1.3441, "test_samples_per_second": 1523.738, "test_steps_per_second": 47.617}, {"test_loss": 0.9340915083885193, "test_mcc": 0.2799181549022256, "test_macro_f1": 0.4137946573128968, "test_runtime": 1.3637, "test_samples_per_second": 1501.811, "test_steps_per_second": 46.932}, {"test_loss": 0.938642680644989, "test_mcc": 0.26015311117733075, "test_macro_f1": 0.407922449314321, "test_runtime": 1.3942, "test_samples_per_second": 1468.995, "test_steps_per_second": 45.906}, {"test_loss": 0.9394426941871643, "test_mcc": 0.29102255435293595, "test_macro_f1": 0.41514745335534825, "test_runtime": 1.3959, "test_samples_per_second": 1467.144, "test_steps_per_second": 45.848}, {"test_loss": 0.9160760641098022, "test_mcc": 0.31614636198309776, "test_macro_f1": 0.4296484003801077, "test_runtime": 1.3941, "test_samples_per_second": 1469.023, "test_steps_per_second": 45.907}, {"test_loss": 0.9189176559448242, "test_mcc": 0.26669732615419167, "test_macro_f1": 0.40831500035436524, "test_runtime": 1.395, "test_samples_per_second": 1468.143, "test_steps_per_second": 45.879}, {"test_loss": 0.9125825762748718, "test_mcc": 0.30350139972734236, "test_macro_f1": 0.422744677044194, "test_runtime": 1.3683, "test_samples_per_second": 1496.756, "test_steps_per_second": 46.774}, {"test_loss": 0.9274510145187378, "test_mcc": 0.2956078094160205, "test_macro_f1": 0.4185838775768706, "test_runtime": 1.3742, "test_samples_per_second": 1490.371, "test_steps_per_second": 46.574}]}, "total": {"test_mcc": 29.00331689798602, "test_mcc_se": 1.2754488581315793, "test_macro_f1": 41.71812206134287, "test_macro_f1_se": 0.5243713300997342}}, "num_model_parameters": 13738755, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.09950128197669983, "test_micro_f1": 0.5334008097165991, "test_micro_f1_no_misc": 0.570964247020585, "test_runtime": 3.0015, "test_samples_per_second": 682.315, "test_steps_per_second": 21.322}, {"test_loss": 0.10446373373270035, "test_micro_f1": 0.5643243243243242, "test_micro_f1_no_misc": 0.5996553704767374, "test_runtime": 2.9915, "test_samples_per_second": 684.598, "test_steps_per_second": 21.394}, {"test_loss": 0.09169363975524902, "test_micro_f1": 0.5685328185328185, "test_micro_f1_no_misc": 0.6019517205957884, "test_runtime": 2.9888, "test_samples_per_second": 685.215, "test_steps_per_second": 21.413}, {"test_loss": 0.09949146956205368, "test_micro_f1": 0.5170202269363591, "test_micro_f1_no_misc": 0.5441329179646938, "test_runtime": 3.0076, "test_samples_per_second": 680.948, "test_steps_per_second": 21.28}, {"test_loss": 0.10470638424158096, "test_micro_f1": 0.5525812619502868, "test_micro_f1_no_misc": 0.5862068965517241, "test_runtime": 3.0223, "test_samples_per_second": 677.64, "test_steps_per_second": 21.176}, {"test_loss": 0.10462390631437302, "test_micro_f1": 0.5248990578734858, "test_micro_f1_no_misc": 0.5595408895265425, "test_runtime": 2.9891, "test_samples_per_second": 685.147, "test_steps_per_second": 21.411}, {"test_loss": 0.1061706468462944, "test_micro_f1": 0.5162835249042146, "test_micro_f1_no_misc": 0.5463760770400405, "test_runtime": 3.0263, "test_samples_per_second": 676.734, "test_steps_per_second": 21.148}, {"test_loss": 0.08576904237270355, "test_micro_f1": 0.5728476821192052, "test_micro_f1_no_misc": 0.6057410661980082, "test_runtime": 3.0286, "test_samples_per_second": 676.228, "test_steps_per_second": 21.132}, {"test_loss": 0.09304329752922058, "test_micro_f1": 0.5606736007924715, "test_micro_f1_no_misc": 0.592050209205021, "test_runtime": 2.991, "test_samples_per_second": 684.725, "test_steps_per_second": 21.398}, {"test_loss": 0.09341830760240555, "test_micro_f1": 0.5443279313632031, "test_micro_f1_no_misc": 0.5750251762336355, "test_runtime": 3.0854, "test_samples_per_second": 663.763, "test_steps_per_second": 20.743}]}, "total": {"test_micro_f1": 54.548912385129675, "test_micro_f1_se": 1.330942107836476, "test_micro_f1_no_misc": 57.81644570812776, "test_micro_f1_no_misc_se": 1.4047182816420352}}, "num_model_parameters": 13674505, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.09996414184570312, "test_micro_f1": 0.6805555555555556, "test_micro_f1_no_misc": 0.7067020570670206, "test_runtime": 3.0372, "test_samples_per_second": 674.302, "test_steps_per_second": 21.072}, {"test_loss": 0.09990023076534271, "test_micro_f1": 0.7263273125342091, "test_micro_f1_no_misc": 0.7577595433464145, "test_runtime": 2.9649, "test_samples_per_second": 690.741, "test_steps_per_second": 21.586}, {"test_loss": 0.10368119180202484, "test_micro_f1": 0.7252169339994741, "test_micro_f1_no_misc": 0.7604349351104874, "test_runtime": 3.1195, "test_samples_per_second": 656.515, "test_steps_per_second": 20.516}, {"test_loss": 0.10046181827783585, "test_micro_f1": 0.6948003014318009, "test_micro_f1_no_misc": 0.7305681422098292, "test_runtime": 2.9483, "test_samples_per_second": 694.647, "test_steps_per_second": 21.708}, {"test_loss": 0.11052556335926056, "test_micro_f1": 0.6661021732994638, "test_micro_f1_no_misc": 0.7052154195011338, "test_runtime": 3.0389, "test_samples_per_second": 673.922, "test_steps_per_second": 21.06}, {"test_loss": 0.1036154180765152, "test_micro_f1": 0.7097486882076774, "test_micro_f1_no_misc": 0.7368807339449541, "test_runtime": 3.107, "test_samples_per_second": 659.165, "test_steps_per_second": 20.599}, {"test_loss": 0.11121930181980133, "test_micro_f1": 0.6723449560819803, "test_micro_f1_no_misc": 0.6937346867343367, "test_runtime": 3.1515, "test_samples_per_second": 649.845, "test_steps_per_second": 20.308}, {"test_loss": 0.0938594788312912, "test_micro_f1": 0.7242597120347731, "test_micro_f1_no_misc": 0.7644283121597096, "test_runtime": 3.0353, "test_samples_per_second": 674.738, "test_steps_per_second": 21.086}, {"test_loss": 0.09320341795682907, "test_micro_f1": 0.7176906779661016, "test_micro_f1_no_misc": 0.744236311239193, "test_runtime": 2.9979, "test_samples_per_second": 683.135, "test_steps_per_second": 21.348}, {"test_loss": 0.09751192480325699, "test_micro_f1": 0.7199148029818956, "test_micro_f1_no_misc": 0.7572046109510087, "test_runtime": 2.9451, "test_samples_per_second": 695.381, "test_steps_per_second": 21.731}]}, "total": {"test_micro_f1": 70.36961114092932, "test_micro_f1_se": 1.4468827676989064, "test_micro_f1_no_misc": 73.57164752264089, "test_micro_f1_no_misc_se": 1.602742458234595}}, "num_model_parameters": 13674505, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.09442335367202759, "test_micro_f1": 0.6419040750090155, "test_micro_f1_no_misc": 0.684878799538284, "test_runtime": 2.8652, "test_samples_per_second": 714.789, "test_steps_per_second": 22.337}, {"test_loss": 0.07235677540302277, "test_micro_f1": 0.6997824510514865, "test_micro_f1_no_misc": 0.7384131971720346, "test_runtime": 2.8729, "test_samples_per_second": 712.867, "test_steps_per_second": 22.277}, {"test_loss": 0.07862649857997894, "test_micro_f1": 0.679598198822307, "test_micro_f1_no_misc": 0.7173027047054464, "test_runtime": 2.9324, "test_samples_per_second": 698.413, "test_steps_per_second": 21.825}, {"test_loss": 0.07825188338756561, "test_micro_f1": 0.6864436012418075, "test_micro_f1_no_misc": 0.723047619047619, "test_runtime": 2.7323, "test_samples_per_second": 749.54, "test_steps_per_second": 23.423}, {"test_loss": 0.07872965186834335, "test_micro_f1": 0.6797771222549983, "test_micro_f1_no_misc": 0.7214611872146119, "test_runtime": 2.8883, "test_samples_per_second": 709.072, "test_steps_per_second": 22.158}, {"test_loss": 0.07827607542276382, "test_micro_f1": 0.6671127467380394, "test_micro_f1_no_misc": 0.6965718453683443, "test_runtime": 2.8749, "test_samples_per_second": 712.385, "test_steps_per_second": 22.262}, {"test_loss": 0.07983529567718506, "test_micro_f1": 0.691316146540027, "test_micro_f1_no_misc": 0.7144970414201183, "test_runtime": 2.7294, "test_samples_per_second": 750.36, "test_steps_per_second": 23.449}, {"test_loss": 0.07621999084949493, "test_micro_f1": 0.7167868177136971, "test_micro_f1_no_misc": 0.7466863033873343, "test_runtime": 2.8832, "test_samples_per_second": 710.327, "test_steps_per_second": 22.198}, {"test_loss": 0.07990153133869171, "test_micro_f1": 0.6843806104129264, "test_micro_f1_no_misc": 0.7209302325581396, "test_runtime": 2.7556, "test_samples_per_second": 743.205, "test_steps_per_second": 23.225}, {"test_loss": 0.0874200165271759, "test_micro_f1": 0.6733668341708543, "test_micro_f1_no_misc": 0.7210144927536232, "test_runtime": 2.7821, "test_samples_per_second": 736.122, "test_steps_per_second": 23.004}]}, "total": {"test_micro_f1": 68.2046860395516, "test_micro_f1_se": 1.2315072819605393, "test_micro_f1_no_misc": 71.84803423165556, "test_micro_f1_no_misc_se": 1.1051503076113718}}, "num_model_parameters": 13674505, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.09935411810874939, "test_micro_f1": 0.6172393007836046, "test_micro_f1_no_misc": 0.6509853782581055, "test_runtime": 3.0813, "test_samples_per_second": 664.659, "test_steps_per_second": 20.771}, {"test_loss": 0.10107111185789108, "test_micro_f1": 0.6333333333333333, "test_micro_f1_no_misc": 0.6732046820626384, "test_runtime": 3.0165, "test_samples_per_second": 678.922, "test_steps_per_second": 21.216}, {"test_loss": 0.10244406759738922, "test_micro_f1": 0.6095688127584169, "test_micro_f1_no_misc": 0.6537852391510928, "test_runtime": 2.9008, "test_samples_per_second": 706.007, "test_steps_per_second": 22.063}, {"test_loss": 0.11287674307823181, "test_micro_f1": 0.5935030728709394, "test_micro_f1_no_misc": 0.6444232602478551, "test_runtime": 2.9881, "test_samples_per_second": 685.396, "test_steps_per_second": 21.419}, {"test_loss": 0.10633338242769241, "test_micro_f1": 0.6201366201366202, "test_micro_f1_no_misc": 0.6737657308809294, "test_runtime": 2.9386, "test_samples_per_second": 696.92, "test_steps_per_second": 21.779}, {"test_loss": 0.1014300137758255, "test_micro_f1": 0.6302325581395349, "test_micro_f1_no_misc": 0.6749921948173587, "test_runtime": 2.9293, "test_samples_per_second": 699.132, "test_steps_per_second": 21.848}, {"test_loss": 0.096251480281353, "test_micro_f1": 0.6191198786039455, "test_micro_f1_no_misc": 0.6715039577836411, "test_runtime": 3.0095, "test_samples_per_second": 680.509, "test_steps_per_second": 21.266}, {"test_loss": 0.09344552457332611, "test_micro_f1": 0.6401648998822143, "test_micro_f1_no_misc": 0.689283449587825, "test_runtime": 3.1299, "test_samples_per_second": 654.336, "test_steps_per_second": 20.448}, {"test_loss": 0.11147457361221313, "test_micro_f1": 0.6308396946564886, "test_micro_f1_no_misc": 0.6723071916693785, "test_runtime": 2.958, "test_samples_per_second": 692.368, "test_steps_per_second": 21.637}, {"test_loss": 0.09733571112155914, "test_micro_f1": 0.6672710788757933, "test_micro_f1_no_misc": 0.7097396335583415, "test_runtime": 2.9155, "test_samples_per_second": 702.45, "test_steps_per_second": 21.952}]}, "total": {"test_micro_f1": 62.6140925004089, "test_micro_f1_se": 1.2193661207361786, "test_micro_f1_no_misc": 67.13990718017165, "test_micro_f1_no_misc_se": 1.1809110799963247}}, "num_model_parameters": 13674505, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.6800326108932495, "test_mcc": 0.14844814128889292, "test_macro_f1": 0.5400411332048544, "test_runtime": 1.4398, "test_samples_per_second": 1422.377, "test_steps_per_second": 44.449}, {"test_loss": 0.6689012050628662, "test_mcc": 0.17766170370998918, "test_macro_f1": 0.5881620049163963, "test_runtime": 1.4479, "test_samples_per_second": 1414.423, "test_steps_per_second": 44.201}, {"test_loss": 0.6756374835968018, "test_mcc": 0.1797498491423049, "test_macro_f1": 0.5822855601392206, "test_runtime": 1.4556, "test_samples_per_second": 1406.976, "test_steps_per_second": 43.968}, {"test_loss": 0.6734179854393005, "test_mcc": 0.16576494949406775, "test_macro_f1": 0.5749488429515066, "test_runtime": 1.4431, "test_samples_per_second": 1419.166, "test_steps_per_second": 44.349}, {"test_loss": 0.6703537702560425, "test_mcc": 0.1870718544996167, "test_macro_f1": 0.5825288991121735, "test_runtime": 1.4977, "test_samples_per_second": 1367.415, "test_steps_per_second": 42.732}, {"test_loss": 0.6731575727462769, "test_mcc": 0.17893088099124194, "test_macro_f1": 0.5879992392726452, "test_runtime": 1.4349, "test_samples_per_second": 1427.247, "test_steps_per_second": 44.601}, {"test_loss": 0.6667816042900085, "test_mcc": 0.21491408336570056, "test_macro_f1": 0.5899719045711128, "test_runtime": 1.4248, "test_samples_per_second": 1437.417, "test_steps_per_second": 44.919}, {"test_loss": 0.6637973785400391, "test_mcc": 0.20450644940859655, "test_macro_f1": 0.6002139881236114, "test_runtime": 1.4575, "test_samples_per_second": 1405.148, "test_steps_per_second": 43.911}, {"test_loss": 0.6570813655853271, "test_mcc": 0.24416275305240667, "test_macro_f1": 0.6116807899806619, "test_runtime": 1.4314, "test_samples_per_second": 1430.809, "test_steps_per_second": 44.713}, {"test_loss": 0.663947343826294, "test_mcc": 0.2250395389519955, "test_macro_f1": 0.6046098577104726, "test_runtime": 1.4779, "test_samples_per_second": 1385.717, "test_steps_per_second": 43.304}]}, "total": {"test_mcc": 19.262502039048126, "test_mcc_se": 1.8041830019354874, "test_macro_f1": 58.624422199826554, "test_macro_f1_se": 1.2208611811010774}}, "num_model_parameters": 13738498, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.4427855312824249, "test_mcc": 0.652251253372946, "test_macro_f1": 0.8202789628630538, "test_runtime": 1.3449, "test_samples_per_second": 1522.769, "test_steps_per_second": 47.587}, {"test_loss": 0.4185330271720886, "test_mcc": 0.6859632067583028, "test_macro_f1": 0.8401289098168405, "test_runtime": 1.3584, "test_samples_per_second": 1507.644, "test_steps_per_second": 47.114}, {"test_loss": 0.3933051526546478, "test_mcc": 0.7158030521256725, "test_macro_f1": 0.8559527075962199, "test_runtime": 1.3363, "test_samples_per_second": 1532.611, "test_steps_per_second": 47.894}, {"test_loss": 0.43337345123291016, "test_mcc": 0.66587127503929, "test_macro_f1": 0.8279158516196748, "test_runtime": 1.3678, "test_samples_per_second": 1497.278, "test_steps_per_second": 46.79}, {"test_loss": 0.42813289165496826, "test_mcc": 0.6713218720608815, "test_macro_f1": 0.8331061060297962, "test_runtime": 1.3397, "test_samples_per_second": 1528.723, "test_steps_per_second": 47.773}, {"test_loss": 0.43937215209007263, "test_mcc": 0.6825583360750742, "test_macro_f1": 0.8298821658696349, "test_runtime": 1.3468, "test_samples_per_second": 1520.635, "test_steps_per_second": 47.52}, {"test_loss": 0.44426989555358887, "test_mcc": 0.6522008089379933, "test_macro_f1": 0.8193691879973156, "test_runtime": 1.3444, "test_samples_per_second": 1523.345, "test_steps_per_second": 47.605}, {"test_loss": 0.4217735528945923, "test_mcc": 0.6952099621221886, "test_macro_f1": 0.8380138350604784, "test_runtime": 1.3425, "test_samples_per_second": 1525.489, "test_steps_per_second": 47.672}, {"test_loss": 0.4229186177253723, "test_mcc": 0.6959288590727363, "test_macro_f1": 0.8435975934840015, "test_runtime": 1.3641, "test_samples_per_second": 1501.39, "test_steps_per_second": 46.918}, {"test_loss": 0.45330920815467834, "test_mcc": 0.656396454642375, "test_macro_f1": 0.8238958098751539, "test_runtime": 1.3765, "test_samples_per_second": 1487.853, "test_steps_per_second": 46.495}]}, "total": {"test_mcc": 67.7350508020746, "test_mcc_se": 1.3251047968384146, "test_macro_f1": 83.32141130212169, "test_macro_f1_se": 0.7099205617687057}}, "num_model_parameters": 13738498, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.639147162437439, "test_mcc": 0.3281123425889602, "test_macro_f1": 0.6464913842562368, "test_runtime": 1.4075, "test_samples_per_second": 1455.059, "test_steps_per_second": 45.471}, {"test_loss": 0.6170318126678467, "test_mcc": 0.38000592546083134, "test_macro_f1": 0.6744759532165957, "test_runtime": 1.3802, "test_samples_per_second": 1483.858, "test_steps_per_second": 46.371}, {"test_loss": 0.6618131399154663, "test_mcc": 0.28850806114309574, "test_macro_f1": 0.6106179306966288, "test_runtime": 1.3736, "test_samples_per_second": 1490.978, "test_steps_per_second": 46.593}, {"test_loss": 0.647197425365448, "test_mcc": 0.25609294981212644, "test_macro_f1": 0.6111363431482819, "test_runtime": 1.3614, "test_samples_per_second": 1504.294, "test_steps_per_second": 47.009}, {"test_loss": 0.6554824709892273, "test_mcc": 0.34064894126288375, "test_macro_f1": 0.6603438737426746, "test_runtime": 1.3836, "test_samples_per_second": 1480.249, "test_steps_per_second": 46.258}, {"test_loss": 0.61083984375, "test_mcc": 0.3736924120481652, "test_macro_f1": 0.6796230131906758, "test_runtime": 1.3503, "test_samples_per_second": 1516.706, "test_steps_per_second": 47.397}, {"test_loss": 0.6110321283340454, "test_mcc": 0.35724185243376544, "test_macro_f1": 0.6723242037681574, "test_runtime": 1.3803, "test_samples_per_second": 1483.764, "test_steps_per_second": 46.368}, {"test_loss": 0.6193231344223022, "test_mcc": 0.3852165394715082, "test_macro_f1": 0.6768194746016699, "test_runtime": 1.3502, "test_samples_per_second": 1516.779, "test_steps_per_second": 47.399}, {"test_loss": 0.6534402370452881, "test_mcc": 0.3106651422087942, "test_macro_f1": 0.6413018697523598, "test_runtime": 1.3335, "test_samples_per_second": 1535.83, "test_steps_per_second": 47.995}, {"test_loss": 0.6472413539886475, "test_mcc": 0.3370136829332631, "test_macro_f1": 0.6493641769126139, "test_runtime": 1.3621, "test_samples_per_second": 1503.541, "test_steps_per_second": 46.986}]}, "total": {"test_mcc": 33.571978493633935, "test_mcc_se": 2.5802340693271972, "test_macro_f1": 65.22498223285893, "test_macro_f1_se": 1.5869857396065976}}, "num_model_parameters": 13738498, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_loss": 0.6731300354003906, "test_mcc": 0.16682795093919342, "test_macro_f1": 0.579875891071337, "test_runtime": 1.4329, "test_samples_per_second": 1429.29, "test_steps_per_second": 44.665}, {"test_loss": 0.6641029119491577, "test_mcc": 0.22166611673147807, "test_macro_f1": 0.6071286673444243, "test_runtime": 1.4282, "test_samples_per_second": 1433.963, "test_steps_per_second": 44.811}, {"test_loss": 0.6655855178833008, "test_mcc": 0.20522019283003684, "test_macro_f1": 0.5857945975593034, "test_runtime": 1.4112, "test_samples_per_second": 1451.235, "test_steps_per_second": 45.351}, {"test_loss": 0.6633596420288086, "test_mcc": 0.21606370235135652, "test_macro_f1": 0.6008301780411103, "test_runtime": 1.3714, "test_samples_per_second": 1493.391, "test_steps_per_second": 46.668}, {"test_loss": 0.6509150862693787, "test_mcc": 0.2542912591876981, "test_macro_f1": 0.626604648491896, "test_runtime": 1.4714, "test_samples_per_second": 1391.858, "test_steps_per_second": 43.496}, {"test_loss": 0.6627111434936523, "test_mcc": 0.21635416937306873, "test_macro_f1": 0.6031439527863146, "test_runtime": 1.4287, "test_samples_per_second": 1433.507, "test_steps_per_second": 44.797}, {"test_loss": 0.6753562688827515, "test_mcc": 0.19908495463566253, "test_macro_f1": 0.5900897736115367, "test_runtime": 1.4006, "test_samples_per_second": 1462.247, "test_steps_per_second": 45.695}, {"test_loss": 0.6640027761459351, "test_mcc": 0.21301084456987737, "test_macro_f1": 0.5973268825043356, "test_runtime": 1.4041, "test_samples_per_second": 1458.609, "test_steps_per_second": 45.582}, {"test_loss": 0.6576345562934875, "test_mcc": 0.253336221381898, "test_macro_f1": 0.6261072938835035, "test_runtime": 1.394, "test_samples_per_second": 1469.177, "test_steps_per_second": 45.912}, {"test_loss": 0.663414716720581, "test_mcc": 0.23283697973880413, "test_macro_f1": 0.61465956137708, "test_runtime": 1.424, "test_samples_per_second": 1438.161, "test_steps_per_second": 44.943}]}, "total": {"test_mcc": 21.786923917390737, "test_mcc_se": 1.596346186086808, "test_macro_f1": 60.31561446670841, "test_macro_f1_se": 0.9861246469122528}}, "num_model_parameters": 13738498, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 5.978260869565218, "test_f1": 6.189114089571755}]}, "total": {"test_em": 0.5978260869565217, "test_em_se": 1.1717391304347826, "test_f1": 0.6189114089571756, "test_f1_se": 1.213066361556064}}, "num_model_parameters": 13672706, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.8259313106536865, "test_mcc": 0.4851041230135557, "test_macro_f1": 0.6594928638856171, "test_runtime": 4.1648, "test_samples_per_second": 491.744, "test_steps_per_second": 15.367}, {"test_loss": 0.8770625591278076, "test_mcc": 0.45130208770248925, "test_macro_f1": 0.6349348929153708, "test_runtime": 4.1792, "test_samples_per_second": 490.046, "test_steps_per_second": 15.314}, {"test_loss": 0.9354835748672485, "test_mcc": 0.41666586765226604, "test_macro_f1": 0.6089894723394411, "test_runtime": 4.1262, "test_samples_per_second": 496.345, "test_steps_per_second": 15.511}, {"test_loss": 0.858107328414917, "test_mcc": 0.4780838718014873, "test_macro_f1": 0.6522897206779755, "test_runtime": 4.1394, "test_samples_per_second": 494.753, "test_steps_per_second": 15.461}, {"test_loss": 0.8985576629638672, "test_mcc": 0.42507561286223644, "test_macro_f1": 0.6136047827980039, "test_runtime": 4.0372, "test_samples_per_second": 507.279, "test_steps_per_second": 15.852}, {"test_loss": 0.9156005382537842, "test_mcc": 0.399719994632766, "test_macro_f1": 0.5889811669198446, "test_runtime": 4.126, "test_samples_per_second": 496.362, "test_steps_per_second": 15.511}, {"test_loss": 0.8542719483375549, "test_mcc": 0.4422693362990375, "test_macro_f1": 0.619900106213107, "test_runtime": 4.0723, "test_samples_per_second": 502.912, "test_steps_per_second": 15.716}, {"test_loss": 0.8547666668891907, "test_mcc": 0.4257207297248493, "test_macro_f1": 0.6137939871768013, "test_runtime": 4.1619, "test_samples_per_second": 492.084, "test_steps_per_second": 15.378}, {"test_loss": 0.8849054574966431, "test_mcc": 0.4470368497707236, "test_macro_f1": 0.6307488959671558, "test_runtime": 4.1681, "test_samples_per_second": 491.355, "test_steps_per_second": 15.355}, {"test_loss": 0.8755559921264648, "test_mcc": 0.4079944394926532, "test_macro_f1": 0.6036733723872575, "test_runtime": 4.0294, "test_samples_per_second": 508.259, "test_steps_per_second": 15.883}]}, "total": {"test_mcc": 43.789729129520644, "test_mcc_se": 1.7580500830613897, "test_macro_f1": 62.264092612805754, "test_macro_f1_se": 1.3548657603769527}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.08563782274723053, "test_micro_f1": 0.7305660377358492, "test_micro_f1_no_misc": 0.7816091954022989, "test_runtime": 7.7174, "test_samples_per_second": 265.373, "test_steps_per_second": 8.293}, {"test_loss": 0.07155980169773102, "test_micro_f1": 0.7600661886376173, "test_micro_f1_no_misc": 0.7908330301927974, "test_runtime": 5.9268, "test_samples_per_second": 345.546, "test_steps_per_second": 10.798}, {"test_loss": 0.08029364794492722, "test_micro_f1": 0.7682083997873471, "test_micro_f1_no_misc": 0.8047294876388391, "test_runtime": 7.5682, "test_samples_per_second": 270.607, "test_steps_per_second": 8.456}, {"test_loss": 0.07987995445728302, "test_micro_f1": 0.7364476642518113, "test_micro_f1_no_misc": 0.777027027027027, "test_runtime": 7.3432, "test_samples_per_second": 278.897, "test_steps_per_second": 8.716}, {"test_loss": 0.07714369893074036, "test_micro_f1": 0.7341772151898733, "test_micro_f1_no_misc": 0.7725065371684722, "test_runtime": 7.4054, "test_samples_per_second": 276.555, "test_steps_per_second": 8.642}, {"test_loss": 0.07982088625431061, "test_micro_f1": 0.7294968028912983, "test_micro_f1_no_misc": 0.7724550898203594, "test_runtime": 7.6497, "test_samples_per_second": 267.724, "test_steps_per_second": 8.366}, {"test_loss": 0.07774636149406433, "test_micro_f1": 0.7321243523316062, "test_micro_f1_no_misc": 0.7713498622589532, "test_runtime": 7.6881, "test_samples_per_second": 266.385, "test_steps_per_second": 8.325}, {"test_loss": 0.07631233334541321, "test_micro_f1": 0.7284017278617709, "test_micro_f1_no_misc": 0.7730239303843365, "test_runtime": 7.6554, "test_samples_per_second": 267.522, "test_steps_per_second": 8.36}, {"test_loss": 0.07782482355833054, "test_micro_f1": 0.767643865363735, "test_micro_f1_no_misc": 0.799260628465804, "test_runtime": 7.2927, "test_samples_per_second": 280.829, "test_steps_per_second": 8.776}, {"test_loss": 0.08203399181365967, "test_micro_f1": 0.7460614152202937, "test_micro_f1_no_misc": 0.7916366258111031, "test_runtime": 6.4309, "test_samples_per_second": 318.464, "test_steps_per_second": 9.952}]}, "total": {"test_micro_f1": 74.33193669271202, "test_micro_f1_se": 0.9975897841145357, "test_micro_f1_no_misc": 78.34431414169991, "test_micro_f1_no_misc_se": 0.7632345326251632}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.5943644642829895, "test_mcc": 0.4035598238251887, "test_macro_f1": 0.663782128756748, "test_runtime": 3.4539, "test_samples_per_second": 592.96, "test_steps_per_second": 18.53}, {"test_loss": 0.6090066432952881, "test_mcc": 0.5260628602221953, "test_macro_f1": 0.7293516637409021, "test_runtime": 3.5478, "test_samples_per_second": 577.259, "test_steps_per_second": 18.039}, {"test_loss": 0.5803389549255371, "test_mcc": 0.4480809151327521, "test_macro_f1": 0.7010537726975625, "test_runtime": 3.41, "test_samples_per_second": 600.581, "test_steps_per_second": 18.768}, {"test_loss": 0.5743892192840576, "test_mcc": 0.5094552649297744, "test_macro_f1": 0.7228287532528275, "test_runtime": 3.5175, "test_samples_per_second": 582.238, "test_steps_per_second": 18.195}, {"test_loss": 0.6046954393386841, "test_mcc": 0.4279718343094289, "test_macro_f1": 0.6622422668296053, "test_runtime": 3.4242, "test_samples_per_second": 598.095, "test_steps_per_second": 18.69}, {"test_loss": 0.6026453971862793, "test_mcc": 0.39549925963452404, "test_macro_f1": 0.6775361748358553, "test_runtime": 3.3506, "test_samples_per_second": 611.226, "test_steps_per_second": 19.101}, {"test_loss": 0.6064542531967163, "test_mcc": 0.470220288134885, "test_macro_f1": 0.6986650303862337, "test_runtime": 3.4079, "test_samples_per_second": 600.951, "test_steps_per_second": 18.78}, {"test_loss": 0.5972097516059875, "test_mcc": 0.42106629890655295, "test_macro_f1": 0.6647434099474223, "test_runtime": 3.3274, "test_samples_per_second": 615.502, "test_steps_per_second": 19.234}, {"test_loss": 0.5993454456329346, "test_mcc": 0.5046777824716374, "test_macro_f1": 0.7337872240235055, "test_runtime": 3.4946, "test_samples_per_second": 586.042, "test_steps_per_second": 18.314}, {"test_loss": 0.6020677089691162, "test_mcc": 0.4896773239301478, "test_macro_f1": 0.7076972213350368, "test_runtime": 3.4774, "test_samples_per_second": 588.952, "test_steps_per_second": 18.405}]}, "total": {"test_mcc": 45.96271651497087, "test_mcc_se": 2.9085866425096176, "test_macro_f1": 69.61687645805699, "test_macro_f1_se": 1.7192272689018442}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_em": 41.98295894655306, "test_f1": 46.40071334439226}, {"test_em": 39.30232558139535, "test_f1": 44.71079701535691}, {"test_em": 38.717156105100464, "test_f1": 43.015885127404836}, {"test_em": 37.92834890965732, "test_f1": 43.32951618189675}, {"test_em": 39.45945945945946, "test_f1": 43.84276112192963}, {"test_em": 37.23978411719352, "test_f1": 43.173413320371736}, {"test_em": 39.40774487471526, "test_f1": 44.3124823213612}, {"test_em": 38.55702094647013, "test_f1": 43.744071786984314}, {"test_em": 42.03921568627451, "test_f1": 46.90948364248308}, {"test_em": 34.78260869565217, "test_f1": 39.698412473124954}]}, "total": {"test_em": 38.941662332247134, "test_em_se": 1.3209459612891568, "test_f1": 43.91375363353057, "test_f1_se": 1.2301447389022926}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.9511048793792725, "test_mcc": 0.3863764665944451, "test_macro_f1": 0.5805508205864863, "test_runtime": 1.4116, "test_samples_per_second": 1450.87, "test_steps_per_second": 45.34}, {"test_loss": 0.9286264777183533, "test_mcc": 0.3845167885982489, "test_macro_f1": 0.5730427292066168, "test_runtime": 1.4126, "test_samples_per_second": 1449.826, "test_steps_per_second": 45.307}, {"test_loss": 0.938200056552887, "test_mcc": 0.3815460461537334, "test_macro_f1": 0.5794500320674856, "test_runtime": 1.4262, "test_samples_per_second": 1435.989, "test_steps_per_second": 44.875}, {"test_loss": 0.9134310483932495, "test_mcc": 0.41114695131440143, "test_macro_f1": 0.6056435573153549, "test_runtime": 1.4565, "test_samples_per_second": 1406.135, "test_steps_per_second": 43.942}, {"test_loss": 0.93016117811203, "test_mcc": 0.3557610412985386, "test_macro_f1": 0.5338473427927068, "test_runtime": 1.4239, "test_samples_per_second": 1438.27, "test_steps_per_second": 44.946}, {"test_loss": 0.9744637608528137, "test_mcc": 0.36949898362356515, "test_macro_f1": 0.5786122154869996, "test_runtime": 1.401, "test_samples_per_second": 1461.802, "test_steps_per_second": 45.681}, {"test_loss": 0.9423920512199402, "test_mcc": 0.3157946111409736, "test_macro_f1": 0.46591292595554656, "test_runtime": 1.4045, "test_samples_per_second": 1458.145, "test_steps_per_second": 45.567}, {"test_loss": 0.9490402936935425, "test_mcc": 0.28996888938527704, "test_macro_f1": 0.4108295649808054, "test_runtime": 1.4711, "test_samples_per_second": 1392.13, "test_steps_per_second": 43.504}, {"test_loss": 0.9524816870689392, "test_mcc": 0.2848436357094049, "test_macro_f1": 0.40969788329878787, "test_runtime": 1.4593, "test_samples_per_second": 1403.388, "test_steps_per_second": 43.856}, {"test_loss": 0.9637970924377441, "test_mcc": 0.2659627225069846, "test_macro_f1": 0.40271382978424913, "test_runtime": 1.4116, "test_samples_per_second": 1450.827, "test_steps_per_second": 45.338}]}, "total": {"test_mcc": 34.45416136325573, "test_mcc_se": 3.163481391437618, "test_macro_f1": 51.40300901475039, "test_macro_f1_se": 5.118815543044562}}, "num_model_parameters": 13738755, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.11979299783706665, "test_micro_f1": 0.6658452439625432, "test_micro_f1_no_misc": 0.7023271969433831, "test_runtime": 3.0639, "test_samples_per_second": 668.422, "test_steps_per_second": 20.888}, {"test_loss": 0.1116604208946228, "test_micro_f1": 0.6915382535820492, "test_micro_f1_no_misc": 0.7335034633612832, "test_runtime": 2.8411, "test_samples_per_second": 720.839, "test_steps_per_second": 22.526}, {"test_loss": 0.11154235899448395, "test_micro_f1": 0.6921712693184696, "test_micro_f1_no_misc": 0.7321554770318023, "test_runtime": 3.0679, "test_samples_per_second": 667.561, "test_steps_per_second": 20.861}, {"test_loss": 0.1105869859457016, "test_micro_f1": 0.6923076923076923, "test_micro_f1_no_misc": 0.732962447844228, "test_runtime": 2.9322, "test_samples_per_second": 698.44, "test_steps_per_second": 21.826}, {"test_loss": 0.11242640763521194, "test_micro_f1": 0.6693722943722944, "test_micro_f1_no_misc": 0.6981201621820862, "test_runtime": 2.9703, "test_samples_per_second": 689.491, "test_steps_per_second": 21.547}, {"test_loss": 0.11226800084114075, "test_micro_f1": 0.6937348749663889, "test_micro_f1_no_misc": 0.712966383450314, "test_runtime": 3.0462, "test_samples_per_second": 672.308, "test_steps_per_second": 21.01}, {"test_loss": 0.10550062358379364, "test_micro_f1": 0.6822995461422088, "test_micro_f1_no_misc": 0.7098121085594989, "test_runtime": 3.111, "test_samples_per_second": 658.312, "test_steps_per_second": 20.572}, {"test_loss": 0.10377576947212219, "test_micro_f1": 0.7067024128686329, "test_micro_f1_no_misc": 0.7546193643754618, "test_runtime": 2.9629, "test_samples_per_second": 691.22, "test_steps_per_second": 21.601}, {"test_loss": 0.10895483195781708, "test_micro_f1": 0.693535723632557, "test_micro_f1_no_misc": 0.7115998581057114, "test_runtime": 2.9184, "test_samples_per_second": 701.744, "test_steps_per_second": 21.929}, {"test_loss": 0.1118413507938385, "test_micro_f1": 0.6951731374606506, "test_micro_f1_no_misc": 0.7239176721078779, "test_runtime": 2.8717, "test_samples_per_second": 713.174, "test_steps_per_second": 22.287}]}, "total": {"test_micro_f1": 68.82680448613488, "test_micro_f1_se": 0.7682831769091875, "test_micro_f1_no_misc": 72.11984133961647, "test_micro_f1_no_misc_se": 1.0760170606928046}}, "num_model_parameters": 13674505, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.4505631625652313, "test_mcc": 0.6410276904267794, "test_macro_f1": 0.8201682677394571, "test_runtime": 1.3795, "test_samples_per_second": 1484.631, "test_steps_per_second": 46.395}, {"test_loss": 0.4541802406311035, "test_mcc": 0.6383156984455722, "test_macro_f1": 0.8178116283701035, "test_runtime": 1.3165, "test_samples_per_second": 1555.6, "test_steps_per_second": 48.613}, {"test_loss": 0.462405264377594, "test_mcc": 0.6318980707751227, "test_macro_f1": 0.8118917214450352, "test_runtime": 1.3097, "test_samples_per_second": 1563.682, "test_steps_per_second": 48.865}, {"test_loss": 0.44491174817085266, "test_mcc": 0.6536216368650402, "test_macro_f1": 0.8233453965527816, "test_runtime": 1.3248, "test_samples_per_second": 1545.884, "test_steps_per_second": 48.309}, {"test_loss": 0.42696696519851685, "test_mcc": 0.6763830942678419, "test_macro_f1": 0.8372933762297223, "test_runtime": 1.3168, "test_samples_per_second": 1555.284, "test_steps_per_second": 48.603}, {"test_loss": 0.4285161793231964, "test_mcc": 0.6610103383535165, "test_macro_f1": 0.8285128079496562, "test_runtime": 1.3226, "test_samples_per_second": 1548.455, "test_steps_per_second": 48.389}, {"test_loss": 0.46472638845443726, "test_mcc": 0.6485505846426295, "test_macro_f1": 0.8214841375884645, "test_runtime": 1.3108, "test_samples_per_second": 1562.385, "test_steps_per_second": 48.825}, {"test_loss": 0.4623018503189087, "test_mcc": 0.6467001413497138, "test_macro_f1": 0.8169412158126623, "test_runtime": 1.3272, "test_samples_per_second": 1543.154, "test_steps_per_second": 48.224}, {"test_loss": 0.44152194261550903, "test_mcc": 0.6549554427447429, "test_macro_f1": 0.8268571625086453, "test_runtime": 1.323, "test_samples_per_second": 1547.992, "test_steps_per_second": 48.375}, {"test_loss": 0.44228053092956543, "test_mcc": 0.6624974553468664, "test_macro_f1": 0.8280326773509901, "test_runtime": 1.3141, "test_samples_per_second": 1558.491, "test_steps_per_second": 48.703}]}, "total": {"test_mcc": 65.14960153217825, "test_mcc_se": 0.812466327668873, "test_macro_f1": 82.32338391547518, "test_macro_f1_se": 0.44876351242200974}}, "num_model_parameters": 13738498, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_em": 37.955073586367156, "test_f1": 43.874654428260854}, {"test_em": 37.674418604651166, "test_f1": 43.77016001521008}, {"test_em": 38.17619783616692, "test_f1": 43.19221139188626}, {"test_em": 38.3177570093458, "test_f1": 42.89104371482268}, {"test_em": 30.424710424710426, "test_f1": 35.366914055989696}, {"test_em": 37.085582112567465, "test_f1": 41.77372990845258}, {"test_em": 34.24449506454062, "test_f1": 40.020864347401584}, {"test_em": 34.29014740108612, "test_f1": 40.228598634952}, {"test_em": 38.35294117647059, "test_f1": 43.190944106515026}, {"test_em": 36.18012422360248, "test_f1": 41.222348940082775}]}, "total": {"test_em": 36.27014474395088, "test_em_se": 1.598205520128586, "test_f1": 41.55314695435736, "test_f1_se": 1.6002439871764185}}, "num_model_parameters": 134702594, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_em": 30.286599535243997, "test_f1": 36.09032168104712}, {"test_em": 26.046511627906977, "test_f1": 31.79281860250613}, {"test_em": 39.10355486862442, "test_f1": 44.60149046486438}, {"test_em": 33.72274143302181, "test_f1": 39.165866353917934}, {"test_em": 33.97683397683398, "test_f1": 39.11679201351914}, {"test_em": 41.480339244410175, "test_f1": 46.495644550771765}, {"test_em": 36.14274867122248, "test_f1": 41.89303211969036}, {"test_em": 28.161365399534525, "test_f1": 32.89693788739057}, {"test_em": 36.23529411764706, "test_f1": 42.04909068888306}, {"test_em": 39.0527950310559, "test_f1": 45.81800433190616}]}, "total": {"test_em": 34.42087839055013, "test_em_se": 3.1097801528098126, "test_f1": 39.99199986944966, "test_f1_se": 3.197802906540675}}, "num_model_parameters": 134702594, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_em": 42.91247095274981, "test_f1": 50.52515841395128}, {"test_em": 45.348837209302324, "test_f1": 52.40012514465317}, {"test_em": 44.04945904173107, "test_f1": 50.80645263763585}, {"test_em": 42.834890965732086, "test_f1": 49.41630367064742}, {"test_em": 37.915057915057915, "test_f1": 44.65809593739712}, {"test_em": 44.02467232074017, "test_f1": 50.76456652949555}, {"test_em": 43.65983295368261, "test_f1": 49.91992169676219}, {"test_em": 44.37548487199379, "test_f1": 51.209297050955406}, {"test_em": 43.84313725490196, "test_f1": 50.66633889862806}, {"test_em": 41.537267080745345, "test_f1": 47.70679738586639}]}, "total": {"test_em": 43.05011105666371, "test_em_se": 1.2854672816293775, "test_f1": 49.80730573659924, "test_f1_se": 1.3539653137359537}}, "num_model_parameters": 134702594, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.5948111414909363, "test_mcc": 0.6007777586289609, "test_macro_f1": 0.5676418388630479, "test_runtime": 16.0729, "test_samples_per_second": 127.42, "test_steps_per_second": 15.927}, {"test_loss": 0.6756865382194519, "test_mcc": 0.5406531431400491, "test_macro_f1": 0.5201190975600323, "test_runtime": 15.2965, "test_samples_per_second": 133.887, "test_steps_per_second": 16.736}, {"test_loss": 0.6314682960510254, "test_mcc": 0.5707486919688421, "test_macro_f1": 0.56001020579285, "test_runtime": 15.643, "test_samples_per_second": 130.921, "test_steps_per_second": 16.365}, {"test_loss": 0.6313557624816895, "test_mcc": 0.5644196321002312, "test_macro_f1": 0.5881444736325832, "test_runtime": 15.2116, "test_samples_per_second": 134.634, "test_steps_per_second": 16.829}, {"test_loss": 0.611475944519043, "test_mcc": 0.6042711275306486, "test_macro_f1": 0.5786506351543055, "test_runtime": 14.9743, "test_samples_per_second": 136.768, "test_steps_per_second": 17.096}, {"test_loss": 0.6355537176132202, "test_mcc": 0.5643619969426199, "test_macro_f1": 0.5614987882930467, "test_runtime": 15.4793, "test_samples_per_second": 132.306, "test_steps_per_second": 16.538}, {"test_loss": 0.6005860567092896, "test_mcc": 0.609924486906339, "test_macro_f1": 0.572875802389481, "test_runtime": 14.8442, "test_samples_per_second": 137.966, "test_steps_per_second": 17.246}, {"test_loss": 0.6331700086593628, "test_mcc": 0.5637665504541252, "test_macro_f1": 0.5749539312461395, "test_runtime": 15.9603, "test_samples_per_second": 128.319, "test_steps_per_second": 16.04}, {"test_loss": 0.7123953104019165, "test_mcc": 0.5188223643288628, "test_macro_f1": 0.5222169637346235, "test_runtime": 15.7979, "test_samples_per_second": 129.637, "test_steps_per_second": 16.205}, {"test_loss": 0.6191898584365845, "test_mcc": 0.6038608676435748, "test_macro_f1": 0.6064989781353535, "test_runtime": 15.4245, "test_samples_per_second": 132.776, "test_steps_per_second": 16.597}]}, "total": {"test_mcc": 57.416066196442536, "test_mcc_se": 1.8790490183769788, "test_macro_f1": 56.526107148014624, "test_macro_f1_se": 1.6648362184336327}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.8317346572875977, "test_mcc": 0.3999305462385102, "test_macro_f1": 0.5406604150178967, "test_runtime": 3.8331, "test_samples_per_second": 534.3, "test_steps_per_second": 16.697}, {"test_loss": 0.8179334402084351, "test_mcc": 0.4169125793533658, "test_macro_f1": 0.5802014738720193, "test_runtime": 3.6281, "test_samples_per_second": 564.477, "test_steps_per_second": 17.64}, {"test_loss": 0.8347162008285522, "test_mcc": 0.4018515739055989, "test_macro_f1": 0.5577074416128155, "test_runtime": 3.6386, "test_samples_per_second": 562.85, "test_steps_per_second": 17.589}, {"test_loss": 0.8322739601135254, "test_mcc": 0.4331027756917295, "test_macro_f1": 0.5896214416672971, "test_runtime": 3.6755, "test_samples_per_second": 557.208, "test_steps_per_second": 17.413}, {"test_loss": 0.7977245450019836, "test_mcc": 0.4257310482911008, "test_macro_f1": 0.5954325161515213, "test_runtime": 3.7058, "test_samples_per_second": 552.64, "test_steps_per_second": 17.27}, {"test_loss": 0.8907067775726318, "test_mcc": 0.35331638096825246, "test_macro_f1": 0.4835565955672993, "test_runtime": 3.8348, "test_samples_per_second": 534.056, "test_steps_per_second": 16.689}, {"test_loss": 0.7848453521728516, "test_mcc": 0.4240646327016191, "test_macro_f1": 0.5618515546360626, "test_runtime": 3.6334, "test_samples_per_second": 563.667, "test_steps_per_second": 17.615}, {"test_loss": 0.8326398134231567, "test_mcc": 0.37288401024009094, "test_macro_f1": 0.4722909251159623, "test_runtime": 3.7137, "test_samples_per_second": 551.479, "test_steps_per_second": 17.234}, {"test_loss": 0.8451032638549805, "test_mcc": 0.4044109564595934, "test_macro_f1": 0.5590463075469371, "test_runtime": 3.7589, "test_samples_per_second": 544.84, "test_steps_per_second": 17.026}, {"test_loss": 0.8407335877418518, "test_mcc": 0.4325510360035901, "test_macro_f1": 0.5792773358556033, "test_runtime": 3.8279, "test_samples_per_second": 535.018, "test_steps_per_second": 16.719}]}, "total": {"test_mcc": 40.64755539853451, "test_mcc_se": 1.6268906922137456, "test_macro_f1": 55.19646007043415, "test_macro_f1_se": 2.628562331197286}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.1392979770898819, "test_micro_f1": 0.4580351333767078, "test_micro_f1_no_misc": 0.5035971223021583, "test_runtime": 7.4414, "test_samples_per_second": 275.217, "test_steps_per_second": 8.601}, {"test_loss": 0.12646913528442383, "test_micro_f1": 0.4699248120300752, "test_micro_f1_no_misc": 0.505050505050505, "test_runtime": 7.2419, "test_samples_per_second": 282.798, "test_steps_per_second": 8.837}, {"test_loss": 0.12632162868976593, "test_micro_f1": 0.47310584152689417, "test_micro_f1_no_misc": 0.49969154842689695, "test_runtime": 7.2543, "test_samples_per_second": 282.316, "test_steps_per_second": 8.822}, {"test_loss": 0.12906324863433838, "test_micro_f1": 0.43384982121573296, "test_micro_f1_no_misc": 0.46163601775523144, "test_runtime": 7.0383, "test_samples_per_second": 290.981, "test_steps_per_second": 9.093}, {"test_loss": 0.13966171443462372, "test_micro_f1": 0.45663716814159294, "test_micro_f1_no_misc": 0.48280254777070064, "test_runtime": 7.4759, "test_samples_per_second": 273.947, "test_steps_per_second": 8.561}, {"test_loss": 0.1344464123249054, "test_micro_f1": 0.499752597723899, "test_micro_f1_no_misc": 0.5241979336595975, "test_runtime": 6.0081, "test_samples_per_second": 340.874, "test_steps_per_second": 10.652}, {"test_loss": 0.12950241565704346, "test_micro_f1": 0.47645739910313906, "test_micro_f1_no_misc": 0.5137278828553997, "test_runtime": 6.385, "test_samples_per_second": 320.751, "test_steps_per_second": 10.023}, {"test_loss": 0.1172124370932579, "test_micro_f1": 0.475177304964539, "test_micro_f1_no_misc": 0.5067698259187621, "test_runtime": 7.5281, "test_samples_per_second": 272.047, "test_steps_per_second": 8.501}, {"test_loss": 0.1250504106283188, "test_micro_f1": 0.47577092511013214, "test_micro_f1_no_misc": 0.5014819205690575, "test_runtime": 6.8939, "test_samples_per_second": 297.074, "test_steps_per_second": 9.284}, {"test_loss": 0.13015209138393402, "test_micro_f1": 0.4958586416344561, "test_micro_f1_no_misc": 0.5304914150384842, "test_runtime": 6.934, "test_samples_per_second": 295.356, "test_steps_per_second": 9.23}]}, "total": {"test_micro_f1": 47.145696448271686, "test_micro_f1_se": 1.1819151526216585, "test_micro_f1_no_misc": 50.29446719346793, "test_micro_f1_no_misc_se": 1.2172226638548322}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.10383568704128265, "test_micro_f1": 0.6768670309653916, "test_micro_f1_no_misc": 0.7186606778276846, "test_runtime": 6.6, "test_samples_per_second": 310.304, "test_steps_per_second": 9.697}, {"test_loss": 0.08742953836917877, "test_micro_f1": 0.7070401211203634, "test_micro_f1_no_misc": 0.7409863240779114, "test_runtime": 6.5369, "test_samples_per_second": 313.296, "test_steps_per_second": 9.791}, {"test_loss": 0.10294035822153091, "test_micro_f1": 0.6781272860277981, "test_micro_f1_no_misc": 0.7182866556836902, "test_runtime": 6.2819, "test_samples_per_second": 326.016, "test_steps_per_second": 10.188}, {"test_loss": 0.09843029081821442, "test_micro_f1": 0.7025270758122744, "test_micro_f1_no_misc": 0.7286696320258795, "test_runtime": 6.302, "test_samples_per_second": 324.978, "test_steps_per_second": 10.156}, {"test_loss": 0.09707885980606079, "test_micro_f1": 0.7159640635798205, "test_micro_f1_no_misc": 0.7449018853405155, "test_runtime": 6.6095, "test_samples_per_second": 309.856, "test_steps_per_second": 9.683}, {"test_loss": 0.09526284784078598, "test_micro_f1": 0.7104736490993996, "test_micro_f1_no_misc": 0.743091859596714, "test_runtime": 6.5923, "test_samples_per_second": 310.665, "test_steps_per_second": 9.708}, {"test_loss": 0.09859806299209595, "test_micro_f1": 0.6813725490196079, "test_micro_f1_no_misc": 0.7155676941084667, "test_runtime": 6.1065, "test_samples_per_second": 335.378, "test_steps_per_second": 10.481}, {"test_loss": 0.10135902464389801, "test_micro_f1": 0.6784170269371467, "test_micro_f1_no_misc": 0.7057142857142856, "test_runtime": 6.2665, "test_samples_per_second": 326.815, "test_steps_per_second": 10.213}, {"test_loss": 0.09169792383909225, "test_micro_f1": 0.6958054282692985, "test_micro_f1_no_misc": 0.7261296660117877, "test_runtime": 6.1617, "test_samples_per_second": 332.378, "test_steps_per_second": 10.387}, {"test_loss": 0.10583394765853882, "test_micro_f1": 0.6859154929577465, "test_micro_f1_no_misc": 0.7202797202797202, "test_runtime": 6.3053, "test_samples_per_second": 324.808, "test_steps_per_second": 10.15}]}, "total": {"test_micro_f1": 69.32509723788847, "test_micro_f1_se": 0.9256441400858243, "test_micro_f1_no_misc": 72.62288400666655, "test_micro_f1_no_misc_se": 0.8126187878240345}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.1473836600780487, "test_micro_f1": 0.533201189296333, "test_micro_f1_no_misc": 0.5666901905434015, "test_runtime": 6.5791, "test_samples_per_second": 311.289, "test_steps_per_second": 9.728}, {"test_loss": 0.14189134538173676, "test_micro_f1": 0.6094473602963877, "test_micro_f1_no_misc": 0.6491582491582492, "test_runtime": 6.8973, "test_samples_per_second": 296.928, "test_steps_per_second": 9.279}, {"test_loss": 0.1404268741607666, "test_micro_f1": 0.5602586713697825, "test_micro_f1_no_misc": 0.6028368794326241, "test_runtime": 6.4369, "test_samples_per_second": 318.165, "test_steps_per_second": 9.943}, {"test_loss": 0.15650473535060883, "test_micro_f1": 0.549652118912081, "test_micro_f1_no_misc": 0.5883161512027492, "test_runtime": 6.6581, "test_samples_per_second": 307.597, "test_steps_per_second": 9.612}, {"test_loss": 0.14943385124206543, "test_micro_f1": 0.5608187134502924, "test_micro_f1_no_misc": 0.5994832041343668, "test_runtime": 6.3037, "test_samples_per_second": 324.891, "test_steps_per_second": 10.153}, {"test_loss": 0.15644894540309906, "test_micro_f1": 0.5084850354828756, "test_micro_f1_no_misc": 0.5407925407925408, "test_runtime": 6.4251, "test_samples_per_second": 318.748, "test_steps_per_second": 9.961}, {"test_loss": 0.14232909679412842, "test_micro_f1": 0.5368522690698423, "test_micro_f1_no_misc": 0.572825707300035, "test_runtime": 6.888, "test_samples_per_second": 297.331, "test_steps_per_second": 9.292}, {"test_loss": 0.13513870537281036, "test_micro_f1": 0.5673575129533679, "test_micro_f1_no_misc": 0.600627833972794, "test_runtime": 6.8885, "test_samples_per_second": 297.307, "test_steps_per_second": 9.291}, {"test_loss": 0.1509508639574051, "test_micro_f1": 0.5326695706285004, "test_micro_f1_no_misc": 0.5655682582380632, "test_runtime": 5.9845, "test_samples_per_second": 342.217, "test_steps_per_second": 10.694}, {"test_loss": 0.1529819667339325, "test_micro_f1": 0.5527831094049903, "test_micro_f1_no_misc": 0.5868673050615594, "test_runtime": 6.29, "test_samples_per_second": 325.597, "test_steps_per_second": 10.175}]}, "total": {"test_micro_f1": 55.11525550864454, "test_micro_f1_se": 1.6696519250683506, "test_micro_f1_no_misc": 58.731663198363826, "test_micro_f1_no_misc_se": 1.8087540131803193}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.6927509903907776, "test_mcc": 0.058033824553810016, "test_macro_f1": 0.5158730158730159, "test_runtime": 3.3428, "test_samples_per_second": 612.656, "test_steps_per_second": 19.145}, {"test_loss": 0.6920045018196106, "test_mcc": 0.06091400858516651, "test_macro_f1": 0.528895468952554, "test_runtime": 3.6304, "test_samples_per_second": 564.125, "test_steps_per_second": 17.629}, {"test_loss": 0.6946310997009277, "test_mcc": 0.08668762999606475, "test_macro_f1": 0.5398917949495935, "test_runtime": 3.5751, "test_samples_per_second": 572.844, "test_steps_per_second": 17.901}, {"test_loss": 0.6950023174285889, "test_mcc": 0.040203386463292176, "test_macro_f1": 0.5182425685536524, "test_runtime": 3.4916, "test_samples_per_second": 586.542, "test_steps_per_second": 18.329}, {"test_loss": 0.6965133547782898, "test_mcc": 0.016686957883899567, "test_macro_f1": 0.5082997261756743, "test_runtime": 3.5584, "test_samples_per_second": 575.543, "test_steps_per_second": 17.986}, {"test_loss": 0.6940710544586182, "test_mcc": 0.03520017549879948, "test_macro_f1": 0.4904458598726115, "test_runtime": 3.5431, "test_samples_per_second": 578.026, "test_steps_per_second": 18.063}, {"test_loss": 0.6933621168136597, "test_mcc": 0.08417765648659947, "test_macro_f1": 0.5337301587301587, "test_runtime": 3.5484, "test_samples_per_second": 577.157, "test_steps_per_second": 18.036}, {"test_loss": 0.7009811997413635, "test_mcc": 0.06917644797207402, "test_macro_f1": 0.5345870766589365, "test_runtime": 3.4542, "test_samples_per_second": 592.906, "test_steps_per_second": 18.528}, {"test_loss": 0.6953099966049194, "test_mcc": 0.016828595843800143, "test_macro_f1": 0.5033327570641004, "test_runtime": 3.672, "test_samples_per_second": 557.729, "test_steps_per_second": 17.429}, {"test_loss": 0.6961537003517151, "test_mcc": 0.026550001725798137, "test_macro_f1": 0.48348045397225725, "test_runtime": 3.5333, "test_samples_per_second": 579.624, "test_steps_per_second": 18.113}]}, "total": {"test_mcc": 4.944586850093042, "test_mcc_se": 1.6185572913901394, "test_macro_f1": 51.56778880802555, "test_macro_f1_se": 1.1924442735885123}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.6418743133544922, "test_mcc": 0.2534680185341604, "test_macro_f1": 0.626712472564176, "test_runtime": 3.5486, "test_samples_per_second": 577.125, "test_steps_per_second": 18.035}, {"test_loss": 0.6453213095664978, "test_mcc": 0.3009827060929441, "test_macro_f1": 0.6277418618941264, "test_runtime": 3.5686, "test_samples_per_second": 573.903, "test_steps_per_second": 17.934}, {"test_loss": 0.6468819379806519, "test_mcc": 0.2731599465801441, "test_macro_f1": 0.6319697947284155, "test_runtime": 3.5667, "test_samples_per_second": 574.202, "test_steps_per_second": 17.944}, {"test_loss": 0.6404098272323608, "test_mcc": 0.30427328389979746, "test_macro_f1": 0.6189430214817252, "test_runtime": 3.6479, "test_samples_per_second": 561.42, "test_steps_per_second": 17.544}, {"test_loss": 0.6526533365249634, "test_mcc": 0.24992371513280937, "test_macro_f1": 0.590138410351462, "test_runtime": 3.708, "test_samples_per_second": 552.321, "test_steps_per_second": 17.26}, {"test_loss": 0.621482253074646, "test_mcc": 0.3723163687364141, "test_macro_f1": 0.6626980829722833, "test_runtime": 3.4472, "test_samples_per_second": 594.113, "test_steps_per_second": 18.566}, {"test_loss": 0.6314249038696289, "test_mcc": 0.30457860610996096, "test_macro_f1": 0.641308657083918, "test_runtime": 3.5568, "test_samples_per_second": 575.807, "test_steps_per_second": 17.994}, {"test_loss": 0.6565333604812622, "test_mcc": 0.2625094316108699, "test_macro_f1": 0.5664968638093217, "test_runtime": 3.5491, "test_samples_per_second": 577.055, "test_steps_per_second": 18.033}, {"test_loss": 0.6923001408576965, "test_mcc": 0.30072016657964373, "test_macro_f1": 0.6168217417835403, "test_runtime": 3.489, "test_samples_per_second": 586.989, "test_steps_per_second": 18.343}, {"test_loss": 0.6586903929710388, "test_mcc": 0.32484969559293697, "test_macro_f1": 0.6424075297000391, "test_runtime": 3.6535, "test_samples_per_second": 560.565, "test_steps_per_second": 17.518}]}, "total": {"test_mcc": 29.46781938869681, "test_mcc_se": 2.300943916679206, "test_macro_f1": 62.25238436369007, "test_macro_f1_se": 1.6948142935354733}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_loss": 0.678364634513855, "test_mcc": 0.1167871107587915, "test_macro_f1": 0.5579907064150061, "test_runtime": 3.8775, "test_samples_per_second": 528.176, "test_steps_per_second": 16.506}, {"test_loss": 0.6901883482933044, "test_mcc": 0.08384525905680694, "test_macro_f1": 0.5271108333984222, "test_runtime": 4.0385, "test_samples_per_second": 507.116, "test_steps_per_second": 15.847}, {"test_loss": 0.6842251420021057, "test_mcc": 0.12395745337440427, "test_macro_f1": 0.5347717943418137, "test_runtime": 3.9925, "test_samples_per_second": 512.958, "test_steps_per_second": 16.03}, {"test_loss": 0.6643949747085571, "test_mcc": 0.20995819332599838, "test_macro_f1": 0.6040264934934252, "test_runtime": 3.8376, "test_samples_per_second": 533.67, "test_steps_per_second": 16.677}, {"test_loss": 0.6727715730667114, "test_mcc": 0.13673042474306443, "test_macro_f1": 0.5679973826372036, "test_runtime": 3.878, "test_samples_per_second": 528.106, "test_steps_per_second": 16.503}, {"test_loss": 0.6932881474494934, "test_mcc": 0.07569064880760994, "test_macro_f1": 0.5330120613139482, "test_runtime": 4.0035, "test_samples_per_second": 511.548, "test_steps_per_second": 15.986}, {"test_loss": 0.681620717048645, "test_mcc": 0.12207999084685818, "test_macro_f1": 0.5515610272472847, "test_runtime": 3.9102, "test_samples_per_second": 523.759, "test_steps_per_second": 16.367}, {"test_loss": 0.6797446012496948, "test_mcc": 0.14733422739401786, "test_macro_f1": 0.5248291432512415, "test_runtime": 3.9241, "test_samples_per_second": 521.902, "test_steps_per_second": 16.309}, {"test_loss": 0.6681100130081177, "test_mcc": 0.20644487188597085, "test_macro_f1": 0.6028181613250654, "test_runtime": 3.9053, "test_samples_per_second": 524.418, "test_steps_per_second": 16.388}, {"test_loss": 0.6889625191688538, "test_mcc": 0.07265364999883414, "test_macro_f1": 0.5266829250316589, "test_runtime": 3.9848, "test_samples_per_second": 513.949, "test_steps_per_second": 16.061}]}, "total": {"test_mcc": 12.954818301923563, "test_mcc_se": 3.009807661148893, "test_macro_f1": 55.30800528455069, "test_macro_f1_se": 1.873780861575974}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_em": 37.8001549186677, "test_f1": 43.68139436051116}, {"test_em": 39.37984496124031, "test_f1": 44.4601952095472}, {"test_em": 34.8531684698609, "test_f1": 40.725417149246155}, {"test_em": 24.610591900311526, "test_f1": 30.704101808530613}, {"test_em": 34.36293436293436, "test_f1": 40.63044747408151}, {"test_em": 31.225905936777178, "test_f1": 38.0014219245083}, {"test_em": 34.16856492027335, "test_f1": 39.88655453208653}, {"test_em": 38.78975950349108, "test_f1": 44.055555712719084}, {"test_em": 38.27450980392157, "test_f1": 44.545278845479174}, {"test_em": 29.891304347826086, "test_f1": 36.55962145356988}]}, "total": {"test_em": 34.3356739125304, "test_em_se": 2.9005083679531194, "test_f1": 40.32499884702796, "test_f1_se": 2.714894111009261}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_em": 36.096049573973666, "test_f1": 41.57928925982586}, {"test_em": 35.348837209302324, "test_f1": 41.010680874897005}, {"test_em": 33.53941267387945, "test_f1": 39.624794207969096}, {"test_em": 10.43613707165109, "test_f1": 17.807910991683908}, {"test_em": 34.67181467181467, "test_f1": 40.66930058302672}, {"test_em": 32.45952197378566, "test_f1": 37.51540078347582}, {"test_em": 31.58694001518603, "test_f1": 37.15629477661454}, {"test_em": 21.024049650892163, "test_f1": 27.675797495185986}, {"test_em": 36.23529411764706, "test_f1": 41.74141048315867}, {"test_em": 30.512422360248447, "test_f1": 36.210951171222625}]}, "total": {"test_em": 30.191047931838057, "test_em_se": 5.105964876810771, "test_f1": 36.099183062706025, "test_f1_se": 4.747197153875498}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.07292474786656322}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 0.0, "test_em_se": 0.0, "test_f1": 0.007292474786656322, "test_f1_se": 0.014293250581846393}}, "num_model_parameters": 13672706, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 0.0, "test_em_se": 0.0, "test_f1": 0.0, "test_f1_se": 0.0}}, "num_model_parameters": 13672706, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.6850857734680176, "test_mcc": 0.6072908037278589, "test_macro_f1": 0.5479262163809108, "test_runtime": 2.0731, "test_samples_per_second": 987.873, "test_steps_per_second": 30.871}, {"test_loss": 0.725700318813324, "test_mcc": 0.5463184021749905, "test_macro_f1": 0.5228764124168251, "test_runtime": 1.7979, "test_samples_per_second": 1139.111, "test_steps_per_second": 35.597}, {"test_loss": 0.7270582914352417, "test_mcc": 0.5439510471374785, "test_macro_f1": 0.5218820692865911, "test_runtime": 2.1135, "test_samples_per_second": 969.022, "test_steps_per_second": 30.282}, {"test_loss": 0.7113814353942871, "test_mcc": 0.5890399325951846, "test_macro_f1": 0.5407386878695842, "test_runtime": 2.082, "test_samples_per_second": 983.659, "test_steps_per_second": 30.739}, {"test_loss": 0.6929236650466919, "test_mcc": 0.5836676889777865, "test_macro_f1": 0.5391545933323126, "test_runtime": 1.7763, "test_samples_per_second": 1152.975, "test_steps_per_second": 36.03}, {"test_loss": 0.7254387140274048, "test_mcc": 0.5640455932107212, "test_macro_f1": 0.5284794064075689, "test_runtime": 2.1065, "test_samples_per_second": 972.239, "test_steps_per_second": 30.382}, {"test_loss": 0.6796953678131104, "test_mcc": 0.5806359140624792, "test_macro_f1": 0.5374313304680434, "test_runtime": 1.9094, "test_samples_per_second": 1072.563, "test_steps_per_second": 33.518}, {"test_loss": 0.7333772778511047, "test_mcc": 0.5686307054858748, "test_macro_f1": 0.5303388886552399, "test_runtime": 1.766, "test_samples_per_second": 1159.693, "test_steps_per_second": 36.24}, {"test_loss": 0.7096705436706543, "test_mcc": 0.5757443788185331, "test_macro_f1": 0.5357592439673365, "test_runtime": 1.732, "test_samples_per_second": 1182.472, "test_steps_per_second": 36.952}, {"test_loss": 0.6656427979469299, "test_mcc": 0.6112166750435905, "test_macro_f1": 0.5498875564399758, "test_runtime": 1.7354, "test_samples_per_second": 1180.124, "test_steps_per_second": 36.879}]}, "total": {"test_mcc": 57.70541141234497, "test_mcc_se": 1.3957430122091168, "test_macro_f1": 53.544744052243885, "test_macro_f1_se": 0.5940344949595855}}, "num_model_parameters": 13738755, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.9221458435058594, "test_mcc": 0.3575612253447878, "test_macro_f1": 0.44413411820741305, "test_runtime": 1.3532, "test_samples_per_second": 1513.453, "test_steps_per_second": 47.295}, {"test_loss": 0.9154276847839355, "test_mcc": 0.3132164770111301, "test_macro_f1": 0.428738567053548, "test_runtime": 1.3537, "test_samples_per_second": 1512.912, "test_steps_per_second": 47.278}, {"test_loss": 0.9144600629806519, "test_mcc": 0.3064131123009781, "test_macro_f1": 0.4258158974911435, "test_runtime": 1.364, "test_samples_per_second": 1501.498, "test_steps_per_second": 46.922}, {"test_loss": 0.9183693528175354, "test_mcc": 0.3289505817464048, "test_macro_f1": 0.43412961894892493, "test_runtime": 1.3755, "test_samples_per_second": 1488.96, "test_steps_per_second": 46.53}, {"test_loss": 0.9123685359954834, "test_mcc": 0.3254162293394214, "test_macro_f1": 0.4341711667625763, "test_runtime": 1.3463, "test_samples_per_second": 1521.161, "test_steps_per_second": 47.536}, {"test_loss": 0.9004960656166077, "test_mcc": 0.33801981135258624, "test_macro_f1": 0.4852728117240608, "test_runtime": 1.8683, "test_samples_per_second": 1096.211, "test_steps_per_second": 34.257}, {"test_loss": 0.8998340368270874, "test_mcc": 0.3566626806398301, "test_macro_f1": 0.44001151483236794, "test_runtime": 1.3792, "test_samples_per_second": 1484.971, "test_steps_per_second": 46.405}, {"test_loss": 0.8881491422653198, "test_mcc": 0.37217031480166357, "test_macro_f1": 0.4803877856689928, "test_runtime": 1.4073, "test_samples_per_second": 1455.269, "test_steps_per_second": 45.477}, {"test_loss": 0.9101545810699463, "test_mcc": 0.336712278191927, "test_macro_f1": 0.5119060016635611, "test_runtime": 1.426, "test_samples_per_second": 1436.153, "test_steps_per_second": 44.88}, {"test_loss": 0.9141300916671753, "test_mcc": 0.30626364286639807, "test_macro_f1": 0.42775146422734767, "test_runtime": 1.4224, "test_samples_per_second": 1439.846, "test_steps_per_second": 44.995}]}, "total": {"test_mcc": 33.41386353595127, "test_mcc_se": 1.4028420671172184, "test_macro_f1": 45.12318946579937, "test_macro_f1_se": 1.8655249171658481}}, "num_model_parameters": 13738755, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.15005284547805786, "test_micro_f1": 0.36626506024096384, "test_micro_f1_no_misc": 0.3963494132985659, "test_runtime": 3.0429, "test_samples_per_second": 673.032, "test_steps_per_second": 21.032}, {"test_loss": 0.13952350616455078, "test_micro_f1": 0.41394335511982566, "test_micro_f1_no_misc": 0.4400694846554719, "test_runtime": 2.9701, "test_samples_per_second": 689.546, "test_steps_per_second": 21.548}, {"test_loss": 0.14429770410060883, "test_micro_f1": 0.36555360281195076, "test_micro_f1_no_misc": 0.38733705772811916, "test_runtime": 3.0376, "test_samples_per_second": 674.215, "test_steps_per_second": 21.069}, {"test_loss": 0.1518951654434204, "test_micro_f1": 0.4111045481393975, "test_micro_f1_no_misc": 0.4371859296482412, "test_runtime": 3.3684, "test_samples_per_second": 608.012, "test_steps_per_second": 19.0}, {"test_loss": 0.1709951013326645, "test_micro_f1": 0.2503848127244741, "test_micro_f1_no_misc": 0.2647856755290288, "test_runtime": 3.7378, "test_samples_per_second": 547.916, "test_steps_per_second": 17.122}, {"test_loss": 0.15283238887786865, "test_micro_f1": 0.41365257259297, "test_micro_f1_no_misc": 0.4449315068493151, "test_runtime": 3.336, "test_samples_per_second": 613.907, "test_steps_per_second": 19.185}, {"test_loss": 0.16751784086227417, "test_micro_f1": 0.2848, "test_micro_f1_no_misc": 0.3034090909090909, "test_runtime": 3.0391, "test_samples_per_second": 673.88, "test_steps_per_second": 21.059}, {"test_loss": 0.13232602179050446, "test_micro_f1": 0.44768856447688565, "test_micro_f1_no_misc": 0.475759534583064, "test_runtime": 2.9682, "test_samples_per_second": 689.979, "test_steps_per_second": 21.562}, {"test_loss": 0.15828150510787964, "test_micro_f1": 0.3509865005192108, "test_micro_f1_no_misc": 0.37163276525563493, "test_runtime": 3.405, "test_samples_per_second": 601.465, "test_steps_per_second": 18.796}, {"test_loss": 0.15550130605697632, "test_micro_f1": 0.3695014662756598, "test_micro_f1_no_misc": 0.39523212045169387, "test_runtime": 3.0468, "test_samples_per_second": 672.178, "test_steps_per_second": 21.006}]}, "total": {"test_micro_f1": 36.73880482901338, "test_micro_f1_se": 3.7789420408748864, "test_micro_f1_no_misc": 39.166925789082256, "test_micro_f1_no_misc_se": 4.062583984000899}}, "num_model_parameters": 13674505, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.14833751320838928, "test_micro_f1": 0.5465402177730945, "test_micro_f1_no_misc": 0.5845229151014275, "test_runtime": 3.0573, "test_samples_per_second": 669.87, "test_steps_per_second": 20.933}, {"test_loss": 0.12693668901920319, "test_micro_f1": 0.6050420168067226, "test_micro_f1_no_misc": 0.6423762376237625, "test_runtime": 3.3433, "test_samples_per_second": 612.575, "test_steps_per_second": 19.143}, {"test_loss": 0.1423625946044922, "test_micro_f1": 0.5671641791044776, "test_micro_f1_no_misc": 0.6043165467625901, "test_runtime": 3.6528, "test_samples_per_second": 560.669, "test_steps_per_second": 17.521}, {"test_loss": 0.15080055594444275, "test_micro_f1": 0.5946140035906642, "test_micro_f1_no_misc": 0.6323024054982818, "test_runtime": 3.2658, "test_samples_per_second": 627.099, "test_steps_per_second": 19.597}, {"test_loss": 0.14917325973510742, "test_micro_f1": 0.5817812394175415, "test_micro_f1_no_misc": 0.6263215457528253, "test_runtime": 2.9527, "test_samples_per_second": 693.604, "test_steps_per_second": 21.675}, {"test_loss": 0.13829341530799866, "test_micro_f1": 0.5867823765020027, "test_micro_f1_no_misc": 0.6338439095550693, "test_runtime": 2.9682, "test_samples_per_second": 689.975, "test_steps_per_second": 21.562}, {"test_loss": 0.18425503373146057, "test_micro_f1": 0.46777281429483086, "test_micro_f1_no_misc": 0.5006830601092895, "test_runtime": 3.315, "test_samples_per_second": 617.791, "test_steps_per_second": 19.306}, {"test_loss": 0.16745208203792572, "test_micro_f1": 0.49719495091164095, "test_micro_f1_no_misc": 0.5228613569321534, "test_runtime": 3.0715, "test_samples_per_second": 666.772, "test_steps_per_second": 20.837}, {"test_loss": 0.14004385471343994, "test_micro_f1": 0.5806215722120658, "test_micro_f1_no_misc": 0.6198282591725215, "test_runtime": 3.3502, "test_samples_per_second": 611.315, "test_steps_per_second": 19.104}, {"test_loss": 0.1569112241268158, "test_micro_f1": 0.5678510998307953, "test_micro_f1_no_misc": 0.608632571635836, "test_runtime": 3.3413, "test_samples_per_second": 612.941, "test_steps_per_second": 19.154}]}, "total": {"test_micro_f1": 55.953644704438354, "test_micro_f1_se": 2.739811579152934, "test_micro_f1_no_misc": 59.75688808143757, "test_micro_f1_no_misc_se": 3.0052197213012533}}, "num_model_parameters": 13674505, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.19414080679416656, "test_micro_f1": 0.43202416918429004, "test_micro_f1_no_misc": 0.455704270235819, "test_runtime": 3.3399, "test_samples_per_second": 613.188, "test_steps_per_second": 19.162}, {"test_loss": 0.17619681358337402, "test_micro_f1": 0.5099910527885475, "test_micro_f1_no_misc": 0.5462696125520332, "test_runtime": 3.573, "test_samples_per_second": 573.187, "test_steps_per_second": 17.912}, {"test_loss": 0.16969996690750122, "test_micro_f1": 0.5188794153471377, "test_micro_f1_no_misc": 0.5543266102797658, "test_runtime": 2.9127, "test_samples_per_second": 703.124, "test_steps_per_second": 21.973}, {"test_loss": 0.18709684908390045, "test_micro_f1": 0.49954586739327883, "test_micro_f1_no_misc": 0.5327736519212141, "test_runtime": 2.8824, "test_samples_per_second": 710.527, "test_steps_per_second": 22.204}, {"test_loss": 0.17573338747024536, "test_micro_f1": 0.5104353011329755, "test_micro_f1_no_misc": 0.5527930255085566, "test_runtime": 2.8087, "test_samples_per_second": 729.152, "test_steps_per_second": 22.786}, {"test_loss": 0.17088645696640015, "test_micro_f1": 0.5074360499702558, "test_micro_f1_no_misc": 0.5478484264611433, "test_runtime": 2.8988, "test_samples_per_second": 706.494, "test_steps_per_second": 22.078}, {"test_loss": 0.18336284160614014, "test_micro_f1": 0.4653061224489796, "test_micro_f1_no_misc": 0.5007844367743961, "test_runtime": 3.0588, "test_samples_per_second": 669.543, "test_steps_per_second": 20.923}, {"test_loss": 0.19336183369159698, "test_micro_f1": 0.44224633056796425, "test_micro_f1_no_misc": 0.46983050847457625, "test_runtime": 3.565, "test_samples_per_second": 574.467, "test_steps_per_second": 17.952}, {"test_loss": 0.1815992295742035, "test_micro_f1": 0.4610900612066453, "test_micro_f1_no_misc": 0.48963169297431136, "test_runtime": 2.9109, "test_samples_per_second": 703.558, "test_steps_per_second": 21.986}, {"test_loss": 0.1863715648651123, "test_micro_f1": 0.4672279013830427, "test_micro_f1_no_misc": 0.4939605848696758, "test_runtime": 2.8735, "test_samples_per_second": 712.724, "test_steps_per_second": 22.273}]}, "total": {"test_micro_f1": 48.141822714231175, "test_micro_f1_se": 1.9507975444969128, "test_micro_f1_no_misc": 51.43922820051491, "test_micro_f1_no_misc_se": 2.2809165525451465}}, "num_model_parameters": 13674505, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.663860559463501, "test_mcc": 0.21805348503731947, "test_macro_f1": 0.6014794606662852, "test_runtime": 1.3757, "test_samples_per_second": 1488.646, "test_steps_per_second": 46.52}, {"test_loss": 0.6853358149528503, "test_mcc": 0.12381282026719395, "test_macro_f1": 0.5618837613123912, "test_runtime": 1.3527, "test_samples_per_second": 1514.063, "test_steps_per_second": 47.314}, {"test_loss": 0.6791921257972717, "test_mcc": 0.21712834989116334, "test_macro_f1": 0.5747605242944572, "test_runtime": 1.6847, "test_samples_per_second": 1215.629, "test_steps_per_second": 37.988}, {"test_loss": 0.6737388968467712, "test_mcc": 0.15815384529566312, "test_macro_f1": 0.5785963017404065, "test_runtime": 1.7168, "test_samples_per_second": 1192.888, "test_steps_per_second": 37.278}, {"test_loss": 0.6690237522125244, "test_mcc": 0.1884609259323536, "test_macro_f1": 0.5863095238095237, "test_runtime": 1.4313, "test_samples_per_second": 1430.846, "test_steps_per_second": 44.714}, {"test_loss": 0.6796184778213501, "test_mcc": 0.1386005901791087, "test_macro_f1": 0.566390596034738, "test_runtime": 1.733, "test_samples_per_second": 1181.737, "test_steps_per_second": 36.929}, {"test_loss": 0.6874085664749146, "test_mcc": 0.1416066961792246, "test_macro_f1": 0.5655172413793104, "test_runtime": 1.6346, "test_samples_per_second": 1252.923, "test_steps_per_second": 39.154}, {"test_loss": 0.6725318431854248, "test_mcc": 0.2048390249518697, "test_macro_f1": 0.5652172807621715, "test_runtime": 1.4611, "test_samples_per_second": 1401.654, "test_steps_per_second": 43.802}, {"test_loss": 0.6848899126052856, "test_mcc": 0.10904583992892149, "test_macro_f1": 0.5462051593040071, "test_runtime": 1.4843, "test_samples_per_second": 1379.761, "test_steps_per_second": 43.118}, {"test_loss": 0.6702340245246887, "test_mcc": 0.21011055344916849, "test_macro_f1": 0.5946418892760357, "test_runtime": 1.4575, "test_samples_per_second": 1405.129, "test_steps_per_second": 43.91}]}, "total": {"test_mcc": 17.098121311119865, "test_mcc_se": 2.5692793455104006, "test_macro_f1": 57.41001738579327, "test_macro_f1_se": 1.0290133892368598}}, "num_model_parameters": 13738498, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.6326239705085754, "test_mcc": 0.34208863024093705, "test_macro_f1": 0.6708369102806233, "test_runtime": 1.6665, "test_samples_per_second": 1228.928, "test_steps_per_second": 38.404}, {"test_loss": 0.617887556552887, "test_mcc": 0.37320854147907734, "test_macro_f1": 0.6815529049284175, "test_runtime": 1.7049, "test_samples_per_second": 1201.219, "test_steps_per_second": 37.538}, {"test_loss": 0.6487076878547668, "test_mcc": 0.33889414287568637, "test_macro_f1": 0.6605516448338136, "test_runtime": 1.4454, "test_samples_per_second": 1416.901, "test_steps_per_second": 44.278}, {"test_loss": 0.6391922235488892, "test_mcc": 0.30449649110179244, "test_macro_f1": 0.6491720368708704, "test_runtime": 1.4466, "test_samples_per_second": 1415.707, "test_steps_per_second": 44.241}, {"test_loss": 0.6350597739219666, "test_mcc": 0.3097999860392033, "test_macro_f1": 0.649063560443792, "test_runtime": 1.6487, "test_samples_per_second": 1242.177, "test_steps_per_second": 38.818}, {"test_loss": 0.6241515278816223, "test_mcc": 0.336413774563249, "test_macro_f1": 0.6572125147244128, "test_runtime": 1.8402, "test_samples_per_second": 1112.927, "test_steps_per_second": 34.779}, {"test_loss": 0.6305841207504272, "test_mcc": 0.3056098182412952, "test_macro_f1": 0.6516456084367079, "test_runtime": 1.6425, "test_samples_per_second": 1246.863, "test_steps_per_second": 38.964}, {"test_loss": 0.6342761516571045, "test_mcc": 0.3507540545081282, "test_macro_f1": 0.6616307711155577, "test_runtime": 1.7071, "test_samples_per_second": 1199.696, "test_steps_per_second": 37.491}, {"test_loss": 0.6270601749420166, "test_mcc": 0.3272685845548687, "test_macro_f1": 0.6635645130410381, "test_runtime": 1.4465, "test_samples_per_second": 1415.815, "test_steps_per_second": 44.244}, {"test_loss": 0.6530553102493286, "test_mcc": 0.2985072139709634, "test_macro_f1": 0.636695136864798, "test_runtime": 1.4396, "test_samples_per_second": 1422.591, "test_steps_per_second": 44.456}]}, "total": {"test_mcc": 32.87041237575201, "test_mcc_se": 1.4898148744642992, "test_macro_f1": 65.81925601540031, "test_macro_f1_se": 0.7792216860850366}}, "num_model_parameters": 13738498, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_loss": 0.6637130975723267, "test_mcc": 0.20617900791628652, "test_macro_f1": 0.5951583159908156, "test_runtime": 1.6547, "test_samples_per_second": 1237.675, "test_steps_per_second": 38.677}, {"test_loss": 0.6756634712219238, "test_mcc": 0.1856013584258574, "test_macro_f1": 0.5653536974498934, "test_runtime": 1.7378, "test_samples_per_second": 1178.515, "test_steps_per_second": 36.829}, {"test_loss": 0.6619116067886353, "test_mcc": 0.23046312046153974, "test_macro_f1": 0.6052562504419113, "test_runtime": 1.3924, "test_samples_per_second": 1470.808, "test_steps_per_second": 45.963}, {"test_loss": 0.669430136680603, "test_mcc": 0.2074471806467431, "test_macro_f1": 0.5880566801619433, "test_runtime": 1.438, "test_samples_per_second": 1424.242, "test_steps_per_second": 44.508}, {"test_loss": 0.6551246643066406, "test_mcc": 0.24220346349648092, "test_macro_f1": 0.6138763197586727, "test_runtime": 1.6087, "test_samples_per_second": 1273.11, "test_steps_per_second": 39.785}, {"test_loss": 0.6762902140617371, "test_mcc": 0.1744666885241692, "test_macro_f1": 0.5868811300052226, "test_runtime": 1.6574, "test_samples_per_second": 1235.696, "test_steps_per_second": 38.616}, {"test_loss": 0.6749740839004517, "test_mcc": 0.16148772942469208, "test_macro_f1": 0.5805543058087832, "test_runtime": 1.7434, "test_samples_per_second": 1174.698, "test_steps_per_second": 36.709}, {"test_loss": 0.6551318168640137, "test_mcc": 0.2442637627369884, "test_macro_f1": 0.621988521819818, "test_runtime": 1.6553, "test_samples_per_second": 1237.22, "test_steps_per_second": 38.663}, {"test_loss": 0.6671690940856934, "test_mcc": 0.18995152445309188, "test_macro_f1": 0.5949552854849804, "test_runtime": 1.4869, "test_samples_per_second": 1377.395, "test_steps_per_second": 43.044}, {"test_loss": 0.6764695644378662, "test_mcc": 0.16674672251608605, "test_macro_f1": 0.5745952677459527, "test_runtime": 1.3805, "test_samples_per_second": 1483.499, "test_steps_per_second": 46.359}]}, "total": {"test_mcc": 20.088105586019353, "test_mcc_se": 1.8826331352507255, "test_macro_f1": 59.26675774667993, "test_macro_f1_se": 1.0841341203558397}}, "num_model_parameters": 13738498, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_em": 12.703330751355539, "test_f1": 13.920485874397576}, {"test_em": 14.108527131782946, "test_f1": 15.621492329426674}, {"test_em": 11.437403400309119, "test_f1": 11.96024855073405}, {"test_em": 9.813084112149532, "test_f1": 10.74769263884162}, {"test_em": 10.115830115830116, "test_f1": 10.718879418127537}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 3.7205770690964313, "test_f1": 3.8838607162337566}, {"test_em": 5.740884406516679, "test_f1": 5.983995874015496}, {"test_em": 5.647058823529412, "test_f1": 6.028099972226724}, {"test_em": 0.07763975155279502, "test_f1": 0.07763975155279502}]}, "total": {"test_em": 7.336433556212256, "test_em_se": 3.135517862886065, "test_f1": 7.8942395125556235, "test_f1_se": 3.4280530808733323}}, "num_model_parameters": 13672706, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_em": 1.0844306738962044, "test_f1": 1.1463981409759876}, {"test_em": 0.6201550387596899, "test_f1": 0.6201550387596899}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 3.2710280373831777, "test_f1": 3.661177866785344}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.07710100231303008, "test_f1": 0.07710100231303008}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 7.529411764705882, "test_f1": 8.348562241295804}, {"test_em": 0.07763975155279502, "test_f1": 0.07763975155279502}]}, "total": {"test_em": 1.265976626861078, "test_em_se": 1.5031956656161414, "test_f1": 1.393103404168265, "test_f1_se": 1.6708754105657881}}, "num_model_parameters": 13672706, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_em": 0.8520526723470179, "test_f1": 1.0379550735863672}, {"test_em": 0.07751937984496124, "test_f1": 0.07751937984496124}, {"test_em": 6.182380216383308, "test_f1": 6.638944088712249}, {"test_em": 12.850467289719626, "test_f1": 14.062330020273942}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 10.098709187547456, "test_f1": 11.590148010371843}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 3.006112874584237, "test_em_se": 3.0343455901958967, "test_f1": 3.3406896572789364, "test_f1_se": 3.3672822895877745}}, "num_model_parameters": 13672706, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.42714250087738037, "test_mcc": 0.7217360348809729, "test_macro_f1": 0.7006632558342955, "test_runtime": 14.6092, "test_samples_per_second": 140.186, "test_steps_per_second": 17.523}, {"test_loss": 0.4281933903694153, "test_mcc": 0.7129431295898077, "test_macro_f1": 0.6825139491358628, "test_runtime": 15.0354, "test_samples_per_second": 136.212, "test_steps_per_second": 17.026}, {"test_loss": 0.4126081168651581, "test_mcc": 0.7469022365153483, "test_macro_f1": 0.6973308926095093, "test_runtime": 20.2071, "test_samples_per_second": 101.35, "test_steps_per_second": 50.675}, {"test_loss": 0.3794676661491394, "test_mcc": 0.7518874089304572, "test_macro_f1": 0.6782297081174402, "test_runtime": 19.3597, "test_samples_per_second": 105.787, "test_steps_per_second": 52.893}, {"test_loss": 0.41909927129745483, "test_mcc": 0.7165827931314035, "test_macro_f1": 0.6841488061931335, "test_runtime": 17.5111, "test_samples_per_second": 116.954, "test_steps_per_second": 58.477}, {"test_loss": 0.41434383392333984, "test_mcc": 0.7194611348148742, "test_macro_f1": 0.6235651878535786, "test_runtime": 19.709, "test_samples_per_second": 103.912, "test_steps_per_second": 51.956}, {"test_loss": 0.4120669960975647, "test_mcc": 0.7389382656895662, "test_macro_f1": 0.703740071333755, "test_runtime": 19.4692, "test_samples_per_second": 105.192, "test_steps_per_second": 52.596}, {"test_loss": 0.41563886404037476, "test_mcc": 0.7330623498241947, "test_macro_f1": 0.685840054104872, "test_runtime": 17.7984, "test_samples_per_second": 115.066, "test_steps_per_second": 57.533}, {"test_loss": 0.42007938027381897, "test_mcc": 0.7254631335679937, "test_macro_f1": 0.6544982290571476, "test_runtime": 20.6591, "test_samples_per_second": 99.133, "test_steps_per_second": 49.567}, {"test_loss": 0.4307374358177185, "test_mcc": 0.7099886460950513, "test_macro_f1": 0.702314205208709, "test_runtime": 19.8858, "test_samples_per_second": 102.988, "test_steps_per_second": 51.494}]}, "total": {"test_mcc": 72.7696513303967, "test_mcc_se": 0.8939717467701745, "test_macro_f1": 68.12844359448304, "test_macro_f1_se": 1.5554751221197105}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.8595360517501831, "test_mcc": 0.45035639181172016, "test_macro_f1": 0.6347814989000956, "test_runtime": 4.7591, "test_samples_per_second": 430.329, "test_steps_per_second": 13.448}, {"test_loss": 0.8463402986526489, "test_mcc": 0.4084170257043301, "test_macro_f1": 0.6051568744786189, "test_runtime": 4.3583, "test_samples_per_second": 469.908, "test_steps_per_second": 14.685}, {"test_loss": 0.8713356852531433, "test_mcc": 0.39458559076706956, "test_macro_f1": 0.5940477765273894, "test_runtime": 4.8112, "test_samples_per_second": 425.677, "test_steps_per_second": 13.302}, {"test_loss": 0.8910831809043884, "test_mcc": 0.4230526203526059, "test_macro_f1": 0.6146140831601946, "test_runtime": 4.3125, "test_samples_per_second": 474.897, "test_steps_per_second": 14.841}, {"test_loss": 0.8561678528785706, "test_mcc": 0.40184242878963206, "test_macro_f1": 0.6037033506839742, "test_runtime": 4.2674, "test_samples_per_second": 479.914, "test_steps_per_second": 14.997}, {"test_loss": 0.8606969118118286, "test_mcc": 0.447618432426719, "test_macro_f1": 0.6302088234111125, "test_runtime": 4.2966, "test_samples_per_second": 476.655, "test_steps_per_second": 14.895}, {"test_loss": 0.8338045477867126, "test_mcc": 0.43361982020244777, "test_macro_f1": 0.6206410372117656, "test_runtime": 4.6762, "test_samples_per_second": 437.958, "test_steps_per_second": 13.686}, {"test_loss": 0.8326494693756104, "test_mcc": 0.4212796647535517, "test_macro_f1": 0.612140988646567, "test_runtime": 4.7675, "test_samples_per_second": 429.573, "test_steps_per_second": 13.424}, {"test_loss": 0.8392280340194702, "test_mcc": 0.4173452033711279, "test_macro_f1": 0.6083074952623593, "test_runtime": 4.3112, "test_samples_per_second": 475.046, "test_steps_per_second": 14.845}, {"test_loss": 0.9069846868515015, "test_mcc": 0.42763664081126573, "test_macro_f1": 0.6171605504662437, "test_runtime": 4.5555, "test_samples_per_second": 449.567, "test_steps_per_second": 14.049}]}, "total": {"test_mcc": 42.2575381899047, "test_mcc_se": 1.1296318600361954, "test_macro_f1": 61.40762478748321, "test_macro_f1_se": 0.7639200902591794}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.7107608318328857, "test_mcc": 0.5396912952527391, "test_macro_f1": 0.6931040329807531, "test_runtime": 4.1452, "test_samples_per_second": 494.065, "test_steps_per_second": 15.44}, {"test_loss": 0.7964362502098083, "test_mcc": 0.48589033337598425, "test_macro_f1": 0.6356006341520283, "test_runtime": 3.7549, "test_samples_per_second": 545.414, "test_steps_per_second": 17.044}, {"test_loss": 0.7170045971870422, "test_mcc": 0.5142687842865151, "test_macro_f1": 0.661867921099914, "test_runtime": 3.6369, "test_samples_per_second": 563.124, "test_steps_per_second": 17.598}, {"test_loss": 0.7187765836715698, "test_mcc": 0.5158434010635206, "test_macro_f1": 0.6663686082907077, "test_runtime": 3.6097, "test_samples_per_second": 567.365, "test_steps_per_second": 17.73}, {"test_loss": 0.7189114093780518, "test_mcc": 0.5239066878068341, "test_macro_f1": 0.6655744161345897, "test_runtime": 3.5836, "test_samples_per_second": 571.488, "test_steps_per_second": 17.859}, {"test_loss": 0.7845156788825989, "test_mcc": 0.5290302408182672, "test_macro_f1": 0.6786400766769397, "test_runtime": 3.649, "test_samples_per_second": 561.243, "test_steps_per_second": 17.539}, {"test_loss": 0.6973204016685486, "test_mcc": 0.5389995838191294, "test_macro_f1": 0.6675807261058101, "test_runtime": 3.8176, "test_samples_per_second": 536.464, "test_steps_per_second": 16.765}, {"test_loss": 0.7538309097290039, "test_mcc": 0.53562538090864, "test_macro_f1": 0.6831617730615155, "test_runtime": 4.0322, "test_samples_per_second": 507.907, "test_steps_per_second": 15.872}, {"test_loss": 0.7684943675994873, "test_mcc": 0.5180646990458779, "test_macro_f1": 0.6713237233274908, "test_runtime": 3.97, "test_samples_per_second": 515.867, "test_steps_per_second": 16.121}, {"test_loss": 0.7281484603881836, "test_mcc": 0.5147481768855339, "test_macro_f1": 0.6554747164045599, "test_runtime": 4.1236, "test_samples_per_second": 496.655, "test_steps_per_second": 15.52}]}, "total": {"test_mcc": 52.16068583263041, "test_mcc_se": 0.9927210030394626, "test_macro_f1": 66.78696628234307, "test_macro_f1_se": 0.977187729053767}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.07926434278488159, "test_micro_f1": 0.6292362164896308, "test_micro_f1_no_misc": 0.7051129607609988, "test_runtime": 8.0726, "test_samples_per_second": 253.697, "test_steps_per_second": 7.928}, {"test_loss": 0.07712739706039429, "test_micro_f1": 0.6389873417721519, "test_micro_f1_no_misc": 0.7131050767414404, "test_runtime": 7.1702, "test_samples_per_second": 285.628, "test_steps_per_second": 8.926}, {"test_loss": 0.07101019471883774, "test_micro_f1": 0.6067415730337079, "test_micro_f1_no_misc": 0.6663118680149016, "test_runtime": 7.1781, "test_samples_per_second": 285.313, "test_steps_per_second": 8.916}, {"test_loss": 0.07856982946395874, "test_micro_f1": 0.6044568245125349, "test_micro_f1_no_misc": 0.6644808743169399, "test_runtime": 7.9688, "test_samples_per_second": 257.001, "test_steps_per_second": 8.031}, {"test_loss": 0.07964970171451569, "test_micro_f1": 0.6408942710759199, "test_micro_f1_no_misc": 0.6852138073158166, "test_runtime": 8.0196, "test_samples_per_second": 255.375, "test_steps_per_second": 7.98}, {"test_loss": 0.07799417525529861, "test_micro_f1": 0.614373356704645, "test_micro_f1_no_misc": 0.6690984887962481, "test_runtime": 5.7925, "test_samples_per_second": 353.561, "test_steps_per_second": 11.049}, {"test_loss": 0.08330398797988892, "test_micro_f1": 0.5929791271347248, "test_micro_f1_no_misc": 0.6618705035971223, "test_runtime": 6.1877, "test_samples_per_second": 330.98, "test_steps_per_second": 10.343}, {"test_loss": 0.060577210038900375, "test_micro_f1": 0.6402569593147751, "test_micro_f1_no_misc": 0.6895720313441832, "test_runtime": 7.8518, "test_samples_per_second": 260.833, "test_steps_per_second": 8.151}, {"test_loss": 0.07061155140399933, "test_micro_f1": 0.6341463414634146, "test_micro_f1_no_misc": 0.7037444933920705, "test_runtime": 6.6856, "test_samples_per_second": 306.332, "test_steps_per_second": 9.573}, {"test_loss": 0.07126546651124954, "test_micro_f1": 0.6515662650602411, "test_micro_f1_no_misc": 0.7353951890034365, "test_runtime": 8.0879, "test_samples_per_second": 253.217, "test_steps_per_second": 7.913}]}, "total": {"test_micro_f1": 62.53638276561746, "test_micro_f1_se": 1.201271312666734, "test_micro_f1_no_misc": 68.93905293283159, "test_micro_f1_no_misc_se": 1.5282626926264264}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.0771687775850296, "test_micro_f1": 0.7539240506329115, "test_micro_f1_no_misc": 0.7690749493585415, "test_runtime": 8.8727, "test_samples_per_second": 230.821, "test_steps_per_second": 7.213}, {"test_loss": 0.07413376867771149, "test_micro_f1": 0.7697743952160913, "test_micro_f1_no_misc": 0.7957848837209303, "test_runtime": 7.4197, "test_samples_per_second": 276.021, "test_steps_per_second": 8.626}, {"test_loss": 0.08718438446521759, "test_micro_f1": 0.7470937742185482, "test_micro_f1_no_misc": 0.7785939139559286, "test_runtime": 8.1962, "test_samples_per_second": 249.872, "test_steps_per_second": 7.809}, {"test_loss": 0.08384644985198975, "test_micro_f1": 0.7340692423482188, "test_micro_f1_no_misc": 0.7546791443850267, "test_runtime": 8.2116, "test_samples_per_second": 249.404, "test_steps_per_second": 7.794}, {"test_loss": 0.08388049900531769, "test_micro_f1": 0.7304964539007092, "test_micro_f1_no_misc": 0.7608453837597331, "test_runtime": 8.8872, "test_samples_per_second": 230.444, "test_steps_per_second": 7.201}, {"test_loss": 0.08139722049236298, "test_micro_f1": 0.7346938775510203, "test_micro_f1_no_misc": 0.7591294725193656, "test_runtime": 8.4732, "test_samples_per_second": 241.702, "test_steps_per_second": 7.553}, {"test_loss": 0.07842414826154709, "test_micro_f1": 0.7118819570282164, "test_micro_f1_no_misc": 0.7257383966244726, "test_runtime": 8.2402, "test_samples_per_second": 248.538, "test_steps_per_second": 7.767}, {"test_loss": 0.07785913348197937, "test_micro_f1": 0.6998158379373849, "test_micro_f1_no_misc": 0.7305218012866332, "test_runtime": 8.7047, "test_samples_per_second": 235.276, "test_steps_per_second": 7.352}, {"test_loss": 0.07788120210170746, "test_micro_f1": 0.7440021091484313, "test_micro_f1_no_misc": 0.7601001072577762, "test_runtime": 8.1669, "test_samples_per_second": 250.767, "test_steps_per_second": 7.836}, {"test_loss": 0.07524743676185608, "test_micro_f1": 0.7745695364238411, "test_micro_f1_no_misc": 0.7995712754555199, "test_runtime": 7.59, "test_samples_per_second": 269.827, "test_steps_per_second": 8.432}]}, "total": {"test_micro_f1": 74.00321234405374, "test_micro_f1_se": 1.4463348470273913, "test_micro_f1_no_misc": 76.34039328323927, "test_micro_f1_no_misc_se": 1.4943034775309365}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.059192027896642685, "test_micro_f1": 0.7315676449534718, "test_micro_f1_no_misc": 0.7811877241929055, "test_runtime": 7.0294, "test_samples_per_second": 291.349, "test_steps_per_second": 9.105}, {"test_loss": 0.04980616271495819, "test_micro_f1": 0.7766776677667768, "test_micro_f1_no_misc": 0.8212835093419983, "test_runtime": 6.3915, "test_samples_per_second": 320.428, "test_steps_per_second": 10.013}, {"test_loss": 0.05685529485344887, "test_micro_f1": 0.7376083188908146, "test_micro_f1_no_misc": 0.7779056386651324, "test_runtime": 5.8914, "test_samples_per_second": 347.627, "test_steps_per_second": 10.863}, {"test_loss": 0.05522306635975838, "test_micro_f1": 0.7438982468202132, "test_micro_f1_no_misc": 0.7867981790591805, "test_runtime": 6.4716, "test_samples_per_second": 316.458, "test_steps_per_second": 9.889}, {"test_loss": 0.05751001089811325, "test_micro_f1": 0.7541638907395071, "test_micro_f1_no_misc": 0.7929036929761042, "test_runtime": 6.9411, "test_samples_per_second": 295.054, "test_steps_per_second": 9.22}, {"test_loss": 0.05513510853052139, "test_micro_f1": 0.7595021863437604, "test_micro_f1_no_misc": 0.8002931476731403, "test_runtime": 6.9227, "test_samples_per_second": 295.84, "test_steps_per_second": 9.245}, {"test_loss": 0.0582682341337204, "test_micro_f1": 0.7463694697737251, "test_micro_f1_no_misc": 0.7837638376383764, "test_runtime": 5.8893, "test_samples_per_second": 347.749, "test_steps_per_second": 10.867}, {"test_loss": 0.04892345890402794, "test_micro_f1": 0.811534500514933, "test_micro_f1_no_misc": 0.8364038319823139, "test_runtime": 5.7939, "test_samples_per_second": 353.475, "test_steps_per_second": 11.046}, {"test_loss": 0.051636237651109695, "test_micro_f1": 0.7383863080684596, "test_micro_f1_no_misc": 0.7862446268073466, "test_runtime": 5.8908, "test_samples_per_second": 347.658, "test_steps_per_second": 10.864}, {"test_loss": 0.05645396560430527, "test_micro_f1": 0.7932885906040269, "test_micro_f1_no_misc": 0.8416698006769462, "test_runtime": 6.9454, "test_samples_per_second": 294.871, "test_steps_per_second": 9.215}]}, "total": {"test_micro_f1": 75.92996824475688, "test_micro_f1_se": 1.639004721827754, "test_micro_f1_no_misc": 80.08453989013444, "test_micro_f1_no_misc_se": 1.4648469724019688}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.06826154887676239, "test_micro_f1": 0.7465522525283481, "test_micro_f1_no_misc": 0.7849898580121704, "test_runtime": 6.3409, "test_samples_per_second": 322.984, "test_steps_per_second": 10.093}, {"test_loss": 0.0767335519194603, "test_micro_f1": 0.7330533893221356, "test_micro_f1_no_misc": 0.7677035076108537, "test_runtime": 6.6541, "test_samples_per_second": 307.78, "test_steps_per_second": 9.618}, {"test_loss": 0.08831610530614853, "test_micro_f1": 0.6600955794504182, "test_micro_f1_no_misc": 0.7039431157078215, "test_runtime": 6.5951, "test_samples_per_second": 310.535, "test_steps_per_second": 9.704}, {"test_loss": 0.08337004482746124, "test_micro_f1": 0.6975782634376847, "test_micro_f1_no_misc": 0.7451623483109217, "test_runtime": 6.1468, "test_samples_per_second": 333.183, "test_steps_per_second": 10.412}, {"test_loss": 0.08803503215312958, "test_micro_f1": 0.6430678466076697, "test_micro_f1_no_misc": 0.6950448952444297, "test_runtime": 5.8937, "test_samples_per_second": 347.491, "test_steps_per_second": 10.859}, {"test_loss": 0.07840435206890106, "test_micro_f1": 0.7080459770114944, "test_micro_f1_no_misc": 0.7599364069952307, "test_runtime": 6.6565, "test_samples_per_second": 307.669, "test_steps_per_second": 9.615}, {"test_loss": 0.07574346661567688, "test_micro_f1": 0.6737545565006076, "test_micro_f1_no_misc": 0.720558882235529, "test_runtime": 6.6472, "test_samples_per_second": 308.1, "test_steps_per_second": 9.628}, {"test_loss": 0.075368732213974, "test_micro_f1": 0.705247376311844, "test_micro_f1_no_misc": 0.7486106570774762, "test_runtime": 6.437, "test_samples_per_second": 318.16, "test_steps_per_second": 9.942}, {"test_loss": 0.07863171398639679, "test_micro_f1": 0.7046694966646453, "test_micro_f1_no_misc": 0.7434100767434101, "test_runtime": 6.1281, "test_samples_per_second": 334.197, "test_steps_per_second": 10.444}, {"test_loss": 0.0714193731546402, "test_micro_f1": 0.7537718768859386, "test_micro_f1_no_misc": 0.7899999999999999, "test_runtime": 5.8162, "test_samples_per_second": 352.122, "test_steps_per_second": 11.004}]}, "total": {"test_micro_f1": 70.25836614720787, "test_micro_f1_se": 2.2372921202399243, "test_micro_f1_no_misc": 74.59359747937843, "test_micro_f1_no_misc_se": 1.9760620789483592}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.5769796967506409, "test_mcc": 0.44979104416914123, "test_macro_f1": 0.7097499362002075, "test_runtime": 3.2577, "test_samples_per_second": 628.667, "test_steps_per_second": 19.646}, {"test_loss": 0.6169146299362183, "test_mcc": 0.4479203733514525, "test_macro_f1": 0.7064762388180132, "test_runtime": 3.4937, "test_samples_per_second": 586.203, "test_steps_per_second": 18.319}, {"test_loss": 0.6139849424362183, "test_mcc": 0.40672494996083297, "test_macro_f1": 0.6489695163422429, "test_runtime": 3.7007, "test_samples_per_second": 553.408, "test_steps_per_second": 17.294}, {"test_loss": 0.6139234900474548, "test_mcc": 0.43273600789365757, "test_macro_f1": 0.6923186184931152, "test_runtime": 3.6478, "test_samples_per_second": 561.43, "test_steps_per_second": 17.545}, {"test_loss": 0.6244074702262878, "test_mcc": 0.39680783260018215, "test_macro_f1": 0.691755525453556, "test_runtime": 3.5928, "test_samples_per_second": 570.022, "test_steps_per_second": 17.813}, {"test_loss": 0.596804141998291, "test_mcc": 0.3969866955967519, "test_macro_f1": 0.6654844605126213, "test_runtime": 3.5901, "test_samples_per_second": 570.455, "test_steps_per_second": 17.827}, {"test_loss": 0.6255739331245422, "test_mcc": 0.31849061567087417, "test_macro_f1": 0.6214289217258122, "test_runtime": 3.5695, "test_samples_per_second": 573.751, "test_steps_per_second": 17.93}, {"test_loss": 0.6124898791313171, "test_mcc": 0.3556378776213832, "test_macro_f1": 0.6519707177808405, "test_runtime": 3.3828, "test_samples_per_second": 605.419, "test_steps_per_second": 18.919}, {"test_loss": 0.5858394503593445, "test_mcc": 0.42288822066116555, "test_macro_f1": 0.6829970276484774, "test_runtime": 3.372, "test_samples_per_second": 607.346, "test_steps_per_second": 18.98}, {"test_loss": 0.6058034300804138, "test_mcc": 0.39311936584448814, "test_macro_f1": 0.6393598375022524, "test_runtime": 3.5923, "test_samples_per_second": 570.11, "test_steps_per_second": 17.816}]}, "total": {"test_mcc": 40.2110298336993, "test_mcc_se": 2.5345720528887483, "test_macro_f1": 67.10510800477138, "test_macro_f1_se": 1.8623515793622532}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.6700131893157959, "test_mcc": 0.3740421620355577, "test_macro_f1": 0.6739447324013332, "test_runtime": 4.0949, "test_samples_per_second": 500.132, "test_steps_per_second": 15.629}, {"test_loss": 0.6366943120956421, "test_mcc": 0.32050684953309855, "test_macro_f1": 0.6388631629953537, "test_runtime": 3.7603, "test_samples_per_second": 544.644, "test_steps_per_second": 17.02}, {"test_loss": 0.6911853551864624, "test_mcc": 0.09319268850906691, "test_macro_f1": 0.42782092976610225, "test_runtime": 4.0488, "test_samples_per_second": 505.832, "test_steps_per_second": 15.807}, {"test_loss": 0.6291834115982056, "test_mcc": 0.33817297910994226, "test_macro_f1": 0.6416045308518118, "test_runtime": 4.1474, "test_samples_per_second": 493.801, "test_steps_per_second": 15.431}, {"test_loss": 0.6307765245437622, "test_mcc": 0.3643849543110479, "test_macro_f1": 0.6648318132317736, "test_runtime": 3.9467, "test_samples_per_second": 518.914, "test_steps_per_second": 16.216}, {"test_loss": 0.6342612504959106, "test_mcc": 0.39455296210146185, "test_macro_f1": 0.6497472450166274, "test_runtime": 3.6604, "test_samples_per_second": 559.499, "test_steps_per_second": 17.484}, {"test_loss": 0.6275454759597778, "test_mcc": 0.39527382692959173, "test_macro_f1": 0.6885536857586152, "test_runtime": 3.5664, "test_samples_per_second": 574.251, "test_steps_per_second": 17.945}, {"test_loss": 0.5854218006134033, "test_mcc": 0.43127118941238674, "test_macro_f1": 0.7007007007007007, "test_runtime": 4.0275, "test_samples_per_second": 508.503, "test_steps_per_second": 15.891}, {"test_loss": 0.626651406288147, "test_mcc": 0.3668609196157721, "test_macro_f1": 0.6765128680732668, "test_runtime": 3.9361, "test_samples_per_second": 520.306, "test_steps_per_second": 16.26}, {"test_loss": 0.6265924572944641, "test_mcc": 0.40174727627327117, "test_macro_f1": 0.6881778826012073, "test_runtime": 4.0381, "test_samples_per_second": 507.165, "test_steps_per_second": 15.849}]}, "total": {"test_mcc": 34.80005807831197, "test_mcc_se": 5.891112809242516, "test_macro_f1": 64.50757551396794, "test_macro_f1_se": 4.90332642063649}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.6896312832832336, "test_mcc": 0.08325629386102648, "test_macro_f1": 0.5397824705015725, "test_runtime": 3.697, "test_samples_per_second": 553.966, "test_steps_per_second": 17.311}, {"test_loss": 0.6261224746704102, "test_mcc": 0.41268563828137, "test_macro_f1": 0.6723724204127339, "test_runtime": 3.6074, "test_samples_per_second": 567.717, "test_steps_per_second": 17.741}, {"test_loss": 0.6083418130874634, "test_mcc": 0.43887734336525486, "test_macro_f1": 0.6835754678925803, "test_runtime": 3.6496, "test_samples_per_second": 561.164, "test_steps_per_second": 17.536}, {"test_loss": 0.6021780371665955, "test_mcc": 0.4258120441916141, "test_macro_f1": 0.7016119945761763, "test_runtime": 3.3912, "test_samples_per_second": 603.908, "test_steps_per_second": 18.872}, {"test_loss": 0.6211950778961182, "test_mcc": 0.3781677490262853, "test_macro_f1": 0.66466385603077, "test_runtime": 3.3666, "test_samples_per_second": 608.337, "test_steps_per_second": 19.011}, {"test_loss": 0.6124529242515564, "test_mcc": 0.422553397458925, "test_macro_f1": 0.6923919669915093, "test_runtime": 3.2418, "test_samples_per_second": 631.745, "test_steps_per_second": 19.742}, {"test_loss": 0.6032592058181763, "test_mcc": 0.38286100639482296, "test_macro_f1": 0.6788236949142175, "test_runtime": 3.6045, "test_samples_per_second": 568.175, "test_steps_per_second": 17.755}, {"test_loss": 0.6162868738174438, "test_mcc": 0.40393994154702384, "test_macro_f1": 0.6801956938376226, "test_runtime": 3.747, "test_samples_per_second": 546.578, "test_steps_per_second": 17.081}, {"test_loss": 0.6417685747146606, "test_mcc": 0.33852251511156517, "test_macro_f1": 0.6123596148306225, "test_runtime": 3.5405, "test_samples_per_second": 578.453, "test_steps_per_second": 18.077}, {"test_loss": 0.6415753364562988, "test_mcc": 0.3432103274873687, "test_macro_f1": 0.6259765349862147, "test_runtime": 3.7258, "test_samples_per_second": 549.674, "test_steps_per_second": 17.177}]}, "total": {"test_mcc": 36.29886256725256, "test_mcc_se": 6.443400795800468, "test_macro_f1": 65.51753714974019, "test_macro_f1_se": 3.0588500577641713}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_loss": 0.6588037014007568, "test_mcc": 0.19064411004011184, "test_macro_f1": 0.5801808079875557, "test_runtime": 3.854, "test_samples_per_second": 531.4, "test_steps_per_second": 16.606}, {"test_loss": 0.6928514242172241, "test_mcc": 0.03405418008965942, "test_macro_f1": 0.39762840019529777, "test_runtime": 4.0021, "test_samples_per_second": 511.734, "test_steps_per_second": 15.992}, {"test_loss": 0.6938334703445435, "test_mcc": 0.025560163258814998, "test_macro_f1": 0.5056987315294055, "test_runtime": 4.0356, "test_samples_per_second": 507.486, "test_steps_per_second": 15.859}, {"test_loss": 0.6911170482635498, "test_mcc": 0.07442079554478276, "test_macro_f1": 0.4605552722096233, "test_runtime": 3.4665, "test_samples_per_second": 590.804, "test_steps_per_second": 18.463}, {"test_loss": 0.6085689067840576, "test_mcc": 0.3080014874037417, "test_macro_f1": 0.6429748348095037, "test_runtime": 3.5224, "test_samples_per_second": 581.427, "test_steps_per_second": 18.17}, {"test_loss": 0.6698602437973022, "test_mcc": 0.19576199204252373, "test_macro_f1": 0.5949636698974141, "test_runtime": 3.654, "test_samples_per_second": 560.489, "test_steps_per_second": 17.515}, {"test_loss": 0.6922368407249451, "test_mcc": 0.03934575149380795, "test_macro_f1": 0.5193749628462816, "test_runtime": 3.5469, "test_samples_per_second": 577.403, "test_steps_per_second": 18.044}, {"test_loss": 0.657731294631958, "test_mcc": 0.2168754573083232, "test_macro_f1": 0.5929892809573141, "test_runtime": 3.917, "test_samples_per_second": 522.843, "test_steps_per_second": 16.339}, {"test_loss": 0.6937646865844727, "test_mcc": 0.07642774374983749, "test_macro_f1": 0.37646466673002266, "test_runtime": 3.806, "test_samples_per_second": 538.101, "test_steps_per_second": 16.816}, {"test_loss": 0.6599138975143433, "test_mcc": 0.26025262837339785, "test_macro_f1": 0.6069247607020354, "test_runtime": 3.9867, "test_samples_per_second": 513.711, "test_steps_per_second": 16.053}]}, "total": {"test_mcc": 14.21344309305001, "test_mcc_se": 6.435185173376038, "test_macro_f1": 52.77755387864455, "test_macro_f1_se": 5.694078063706373}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_em": 24.089852827265684, "test_f1": 29.454394201578225}, {"test_em": 26.356589147286822, "test_f1": 31.09900116423737}, {"test_em": 32.30293663060278, "test_f1": 36.40005075783798}, {"test_em": 25.856697819314643, "test_f1": 30.978851857692895}, {"test_em": 28.10810810810811, "test_f1": 33.47131248837114}, {"test_em": 27.756360832690824, "test_f1": 33.092696872563785}, {"test_em": 22.703113135914958, "test_f1": 27.806544110281152}, {"test_em": 17.765709852598913, "test_f1": 24.12791020037143}, {"test_em": 29.568627450980394, "test_f1": 34.143366183655054}, {"test_em": 34.3944099378882, "test_f1": 38.51340311092613}]}, "total": {"test_em": 26.89024057426513, "test_em_se": 2.958101290751386, "test_f1": 31.908753094751518, "test_f1_se": 2.593197558608933}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_em": 28.11773818745159, "test_f1": 33.114269641279705}, {"test_em": 28.372093023255815, "test_f1": 34.17356553255469}, {"test_em": 27.975270479134466, "test_f1": 32.64192914496652}, {"test_em": 32.71028037383178, "test_f1": 37.80566256845518}, {"test_em": 24.633204633204635, "test_f1": 30.82595248931808}, {"test_em": 24.903623747108714, "test_f1": 30.516780851763144}, {"test_em": 27.33485193621868, "test_f1": 32.36764006983055}, {"test_em": 25.13576415826222, "test_f1": 30.745824358285855}, {"test_em": 28.941176470588236, "test_f1": 33.67116338897911}, {"test_em": 32.7639751552795, "test_f1": 37.456839293339904}]}, "total": {"test_em": 28.088797816433566, "test_em_se": 1.7941253746170756, "test_f1": 33.33196273387727, "test_f1_se": 1.6029830187247598}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_em": 24.3996901626646, "test_f1": 30.454827704986442}, {"test_em": 35.65891472868217, "test_f1": 41.03447469476814}, {"test_em": 31.839258114374033, "test_f1": 37.37206831273503}, {"test_em": 32.087227414330215, "test_f1": 37.96768525043157}, {"test_em": 29.343629343629345, "test_f1": 36.08025637873918}, {"test_em": 26.985350809560526, "test_f1": 32.40030365592873}, {"test_em": 32.49810174639332, "test_f1": 37.58415802929761}, {"test_em": 34.52288595810706, "test_f1": 39.96309441530615}, {"test_em": 27.92156862745098, "test_f1": 33.70433348972622}, {"test_em": 36.72360248447205, "test_f1": 41.33736442005288}]}, "total": {"test_em": 31.19802293896643, "test_em_se": 2.466419731848676, "test_f1": 36.7898566351972, "test_f1_se": 2.2683745134792104}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.5726084113121033, "test_mcc": 0.6199986544630034, "test_macro_f1": 0.5720941756220699, "test_runtime": 17.6814, "test_samples_per_second": 115.828, "test_steps_per_second": 14.479}, {"test_loss": 0.6118205785751343, "test_mcc": 0.6092290253406611, "test_macro_f1": 0.5775012802055067, "test_runtime": 17.0436, "test_samples_per_second": 120.163, "test_steps_per_second": 15.02}, {"test_loss": 0.7417598962783813, "test_mcc": 0.5807399583420293, "test_macro_f1": 0.6235122993612111, "test_runtime": 17.3598, "test_samples_per_second": 117.973, "test_steps_per_second": 14.747}, {"test_loss": 0.562394917011261, "test_mcc": 0.6331956874356869, "test_macro_f1": 0.5717192631754249, "test_runtime": 17.0289, "test_samples_per_second": 120.266, "test_steps_per_second": 15.033}, {"test_loss": 0.582236647605896, "test_mcc": 0.6296114117531763, "test_macro_f1": 0.6621245457189301, "test_runtime": 16.9049, "test_samples_per_second": 121.148, "test_steps_per_second": 15.144}, {"test_loss": 0.5920650959014893, "test_mcc": 0.6162665243672435, "test_macro_f1": 0.6036378590453046, "test_runtime": 17.2713, "test_samples_per_second": 118.578, "test_steps_per_second": 14.822}, {"test_loss": 0.5349956154823303, "test_mcc": 0.6573002425540495, "test_macro_f1": 0.5896052505990227, "test_runtime": 16.7219, "test_samples_per_second": 122.474, "test_steps_per_second": 15.309}, {"test_loss": 0.5933281183242798, "test_mcc": 0.629328663831471, "test_macro_f1": 0.5539720777184239, "test_runtime": 17.7687, "test_samples_per_second": 115.259, "test_steps_per_second": 14.407}, {"test_loss": 0.6067169904708862, "test_mcc": 0.6083920125599356, "test_macro_f1": 0.5472928445491675, "test_runtime": 17.5813, "test_samples_per_second": 116.487, "test_steps_per_second": 14.561}, {"test_loss": 0.578134298324585, "test_mcc": 0.6338836560344059, "test_macro_f1": 0.6423038248258104, "test_runtime": 17.1644, "test_samples_per_second": 119.317, "test_steps_per_second": 14.915}]}, "total": {"test_mcc": 62.17945836681663, "test_mcc_se": 1.2586525668886084, "test_macro_f1": 59.43763420820871, "test_macro_f1_se": 2.3545640168379367}}, "num_model_parameters": 103822851, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.9213099479675293, "test_mcc": 0.32971687929259735, "test_macro_f1": 0.5357426758782414, "test_runtime": 5.0011, "test_samples_per_second": 409.509, "test_steps_per_second": 12.797}, {"test_loss": 0.9566901326179504, "test_mcc": 0.3479216397527314, "test_macro_f1": 0.5601224338295355, "test_runtime": 4.9476, "test_samples_per_second": 413.941, "test_steps_per_second": 12.936}, {"test_loss": 0.9920240044593811, "test_mcc": 0.29635375313408324, "test_macro_f1": 0.5002399058218284, "test_runtime": 4.9561, "test_samples_per_second": 413.232, "test_steps_per_second": 12.913}, {"test_loss": 0.9680212140083313, "test_mcc": 0.318761851930472, "test_macro_f1": 0.5280450855160391, "test_runtime": 4.9385, "test_samples_per_second": 414.703, "test_steps_per_second": 12.959}, {"test_loss": 0.9732691049575806, "test_mcc": 0.3128550131363657, "test_macro_f1": 0.5393004000580638, "test_runtime": 4.9088, "test_samples_per_second": 417.209, "test_steps_per_second": 13.038}, {"test_loss": 1.0565303564071655, "test_mcc": 0.3039965312605174, "test_macro_f1": 0.5026635723701826, "test_runtime": 4.9731, "test_samples_per_second": 411.814, "test_steps_per_second": 12.869}, {"test_loss": 0.9325793981552124, "test_mcc": 0.34185514504375425, "test_macro_f1": 0.5477161252370936, "test_runtime": 4.9533, "test_samples_per_second": 413.46, "test_steps_per_second": 12.921}, {"test_loss": 0.971328616142273, "test_mcc": 0.3087713951211526, "test_macro_f1": 0.5103277916342157, "test_runtime": 4.9329, "test_samples_per_second": 415.169, "test_steps_per_second": 12.974}, {"test_loss": 0.9688633680343628, "test_mcc": 0.35797837847078573, "test_macro_f1": 0.5616992216584183, "test_runtime": 4.9006, "test_samples_per_second": 417.908, "test_steps_per_second": 13.06}, {"test_loss": 1.0071221590042114, "test_mcc": 0.2873604912192826, "test_macro_f1": 0.47133589372946844, "test_runtime": 4.8337, "test_samples_per_second": 423.693, "test_steps_per_second": 13.24}]}, "total": {"test_mcc": 32.05571078361742, "test_mcc_se": 1.4388464239627061, "test_macro_f1": 52.571931057330865, "test_macro_f1_se": 1.8043753604563753}}, "num_model_parameters": 103822851, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.8476896286010742, "test_mcc": 0.3475715020930955, "test_macro_f1": 0.4428402859730394, "test_runtime": 4.0609, "test_samples_per_second": 504.325, "test_steps_per_second": 15.76}, {"test_loss": 0.8726292848587036, "test_mcc": 0.33329920929078655, "test_macro_f1": 0.4688540897559277, "test_runtime": 3.7913, "test_samples_per_second": 540.188, "test_steps_per_second": 16.881}, {"test_loss": 0.879153847694397, "test_mcc": 0.3648490066627047, "test_macro_f1": 0.45521781152136825, "test_runtime": 3.8702, "test_samples_per_second": 529.166, "test_steps_per_second": 16.536}, {"test_loss": 0.872098445892334, "test_mcc": 0.3026595526388022, "test_macro_f1": 0.42422678622718396, "test_runtime": 3.9424, "test_samples_per_second": 519.48, "test_steps_per_second": 16.234}, {"test_loss": 0.8713445663452148, "test_mcc": 0.3183080298317431, "test_macro_f1": 0.45353183774567407, "test_runtime": 3.9489, "test_samples_per_second": 518.626, "test_steps_per_second": 16.207}, {"test_loss": 0.9204418659210205, "test_mcc": 0.3104790694226211, "test_macro_f1": 0.46956421726216896, "test_runtime": 4.1129, "test_samples_per_second": 497.948, "test_steps_per_second": 15.561}, {"test_loss": 0.8710132241249084, "test_mcc": 0.34012792570419587, "test_macro_f1": 0.5087998347243458, "test_runtime": 3.9299, "test_samples_per_second": 521.132, "test_steps_per_second": 16.285}, {"test_loss": 0.8771933317184448, "test_mcc": 0.3312332691941697, "test_macro_f1": 0.5012765932310373, "test_runtime": 3.982, "test_samples_per_second": 514.319, "test_steps_per_second": 16.072}, {"test_loss": 0.886886477470398, "test_mcc": 0.3333410669123718, "test_macro_f1": 0.4984951519804364, "test_runtime": 4.1143, "test_samples_per_second": 497.781, "test_steps_per_second": 15.556}, {"test_loss": 0.9118508696556091, "test_mcc": 0.2908831325908192, "test_macro_f1": 0.4288120818236794, "test_runtime": 4.1216, "test_samples_per_second": 496.889, "test_steps_per_second": 15.528}]}, "total": {"test_mcc": 32.7275176434131, "test_mcc_se": 1.3658426619072654, "test_macro_f1": 46.51618690244862, "test_macro_f1_se": 1.857357756503323}}, "num_model_parameters": 103822851, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.06883767247200012, "test_micro_f1": 0.6468513853904282, "test_micro_f1_no_misc": 0.7082630691399663, "test_runtime": 8.5316, "test_samples_per_second": 240.049, "test_steps_per_second": 7.502}, {"test_loss": 0.06346842646598816, "test_micro_f1": 0.6851174934725849, "test_micro_f1_no_misc": 0.7476303317535544, "test_runtime": 8.0309, "test_samples_per_second": 255.014, "test_steps_per_second": 7.969}, {"test_loss": 0.05922970920801163, "test_micro_f1": 0.674264007597341, "test_micro_f1_no_misc": 0.7374537770734284, "test_runtime": 8.0036, "test_samples_per_second": 255.884, "test_steps_per_second": 7.996}, {"test_loss": 0.062011994421482086, "test_micro_f1": 0.6938369781312127, "test_micro_f1_no_misc": 0.7361492046077892, "test_runtime": 8.5025, "test_samples_per_second": 240.869, "test_steps_per_second": 7.527}, {"test_loss": 0.06730565428733826, "test_micro_f1": 0.6995260663507109, "test_micro_f1_no_misc": 0.7431524547803617, "test_runtime": 8.5156, "test_samples_per_second": 240.499, "test_steps_per_second": 7.516}, {"test_loss": 0.05460764095187187, "test_micro_f1": 0.727015558698727, "test_micro_f1_no_misc": 0.7758433079434166, "test_runtime": 7.5057, "test_samples_per_second": 272.861, "test_steps_per_second": 8.527}, {"test_loss": 0.06998375058174133, "test_micro_f1": 0.6820365033621518, "test_micro_f1_no_misc": 0.7251828631138975, "test_runtime": 7.7665, "test_samples_per_second": 263.696, "test_steps_per_second": 8.24}, {"test_loss": 0.05449652671813965, "test_micro_f1": 0.6753106428957321, "test_micro_f1_no_misc": 0.7295081967213114, "test_runtime": 8.5585, "test_samples_per_second": 239.294, "test_steps_per_second": 7.478}, {"test_loss": 0.05403764545917511, "test_micro_f1": 0.7037037037037037, "test_micro_f1_no_misc": 0.7495995728777363, "test_runtime": 8.0926, "test_samples_per_second": 253.07, "test_steps_per_second": 7.908}, {"test_loss": 0.06449912488460541, "test_micro_f1": 0.7053093034583536, "test_micro_f1_no_misc": 0.7600872410032715, "test_runtime": 8.4635, "test_samples_per_second": 241.982, "test_steps_per_second": 7.562}]}, "total": {"test_micro_f1": 68.92971643060946, "test_micro_f1_se": 1.35561615833289, "test_micro_f1_no_misc": 74.12870019014733, "test_micro_f1_no_misc_se": 1.1669195624897808}}, "num_model_parameters": 103236873, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.05945861339569092, "test_micro_f1": 0.8066528066528067, "test_micro_f1_no_misc": 0.8260869565217391, "test_runtime": 9.2977, "test_samples_per_second": 220.27, "test_steps_per_second": 6.883}, {"test_loss": 0.0626656711101532, "test_micro_f1": 0.8129032258064516, "test_micro_f1_no_misc": 0.828741623231571, "test_runtime": 7.0629, "test_samples_per_second": 289.967, "test_steps_per_second": 9.061}, {"test_loss": 0.05868513882160187, "test_micro_f1": 0.8133793469604459, "test_micro_f1_no_misc": 0.8297948902482908, "test_runtime": 9.4327, "test_samples_per_second": 217.117, "test_steps_per_second": 6.785}, {"test_loss": 0.06490593403577805, "test_micro_f1": 0.8093023255813954, "test_micro_f1_no_misc": 0.8304547056750088, "test_runtime": 8.8447, "test_samples_per_second": 231.551, "test_steps_per_second": 7.236}, {"test_loss": 0.06991780549287796, "test_micro_f1": 0.7959527824620574, "test_micro_f1_no_misc": 0.817903596021423, "test_runtime": 9.3126, "test_samples_per_second": 219.918, "test_steps_per_second": 6.872}, {"test_loss": 0.07103292644023895, "test_micro_f1": 0.8177504884175271, "test_micro_f1_no_misc": 0.8392036753445635, "test_runtime": 9.0696, "test_samples_per_second": 225.81, "test_steps_per_second": 7.057}, {"test_loss": 0.06587117910385132, "test_micro_f1": 0.8032085561497326, "test_micro_f1_no_misc": 0.8260244428468728, "test_runtime": 9.3079, "test_samples_per_second": 220.029, "test_steps_per_second": 6.876}, {"test_loss": 0.05430710315704346, "test_micro_f1": 0.7977931034482759, "test_micro_f1_no_misc": 0.8332097850259451, "test_runtime": 9.3008, "test_samples_per_second": 220.196, "test_steps_per_second": 6.881}, {"test_loss": 0.06434528529644012, "test_micro_f1": 0.814537680384821, "test_micro_f1_no_misc": 0.8306878306878307, "test_runtime": 8.8603, "test_samples_per_second": 231.142, "test_steps_per_second": 7.223}, {"test_loss": 0.060149192810058594, "test_micro_f1": 0.8078473528621338, "test_micro_f1_no_misc": 0.8306595365418895, "test_runtime": 7.4452, "test_samples_per_second": 275.075, "test_steps_per_second": 8.596}]}, "total": {"test_micro_f1": 80.79327668725647, "test_micro_f1_se": 0.4462584655856006, "test_micro_f1_no_misc": 82.92767042145132, "test_micro_f1_no_misc_se": 0.3394562974057795}}, "num_model_parameters": 103236873, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.04003229737281799, "test_micro_f1": 0.8323203432248838, "test_micro_f1_no_misc": 0.8752039151712887, "test_runtime": 7.1044, "test_samples_per_second": 288.273, "test_steps_per_second": 9.009}, {"test_loss": 0.03812097758054733, "test_micro_f1": 0.8200743494423792, "test_micro_f1_no_misc": 0.857849196538937, "test_runtime": 7.2192, "test_samples_per_second": 283.687, "test_steps_per_second": 8.865}, {"test_loss": 0.047607824206352234, "test_micro_f1": 0.831476323119777, "test_micro_f1_no_misc": 0.8660194174757282, "test_runtime": 6.8232, "test_samples_per_second": 300.151, "test_steps_per_second": 9.38}, {"test_loss": 0.03651485592126846, "test_micro_f1": 0.847949080622348, "test_micro_f1_no_misc": 0.8841940532081377, "test_runtime": 6.4784, "test_samples_per_second": 316.126, "test_steps_per_second": 9.879}, {"test_loss": 0.04064562916755676, "test_micro_f1": 0.8573333333333334, "test_micro_f1_no_misc": 0.8807947019867549, "test_runtime": 7.0894, "test_samples_per_second": 288.881, "test_steps_per_second": 9.028}, {"test_loss": 0.037759192287921906, "test_micro_f1": 0.8276807125727988, "test_micro_f1_no_misc": 0.8737936154417224, "test_runtime": 7.1332, "test_samples_per_second": 287.108, "test_steps_per_second": 8.972}, {"test_loss": 0.03620992600917816, "test_micro_f1": 0.8473177441540578, "test_micro_f1_no_misc": 0.8877470355731226, "test_runtime": 6.3232, "test_samples_per_second": 323.888, "test_steps_per_second": 10.122}, {"test_loss": 0.04194864630699158, "test_micro_f1": 0.8386206896551724, "test_micro_f1_no_misc": 0.8637379002233805, "test_runtime": 6.697, "test_samples_per_second": 305.807, "test_steps_per_second": 9.556}, {"test_loss": 0.03643868863582611, "test_micro_f1": 0.8405589394482265, "test_micro_f1_no_misc": 0.875710804224208, "test_runtime": 6.6388, "test_samples_per_second": 308.488, "test_steps_per_second": 9.64}, {"test_loss": 0.04660961776971817, "test_micro_f1": 0.8426775399252464, "test_micro_f1_no_misc": 0.8869230769230768, "test_runtime": 6.9016, "test_samples_per_second": 296.745, "test_steps_per_second": 9.273}]}, "total": {"test_micro_f1": 83.86009055498225, "test_micro_f1_se": 0.6812915933282139, "test_micro_f1_no_misc": 87.51973716766356, "test_micro_f1_no_misc_se": 0.6286969024982924}}, "num_model_parameters": 103236873, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.058214426040649414, "test_micro_f1": 0.7819004524886878, "test_micro_f1_no_misc": 0.8168449197860963, "test_runtime": 6.8438, "test_samples_per_second": 299.25, "test_steps_per_second": 9.352}, {"test_loss": 0.05492616444826126, "test_micro_f1": 0.8232758620689655, "test_micro_f1_no_misc": 0.8537931034482759, "test_runtime": 6.9798, "test_samples_per_second": 293.417, "test_steps_per_second": 9.169}, {"test_loss": 0.05586833134293556, "test_micro_f1": 0.8095823095823095, "test_micro_f1_no_misc": 0.8466299862448419, "test_runtime": 6.5378, "test_samples_per_second": 313.253, "test_steps_per_second": 9.789}, {"test_loss": 0.06423637270927429, "test_micro_f1": 0.7535022354694485, "test_micro_f1_no_misc": 0.7955985328442814, "test_runtime": 6.7825, "test_samples_per_second": 301.952, "test_steps_per_second": 9.436}, {"test_loss": 0.06065574660897255, "test_micro_f1": 0.7533577533577533, "test_micro_f1_no_misc": 0.8046211348963642, "test_runtime": 6.4621, "test_samples_per_second": 316.925, "test_steps_per_second": 9.904}, {"test_loss": 0.060790691524744034, "test_micro_f1": 0.7508226144181873, "test_micro_f1_no_misc": 0.8071099407504939, "test_runtime": 6.4554, "test_samples_per_second": 317.253, "test_steps_per_second": 9.914}, {"test_loss": 0.052210140973329544, "test_micro_f1": 0.8159950015620119, "test_micro_f1_no_misc": 0.8532494758909852, "test_runtime": 7.0046, "test_samples_per_second": 292.378, "test_steps_per_second": 9.137}, {"test_loss": 0.05425077676773071, "test_micro_f1": 0.8266913809082483, "test_micro_f1_no_misc": 0.864565292691375, "test_runtime": 7.0085, "test_samples_per_second": 292.217, "test_steps_per_second": 9.132}, {"test_loss": 0.061540860682725906, "test_micro_f1": 0.7489990760702188, "test_micro_f1_no_misc": 0.7933491686460807, "test_runtime": 6.5476, "test_samples_per_second": 312.785, "test_steps_per_second": 9.775}, {"test_loss": 0.05087337642908096, "test_micro_f1": 0.8012288786482334, "test_micro_f1_no_misc": 0.8298228017385489, "test_runtime": 6.5804, "test_samples_per_second": 311.228, "test_steps_per_second": 9.726}]}, "total": {"test_micro_f1": 78.65355564574064, "test_micro_f1_se": 2.0110676589375993, "test_micro_f1_no_misc": 82.65584356937345, "test_micro_f1_no_misc_se": 1.6434152524804666}}, "num_model_parameters": 103236873, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6487342119216919, "test_mcc": 0.4033269120446041, "test_macro_f1": 0.7006715329859434, "test_runtime": 4.037, "test_samples_per_second": 507.303, "test_steps_per_second": 15.853}, {"test_loss": 0.6705654263496399, "test_mcc": 0.36337320328782124, "test_macro_f1": 0.6614485313968457, "test_runtime": 4.357, "test_samples_per_second": 470.05, "test_steps_per_second": 14.689}, {"test_loss": 0.6137560606002808, "test_mcc": 0.38097361728698736, "test_macro_f1": 0.684124448169392, "test_runtime": 4.3381, "test_samples_per_second": 472.092, "test_steps_per_second": 14.753}, {"test_loss": 0.6877801418304443, "test_mcc": 0.08071390789082444, "test_macro_f1": 0.3866653849424518, "test_runtime": 4.2577, "test_samples_per_second": 481.011, "test_steps_per_second": 15.032}, {"test_loss": 0.63169264793396, "test_mcc": 0.4257069460638268, "test_macro_f1": 0.7052013293144757, "test_runtime": 4.3136, "test_samples_per_second": 474.779, "test_steps_per_second": 14.837}, {"test_loss": 0.5956544280052185, "test_mcc": 0.4152613731722284, "test_macro_f1": 0.7074887758613002, "test_runtime": 4.1896, "test_samples_per_second": 488.835, "test_steps_per_second": 15.276}, {"test_loss": 0.5741124153137207, "test_mcc": 0.4014330935056109, "test_macro_f1": 0.6982169085107095, "test_runtime": 4.2678, "test_samples_per_second": 479.872, "test_steps_per_second": 14.996}, {"test_loss": 0.6372643709182739, "test_mcc": 0.4494857969679366, "test_macro_f1": 0.7092647826438297, "test_runtime": 4.2203, "test_samples_per_second": 485.275, "test_steps_per_second": 15.165}, {"test_loss": 0.7149484157562256, "test_mcc": 0.39054217934223284, "test_macro_f1": 0.6862717722740119, "test_runtime": 4.2646, "test_samples_per_second": 480.236, "test_steps_per_second": 15.007}, {"test_loss": 0.6791335344314575, "test_mcc": 0.3826444586847789, "test_macro_f1": 0.657469168004014, "test_runtime": 4.2825, "test_samples_per_second": 478.225, "test_steps_per_second": 14.945}]}, "total": {"test_mcc": 36.93461488246852, "test_mcc_se": 6.467568922484151, "test_macro_f1": 65.96822634102973, "test_macro_f1_se": 6.05282813470691}}, "num_model_parameters": 103822082, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6919434070587158, "test_mcc": 0.04364877693225425, "test_macro_f1": 0.5209868953027579, "test_runtime": 4.1965, "test_samples_per_second": 488.029, "test_steps_per_second": 15.251}, {"test_loss": 0.5869007110595703, "test_mcc": 0.4435579728248503, "test_macro_f1": 0.7088886470211615, "test_runtime": 4.3205, "test_samples_per_second": 474.018, "test_steps_per_second": 14.813}, {"test_loss": 0.6911429762840271, "test_mcc": 0.04933500575259521, "test_macro_f1": 0.4787298442573331, "test_runtime": 4.2129, "test_samples_per_second": 486.126, "test_steps_per_second": 15.191}, {"test_loss": 0.6268758773803711, "test_mcc": 0.38153934404142953, "test_macro_f1": 0.6710568583360103, "test_runtime": 4.3988, "test_samples_per_second": 465.578, "test_steps_per_second": 14.549}, {"test_loss": 0.5769331455230713, "test_mcc": 0.4696081756909976, "test_macro_f1": 0.726261168866543, "test_runtime": 4.1937, "test_samples_per_second": 488.351, "test_steps_per_second": 15.261}, {"test_loss": 0.6944572329521179, "test_mcc": 0.006975388794855385, "test_macro_f1": 0.4432573054576538, "test_runtime": 4.2079, "test_samples_per_second": 486.705, "test_steps_per_second": 15.21}, {"test_loss": 0.6136187314987183, "test_mcc": 0.42201142736891334, "test_macro_f1": 0.7048959515883282, "test_runtime": 4.0777, "test_samples_per_second": 502.242, "test_steps_per_second": 15.695}, {"test_loss": 0.5537933111190796, "test_mcc": 0.4402632866491776, "test_macro_f1": 0.7199664104016076, "test_runtime": 4.1394, "test_samples_per_second": 494.757, "test_steps_per_second": 15.461}, {"test_loss": 0.6070873737335205, "test_mcc": 0.3964126942183216, "test_macro_f1": 0.6925371760402893, "test_runtime": 4.1474, "test_samples_per_second": 493.809, "test_steps_per_second": 15.432}, {"test_loss": 0.6227549314498901, "test_mcc": 0.4413150589864496, "test_macro_f1": 0.7051058530510586, "test_runtime": 4.2429, "test_samples_per_second": 482.687, "test_steps_per_second": 15.084}]}, "total": {"test_mcc": 30.94667131259844, "test_mcc_se": 11.928774377318142, "test_macro_f1": 63.71686110322743, "test_macro_f1_se": 6.838371811592003}}, "num_model_parameters": 103822082, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.5993164777755737, "test_mcc": 0.48986692357942224, "test_macro_f1": 0.737095846185617, "test_runtime": 3.8412, "test_samples_per_second": 533.163, "test_steps_per_second": 16.661}, {"test_loss": 0.5795429944992065, "test_mcc": 0.44621107141749183, "test_macro_f1": 0.7021602633739072, "test_runtime": 3.8562, "test_samples_per_second": 531.094, "test_steps_per_second": 16.597}, {"test_loss": 0.6068947315216064, "test_mcc": 0.34466031982071293, "test_macro_f1": 0.6510517802302505, "test_runtime": 3.8753, "test_samples_per_second": 528.472, "test_steps_per_second": 16.515}, {"test_loss": 0.6258478164672852, "test_mcc": 0.34233160386122435, "test_macro_f1": 0.6401611057549355, "test_runtime": 4.0348, "test_samples_per_second": 507.589, "test_steps_per_second": 15.862}, {"test_loss": 0.6043746471405029, "test_mcc": 0.3713623563852217, "test_macro_f1": 0.6589965063554597, "test_runtime": 3.9451, "test_samples_per_second": 519.119, "test_steps_per_second": 16.222}, {"test_loss": 0.5790317058563232, "test_mcc": 0.44331554411426954, "test_macro_f1": 0.7143563133185076, "test_runtime": 3.8196, "test_samples_per_second": 536.184, "test_steps_per_second": 16.756}, {"test_loss": 0.6020852327346802, "test_mcc": 0.35762325743498313, "test_macro_f1": 0.6615650839033274, "test_runtime": 3.8477, "test_samples_per_second": 532.263, "test_steps_per_second": 16.633}, {"test_loss": 0.6067598462104797, "test_mcc": 0.38327542457705843, "test_macro_f1": 0.6622892657007795, "test_runtime": 3.8914, "test_samples_per_second": 526.295, "test_steps_per_second": 16.447}, {"test_loss": 0.6236613988876343, "test_mcc": 0.4757670710311456, "test_macro_f1": 0.7194382794854168, "test_runtime": 3.8476, "test_samples_per_second": 532.275, "test_steps_per_second": 16.634}, {"test_loss": 0.6921616196632385, "test_mcc": -0.013261041231876162, "test_macro_f1": 0.3730716120686624, "test_runtime": 3.9393, "test_samples_per_second": 519.888, "test_steps_per_second": 16.246}]}, "total": {"test_mcc": 36.41152530989654, "test_mcc_se": 8.886766913708396, "test_macro_f1": 65.20186056376865, "test_macro_f1_se": 6.414056469261838}}, "num_model_parameters": 103822082, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6277604103088379, "test_mcc": 0.31808141457773237, "test_macro_f1": 0.6365954887218046, "test_runtime": 4.072, "test_samples_per_second": 502.947, "test_steps_per_second": 15.717}, {"test_loss": 0.6356289982795715, "test_mcc": 0.3106380788005972, "test_macro_f1": 0.6460178878994263, "test_runtime": 4.1772, "test_samples_per_second": 490.284, "test_steps_per_second": 15.321}, {"test_loss": 0.6566583514213562, "test_mcc": 0.3003278177265805, "test_macro_f1": 0.6329601036681154, "test_runtime": 4.1795, "test_samples_per_second": 490.007, "test_steps_per_second": 15.313}, {"test_loss": 0.6106196045875549, "test_mcc": 0.33250037852923453, "test_macro_f1": 0.6618984038532276, "test_runtime": 4.0429, "test_samples_per_second": 506.562, "test_steps_per_second": 15.83}, {"test_loss": 0.5979601144790649, "test_mcc": 0.38489636608224637, "test_macro_f1": 0.6825792740817529, "test_runtime": 4.097, "test_samples_per_second": 499.876, "test_steps_per_second": 15.621}, {"test_loss": 0.6099728345870972, "test_mcc": 0.34184507411513493, "test_macro_f1": 0.644363676747485, "test_runtime": 4.2454, "test_samples_per_second": 482.402, "test_steps_per_second": 15.075}, {"test_loss": 0.625065267086029, "test_mcc": 0.3303668167593111, "test_macro_f1": 0.6391650072459252, "test_runtime": 4.0416, "test_samples_per_second": 506.727, "test_steps_per_second": 15.835}, {"test_loss": 0.612177848815918, "test_mcc": 0.3298103481972319, "test_macro_f1": 0.6635156378734465, "test_runtime": 4.3321, "test_samples_per_second": 472.752, "test_steps_per_second": 14.774}, {"test_loss": 0.6194630861282349, "test_mcc": 0.32903415412492004, "test_macro_f1": 0.6398000089034133, "test_runtime": 4.092, "test_samples_per_second": 500.49, "test_steps_per_second": 15.64}, {"test_loss": 0.6908828020095825, "test_mcc": 0.0592236688996791, "test_macro_f1": 0.3649588486665361, "test_runtime": 4.1798, "test_samples_per_second": 489.973, "test_steps_per_second": 15.312}]}, "total": {"test_mcc": 30.36724117812668, "test_mcc_se": 5.503031344055084, "test_macro_f1": 62.11854337661132, "test_macro_f1_se": 5.660688291211028}}, "num_model_parameters": 103822082, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_em": 43.532145623547635, "test_f1": 47.88472264170534}, {"test_em": 46.12403100775194, "test_f1": 50.036818881206514}, {"test_em": 49.61360123647604, "test_f1": 54.25085071264863}, {"test_em": 45.17133956386293, "test_f1": 49.70530327053934}, {"test_em": 40.69498069498069, "test_f1": 44.33715057019481}, {"test_em": 48.03392444101773, "test_f1": 52.56562545162576}, {"test_em": 45.63401670463174, "test_f1": 50.12413229819098}, {"test_em": 43.9100077579519, "test_f1": 47.00858607614871}, {"test_em": 49.333333333333336, "test_f1": 53.68984615393519}, {"test_em": 44.099378881987576, "test_f1": 47.867795828679085}]}, "total": {"test_em": 45.61467592455415, "test_em_se": 1.726967705062459, "test_f1": 49.747083188487444, "test_f1_se": 1.9355454650980746}}, "num_model_parameters": 103231490, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_em": 49.10921766072812, "test_f1": 53.92614146092616}, {"test_em": 43.798449612403104, "test_f1": 48.37731074302788}, {"test_em": 48.91808346213292, "test_f1": 53.7974936895553}, {"test_em": 50.07788161993769, "test_f1": 54.18164113919444}, {"test_em": 45.63706563706564, "test_f1": 48.99616867109126}, {"test_em": 49.26754047802621, "test_f1": 54.64584083305305}, {"test_em": 46.46924829157175, "test_f1": 50.831510934016606}, {"test_em": 44.45306439100077, "test_f1": 48.51423074586686}, {"test_em": 41.09803921568628, "test_f1": 46.81132426906461}, {"test_em": 48.60248447204969, "test_f1": 52.75919665204901}]}, "total": {"test_em": 46.74310748406022, "test_em_se": 1.8288688437714435, "test_f1": 51.28408591378452, "test_f1_se": 1.8098309293843824}}, "num_model_parameters": 103231490, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_em": 48.2571649883811, "test_f1": 52.632896377095896}, {"test_em": 47.286821705426355, "test_f1": 51.635404820857346}, {"test_em": 49.07264296754251, "test_f1": 53.43790487801186}, {"test_em": 50.15576323987539, "test_f1": 54.30500871674431}, {"test_em": 46.1003861003861, "test_f1": 50.30926696826739}, {"test_em": 46.106399383191984, "test_f1": 51.17181725758078}, {"test_em": 48.06378132118451, "test_f1": 52.73714787750697}, {"test_em": 47.47866563227308, "test_f1": 51.71096406821653}, {"test_em": 47.05882352941177, "test_f1": 51.63341093615482}, {"test_em": 50.85403726708075, "test_f1": 54.44944626447974}]}, "total": {"test_em": 48.043448613475356, "test_em_se": 0.9877054587744731, "test_f1": 52.402326816491566, "test_f1_se": 0.8417870427953679}}, "num_model_parameters": 103231490, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.5931481122970581, "test_mcc": 0.6255428719442041, "test_macro_f1": 0.5901643210244066, "test_runtime": 8.4711, "test_samples_per_second": 241.763, "test_steps_per_second": 30.22}, {"test_loss": 0.6462446451187134, "test_mcc": 0.5863532053312338, "test_macro_f1": 0.5393369790917317, "test_runtime": 8.206, "test_samples_per_second": 249.575, "test_steps_per_second": 31.197}, {"test_loss": 0.6812509298324585, "test_mcc": 0.5719674419735671, "test_macro_f1": 0.5764898343266096, "test_runtime": 8.3628, "test_samples_per_second": 244.895, "test_steps_per_second": 30.612}, {"test_loss": 0.6184343099594116, "test_mcc": 0.575077777450713, "test_macro_f1": 0.5416466032915089, "test_runtime": 8.1221, "test_samples_per_second": 252.15, "test_steps_per_second": 31.519}, {"test_loss": 0.610095739364624, "test_mcc": 0.610446318184373, "test_macro_f1": 0.5511925490492496, "test_runtime": 8.0898, "test_samples_per_second": 253.157, "test_steps_per_second": 31.645}, {"test_loss": 0.6265614032745361, "test_mcc": 0.5957720357046109, "test_macro_f1": 0.5437740642654306, "test_runtime": 8.3384, "test_samples_per_second": 245.612, "test_steps_per_second": 30.701}, {"test_loss": 0.6821038126945496, "test_mcc": 0.5735318810383373, "test_macro_f1": 0.5339863438536185, "test_runtime": 8.0341, "test_samples_per_second": 254.913, "test_steps_per_second": 31.864}, {"test_loss": 0.6051120758056641, "test_mcc": 0.6151974944839927, "test_macro_f1": 0.5503615420232837, "test_runtime": 8.5923, "test_samples_per_second": 238.353, "test_steps_per_second": 29.794}, {"test_loss": 0.619484543800354, "test_mcc": 0.5951834313069678, "test_macro_f1": 0.5433073158306497, "test_runtime": 8.4956, "test_samples_per_second": 241.066, "test_steps_per_second": 30.133}, {"test_loss": 0.5722318887710571, "test_mcc": 0.6166146523270661, "test_macro_f1": 0.6456485958935757, "test_runtime": 8.2577, "test_samples_per_second": 248.011, "test_steps_per_second": 31.001}]}, "total": {"test_mcc": 59.65687109745066, "test_mcc_se": 1.2197664685902492, "test_macro_f1": 56.159081486500654, "test_macro_f1_se": 2.1316186858581205}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.9838711619377136, "test_mcc": 0.3595167770609236, "test_macro_f1": 0.5622390847204066, "test_runtime": 2.6156, "test_samples_per_second": 782.985, "test_steps_per_second": 24.468}, {"test_loss": 0.9663617014884949, "test_mcc": 0.343348959729004, "test_macro_f1": 0.5471697560573487, "test_runtime": 2.5935, "test_samples_per_second": 789.676, "test_steps_per_second": 24.677}, {"test_loss": 0.9977783560752869, "test_mcc": 0.30979559053432637, "test_macro_f1": 0.5299032287412682, "test_runtime": 2.7212, "test_samples_per_second": 752.597, "test_steps_per_second": 23.519}, {"test_loss": 0.9824957251548767, "test_mcc": 0.3004851113288645, "test_macro_f1": 0.5195642279707374, "test_runtime": 2.5649, "test_samples_per_second": 798.478, "test_steps_per_second": 24.952}, {"test_loss": 1.0539395809173584, "test_mcc": 0.34036010876539136, "test_macro_f1": 0.5565423904551766, "test_runtime": 2.5686, "test_samples_per_second": 797.316, "test_steps_per_second": 24.916}, {"test_loss": 1.0306789875030518, "test_mcc": 0.3011595209916354, "test_macro_f1": 0.5296008914029219, "test_runtime": 2.5862, "test_samples_per_second": 791.898, "test_steps_per_second": 24.747}, {"test_loss": 0.9414975643157959, "test_mcc": 0.3519890821246645, "test_macro_f1": 0.5632196521296672, "test_runtime": 2.5971, "test_samples_per_second": 788.559, "test_steps_per_second": 24.642}, {"test_loss": 1.0309324264526367, "test_mcc": 0.30087271006441824, "test_macro_f1": 0.5278834111041429, "test_runtime": 2.7113, "test_samples_per_second": 755.361, "test_steps_per_second": 23.605}, {"test_loss": 1.0448081493377686, "test_mcc": 0.32597299621878484, "test_macro_f1": 0.5455730513918594, "test_runtime": 2.5585, "test_samples_per_second": 800.484, "test_steps_per_second": 25.015}, {"test_loss": 0.9972730278968811, "test_mcc": 0.3194848980911307, "test_macro_f1": 0.5270450571746469, "test_runtime": 2.569, "test_samples_per_second": 797.186, "test_steps_per_second": 24.912}]}, "total": {"test_mcc": 32.52985754909143, "test_mcc_se": 1.3867845624931876, "test_macro_f1": 54.08740751148176, "test_macro_f1_se": 0.9961037501498571}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.8982025384902954, "test_mcc": 0.37491924023830936, "test_macro_f1": 0.5349948066913988, "test_runtime": 2.0765, "test_samples_per_second": 986.28, "test_steps_per_second": 30.821}, {"test_loss": 0.8822892308235168, "test_mcc": 0.37185930736842526, "test_macro_f1": 0.539739126546804, "test_runtime": 1.9743, "test_samples_per_second": 1037.342, "test_steps_per_second": 32.417}, {"test_loss": 0.8715181350708008, "test_mcc": 0.364394040502176, "test_macro_f1": 0.44820914087666514, "test_runtime": 1.9652, "test_samples_per_second": 1042.128, "test_steps_per_second": 32.566}, {"test_loss": 1.0396620035171509, "test_mcc": 0.3158465395458621, "test_macro_f1": 0.46800795128634737, "test_runtime": 2.0146, "test_samples_per_second": 1016.576, "test_steps_per_second": 31.768}, {"test_loss": 0.9111250638961792, "test_mcc": 0.3342272310784121, "test_macro_f1": 0.5007261076413889, "test_runtime": 2.016, "test_samples_per_second": 1015.87, "test_steps_per_second": 31.746}, {"test_loss": 0.907373309135437, "test_mcc": 0.28323958841517616, "test_macro_f1": 0.43288827398393304, "test_runtime": 2.0877, "test_samples_per_second": 980.988, "test_steps_per_second": 30.656}, {"test_loss": 0.9083325862884521, "test_mcc": 0.3546713693992086, "test_macro_f1": 0.44438774694852506, "test_runtime": 2.0005, "test_samples_per_second": 1023.751, "test_steps_per_second": 31.992}, {"test_loss": 0.8836734294891357, "test_mcc": 0.3252256018786519, "test_macro_f1": 0.4402258556968645, "test_runtime": 2.0374, "test_samples_per_second": 1005.198, "test_steps_per_second": 31.412}, {"test_loss": 0.8768707513809204, "test_mcc": 0.2839504789596304, "test_macro_f1": 0.41413751085744366, "test_runtime": 2.0931, "test_samples_per_second": 978.45, "test_steps_per_second": 30.577}, {"test_loss": 0.9222736954689026, "test_mcc": 0.3073969228575745, "test_macro_f1": 0.4693863845564385, "test_runtime": 2.0608, "test_samples_per_second": 993.793, "test_steps_per_second": 31.056}]}, "total": {"test_mcc": 33.15730320243427, "test_mcc_se": 2.1266778093046903, "test_macro_f1": 46.92702905085809, "test_macro_f1_se": 2.6575662252794103}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.07885599136352539, "test_micro_f1": 0.6410389610389611, "test_micro_f1_no_misc": 0.7014662756598241, "test_runtime": 4.8685, "test_samples_per_second": 420.663, "test_steps_per_second": 13.146}, {"test_loss": 0.06985616683959961, "test_micro_f1": 0.6454689984101749, "test_micro_f1_no_misc": 0.7071688942891858, "test_runtime": 4.5273, "test_samples_per_second": 452.372, "test_steps_per_second": 14.137}, {"test_loss": 0.06338716298341751, "test_micro_f1": 0.6536775450560156, "test_micro_f1_no_misc": 0.7120535714285714, "test_runtime": 4.5533, "test_samples_per_second": 449.783, "test_steps_per_second": 14.056}, {"test_loss": 0.06693544238805771, "test_micro_f1": 0.6509803921568627, "test_micro_f1_no_misc": 0.7019498607242339, "test_runtime": 4.6946, "test_samples_per_second": 436.244, "test_steps_per_second": 13.633}, {"test_loss": 0.06831099092960358, "test_micro_f1": 0.6571155682903534, "test_micro_f1_no_misc": 0.7086446104589115, "test_runtime": 4.9499, "test_samples_per_second": 413.748, "test_steps_per_second": 12.93}, {"test_loss": 0.06605657190084457, "test_micro_f1": 0.6669793621013134, "test_micro_f1_no_misc": 0.7214659685863876, "test_runtime": 4.417, "test_samples_per_second": 463.665, "test_steps_per_second": 14.49}, {"test_loss": 0.07426276803016663, "test_micro_f1": 0.6036644165863067, "test_micro_f1_no_misc": 0.6507276507276507, "test_runtime": 4.7459, "test_samples_per_second": 431.532, "test_steps_per_second": 13.485}, {"test_loss": 0.05904718488454819, "test_micro_f1": 0.6136606189967982, "test_micro_f1_no_misc": 0.6800486618004866, "test_runtime": 5.4518, "test_samples_per_second": 375.653, "test_steps_per_second": 11.739}, {"test_loss": 0.06351098418235779, "test_micro_f1": 0.6442307692307693, "test_micro_f1_no_misc": 0.6952743074416078, "test_runtime": 5.0872, "test_samples_per_second": 402.577, "test_steps_per_second": 12.581}, {"test_loss": 0.06304733455181122, "test_micro_f1": 0.6689791873141724, "test_micro_f1_no_misc": 0.729559748427673, "test_runtime": 5.3052, "test_samples_per_second": 386.036, "test_steps_per_second": 12.064}]}, "total": {"test_micro_f1": 64.45795819181728, "test_micro_f1_se": 1.3101682361918348, "test_micro_f1_no_misc": 70.08359549544532, "test_micro_f1_no_misc_se": 1.3786871579950861}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.07393626123666763, "test_micro_f1": 0.749219562955255, "test_micro_f1_no_misc": 0.7715072264280799, "test_runtime": 6.3387, "test_samples_per_second": 323.095, "test_steps_per_second": 10.097}, {"test_loss": 0.06793186813592911, "test_micro_f1": 0.7929292929292928, "test_micro_f1_no_misc": 0.8135593220338982, "test_runtime": 4.5632, "test_samples_per_second": 448.809, "test_steps_per_second": 14.025}, {"test_loss": 0.07151660323143005, "test_micro_f1": 0.7684126562084552, "test_micro_f1_no_misc": 0.7978221415607986, "test_runtime": 6.2141, "test_samples_per_second": 329.575, "test_steps_per_second": 10.299}, {"test_loss": 0.0747632086277008, "test_micro_f1": 0.7740458015267175, "test_micro_f1_no_misc": 0.7966862271315153, "test_runtime": 6.0381, "test_samples_per_second": 339.182, "test_steps_per_second": 10.599}, {"test_loss": 0.07463732361793518, "test_micro_f1": 0.7554683118339877, "test_micro_f1_no_misc": 0.7859569648924122, "test_runtime": 5.5713, "test_samples_per_second": 367.596, "test_steps_per_second": 11.487}, {"test_loss": 0.0776684507727623, "test_micro_f1": 0.7754070746771478, "test_micro_f1_no_misc": 0.7867867867867867, "test_runtime": 5.6473, "test_samples_per_second": 362.65, "test_steps_per_second": 11.333}, {"test_loss": 0.07411935180425644, "test_micro_f1": 0.7859649122807018, "test_micro_f1_no_misc": 0.8020050125313284, "test_runtime": 5.7186, "test_samples_per_second": 358.132, "test_steps_per_second": 11.192}, {"test_loss": 0.06837767362594604, "test_micro_f1": 0.7767313019390583, "test_micro_f1_no_misc": 0.8040313549832027, "test_runtime": 6.0918, "test_samples_per_second": 336.19, "test_steps_per_second": 10.506}, {"test_loss": 0.07468175888061523, "test_micro_f1": 0.7752599306851508, "test_micro_f1_no_misc": 0.7831547838936093, "test_runtime": 5.7734, "test_samples_per_second": 354.727, "test_steps_per_second": 11.085}, {"test_loss": 0.07330668717622757, "test_micro_f1": 0.7793047696038804, "test_micro_f1_no_misc": 0.805393586005831, "test_runtime": 5.0953, "test_samples_per_second": 401.939, "test_steps_per_second": 12.561}]}, "total": {"test_micro_f1": 77.32743614639647, "test_micro_f1_se": 0.8065673617351604, "test_micro_f1_no_misc": 79.46903406247462, "test_micro_f1_no_misc_se": 0.7824774809036766}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.052519433200359344, "test_micro_f1": 0.7875271936185642, "test_micro_f1_no_misc": 0.830997526793075, "test_runtime": 4.5662, "test_samples_per_second": 448.517, "test_steps_per_second": 14.016}, {"test_loss": 0.04136752337217331, "test_micro_f1": 0.7985185185185184, "test_micro_f1_no_misc": 0.825487012987013, "test_runtime": 4.8929, "test_samples_per_second": 418.562, "test_steps_per_second": 13.08}, {"test_loss": 0.047523535788059235, "test_micro_f1": 0.8054968287526427, "test_micro_f1_no_misc": 0.8392647633946031, "test_runtime": 4.5008, "test_samples_per_second": 455.035, "test_steps_per_second": 14.22}, {"test_loss": 0.04423651844263077, "test_micro_f1": 0.8007079646017699, "test_micro_f1_no_misc": 0.8312822548630409, "test_runtime": 4.3868, "test_samples_per_second": 466.854, "test_steps_per_second": 14.589}, {"test_loss": 0.04567839205265045, "test_micro_f1": 0.8078327248589446, "test_micro_f1_no_misc": 0.8378978534418949, "test_runtime": 4.7166, "test_samples_per_second": 434.208, "test_steps_per_second": 13.569}, {"test_loss": 0.04074645787477493, "test_micro_f1": 0.822282980177717, "test_micro_f1_no_misc": 0.8468606431852985, "test_runtime": 4.5856, "test_samples_per_second": 446.612, "test_steps_per_second": 13.957}, {"test_loss": 0.044549841433763504, "test_micro_f1": 0.7810368349249659, "test_micro_f1_no_misc": 0.8122402720060447, "test_runtime": 4.2248, "test_samples_per_second": 484.757, "test_steps_per_second": 15.149}, {"test_loss": 0.04412980377674103, "test_micro_f1": 0.8324625566004875, "test_micro_f1_no_misc": 0.8562806488117692, "test_runtime": 3.9658, "test_samples_per_second": 516.42, "test_steps_per_second": 16.138}, {"test_loss": 0.0411466509103775, "test_micro_f1": 0.8233608025797204, "test_micro_f1_no_misc": 0.8433734939759036, "test_runtime": 4.0626, "test_samples_per_second": 504.115, "test_steps_per_second": 15.754}, {"test_loss": 0.04979686439037323, "test_micro_f1": 0.8013513513513515, "test_micro_f1_no_misc": 0.8382739212007506, "test_runtime": 4.2113, "test_samples_per_second": 486.315, "test_steps_per_second": 15.197}]}, "total": {"test_micro_f1": 80.60577755984681, "test_micro_f1_se": 0.9994870090661249, "test_micro_f1_no_misc": 83.61958390659395, "test_micro_f1_no_misc_se": 0.7520442337506542}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.05850654095411301, "test_micro_f1": 0.7625766871165643, "test_micro_f1_no_misc": 0.8033783783783783, "test_runtime": 3.9376, "test_samples_per_second": 520.111, "test_steps_per_second": 16.253}, {"test_loss": 0.058066897094249725, "test_micro_f1": 0.7902735562310029, "test_micro_f1_no_misc": 0.825706594885599, "test_runtime": 4.0573, "test_samples_per_second": 504.763, "test_steps_per_second": 15.774}, {"test_loss": 0.06137606501579285, "test_micro_f1": 0.7662416514875531, "test_micro_f1_no_misc": 0.8079514824797844, "test_runtime": 4.1097, "test_samples_per_second": 498.336, "test_steps_per_second": 15.573}, {"test_loss": 0.06929385662078857, "test_micro_f1": 0.7493917274939172, "test_micro_f1_no_misc": 0.7885135135135136, "test_runtime": 4.5056, "test_samples_per_second": 454.541, "test_steps_per_second": 14.204}, {"test_loss": 0.07289566844701767, "test_micro_f1": 0.7581779272393763, "test_micro_f1_no_misc": 0.8023496890117484, "test_runtime": 4.3123, "test_samples_per_second": 474.925, "test_steps_per_second": 14.841}, {"test_loss": 0.0637834370136261, "test_micro_f1": 0.7567730282962072, "test_micro_f1_no_misc": 0.7986688851913477, "test_runtime": 4.3958, "test_samples_per_second": 465.895, "test_steps_per_second": 14.559}, {"test_loss": 0.05734827369451523, "test_micro_f1": 0.7618751940391183, "test_micro_f1_no_misc": 0.8093781855249745, "test_runtime": 4.6145, "test_samples_per_second": 443.819, "test_steps_per_second": 13.869}, {"test_loss": 0.059141840785741806, "test_micro_f1": 0.7691837358605931, "test_micro_f1_no_misc": 0.8056775937816829, "test_runtime": 4.6307, "test_samples_per_second": 442.263, "test_steps_per_second": 13.821}, {"test_loss": 0.06570740789175034, "test_micro_f1": 0.7593846153846154, "test_micro_f1_no_misc": 0.803061934585943, "test_runtime": 4.1637, "test_samples_per_second": 491.872, "test_steps_per_second": 15.371}, {"test_loss": 0.060040757060050964, "test_micro_f1": 0.7871287128712872, "test_micro_f1_no_misc": 0.8240053944706676, "test_runtime": 4.2759, "test_samples_per_second": 478.961, "test_steps_per_second": 14.968}]}, "total": {"test_micro_f1": 76.61006836020235, "test_micro_f1_se": 0.8108638392297751, "test_micro_f1_no_misc": 80.6869165182364, "test_micro_f1_no_misc_se": 0.687915745189592}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6397984027862549, "test_mcc": 0.34625402773358116, "test_macro_f1": 0.6478706203152655, "test_runtime": 2.0443, "test_samples_per_second": 1001.797, "test_steps_per_second": 31.306}, {"test_loss": 0.6241397857666016, "test_mcc": 0.33430435545311554, "test_macro_f1": 0.6549317323520867, "test_runtime": 2.3156, "test_samples_per_second": 884.428, "test_steps_per_second": 27.638}, {"test_loss": 0.6355386972427368, "test_mcc": 0.34092366748583164, "test_macro_f1": 0.6438268030624719, "test_runtime": 2.1101, "test_samples_per_second": 970.557, "test_steps_per_second": 30.33}, {"test_loss": 0.6074278354644775, "test_mcc": 0.31863520170730764, "test_macro_f1": 0.6588049559062026, "test_runtime": 2.0844, "test_samples_per_second": 982.543, "test_steps_per_second": 30.704}, {"test_loss": 0.6229304075241089, "test_mcc": 0.33568267945218033, "test_macro_f1": 0.6488788497531499, "test_runtime": 2.0972, "test_samples_per_second": 976.557, "test_steps_per_second": 30.517}, {"test_loss": 0.621982216835022, "test_mcc": 0.32191276294034415, "test_macro_f1": 0.6518591279672303, "test_runtime": 2.0873, "test_samples_per_second": 981.161, "test_steps_per_second": 30.661}, {"test_loss": 0.6242602467536926, "test_mcc": 0.3181104261831187, "test_macro_f1": 0.6351635163516353, "test_runtime": 2.1284, "test_samples_per_second": 962.239, "test_steps_per_second": 30.07}, {"test_loss": 0.615681529045105, "test_mcc": 0.38062575799118636, "test_macro_f1": 0.6853462150862527, "test_runtime": 2.0962, "test_samples_per_second": 977.018, "test_steps_per_second": 30.532}, {"test_loss": 0.6200005412101746, "test_mcc": 0.34050344613796396, "test_macro_f1": 0.6624096562271031, "test_runtime": 2.0637, "test_samples_per_second": 992.401, "test_steps_per_second": 31.013}, {"test_loss": 0.6243327856063843, "test_mcc": 0.3345173126611063, "test_macro_f1": 0.6431476203836328, "test_runtime": 2.073, "test_samples_per_second": 987.927, "test_steps_per_second": 30.873}]}, "total": {"test_mcc": 33.71469637745735, "test_mcc_se": 1.1227394500093146, "test_macro_f1": 65.32239097405031, "test_macro_f1_se": 0.8557669370918014}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6510433554649353, "test_mcc": 0.34796893863868655, "test_macro_f1": 0.6516441876305188, "test_runtime": 2.2376, "test_samples_per_second": 915.275, "test_steps_per_second": 28.602}, {"test_loss": 0.6293392181396484, "test_mcc": 0.38035655104548804, "test_macro_f1": 0.6888146041806855, "test_runtime": 2.3291, "test_samples_per_second": 879.328, "test_steps_per_second": 27.479}, {"test_loss": 0.607771098613739, "test_mcc": 0.3959640872495507, "test_macro_f1": 0.6979653785025988, "test_runtime": 2.2946, "test_samples_per_second": 892.516, "test_steps_per_second": 27.891}, {"test_loss": 0.6420491337776184, "test_mcc": 0.29130126882714685, "test_macro_f1": 0.6169006665329809, "test_runtime": 2.3855, "test_samples_per_second": 858.528, "test_steps_per_second": 26.829}, {"test_loss": 0.604354739189148, "test_mcc": 0.3465985672793435, "test_macro_f1": 0.6709334282229814, "test_runtime": 2.2706, "test_samples_per_second": 901.977, "test_steps_per_second": 28.187}, {"test_loss": 0.5954408645629883, "test_mcc": 0.3888926284877169, "test_macro_f1": 0.6898243819037297, "test_runtime": 2.2466, "test_samples_per_second": 911.616, "test_steps_per_second": 28.488}, {"test_loss": 0.6216642260551453, "test_mcc": 0.3303208736677263, "test_macro_f1": 0.6573907425354193, "test_runtime": 2.4116, "test_samples_per_second": 849.226, "test_steps_per_second": 26.538}, {"test_loss": 0.5958128571510315, "test_mcc": 0.4080132980857589, "test_macro_f1": 0.7038123167155426, "test_runtime": 2.5827, "test_samples_per_second": 792.977, "test_steps_per_second": 24.781}, {"test_loss": 0.6439557075500488, "test_mcc": 0.2934525544640833, "test_macro_f1": 0.6246378936606127, "test_runtime": 2.2134, "test_samples_per_second": 925.269, "test_steps_per_second": 28.915}, {"test_loss": 0.6183584332466125, "test_mcc": 0.37005888106145635, "test_macro_f1": 0.6843171221730686, "test_runtime": 2.5262, "test_samples_per_second": 810.697, "test_steps_per_second": 25.334}]}, "total": {"test_mcc": 35.52927648806958, "test_mcc_se": 2.5371499533297546, "test_macro_f1": 66.86240722058139, "test_macro_f1_se": 1.8745588685757784}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6284542083740234, "test_mcc": 0.3097156127174965, "test_macro_f1": 0.6331266152574733, "test_runtime": 2.3174, "test_samples_per_second": 883.754, "test_steps_per_second": 27.617}, {"test_loss": 0.6001599431037903, "test_mcc": 0.4344083286946078, "test_macro_f1": 0.7060497223108735, "test_runtime": 2.2201, "test_samples_per_second": 922.461, "test_steps_per_second": 28.827}, {"test_loss": 0.6199645400047302, "test_mcc": 0.3230129474313385, "test_macro_f1": 0.6503741319945371, "test_runtime": 2.3557, "test_samples_per_second": 869.393, "test_steps_per_second": 27.169}, {"test_loss": 0.614707887172699, "test_mcc": 0.3457472999086388, "test_macro_f1": 0.6666678722950221, "test_runtime": 2.3088, "test_samples_per_second": 887.022, "test_steps_per_second": 27.719}, {"test_loss": 0.6223750114440918, "test_mcc": 0.3533915534722432, "test_macro_f1": 0.6404746315909229, "test_runtime": 2.2647, "test_samples_per_second": 904.333, "test_steps_per_second": 28.26}, {"test_loss": 0.5853977203369141, "test_mcc": 0.3914165637746474, "test_macro_f1": 0.678301090367299, "test_runtime": 2.2916, "test_samples_per_second": 893.683, "test_steps_per_second": 27.928}, {"test_loss": 0.5919941067695618, "test_mcc": 0.3866012946448179, "test_macro_f1": 0.6900612302494611, "test_runtime": 1.9714, "test_samples_per_second": 1038.874, "test_steps_per_second": 32.465}, {"test_loss": 0.6506462097167969, "test_mcc": 0.3929863214221167, "test_macro_f1": 0.6829086731236769, "test_runtime": 2.2287, "test_samples_per_second": 918.912, "test_steps_per_second": 28.716}, {"test_loss": 0.6116677522659302, "test_mcc": 0.351826437775955, "test_macro_f1": 0.6570146204216978, "test_runtime": 2.2313, "test_samples_per_second": 917.854, "test_steps_per_second": 28.683}, {"test_loss": 0.6342633962631226, "test_mcc": 0.32043071105425397, "test_macro_f1": 0.606044414046637, "test_runtime": 2.2411, "test_samples_per_second": 913.836, "test_steps_per_second": 28.557}]}, "total": {"test_mcc": 36.095370708961156, "test_mcc_se": 2.4520583547884147, "test_macro_f1": 66.11023001657601, "test_macro_f1_se": 1.8516549530406303}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6250221729278564, "test_mcc": 0.31304626318014406, "test_macro_f1": 0.656131614220365, "test_runtime": 2.098, "test_samples_per_second": 976.175, "test_steps_per_second": 30.505}, {"test_loss": 0.6430286169052124, "test_mcc": 0.240842834923322, "test_macro_f1": 0.603892142910278, "test_runtime": 2.1604, "test_samples_per_second": 947.975, "test_steps_per_second": 29.624}, {"test_loss": 0.6394037008285522, "test_mcc": 0.2749735847212609, "test_macro_f1": 0.616773157636552, "test_runtime": 2.1424, "test_samples_per_second": 955.941, "test_steps_per_second": 29.873}, {"test_loss": 0.6376358270645142, "test_mcc": 0.30434543767778033, "test_macro_f1": 0.6517339184454539, "test_runtime": 2.3072, "test_samples_per_second": 887.639, "test_steps_per_second": 27.739}, {"test_loss": 0.6060951352119446, "test_mcc": 0.34270992273014694, "test_macro_f1": 0.6701053069607298, "test_runtime": 2.075, "test_samples_per_second": 986.967, "test_steps_per_second": 30.843}, {"test_loss": 0.6344801783561707, "test_mcc": 0.28886769784497035, "test_macro_f1": 0.6360791276434685, "test_runtime": 2.4116, "test_samples_per_second": 849.234, "test_steps_per_second": 26.539}, {"test_loss": 0.6564102172851562, "test_mcc": 0.23609796177057135, "test_macro_f1": 0.5993473744341369, "test_runtime": 2.3795, "test_samples_per_second": 860.686, "test_steps_per_second": 26.896}, {"test_loss": 0.6123982667922974, "test_mcc": 0.3219374715426047, "test_macro_f1": 0.6597609954475896, "test_runtime": 2.231, "test_samples_per_second": 917.974, "test_steps_per_second": 28.687}, {"test_loss": 0.6123068928718567, "test_mcc": 0.34660990827026067, "test_macro_f1": 0.672726717650471, "test_runtime": 2.3486, "test_samples_per_second": 872.008, "test_steps_per_second": 27.25}, {"test_loss": 0.6130435466766357, "test_mcc": 0.34054837241240565, "test_macro_f1": 0.6627817214830398, "test_runtime": 2.0893, "test_samples_per_second": 980.235, "test_steps_per_second": 30.632}]}, "total": {"test_mcc": 30.09979455073467, "test_mcc_se": 2.4993277856020204, "test_macro_f1": 64.29332076832084, "test_macro_f1_se": 1.6923755830562877}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_em": 40.975987606506585, "test_f1": 44.626876896218235}, {"test_em": 40.23255813953488, "test_f1": 43.399670407032346}, {"test_em": 39.799072642967545, "test_f1": 43.27100653809782}, {"test_em": 34.73520249221184, "test_f1": 38.843591538590985}, {"test_em": 42.77992277992278, "test_f1": 46.82334618071016}, {"test_em": 39.86121819583654, "test_f1": 43.20443593258209}, {"test_em": 41.60971905846621, "test_f1": 44.746355100188396}, {"test_em": 35.06594259115594, "test_f1": 38.95230959587135}, {"test_em": 36.3921568627451, "test_f1": 40.53838104063929}, {"test_em": 43.16770186335404, "test_f1": 46.200876213663655}]}, "total": {"test_em": 39.46194822327014, "test_em_se": 1.8890748792909087, "test_f1": 43.06068494435944, "test_f1_se": 1.7349329629967853}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_em": 36.71572424477149, "test_f1": 41.77447059293996}, {"test_em": 35.50387596899225, "test_f1": 40.14432207468304}, {"test_em": 39.56723338485317, "test_f1": 43.3817953778954}, {"test_em": 37.69470404984423, "test_f1": 41.915088053600414}, {"test_em": 40.30888030888031, "test_f1": 44.67495754159984}, {"test_em": 33.8473400154202, "test_f1": 37.66139698746142}, {"test_em": 35.07972665148064, "test_f1": 39.446637695654495}, {"test_em": 36.69511249030256, "test_f1": 41.24988438182722}, {"test_em": 33.88235294117647, "test_f1": 38.61955974491145}, {"test_em": 35.869565217391305, "test_f1": 40.91784117956496}]}, "total": {"test_em": 36.51645152731126, "test_em_se": 1.3503670712468785, "test_f1": 40.97859536301382, "test_f1_se": 1.3170452783074502}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_em": 39.349341595662274, "test_f1": 44.27544949193394}, {"test_em": 41.627906976744185, "test_f1": 46.768534532752845}, {"test_em": 41.9629057187017, "test_f1": 46.243146443835585}, {"test_em": 40.42056074766355, "test_f1": 45.132915624661955}, {"test_em": 38.84169884169884, "test_f1": 43.671586194556006}, {"test_em": 37.471087124132616, "test_f1": 41.54179682043565}, {"test_em": 37.73728170083523, "test_f1": 42.761882626096785}, {"test_em": 38.40186190845617, "test_f1": 43.025416632078674}, {"test_em": 37.254901960784316, "test_f1": 41.87621788961059}, {"test_em": 40.21739130434783, "test_f1": 44.907661829991866}]}, "total": {"test_em": 39.32849378790267, "test_em_se": 1.045086780160845, "test_f1": 44.02046080859539, "test_f1_se": 1.0936132505985154}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.598442018032074, "test_mcc": 0.6088070136604348, "test_macro_f1": 0.5757139649152626, "test_runtime": 9.0252, "test_samples_per_second": 226.92, "test_steps_per_second": 28.365}, {"test_loss": 0.6204009056091309, "test_mcc": 0.602559146819661, "test_macro_f1": 0.5463682338345556, "test_runtime": 8.686, "test_samples_per_second": 235.781, "test_steps_per_second": 29.473}, {"test_loss": 0.6285107731819153, "test_mcc": 0.6036086959718202, "test_macro_f1": 0.6011147140712004, "test_runtime": 9.7489, "test_samples_per_second": 210.075, "test_steps_per_second": 26.259}, {"test_loss": 0.5868617296218872, "test_mcc": 0.5945051962743827, "test_macro_f1": 0.5756052407857548, "test_runtime": 9.397, "test_samples_per_second": 217.941, "test_steps_per_second": 27.243}, {"test_loss": 0.6240123510360718, "test_mcc": 0.6041994659924541, "test_macro_f1": 0.5470880022758215, "test_runtime": 9.344, "test_samples_per_second": 219.179, "test_steps_per_second": 27.397}, {"test_loss": 0.6426491737365723, "test_mcc": 0.6020728786243681, "test_macro_f1": 0.5466210822970308, "test_runtime": 9.347, "test_samples_per_second": 219.109, "test_steps_per_second": 27.389}, {"test_loss": 0.5777442455291748, "test_mcc": 0.6166585243654539, "test_macro_f1": 0.5502919532586935, "test_runtime": 9.2277, "test_samples_per_second": 221.941, "test_steps_per_second": 27.743}, {"test_loss": 0.5808594226837158, "test_mcc": 0.6172161077376481, "test_macro_f1": 0.5951311897907586, "test_runtime": 9.7921, "test_samples_per_second": 209.149, "test_steps_per_second": 26.144}, {"test_loss": 0.6049253344535828, "test_mcc": 0.604210435709888, "test_macro_f1": 0.5473840360586523, "test_runtime": 9.8593, "test_samples_per_second": 207.724, "test_steps_per_second": 25.965}, {"test_loss": 0.5827426910400391, "test_mcc": 0.6152496789419176, "test_macro_f1": 0.5840553845821602, "test_runtime": 9.4586, "test_samples_per_second": 216.523, "test_steps_per_second": 27.065}]}, "total": {"test_mcc": 60.69087144098029, "test_mcc_se": 0.460189071808621, "test_macro_f1": 56.6937380186989, "test_macro_f1_se": 1.354372830554928}}, "num_model_parameters": 108783363, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.959845244884491, "test_mcc": 0.2986257137278529, "test_macro_f1": 0.5244768033595577, "test_runtime": 2.8403, "test_samples_per_second": 721.048, "test_steps_per_second": 22.533}, {"test_loss": 0.9536122679710388, "test_mcc": 0.37513434611912877, "test_macro_f1": 0.5769370207794897, "test_runtime": 2.9054, "test_samples_per_second": 704.888, "test_steps_per_second": 22.028}, {"test_loss": 0.9784979820251465, "test_mcc": 0.31807093786744933, "test_macro_f1": 0.5378339758774985, "test_runtime": 2.8596, "test_samples_per_second": 716.189, "test_steps_per_second": 22.381}, {"test_loss": 0.9898152351379395, "test_mcc": 0.3236358044510942, "test_macro_f1": 0.5327881211924435, "test_runtime": 2.6257, "test_samples_per_second": 779.975, "test_steps_per_second": 24.374}, {"test_loss": 0.9780664443969727, "test_mcc": 0.31660287409087035, "test_macro_f1": 0.5373735568217263, "test_runtime": 2.7898, "test_samples_per_second": 734.111, "test_steps_per_second": 22.941}, {"test_loss": 0.9792948961257935, "test_mcc": 0.28707297371740287, "test_macro_f1": 0.5187007709000282, "test_runtime": 2.7222, "test_samples_per_second": 752.339, "test_steps_per_second": 23.511}, {"test_loss": 0.9388538599014282, "test_mcc": 0.33984234373199873, "test_macro_f1": 0.555167513977567, "test_runtime": 2.6686, "test_samples_per_second": 767.446, "test_steps_per_second": 23.983}, {"test_loss": 1.0198261737823486, "test_mcc": 0.2852495726671004, "test_macro_f1": 0.4730305284655159, "test_runtime": 2.6575, "test_samples_per_second": 770.66, "test_steps_per_second": 24.083}, {"test_loss": 1.0003201961517334, "test_mcc": 0.3086668960526721, "test_macro_f1": 0.5320750396646051, "test_runtime": 2.5921, "test_samples_per_second": 790.106, "test_steps_per_second": 24.691}, {"test_loss": 0.9752911329269409, "test_mcc": 0.32841147153311717, "test_macro_f1": 0.5369005619165635, "test_runtime": 2.5761, "test_samples_per_second": 795.001, "test_steps_per_second": 24.844}]}, "total": {"test_mcc": 31.813129339586872, "test_mcc_se": 1.6495739520391912, "test_macro_f1": 53.25283892954995, "test_macro_f1_se": 1.6465680956255513}}, "num_model_parameters": 108783363, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.8822238445281982, "test_mcc": 0.32880383346473513, "test_macro_f1": 0.43169404185946986, "test_runtime": 2.09, "test_samples_per_second": 979.883, "test_steps_per_second": 30.621}, {"test_loss": 0.8665752410888672, "test_mcc": 0.352142077620696, "test_macro_f1": 0.4511431407922089, "test_runtime": 1.9735, "test_samples_per_second": 1037.734, "test_steps_per_second": 32.429}, {"test_loss": 0.8869636058807373, "test_mcc": 0.3608749882282718, "test_macro_f1": 0.5201019467837672, "test_runtime": 2.0239, "test_samples_per_second": 1011.908, "test_steps_per_second": 31.622}, {"test_loss": 1.0045194625854492, "test_mcc": 0.35299079628460844, "test_macro_f1": 0.510127463485845, "test_runtime": 2.0362, "test_samples_per_second": 1005.774, "test_steps_per_second": 31.43}, {"test_loss": 0.9731020331382751, "test_mcc": 0.31791520403437934, "test_macro_f1": 0.47636004021727435, "test_runtime": 2.0391, "test_samples_per_second": 1004.366, "test_steps_per_second": 31.386}, {"test_loss": 0.9059712290763855, "test_mcc": 0.3120019586621947, "test_macro_f1": 0.42453607010617356, "test_runtime": 2.0855, "test_samples_per_second": 982.009, "test_steps_per_second": 30.688}, {"test_loss": 0.8781998157501221, "test_mcc": 0.3797065322797178, "test_macro_f1": 0.5282362742331019, "test_runtime": 1.9973, "test_samples_per_second": 1025.384, "test_steps_per_second": 32.043}, {"test_loss": 0.9737206697463989, "test_mcc": 0.29632683895458595, "test_macro_f1": 0.4690483304666227, "test_runtime": 2.0581, "test_samples_per_second": 995.075, "test_steps_per_second": 31.096}, {"test_loss": 0.8642306327819824, "test_mcc": 0.32106573847933295, "test_macro_f1": 0.4307216168617159, "test_runtime": 2.1037, "test_samples_per_second": 973.529, "test_steps_per_second": 30.423}, {"test_loss": 0.8907140493392944, "test_mcc": 0.2972828749671892, "test_macro_f1": 0.42068825664952064, "test_runtime": 2.1064, "test_samples_per_second": 972.253, "test_steps_per_second": 30.383}]}, "total": {"test_mcc": 33.191108429757115, "test_mcc_se": 1.7484261764602265, "test_macro_f1": 46.626571814556996, "test_macro_f1_se": 2.553699830963399}}, "num_model_parameters": 108783363, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.07408320903778076, "test_micro_f1": 0.6041351487644983, "test_micro_f1_no_misc": 0.674026728646136, "test_runtime": 4.8764, "test_samples_per_second": 419.981, "test_steps_per_second": 13.124}, {"test_loss": 0.07065445184707642, "test_micro_f1": 0.6493918561607616, "test_micro_f1_no_misc": 0.7197568389057751, "test_runtime": 4.5683, "test_samples_per_second": 448.309, "test_steps_per_second": 14.01}, {"test_loss": 0.0657033771276474, "test_micro_f1": 0.6464167062173706, "test_micro_f1_no_misc": 0.6989473684210527, "test_runtime": 4.5292, "test_samples_per_second": 452.172, "test_steps_per_second": 14.13}, {"test_loss": 0.06402184814214706, "test_micro_f1": 0.6289614822038031, "test_micro_f1_no_misc": 0.6879739978331527, "test_runtime": 4.8773, "test_samples_per_second": 419.901, "test_steps_per_second": 13.122}, {"test_loss": 0.07036963850259781, "test_micro_f1": 0.651949271958666, "test_micro_f1_no_misc": 0.7223113964686998, "test_runtime": 4.8062, "test_samples_per_second": 426.119, "test_steps_per_second": 13.316}, {"test_loss": 0.06529048085212708, "test_micro_f1": 0.6770685579196218, "test_micro_f1_no_misc": 0.721102863202545, "test_runtime": 4.1297, "test_samples_per_second": 495.922, "test_steps_per_second": 15.498}, {"test_loss": 0.07414191961288452, "test_micro_f1": 0.6175024582104228, "test_micro_f1_no_misc": 0.6806862202545655, "test_runtime": 4.5418, "test_samples_per_second": 450.918, "test_steps_per_second": 14.091}, {"test_loss": 0.06095121428370476, "test_micro_f1": 0.6627597229621737, "test_micro_f1_no_misc": 0.7321089297023432, "test_runtime": 4.7869, "test_samples_per_second": 427.833, "test_steps_per_second": 13.37}, {"test_loss": 0.06492196768522263, "test_micro_f1": 0.6405228758169934, "test_micro_f1_no_misc": 0.6881266490765171, "test_runtime": 4.6084, "test_samples_per_second": 444.405, "test_steps_per_second": 13.888}, {"test_loss": 0.06963204592466354, "test_micro_f1": 0.6703187250996016, "test_micro_f1_no_misc": 0.7311347121296813, "test_runtime": 4.8024, "test_samples_per_second": 426.453, "test_steps_per_second": 13.327}]}, "total": {"test_micro_f1": 64.49026805313913, "test_micro_f1_se": 1.4250547491605121, "test_micro_f1_no_misc": 70.5617570464047, "test_micro_f1_no_misc_se": 1.3630397922011948}}, "num_model_parameters": 108197385, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.07348716259002686, "test_micro_f1": 0.766948068559734, "test_micro_f1_no_misc": 0.7883760683760683, "test_runtime": 5.5155, "test_samples_per_second": 371.32, "test_steps_per_second": 11.604}, {"test_loss": 0.06931736320257187, "test_micro_f1": 0.7740854509913432, "test_micro_f1_no_misc": 0.7927140255009106, "test_runtime": 4.3278, "test_samples_per_second": 473.219, "test_steps_per_second": 14.788}, {"test_loss": 0.07162250578403473, "test_micro_f1": 0.7732123799359659, "test_micro_f1_no_misc": 0.8057971014492755, "test_runtime": 5.5476, "test_samples_per_second": 369.17, "test_steps_per_second": 11.537}, {"test_loss": 0.07169213145971298, "test_micro_f1": 0.7830797007995872, "test_micro_f1_no_misc": 0.7947748367136472, "test_runtime": 5.262, "test_samples_per_second": 389.209, "test_steps_per_second": 12.163}, {"test_loss": 0.07547540962696075, "test_micro_f1": 0.7522573363431151, "test_micro_f1_no_misc": 0.7846674182638106, "test_runtime": 5.4876, "test_samples_per_second": 373.207, "test_steps_per_second": 11.663}, {"test_loss": 0.08064734935760498, "test_micro_f1": 0.7725590663250783, "test_micro_f1_no_misc": 0.7851739788199698, "test_runtime": 5.3594, "test_samples_per_second": 382.133, "test_steps_per_second": 11.942}, {"test_loss": 0.07635776698589325, "test_micro_f1": 0.7814533622559653, "test_micro_f1_no_misc": 0.7956834532374101, "test_runtime": 5.5207, "test_samples_per_second": 370.969, "test_steps_per_second": 11.593}, {"test_loss": 0.06517384946346283, "test_micro_f1": 0.7902251510159253, "test_micro_f1_no_misc": 0.814317673378076, "test_runtime": 5.4431, "test_samples_per_second": 376.258, "test_steps_per_second": 11.758}, {"test_loss": 0.07406941056251526, "test_micro_f1": 0.7744301807702385, "test_micro_f1_no_misc": 0.7953130721347492, "test_runtime": 5.3029, "test_samples_per_second": 386.206, "test_steps_per_second": 12.069}, {"test_loss": 0.07571187615394592, "test_micro_f1": 0.7878951634693326, "test_micro_f1_no_misc": 0.8100719424460432, "test_runtime": 4.5734, "test_samples_per_second": 447.81, "test_steps_per_second": 13.994}]}, "total": {"test_micro_f1": 77.56145860466286, "test_micro_f1_se": 0.6832311045229497, "test_micro_f1_no_misc": 79.66889570319961, "test_micro_f1_no_misc_se": 0.6339079254527006}}, "num_model_parameters": 108197385, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.05214144289493561, "test_micro_f1": 0.7858942065491185, "test_micro_f1_no_misc": 0.8225806451612903, "test_runtime": 4.1552, "test_samples_per_second": 492.872, "test_steps_per_second": 15.402}, {"test_loss": 0.04178233444690704, "test_micro_f1": 0.7964272422776331, "test_micro_f1_no_misc": 0.8261049153242461, "test_runtime": 4.1655, "test_samples_per_second": 491.661, "test_steps_per_second": 15.364}, {"test_loss": 0.050236254930496216, "test_micro_f1": 0.8045658941542718, "test_micro_f1_no_misc": 0.832183908045977, "test_runtime": 3.9832, "test_samples_per_second": 514.161, "test_steps_per_second": 16.068}, {"test_loss": 0.042933933436870575, "test_micro_f1": 0.8059914407988588, "test_micro_f1_no_misc": 0.8294234592445328, "test_runtime": 4.312, "test_samples_per_second": 474.953, "test_steps_per_second": 14.842}, {"test_loss": 0.044343020766973495, "test_micro_f1": 0.8286290322580646, "test_micro_f1_no_misc": 0.8560775540641312, "test_runtime": 4.2827, "test_samples_per_second": 478.199, "test_steps_per_second": 14.944}, {"test_loss": 0.04062633216381073, "test_micro_f1": 0.8554794520547945, "test_micro_f1_no_misc": 0.8808885484488701, "test_runtime": 4.7631, "test_samples_per_second": 429.97, "test_steps_per_second": 13.437}, {"test_loss": 0.04610362648963928, "test_micro_f1": 0.764705882352941, "test_micro_f1_no_misc": 0.7988165680473372, "test_runtime": 4.2986, "test_samples_per_second": 476.434, "test_steps_per_second": 14.889}, {"test_loss": 0.042720869183540344, "test_micro_f1": 0.8139214334941419, "test_micro_f1_no_misc": 0.846211552888222, "test_runtime": 4.3512, "test_samples_per_second": 470.679, "test_steps_per_second": 14.709}, {"test_loss": 0.04230647161602974, "test_micro_f1": 0.8094555873925501, "test_micro_f1_no_misc": 0.8387869114126097, "test_runtime": 4.4411, "test_samples_per_second": 461.146, "test_steps_per_second": 14.411}, {"test_loss": 0.05537272244691849, "test_micro_f1": 0.789859906604403, "test_micro_f1_no_misc": 0.8284023668639054, "test_runtime": 4.9337, "test_samples_per_second": 415.104, "test_steps_per_second": 12.972}]}, "total": {"test_micro_f1": 80.54930077936777, "test_micro_f1_se": 1.5316526257102112, "test_micro_f1_no_misc": 83.59476429501122, "test_micro_f1_no_misc_se": 1.3557638140469632}}, "num_model_parameters": 108197385, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.06006384268403053, "test_micro_f1": 0.7565379825653799, "test_micro_f1_no_misc": 0.8009494743981012, "test_runtime": 4.4457, "test_samples_per_second": 460.668, "test_steps_per_second": 14.396}, {"test_loss": 0.05860161781311035, "test_micro_f1": 0.773423147581139, "test_micro_f1_no_misc": 0.8055367994598245, "test_runtime": 4.1363, "test_samples_per_second": 495.123, "test_steps_per_second": 15.473}, {"test_loss": 0.06657804548740387, "test_micro_f1": 0.7350735073507352, "test_micro_f1_no_misc": 0.777124183006536, "test_runtime": 4.4317, "test_samples_per_second": 462.126, "test_steps_per_second": 14.441}, {"test_loss": 0.07314489781856537, "test_micro_f1": 0.7590719809637121, "test_micro_f1_no_misc": 0.8013289036544852, "test_runtime": 4.4963, "test_samples_per_second": 455.481, "test_steps_per_second": 14.234}, {"test_loss": 0.07314793765544891, "test_micro_f1": 0.7412333736396615, "test_micro_f1_no_misc": 0.7840054682159946, "test_runtime": 4.4371, "test_samples_per_second": 461.564, "test_steps_per_second": 14.424}, {"test_loss": 0.06693875789642334, "test_micro_f1": 0.7575666766556787, "test_micro_f1_no_misc": 0.8038183015141541, "test_runtime": 4.3905, "test_samples_per_second": 466.46, "test_steps_per_second": 14.577}, {"test_loss": 0.05895775184035301, "test_micro_f1": 0.777639751552795, "test_micro_f1_no_misc": 0.823168654173765, "test_runtime": 4.0769, "test_samples_per_second": 502.34, "test_steps_per_second": 15.698}, {"test_loss": 0.058470580726861954, "test_micro_f1": 0.7667887667887667, "test_micro_f1_no_misc": 0.8120965001698947, "test_runtime": 4.4963, "test_samples_per_second": 455.485, "test_steps_per_second": 14.234}, {"test_loss": 0.07025061547756195, "test_micro_f1": 0.7489230769230768, "test_micro_f1_no_misc": 0.7909336941813262, "test_runtime": 4.2505, "test_samples_per_second": 481.823, "test_steps_per_second": 15.057}, {"test_loss": 0.05805191397666931, "test_micro_f1": 0.7917309472385066, "test_micro_f1_no_misc": 0.8304054054054054, "test_runtime": 3.9233, "test_samples_per_second": 522.007, "test_steps_per_second": 16.313}]}, "total": {"test_micro_f1": 76.07989211259452, "test_micro_f1_se": 1.0641277282457864, "test_micro_f1_no_misc": 80.29367384179487, "test_micro_f1_no_misc_se": 1.018568503788895}}, "num_model_parameters": 108197385, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.6620047688484192, "test_mcc": 0.3149501966852046, "test_macro_f1": 0.6337478439746114, "test_runtime": 2.1349, "test_samples_per_second": 959.29, "test_steps_per_second": 29.978}, {"test_loss": 0.6435861587524414, "test_mcc": 0.2835930003039474, "test_macro_f1": 0.5791558728116125, "test_runtime": 2.196, "test_samples_per_second": 932.603, "test_steps_per_second": 29.144}, {"test_loss": 0.6269248127937317, "test_mcc": 0.30842922684136964, "test_macro_f1": 0.6470694895624074, "test_runtime": 2.2321, "test_samples_per_second": 917.542, "test_steps_per_second": 28.673}, {"test_loss": 0.6378536820411682, "test_mcc": 0.2835701214984104, "test_macro_f1": 0.6250344061310801, "test_runtime": 2.1774, "test_samples_per_second": 940.575, "test_steps_per_second": 29.393}, {"test_loss": 0.6323719620704651, "test_mcc": 0.3589895993137174, "test_macro_f1": 0.6701590877528663, "test_runtime": 2.3005, "test_samples_per_second": 890.254, "test_steps_per_second": 27.82}, {"test_loss": 0.6297491788864136, "test_mcc": 0.32224530267584217, "test_macro_f1": 0.661116976482246, "test_runtime": 2.4078, "test_samples_per_second": 850.586, "test_steps_per_second": 26.581}, {"test_loss": 0.6404032707214355, "test_mcc": 0.27966106551291414, "test_macro_f1": 0.6296916493416241, "test_runtime": 2.4544, "test_samples_per_second": 834.432, "test_steps_per_second": 26.076}, {"test_loss": 0.640355110168457, "test_mcc": 0.31415528969750656, "test_macro_f1": 0.6305470518918852, "test_runtime": 2.4922, "test_samples_per_second": 821.767, "test_steps_per_second": 25.68}, {"test_loss": 0.667907178401947, "test_mcc": 0.31879239052009556, "test_macro_f1": 0.6488660448183154, "test_runtime": 2.4495, "test_samples_per_second": 836.075, "test_steps_per_second": 26.127}, {"test_loss": 0.6499851942062378, "test_mcc": 0.2983524615407323, "test_macro_f1": 0.6136784843669317, "test_runtime": 2.5239, "test_samples_per_second": 811.442, "test_steps_per_second": 25.358}]}, "total": {"test_mcc": 30.8273865458974, "test_mcc_se": 1.474517236145536, "test_macro_f1": 63.39066907133579, "test_macro_f1_se": 1.5958335429513253}}, "num_model_parameters": 108782594, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.6831779479980469, "test_mcc": 0.3739725042357428, "test_macro_f1": 0.6869847778093312, "test_runtime": 2.4383, "test_samples_per_second": 839.934, "test_steps_per_second": 26.248}, {"test_loss": 0.626750648021698, "test_mcc": 0.3742757145814074, "test_macro_f1": 0.6831846037572, "test_runtime": 2.6246, "test_samples_per_second": 780.319, "test_steps_per_second": 24.385}, {"test_loss": 0.6560368537902832, "test_mcc": 0.4133909085373396, "test_macro_f1": 0.7048515034126546, "test_runtime": 2.6363, "test_samples_per_second": 776.859, "test_steps_per_second": 24.277}, {"test_loss": 0.6705655455589294, "test_mcc": 0.3263635340269326, "test_macro_f1": 0.6529684483053282, "test_runtime": 2.6728, "test_samples_per_second": 766.245, "test_steps_per_second": 23.945}, {"test_loss": 0.6157652139663696, "test_mcc": 0.3316029754183184, "test_macro_f1": 0.6626182564763652, "test_runtime": 2.4588, "test_samples_per_second": 832.919, "test_steps_per_second": 26.029}, {"test_loss": 0.6395504474639893, "test_mcc": 0.2973160774432185, "test_macro_f1": 0.6211492052095176, "test_runtime": 2.5114, "test_samples_per_second": 815.491, "test_steps_per_second": 25.484}, {"test_loss": 0.6123354434967041, "test_mcc": 0.3122469270360117, "test_macro_f1": 0.6557478478875858, "test_runtime": 2.5202, "test_samples_per_second": 812.627, "test_steps_per_second": 25.395}, {"test_loss": 0.6105962991714478, "test_mcc": 0.38795063401350544, "test_macro_f1": 0.6930407940756521, "test_runtime": 2.5772, "test_samples_per_second": 794.668, "test_steps_per_second": 24.833}, {"test_loss": 0.6584016680717468, "test_mcc": 0.2659344544357675, "test_macro_f1": 0.5801152689886557, "test_runtime": 2.4287, "test_samples_per_second": 843.238, "test_steps_per_second": 26.351}, {"test_loss": 0.6150599122047424, "test_mcc": 0.3297566008070434, "test_macro_f1": 0.6568628514548541, "test_runtime": 2.533, "test_samples_per_second": 808.536, "test_steps_per_second": 25.267}]}, "total": {"test_mcc": 34.128103305352866, "test_mcc_se": 2.8053253702289593, "test_macro_f1": 65.97523557377144, "test_macro_f1_se": 2.2953876444973718}}, "num_model_parameters": 108782594, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.6077694892883301, "test_mcc": 0.36080464041768073, "test_macro_f1": 0.6689082219465016, "test_runtime": 2.033, "test_samples_per_second": 1007.394, "test_steps_per_second": 31.481}, {"test_loss": 0.623589038848877, "test_mcc": 0.3787754038144335, "test_macro_f1": 0.6471337972587321, "test_runtime": 2.0171, "test_samples_per_second": 1015.303, "test_steps_per_second": 31.728}, {"test_loss": 0.6069279909133911, "test_mcc": 0.35090589288094026, "test_macro_f1": 0.667159818630022, "test_runtime": 2.0631, "test_samples_per_second": 992.657, "test_steps_per_second": 31.021}, {"test_loss": 0.6203212141990662, "test_mcc": 0.3018040358649363, "test_macro_f1": 0.6425805611449947, "test_runtime": 2.0731, "test_samples_per_second": 987.912, "test_steps_per_second": 30.872}, {"test_loss": 0.6023938655853271, "test_mcc": 0.38960559998597594, "test_macro_f1": 0.6893041796344848, "test_runtime": 2.0961, "test_samples_per_second": 977.061, "test_steps_per_second": 30.533}, {"test_loss": 0.5912078619003296, "test_mcc": 0.40231533797703667, "test_macro_f1": 0.6931915271994835, "test_runtime": 1.9774, "test_samples_per_second": 1035.698, "test_steps_per_second": 32.366}, {"test_loss": 0.692366361618042, "test_mcc": 0.019400370316803996, "test_macro_f1": 0.5076752666225031, "test_runtime": 1.9914, "test_samples_per_second": 1028.443, "test_steps_per_second": 32.139}, {"test_loss": 0.5961374044418335, "test_mcc": 0.363414852670272, "test_macro_f1": 0.6745343535049078, "test_runtime": 2.037, "test_samples_per_second": 1005.382, "test_steps_per_second": 31.418}, {"test_loss": 0.623749852180481, "test_mcc": 0.36939053168627783, "test_macro_f1": 0.6769028261711187, "test_runtime": 2.1487, "test_samples_per_second": 953.121, "test_steps_per_second": 29.785}, {"test_loss": 0.6131941080093384, "test_mcc": 0.3237165969331747, "test_macro_f1": 0.6516805427073697, "test_runtime": 2.3616, "test_samples_per_second": 867.218, "test_steps_per_second": 27.101}]}, "total": {"test_mcc": 32.60133262547532, "test_mcc_se": 6.925432321841328, "test_macro_f1": 65.19071094820119, "test_macro_f1_se": 3.3104116867779303}}, "num_model_parameters": 108782594, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_loss": 0.624259352684021, "test_mcc": 0.3088318447963019, "test_macro_f1": 0.6529910606455707, "test_runtime": 2.2595, "test_samples_per_second": 906.383, "test_steps_per_second": 28.324}, {"test_loss": 0.6262174844741821, "test_mcc": 0.32308637753481234, "test_macro_f1": 0.6476388562298723, "test_runtime": 2.3065, "test_samples_per_second": 887.93, "test_steps_per_second": 27.748}, {"test_loss": 0.6434826850891113, "test_mcc": 0.2688362968363086, "test_macro_f1": 0.6054778810046233, "test_runtime": 2.4423, "test_samples_per_second": 838.57, "test_steps_per_second": 26.205}, {"test_loss": 0.639582633972168, "test_mcc": 0.2873348398413944, "test_macro_f1": 0.6229655834689196, "test_runtime": 2.2742, "test_samples_per_second": 900.541, "test_steps_per_second": 28.142}, {"test_loss": 0.6403318047523499, "test_mcc": 0.2755810696147304, "test_macro_f1": 0.6282482656482347, "test_runtime": 2.3647, "test_samples_per_second": 866.055, "test_steps_per_second": 27.064}, {"test_loss": 0.6915188431739807, "test_mcc": 0.08854631335292608, "test_macro_f1": 0.5442574088216278, "test_runtime": 2.3883, "test_samples_per_second": 857.506, "test_steps_per_second": 26.797}, {"test_loss": 0.6436953544616699, "test_mcc": 0.27345839929957466, "test_macro_f1": 0.629692038394214, "test_runtime": 2.2037, "test_samples_per_second": 929.356, "test_steps_per_second": 29.042}, {"test_loss": 0.6906901001930237, "test_mcc": 0.030876230216034452, "test_macro_f1": 0.4955363962000949, "test_runtime": 2.3671, "test_samples_per_second": 865.18, "test_steps_per_second": 27.037}, {"test_loss": 0.6265311241149902, "test_mcc": 0.2862595249949167, "test_macro_f1": 0.6412111187500648, "test_runtime": 2.349, "test_samples_per_second": 871.879, "test_steps_per_second": 27.246}, {"test_loss": 0.6304646730422974, "test_mcc": 0.3538020547664583, "test_macro_f1": 0.6713969466109311, "test_runtime": 2.4549, "test_samples_per_second": 834.247, "test_steps_per_second": 26.07}]}, "total": {"test_mcc": 24.966129512534575, "test_mcc_se": 6.465266655859993, "test_macro_f1": 61.394155557741534, "test_macro_f1_se": 3.3432932359875647}}, "num_model_parameters": 108782594, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_em": 41.98295894655306, "test_f1": 45.619816767965546}, {"test_em": 38.604651162790695, "test_f1": 43.175364597749216}, {"test_em": 36.476043276661514, "test_f1": 40.45040909089556}, {"test_em": 31.46417445482866, "test_f1": 35.21336463673927}, {"test_em": 36.13899613899614, "test_f1": 39.526738463049846}, {"test_em": 40.78643022359291, "test_f1": 44.353856137905254}, {"test_em": 36.21867881548975, "test_f1": 40.2455035669642}, {"test_em": 44.53064391000776, "test_f1": 48.8866219195378}, {"test_em": 44.705882352941174, "test_f1": 48.317012972121304}, {"test_em": 37.732919254658384, "test_f1": 41.47191206137924}]}, "total": {"test_em": 38.864137853652004, "test_em_se": 2.5795649975963975, "test_f1": 42.726060021430726, "test_f1_se": 2.6134769456816827}}, "num_model_parameters": 108192002, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_em": 40.58869093725794, "test_f1": 45.46106864568784}, {"test_em": 33.87596899224806, "test_f1": 38.251303879678865}, {"test_em": 35.85780525502319, "test_f1": 39.99275239353161}, {"test_em": 37.149532710280376, "test_f1": 41.13845182642022}, {"test_em": 37.142857142857146, "test_f1": 41.7146451653307}, {"test_em": 35.774865073245955, "test_f1": 40.04899273781502}, {"test_em": 40.394836750189825, "test_f1": 44.33126668172425}, {"test_em": 36.69511249030256, "test_f1": 41.05518561699344}, {"test_em": 36.3921568627451, "test_f1": 41.10470079331489}, {"test_em": 38.66459627329193, "test_f1": 44.090623421743736}]}, "total": {"test_em": 37.25364224874421, "test_em_se": 1.3001413453841901, "test_f1": 41.71889911622406, "test_f1_se": 1.3920822812106153}}, "num_model_parameters": 108192002, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_em": 43.29976762199845, "test_f1": 48.04460549691389}, {"test_em": 39.689922480620154, "test_f1": 45.46602764770723}, {"test_em": 43.81761978361669, "test_f1": 47.993473250996665}, {"test_em": 43.769470404984425, "test_f1": 48.29288929847346}, {"test_em": 40.84942084942085, "test_f1": 45.721829999333195}, {"test_em": 41.480339244410175, "test_f1": 45.49528289086833}, {"test_em": 40.85041761579347, "test_f1": 45.49491513177964}, {"test_em": 38.091543832428236, "test_f1": 42.7452426749598}, {"test_em": 43.6078431372549, "test_f1": 47.84814636516314}, {"test_em": 38.58695652173913, "test_f1": 43.198851779084976}]}, "total": {"test_em": 41.404330149226645, "test_em_se": 1.3443096559087573, "test_f1": 46.030126453528034, "test_f1_se": 1.241857423625604}}, "num_model_parameters": 108192002, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6121132373809814, "test_mcc": 0.5949205572848049, "test_macro_f1": 0.6215367270918605, "test_runtime": 9.2172, "test_samples_per_second": 222.194, "test_steps_per_second": 27.774}, {"test_loss": 0.6709109544754028, "test_mcc": 0.5445660581011508, "test_macro_f1": 0.5222521363110899, "test_runtime": 8.8295, "test_samples_per_second": 231.949, "test_steps_per_second": 28.994}, {"test_loss": 0.6270642280578613, "test_mcc": 0.5882880872446125, "test_macro_f1": 0.5415275236666722, "test_runtime": 8.9796, "test_samples_per_second": 228.072, "test_steps_per_second": 28.509}, {"test_loss": 0.6036256551742554, "test_mcc": 0.5794560747607239, "test_macro_f1": 0.545546973706167, "test_runtime": 8.8026, "test_samples_per_second": 232.658, "test_steps_per_second": 29.082}, {"test_loss": 0.6310471296310425, "test_mcc": 0.5981789669423119, "test_macro_f1": 0.626052846969651, "test_runtime": 8.7438, "test_samples_per_second": 234.223, "test_steps_per_second": 29.278}, {"test_loss": 0.6557236313819885, "test_mcc": 0.5645406097497426, "test_macro_f1": 0.5319700439927603, "test_runtime": 8.9334, "test_samples_per_second": 229.251, "test_steps_per_second": 28.656}, {"test_loss": 0.6281875967979431, "test_mcc": 0.6232052257288379, "test_macro_f1": 0.5919550339467081, "test_runtime": 8.6623, "test_samples_per_second": 236.426, "test_steps_per_second": 29.553}, {"test_loss": 0.6181328296661377, "test_mcc": 0.5846608419783547, "test_macro_f1": 0.5388946824851616, "test_runtime": 9.2134, "test_samples_per_second": 222.285, "test_steps_per_second": 27.786}, {"test_loss": 0.6400052905082703, "test_mcc": 0.575714751799116, "test_macro_f1": 0.5361857923497267, "test_runtime": 9.1354, "test_samples_per_second": 224.182, "test_steps_per_second": 28.023}, {"test_loss": 0.6152044534683228, "test_mcc": 0.5930888273630719, "test_macro_f1": 0.5475502972857643, "test_runtime": 8.9076, "test_samples_per_second": 229.917, "test_steps_per_second": 28.74}]}, "total": {"test_mcc": 58.46620000952727, "test_mcc_se": 1.3029695119670313, "test_macro_f1": 56.03472057805562, "test_macro_f1_se": 2.364481306719125}}, "num_model_parameters": 61294083, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.9574152231216431, "test_mcc": 0.3028548256848918, "test_macro_f1": 0.5300584454201406, "test_runtime": 2.6039, "test_samples_per_second": 786.516, "test_steps_per_second": 24.579}, {"test_loss": 0.9602832198143005, "test_mcc": 0.35696139527173393, "test_macro_f1": 0.5649785517803686, "test_runtime": 2.5912, "test_samples_per_second": 790.37, "test_steps_per_second": 24.699}, {"test_loss": 0.9973739385604858, "test_mcc": 0.30311568839868136, "test_macro_f1": 0.5307488670073254, "test_runtime": 2.5912, "test_samples_per_second": 790.382, "test_steps_per_second": 24.699}, {"test_loss": 1.015031337738037, "test_mcc": 0.28123265409808884, "test_macro_f1": 0.5027655298667445, "test_runtime": 2.5881, "test_samples_per_second": 791.313, "test_steps_per_second": 24.729}, {"test_loss": 0.9968440532684326, "test_mcc": 0.3273250828168072, "test_macro_f1": 0.5461047983473647, "test_runtime": 2.6226, "test_samples_per_second": 780.916, "test_steps_per_second": 24.404}, {"test_loss": 1.0147664546966553, "test_mcc": 0.30451387901969673, "test_macro_f1": 0.5236668132863277, "test_runtime": 2.6152, "test_samples_per_second": 783.1, "test_steps_per_second": 24.472}, {"test_loss": 0.9462423324584961, "test_mcc": 0.3550005072063945, "test_macro_f1": 0.5679390312125644, "test_runtime": 2.6016, "test_samples_per_second": 787.2, "test_steps_per_second": 24.6}, {"test_loss": 1.0132886171340942, "test_mcc": 0.31549259642179434, "test_macro_f1": 0.5328154209822198, "test_runtime": 2.61, "test_samples_per_second": 784.662, "test_steps_per_second": 24.521}, {"test_loss": 1.0173935890197754, "test_mcc": 0.33950629867407395, "test_macro_f1": 0.5570162234166652, "test_runtime": 2.6208, "test_samples_per_second": 781.448, "test_steps_per_second": 24.42}, {"test_loss": 0.9864786863327026, "test_mcc": 0.3267967723685873, "test_macro_f1": 0.5325171937326637, "test_runtime": 2.5565, "test_samples_per_second": 801.094, "test_steps_per_second": 25.034}]}, "total": {"test_mcc": 32.1279969996075, "test_mcc_se": 1.5178195191471402, "test_macro_f1": 53.88610875052385, "test_macro_f1_se": 1.250510380723161}}, "num_model_parameters": 61294083, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.9031287431716919, "test_mcc": 0.303538011351582, "test_macro_f1": 0.4218113623512065, "test_runtime": 2.1601, "test_samples_per_second": 948.117, "test_steps_per_second": 29.629}, {"test_loss": 0.9054521322250366, "test_mcc": 0.33858164964464355, "test_macro_f1": 0.5214085390287416, "test_runtime": 2.0199, "test_samples_per_second": 1013.922, "test_steps_per_second": 31.685}, {"test_loss": 0.884690523147583, "test_mcc": 0.3219531374288617, "test_macro_f1": 0.43106841737423607, "test_runtime": 2.0467, "test_samples_per_second": 1000.632, "test_steps_per_second": 31.27}, {"test_loss": 0.9411901831626892, "test_mcc": 0.3649006109049573, "test_macro_f1": 0.49465847697909177, "test_runtime": 2.0828, "test_samples_per_second": 983.278, "test_steps_per_second": 30.727}, {"test_loss": 0.9423158764839172, "test_mcc": 0.27450637524027355, "test_macro_f1": 0.4129593290535431, "test_runtime": 2.0909, "test_samples_per_second": 979.487, "test_steps_per_second": 30.609}, {"test_loss": 0.9455045461654663, "test_mcc": 0.21823284663115544, "test_macro_f1": 0.3781765969671192, "test_runtime": 2.2184, "test_samples_per_second": 923.178, "test_steps_per_second": 28.849}, {"test_loss": 0.8928370475769043, "test_mcc": 0.337755574231347, "test_macro_f1": 0.4289919651999244, "test_runtime": 2.2002, "test_samples_per_second": 930.835, "test_steps_per_second": 29.089}, {"test_loss": 0.9587050676345825, "test_mcc": 0.29050380765028044, "test_macro_f1": 0.4158007699620386, "test_runtime": 2.1083, "test_samples_per_second": 971.417, "test_steps_per_second": 30.357}, {"test_loss": 0.9149932861328125, "test_mcc": 0.3367059470271051, "test_macro_f1": 0.45711057805420446, "test_runtime": 2.1973, "test_samples_per_second": 932.067, "test_steps_per_second": 29.127}, {"test_loss": 0.9316720962524414, "test_mcc": 0.28335815803416764, "test_macro_f1": 0.41545751275973014, "test_runtime": 2.1584, "test_samples_per_second": 948.867, "test_steps_per_second": 29.652}]}, "total": {"test_mcc": 30.700361181443736, "test_mcc_se": 2.6280178625857267, "test_macro_f1": 43.77443547729836, "test_macro_f1_se": 2.623915171385441}}, "num_model_parameters": 61294083, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.07210543006658554, "test_micro_f1": 0.6344687341128623, "test_micro_f1_no_misc": 0.7106658809664113, "test_runtime": 5.0127, "test_samples_per_second": 408.561, "test_steps_per_second": 12.768}, {"test_loss": 0.07227160036563873, "test_micro_f1": 0.600524934383202, "test_micro_f1_no_misc": 0.6458087367178277, "test_runtime": 4.8089, "test_samples_per_second": 425.874, "test_steps_per_second": 13.309}, {"test_loss": 0.06949803978204727, "test_micro_f1": 0.6573628488931665, "test_micro_f1_no_misc": 0.7084673097534834, "test_runtime": 4.7445, "test_samples_per_second": 431.654, "test_steps_per_second": 13.489}, {"test_loss": 0.07001091539859772, "test_micro_f1": 0.6411389297987237, "test_micro_f1_no_misc": 0.6770053475935829, "test_runtime": 5.0118, "test_samples_per_second": 408.632, "test_steps_per_second": 12.77}, {"test_loss": 0.07540436834096909, "test_micro_f1": 0.6558627264061011, "test_micro_f1_no_misc": 0.7019180922757905, "test_runtime": 5.0455, "test_samples_per_second": 405.903, "test_steps_per_second": 12.684}, {"test_loss": 0.06827661395072937, "test_micro_f1": 0.6645367412140575, "test_micro_f1_no_misc": 0.7084639498432602, "test_runtime": 4.2168, "test_samples_per_second": 485.679, "test_steps_per_second": 15.177}, {"test_loss": 0.07324720919132233, "test_micro_f1": 0.6229508196721312, "test_micro_f1_no_misc": 0.684297520661157, "test_runtime": 4.6065, "test_samples_per_second": 444.587, "test_steps_per_second": 13.893}, {"test_loss": 0.06208348274230957, "test_micro_f1": 0.6569264069264069, "test_micro_f1_no_misc": 0.7210460772104608, "test_runtime": 4.989, "test_samples_per_second": 410.504, "test_steps_per_second": 12.828}, {"test_loss": 0.06635585427284241, "test_micro_f1": 0.637065637065637, "test_micro_f1_no_misc": 0.6863711001642037, "test_runtime": 4.7535, "test_samples_per_second": 430.837, "test_steps_per_second": 13.464}, {"test_loss": 0.06980647891759872, "test_micro_f1": 0.618789965568126, "test_micro_f1_no_misc": 0.6806167400881057, "test_runtime": 4.9895, "test_samples_per_second": 410.464, "test_steps_per_second": 12.827}]}, "total": {"test_micro_f1": 63.89627744040415, "test_micro_f1_se": 1.2685799809392155, "test_micro_f1_no_misc": 69.24660755274282, "test_micro_f1_no_misc_se": 1.3719352330535588}}, "num_model_parameters": 60708105, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.07233382016420364, "test_micro_f1": 0.7545431277194778, "test_micro_f1_no_misc": 0.7726027397260273, "test_runtime": 5.5644, "test_samples_per_second": 368.055, "test_steps_per_second": 11.502}, {"test_loss": 0.06706278771162033, "test_micro_f1": 0.7871802080404835, "test_micro_f1_no_misc": 0.8079178885630498, "test_runtime": 4.2908, "test_samples_per_second": 477.299, "test_steps_per_second": 14.916}, {"test_loss": 0.07164075970649719, "test_micro_f1": 0.7632268203247774, "test_micro_f1_no_misc": 0.7948809100604336, "test_runtime": 5.5936, "test_samples_per_second": 366.135, "test_steps_per_second": 11.442}, {"test_loss": 0.0738702267408371, "test_micro_f1": 0.7680412371134021, "test_micro_f1_no_misc": 0.7992970123022848, "test_runtime": 5.2664, "test_samples_per_second": 388.878, "test_steps_per_second": 12.152}, {"test_loss": 0.07477802038192749, "test_micro_f1": 0.7613344739093242, "test_micro_f1_no_misc": 0.7921833897031191, "test_runtime": 5.5103, "test_samples_per_second": 371.67, "test_steps_per_second": 11.615}, {"test_loss": 0.07267997413873672, "test_micro_f1": 0.7691884456671253, "test_micro_f1_no_misc": 0.7854491462509281, "test_runtime": 5.428, "test_samples_per_second": 377.3, "test_steps_per_second": 11.791}, {"test_loss": 0.07432416081428528, "test_micro_f1": 0.7712594187298171, "test_micro_f1_no_misc": 0.7850467289719626, "test_runtime": 5.5098, "test_samples_per_second": 371.699, "test_steps_per_second": 11.616}, {"test_loss": 0.07018676400184631, "test_micro_f1": 0.7658741258741258, "test_micro_f1_no_misc": 0.792064097672644, "test_runtime": 5.5167, "test_samples_per_second": 371.236, "test_steps_per_second": 11.601}, {"test_loss": 0.07325770705938339, "test_micro_f1": 0.7733050847457628, "test_micro_f1_no_misc": 0.7782214156079855, "test_runtime": 5.2924, "test_samples_per_second": 386.972, "test_steps_per_second": 12.093}, {"test_loss": 0.07010110467672348, "test_micro_f1": 0.7694362810579749, "test_micro_f1_no_misc": 0.7937883712531599, "test_runtime": 4.5599, "test_samples_per_second": 449.13, "test_steps_per_second": 14.035}]}, "total": {"test_micro_f1": 76.83389223182272, "test_micro_f1_se": 0.5314920568384356, "test_micro_f1_no_misc": 79.01451700111595, "test_micro_f1_no_misc_se": 0.6338081031231992}}, "num_model_parameters": 60708105, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.046761516481637955, "test_micro_f1": 0.7928649435748089, "test_micro_f1_no_misc": 0.8318947801068639, "test_runtime": 4.2353, "test_samples_per_second": 483.551, "test_steps_per_second": 15.111}, {"test_loss": 0.043147262185811996, "test_micro_f1": 0.7988121752041574, "test_micro_f1_no_misc": 0.8208522962350021, "test_runtime": 4.3325, "test_samples_per_second": 472.701, "test_steps_per_second": 14.772}, {"test_loss": 0.04925202950835228, "test_micro_f1": 0.7981683691440649, "test_micro_f1_no_misc": 0.8281249999999999, "test_runtime": 4.1912, "test_samples_per_second": 488.641, "test_steps_per_second": 15.27}, {"test_loss": 0.041068702936172485, "test_micro_f1": 0.8052407932011333, "test_micro_f1_no_misc": 0.830367734282325, "test_runtime": 3.9324, "test_samples_per_second": 520.803, "test_steps_per_second": 16.275}, {"test_loss": 0.04803908243775368, "test_micro_f1": 0.7852596314907873, "test_micro_f1_no_misc": 0.8202123764188941, "test_runtime": 4.3095, "test_samples_per_second": 475.227, "test_steps_per_second": 14.851}, {"test_loss": 0.03973064571619034, "test_micro_f1": 0.822685343354971, "test_micro_f1_no_misc": 0.8490351872871736, "test_runtime": 4.2517, "test_samples_per_second": 481.687, "test_steps_per_second": 15.053}, {"test_loss": 0.04729101061820984, "test_micro_f1": 0.7905084745762713, "test_micro_f1_no_misc": 0.8186687069625096, "test_runtime": 3.8608, "test_samples_per_second": 530.457, "test_steps_per_second": 16.577}, {"test_loss": 0.048124030232429504, "test_micro_f1": 0.7935417382342838, "test_micro_f1_no_misc": 0.8218262806236081, "test_runtime": 4.0196, "test_samples_per_second": 509.504, "test_steps_per_second": 15.922}, {"test_loss": 0.0447787269949913, "test_micro_f1": 0.798862828713575, "test_micro_f1_no_misc": 0.8223107569721115, "test_runtime": 3.98, "test_samples_per_second": 514.578, "test_steps_per_second": 16.081}, {"test_loss": 0.0539480522274971, "test_micro_f1": 0.8055367994598245, "test_micro_f1_no_misc": 0.8402234636871508, "test_runtime": 4.1666, "test_samples_per_second": 491.527, "test_steps_per_second": 15.36}]}, "total": {"test_micro_f1": 79.91481096953878, "test_micro_f1_se": 0.6439674199922035, "test_micro_f1_no_misc": 82.83516582575639, "test_micro_f1_no_misc_se": 0.6131381791550866}}, "num_model_parameters": 60708105, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.06108380854129791, "test_micro_f1": 0.7218934911242604, "test_micro_f1_no_misc": 0.7644118627124292, "test_runtime": 4.2472, "test_samples_per_second": 482.2, "test_steps_per_second": 15.069}, {"test_loss": 0.05914606526494026, "test_micro_f1": 0.7726027397260274, "test_micro_f1_no_misc": 0.8037508372404554, "test_runtime": 4.3973, "test_samples_per_second": 465.738, "test_steps_per_second": 14.554}, {"test_loss": 0.07140939682722092, "test_micro_f1": 0.7180899908172635, "test_micro_f1_no_misc": 0.7567748410839744, "test_runtime": 4.0979, "test_samples_per_second": 499.773, "test_steps_per_second": 15.618}, {"test_loss": 0.07048441469669342, "test_micro_f1": 0.7323688969258589, "test_micro_f1_no_misc": 0.773678963110668, "test_runtime": 4.1127, "test_samples_per_second": 497.964, "test_steps_per_second": 15.561}, {"test_loss": 0.07730967551469803, "test_micro_f1": 0.7387223735997578, "test_micro_f1_no_misc": 0.7949762389680924, "test_runtime": 3.9898, "test_samples_per_second": 513.312, "test_steps_per_second": 16.041}, {"test_loss": 0.06752941757440567, "test_micro_f1": 0.7329528386902974, "test_micro_f1_no_misc": 0.7843007915567283, "test_runtime": 3.981, "test_samples_per_second": 514.449, "test_steps_per_second": 16.077}, {"test_loss": 0.06428728997707367, "test_micro_f1": 0.7393536695862278, "test_micro_f1_no_misc": 0.7897227856659905, "test_runtime": 4.2606, "test_samples_per_second": 480.685, "test_steps_per_second": 15.021}, {"test_loss": 0.05997730791568756, "test_micro_f1": 0.7844107639962883, "test_micro_f1_no_misc": 0.8196834136269786, "test_runtime": 4.2952, "test_samples_per_second": 476.807, "test_steps_per_second": 14.9}, {"test_loss": 0.07054544240236282, "test_micro_f1": 0.755037783375315, "test_micro_f1_no_misc": 0.7944444444444444, "test_runtime": 4.0193, "test_samples_per_second": 509.547, "test_steps_per_second": 15.923}, {"test_loss": 0.06035179644823074, "test_micro_f1": 0.7685241886099204, "test_micro_f1_no_misc": 0.8013201320132013, "test_runtime": 4.12, "test_samples_per_second": 497.089, "test_steps_per_second": 15.534}]}, "total": {"test_micro_f1": 74.63956736451217, "test_micro_f1_se": 1.3987762765004885, "test_micro_f1_no_misc": 78.83064310422962, "test_micro_f1_no_misc_se": 1.1817512883751773}}, "num_model_parameters": 60708105, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6465713977813721, "test_mcc": 0.27794979960305083, "test_macro_f1": 0.6239242541362278, "test_runtime": 2.1491, "test_samples_per_second": 952.938, "test_steps_per_second": 29.779}, {"test_loss": 0.6536016464233398, "test_mcc": 0.24928272414832667, "test_macro_f1": 0.6122580230707602, "test_runtime": 2.2771, "test_samples_per_second": 899.374, "test_steps_per_second": 28.105}, {"test_loss": 0.6705687642097473, "test_mcc": 0.2972812343875249, "test_macro_f1": 0.6399640209797968, "test_runtime": 2.2643, "test_samples_per_second": 904.489, "test_steps_per_second": 28.265}, {"test_loss": 0.6343855857849121, "test_mcc": 0.30337914696595675, "test_macro_f1": 0.6345564799561494, "test_runtime": 2.2233, "test_samples_per_second": 921.133, "test_steps_per_second": 28.785}, {"test_loss": 0.6362963914871216, "test_mcc": 0.32269775538310597, "test_macro_f1": 0.6497640473846467, "test_runtime": 2.2666, "test_samples_per_second": 903.56, "test_steps_per_second": 28.236}, {"test_loss": 0.6423201560974121, "test_mcc": 0.31600375122668595, "test_macro_f1": 0.654727420417797, "test_runtime": 2.2035, "test_samples_per_second": 929.416, "test_steps_per_second": 29.044}, {"test_loss": 0.6714088916778564, "test_mcc": 0.3174489653099496, "test_macro_f1": 0.6538081791813136, "test_runtime": 2.2433, "test_samples_per_second": 912.931, "test_steps_per_second": 28.529}, {"test_loss": 0.6741207838058472, "test_mcc": 0.3251092310711677, "test_macro_f1": 0.6334759539636943, "test_runtime": 2.2426, "test_samples_per_second": 913.24, "test_steps_per_second": 28.539}, {"test_loss": 0.6678441762924194, "test_mcc": 0.2685201534530976, "test_macro_f1": 0.6310016287818729, "test_runtime": 2.2361, "test_samples_per_second": 915.86, "test_steps_per_second": 28.621}, {"test_loss": 0.6557070016860962, "test_mcc": 0.3021387521027683, "test_macro_f1": 0.6191605658163688, "test_runtime": 2.251, "test_samples_per_second": 909.806, "test_steps_per_second": 28.431}]}, "total": {"test_mcc": 29.79811513651634, "test_mcc_se": 1.5650448641985246, "test_macro_f1": 63.52640573688627, "test_macro_f1_se": 0.8991594301614878}}, "num_model_parameters": 61293314, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.634018063545227, "test_mcc": 0.3021205796263928, "test_macro_f1": 0.6109981911103458, "test_runtime": 2.1893, "test_samples_per_second": 935.442, "test_steps_per_second": 29.233}, {"test_loss": 0.6255066990852356, "test_mcc": 0.3386587616625243, "test_macro_f1": 0.6524244788195439, "test_runtime": 2.2856, "test_samples_per_second": 896.029, "test_steps_per_second": 28.001}, {"test_loss": 0.6237317323684692, "test_mcc": 0.34104517769544984, "test_macro_f1": 0.6425545418484728, "test_runtime": 2.284, "test_samples_per_second": 896.689, "test_steps_per_second": 28.022}, {"test_loss": 0.6394294500350952, "test_mcc": 0.32843497761547646, "test_macro_f1": 0.6423702677665012, "test_runtime": 2.3321, "test_samples_per_second": 878.163, "test_steps_per_second": 27.443}, {"test_loss": 0.6079925298690796, "test_mcc": 0.3434705516311241, "test_macro_f1": 0.6695670325398262, "test_runtime": 2.2439, "test_samples_per_second": 912.71, "test_steps_per_second": 28.522}, {"test_loss": 0.6044963598251343, "test_mcc": 0.36058790975563576, "test_macro_f1": 0.6702179773340822, "test_runtime": 2.2058, "test_samples_per_second": 928.446, "test_steps_per_second": 29.014}, {"test_loss": 0.6068449020385742, "test_mcc": 0.34953998271778425, "test_macro_f1": 0.6714664983605695, "test_runtime": 2.2092, "test_samples_per_second": 927.033, "test_steps_per_second": 28.97}, {"test_loss": 0.609663724899292, "test_mcc": 0.3923879292193743, "test_macro_f1": 0.6959538675984801, "test_runtime": 2.1998, "test_samples_per_second": 930.997, "test_steps_per_second": 29.094}, {"test_loss": 0.6333711743354797, "test_mcc": 0.37678156801207907, "test_macro_f1": 0.6883802749720487, "test_runtime": 2.2039, "test_samples_per_second": 929.256, "test_steps_per_second": 29.039}, {"test_loss": 0.615980327129364, "test_mcc": 0.34229493671170963, "test_macro_f1": 0.6453101394277865, "test_runtime": 2.2479, "test_samples_per_second": 911.065, "test_steps_per_second": 28.471}]}, "total": {"test_mcc": 34.753223746475506, "test_mcc_se": 1.550715144946641, "test_macro_f1": 65.89243269777658, "test_macro_f1_se": 1.5602873378047226}}, "num_model_parameters": 61293314, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6068178415298462, "test_mcc": 0.36661330493557287, "test_macro_f1": 0.6812396236856668, "test_runtime": 2.0504, "test_samples_per_second": 998.833, "test_steps_per_second": 31.214}, {"test_loss": 0.6131181716918945, "test_mcc": 0.4142909406705376, "test_macro_f1": 0.6834240591620104, "test_runtime": 2.0596, "test_samples_per_second": 994.387, "test_steps_per_second": 31.075}, {"test_loss": 0.6363433599472046, "test_mcc": 0.3063110127122926, "test_macro_f1": 0.623906510851419, "test_runtime": 2.0692, "test_samples_per_second": 989.733, "test_steps_per_second": 30.929}, {"test_loss": 0.6265408992767334, "test_mcc": 0.2895506265277844, "test_macro_f1": 0.6209936374497406, "test_runtime": 2.14, "test_samples_per_second": 957.022, "test_steps_per_second": 29.907}, {"test_loss": 0.6241070628166199, "test_mcc": 0.3185276256537986, "test_macro_f1": 0.6483649517357382, "test_runtime": 2.0915, "test_samples_per_second": 979.19, "test_steps_per_second": 30.6}, {"test_loss": 0.6132698059082031, "test_mcc": 0.33412076911454114, "test_macro_f1": 0.6520976529741549, "test_runtime": 2.0265, "test_samples_per_second": 1010.621, "test_steps_per_second": 31.582}, {"test_loss": 0.6007551550865173, "test_mcc": 0.37666918814582606, "test_macro_f1": 0.6866113101833864, "test_runtime": 2.0137, "test_samples_per_second": 1017.053, "test_steps_per_second": 31.783}, {"test_loss": 0.6506762504577637, "test_mcc": 0.3361689346643482, "test_macro_f1": 0.6376789508440226, "test_runtime": 2.0466, "test_samples_per_second": 1000.688, "test_steps_per_second": 31.271}, {"test_loss": 0.6619604825973511, "test_mcc": 0.359897169124329, "test_macro_f1": 0.672713971176119, "test_runtime": 2.0377, "test_samples_per_second": 1005.056, "test_steps_per_second": 31.408}, {"test_loss": 0.6364774703979492, "test_mcc": 0.3220791845823686, "test_macro_f1": 0.6531117807788696, "test_runtime": 2.1385, "test_samples_per_second": 957.681, "test_steps_per_second": 29.928}]}, "total": {"test_mcc": 34.24228756131399, "test_mcc_se": 2.302551274038062, "test_macro_f1": 65.60142448841128, "test_macro_f1_se": 1.5010306148742836}}, "num_model_parameters": 61293314, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6371994018554688, "test_mcc": 0.2831891794850107, "test_macro_f1": 0.6402565106259865, "test_runtime": 2.2508, "test_samples_per_second": 909.879, "test_steps_per_second": 28.434}, {"test_loss": 0.6595746874809265, "test_mcc": 0.21051671341564288, "test_macro_f1": 0.604911799598195, "test_runtime": 2.2221, "test_samples_per_second": 921.654, "test_steps_per_second": 28.802}, {"test_loss": 0.6329755783081055, "test_mcc": 0.29574957306381233, "test_macro_f1": 0.6408263953129818, "test_runtime": 2.2243, "test_samples_per_second": 920.747, "test_steps_per_second": 28.773}, {"test_loss": 0.6365450620651245, "test_mcc": 0.26402035758872605, "test_macro_f1": 0.6307244925655566, "test_runtime": 2.1328, "test_samples_per_second": 960.231, "test_steps_per_second": 30.007}, {"test_loss": 0.6510826349258423, "test_mcc": 0.2690697908540057, "test_macro_f1": 0.601615585649798, "test_runtime": 2.1526, "test_samples_per_second": 951.393, "test_steps_per_second": 29.731}, {"test_loss": 0.6532336473464966, "test_mcc": 0.28162428688464775, "test_macro_f1": 0.6405278731556563, "test_runtime": 2.236, "test_samples_per_second": 915.918, "test_steps_per_second": 28.622}, {"test_loss": 0.6598137617111206, "test_mcc": 0.2024936305715909, "test_macro_f1": 0.5925083863057157, "test_runtime": 2.2075, "test_samples_per_second": 927.749, "test_steps_per_second": 28.992}, {"test_loss": 0.6363517642021179, "test_mcc": 0.2831187755800474, "test_macro_f1": 0.6415440279814185, "test_runtime": 2.1695, "test_samples_per_second": 943.977, "test_steps_per_second": 29.499}, {"test_loss": 0.6403212547302246, "test_mcc": 0.2783792712510814, "test_macro_f1": 0.627353596717884, "test_runtime": 2.1617, "test_samples_per_second": 947.418, "test_steps_per_second": 29.607}, {"test_loss": 0.635241687297821, "test_mcc": 0.3516404982860226, "test_macro_f1": 0.6670649128306761, "test_runtime": 2.2099, "test_samples_per_second": 926.729, "test_steps_per_second": 28.96}]}, "total": {"test_mcc": 27.198020769805876, "test_mcc_se": 2.61107712763629, "test_macro_f1": 62.87333580743868, "test_macro_f1_se": 1.412245203518293}}, "num_model_parameters": 61293314, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_em": 37.180480247869866, "test_f1": 41.748057752337225}, {"test_em": 43.02325581395349, "test_f1": 46.57550715485052}, {"test_em": 41.65378670788253, "test_f1": 45.93884618033217}, {"test_em": 33.8006230529595, "test_f1": 37.936237381333214}, {"test_em": 39.07335907335907, "test_f1": 43.027394957956645}, {"test_em": 41.17193523515806, "test_f1": 45.23733722269036}, {"test_em": 37.43356112376613, "test_f1": 41.36576657797365}, {"test_em": 37.62606671838635, "test_f1": 41.8218686087255}, {"test_em": 38.588235294117645, "test_f1": 42.237197733276176}, {"test_em": 37.18944099378882, "test_f1": 40.47949034112694}]}, "total": {"test_em": 38.67407442612414, "test_em_se": 1.6659724691621074, "test_f1": 42.63677039106024, "test_f1_se": 1.643892856789048}}, "num_model_parameters": 60702722, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_em": 35.243996901626645, "test_f1": 39.18090976142781}, {"test_em": 39.53488372093023, "test_f1": 44.275002870462096}, {"test_em": 39.41267387944359, "test_f1": 43.01365481026549}, {"test_em": 33.95638629283489, "test_f1": 38.041499467818156}, {"test_em": 40.463320463320464, "test_f1": 44.761766871895105}, {"test_em": 36.622976098689286, "test_f1": 41.5030332573914}, {"test_em": 37.58542141230068, "test_f1": 41.6114838684075}, {"test_em": 28.316524437548487, "test_f1": 33.103250204108065}, {"test_em": 34.745098039215684, "test_f1": 39.31866514135683}, {"test_em": 37.11180124223603, "test_f1": 41.9862524921031}]}, "total": {"test_em": 36.2993082488146, "test_em_se": 2.1929370247219997, "test_f1": 40.67955187452356, "test_f1_se": 2.1346258467648824}}, "num_model_parameters": 60702722, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_em": 41.36328427575523, "test_f1": 45.89135889337572}, {"test_em": 38.21705426356589, "test_f1": 43.48113558681274}, {"test_em": 42.04018547140649, "test_f1": 46.508721207959255}, {"test_em": 39.56386292834891, "test_f1": 43.42327051741204}, {"test_em": 37.45173745173745, "test_f1": 43.00680951850113}, {"test_em": 42.5597532767926, "test_f1": 47.32847291002556}, {"test_em": 40.394836750189825, "test_f1": 45.090757066175996}, {"test_em": 39.87587276958883, "test_f1": 44.07033406565646}, {"test_em": 42.666666666666664, "test_f1": 47.02365423348848}, {"test_em": 37.422360248447205, "test_f1": 42.08310868510866}]}, "total": {"test_em": 40.155561410249916, "test_em_se": 1.241688121315019, "test_f1": 44.790762268451594, "test_f1_se": 1.1371852216638114}}, "num_model_parameters": 60702722, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6280220150947571, "test_mcc": 0.587389849882171, "test_macro_f1": 0.5398617263961661, "test_runtime": 9.1661, "test_samples_per_second": 223.431, "test_steps_per_second": 27.929}, {"test_loss": 0.6491872072219849, "test_mcc": 0.5685046532963297, "test_macro_f1": 0.5333055798172078, "test_runtime": 8.8043, "test_samples_per_second": 232.613, "test_steps_per_second": 29.077}, {"test_loss": 0.6155259609222412, "test_mcc": 0.5813022051399609, "test_macro_f1": 0.5460584120664554, "test_runtime": 8.9464, "test_samples_per_second": 228.92, "test_steps_per_second": 28.615}, {"test_loss": 0.5876519680023193, "test_mcc": 0.6140554342077713, "test_macro_f1": 0.5935463458509379, "test_runtime": 8.7745, "test_samples_per_second": 233.403, "test_steps_per_second": 29.175}, {"test_loss": 0.6421474814414978, "test_mcc": 0.5996363126769074, "test_macro_f1": 0.5814684907434319, "test_runtime": 8.8627, "test_samples_per_second": 231.082, "test_steps_per_second": 28.885}, {"test_loss": 0.6392742395401001, "test_mcc": 0.5760814675194905, "test_macro_f1": 0.5706982278187315, "test_runtime": 9.011, "test_samples_per_second": 227.278, "test_steps_per_second": 28.41}, {"test_loss": 0.5949877500534058, "test_mcc": 0.5984045185429314, "test_macro_f1": 0.5498104829052294, "test_runtime": 8.6367, "test_samples_per_second": 237.126, "test_steps_per_second": 29.641}, {"test_loss": 0.6112939119338989, "test_mcc": 0.6168254424266387, "test_macro_f1": 0.5686060505945144, "test_runtime": 9.1937, "test_samples_per_second": 222.76, "test_steps_per_second": 27.845}, {"test_loss": 0.6364062428474426, "test_mcc": 0.575440550493549, "test_macro_f1": 0.5358851308176432, "test_runtime": 9.0878, "test_samples_per_second": 225.358, "test_steps_per_second": 28.17}, {"test_loss": 0.5814807415008545, "test_mcc": 0.6248428784946377, "test_macro_f1": 0.5552038508220236, "test_runtime": 8.8488, "test_samples_per_second": 231.445, "test_steps_per_second": 28.931}]}, "total": {"test_mcc": 59.424833126803875, "test_mcc_se": 1.2127252266201771, "test_macro_f1": 55.74444297832342, "test_macro_f1_se": 1.2618514633167133}}, "num_model_parameters": 68652291, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.9376376271247864, "test_mcc": 0.32792615332881764, "test_macro_f1": 0.5427549412516975, "test_runtime": 2.6019, "test_samples_per_second": 787.123, "test_steps_per_second": 24.598}, {"test_loss": 0.9642288684844971, "test_mcc": 0.33371497828335656, "test_macro_f1": 0.5501814436220204, "test_runtime": 2.5825, "test_samples_per_second": 793.034, "test_steps_per_second": 24.782}, {"test_loss": 0.9732016921043396, "test_mcc": 0.31109147325433256, "test_macro_f1": 0.5388087941894368, "test_runtime": 2.5881, "test_samples_per_second": 791.316, "test_steps_per_second": 24.729}, {"test_loss": 0.981918454170227, "test_mcc": 0.3305965023051122, "test_macro_f1": 0.5488190234366169, "test_runtime": 2.6141, "test_samples_per_second": 783.431, "test_steps_per_second": 24.482}, {"test_loss": 1.0309381484985352, "test_mcc": 0.3210997521757579, "test_macro_f1": 0.5477918053101317, "test_runtime": 2.5713, "test_samples_per_second": 796.493, "test_steps_per_second": 24.89}, {"test_loss": 1.0167739391326904, "test_mcc": 0.27800369983722106, "test_macro_f1": 0.5030070039129617, "test_runtime": 2.5944, "test_samples_per_second": 789.379, "test_steps_per_second": 24.668}, {"test_loss": 0.9528157114982605, "test_mcc": 0.36316042521566105, "test_macro_f1": 0.5701401836175828, "test_runtime": 2.5941, "test_samples_per_second": 789.496, "test_steps_per_second": 24.672}, {"test_loss": 1.0325844287872314, "test_mcc": 0.28411782112112205, "test_macro_f1": 0.5127831855852288, "test_runtime": 2.7041, "test_samples_per_second": 757.366, "test_steps_per_second": 23.668}, {"test_loss": 1.0468807220458984, "test_mcc": 0.30247226776022784, "test_macro_f1": 0.5317881396582597, "test_runtime": 2.5764, "test_samples_per_second": 794.895, "test_steps_per_second": 24.84}, {"test_loss": 0.9663381576538086, "test_mcc": 0.337235843764679, "test_macro_f1": 0.5530855713349082, "test_runtime": 2.5434, "test_samples_per_second": 805.219, "test_steps_per_second": 25.163}]}, "total": {"test_mcc": 31.894189170462877, "test_mcc_se": 1.5937749999710729, "test_macro_f1": 53.99160091918846, "test_macro_f1_se": 1.2235699452936895}}, "num_model_parameters": 68652291, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.9025670289993286, "test_mcc": 0.2981316457922525, "test_macro_f1": 0.4192377430104283, "test_runtime": 2.1312, "test_samples_per_second": 960.963, "test_steps_per_second": 30.03}, {"test_loss": 0.9078704118728638, "test_mcc": 0.2921512065576418, "test_macro_f1": 0.43701619318876633, "test_runtime": 1.9925, "test_samples_per_second": 1027.867, "test_steps_per_second": 32.121}, {"test_loss": 0.8920965194702148, "test_mcc": 0.32392774993395457, "test_macro_f1": 0.4379279702886243, "test_runtime": 2.0334, "test_samples_per_second": 1007.159, "test_steps_per_second": 31.474}, {"test_loss": 0.9245423078536987, "test_mcc": 0.2963318090795398, "test_macro_f1": 0.4141644861678972, "test_runtime": 2.0564, "test_samples_per_second": 995.923, "test_steps_per_second": 31.123}, {"test_loss": 0.9278267025947571, "test_mcc": 0.3291184903000779, "test_macro_f1": 0.5225010970181059, "test_runtime": 2.0824, "test_samples_per_second": 983.457, "test_steps_per_second": 30.733}, {"test_loss": 0.9532678127288818, "test_mcc": 0.21655815397109965, "test_macro_f1": 0.3772804061188117, "test_runtime": 2.1251, "test_samples_per_second": 963.737, "test_steps_per_second": 30.117}, {"test_loss": 0.870798647403717, "test_mcc": 0.3654802131364526, "test_macro_f1": 0.549051377479267, "test_runtime": 2.0861, "test_samples_per_second": 981.736, "test_steps_per_second": 30.679}, {"test_loss": 0.8962711691856384, "test_mcc": 0.24950656640201477, "test_macro_f1": 0.4032520026178925, "test_runtime": 2.1425, "test_samples_per_second": 955.899, "test_steps_per_second": 29.872}, {"test_loss": 0.9209895133972168, "test_mcc": 0.277771691292629, "test_macro_f1": 0.4113579259936044, "test_runtime": 2.1408, "test_samples_per_second": 956.664, "test_steps_per_second": 29.896}, {"test_loss": 0.8975252509117126, "test_mcc": 0.28793825919331134, "test_macro_f1": 0.43352971714389743, "test_runtime": 2.1332, "test_samples_per_second": 960.07, "test_steps_per_second": 30.002}]}, "total": {"test_mcc": 29.36915785658974, "test_mcc_se": 2.5755243528543534, "test_macro_f1": 44.053189190272946, "test_macro_f1_se": 3.328407425330814}}, "num_model_parameters": 68652291, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.07688240706920624, "test_micro_f1": 0.6358811040339702, "test_micro_f1_no_misc": 0.7020357803824799, "test_runtime": 5.0079, "test_samples_per_second": 408.952, "test_steps_per_second": 12.78}, {"test_loss": 0.0733347088098526, "test_micro_f1": 0.6163793103448276, "test_micro_f1_no_misc": 0.6843730697961705, "test_runtime": 4.7517, "test_samples_per_second": 431.006, "test_steps_per_second": 13.469}, {"test_loss": 0.0647740513086319, "test_micro_f1": 0.6410767696909272, "test_micro_f1_no_misc": 0.7013422818791946, "test_runtime": 4.7117, "test_samples_per_second": 434.662, "test_steps_per_second": 13.583}, {"test_loss": 0.07015466690063477, "test_micro_f1": 0.6235059760956174, "test_micro_f1_no_misc": 0.6813063063063063, "test_runtime": 5.0702, "test_samples_per_second": 403.93, "test_steps_per_second": 12.623}, {"test_loss": 0.07265640795230865, "test_micro_f1": 0.6372007366482504, "test_micro_f1_no_misc": 0.6904276985743381, "test_runtime": 4.9845, "test_samples_per_second": 410.875, "test_steps_per_second": 12.84}, {"test_loss": 0.06563793122768402, "test_micro_f1": 0.6813186813186813, "test_micro_f1_no_misc": 0.7220216606498194, "test_runtime": 4.1479, "test_samples_per_second": 493.746, "test_steps_per_second": 15.43}, {"test_loss": 0.0749412328004837, "test_micro_f1": 0.6173913043478261, "test_micro_f1_no_misc": 0.7030716723549488, "test_runtime": 4.6471, "test_samples_per_second": 440.707, "test_steps_per_second": 13.772}, {"test_loss": 0.061632029712200165, "test_micro_f1": 0.6602150537634409, "test_micro_f1_no_misc": 0.7103960396039604, "test_runtime": 5.0146, "test_samples_per_second": 408.408, "test_steps_per_second": 12.763}, {"test_loss": 0.06758402287960052, "test_micro_f1": 0.6148007590132827, "test_micro_f1_no_misc": 0.6760411032990806, "test_runtime": 4.7488, "test_samples_per_second": 431.264, "test_steps_per_second": 13.477}, {"test_loss": 0.06749022752046585, "test_micro_f1": 0.6229348882410107, "test_micro_f1_no_misc": 0.6912899669239251, "test_runtime": 4.9734, "test_samples_per_second": 411.794, "test_steps_per_second": 12.869}]}, "total": {"test_micro_f1": 63.50704583497835, "test_micro_f1_se": 1.3335366118643384, "test_micro_f1_no_misc": 69.62305579770225, "test_micro_f1_no_misc_se": 0.8769045336007737}}, "num_model_parameters": 68066313, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.07489348948001862, "test_micro_f1": 0.782852768563409, "test_micro_f1_no_misc": 0.8080601092896176, "test_runtime": 5.5623, "test_samples_per_second": 368.194, "test_steps_per_second": 11.506}, {"test_loss": 0.06709232926368713, "test_micro_f1": 0.7791991101223581, "test_micro_f1_no_misc": 0.8047722342733189, "test_runtime": 4.2875, "test_samples_per_second": 477.67, "test_steps_per_second": 14.927}, {"test_loss": 0.07179579138755798, "test_micro_f1": 0.7503949447077409, "test_micro_f1_no_misc": 0.7780513542033064, "test_runtime": 5.525, "test_samples_per_second": 370.676, "test_steps_per_second": 11.584}, {"test_loss": 0.07160244882106781, "test_micro_f1": 0.7662538699690403, "test_micro_f1_no_misc": 0.7950877192982457, "test_runtime": 5.1909, "test_samples_per_second": 394.536, "test_steps_per_second": 12.329}, {"test_loss": 0.07820554077625275, "test_micro_f1": 0.7436188315371526, "test_micro_f1_no_misc": 0.7737556561085973, "test_runtime": 5.4313, "test_samples_per_second": 377.076, "test_steps_per_second": 11.784}, {"test_loss": 0.07679767906665802, "test_micro_f1": 0.7795580110497237, "test_micro_f1_no_misc": 0.7932960893854748, "test_runtime": 5.3815, "test_samples_per_second": 380.564, "test_steps_per_second": 11.893}, {"test_loss": 0.07727460563182831, "test_micro_f1": 0.7811993517017828, "test_micro_f1_no_misc": 0.8012889366272825, "test_runtime": 5.6132, "test_samples_per_second": 364.855, "test_steps_per_second": 11.402}, {"test_loss": 0.06701348721981049, "test_micro_f1": 0.7738161559888579, "test_micro_f1_no_misc": 0.8031437125748503, "test_runtime": 5.46, "test_samples_per_second": 375.09, "test_steps_per_second": 11.722}, {"test_loss": 0.07101922482252121, "test_micro_f1": 0.7713454929949776, "test_micro_f1_no_misc": 0.7899159663865547, "test_runtime": 5.216, "test_samples_per_second": 392.642, "test_steps_per_second": 12.27}, {"test_loss": 0.07268506288528442, "test_micro_f1": 0.790886899918633, "test_micro_f1_no_misc": 0.8111432706222864, "test_runtime": 4.5639, "test_samples_per_second": 448.738, "test_steps_per_second": 14.023}]}, "total": {"test_micro_f1": 77.19125436553675, "test_micro_f1_se": 0.9186279816468194, "test_micro_f1_no_misc": 79.58515048769536, "test_micro_f1_no_misc_se": 0.7709957634886199}}, "num_model_parameters": 68066313, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.05262778699398041, "test_micro_f1": 0.7623157137720246, "test_micro_f1_no_misc": 0.8181076672104405, "test_runtime": 4.3837, "test_samples_per_second": 467.185, "test_steps_per_second": 14.6}, {"test_loss": 0.039201244711875916, "test_micro_f1": 0.8094523630907728, "test_micro_f1_no_misc": 0.837344398340249, "test_runtime": 4.3061, "test_samples_per_second": 475.61, "test_steps_per_second": 14.863}, {"test_loss": 0.049985069781541824, "test_micro_f1": 0.798158640226629, "test_micro_f1_no_misc": 0.8297045101088647, "test_runtime": 4.1711, "test_samples_per_second": 491.002, "test_steps_per_second": 15.344}, {"test_loss": 0.046659596264362335, "test_micro_f1": 0.7886634009797062, "test_micro_f1_no_misc": 0.8105385509492444, "test_runtime": 3.9298, "test_samples_per_second": 521.142, "test_steps_per_second": 16.286}, {"test_loss": 0.04434506222605705, "test_micro_f1": 0.8202548625083835, "test_micro_f1_no_misc": 0.8463268365817092, "test_runtime": 4.2468, "test_samples_per_second": 482.244, "test_steps_per_second": 15.07}, {"test_loss": 0.037908025085926056, "test_micro_f1": 0.8495697074010327, "test_micro_f1_no_misc": 0.8785190898573082, "test_runtime": 4.2555, "test_samples_per_second": 481.256, "test_steps_per_second": 15.039}, {"test_loss": 0.04371882230043411, "test_micro_f1": 0.7973901098901099, "test_micro_f1_no_misc": 0.8262695685376097, "test_runtime": 3.863, "test_samples_per_second": 530.156, "test_steps_per_second": 16.567}, {"test_loss": 0.04627575725317001, "test_micro_f1": 0.7954007439972945, "test_micro_f1_no_misc": 0.8177842565597668, "test_runtime": 4.031, "test_samples_per_second": 508.057, "test_steps_per_second": 15.877}, {"test_loss": 0.044210996478796005, "test_micro_f1": 0.8044333214158026, "test_micro_f1_no_misc": 0.8237655560016057, "test_runtime": 4.0032, "test_samples_per_second": 511.597, "test_steps_per_second": 15.987}, {"test_loss": 0.04859978333115578, "test_micro_f1": 0.8036998972250772, "test_micro_f1_no_misc": 0.8381962864721486, "test_runtime": 4.1912, "test_samples_per_second": 488.643, "test_steps_per_second": 15.27}]}, "total": {"test_micro_f1": 80.29338760506833, "test_micro_f1_se": 1.3834646112690503, "test_micro_f1_no_misc": 83.26556720618946, "test_micro_f1_no_misc_se": 1.2035408549990407}}, "num_model_parameters": 68066313, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.05868992954492569, "test_micro_f1": 0.7353212419305256, "test_micro_f1_no_misc": 0.7793582533906716, "test_runtime": 4.2012, "test_samples_per_second": 487.481, "test_steps_per_second": 15.234}, {"test_loss": 0.05912995710968971, "test_micro_f1": 0.7675544794188863, "test_micro_f1_no_misc": 0.8036437246963564, "test_runtime": 4.2479, "test_samples_per_second": 482.123, "test_steps_per_second": 15.066}, {"test_loss": 0.06759839504957199, "test_micro_f1": 0.75, "test_micro_f1_no_misc": 0.7891109579600276, "test_runtime": 4.0295, "test_samples_per_second": 508.253, "test_steps_per_second": 15.883}, {"test_loss": 0.07027143239974976, "test_micro_f1": 0.7289048473967683, "test_micro_f1_no_misc": 0.774364056821936, "test_runtime": 4.0885, "test_samples_per_second": 500.916, "test_steps_per_second": 15.654}, {"test_loss": 0.07638358324766159, "test_micro_f1": 0.7480170835875534, "test_micro_f1_no_misc": 0.7982093663911846, "test_runtime": 3.9993, "test_samples_per_second": 512.092, "test_steps_per_second": 16.003}, {"test_loss": 0.06845000386238098, "test_micro_f1": 0.7633726201269265, "test_micro_f1_no_misc": 0.8105579685933846, "test_runtime": 3.9865, "test_samples_per_second": 513.734, "test_steps_per_second": 16.054}, {"test_loss": 0.06200840696692467, "test_micro_f1": 0.7424666045355701, "test_micro_f1_no_misc": 0.7901318012842177, "test_runtime": 4.2799, "test_samples_per_second": 478.514, "test_steps_per_second": 14.954}, {"test_loss": 0.06041408330202103, "test_micro_f1": 0.7857142857142858, "test_micro_f1_no_misc": 0.8191126279863482, "test_runtime": 4.2486, "test_samples_per_second": 482.044, "test_steps_per_second": 15.064}, {"test_loss": 0.07184041291475296, "test_micro_f1": 0.7342398022249691, "test_micro_f1_no_misc": 0.7804214819850444, "test_runtime": 3.9847, "test_samples_per_second": 513.969, "test_steps_per_second": 16.062}, {"test_loss": 0.06124964728951454, "test_micro_f1": 0.7757724074640562, "test_micro_f1_no_misc": 0.8139613690274484, "test_runtime": 4.0081, "test_samples_per_second": 510.967, "test_steps_per_second": 15.968}]}, "total": {"test_micro_f1": 75.31363372399541, "test_micro_f1_se": 1.1864589159601835, "test_micro_f1_no_misc": 79.5887160813662, "test_micro_f1_no_misc_se": 0.9693947562975369}}, "num_model_parameters": 68066313, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6388475894927979, "test_mcc": 0.32086360477507486, "test_macro_f1": 0.6572047746177648, "test_runtime": 2.1322, "test_samples_per_second": 960.492, "test_steps_per_second": 30.015}, {"test_loss": 0.6427990198135376, "test_mcc": 0.2440372595642707, "test_macro_f1": 0.6064698941451672, "test_runtime": 2.2579, "test_samples_per_second": 907.02, "test_steps_per_second": 28.344}, {"test_loss": 0.6565976142883301, "test_mcc": 0.32851288691304165, "test_macro_f1": 0.6555969876434891, "test_runtime": 2.2589, "test_samples_per_second": 906.635, "test_steps_per_second": 28.332}, {"test_loss": 0.6515676975250244, "test_mcc": 0.23963290787537886, "test_macro_f1": 0.5946309053997482, "test_runtime": 2.2435, "test_samples_per_second": 912.842, "test_steps_per_second": 28.526}, {"test_loss": 0.6423653364181519, "test_mcc": 0.3122015809035427, "test_macro_f1": 0.6156022406473547, "test_runtime": 2.2559, "test_samples_per_second": 907.847, "test_steps_per_second": 28.37}, {"test_loss": 0.6401476860046387, "test_mcc": 0.30313289564998397, "test_macro_f1": 0.626659552709973, "test_runtime": 2.1919, "test_samples_per_second": 934.357, "test_steps_per_second": 29.199}, {"test_loss": 0.6751893758773804, "test_mcc": 0.3021325436728567, "test_macro_f1": 0.6435692060856577, "test_runtime": 2.2402, "test_samples_per_second": 914.221, "test_steps_per_second": 28.569}, {"test_loss": 0.6467100381851196, "test_mcc": 0.31422648210877685, "test_macro_f1": 0.6432128468842171, "test_runtime": 2.2096, "test_samples_per_second": 926.853, "test_steps_per_second": 28.964}, {"test_loss": 0.6482001543045044, "test_mcc": 0.2516290932099908, "test_macro_f1": 0.6118704824587178, "test_runtime": 2.2363, "test_samples_per_second": 915.799, "test_steps_per_second": 28.619}, {"test_loss": 0.6546545028686523, "test_mcc": 0.28460631656176727, "test_macro_f1": 0.6100824655330355, "test_runtime": 2.2535, "test_samples_per_second": 908.809, "test_steps_per_second": 28.4}]}, "total": {"test_mcc": 29.00975571234684, "test_mcc_se": 2.0645797861181916, "test_macro_f1": 62.64899356125125, "test_macro_f1_se": 1.3672134625624663}}, "num_model_parameters": 68651522, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6489778757095337, "test_mcc": 0.27728893306805114, "test_macro_f1": 0.6107710771975087, "test_runtime": 2.2252, "test_samples_per_second": 920.361, "test_steps_per_second": 28.761}, {"test_loss": 0.6230524778366089, "test_mcc": 0.39066531737929194, "test_macro_f1": 0.691587498278948, "test_runtime": 2.2813, "test_samples_per_second": 897.725, "test_steps_per_second": 28.054}, {"test_loss": 0.6236303448677063, "test_mcc": 0.3117965301751545, "test_macro_f1": 0.6558926268297364, "test_runtime": 2.2339, "test_samples_per_second": 916.77, "test_steps_per_second": 28.649}, {"test_loss": 0.6358810663223267, "test_mcc": 0.3789127545243479, "test_macro_f1": 0.6894504595319135, "test_runtime": 2.3244, "test_samples_per_second": 881.083, "test_steps_per_second": 27.534}, {"test_loss": 0.6001019477844238, "test_mcc": 0.3834823167546647, "test_macro_f1": 0.6908354352977145, "test_runtime": 2.2582, "test_samples_per_second": 906.911, "test_steps_per_second": 28.341}, {"test_loss": 0.6066043376922607, "test_mcc": 0.3752457049864277, "test_macro_f1": 0.667222084352584, "test_runtime": 2.2276, "test_samples_per_second": 919.362, "test_steps_per_second": 28.73}, {"test_loss": 0.6118993759155273, "test_mcc": 0.37126796819051255, "test_macro_f1": 0.6843668288958871, "test_runtime": 2.1636, "test_samples_per_second": 946.559, "test_steps_per_second": 29.58}, {"test_loss": 0.606604814529419, "test_mcc": 0.3806521919258711, "test_macro_f1": 0.6900880258158142, "test_runtime": 2.1988, "test_samples_per_second": 931.422, "test_steps_per_second": 29.107}, {"test_loss": 0.6470713019371033, "test_mcc": 0.37529377704629713, "test_macro_f1": 0.6843997234810661, "test_runtime": 2.1973, "test_samples_per_second": 932.061, "test_steps_per_second": 29.127}, {"test_loss": 0.6116140484809875, "test_mcc": 0.3553894559853872, "test_macro_f1": 0.6734705620736077, "test_runtime": 2.2379, "test_samples_per_second": 915.136, "test_steps_per_second": 28.598}]}, "total": {"test_mcc": 35.99994950036006, "test_mcc_se": 2.268415921811771, "test_macro_f1": 67.3808432175478, "test_macro_f1_se": 1.5567366058064054}}, "num_model_parameters": 68651522, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6358458399772644, "test_mcc": 0.3538416231663423, "test_macro_f1": 0.6769206499447863, "test_runtime": 2.0334, "test_samples_per_second": 1007.163, "test_steps_per_second": 31.474}, {"test_loss": 0.6162962913513184, "test_mcc": 0.3801651959003189, "test_macro_f1": 0.6735861672186718, "test_runtime": 2.0723, "test_samples_per_second": 988.257, "test_steps_per_second": 30.883}, {"test_loss": 0.6219395399093628, "test_mcc": 0.36014865262011003, "test_macro_f1": 0.6693205801959872, "test_runtime": 2.0533, "test_samples_per_second": 997.422, "test_steps_per_second": 31.169}, {"test_loss": 0.6922799944877625, "test_mcc": 0.04909940147374931, "test_macro_f1": 0.5126671795227036, "test_runtime": 2.0913, "test_samples_per_second": 979.279, "test_steps_per_second": 30.602}, {"test_loss": 0.6200753450393677, "test_mcc": 0.3537457638458294, "test_macro_f1": 0.6716370049703384, "test_runtime": 2.1029, "test_samples_per_second": 973.883, "test_steps_per_second": 30.434}, {"test_loss": 0.5895946025848389, "test_mcc": 0.3745824541083998, "test_macro_f1": 0.6791880685685996, "test_runtime": 2.0112, "test_samples_per_second": 1018.299, "test_steps_per_second": 31.822}, {"test_loss": 0.6049299240112305, "test_mcc": 0.39081259546996966, "test_macro_f1": 0.6952252099246533, "test_runtime": 2.0056, "test_samples_per_second": 1021.131, "test_steps_per_second": 31.91}, {"test_loss": 0.6403192281723022, "test_mcc": 0.239666580432858, "test_macro_f1": 0.6196085004598149, "test_runtime": 2.0421, "test_samples_per_second": 1002.889, "test_steps_per_second": 31.34}, {"test_loss": 0.6249622106552124, "test_mcc": 0.3291745255690971, "test_macro_f1": 0.6302484732035241, "test_runtime": 2.021, "test_samples_per_second": 1013.365, "test_steps_per_second": 31.668}, {"test_loss": 0.6355522871017456, "test_mcc": 0.3187103513725825, "test_macro_f1": 0.6338369921538464, "test_runtime": 2.0975, "test_samples_per_second": 976.411, "test_steps_per_second": 30.513}]}, "total": {"test_mcc": 31.49947143959257, "test_mcc_se": 6.374115138797761, "test_macro_f1": 64.62238826162927, "test_macro_f1_se": 3.28701721765487}}, "num_model_parameters": 68651522, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6924291849136353, "test_mcc": 0.011981371128893692, "test_macro_f1": 0.4879101224922875, "test_runtime": 2.1461, "test_samples_per_second": 954.267, "test_steps_per_second": 29.821}, {"test_loss": 0.6310205459594727, "test_mcc": 0.2985013753593957, "test_macro_f1": 0.6277418618941265, "test_runtime": 2.2009, "test_samples_per_second": 930.527, "test_steps_per_second": 29.079}, {"test_loss": 0.6395875215530396, "test_mcc": 0.3005492409775473, "test_macro_f1": 0.6454776314307851, "test_runtime": 2.207, "test_samples_per_second": 927.955, "test_steps_per_second": 28.999}, {"test_loss": 0.6921131610870361, "test_mcc": 0.039700202518047754, "test_macro_f1": 0.5055319357577819, "test_runtime": 2.113, "test_samples_per_second": 969.258, "test_steps_per_second": 30.289}, {"test_loss": 0.6270883083343506, "test_mcc": 0.32283139665607113, "test_macro_f1": 0.650867711593846, "test_runtime": 2.1356, "test_samples_per_second": 958.982, "test_steps_per_second": 29.968}, {"test_loss": 0.6459946632385254, "test_mcc": 0.279156780639077, "test_macro_f1": 0.6326367868197217, "test_runtime": 2.2385, "test_samples_per_second": 914.882, "test_steps_per_second": 28.59}, {"test_loss": 0.6511306762695312, "test_mcc": 0.23111054964458447, "test_macro_f1": 0.6059993603321445, "test_runtime": 2.1837, "test_samples_per_second": 937.845, "test_steps_per_second": 29.308}, {"test_loss": 0.6282384395599365, "test_mcc": 0.3082433094764983, "test_macro_f1": 0.6540457766867174, "test_runtime": 2.1465, "test_samples_per_second": 954.093, "test_steps_per_second": 29.815}, {"test_loss": 0.6421023011207581, "test_mcc": 0.2793138089099365, "test_macro_f1": 0.636695136864798, "test_runtime": 2.1373, "test_samples_per_second": 958.224, "test_steps_per_second": 29.944}, {"test_loss": 0.6356846690177917, "test_mcc": 0.3346268087690096, "test_macro_f1": 0.6538813636384759, "test_runtime": 2.1913, "test_samples_per_second": 934.608, "test_steps_per_second": 29.206}]}, "total": {"test_mcc": 24.060148440790613, "test_mcc_se": 7.240742790908388, "test_macro_f1": 61.007876875106845, "test_macro_f1_se": 3.8190517445391343}}, "num_model_parameters": 68651522, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_em": 41.673121611154144, "test_f1": 46.16031999080366}, {"test_em": 41.24031007751938, "test_f1": 45.026691110480435}, {"test_em": 37.01700154559506, "test_f1": 41.62185199846624}, {"test_em": 34.26791277258567, "test_f1": 38.04159239992135}, {"test_em": 42.3938223938224, "test_f1": 45.69235103445629}, {"test_em": 43.71626831148805, "test_f1": 47.422270641529906}, {"test_em": 42.74867122247532, "test_f1": 46.718213635633084}, {"test_em": 43.13421256788208, "test_f1": 46.78807813742607}, {"test_em": 36.15686274509804, "test_f1": 39.96532029724528}, {"test_em": 41.07142857142857, "test_f1": 44.59059400005116}]}, "total": {"test_em": 40.341961181904864, "test_em_se": 2.04275733900634, "test_f1": 44.20272832460135, "test_f1_se": 1.9906177176739188}}, "num_model_parameters": 68060930, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_em": 36.56080557707204, "test_f1": 40.58452892708374}, {"test_em": 39.224806201550386, "test_f1": 43.534257435120224}, {"test_em": 32.07109737248841, "test_f1": 36.46772808114271}, {"test_em": 35.82554517133956, "test_f1": 39.534691018497384}, {"test_em": 35.5984555984556, "test_f1": 39.91595507766883}, {"test_em": 39.321511179645334, "test_f1": 43.79028615576162}, {"test_em": 38.49658314350797, "test_f1": 43.15751110185039}, {"test_em": 41.03956555469356, "test_f1": 45.3037902273696}, {"test_em": 35.372549019607845, "test_f1": 40.506469404247596}, {"test_em": 33.69565217391305, "test_f1": 38.80903444160251}]}, "total": {"test_em": 36.720657099227374, "test_em_se": 1.7225546622319325, "test_f1": 41.16042518703446, "test_f1_se": 1.68109345792956}}, "num_model_parameters": 68060930, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_em": 39.039504260263364, "test_f1": 43.936786533628705}, {"test_em": 40.310077519379846, "test_f1": 44.55218954249466}, {"test_em": 36.244204018547144, "test_f1": 41.121447138252194}, {"test_em": 44.39252336448598, "test_f1": 48.802996971977194}, {"test_em": 40.38610038610039, "test_f1": 45.83812715167635}, {"test_em": 40.40092521202776, "test_f1": 43.839052049850345}, {"test_em": 43.81169324221716, "test_f1": 47.482161872152496}, {"test_em": 42.82389449185415, "test_f1": 47.29771693897168}, {"test_em": 43.13725490196079, "test_f1": 47.74527171430087}, {"test_em": 43.7111801242236, "test_f1": 48.43277121778587}]}, "total": {"test_em": 41.425735752106014, "test_em_se": 1.607255333055468, "test_f1": 45.904852113109044, "test_f1_se": 1.5386057546036638}}, "num_model_parameters": 68060930, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.3984375, "test_mcc": 0.7372492959362836, "test_macro_f1": 0.7204915916470437, "test_runtime": 14.5609, "test_samples_per_second": 140.65, "test_steps_per_second": 17.581}, {"test_loss": 0.4533945918083191, "test_mcc": 0.698930492541809, "test_macro_f1": 0.5893322572378891, "test_runtime": 13.7862, "test_samples_per_second": 148.554, "test_steps_per_second": 18.569}, {"test_loss": 0.41173702478408813, "test_mcc": 0.72276460367813, "test_macro_f1": 0.6847773802944258, "test_runtime": 17.5545, "test_samples_per_second": 116.665, "test_steps_per_second": 58.333}, {"test_loss": 0.3624541163444519, "test_mcc": 0.7782019130210601, "test_macro_f1": 0.6854888159561942, "test_runtime": 17.1464, "test_samples_per_second": 119.442, "test_steps_per_second": 59.721}, {"test_loss": 0.4028565287590027, "test_mcc": 0.7289468242116157, "test_macro_f1": 0.7110382058086097, "test_runtime": 17.3895, "test_samples_per_second": 117.772, "test_steps_per_second": 58.886}, {"test_loss": 0.42806822061538696, "test_mcc": 0.7156905556529364, "test_macro_f1": 0.6450916113838976, "test_runtime": 17.5488, "test_samples_per_second": 116.703, "test_steps_per_second": 58.352}, {"test_loss": 0.4013998210430145, "test_mcc": 0.7407682983685472, "test_macro_f1": 0.6814921332084133, "test_runtime": 17.7659, "test_samples_per_second": 115.277, "test_steps_per_second": 57.638}, {"test_loss": 0.4403309226036072, "test_mcc": 0.7235355025160013, "test_macro_f1": 0.6439745928876962, "test_runtime": 17.6949, "test_samples_per_second": 115.74, "test_steps_per_second": 57.87}, {"test_loss": 0.3779985308647156, "test_mcc": 0.7623103348093778, "test_macro_f1": 0.7355931250498431, "test_runtime": 17.4822, "test_samples_per_second": 117.148, "test_steps_per_second": 58.574}, {"test_loss": 0.3920373022556305, "test_mcc": 0.7582285259166421, "test_macro_f1": 0.7637518785588083, "test_runtime": 17.5045, "test_samples_per_second": 116.998, "test_steps_per_second": 58.499}]}, "total": {"test_mcc": 73.66626346652403, "test_mcc_se": 1.4832476494528133, "test_macro_f1": 68.6103159203282, "test_macro_f1_se": 3.1419606610960047}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.7979549169540405, "test_mcc": 0.49033500495431676, "test_macro_f1": 0.6636398081816386, "test_runtime": 4.3528, "test_samples_per_second": 470.502, "test_steps_per_second": 14.703}, {"test_loss": 0.775367259979248, "test_mcc": 0.5215445680345615, "test_macro_f1": 0.6806798782272088, "test_runtime": 4.3646, "test_samples_per_second": 469.225, "test_steps_per_second": 14.663}, {"test_loss": 0.8322739601135254, "test_mcc": 0.45045307578193516, "test_macro_f1": 0.634246647739133, "test_runtime": 4.3323, "test_samples_per_second": 472.727, "test_steps_per_second": 14.773}, {"test_loss": 0.7992556691169739, "test_mcc": 0.5042979336090603, "test_macro_f1": 0.672496400514615, "test_runtime": 4.2906, "test_samples_per_second": 477.323, "test_steps_per_second": 14.916}, {"test_loss": 0.8251465559005737, "test_mcc": 0.4726934462120212, "test_macro_f1": 0.6535089379007578, "test_runtime": 4.2479, "test_samples_per_second": 482.116, "test_steps_per_second": 15.066}, {"test_loss": 0.8414341807365417, "test_mcc": 0.4502274260249796, "test_macro_f1": 0.6382925175690443, "test_runtime": 4.2807, "test_samples_per_second": 478.426, "test_steps_per_second": 14.951}, {"test_loss": 0.7989815473556519, "test_mcc": 0.4801701688209663, "test_macro_f1": 0.6571440129461865, "test_runtime": 4.3108, "test_samples_per_second": 475.087, "test_steps_per_second": 14.846}, {"test_loss": 0.8041589856147766, "test_mcc": 0.4824394826364261, "test_macro_f1": 0.659407837873231, "test_runtime": 4.3425, "test_samples_per_second": 471.62, "test_steps_per_second": 14.738}, {"test_loss": 0.7913665175437927, "test_mcc": 0.478379560622582, "test_macro_f1": 0.6537045445788978, "test_runtime": 4.2868, "test_samples_per_second": 477.748, "test_steps_per_second": 14.93}, {"test_loss": 0.8464223742485046, "test_mcc": 0.45245412460627266, "test_macro_f1": 0.6359316588226688, "test_runtime": 4.2444, "test_samples_per_second": 482.514, "test_steps_per_second": 15.079}]}, "total": {"test_mcc": 47.829947913031226, "test_mcc_se": 1.4571573031044984, "test_macro_f1": 65.49052244353382, "test_macro_f1_se": 0.9560807696728523}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.7557374238967896, "test_mcc": 0.5645601294547659, "test_macro_f1": 0.6943276147064991, "test_runtime": 3.6695, "test_samples_per_second": 558.11, "test_steps_per_second": 17.441}, {"test_loss": 0.7330427169799805, "test_mcc": 0.5056110731322936, "test_macro_f1": 0.6556012257321041, "test_runtime": 3.4183, "test_samples_per_second": 599.131, "test_steps_per_second": 18.723}, {"test_loss": 0.7310600876808167, "test_mcc": 0.5389721362497456, "test_macro_f1": 0.6790891127545179, "test_runtime": 3.5217, "test_samples_per_second": 581.539, "test_steps_per_second": 18.173}, {"test_loss": 0.7318670153617859, "test_mcc": 0.5296269742687791, "test_macro_f1": 0.6714640392998392, "test_runtime": 3.6083, "test_samples_per_second": 567.578, "test_steps_per_second": 17.737}, {"test_loss": 0.7120949029922485, "test_mcc": 0.5580522625886081, "test_macro_f1": 0.68331101054866, "test_runtime": 3.5521, "test_samples_per_second": 576.564, "test_steps_per_second": 18.018}, {"test_loss": 0.723419725894928, "test_mcc": 0.5644376388058656, "test_macro_f1": 0.6912611462699495, "test_runtime": 3.6434, "test_samples_per_second": 562.108, "test_steps_per_second": 17.566}, {"test_loss": 0.7128522992134094, "test_mcc": 0.5597286532799823, "test_macro_f1": 0.6911865905014775, "test_runtime": 3.4706, "test_samples_per_second": 590.096, "test_steps_per_second": 18.441}, {"test_loss": 0.7408984899520874, "test_mcc": 0.5320390313452394, "test_macro_f1": 0.676316913569298, "test_runtime": 3.576, "test_samples_per_second": 572.701, "test_steps_per_second": 17.897}, {"test_loss": 0.70038902759552, "test_mcc": 0.5424830579904157, "test_macro_f1": 0.692961832154165, "test_runtime": 3.7095, "test_samples_per_second": 552.101, "test_steps_per_second": 17.253}, {"test_loss": 0.7028564810752869, "test_mcc": 0.550180233372778, "test_macro_f1": 0.6895823008490759, "test_runtime": 3.6856, "test_samples_per_second": 555.675, "test_steps_per_second": 17.365}]}, "total": {"test_mcc": 54.45691190488474, "test_mcc_se": 1.1634411732373366, "test_macro_f1": 68.25101786385585, "test_macro_f1_se": 0.7584223096425061}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.05460071563720703, "test_micro_f1": 0.6887218045112782, "test_micro_f1_no_misc": 0.7603498542274053, "test_runtime": 7.3027, "test_samples_per_second": 280.442, "test_steps_per_second": 8.764}, {"test_loss": 0.05584348365664482, "test_micro_f1": 0.7451797811360084, "test_micro_f1_no_misc": 0.8021015761821365, "test_runtime": 7.017, "test_samples_per_second": 291.861, "test_steps_per_second": 9.121}, {"test_loss": 0.050929956138134, "test_micro_f1": 0.7770137524557957, "test_micro_f1_no_misc": 0.8123309897241752, "test_runtime": 6.5249, "test_samples_per_second": 313.874, "test_steps_per_second": 9.809}, {"test_loss": 0.05707508325576782, "test_micro_f1": 0.6764112903225806, "test_micro_f1_no_misc": 0.7283680175246441, "test_runtime": 7.1894, "test_samples_per_second": 284.865, "test_steps_per_second": 8.902}, {"test_loss": 0.056872885674238205, "test_micro_f1": 0.6981481481481482, "test_micro_f1_no_misc": 0.7661161427810336, "test_runtime": 7.2268, "test_samples_per_second": 283.391, "test_steps_per_second": 8.856}, {"test_loss": 0.04861561208963394, "test_micro_f1": 0.7824463118580764, "test_micro_f1_no_misc": 0.825040128410915, "test_runtime": 5.8798, "test_samples_per_second": 348.309, "test_steps_per_second": 10.885}, {"test_loss": 0.05310695990920067, "test_micro_f1": 0.7187650747708634, "test_micro_f1_no_misc": 0.789153292750415, "test_runtime": 5.9519, "test_samples_per_second": 344.093, "test_steps_per_second": 10.753}, {"test_loss": 0.050765275955200195, "test_micro_f1": 0.7172995780590717, "test_micro_f1_no_misc": 0.7623529411764706, "test_runtime": 7.0072, "test_samples_per_second": 292.271, "test_steps_per_second": 9.133}, {"test_loss": 0.04640527069568634, "test_micro_f1": 0.7516650808753569, "test_micro_f1_no_misc": 0.7950643776824035, "test_runtime": 6.5345, "test_samples_per_second": 313.413, "test_steps_per_second": 9.794}, {"test_loss": 0.0519963800907135, "test_micro_f1": 0.7478912839737581, "test_micro_f1_no_misc": 0.818836565096953, "test_runtime": 7.2061, "test_samples_per_second": 284.205, "test_steps_per_second": 8.881}]}, "total": {"test_micro_f1": 73.03542106110939, "test_micro_f1_se": 2.2497120790667102, "test_micro_f1_no_misc": 78.59713885556553, "test_micro_f1_no_misc_se": 1.9138293485184685}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.05361787974834442, "test_micro_f1": 0.8130412633723891, "test_micro_f1_no_misc": 0.8315290933694182, "test_runtime": 8.1173, "test_samples_per_second": 252.301, "test_steps_per_second": 7.884}, {"test_loss": 0.04825267195701599, "test_micro_f1": 0.8450704225352114, "test_micro_f1_no_misc": 0.8738805970149254, "test_runtime": 6.703, "test_samples_per_second": 305.535, "test_steps_per_second": 9.548}, {"test_loss": 0.05234106257557869, "test_micro_f1": 0.8276045830002664, "test_micro_f1_no_misc": 0.8425593098490295, "test_runtime": 8.1091, "test_samples_per_second": 252.555, "test_steps_per_second": 7.892}, {"test_loss": 0.055265963077545166, "test_micro_f1": 0.8185071574642127, "test_micro_f1_no_misc": 0.8436860068259385, "test_runtime": 7.9124, "test_samples_per_second": 258.836, "test_steps_per_second": 8.089}, {"test_loss": 0.05708770453929901, "test_micro_f1": 0.7906584130557118, "test_micro_f1_no_misc": 0.82091212458287, "test_runtime": 8.1948, "test_samples_per_second": 249.915, "test_steps_per_second": 7.81}, {"test_loss": 0.05264045298099518, "test_micro_f1": 0.8687377553876294, "test_micro_f1_no_misc": 0.879053796260969, "test_runtime": 8.0319, "test_samples_per_second": 254.984, "test_steps_per_second": 7.968}, {"test_loss": 0.05686180293560028, "test_micro_f1": 0.8352692713833157, "test_micro_f1_no_misc": 0.8515130190007038, "test_runtime": 8.19, "test_samples_per_second": 250.06, "test_steps_per_second": 7.814}, {"test_loss": 0.05295860022306442, "test_micro_f1": 0.8211517165005536, "test_micro_f1_no_misc": 0.8302300109529025, "test_runtime": 8.1478, "test_samples_per_second": 251.356, "test_steps_per_second": 7.855}, {"test_loss": 0.05483093112707138, "test_micro_f1": 0.822210357714896, "test_micro_f1_no_misc": 0.8274596182085169, "test_runtime": 7.8484, "test_samples_per_second": 260.944, "test_steps_per_second": 8.155}, {"test_loss": 0.050522539764642715, "test_micro_f1": 0.8393094289508632, "test_micro_f1_no_misc": 0.8573481854114265, "test_runtime": 6.9579, "test_samples_per_second": 294.342, "test_steps_per_second": 9.198}]}, "total": {"test_micro_f1": 82.8156036936505, "test_micro_f1_se": 1.293585700770601, "test_micro_f1_no_misc": 84.581717614767, "test_micro_f1_no_misc_se": 1.2182803628304035}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.034224193543195724, "test_micro_f1": 0.8892128279883382, "test_micro_f1_no_misc": 0.916321458160729, "test_runtime": 6.3793, "test_samples_per_second": 321.036, "test_steps_per_second": 10.032}, {"test_loss": 0.03502294793725014, "test_micro_f1": 0.8401759530791789, "test_micro_f1_no_misc": 0.8769106999195495, "test_runtime": 6.3291, "test_samples_per_second": 323.584, "test_steps_per_second": 10.112}, {"test_loss": 0.034186091274023056, "test_micro_f1": 0.8737588652482269, "test_micro_f1_no_misc": 0.9021006738010305, "test_runtime": 5.9166, "test_samples_per_second": 346.146, "test_steps_per_second": 10.817}, {"test_loss": 0.031022369861602783, "test_micro_f1": 0.8730214562082307, "test_micro_f1_no_misc": 0.8929133858267717, "test_runtime": 5.8469, "test_samples_per_second": 350.273, "test_steps_per_second": 10.946}, {"test_loss": 0.03683383762836456, "test_micro_f1": 0.8311170212765957, "test_micro_f1_no_misc": 0.867674161444895, "test_runtime": 6.3009, "test_samples_per_second": 325.031, "test_steps_per_second": 10.157}, {"test_loss": 0.026994876563549042, "test_micro_f1": 0.8955837042108866, "test_micro_f1_no_misc": 0.9188149288187765, "test_runtime": 6.3723, "test_samples_per_second": 321.389, "test_steps_per_second": 10.043}, {"test_loss": 0.030338771641254425, "test_micro_f1": 0.8902734510211145, "test_micro_f1_no_misc": 0.9072720277029627, "test_runtime": 5.7761, "test_samples_per_second": 354.565, "test_steps_per_second": 11.08}, {"test_loss": 0.02844446897506714, "test_micro_f1": 0.8891957197100449, "test_micro_f1_no_misc": 0.9070464767616193, "test_runtime": 5.7729, "test_samples_per_second": 354.761, "test_steps_per_second": 11.086}, {"test_loss": 0.0319068618118763, "test_micro_f1": 0.8826695371367062, "test_micro_f1_no_misc": 0.8992688870836718, "test_runtime": 5.8268, "test_samples_per_second": 351.479, "test_steps_per_second": 10.984}, {"test_loss": 0.03286292403936386, "test_micro_f1": 0.8908026179813985, "test_micro_f1_no_misc": 0.9189189189189189, "test_runtime": 6.2719, "test_samples_per_second": 326.536, "test_steps_per_second": 10.204}]}, "total": {"test_micro_f1": 87.5581115386072, "test_micro_f1_se": 1.3873980326855673, "test_micro_f1_no_misc": 90.07241618438925, "test_micro_f1_no_misc_se": 1.075294423507468}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.04272138327360153, "test_micro_f1": 0.8218249075215783, "test_micro_f1_no_misc": 0.8578183046268153, "test_runtime": 5.8253, "test_samples_per_second": 351.571, "test_steps_per_second": 10.987}, {"test_loss": 0.04637790843844414, "test_micro_f1": 0.8268998793727382, "test_micro_f1_no_misc": 0.8568561872909699, "test_runtime": 6.0194, "test_samples_per_second": 340.236, "test_steps_per_second": 10.632}, {"test_loss": 0.047335587441921234, "test_micro_f1": 0.7992777610592837, "test_micro_f1_no_misc": 0.8357810413885182, "test_runtime": 5.8905, "test_samples_per_second": 347.679, "test_steps_per_second": 10.865}, {"test_loss": 0.052097074687480927, "test_micro_f1": 0.8031353632800723, "test_micro_f1_no_misc": 0.8328894806924101, "test_runtime": 6.1069, "test_samples_per_second": 335.358, "test_steps_per_second": 10.48}, {"test_loss": 0.05681322515010834, "test_micro_f1": 0.8126696832579187, "test_micro_f1_no_misc": 0.8501742160278747, "test_runtime": 5.8368, "test_samples_per_second": 350.877, "test_steps_per_second": 10.965}, {"test_loss": 0.05026167631149292, "test_micro_f1": 0.830188679245283, "test_micro_f1_no_misc": 0.8630648997621475, "test_runtime": 6.0186, "test_samples_per_second": 340.278, "test_steps_per_second": 10.634}, {"test_loss": 0.043812818825244904, "test_micro_f1": 0.8173431734317342, "test_micro_f1_no_misc": 0.8546075085324232, "test_runtime": 6.1117, "test_samples_per_second": 335.098, "test_steps_per_second": 10.472}, {"test_loss": 0.0414632111787796, "test_micro_f1": 0.8406862745098039, "test_micro_f1_no_misc": 0.8753462603878116, "test_runtime": 6.0435, "test_samples_per_second": 338.875, "test_steps_per_second": 10.59}, {"test_loss": 0.047710955142974854, "test_micro_f1": 0.823854903166308, "test_micro_f1_no_misc": 0.8549671166493598, "test_runtime": 5.5544, "test_samples_per_second": 368.717, "test_steps_per_second": 11.522}, {"test_loss": 0.03882468119263649, "test_micro_f1": 0.8640391078521235, "test_micro_f1_no_misc": 0.8838315217391305, "test_runtime": 5.8242, "test_samples_per_second": 351.634, "test_steps_per_second": 10.989}]}, "total": {"test_micro_f1": 82.39919732696842, "test_micro_f1_se": 1.159962742177443, "test_micro_f1_no_misc": 85.6533653709746, "test_micro_f1_no_misc_se": 0.9645960905097428}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.69027179479599, "test_mcc": 0.10027296511360077, "test_macro_f1": 0.49159064109725065, "test_runtime": 3.2116, "test_samples_per_second": 637.695, "test_steps_per_second": 19.928}, {"test_loss": 0.6855356693267822, "test_mcc": 0.1414427487436102, "test_macro_f1": 0.570714705244806, "test_runtime": 3.3549, "test_samples_per_second": 610.453, "test_steps_per_second": 19.077}, {"test_loss": 0.6792474985122681, "test_mcc": 0.12483384276333645, "test_macro_f1": 0.4529704896253224, "test_runtime": 3.3208, "test_samples_per_second": 616.723, "test_steps_per_second": 19.273}, {"test_loss": 0.6816986203193665, "test_mcc": 0.1548788475451093, "test_macro_f1": 0.5629200527644906, "test_runtime": 3.2289, "test_samples_per_second": 634.278, "test_steps_per_second": 19.821}, {"test_loss": 0.6860703229904175, "test_mcc": 0.14312933106730366, "test_macro_f1": 0.5112414963826554, "test_runtime": 3.2513, "test_samples_per_second": 629.911, "test_steps_per_second": 19.685}, {"test_loss": 0.6740521192550659, "test_mcc": 0.2821978398538997, "test_macro_f1": 0.6186809603511818, "test_runtime": 3.2278, "test_samples_per_second": 634.49, "test_steps_per_second": 19.828}, {"test_loss": 0.6911693811416626, "test_mcc": 0.07783880246777271, "test_macro_f1": 0.5243053377657907, "test_runtime": 3.2792, "test_samples_per_second": 624.538, "test_steps_per_second": 19.517}, {"test_loss": 0.6924001574516296, "test_mcc": 0.06994339393643063, "test_macro_f1": 0.42314838791744463, "test_runtime": 3.3615, "test_samples_per_second": 609.257, "test_steps_per_second": 19.039}, {"test_loss": 0.6854655146598816, "test_mcc": 0.16696652750899285, "test_macro_f1": 0.5793633422784694, "test_runtime": 3.2831, "test_samples_per_second": 623.795, "test_steps_per_second": 19.494}, {"test_loss": 0.6678285598754883, "test_mcc": 0.2798437081446339, "test_macro_f1": 0.5940566371137506, "test_runtime": 3.2716, "test_samples_per_second": 625.993, "test_steps_per_second": 19.562}]}, "total": {"test_mcc": 15.4134800714469, "test_mcc_se": 4.5882052718797475, "test_macro_f1": 53.289920505411615, "test_macro_f1_se": 3.934784829697723}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.6846097707748413, "test_mcc": 0.13821195525502725, "test_macro_f1": 0.48651828642782935, "test_runtime": 3.7088, "test_samples_per_second": 552.205, "test_steps_per_second": 17.256}, {"test_loss": 0.6903553009033203, "test_mcc": 0.06675927064969639, "test_macro_f1": 0.533196002136263, "test_runtime": 3.8206, "test_samples_per_second": 536.038, "test_steps_per_second": 16.751}, {"test_loss": 0.6934489011764526, "test_mcc": -0.0012579298467452137, "test_macro_f1": 0.49781090403461015, "test_runtime": 3.6944, "test_samples_per_second": 554.358, "test_steps_per_second": 17.324}, {"test_loss": 0.6951579451560974, "test_mcc": -0.030024321887565233, "test_macro_f1": 0.39153496908505453, "test_runtime": 3.8215, "test_samples_per_second": 535.914, "test_steps_per_second": 16.747}, {"test_loss": 0.6869548559188843, "test_mcc": 0.14715233458946536, "test_macro_f1": 0.507863592396782, "test_runtime": 3.6481, "test_samples_per_second": 561.385, "test_steps_per_second": 17.543}, {"test_loss": 0.6734711527824402, "test_mcc": 0.24074006487661062, "test_macro_f1": 0.6023920375651177, "test_runtime": 3.7131, "test_samples_per_second": 551.56, "test_steps_per_second": 17.236}, {"test_loss": 0.6917335391044617, "test_mcc": 0.07815694042610347, "test_macro_f1": 0.40629567691280444, "test_runtime": 3.5845, "test_samples_per_second": 571.352, "test_steps_per_second": 17.855}, {"test_loss": 0.684430718421936, "test_mcc": 0.15729579498884932, "test_macro_f1": 0.41008005631833505, "test_runtime": 3.6409, "test_samples_per_second": 562.495, "test_steps_per_second": 17.578}, {"test_loss": 0.6819944977760315, "test_mcc": 0.19530894259461495, "test_macro_f1": 0.533099515777377, "test_runtime": 3.633, "test_samples_per_second": 563.728, "test_steps_per_second": 17.616}, {"test_loss": 0.6735408306121826, "test_mcc": 0.19471781478437866, "test_macro_f1": 0.5130925294331491, "test_runtime": 3.7379, "test_samples_per_second": 547.894, "test_steps_per_second": 17.122}]}, "total": {"test_mcc": 11.870608664304356, "test_mcc_se": 5.4689779917211, "test_macro_f1": 48.81883570087322, "test_macro_f1_se": 4.149417226319911}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.6826624870300293, "test_mcc": 0.31365676873335147, "test_macro_f1": 0.6521583666318038, "test_runtime": 3.3104, "test_samples_per_second": 618.653, "test_steps_per_second": 19.333}, {"test_loss": 0.6942108273506165, "test_mcc": -0.003343245160531744, "test_macro_f1": 0.49831399502200974, "test_runtime": 3.2856, "test_samples_per_second": 623.321, "test_steps_per_second": 19.479}, {"test_loss": 0.6903786659240723, "test_mcc": 0.08619471714215667, "test_macro_f1": 0.48686573092266583, "test_runtime": 3.3334, "test_samples_per_second": 614.386, "test_steps_per_second": 19.2}, {"test_loss": 0.6913783550262451, "test_mcc": 0.03390137781755089, "test_macro_f1": 0.5142310325721107, "test_runtime": 3.4026, "test_samples_per_second": 601.896, "test_steps_per_second": 18.809}, {"test_loss": 0.6891160607337952, "test_mcc": 0.09441417356940932, "test_macro_f1": 0.42470159021433324, "test_runtime": 3.399, "test_samples_per_second": 602.538, "test_steps_per_second": 18.829}, {"test_loss": 0.6837481260299683, "test_mcc": 0.14379923911582237, "test_macro_f1": 0.45161185483024363, "test_runtime": 3.2151, "test_samples_per_second": 636.996, "test_steps_per_second": 19.906}, {"test_loss": 0.6946583986282349, "test_mcc": 0.022467537801531132, "test_macro_f1": 0.4206057623007014, "test_runtime": 3.2842, "test_samples_per_second": 623.587, "test_steps_per_second": 19.487}, {"test_loss": 0.6839818954467773, "test_mcc": 0.16538127045051398, "test_macro_f1": 0.45011648495014445, "test_runtime": 3.2983, "test_samples_per_second": 620.932, "test_steps_per_second": 19.404}, {"test_loss": 0.6802347302436829, "test_mcc": 0.19668323217963848, "test_macro_f1": 0.5785610652458634, "test_runtime": 3.2211, "test_samples_per_second": 635.81, "test_steps_per_second": 19.869}, {"test_loss": 0.6805270314216614, "test_mcc": 0.16280390593996633, "test_macro_f1": 0.5782468072985381, "test_runtime": 3.4104, "test_samples_per_second": 600.522, "test_steps_per_second": 18.766}]}, "total": {"test_mcc": 12.15958977589409, "test_mcc_se": 5.9072452267667375, "test_macro_f1": 50.554126899884146, "test_macro_f1_se": 4.725748500372387}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_loss": 0.6881355047225952, "test_mcc": 0.10139701145766251, "test_macro_f1": 0.542218496786812, "test_runtime": 3.5092, "test_samples_per_second": 583.617, "test_steps_per_second": 18.238}, {"test_loss": 0.6883654594421387, "test_mcc": 0.13013052307143264, "test_macro_f1": 0.4486323186215808, "test_runtime": 3.6048, "test_samples_per_second": 568.132, "test_steps_per_second": 17.754}, {"test_loss": 0.6885557770729065, "test_mcc": 0.0713314505064988, "test_macro_f1": 0.5350209457444699, "test_runtime": 3.6399, "test_samples_per_second": 562.654, "test_steps_per_second": 17.583}, {"test_loss": 0.6918429732322693, "test_mcc": 0.049796054804529664, "test_macro_f1": 0.36440902855343743, "test_runtime": 3.4485, "test_samples_per_second": 593.886, "test_steps_per_second": 18.559}, {"test_loss": 0.6885234117507935, "test_mcc": 0.06863353635347719, "test_macro_f1": 0.5330423624924276, "test_runtime": 3.4703, "test_samples_per_second": 590.154, "test_steps_per_second": 18.442}, {"test_loss": 0.6923522353172302, "test_mcc": 0.05970919413138284, "test_macro_f1": 0.5288084814091876, "test_runtime": 3.5884, "test_samples_per_second": 570.725, "test_steps_per_second": 17.835}, {"test_loss": 0.6901253461837769, "test_mcc": 0.10574642680839808, "test_macro_f1": 0.45662129170265886, "test_runtime": 3.5192, "test_samples_per_second": 581.957, "test_steps_per_second": 18.186}, {"test_loss": 0.6881489753723145, "test_mcc": 0.12240099786088633, "test_macro_f1": 0.5110742895409544, "test_runtime": 3.5088, "test_samples_per_second": 583.675, "test_steps_per_second": 18.24}, {"test_loss": 0.6865302324295044, "test_mcc": 0.04252426760941885, "test_macro_f1": 0.4263043640991092, "test_runtime": 3.4938, "test_samples_per_second": 586.182, "test_steps_per_second": 18.318}, {"test_loss": 0.6894694566726685, "test_mcc": 0.14708517402447774, "test_macro_f1": 0.5110464722287382, "test_runtime": 3.5828, "test_samples_per_second": 571.627, "test_steps_per_second": 17.863}]}, "total": {"test_mcc": 8.987546366281645, "test_mcc_se": 2.2527747310379707, "test_macro_f1": 48.571780511793754, "test_macro_f1_se": 3.665180043314442}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_em": 46.78543764523625, "test_f1": 51.497374206238604}, {"test_em": 38.52713178294574, "test_f1": 42.948999219061854}, {"test_em": 36.321483771251934, "test_f1": 40.346240568995135}, {"test_em": 34.81308411214953, "test_f1": 38.397774805021974}, {"test_em": 28.571428571428573, "test_f1": 32.44654208860313}, {"test_em": 31.225905936777178, "test_f1": 34.87471645196904}, {"test_em": 30.44798785117692, "test_f1": 34.006115724992014}, {"test_em": 45.84949573312645, "test_f1": 50.51322115495982}, {"test_em": 24.784313725490197, "test_f1": 29.807252287770623}, {"test_em": 26.009316770186334, "test_f1": 30.18023122607234}]}, "total": {"test_em": 34.33355858997691, "test_em_se": 4.746781786595312, "test_f1": 38.501846773368456, "test_f1_se": 4.850648144385983}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_em": 46.630518977536795, "test_f1": 51.774664302698326}, {"test_em": 44.031007751937985, "test_f1": 49.28420481327455}, {"test_em": 48.99536321483771, "test_f1": 53.311127561442156}, {"test_em": 34.890965732087224, "test_f1": 39.114823115119705}, {"test_em": 48.18532818532819, "test_f1": 53.303103922520094}, {"test_em": 46.569005397070164, "test_f1": 52.09753947447026}, {"test_em": 49.12680334092635, "test_f1": 54.22297073067184}, {"test_em": 29.945694336695112, "test_f1": 34.45626365820208}, {"test_em": 23.686274509803923, "test_f1": 30.297147648857568}, {"test_em": 33.850931677018636, "test_f1": 38.71925732735684}]}, "total": {"test_em": 40.591189312324204, "test_em_se": 5.703956439104951, "test_f1": 45.65811025546134, "test_f1_se": 5.600409409782542}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_em": 46.78543764523625, "test_f1": 52.68253280587421}, {"test_em": 32.945736434108525, "test_f1": 37.52049636283563}, {"test_em": 47.14064914992272, "test_f1": 52.259395955857414}, {"test_em": 30.218068535825545, "test_f1": 34.882046804542384}, {"test_em": 45.01930501930502, "test_f1": 50.05613283189577}, {"test_em": 43.176561295296835, "test_f1": 47.771954973936914}, {"test_em": 46.77296886864085, "test_f1": 52.15797206385863}, {"test_em": 46.31497284716835, "test_f1": 51.404087129065324}, {"test_em": 47.294117647058826, "test_f1": 52.77319065658163}, {"test_em": 34.23913043478261, "test_f1": 38.638960939813785}]}, "total": {"test_em": 41.990694787734554, "test_em_se": 4.184797213580539, "test_f1": 47.014677052426165, "test_f1_se": 4.4109884829665}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6070674061775208, "test_mcc": 0.606934510175416, "test_macro_f1": 0.5826823315450907, "test_runtime": 8.9407, "test_samples_per_second": 229.065, "test_steps_per_second": 28.633}, {"test_loss": 0.6509135961532593, "test_mcc": 0.569772927713878, "test_macro_f1": 0.5334923343922154, "test_runtime": 8.6476, "test_samples_per_second": 236.829, "test_steps_per_second": 29.604}, {"test_loss": 0.6349799633026123, "test_mcc": 0.5776673084573348, "test_macro_f1": 0.5373075002627983, "test_runtime": 8.7832, "test_samples_per_second": 233.171, "test_steps_per_second": 29.146}, {"test_loss": 0.6005284786224365, "test_mcc": 0.5999451894409717, "test_macro_f1": 0.5619883651787118, "test_runtime": 8.5966, "test_samples_per_second": 238.235, "test_steps_per_second": 29.779}, {"test_loss": 0.606364905834198, "test_mcc": 0.6217241263991481, "test_macro_f1": 0.5695037058840641, "test_runtime": 8.5199, "test_samples_per_second": 240.379, "test_steps_per_second": 30.047}, {"test_loss": 0.639114499092102, "test_mcc": 0.5816511260439079, "test_macro_f1": 0.5373366910309879, "test_runtime": 8.7277, "test_samples_per_second": 234.656, "test_steps_per_second": 29.332}, {"test_loss": 0.6250084042549133, "test_mcc": 0.6149913628032804, "test_macro_f1": 0.550198918650202, "test_runtime": 8.5051, "test_samples_per_second": 240.796, "test_steps_per_second": 30.1}, {"test_loss": 0.6039390563964844, "test_mcc": 0.6047039099341414, "test_macro_f1": 0.5461322467176645, "test_runtime": 8.9708, "test_samples_per_second": 228.297, "test_steps_per_second": 28.537}, {"test_loss": 0.626332700252533, "test_mcc": 0.5893017686455814, "test_macro_f1": 0.5410583709139086, "test_runtime": 9.0094, "test_samples_per_second": 227.318, "test_steps_per_second": 28.415}, {"test_loss": 0.57294100522995, "test_mcc": 0.6164203210067929, "test_macro_f1": 0.5554412343251273, "test_runtime": 8.7927, "test_samples_per_second": 232.92, "test_steps_per_second": 29.115}]}, "total": {"test_mcc": 59.83112550620453, "test_mcc_se": 1.1071181092140012, "test_macro_f1": 55.15141698900771, "test_macro_f1_se": 0.9882072041970144}}, "num_model_parameters": 75548163, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 1.0394988059997559, "test_mcc": 0.32385053268617614, "test_macro_f1": 0.5441082499261966, "test_runtime": 2.6461, "test_samples_per_second": 773.968, "test_steps_per_second": 24.186}, {"test_loss": 0.9792877435684204, "test_mcc": 0.34760316993587087, "test_macro_f1": 0.5582648566400477, "test_runtime": 2.566, "test_samples_per_second": 798.132, "test_steps_per_second": 24.942}, {"test_loss": 0.9803423285484314, "test_mcc": 0.2935207229270437, "test_macro_f1": 0.5159753892870452, "test_runtime": 2.582, "test_samples_per_second": 793.171, "test_steps_per_second": 24.787}, {"test_loss": 1.0349674224853516, "test_mcc": 0.3478193859821693, "test_macro_f1": 0.5427442427851442, "test_runtime": 2.5765, "test_samples_per_second": 794.863, "test_steps_per_second": 24.839}, {"test_loss": 0.9959534406661987, "test_mcc": 0.3020822800669528, "test_macro_f1": 0.5250283198889169, "test_runtime": 2.5791, "test_samples_per_second": 794.091, "test_steps_per_second": 24.815}, {"test_loss": 1.0381441116333008, "test_mcc": 0.31794038856534046, "test_macro_f1": 0.5285377931322653, "test_runtime": 2.6657, "test_samples_per_second": 768.284, "test_steps_per_second": 24.009}, {"test_loss": 0.9807335138320923, "test_mcc": 0.34447390302580955, "test_macro_f1": 0.5435473403042873, "test_runtime": 2.5844, "test_samples_per_second": 792.454, "test_steps_per_second": 24.764}, {"test_loss": 1.0287399291992188, "test_mcc": 0.25844203904059676, "test_macro_f1": 0.4674005222033111, "test_runtime": 2.5903, "test_samples_per_second": 790.638, "test_steps_per_second": 24.707}, {"test_loss": 0.9657151699066162, "test_mcc": 0.29279089523641794, "test_macro_f1": 0.5103047616644324, "test_runtime": 2.5625, "test_samples_per_second": 799.207, "test_steps_per_second": 24.975}, {"test_loss": 0.9933691620826721, "test_mcc": 0.3014734639000963, "test_macro_f1": 0.5074113116284785, "test_runtime": 2.6043, "test_samples_per_second": 786.382, "test_steps_per_second": 24.574}]}, "total": {"test_mcc": 31.299967813664743, "test_mcc_se": 1.7962503829641023, "test_macro_f1": 52.433227874601265, "test_macro_f1_se": 1.6087199520310724}}, "num_model_parameters": 75548163, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.8988223671913147, "test_mcc": 0.37309856142625225, "test_macro_f1": 0.5381336737494579, "test_runtime": 2.0673, "test_samples_per_second": 990.656, "test_steps_per_second": 30.958}, {"test_loss": 0.8961153030395508, "test_mcc": 0.2889263263871784, "test_macro_f1": 0.4135608655658803, "test_runtime": 1.9331, "test_samples_per_second": 1059.459, "test_steps_per_second": 33.108}, {"test_loss": 0.8638737201690674, "test_mcc": 0.3299988973133574, "test_macro_f1": 0.4517445757917627, "test_runtime": 1.9734, "test_samples_per_second": 1037.816, "test_steps_per_second": 32.432}, {"test_loss": 0.9109016060829163, "test_mcc": 0.30979899364892105, "test_macro_f1": 0.4193608380589117, "test_runtime": 1.9826, "test_samples_per_second": 1032.998, "test_steps_per_second": 32.281}, {"test_loss": 0.9341409206390381, "test_mcc": 0.3419576026703751, "test_macro_f1": 0.4968230942047905, "test_runtime": 2.0156, "test_samples_per_second": 1016.094, "test_steps_per_second": 31.753}, {"test_loss": 0.9126362204551697, "test_mcc": 0.30055542538775626, "test_macro_f1": 0.4208944723018859, "test_runtime": 2.0473, "test_samples_per_second": 1000.32, "test_steps_per_second": 31.26}, {"test_loss": 0.8515099883079529, "test_mcc": 0.3752719193375963, "test_macro_f1": 0.5297144826463426, "test_runtime": 1.9772, "test_samples_per_second": 1035.801, "test_steps_per_second": 32.369}, {"test_loss": 0.8879411220550537, "test_mcc": 0.29302793977887776, "test_macro_f1": 0.41623547876409567, "test_runtime": 2.0674, "test_samples_per_second": 990.638, "test_steps_per_second": 30.957}, {"test_loss": 0.9003000855445862, "test_mcc": 0.34550147568502493, "test_macro_f1": 0.514702760643098, "test_runtime": 2.069, "test_samples_per_second": 989.852, "test_steps_per_second": 30.933}, {"test_loss": 0.8940489292144775, "test_mcc": 0.3075752408579236, "test_macro_f1": 0.4248731159495461, "test_runtime": 2.1122, "test_samples_per_second": 969.624, "test_steps_per_second": 30.301}]}, "total": {"test_mcc": 32.65712382493263, "test_mcc_se": 1.9605075713018987, "test_macro_f1": 46.260433576757706, "test_macro_f1_se": 3.187319127123577}}, "num_model_parameters": 75548163, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.07561072707176208, "test_micro_f1": 0.595482546201232, "test_micro_f1_no_misc": 0.6804878048780488, "test_runtime": 4.8069, "test_samples_per_second": 426.059, "test_steps_per_second": 13.314}, {"test_loss": 0.07100753486156464, "test_micro_f1": 0.6431246655965758, "test_micro_f1_no_misc": 0.7084870848708487, "test_runtime": 4.5158, "test_samples_per_second": 453.521, "test_steps_per_second": 14.173}, {"test_loss": 0.06829565763473511, "test_micro_f1": 0.6478468899521531, "test_micro_f1_no_misc": 0.7046799354491662, "test_runtime": 4.5327, "test_samples_per_second": 451.825, "test_steps_per_second": 14.12}, {"test_loss": 0.06924156844615936, "test_micro_f1": 0.6544007956240677, "test_micro_f1_no_misc": 0.6881485527034408, "test_runtime": 4.9035, "test_samples_per_second": 417.659, "test_steps_per_second": 13.052}, {"test_loss": 0.07076665759086609, "test_micro_f1": 0.6514563106796116, "test_micro_f1_no_misc": 0.7126684636118599, "test_runtime": 4.858, "test_samples_per_second": 421.569, "test_steps_per_second": 13.174}, {"test_loss": 0.06598429381847382, "test_micro_f1": 0.6751173708920188, "test_micro_f1_no_misc": 0.7283359914938862, "test_runtime": 4.1123, "test_samples_per_second": 498.015, "test_steps_per_second": 15.563}, {"test_loss": 0.07521708309650421, "test_micro_f1": 0.6146435452793834, "test_micro_f1_no_misc": 0.6898485698261357, "test_runtime": 4.5101, "test_samples_per_second": 454.094, "test_steps_per_second": 14.19}, {"test_loss": 0.06586602330207825, "test_micro_f1": 0.6596082583377448, "test_micro_f1_no_misc": 0.719059405940594, "test_runtime": 4.8869, "test_samples_per_second": 419.076, "test_steps_per_second": 13.096}, {"test_loss": 0.0662136971950531, "test_micro_f1": 0.6219047619047617, "test_micro_f1_no_misc": 0.6891220320265047, "test_runtime": 4.6679, "test_samples_per_second": 438.739, "test_steps_per_second": 13.711}, {"test_loss": 0.06898974627256393, "test_micro_f1": 0.6290165530671861, "test_micro_f1_no_misc": 0.6730462519936204, "test_runtime": 4.9013, "test_samples_per_second": 417.845, "test_steps_per_second": 13.058}]}, "total": {"test_micro_f1": 63.92601697534735, "test_micro_f1_se": 1.47471595811216, "test_micro_f1_no_misc": 69.93884092794104, "test_micro_f1_no_misc_se": 1.1098862600811095}}, "num_model_parameters": 74962185, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.07642531394958496, "test_micro_f1": 0.7698553666582086, "test_micro_f1_no_misc": 0.7910189982728844, "test_runtime": 5.6925, "test_samples_per_second": 359.775, "test_steps_per_second": 11.243}, {"test_loss": 0.06551424413919449, "test_micro_f1": 0.780952380952381, "test_micro_f1_no_misc": 0.8007299270072993, "test_runtime": 4.2617, "test_samples_per_second": 480.555, "test_steps_per_second": 15.017}, {"test_loss": 0.07450699806213379, "test_micro_f1": 0.7488201363398007, "test_micro_f1_no_misc": 0.7751060820367751, "test_runtime": 5.5046, "test_samples_per_second": 372.054, "test_steps_per_second": 11.627}, {"test_loss": 0.07531479746103287, "test_micro_f1": 0.7881177707676129, "test_micro_f1_no_misc": 0.8111150193457617, "test_runtime": 5.2014, "test_samples_per_second": 393.738, "test_steps_per_second": 12.304}, {"test_loss": 0.07502789050340652, "test_micro_f1": 0.7468671679197996, "test_micro_f1_no_misc": 0.7826415094339622, "test_runtime": 5.5711, "test_samples_per_second": 367.61, "test_steps_per_second": 11.488}, {"test_loss": 0.07414551079273224, "test_micro_f1": 0.7873754152823922, "test_micro_f1_no_misc": 0.7989417989417988, "test_runtime": 5.4097, "test_samples_per_second": 378.578, "test_steps_per_second": 11.831}, {"test_loss": 0.06999821960926056, "test_micro_f1": 0.7706716617607706, "test_micro_f1_no_misc": 0.7861724875267284, "test_runtime": 5.5096, "test_samples_per_second": 371.715, "test_steps_per_second": 11.616}, {"test_loss": 0.06902806460857391, "test_micro_f1": 0.7625380991964532, "test_micro_f1_no_misc": 0.7987874194770745, "test_runtime": 5.5294, "test_samples_per_second": 370.385, "test_steps_per_second": 11.575}, {"test_loss": 0.07442483305931091, "test_micro_f1": 0.7795713151627414, "test_micro_f1_no_misc": 0.7954125046244912, "test_runtime": 5.2425, "test_samples_per_second": 390.653, "test_steps_per_second": 12.208}, {"test_loss": 0.07655565440654755, "test_micro_f1": 0.7500668270515906, "test_micro_f1_no_misc": 0.7653352353780313, "test_runtime": 4.6011, "test_samples_per_second": 445.109, "test_steps_per_second": 13.91}]}, "total": {"test_micro_f1": 76.8483614109175, "test_micro_f1_se": 0.9812899362815847, "test_micro_f1_no_misc": 79.05260982044805, "test_micro_f1_no_misc_se": 0.8378709743842847}}, "num_model_parameters": 74962185, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.052054837346076965, "test_micro_f1": 0.796965317919075, "test_micro_f1_no_misc": 0.8290909090909091, "test_runtime": 4.2884, "test_samples_per_second": 477.573, "test_steps_per_second": 14.924}, {"test_loss": 0.045761413872241974, "test_micro_f1": 0.8018936635105609, "test_micro_f1_no_misc": 0.8311164852881902, "test_runtime": 4.156, "test_samples_per_second": 492.776, "test_steps_per_second": 15.399}, {"test_loss": 0.04815243184566498, "test_micro_f1": 0.8007005253940455, "test_micro_f1_no_misc": 0.8377839776803507, "test_runtime": 4.0112, "test_samples_per_second": 510.571, "test_steps_per_second": 15.955}, {"test_loss": 0.04309689998626709, "test_micro_f1": 0.8117184708824581, "test_micro_f1_no_misc": 0.8367103694874851, "test_runtime": 3.92, "test_samples_per_second": 522.443, "test_steps_per_second": 16.326}, {"test_loss": 0.045748621225357056, "test_micro_f1": 0.8141300759326511, "test_micro_f1_no_misc": 0.8449554896142435, "test_runtime": 4.1963, "test_samples_per_second": 488.044, "test_steps_per_second": 15.251}, {"test_loss": 0.03941730409860611, "test_micro_f1": 0.819918144611187, "test_micro_f1_no_misc": 0.8573607932875668, "test_runtime": 4.2824, "test_samples_per_second": 478.234, "test_steps_per_second": 14.945}, {"test_loss": 0.04250670224428177, "test_micro_f1": 0.8035170781197158, "test_micro_f1_no_misc": 0.8368360718379825, "test_runtime": 3.7873, "test_samples_per_second": 540.751, "test_steps_per_second": 16.898}, {"test_loss": 0.04688449203968048, "test_micro_f1": 0.7829642248722316, "test_micro_f1_no_misc": 0.8071979434447301, "test_runtime": 3.9111, "test_samples_per_second": 523.635, "test_steps_per_second": 16.364}, {"test_loss": 0.040495358407497406, "test_micro_f1": 0.8147353361945636, "test_micro_f1_no_misc": 0.8430818878580073, "test_runtime": 3.9263, "test_samples_per_second": 521.615, "test_steps_per_second": 16.3}, {"test_loss": 0.055752113461494446, "test_micro_f1": 0.7857613711272249, "test_micro_f1_no_misc": 0.8251186564439578, "test_runtime": 4.084, "test_samples_per_second": 501.471, "test_steps_per_second": 15.671}]}, "total": {"test_micro_f1": 80.32304208563713, "test_micro_f1_se": 0.7633383084549717, "test_micro_f1_no_misc": 83.49252584033424, "test_micro_f1_no_misc_se": 0.8261552532321725}}, "num_model_parameters": 74962185, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.06129788979887962, "test_micro_f1": 0.736455463728191, "test_micro_f1_no_misc": 0.7835255354200988, "test_runtime": 3.9306, "test_samples_per_second": 521.044, "test_steps_per_second": 16.283}, {"test_loss": 0.06326126307249069, "test_micro_f1": 0.7783103654883163, "test_micro_f1_no_misc": 0.8171900826446281, "test_runtime": 4.1587, "test_samples_per_second": 492.467, "test_steps_per_second": 15.39}, {"test_loss": 0.06292812526226044, "test_micro_f1": 0.769277474195507, "test_micro_f1_no_misc": 0.8125212657366451, "test_runtime": 3.9093, "test_samples_per_second": 523.873, "test_steps_per_second": 16.371}, {"test_loss": 0.06864708662033081, "test_micro_f1": 0.7565429093122337, "test_micro_f1_no_misc": 0.7994589110585051, "test_runtime": 3.9877, "test_samples_per_second": 513.582, "test_steps_per_second": 16.049}, {"test_loss": 0.07391496002674103, "test_micro_f1": 0.7328106151990349, "test_micro_f1_no_misc": 0.7793715846994536, "test_runtime": 3.8144, "test_samples_per_second": 536.916, "test_steps_per_second": 16.779}, {"test_loss": 0.06381464004516602, "test_micro_f1": 0.7382789317507418, "test_micro_f1_no_misc": 0.7762376237623763, "test_runtime": 3.8526, "test_samples_per_second": 531.591, "test_steps_per_second": 16.612}, {"test_loss": 0.06123586744070053, "test_micro_f1": 0.7698113207547169, "test_micro_f1_no_misc": 0.8144827586206896, "test_runtime": 4.0062, "test_samples_per_second": 511.208, "test_steps_per_second": 15.975}, {"test_loss": 0.06139903888106346, "test_micro_f1": 0.7866831072749692, "test_micro_f1_no_misc": 0.8214647316908538, "test_runtime": 4.0401, "test_samples_per_second": 506.923, "test_steps_per_second": 15.841}, {"test_loss": 0.07330054044723511, "test_micro_f1": 0.7584269662921348, "test_micro_f1_no_misc": 0.7976720301266691, "test_runtime": 3.7398, "test_samples_per_second": 547.627, "test_steps_per_second": 17.113}, {"test_loss": 0.05746769905090332, "test_micro_f1": 0.7833537331701347, "test_micro_f1_no_misc": 0.8214528173794976, "test_runtime": 3.9255, "test_samples_per_second": 521.719, "test_steps_per_second": 16.304}]}, "total": {"test_micro_f1": 76.0995088716598, "test_micro_f1_se": 1.2300940548976842, "test_micro_f1_no_misc": 80.23377341139417, "test_micro_f1_no_misc_se": 1.0923845971959587}}, "num_model_parameters": 74962185, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6414989829063416, "test_mcc": 0.31886333903028374, "test_macro_f1": 0.6525792798871373, "test_runtime": 2.104, "test_samples_per_second": 973.367, "test_steps_per_second": 30.418}, {"test_loss": 0.6942712068557739, "test_mcc": 0.2929600749872421, "test_macro_f1": 0.6335593588530111, "test_runtime": 2.2009, "test_samples_per_second": 930.524, "test_steps_per_second": 29.079}, {"test_loss": 0.6300071477890015, "test_mcc": 0.3142918943010975, "test_macro_f1": 0.6387029285069346, "test_runtime": 2.2122, "test_samples_per_second": 925.763, "test_steps_per_second": 28.93}, {"test_loss": 0.6433300375938416, "test_mcc": 0.2669645269703427, "test_macro_f1": 0.6169597769225973, "test_runtime": 2.1796, "test_samples_per_second": 939.616, "test_steps_per_second": 29.363}, {"test_loss": 0.6336427927017212, "test_mcc": 0.32607261214267114, "test_macro_f1": 0.6600862486628578, "test_runtime": 2.2385, "test_samples_per_second": 914.898, "test_steps_per_second": 28.591}, {"test_loss": 0.6315589547157288, "test_mcc": 0.3111188128318374, "test_macro_f1": 0.6532223887836055, "test_runtime": 2.1367, "test_samples_per_second": 958.468, "test_steps_per_second": 29.952}, {"test_loss": 0.6417890191078186, "test_mcc": 0.28980308133224575, "test_macro_f1": 0.6236908188889569, "test_runtime": 2.1794, "test_samples_per_second": 939.71, "test_steps_per_second": 29.366}, {"test_loss": 0.6660175323486328, "test_mcc": 0.2864970655793734, "test_macro_f1": 0.6217133900219667, "test_runtime": 2.164, "test_samples_per_second": 946.39, "test_steps_per_second": 29.575}, {"test_loss": 0.6473690867424011, "test_mcc": 0.272277014814726, "test_macro_f1": 0.5839617685174014, "test_runtime": 2.2215, "test_samples_per_second": 921.919, "test_steps_per_second": 28.81}, {"test_loss": 0.6717571020126343, "test_mcc": 0.3030365035909809, "test_macro_f1": 0.6479067357413704, "test_runtime": 2.1867, "test_samples_per_second": 936.589, "test_steps_per_second": 29.268}]}, "total": {"test_mcc": 29.818849255808004, "test_mcc_se": 1.2284874917446673, "test_macro_f1": 63.323826947858386, "test_macro_f1_se": 1.4098265330509372}}, "num_model_parameters": 75547394, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6492472887039185, "test_mcc": 0.26157164667253713, "test_macro_f1": 0.6079755757341184, "test_runtime": 2.2053, "test_samples_per_second": 928.671, "test_steps_per_second": 29.021}, {"test_loss": 0.593598484992981, "test_mcc": 0.3871624652991002, "test_macro_f1": 0.6928387980246373, "test_runtime": 2.2776, "test_samples_per_second": 899.208, "test_steps_per_second": 28.1}, {"test_loss": 0.6072637438774109, "test_mcc": 0.39160245125425713, "test_macro_f1": 0.6957772742383541, "test_runtime": 2.2322, "test_samples_per_second": 917.485, "test_steps_per_second": 28.671}, {"test_loss": 0.6603342890739441, "test_mcc": 0.3224856376713889, "test_macro_f1": 0.6508932054890316, "test_runtime": 2.3241, "test_samples_per_second": 881.184, "test_steps_per_second": 27.537}, {"test_loss": 0.6004505157470703, "test_mcc": 0.36331132516644277, "test_macro_f1": 0.68163941055073, "test_runtime": 2.2188, "test_samples_per_second": 923.03, "test_steps_per_second": 28.845}, {"test_loss": 0.6364833116531372, "test_mcc": 0.2996371650707643, "test_macro_f1": 0.6081288351363372, "test_runtime": 2.1958, "test_samples_per_second": 932.693, "test_steps_per_second": 29.147}, {"test_loss": 0.6279693841934204, "test_mcc": 0.33491908893526584, "test_macro_f1": 0.6669604263712283, "test_runtime": 2.1655, "test_samples_per_second": 945.756, "test_steps_per_second": 29.555}, {"test_loss": 0.6115615367889404, "test_mcc": 0.38973388797354547, "test_macro_f1": 0.6942703350309201, "test_runtime": 2.1965, "test_samples_per_second": 932.393, "test_steps_per_second": 29.137}, {"test_loss": 0.6440552473068237, "test_mcc": 0.35329974092732397, "test_macro_f1": 0.6766085419982215, "test_runtime": 2.1895, "test_samples_per_second": 935.385, "test_steps_per_second": 29.231}, {"test_loss": 0.6067519783973694, "test_mcc": 0.3877970996571259, "test_macro_f1": 0.693838823913978, "test_runtime": 2.256, "test_samples_per_second": 907.806, "test_steps_per_second": 28.369}]}, "total": {"test_mcc": 34.91520508627752, "test_mcc_se": 2.744044153400429, "test_macro_f1": 66.68931226487558, "test_macro_f1_se": 2.114562354310864}}, "num_model_parameters": 75547394, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6201686859130859, "test_mcc": 0.32422481883373433, "test_macro_f1": 0.6367597206676479, "test_runtime": 2.0306, "test_samples_per_second": 1008.56, "test_steps_per_second": 31.518}, {"test_loss": 0.5829945802688599, "test_mcc": 0.4345637520538031, "test_macro_f1": 0.7075186903384864, "test_runtime": 1.9866, "test_samples_per_second": 1030.92, "test_steps_per_second": 32.216}, {"test_loss": 0.6175534725189209, "test_mcc": 0.35004613498273573, "test_macro_f1": 0.6526552435588374, "test_runtime": 1.9821, "test_samples_per_second": 1033.235, "test_steps_per_second": 32.289}, {"test_loss": 0.6917210817337036, "test_mcc": 0.0671528328631094, "test_macro_f1": 0.48665768634994433, "test_runtime": 2.026, "test_samples_per_second": 1010.855, "test_steps_per_second": 31.589}, {"test_loss": 0.5970357060432434, "test_mcc": 0.38433669590542174, "test_macro_f1": 0.6860600241367154, "test_runtime": 2.014, "test_samples_per_second": 1016.885, "test_steps_per_second": 31.778}, {"test_loss": 0.5674171447753906, "test_mcc": 0.427239301611243, "test_macro_f1": 0.7047240932529679, "test_runtime": 1.9297, "test_samples_per_second": 1061.316, "test_steps_per_second": 33.166}, {"test_loss": 0.6037262678146362, "test_mcc": 0.4171292928536171, "test_macro_f1": 0.7032228147461165, "test_runtime": 1.9514, "test_samples_per_second": 1049.501, "test_steps_per_second": 32.797}, {"test_loss": 0.6466364860534668, "test_mcc": 0.2927890771229779, "test_macro_f1": 0.6329738350487877, "test_runtime": 1.9882, "test_samples_per_second": 1030.063, "test_steps_per_second": 32.189}, {"test_loss": 0.6310846209526062, "test_mcc": 0.3073166846916558, "test_macro_f1": 0.6411930689638681, "test_runtime": 1.9455, "test_samples_per_second": 1052.663, "test_steps_per_second": 32.896}, {"test_loss": 0.6196292042732239, "test_mcc": 0.36008172724410936, "test_macro_f1": 0.6701627361062596, "test_runtime": 2.0092, "test_samples_per_second": 1019.313, "test_steps_per_second": 31.854}]}, "total": {"test_mcc": 33.648803181624075, "test_mcc_se": 6.625458263575136, "test_macro_f1": 65.21927913169631, "test_macro_f1_se": 4.028746566733217}}, "num_model_parameters": 75547394, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6405696868896484, "test_mcc": 0.28982583616779484, "test_macro_f1": 0.6449104519245098, "test_runtime": 2.057, "test_samples_per_second": 995.603, "test_steps_per_second": 31.113}, {"test_loss": 0.6378598213195801, "test_mcc": 0.25460040945076245, "test_macro_f1": 0.6178638714388303, "test_runtime": 2.1317, "test_samples_per_second": 960.714, "test_steps_per_second": 30.022}, {"test_loss": 0.6411252021789551, "test_mcc": 0.3339114065705975, "test_macro_f1": 0.6613883561874275, "test_runtime": 2.1207, "test_samples_per_second": 965.725, "test_steps_per_second": 30.179}, {"test_loss": 0.636447012424469, "test_mcc": 0.2685075536157891, "test_macro_f1": 0.6230650632130743, "test_runtime": 2.0264, "test_samples_per_second": 1010.677, "test_steps_per_second": 31.584}, {"test_loss": 0.6322352290153503, "test_mcc": 0.26994395796320597, "test_macro_f1": 0.6335052812576762, "test_runtime": 2.067, "test_samples_per_second": 990.801, "test_steps_per_second": 30.963}, {"test_loss": 0.642315149307251, "test_mcc": 0.3173763958101427, "test_macro_f1": 0.6482798687330225, "test_runtime": 2.166, "test_samples_per_second": 945.539, "test_steps_per_second": 29.548}, {"test_loss": 0.6497835516929626, "test_mcc": 0.25303843704963636, "test_macro_f1": 0.6159065752140098, "test_runtime": 2.0664, "test_samples_per_second": 991.077, "test_steps_per_second": 30.971}, {"test_loss": 0.6187217235565186, "test_mcc": 0.3607506470476231, "test_macro_f1": 0.6800588848678157, "test_runtime": 2.053, "test_samples_per_second": 997.574, "test_steps_per_second": 31.174}, {"test_loss": 0.6386709213256836, "test_mcc": 0.2782265244277952, "test_macro_f1": 0.6066440282109986, "test_runtime": 2.0674, "test_samples_per_second": 990.616, "test_steps_per_second": 30.957}, {"test_loss": 0.6494410037994385, "test_mcc": 0.28079522256397726, "test_macro_f1": 0.6033311948236544, "test_runtime": 2.1134, "test_samples_per_second": 969.077, "test_steps_per_second": 30.284}]}, "total": {"test_mcc": 29.069763906673245, "test_mcc_se": 2.204484235884321, "test_macro_f1": 63.34953575871018, "test_macro_f1_se": 1.5444719798646245}}, "num_model_parameters": 75547394, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_em": 38.8845855925639, "test_f1": 42.96213665460974}, {"test_em": 41.70542635658915, "test_f1": 45.529459728358155}, {"test_em": 41.190108191653785, "test_f1": 44.74630157080357}, {"test_em": 39.40809968847352, "test_f1": 43.51056290033752}, {"test_em": 32.818532818532816, "test_f1": 36.46463880186935}, {"test_em": 42.5597532767926, "test_f1": 45.90654198881681}, {"test_em": 35.99088838268793, "test_f1": 39.59029574739926}, {"test_em": 43.0566330488751, "test_f1": 46.7389438413248}, {"test_em": 35.13725490196079, "test_f1": 38.72415105079466}, {"test_em": 40.6055900621118, "test_f1": 44.56657184004645}]}, "total": {"test_em": 39.13568723202413, "test_em_se": 2.1271371981540965, "test_f1": 42.873960412436034, "test_f1_se": 2.137635701881589}}, "num_model_parameters": 74956802, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_em": 37.490317583268784, "test_f1": 41.80095747079486}, {"test_em": 35.50387596899225, "test_f1": 39.78399841419607}, {"test_em": 34.69860896445132, "test_f1": 38.845364905794995}, {"test_em": 35.981308411214954, "test_f1": 39.601527475377345}, {"test_em": 35.366795366795365, "test_f1": 40.3697535727611}, {"test_em": 39.09020817270625, "test_f1": 43.50768658195181}, {"test_em": 35.61123766135156, "test_f1": 39.93768151361991}, {"test_em": 36.22963537626067, "test_f1": 39.732076516794464}, {"test_em": 29.49019607843137, "test_f1": 35.115021800919685}, {"test_em": 37.88819875776397, "test_f1": 42.769017655264605}]}, "total": {"test_em": 35.73503823412365, "test_em_se": 1.5944030923062278, "test_f1": 40.14630859074748, "test_f1_se": 1.4405181494094812}}, "num_model_parameters": 74956802, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_em": 41.2858249419055, "test_f1": 47.055918199804296}, {"test_em": 40.62015503875969, "test_f1": 44.82246028545257}, {"test_em": 43.89489953632148, "test_f1": 48.13844184665678}, {"test_em": 41.74454828660436, "test_f1": 46.27737062240548}, {"test_em": 40.077220077220076, "test_f1": 45.71213405534501}, {"test_em": 37.471087124132616, "test_f1": 42.72742292950251}, {"test_em": 35.383447228549734, "test_f1": 40.08544368386944}, {"test_em": 41.970519782777345, "test_f1": 46.54365336752604}, {"test_em": 42.745098039215684, "test_f1": 47.8990298651998}, {"test_em": 40.29503105590062, "test_f1": 44.73885120606926}]}, "total": {"test_em": 40.54878311113871, "test_em_se": 1.5523986082773216, "test_f1": 45.400072606183116, "test_f1_se": 1.5296830828011605}}, "num_model_parameters": 74956802, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.44943106174468994, "test_mcc": 0.723421329538748, "test_macro_f1": 0.6873660664472894, "test_runtime": 7.8184, "test_samples_per_second": 261.947, "test_steps_per_second": 32.743}, {"test_loss": 0.5035946369171143, "test_mcc": 0.7011585458880237, "test_macro_f1": 0.6257284537764143, "test_runtime": 7.6316, "test_samples_per_second": 268.358, "test_steps_per_second": 33.545}, {"test_loss": 0.4714459478855133, "test_mcc": 0.7201174928154414, "test_macro_f1": 0.7008424017656244, "test_runtime": 7.6827, "test_samples_per_second": 266.574, "test_steps_per_second": 33.322}, {"test_loss": 0.4671500325202942, "test_mcc": 0.729764879508095, "test_macro_f1": 0.5973364340417392, "test_runtime": 7.2998, "test_samples_per_second": 280.557, "test_steps_per_second": 35.07}, {"test_loss": 0.4554642140865326, "test_mcc": 0.725856606729859, "test_macro_f1": 0.7065560378381243, "test_runtime": 7.2556, "test_samples_per_second": 282.265, "test_steps_per_second": 35.283}, {"test_loss": 0.4390602707862854, "test_mcc": 0.7415192427887646, "test_macro_f1": 0.7181212669762166, "test_runtime": 7.424, "test_samples_per_second": 275.862, "test_steps_per_second": 34.483}, {"test_loss": 0.4633646309375763, "test_mcc": 0.7281973158456235, "test_macro_f1": 0.6837206689327097, "test_runtime": 7.1318, "test_samples_per_second": 287.166, "test_steps_per_second": 35.896}, {"test_loss": 0.4714897871017456, "test_mcc": 0.7204707916631473, "test_macro_f1": 0.693852096985463, "test_runtime": 7.7156, "test_samples_per_second": 265.437, "test_steps_per_second": 33.18}, {"test_loss": 0.4849446415901184, "test_mcc": 0.7068250429081971, "test_macro_f1": 0.6787675936294032, "test_runtime": 7.6343, "test_samples_per_second": 268.263, "test_steps_per_second": 33.533}, {"test_loss": 0.47521981596946716, "test_mcc": 0.7221163225068441, "test_macro_f1": 0.6954291692515698, "test_runtime": 7.669, "test_samples_per_second": 267.05, "test_steps_per_second": 33.381}]}, "total": {"test_mcc": 72.19447570192744, "test_mcc_se": 0.7058133193113826, "test_macro_f1": 67.87720189644554, "test_macro_f1_se": 2.3425446227828273}}, "num_model_parameters": 117654915, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.8454659581184387, "test_mcc": 0.44481791149519373, "test_macro_f1": 0.628892281024355, "test_runtime": 2.1137, "test_samples_per_second": 968.906, "test_steps_per_second": 30.278}, {"test_loss": 0.809461236000061, "test_mcc": 0.4842876947787657, "test_macro_f1": 0.6541535308469313, "test_runtime": 2.2135, "test_samples_per_second": 925.235, "test_steps_per_second": 28.914}, {"test_loss": 0.879672646522522, "test_mcc": 0.4166422704651774, "test_macro_f1": 0.612052398890316, "test_runtime": 2.0756, "test_samples_per_second": 986.68, "test_steps_per_second": 30.834}, {"test_loss": 0.8441768884658813, "test_mcc": 0.43269928273848957, "test_macro_f1": 0.626749180360996, "test_runtime": 2.0461, "test_samples_per_second": 1000.929, "test_steps_per_second": 31.279}, {"test_loss": 0.8503079414367676, "test_mcc": 0.41730519303546904, "test_macro_f1": 0.615613107888368, "test_runtime": 2.0595, "test_samples_per_second": 994.419, "test_steps_per_second": 31.076}, {"test_loss": 0.8605398535728455, "test_mcc": 0.4286415998158883, "test_macro_f1": 0.6172105412839758, "test_runtime": 2.1664, "test_samples_per_second": 945.343, "test_steps_per_second": 29.542}, {"test_loss": 0.8260973691940308, "test_mcc": 0.4619608656449523, "test_macro_f1": 0.6390200858275351, "test_runtime": 2.0948, "test_samples_per_second": 977.64, "test_steps_per_second": 30.551}, {"test_loss": 0.8496177196502686, "test_mcc": 0.457318591242545, "test_macro_f1": 0.6404225344649167, "test_runtime": 2.1579, "test_samples_per_second": 949.079, "test_steps_per_second": 29.659}, {"test_loss": 0.8403568267822266, "test_mcc": 0.4540113242374718, "test_macro_f1": 0.6416677268454579, "test_runtime": 2.1388, "test_samples_per_second": 957.526, "test_steps_per_second": 29.923}, {"test_loss": 0.8274309635162354, "test_mcc": 0.4505190062745653, "test_macro_f1": 0.6351810365608551, "test_runtime": 2.1121, "test_samples_per_second": 969.659, "test_steps_per_second": 30.302}]}, "total": {"test_mcc": 44.48203739728519, "test_mcc_se": 1.320377383782325, "test_macro_f1": 63.10962423993707, "test_macro_f1_se": 0.8338156051081801}}, "num_model_parameters": 117654915, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.7888378500938416, "test_mcc": 0.4914569135079773, "test_macro_f1": 0.6425989616164712, "test_runtime": 1.8229, "test_samples_per_second": 1123.478, "test_steps_per_second": 35.109}, {"test_loss": 0.8129510879516602, "test_mcc": 0.45081739533453935, "test_macro_f1": 0.5948701106409601, "test_runtime": 1.8256, "test_samples_per_second": 1121.802, "test_steps_per_second": 35.056}, {"test_loss": 0.7764968872070312, "test_mcc": 0.4785818404733187, "test_macro_f1": 0.6269695714035767, "test_runtime": 1.7647, "test_samples_per_second": 1160.507, "test_steps_per_second": 36.266}, {"test_loss": 0.7835884094238281, "test_mcc": 0.46153314549330393, "test_macro_f1": 0.6212309262683858, "test_runtime": 1.7618, "test_samples_per_second": 1162.469, "test_steps_per_second": 36.327}, {"test_loss": 0.7933107614517212, "test_mcc": 0.45835249776099324, "test_macro_f1": 0.6234543960338589, "test_runtime": 1.7952, "test_samples_per_second": 1140.817, "test_steps_per_second": 35.651}, {"test_loss": 0.7676188945770264, "test_mcc": 0.4911085677379448, "test_macro_f1": 0.6463088394811538, "test_runtime": 1.7988, "test_samples_per_second": 1138.524, "test_steps_per_second": 35.579}, {"test_loss": 0.755983829498291, "test_mcc": 0.4737808907637641, "test_macro_f1": 0.6075093959255866, "test_runtime": 1.7528, "test_samples_per_second": 1168.414, "test_steps_per_second": 36.513}, {"test_loss": 0.7857214212417603, "test_mcc": 0.46824101065068235, "test_macro_f1": 0.6257202863424776, "test_runtime": 1.8265, "test_samples_per_second": 1121.274, "test_steps_per_second": 35.04}, {"test_loss": 0.7731292247772217, "test_mcc": 0.4937018980357873, "test_macro_f1": 0.6503560631649922, "test_runtime": 1.8532, "test_samples_per_second": 1105.111, "test_steps_per_second": 34.535}, {"test_loss": 0.7824057340621948, "test_mcc": 0.48514900549137413, "test_macro_f1": 0.6341648907482157, "test_runtime": 1.8282, "test_samples_per_second": 1120.258, "test_steps_per_second": 35.008}]}, "total": {"test_mcc": 47.52723165249685, "test_mcc_se": 0.9435253777630411, "test_macro_f1": 62.73183441625678, "test_macro_f1_se": 1.0678937387876308}}, "num_model_parameters": 117654915, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.09684789180755615, "test_micro_f1": 0.5684523809523808, "test_micro_f1_no_misc": 0.6403766921718658, "test_runtime": 4.1143, "test_samples_per_second": 497.775, "test_steps_per_second": 15.555}, {"test_loss": 0.09882096946239471, "test_micro_f1": 0.5693354264782835, "test_micro_f1_no_misc": 0.6349017272185825, "test_runtime": 3.9331, "test_samples_per_second": 520.712, "test_steps_per_second": 16.272}, {"test_loss": 0.08277064561843872, "test_micro_f1": 0.6122840690978888, "test_micro_f1_no_misc": 0.6663031624863686, "test_runtime": 3.7895, "test_samples_per_second": 540.439, "test_steps_per_second": 16.889}, {"test_loss": 0.09507739543914795, "test_micro_f1": 0.5906040268456376, "test_micro_f1_no_misc": 0.6355437665782493, "test_runtime": 4.1147, "test_samples_per_second": 497.728, "test_steps_per_second": 15.554}, {"test_loss": 0.0916130393743515, "test_micro_f1": 0.5895522388059702, "test_micro_f1_no_misc": 0.6763678696158323, "test_runtime": 4.1076, "test_samples_per_second": 498.594, "test_steps_per_second": 15.581}, {"test_loss": 0.0857977420091629, "test_micro_f1": 0.6141377757766772, "test_micro_f1_no_misc": 0.6787878787878788, "test_runtime": 3.5736, "test_samples_per_second": 573.093, "test_steps_per_second": 17.909}, {"test_loss": 0.09506319463253021, "test_micro_f1": 0.5861084681255948, "test_micro_f1_no_misc": 0.6481687014428413, "test_runtime": 3.7376, "test_samples_per_second": 547.948, "test_steps_per_second": 17.123}, {"test_loss": 0.07909923046827316, "test_micro_f1": 0.6237837837837839, "test_micro_f1_no_misc": 0.689301729660474, "test_runtime": 4.0546, "test_samples_per_second": 505.11, "test_steps_per_second": 15.785}, {"test_loss": 0.0837419182062149, "test_micro_f1": 0.609375, "test_micro_f1_no_misc": 0.6773127753303965, "test_runtime": 3.9592, "test_samples_per_second": 517.282, "test_steps_per_second": 16.165}, {"test_loss": 0.08394208550453186, "test_micro_f1": 0.6355231143552311, "test_micro_f1_no_misc": 0.703037120359955, "test_runtime": 4.2557, "test_samples_per_second": 481.24, "test_steps_per_second": 15.039}]}, "total": {"test_micro_f1": 59.991562842214485, "test_micro_f1_se": 1.4000458555900206, "test_micro_f1_no_misc": 66.50101423652444, "test_micro_f1_no_misc_se": 1.4859862223641833}}, "num_model_parameters": 117509385, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.10197072476148605, "test_micro_f1": 0.7217016966320589, "test_micro_f1_no_misc": 0.7421848739495799, "test_runtime": 4.4548, "test_samples_per_second": 459.733, "test_steps_per_second": 14.367}, {"test_loss": 0.09232519567012787, "test_micro_f1": 0.7348734873487349, "test_micro_f1_no_misc": 0.7532751091703057, "test_runtime": 3.8334, "test_samples_per_second": 534.257, "test_steps_per_second": 16.696}, {"test_loss": 0.10324875265359879, "test_micro_f1": 0.7176532215819801, "test_micro_f1_no_misc": 0.7415570565232847, "test_runtime": 4.6083, "test_samples_per_second": 444.415, "test_steps_per_second": 13.888}, {"test_loss": 0.10428266227245331, "test_micro_f1": 0.6978381096028154, "test_micro_f1_no_misc": 0.7157326130992573, "test_runtime": 4.4609, "test_samples_per_second": 459.098, "test_steps_per_second": 14.347}, {"test_loss": 0.1058788150548935, "test_micro_f1": 0.6939226519337016, "test_micro_f1_no_misc": 0.7250280583613917, "test_runtime": 4.5516, "test_samples_per_second": 449.953, "test_steps_per_second": 14.061}, {"test_loss": 0.09904734790325165, "test_micro_f1": 0.728448275862069, "test_micro_f1_no_misc": 0.741506646971935, "test_runtime": 4.5023, "test_samples_per_second": 454.879, "test_steps_per_second": 14.215}, {"test_loss": 0.10303712636232376, "test_micro_f1": 0.7244979919678715, "test_micro_f1_no_misc": 0.7403949730700179, "test_runtime": 4.525, "test_samples_per_second": 452.6, "test_steps_per_second": 14.144}, {"test_loss": 0.10403269529342651, "test_micro_f1": 0.6994860697863132, "test_micro_f1_no_misc": 0.7237128353879623, "test_runtime": 4.4818, "test_samples_per_second": 456.962, "test_steps_per_second": 14.28}, {"test_loss": 0.09566092491149902, "test_micro_f1": 0.7287107830213551, "test_micro_f1_no_misc": 0.7466192170818504, "test_runtime": 4.3999, "test_samples_per_second": 465.468, "test_steps_per_second": 14.546}, {"test_loss": 0.10112309455871582, "test_micro_f1": 0.7236737925574029, "test_micro_f1_no_misc": 0.7338681548657133, "test_runtime": 4.0354, "test_samples_per_second": 507.514, "test_steps_per_second": 15.86}]}, "total": {"test_micro_f1": 71.70806080294302, "test_micro_f1_se": 0.9046658946006564, "test_micro_f1_no_misc": 73.63879538481298, "test_micro_f1_no_misc_se": 0.7201897638653185}}, "num_model_parameters": 117509385, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.08233403414487839, "test_micro_f1": 0.724679029957204, "test_micro_f1_no_misc": 0.7678068410462777, "test_runtime": 3.6405, "test_samples_per_second": 562.563, "test_steps_per_second": 17.58}, {"test_loss": 0.07742507755756378, "test_micro_f1": 0.7194719471947194, "test_micro_f1_no_misc": 0.7583974099554837, "test_runtime": 3.6408, "test_samples_per_second": 562.51, "test_steps_per_second": 17.578}, {"test_loss": 0.06960912048816681, "test_micro_f1": 0.7530562347188263, "test_micro_f1_no_misc": 0.7861362741236707, "test_runtime": 3.5121, "test_samples_per_second": 583.119, "test_steps_per_second": 18.222}, {"test_loss": 0.06663638353347778, "test_micro_f1": 0.7761089765979742, "test_micro_f1_no_misc": 0.8069073783359498, "test_runtime": 3.4546, "test_samples_per_second": 592.834, "test_steps_per_second": 18.526}, {"test_loss": 0.0765920951962471, "test_micro_f1": 0.7830342577487766, "test_micro_f1_no_misc": 0.8151382823871908, "test_runtime": 3.6303, "test_samples_per_second": 564.137, "test_steps_per_second": 17.629}, {"test_loss": 0.06659891456365585, "test_micro_f1": 0.7600271923861318, "test_micro_f1_no_misc": 0.7996982270841192, "test_runtime": 3.6143, "test_samples_per_second": 566.635, "test_steps_per_second": 17.707}, {"test_loss": 0.07858969271183014, "test_micro_f1": 0.7430671566989644, "test_micro_f1_no_misc": 0.7852852852852852, "test_runtime": 3.557, "test_samples_per_second": 575.76, "test_steps_per_second": 17.992}, {"test_loss": 0.07339633256196976, "test_micro_f1": 0.7334453781512604, "test_micro_f1_no_misc": 0.7650471356055113, "test_runtime": 3.4773, "test_samples_per_second": 588.965, "test_steps_per_second": 18.405}, {"test_loss": 0.0745028629899025, "test_micro_f1": 0.7247091998590061, "test_micro_f1_no_misc": 0.7622820919175912, "test_runtime": 3.4639, "test_samples_per_second": 591.247, "test_steps_per_second": 18.476}, {"test_loss": 0.08143347501754761, "test_micro_f1": 0.7477447377213499, "test_micro_f1_no_misc": 0.7844574780058651, "test_runtime": 3.6385, "test_samples_per_second": 562.867, "test_steps_per_second": 17.59}]}, "total": {"test_micro_f1": 74.65344111034213, "test_micro_f1_se": 1.3552009206223, "test_micro_f1_no_misc": 78.31156403746944, "test_micro_f1_no_misc_se": 1.2201721185233418}}, "num_model_parameters": 117509385, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.09466800838708878, "test_micro_f1": 0.6509661835748792, "test_micro_f1_no_misc": 0.7066848567530696, "test_runtime": 3.624, "test_samples_per_second": 565.116, "test_steps_per_second": 17.66}, {"test_loss": 0.09335839748382568, "test_micro_f1": 0.6917247650803273, "test_micro_f1_no_misc": 0.7394557823129252, "test_runtime": 3.6036, "test_samples_per_second": 568.316, "test_steps_per_second": 17.76}, {"test_loss": 0.09597636759281158, "test_micro_f1": 0.6887892376681615, "test_micro_f1_no_misc": 0.7291458956463941, "test_runtime": 3.469, "test_samples_per_second": 590.374, "test_steps_per_second": 18.449}, {"test_loss": 0.10675367712974548, "test_micro_f1": 0.6462462462462463, "test_micro_f1_no_misc": 0.6930369401765282, "test_runtime": 3.5923, "test_samples_per_second": 570.114, "test_steps_per_second": 17.816}, {"test_loss": 0.10022010654211044, "test_micro_f1": 0.671865626874625, "test_micro_f1_no_misc": 0.7200000000000001, "test_runtime": 3.5471, "test_samples_per_second": 577.368, "test_steps_per_second": 18.043}, {"test_loss": 0.0944407507777214, "test_micro_f1": 0.697387731141767, "test_micro_f1_no_misc": 0.7412868632707775, "test_runtime": 3.585, "test_samples_per_second": 571.271, "test_steps_per_second": 17.852}, {"test_loss": 0.09158746153116226, "test_micro_f1": 0.6560240963855422, "test_micro_f1_no_misc": 0.7170715018816285, "test_runtime": 3.6678, "test_samples_per_second": 558.371, "test_steps_per_second": 17.449}, {"test_loss": 0.09269526600837708, "test_micro_f1": 0.6805896805896806, "test_micro_f1_no_misc": 0.7193756362402443, "test_runtime": 3.6387, "test_samples_per_second": 562.836, "test_steps_per_second": 17.589}, {"test_loss": 0.09973830729722977, "test_micro_f1": 0.6688485569770902, "test_micro_f1_no_misc": 0.7178789938817132, "test_runtime": 3.3051, "test_samples_per_second": 619.648, "test_steps_per_second": 19.364}, {"test_loss": 0.09734183549880981, "test_micro_f1": 0.67518573551263, "test_micro_f1_no_misc": 0.7292561983471073, "test_runtime": 3.4291, "test_samples_per_second": 597.248, "test_steps_per_second": 18.664}]}, "total": {"test_micro_f1": 67.2762786005095, "test_micro_f1_se": 1.0862737513371945, "test_micro_f1_no_misc": 72.13192668510388, "test_micro_f1_no_misc_se": 0.900875884791652}}, "num_model_parameters": 117509385, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.6363586187362671, "test_mcc": 0.29896362747881133, "test_macro_f1": 0.6419922983570164, "test_runtime": 1.6344, "test_samples_per_second": 1253.035, "test_steps_per_second": 39.157}, {"test_loss": 0.647156834602356, "test_mcc": 0.3136786663682813, "test_macro_f1": 0.6499132673852912, "test_runtime": 1.6891, "test_samples_per_second": 1212.488, "test_steps_per_second": 37.89}, {"test_loss": 0.6145946383476257, "test_mcc": 0.3368352965738595, "test_macro_f1": 0.6593881777310429, "test_runtime": 1.6903, "test_samples_per_second": 1211.609, "test_steps_per_second": 37.863}, {"test_loss": 0.6347798109054565, "test_mcc": 0.3091741516601827, "test_macro_f1": 0.644273202070792, "test_runtime": 1.7305, "test_samples_per_second": 1183.506, "test_steps_per_second": 36.985}, {"test_loss": 0.6314615607261658, "test_mcc": 0.3081371993446623, "test_macro_f1": 0.6527135698703612, "test_runtime": 1.6789, "test_samples_per_second": 1219.811, "test_steps_per_second": 38.119}, {"test_loss": 0.6238152980804443, "test_mcc": 0.3298264893431075, "test_macro_f1": 0.6421395628140951, "test_runtime": 1.6624, "test_samples_per_second": 1231.946, "test_steps_per_second": 38.498}, {"test_loss": 0.6308789849281311, "test_mcc": 0.3332754404159978, "test_macro_f1": 0.6499750470492527, "test_runtime": 1.6677, "test_samples_per_second": 1228.056, "test_steps_per_second": 38.377}, {"test_loss": 0.6358592510223389, "test_mcc": 0.280577878812794, "test_macro_f1": 0.6358446273988807, "test_runtime": 1.6802, "test_samples_per_second": 1218.903, "test_steps_per_second": 38.091}, {"test_loss": 0.6237162351608276, "test_mcc": 0.3287770412887877, "test_macro_f1": 0.6382291658102204, "test_runtime": 1.682, "test_samples_per_second": 1217.622, "test_steps_per_second": 38.051}, {"test_loss": 0.6928884983062744, "test_mcc": 0.036178853278845596, "test_macro_f1": 0.5152143705628554, "test_runtime": 1.6785, "test_samples_per_second": 1220.127, "test_steps_per_second": 38.129}]}, "total": {"test_mcc": 28.75424644565329, "test_mcc_se": 5.580067370673629, "test_macro_f1": 63.29683289049808, "test_macro_f1_se": 2.6018363491753}}, "num_model_parameters": 117654530, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.6484607458114624, "test_mcc": 0.24972026264446548, "test_macro_f1": 0.6188066103970251, "test_runtime": 1.8013, "test_samples_per_second": 1136.935, "test_steps_per_second": 35.529}, {"test_loss": 0.6553928852081299, "test_mcc": 0.26187419830538683, "test_macro_f1": 0.6017961194431782, "test_runtime": 1.8786, "test_samples_per_second": 1090.158, "test_steps_per_second": 34.067}, {"test_loss": 0.6456160545349121, "test_mcc": 0.28154393697455554, "test_macro_f1": 0.6405264768901133, "test_runtime": 1.8358, "test_samples_per_second": 1115.611, "test_steps_per_second": 34.863}, {"test_loss": 0.6733287572860718, "test_mcc": 0.20495388855923843, "test_macro_f1": 0.5548445250248523, "test_runtime": 1.902, "test_samples_per_second": 1076.751, "test_steps_per_second": 33.648}, {"test_loss": 0.6437583565711975, "test_mcc": 0.25160884047494164, "test_macro_f1": 0.6243680813746881, "test_runtime": 1.8113, "test_samples_per_second": 1130.709, "test_steps_per_second": 35.335}, {"test_loss": 0.6388658285140991, "test_mcc": 0.2987168595899133, "test_macro_f1": 0.6493485186668956, "test_runtime": 1.8472, "test_samples_per_second": 1108.72, "test_steps_per_second": 34.647}, {"test_loss": 0.6422786116600037, "test_mcc": 0.27298577968355847, "test_macro_f1": 0.6331998480146859, "test_runtime": 1.8021, "test_samples_per_second": 1136.467, "test_steps_per_second": 35.515}, {"test_loss": 0.6320049166679382, "test_mcc": 0.32037563076384595, "test_macro_f1": 0.6577073140669966, "test_runtime": 1.8171, "test_samples_per_second": 1127.095, "test_steps_per_second": 35.222}, {"test_loss": 0.6400133967399597, "test_mcc": 0.27865687925184357, "test_macro_f1": 0.6345934778761382, "test_runtime": 1.8131, "test_samples_per_second": 1129.58, "test_steps_per_second": 35.299}, {"test_loss": 0.674626886844635, "test_mcc": 0.2539603174487044, "test_macro_f1": 0.6038340676172881, "test_runtime": 1.8276, "test_samples_per_second": 1120.567, "test_steps_per_second": 35.018}]}, "total": {"test_mcc": 26.743965936964536, "test_mcc_se": 1.9400509584546337, "test_macro_f1": 62.190250393718614, "test_macro_f1_se": 1.837944367114891}}, "num_model_parameters": 117654530, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.6325873136520386, "test_mcc": 0.31984134646035817, "test_macro_f1": 0.643687649225416, "test_runtime": 1.681, "test_samples_per_second": 1218.32, "test_steps_per_second": 38.072}, {"test_loss": 0.6390907764434814, "test_mcc": 0.3238777908280976, "test_macro_f1": 0.6369164870643286, "test_runtime": 1.696, "test_samples_per_second": 1207.576, "test_steps_per_second": 37.737}, {"test_loss": 0.6785885095596313, "test_mcc": 0.19742547000722432, "test_macro_f1": 0.5447916666666667, "test_runtime": 1.7144, "test_samples_per_second": 1194.605, "test_steps_per_second": 37.331}, {"test_loss": 0.6728471517562866, "test_mcc": 0.2114856519429966, "test_macro_f1": 0.5879873304606977, "test_runtime": 1.7093, "test_samples_per_second": 1198.146, "test_steps_per_second": 37.442}, {"test_loss": 0.6573642492294312, "test_mcc": 0.3075761083344825, "test_macro_f1": 0.6471333561297061, "test_runtime": 1.7102, "test_samples_per_second": 1197.521, "test_steps_per_second": 37.423}, {"test_loss": 0.6171512603759766, "test_mcc": 0.2977272207614468, "test_macro_f1": 0.6457599985414009, "test_runtime": 1.6318, "test_samples_per_second": 1255.092, "test_steps_per_second": 39.222}, {"test_loss": 0.6521496772766113, "test_mcc": 0.23055944756425764, "test_macro_f1": 0.606355619121816, "test_runtime": 1.6389, "test_samples_per_second": 1249.613, "test_steps_per_second": 39.05}, {"test_loss": 0.6389943361282349, "test_mcc": 0.3235622068661568, "test_macro_f1": 0.6445819050319166, "test_runtime": 1.6839, "test_samples_per_second": 1216.227, "test_steps_per_second": 38.007}, {"test_loss": 0.6550273895263672, "test_mcc": 0.25375849108007126, "test_macro_f1": 0.623524255306265, "test_runtime": 1.6481, "test_samples_per_second": 1242.611, "test_steps_per_second": 38.832}, {"test_loss": 0.66206955909729, "test_mcc": 0.22610907087706641, "test_macro_f1": 0.6122100122100123, "test_runtime": 1.6831, "test_samples_per_second": 1216.832, "test_steps_per_second": 38.026}]}, "total": {"test_mcc": 26.919228047221583, "test_mcc_se": 3.124195564693504, "test_macro_f1": 61.929482797582246, "test_macro_f1_se": 2.0438731146938145}}, "num_model_parameters": 117654530, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_loss": 0.672243595123291, "test_mcc": 0.17549321386018546, "test_macro_f1": 0.5750596534910261, "test_runtime": 1.7474, "test_samples_per_second": 1172.021, "test_steps_per_second": 36.626}, {"test_loss": 0.667914628982544, "test_mcc": 0.22998170321293823, "test_macro_f1": 0.6063384047098853, "test_runtime": 1.7934, "test_samples_per_second": 1141.957, "test_steps_per_second": 35.686}, {"test_loss": 0.6663351058959961, "test_mcc": 0.2095011647785717, "test_macro_f1": 0.6038257108248664, "test_runtime": 1.8134, "test_samples_per_second": 1129.37, "test_steps_per_second": 35.293}, {"test_loss": 0.6930347681045532, "test_mcc": 0.02440592729237727, "test_macro_f1": 0.507961850503287, "test_runtime": 1.7495, "test_samples_per_second": 1170.617, "test_steps_per_second": 36.582}, {"test_loss": 0.6632187366485596, "test_mcc": 0.19996479993320312, "test_macro_f1": 0.5975740189036426, "test_runtime": 1.7808, "test_samples_per_second": 1150.015, "test_steps_per_second": 35.938}, {"test_loss": 0.6860871315002441, "test_mcc": 0.09664558269213232, "test_macro_f1": 0.5468538244604098, "test_runtime": 1.7989, "test_samples_per_second": 1138.443, "test_steps_per_second": 35.576}, {"test_loss": 0.6879544258117676, "test_mcc": 0.09649124378007663, "test_macro_f1": 0.4854643629930219, "test_runtime": 1.8536, "test_samples_per_second": 1104.873, "test_steps_per_second": 34.527}, {"test_loss": 0.6887134909629822, "test_mcc": 0.09934779790395516, "test_macro_f1": 0.5495916293163461, "test_runtime": 1.7554, "test_samples_per_second": 1166.693, "test_steps_per_second": 36.459}, {"test_loss": 0.67518550157547, "test_mcc": 0.16824320794078146, "test_macro_f1": 0.5726107969019617, "test_runtime": 1.8115, "test_samples_per_second": 1130.562, "test_steps_per_second": 35.33}, {"test_loss": 0.6765292882919312, "test_mcc": 0.16302061689136715, "test_macro_f1": 0.5789214782020538, "test_runtime": 1.8038, "test_samples_per_second": 1135.391, "test_steps_per_second": 35.481}]}, "total": {"test_mcc": 14.630952582855885, "test_mcc_se": 4.000801200445677, "test_macro_f1": 56.242017303065005, "test_macro_f1_se": 2.5057449294191816}}, "num_model_parameters": 117654530, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_em": 32.92021688613478, "test_f1": 39.06586711429835}, {"test_em": 34.49612403100775, "test_f1": 39.51753555029748}, {"test_em": 28.5935085007728, "test_f1": 34.763597770831616}, {"test_em": 36.44859813084112, "test_f1": 41.7660049721622}, {"test_em": 32.04633204633205, "test_f1": 37.53851881294531}, {"test_em": 34.69545104086353, "test_f1": 40.79691543854498}, {"test_em": 31.511009870918755, "test_f1": 37.239148873333534}, {"test_em": 35.60899922420481, "test_f1": 39.91922192649593}, {"test_em": 29.176470588235293, "test_f1": 34.82509749072349}, {"test_em": 23.757763975155278, "test_f1": 29.71694546136151}]}, "total": {"test_em": 31.92544742944662, "test_em_se": 2.3992053368244104, "test_f1": 37.514885341099436, "test_f1_se": 2.2321611534001304}}, "num_model_parameters": 117506690, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_em": 22.618125484120835, "test_f1": 30.66114183036011}, {"test_em": 21.705426356589147, "test_f1": 29.59328203436602}, {"test_em": 23.02936630602782, "test_f1": 30.805505431331387}, {"test_em": 24.84423676012461, "test_f1": 31.823805179961557}, {"test_em": 24.247104247104247, "test_f1": 32.063683428591254}, {"test_em": 25.212027756360833, "test_f1": 32.41300792741118}, {"test_em": 19.58997722095672, "test_f1": 28.0723993784927}, {"test_em": 24.90302560124127, "test_f1": 32.46360381509133}, {"test_em": 28.392156862745097, "test_f1": 36.02190545824716}, {"test_em": 24.922360248447205, "test_f1": 33.45279114991058}]}, "total": {"test_em": 23.946380684371782, "test_em_se": 1.471616167052672, "test_f1": 31.737112563376325, "test_f1_se": 1.3461445951051494}}, "num_model_parameters": 117506690, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_em": 26.49109217660728, "test_f1": 34.08507499441027}, {"test_em": 29.45736434108527, "test_f1": 36.41943357763886}, {"test_em": 23.338485316846985, "test_f1": 30.760186195372842}, {"test_em": 24.143302180685357, "test_f1": 31.63456635061664}, {"test_em": 29.498069498069498, "test_f1": 36.399748713297946}, {"test_em": 30.30069390902082, "test_f1": 36.193982535528036}, {"test_em": 22.703113135914958, "test_f1": 30.364000434385037}, {"test_em": 26.687354538401863, "test_f1": 33.654025807938304}, {"test_em": 28.392156862745097, "test_f1": 34.6356995461421}, {"test_em": 27.096273291925467, "test_f1": 34.27110591214931}]}, "total": {"test_em": 26.810790525130255, "test_em_se": 1.667604650568609, "test_f1": 33.84178240674794, "test_f1_se": 1.402650444881287}}, "num_model_parameters": 117506690, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.42769843339920044, "test_mcc": 0.7324595036526456, "test_macro_f1": 0.7573031797178583, "test_runtime": 13.6486, "test_samples_per_second": 150.052, "test_steps_per_second": 18.757}, {"test_loss": 0.5357121229171753, "test_mcc": 0.6693171402701172, "test_macro_f1": 0.5869154434299718, "test_runtime": 12.9407, "test_samples_per_second": 158.261, "test_steps_per_second": 19.783}, {"test_loss": 0.49235713481903076, "test_mcc": 0.6881573412853768, "test_macro_f1": 0.688076600503215, "test_runtime": 13.3009, "test_samples_per_second": 153.975, "test_steps_per_second": 19.247}, {"test_loss": 0.45265668630599976, "test_mcc": 0.7247651384491955, "test_macro_f1": 0.6985260864502939, "test_runtime": 12.6255, "test_samples_per_second": 162.212, "test_steps_per_second": 20.276}, {"test_loss": 0.42975127696990967, "test_mcc": 0.7353584926831492, "test_macro_f1": 0.728212518698955, "test_runtime": 12.4629, "test_samples_per_second": 164.328, "test_steps_per_second": 20.541}, {"test_loss": 0.4950559139251709, "test_mcc": 0.6759975345401322, "test_macro_f1": 0.6503478783208919, "test_runtime": 12.962, "test_samples_per_second": 158.0, "test_steps_per_second": 19.75}, {"test_loss": 0.48994842171669006, "test_mcc": 0.6800155149176497, "test_macro_f1": 0.631391581662904, "test_runtime": 12.3732, "test_samples_per_second": 165.519, "test_steps_per_second": 20.69}, {"test_loss": 0.4914247393608093, "test_mcc": 0.6753673345655535, "test_macro_f1": 0.6851420039203345, "test_runtime": 13.3157, "test_samples_per_second": 153.803, "test_steps_per_second": 19.225}, {"test_loss": 0.5489447116851807, "test_mcc": 0.6800989979711275, "test_macro_f1": 0.7032815392125124, "test_runtime": 13.2183, "test_samples_per_second": 154.937, "test_steps_per_second": 19.367}, {"test_loss": 0.44338059425354004, "test_mcc": 0.7343045206967328, "test_macro_f1": 0.7377995723851623, "test_runtime": 12.9116, "test_samples_per_second": 158.617, "test_steps_per_second": 19.827}]}, "total": {"test_mcc": 69.95841519031679, "test_mcc_se": 1.7472517611780851, "test_macro_f1": 68.669964043021, "test_macro_f1_se": 3.2057200781289965}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.9887775182723999, "test_mcc": 0.3348851847453677, "test_macro_f1": 0.5462029531394955, "test_runtime": 5.0854, "test_samples_per_second": 402.722, "test_steps_per_second": 12.585}, {"test_loss": 0.9717763066291809, "test_mcc": 0.35309607035471685, "test_macro_f1": 0.5549171021711977, "test_runtime": 5.0437, "test_samples_per_second": 406.054, "test_steps_per_second": 12.689}, {"test_loss": 0.9431682825088501, "test_mcc": 0.3574778266719949, "test_macro_f1": 0.5628718565849802, "test_runtime": 5.103, "test_samples_per_second": 401.33, "test_steps_per_second": 12.542}, {"test_loss": 0.9518616795539856, "test_mcc": 0.34020874386380817, "test_macro_f1": 0.5617367881715708, "test_runtime": 5.0061, "test_samples_per_second": 409.104, "test_steps_per_second": 12.785}, {"test_loss": 0.9418339729309082, "test_mcc": 0.3493905830207172, "test_macro_f1": 0.5676765017570728, "test_runtime": 4.9913, "test_samples_per_second": 410.311, "test_steps_per_second": 12.822}, {"test_loss": 0.9868105053901672, "test_mcc": 0.3054246112648878, "test_macro_f1": 0.5377562347033521, "test_runtime": 5.1155, "test_samples_per_second": 400.35, "test_steps_per_second": 12.511}, {"test_loss": 1.020867109298706, "test_mcc": 0.30685314186578566, "test_macro_f1": 0.5253664146384479, "test_runtime": 5.0017, "test_samples_per_second": 409.464, "test_steps_per_second": 12.796}, {"test_loss": 0.9514615535736084, "test_mcc": 0.32556366256328123, "test_macro_f1": 0.5243037524676623, "test_runtime": 5.1021, "test_samples_per_second": 401.4, "test_steps_per_second": 12.544}, {"test_loss": 0.9169982075691223, "test_mcc": 0.3718996587945662, "test_macro_f1": 0.5811794633387395, "test_runtime": 5.0871, "test_samples_per_second": 402.586, "test_steps_per_second": 12.581}, {"test_loss": 0.9741390347480774, "test_mcc": 0.30667205740099973, "test_macro_f1": 0.5305999963508797, "test_runtime": 4.939, "test_samples_per_second": 414.662, "test_steps_per_second": 12.958}]}, "total": {"test_mcc": 33.51471540546126, "test_mcc_se": 1.4589663074674255, "test_macro_f1": 54.926110633233996, "test_macro_f1_se": 1.2072657707234928}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.935461163520813, "test_mcc": 0.2714021669026417, "test_macro_f1": 0.40845260018974, "test_runtime": 4.1176, "test_samples_per_second": 497.381, "test_steps_per_second": 15.543}, {"test_loss": 0.9422825574874878, "test_mcc": 0.2990938475149315, "test_macro_f1": 0.41308995131409176, "test_runtime": 3.8461, "test_samples_per_second": 532.493, "test_steps_per_second": 16.64}, {"test_loss": 0.8971070051193237, "test_mcc": 0.29262305473171674, "test_macro_f1": 0.43476589654662745, "test_runtime": 3.855, "test_samples_per_second": 531.262, "test_steps_per_second": 16.602}, {"test_loss": 0.985831618309021, "test_mcc": 0.25056387389021617, "test_macro_f1": 0.4027352480303654, "test_runtime": 3.989, "test_samples_per_second": 513.417, "test_steps_per_second": 16.044}, {"test_loss": 0.9011472463607788, "test_mcc": 0.32380740324093193, "test_macro_f1": 0.45572203325183863, "test_runtime": 4.0237, "test_samples_per_second": 508.987, "test_steps_per_second": 15.906}, {"test_loss": 0.928978681564331, "test_mcc": 0.29205406446187687, "test_macro_f1": 0.44252816344606893, "test_runtime": 4.0642, "test_samples_per_second": 503.907, "test_steps_per_second": 15.747}, {"test_loss": 0.8839520812034607, "test_mcc": 0.3589045492709569, "test_macro_f1": 0.519185261401723, "test_runtime": 4.0114, "test_samples_per_second": 510.546, "test_steps_per_second": 15.955}, {"test_loss": 0.9217977523803711, "test_mcc": 0.26581281480295144, "test_macro_f1": 0.40633965965937363, "test_runtime": 3.9755, "test_samples_per_second": 515.15, "test_steps_per_second": 16.098}, {"test_loss": 0.9617663621902466, "test_mcc": 0.3059454878873091, "test_macro_f1": 0.4549943833592002, "test_runtime": 4.0557, "test_samples_per_second": 504.963, "test_steps_per_second": 15.78}, {"test_loss": 0.9002944231033325, "test_mcc": 0.3077109081737189, "test_macro_f1": 0.4258223533150603, "test_runtime": 4.1169, "test_samples_per_second": 497.463, "test_steps_per_second": 15.546}]}, "total": {"test_mcc": 29.67918170877251, "test_mcc_se": 1.9134224439342113, "test_macro_f1": 43.63635550514089, "test_macro_f1_se": 2.1753100701632375}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.07311204820871353, "test_micro_f1": 0.6341958396752918, "test_micro_f1_no_misc": 0.701254275940707, "test_runtime": 6.4407, "test_samples_per_second": 317.979, "test_steps_per_second": 9.937}, {"test_loss": 0.0741858035326004, "test_micro_f1": 0.6303784344219803, "test_micro_f1_no_misc": 0.6986143187066974, "test_runtime": 5.8586, "test_samples_per_second": 349.572, "test_steps_per_second": 10.924}, {"test_loss": 0.07848384976387024, "test_micro_f1": 0.5273492286115007, "test_micro_f1_no_misc": 0.5701078582434514, "test_runtime": 5.8008, "test_samples_per_second": 353.054, "test_steps_per_second": 11.033}, {"test_loss": 0.08342529088258743, "test_micro_f1": 0.5988960441582336, "test_micro_f1_no_misc": 0.6586134453781513, "test_runtime": 6.3562, "test_samples_per_second": 322.207, "test_steps_per_second": 10.069}, {"test_loss": 0.08070963621139526, "test_micro_f1": 0.5871474803513638, "test_micro_f1_no_misc": 0.6405693950177935, "test_runtime": 6.3103, "test_samples_per_second": 324.547, "test_steps_per_second": 10.142}, {"test_loss": 0.07611171901226044, "test_micro_f1": 0.6531531531531531, "test_micro_f1_no_misc": 0.7044284243048404, "test_runtime": 5.0655, "test_samples_per_second": 404.301, "test_steps_per_second": 12.634}, {"test_loss": 0.07829874008893967, "test_micro_f1": 0.6073249884098284, "test_micro_f1_no_misc": 0.6921815199562602, "test_runtime": 5.3729, "test_samples_per_second": 381.17, "test_steps_per_second": 11.912}, {"test_loss": 0.062380701303482056, "test_micro_f1": 0.6397019691325173, "test_micro_f1_no_misc": 0.7083583884546002, "test_runtime": 6.3727, "test_samples_per_second": 321.371, "test_steps_per_second": 10.043}, {"test_loss": 0.06487709283828735, "test_micro_f1": 0.653953488372093, "test_micro_f1_no_misc": 0.7381878821567538, "test_runtime": 5.9157, "test_samples_per_second": 346.199, "test_steps_per_second": 10.819}, {"test_loss": 0.0696144849061966, "test_micro_f1": 0.6682242990654206, "test_micro_f1_no_misc": 0.742671009771987, "test_runtime": 6.3336, "test_samples_per_second": 323.355, "test_steps_per_second": 10.105}]}, "total": {"test_micro_f1": 62.00324925351383, "test_micro_f1_se": 2.5758598682874845, "test_micro_f1_no_misc": 68.54986517931242, "test_micro_f1_no_misc_se": 3.163587217380638}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.09576438367366791, "test_micro_f1": 0.6979006656426011, "test_micro_f1_no_misc": 0.7267814927389395, "test_runtime": 9.3296, "test_samples_per_second": 219.516, "test_steps_per_second": 6.86}, {"test_loss": 0.08953376859426498, "test_micro_f1": 0.6663016698603886, "test_micro_f1_no_misc": 0.6997870830376153, "test_runtime": 7.4755, "test_samples_per_second": 273.963, "test_steps_per_second": 8.561}, {"test_loss": 0.09418535232543945, "test_micro_f1": 0.6811335205514425, "test_micro_f1_no_misc": 0.7140332272887946, "test_runtime": 9.1775, "test_samples_per_second": 223.154, "test_steps_per_second": 6.974}, {"test_loss": 0.09804349392652512, "test_micro_f1": 0.6811083123425693, "test_micro_f1_no_misc": 0.7130844265052135, "test_runtime": 8.7347, "test_samples_per_second": 234.468, "test_steps_per_second": 7.327}, {"test_loss": 0.09732164442539215, "test_micro_f1": 0.6937973617737861, "test_micro_f1_no_misc": 0.7300658376005853, "test_runtime": 9.48, "test_samples_per_second": 216.035, "test_steps_per_second": 6.751}, {"test_loss": 0.10966869443655014, "test_micro_f1": 0.696763202725724, "test_micro_f1_no_misc": 0.7246376811594204, "test_runtime": 8.9217, "test_samples_per_second": 229.554, "test_steps_per_second": 7.174}, {"test_loss": 0.09736869484186172, "test_micro_f1": 0.7127715951245361, "test_micro_f1_no_misc": 0.736588720770289, "test_runtime": 9.5536, "test_samples_per_second": 214.369, "test_steps_per_second": 6.699}, {"test_loss": 0.08890178054571152, "test_micro_f1": 0.6654392425039454, "test_micro_f1_no_misc": 0.7090252707581227, "test_runtime": 9.2896, "test_samples_per_second": 220.461, "test_steps_per_second": 6.889}, {"test_loss": 0.0974428728222847, "test_micro_f1": 0.7287074829931973, "test_micro_f1_no_misc": 0.7584143605086013, "test_runtime": 8.7726, "test_samples_per_second": 233.455, "test_steps_per_second": 7.295}, {"test_loss": 0.09329386055469513, "test_micro_f1": 0.673998428908091, "test_micro_f1_no_misc": 0.7, "test_runtime": 7.9055, "test_samples_per_second": 259.06, "test_steps_per_second": 8.096}]}, "total": {"test_micro_f1": 68.97921482426281, "test_micro_f1_se": 1.2596857381710442, "test_micro_f1_no_misc": 72.12418100367582, "test_micro_f1_no_misc_se": 1.1157816094084116}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.07774358987808228, "test_micro_f1": 0.6666666666666666, "test_micro_f1_no_misc": 0.7151323587514815, "test_runtime": 6.9979, "test_samples_per_second": 292.661, "test_steps_per_second": 9.146}, {"test_loss": 0.06055936962366104, "test_micro_f1": 0.7523277467411545, "test_micro_f1_no_misc": 0.7763431903373594, "test_runtime": 6.9617, "test_samples_per_second": 294.179, "test_steps_per_second": 9.193}, {"test_loss": 0.0756056159734726, "test_micro_f1": 0.6749740394600207, "test_micro_f1_no_misc": 0.7041397645271553, "test_runtime": 6.5296, "test_samples_per_second": 313.65, "test_steps_per_second": 9.802}, {"test_loss": 0.0737316831946373, "test_micro_f1": 0.6657736101808439, "test_micro_f1_no_misc": 0.6927710843373495, "test_runtime": 6.653, "test_samples_per_second": 307.83, "test_steps_per_second": 9.62}, {"test_loss": 0.06894943118095398, "test_micro_f1": 0.7400194741966893, "test_micro_f1_no_misc": 0.7632920611798981, "test_runtime": 7.1168, "test_samples_per_second": 287.77, "test_steps_per_second": 8.993}, {"test_loss": 0.06984181702136993, "test_micro_f1": 0.7345044746436858, "test_micro_f1_no_misc": 0.7588235294117648, "test_runtime": 7.0215, "test_samples_per_second": 291.674, "test_steps_per_second": 9.115}, {"test_loss": 0.0750085711479187, "test_micro_f1": 0.7050801227412206, "test_micro_f1_no_misc": 0.7311746987951807, "test_runtime": 6.448, "test_samples_per_second": 317.62, "test_steps_per_second": 9.926}, {"test_loss": 0.06670161336660385, "test_micro_f1": 0.7139973082099597, "test_micro_f1_no_misc": 0.7386609071274297, "test_runtime": 6.5118, "test_samples_per_second": 314.504, "test_steps_per_second": 9.828}, {"test_loss": 0.08021952211856842, "test_micro_f1": 0.6354309165526676, "test_micro_f1_no_misc": 0.6740373617994663, "test_runtime": 6.5565, "test_samples_per_second": 312.364, "test_steps_per_second": 9.761}, {"test_loss": 0.07970529049634933, "test_micro_f1": 0.6904761904761905, "test_micro_f1_no_misc": 0.7192792792792793, "test_runtime": 6.6718, "test_samples_per_second": 306.964, "test_steps_per_second": 9.593}]}, "total": {"test_micro_f1": 69.792505498691, "test_micro_f1_se": 2.344521375617122, "test_micro_f1_no_misc": 72.73654235546364, "test_micro_f1_no_misc_se": 2.0260045957125423}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.09083659946918488, "test_micro_f1": 0.6446329336063176, "test_micro_f1_no_misc": 0.6833122629582806, "test_runtime": 6.3327, "test_samples_per_second": 323.403, "test_steps_per_second": 10.106}, {"test_loss": 0.0893336683511734, "test_micro_f1": 0.699317304838231, "test_micro_f1_no_misc": 0.7311118442758165, "test_runtime": 6.4127, "test_samples_per_second": 319.366, "test_steps_per_second": 9.98}, {"test_loss": 0.08633506298065186, "test_micro_f1": 0.6607407407407406, "test_micro_f1_no_misc": 0.7034710743801652, "test_runtime": 6.0751, "test_samples_per_second": 337.113, "test_steps_per_second": 10.535}, {"test_loss": 0.09441418945789337, "test_micro_f1": 0.6321605117766792, "test_micro_f1_no_misc": 0.6716906946264745, "test_runtime": 6.3971, "test_samples_per_second": 320.143, "test_steps_per_second": 10.004}, {"test_loss": 0.10107624530792236, "test_micro_f1": 0.6052163604030825, "test_micro_f1_no_misc": 0.662046204620462, "test_runtime": 6.2898, "test_samples_per_second": 325.604, "test_steps_per_second": 10.175}, {"test_loss": 0.09510037302970886, "test_micro_f1": 0.6704309063893016, "test_micro_f1_no_misc": 0.7110228401191658, "test_runtime": 6.2579, "test_samples_per_second": 327.268, "test_steps_per_second": 10.227}, {"test_loss": 0.08805470168590546, "test_micro_f1": 0.6312292358803987, "test_micro_f1_no_misc": 0.6752052545155993, "test_runtime": 6.45, "test_samples_per_second": 317.519, "test_steps_per_second": 9.922}, {"test_loss": 0.08096867054700851, "test_micro_f1": 0.7009996970614966, "test_micro_f1_no_misc": 0.7403751233958539, "test_runtime": 6.4651, "test_samples_per_second": 316.778, "test_steps_per_second": 9.899}, {"test_loss": 0.09637390822172165, "test_micro_f1": 0.6265348906858341, "test_micro_f1_no_misc": 0.6670988654781199, "test_runtime": 6.0601, "test_samples_per_second": 337.95, "test_steps_per_second": 10.561}, {"test_loss": 0.08041690289974213, "test_micro_f1": 0.6880484114977308, "test_micro_f1_no_misc": 0.7286615742278313, "test_runtime": 6.1602, "test_samples_per_second": 332.454, "test_steps_per_second": 10.389}]}, "total": {"test_micro_f1": 65.59310992879813, "test_micro_f1_se": 2.0574745069294473, "test_micro_f1_no_misc": 69.73995738597768, "test_micro_f1_no_misc_se": 1.8132989147596135}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.43564385175704956, "test_mcc": 0.6686652776415276, "test_macro_f1": 0.832994911754467, "test_runtime": 2.9099, "test_samples_per_second": 703.798, "test_steps_per_second": 21.994}, {"test_loss": 0.6930066347122192, "test_mcc": 0.030750054288280388, "test_macro_f1": 0.5112158889130524, "test_runtime": 2.9914, "test_samples_per_second": 684.627, "test_steps_per_second": 21.395}, {"test_loss": 0.6741538643836975, "test_mcc": 0.17294843430038312, "test_macro_f1": 0.5459795998851881, "test_runtime": 3.0291, "test_samples_per_second": 676.118, "test_steps_per_second": 21.129}, {"test_loss": 0.4116637110710144, "test_mcc": 0.6510658371361294, "test_macro_f1": 0.8246709519436792, "test_runtime": 2.9585, "test_samples_per_second": 692.246, "test_steps_per_second": 21.633}, {"test_loss": 0.4704113304615021, "test_mcc": 0.6419556686190733, "test_macro_f1": 0.8113525310410006, "test_runtime": 3.0179, "test_samples_per_second": 678.621, "test_steps_per_second": 21.207}, {"test_loss": 0.4213959276676178, "test_mcc": 0.6406225953379376, "test_macro_f1": 0.8072549866389891, "test_runtime": 3.0411, "test_samples_per_second": 673.439, "test_steps_per_second": 21.045}, {"test_loss": 0.4008680582046509, "test_mcc": 0.6692062871957555, "test_macro_f1": 0.8277711355187434, "test_runtime": 2.9568, "test_samples_per_second": 692.652, "test_steps_per_second": 21.645}, {"test_loss": 0.4676609933376312, "test_mcc": 0.561610430297816, "test_macro_f1": 0.761157691016364, "test_runtime": 2.9978, "test_samples_per_second": 683.158, "test_steps_per_second": 21.349}, {"test_loss": 0.4457052946090698, "test_mcc": 0.6069185032720359, "test_macro_f1": 0.7874522078817039, "test_runtime": 2.9915, "test_samples_per_second": 684.617, "test_steps_per_second": 21.394}, {"test_loss": 0.43261879682540894, "test_mcc": 0.6438103575364057, "test_macro_f1": 0.815192087450453, "test_runtime": 3.0181, "test_samples_per_second": 678.581, "test_steps_per_second": 21.206}]}, "total": {"test_mcc": 52.87553445625346, "test_mcc_se": 14.23343499679197, "test_macro_f1": 75.2504199204364, "test_macro_f1_se": 7.446600301409194}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.6871996521949768, "test_mcc": 0.0758413308842027, "test_macro_f1": 0.5353901996370236, "test_runtime": 4.3536, "test_samples_per_second": 470.411, "test_steps_per_second": 14.7}, {"test_loss": 0.695426344871521, "test_mcc": 0.046788850365305654, "test_macro_f1": 0.469192601211857, "test_runtime": 4.5377, "test_samples_per_second": 451.326, "test_steps_per_second": 14.104}, {"test_loss": 0.6990472078323364, "test_mcc": -0.04380579567715868, "test_macro_f1": 0.4775385642419474, "test_runtime": 4.4253, "test_samples_per_second": 462.798, "test_steps_per_second": 14.462}, {"test_loss": 0.6950443983078003, "test_mcc": 0.0016724216981642928, "test_macro_f1": 0.49492743383780013, "test_runtime": 4.6682, "test_samples_per_second": 438.711, "test_steps_per_second": 13.71}, {"test_loss": 0.689145565032959, "test_mcc": 0.08416485252207888, "test_macro_f1": 0.5126013201048949, "test_runtime": 4.4267, "test_samples_per_second": 462.643, "test_steps_per_second": 14.458}, {"test_loss": 0.6267300248146057, "test_mcc": 0.30749889370605094, "test_macro_f1": 0.6531880142266184, "test_runtime": 4.3897, "test_samples_per_second": 466.549, "test_steps_per_second": 14.58}, {"test_loss": 0.6880995035171509, "test_mcc": 0.0915010247626423, "test_macro_f1": 0.5389162561576355, "test_runtime": 4.3107, "test_samples_per_second": 475.102, "test_steps_per_second": 14.847}, {"test_loss": 0.6585238575935364, "test_mcc": 0.22613803166485294, "test_macro_f1": 0.5702653007617546, "test_runtime": 4.3413, "test_samples_per_second": 471.745, "test_steps_per_second": 14.742}, {"test_loss": 0.6905272006988525, "test_mcc": 0.028218730935590887, "test_macro_f1": 0.48029186922572387, "test_runtime": 4.4179, "test_samples_per_second": 463.565, "test_steps_per_second": 14.486}, {"test_loss": 0.591330885887146, "test_mcc": 0.3898840686647705, "test_macro_f1": 0.6915307397202016, "test_runtime": 4.4907, "test_samples_per_second": 456.051, "test_steps_per_second": 14.252}]}, "total": {"test_mcc": 12.079024095265005, "test_mcc_se": 8.714498081113621, "test_macro_f1": 54.23842299125457, "test_macro_f1_se": 4.7074950672459215}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.6889296770095825, "test_mcc": 0.058706390633241505, "test_macro_f1": 0.5287138964564608, "test_runtime": 3.9083, "test_samples_per_second": 524.018, "test_steps_per_second": 16.376}, {"test_loss": 0.6924988031387329, "test_mcc": 0.006447677956466684, "test_macro_f1": 0.4682023858494446, "test_runtime": 4.017, "test_samples_per_second": 509.834, "test_steps_per_second": 15.932}, {"test_loss": 0.6225898265838623, "test_mcc": 0.3719955637728191, "test_macro_f1": 0.6517181922234019, "test_runtime": 3.9337, "test_samples_per_second": 520.63, "test_steps_per_second": 16.27}, {"test_loss": 0.6141557693481445, "test_mcc": 0.3971482429921845, "test_macro_f1": 0.6813123126103509, "test_runtime": 4.0315, "test_samples_per_second": 507.993, "test_steps_per_second": 15.875}, {"test_loss": 0.6943176984786987, "test_mcc": 0.03527309192738414, "test_macro_f1": 0.4936526773833927, "test_runtime": 4.0076, "test_samples_per_second": 511.031, "test_steps_per_second": 15.97}, {"test_loss": 0.5828933119773865, "test_mcc": 0.4005967464295798, "test_macro_f1": 0.6893034206965185, "test_runtime": 3.8408, "test_samples_per_second": 533.216, "test_steps_per_second": 16.663}, {"test_loss": 0.6910209655761719, "test_mcc": 0.10372641579707696, "test_macro_f1": 0.5145730137112876, "test_runtime": 3.9162, "test_samples_per_second": 522.956, "test_steps_per_second": 16.342}, {"test_loss": 0.6883863210678101, "test_mcc": 0.0553942148674955, "test_macro_f1": 0.4859900621709427, "test_runtime": 3.8905, "test_samples_per_second": 526.413, "test_steps_per_second": 16.45}, {"test_loss": 0.6870749592781067, "test_mcc": 0.09482163799627465, "test_macro_f1": 0.5122568485134681, "test_runtime": 3.9565, "test_samples_per_second": 517.631, "test_steps_per_second": 16.176}, {"test_loss": 0.6976562738418579, "test_mcc": 0.05896367287455544, "test_macro_f1": 0.5249953996197019, "test_runtime": 4.007, "test_samples_per_second": 511.105, "test_steps_per_second": 15.972}]}, "total": {"test_mcc": 15.830736552470784, "test_mcc_se": 10.057953883323618, "test_macro_f1": 55.50718209234968, "test_macro_f1_se": 5.245367995549541}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_loss": 0.6943578720092773, "test_mcc": 0.005025741081857404, "test_macro_f1": 0.5024437927663734, "test_runtime": 4.0697, "test_samples_per_second": 503.236, "test_steps_per_second": 15.726}, {"test_loss": 0.6959335207939148, "test_mcc": 0.03235608219280483, "test_macro_f1": 0.4650042242030359, "test_runtime": 4.1791, "test_samples_per_second": 490.055, "test_steps_per_second": 15.314}, {"test_loss": 0.636616587638855, "test_mcc": 0.280531875177023, "test_macro_f1": 0.622462416852174, "test_runtime": 4.1451, "test_samples_per_second": 494.078, "test_steps_per_second": 15.44}, {"test_loss": 0.7006411552429199, "test_mcc": 0.020074093693827504, "test_macro_f1": 0.4709374747229637, "test_runtime": 3.8779, "test_samples_per_second": 528.119, "test_steps_per_second": 16.504}, {"test_loss": 0.6917737126350403, "test_mcc": 0.060487203960203816, "test_macro_f1": 0.5239132296624375, "test_runtime": 3.9981, "test_samples_per_second": 512.249, "test_steps_per_second": 16.008}, {"test_loss": 0.6863296627998352, "test_mcc": 0.11397724357988143, "test_macro_f1": 0.5342655853211418, "test_runtime": 4.1293, "test_samples_per_second": 495.969, "test_steps_per_second": 15.499}, {"test_loss": 0.6892603635787964, "test_mcc": 0.0833386602518427, "test_macro_f1": 0.5284303202801945, "test_runtime": 3.9712, "test_samples_per_second": 515.707, "test_steps_per_second": 16.116}, {"test_loss": 0.689568281173706, "test_mcc": 0.07748535445110605, "test_macro_f1": 0.5247431664600046, "test_runtime": 4.0691, "test_samples_per_second": 503.308, "test_steps_per_second": 15.728}, {"test_loss": 0.6897826194763184, "test_mcc": 0.0914974946366253, "test_macro_f1": 0.5457482253399939, "test_runtime": 3.9727, "test_samples_per_second": 515.513, "test_steps_per_second": 16.11}, {"test_loss": 0.6886783838272095, "test_mcc": 0.10499916487791107, "test_macro_f1": 0.5514979626272236, "test_runtime": 4.1457, "test_samples_per_second": 494.007, "test_steps_per_second": 15.438}]}, "total": {"test_mcc": 8.69772913903083, "test_mcc_se": 4.779535305065549, "test_macro_f1": 52.69446398235542, "test_macro_f1_se": 2.7504972349372316}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_em": 31.603408210689388, "test_f1": 34.82538295321123}, {"test_em": 32.713178294573645, "test_f1": 35.48451648683849}, {"test_em": 30.602782071097373, "test_f1": 33.708396586110354}, {"test_em": 30.8411214953271, "test_f1": 34.53617990435141}, {"test_em": 34.51737451737452, "test_f1": 37.82340666374281}, {"test_em": 30.840400925212027, "test_f1": 33.965867206603754}, {"test_em": 26.42369020501139, "test_f1": 29.080509522549907}, {"test_em": 24.82544608223429, "test_f1": 28.09457084739481}, {"test_em": 31.45098039215686, "test_f1": 34.87057483684692}, {"test_em": 31.366459627329192, "test_f1": 34.650308676062004}]}, "total": {"test_em": 30.518484182100575, "test_em_se": 1.7648023253457361, "test_f1": 33.70397136837117, "test_f1_se": 1.8159508262304143}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_em": 31.835786212238574, "test_f1": 35.8732141146894}, {"test_em": 37.5968992248062, "test_f1": 42.37617446845974}, {"test_em": 30.98918083462133, "test_f1": 35.61833074569878}, {"test_em": 25.31152647975078, "test_f1": 30.135277477693805}, {"test_em": 31.583011583011583, "test_f1": 36.42923528107076}, {"test_em": 26.754047802621432, "test_f1": 30.906440332567687}, {"test_em": 28.929384965831435, "test_f1": 33.441613004720836}, {"test_em": 27.773467804499614, "test_f1": 32.192251484416445}, {"test_em": 27.529411764705884, "test_f1": 33.039719061299834}, {"test_em": 34.006211180124225, "test_f1": 38.98287028068603}]}, "total": {"test_em": 30.23089278522111, "test_em_se": 2.308121022270499, "test_f1": 34.89951262513033, "test_f1_se": 2.336845171910273}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_em": 32.37800154918668, "test_f1": 37.327378478503014}, {"test_em": 38.21705426356589, "test_f1": 42.43948496977765}, {"test_em": 34.38948995363215, "test_f1": 38.42118143911693}, {"test_em": 34.11214953271028, "test_f1": 38.18989662555482}, {"test_em": 31.428571428571427, "test_f1": 36.16946896119058}, {"test_em": 36.9313801079414, "test_f1": 41.00991780452331}, {"test_em": 32.80182232346242, "test_f1": 36.89215340760342}, {"test_em": 34.60046547711404, "test_f1": 38.32829409524554}, {"test_em": 34.27450980392157, "test_f1": 39.489730362133166}, {"test_em": 31.444099378881987, "test_f1": 35.56924305535276}]}, "total": {"test_em": 34.05775438189878, "test_em_se": 1.3728515000943133, "test_f1": 38.38367491990012, "test_f1_se": 1.3192846990241527}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.5132026672363281, "test_mcc": 0.6665446859190366, "test_macro_f1": 0.6601697155062344, "test_runtime": 8.5871, "test_samples_per_second": 238.498, "test_steps_per_second": 29.812}, {"test_loss": 0.5917866230010986, "test_mcc": 0.6073508909064504, "test_macro_f1": 0.5892086622932733, "test_runtime": 8.4082, "test_samples_per_second": 243.571, "test_steps_per_second": 30.446}, {"test_loss": 0.6149970889091492, "test_mcc": 0.5991586836083092, "test_macro_f1": 0.5842773699755853, "test_runtime": 8.5023, "test_samples_per_second": 240.877, "test_steps_per_second": 30.11}, {"test_loss": 0.5549505352973938, "test_mcc": 0.6148128109061852, "test_macro_f1": 0.6551954893813462, "test_runtime": 8.2587, "test_samples_per_second": 247.981, "test_steps_per_second": 30.998}, {"test_loss": 0.5524681210517883, "test_mcc": 0.6281515326642368, "test_macro_f1": 0.559571731595946, "test_runtime": 8.1989, "test_samples_per_second": 249.789, "test_steps_per_second": 31.224}, {"test_loss": 0.5777205228805542, "test_mcc": 0.6248657561039048, "test_macro_f1": 0.6341077751299267, "test_runtime": 8.4314, "test_samples_per_second": 242.903, "test_steps_per_second": 30.363}, {"test_loss": 0.6293889284133911, "test_mcc": 0.6070523891442002, "test_macro_f1": 0.547188995215311, "test_runtime": 8.1084, "test_samples_per_second": 252.576, "test_steps_per_second": 31.572}, {"test_loss": 0.5555727481842041, "test_mcc": 0.6183449835385052, "test_macro_f1": 0.5882511380471156, "test_runtime": 8.6934, "test_samples_per_second": 235.58, "test_steps_per_second": 29.448}, {"test_loss": 0.5791482329368591, "test_mcc": 0.6115667041062178, "test_macro_f1": 0.5499046387884061, "test_runtime": 8.6051, "test_samples_per_second": 237.998, "test_steps_per_second": 29.75}, {"test_loss": 0.5407860279083252, "test_mcc": 0.6319287161159464, "test_macro_f1": 0.6591358233299305, "test_runtime": 8.3786, "test_samples_per_second": 244.431, "test_steps_per_second": 30.554}]}, "total": {"test_mcc": 62.09777153012992, "test_mcc_se": 1.1781818147889382, "test_macro_f1": 60.27011339263074, "test_macro_f1_se": 2.8244139936756816}}, "num_model_parameters": 135328515, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 1.0017350912094116, "test_mcc": 0.33571984153376083, "test_macro_f1": 0.5578265781036005, "test_runtime": 2.7041, "test_samples_per_second": 757.371, "test_steps_per_second": 23.668}, {"test_loss": 0.9683842658996582, "test_mcc": 0.3330560601347671, "test_macro_f1": 0.5459850507994725, "test_runtime": 2.682, "test_samples_per_second": 763.621, "test_steps_per_second": 23.863}, {"test_loss": 1.1081082820892334, "test_mcc": 0.33448067856479696, "test_macro_f1": 0.5479254438482195, "test_runtime": 2.6856, "test_samples_per_second": 762.585, "test_steps_per_second": 23.831}, {"test_loss": 1.0535719394683838, "test_mcc": 0.28614963971511664, "test_macro_f1": 0.5223188998016393, "test_runtime": 2.6616, "test_samples_per_second": 769.473, "test_steps_per_second": 24.046}, {"test_loss": 1.0047845840454102, "test_mcc": 0.324726120143262, "test_macro_f1": 0.5353608029396729, "test_runtime": 2.6164, "test_samples_per_second": 782.746, "test_steps_per_second": 24.461}, {"test_loss": 1.105769395828247, "test_mcc": 0.2813381509609995, "test_macro_f1": 0.49209408289592843, "test_runtime": 2.6756, "test_samples_per_second": 765.431, "test_steps_per_second": 23.92}, {"test_loss": 1.0168960094451904, "test_mcc": 0.33630337610329836, "test_macro_f1": 0.5292163717903281, "test_runtime": 2.7134, "test_samples_per_second": 754.76, "test_steps_per_second": 23.586}, {"test_loss": 1.0395512580871582, "test_mcc": 0.3319339347331565, "test_macro_f1": 0.5440726932840497, "test_runtime": 2.6698, "test_samples_per_second": 767.097, "test_steps_per_second": 23.972}, {"test_loss": 0.9693227410316467, "test_mcc": 0.3152378625708695, "test_macro_f1": 0.5298028327143681, "test_runtime": 2.6932, "test_samples_per_second": 760.445, "test_steps_per_second": 23.764}, {"test_loss": 1.0237637758255005, "test_mcc": 0.236587996556343, "test_macro_f1": 0.42078449667463297, "test_runtime": 2.5859, "test_samples_per_second": 791.986, "test_steps_per_second": 24.75}]}, "total": {"test_mcc": 31.155336610163705, "test_mcc_se": 2.0624222302121638, "test_macro_f1": 52.25387252851912, "test_macro_f1_se": 2.4831627637963973}}, "num_model_parameters": 135328515, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.931789219379425, "test_mcc": 0.33798168500646614, "test_macro_f1": 0.4328067083886283, "test_runtime": 2.1056, "test_samples_per_second": 972.624, "test_steps_per_second": 30.395}, {"test_loss": 0.888288676738739, "test_mcc": 0.2723829689258368, "test_macro_f1": 0.3917739213380111, "test_runtime": 1.9971, "test_samples_per_second": 1025.507, "test_steps_per_second": 32.047}, {"test_loss": 0.8415716886520386, "test_mcc": 0.37632631680029005, "test_macro_f1": 0.511039981747002, "test_runtime": 2.0544, "test_samples_per_second": 996.874, "test_steps_per_second": 31.152}, {"test_loss": 0.93647301197052, "test_mcc": 0.2734665867149113, "test_macro_f1": 0.4111358645690057, "test_runtime": 2.0282, "test_samples_per_second": 1009.777, "test_steps_per_second": 31.556}, {"test_loss": 0.8749351501464844, "test_mcc": 0.2889390437092948, "test_macro_f1": 0.41402014852101837, "test_runtime": 2.0482, "test_samples_per_second": 999.886, "test_steps_per_second": 31.246}, {"test_loss": 0.9681864976882935, "test_mcc": 0.30056409361967734, "test_macro_f1": 0.4127162475477082, "test_runtime": 2.0852, "test_samples_per_second": 982.158, "test_steps_per_second": 30.692}, {"test_loss": 0.9179188013076782, "test_mcc": 0.3477011503525138, "test_macro_f1": 0.4841034268471267, "test_runtime": 2.0686, "test_samples_per_second": 990.034, "test_steps_per_second": 30.939}, {"test_loss": 0.8771634101867676, "test_mcc": 0.28279051899078833, "test_macro_f1": 0.4134984388327882, "test_runtime": 2.0634, "test_samples_per_second": 992.554, "test_steps_per_second": 31.017}, {"test_loss": 0.9049450159072876, "test_mcc": 0.28692827126391846, "test_macro_f1": 0.4074058777033234, "test_runtime": 2.1003, "test_samples_per_second": 975.079, "test_steps_per_second": 30.471}, {"test_loss": 0.9043961763381958, "test_mcc": 0.2704470088459843, "test_macro_f1": 0.40585081585081584, "test_runtime": 2.1103, "test_samples_per_second": 970.5, "test_steps_per_second": 30.328}]}, "total": {"test_mcc": 30.375276442296812, "test_mcc_se": 2.2943708025662937, "test_macro_f1": 42.84351431345428, "test_macro_f1_se": 2.3750442108654766}}, "num_model_parameters": 135328515, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.07055187225341797, "test_micro_f1": 0.6702862783810465, "test_micro_f1_no_misc": 0.7563025210084034, "test_runtime": 4.8748, "test_samples_per_second": 420.117, "test_steps_per_second": 13.129}, {"test_loss": 0.06598871946334839, "test_micro_f1": 0.6590078328981723, "test_micro_f1_no_misc": 0.7229204069419509, "test_runtime": 4.5438, "test_samples_per_second": 450.725, "test_steps_per_second": 14.085}, {"test_loss": 0.062177613377571106, "test_micro_f1": 0.6295620437956204, "test_micro_f1_no_misc": 0.7134376686454399, "test_runtime": 4.4967, "test_samples_per_second": 455.441, "test_steps_per_second": 14.233}, {"test_loss": 0.05962759256362915, "test_micro_f1": 0.6619183285849953, "test_micro_f1_no_misc": 0.718816067653277, "test_runtime": 4.6997, "test_samples_per_second": 435.776, "test_steps_per_second": 13.618}, {"test_loss": 0.06867852807044983, "test_micro_f1": 0.6849834201800095, "test_micro_f1_no_misc": 0.7291775798847565, "test_runtime": 4.8653, "test_samples_per_second": 420.936, "test_steps_per_second": 13.154}, {"test_loss": 0.061986371874809265, "test_micro_f1": 0.6724452554744526, "test_micro_f1_no_misc": 0.7180020811654527, "test_runtime": 3.9814, "test_samples_per_second": 514.39, "test_steps_per_second": 16.075}, {"test_loss": 0.0708731859922409, "test_micro_f1": 0.6554621848739496, "test_micro_f1_no_misc": 0.7454445057979018, "test_runtime": 4.1865, "test_samples_per_second": 489.196, "test_steps_per_second": 15.287}, {"test_loss": 0.06025087833404541, "test_micro_f1": 0.6420395421436005, "test_micro_f1_no_misc": 0.7075075075075075, "test_runtime": 5.1029, "test_samples_per_second": 401.344, "test_steps_per_second": 12.542}, {"test_loss": 0.06041981279850006, "test_micro_f1": 0.7016867469879519, "test_micro_f1_no_misc": 0.7398286937901498, "test_runtime": 4.5771, "test_samples_per_second": 447.445, "test_steps_per_second": 13.983}, {"test_loss": 0.06451518833637238, "test_micro_f1": 0.7209971236816874, "test_micro_f1_no_misc": 0.7897323866739486, "test_runtime": 4.6703, "test_samples_per_second": 438.513, "test_steps_per_second": 13.704}]}, "total": {"test_micro_f1": 66.98388757001486, "test_micro_f1_se": 1.6847344634358794, "test_micro_f1_no_misc": 73.41169419068788, "test_micro_f1_no_misc_se": 1.535746817320193}}, "num_model_parameters": 134742537, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.07264493405818939, "test_micro_f1": 0.7565084226646248, "test_micro_f1_no_misc": 0.7688647178789939, "test_runtime": 5.7187, "test_samples_per_second": 358.123, "test_steps_per_second": 11.191}, {"test_loss": 0.0758560374379158, "test_micro_f1": 0.7531521434575511, "test_micro_f1_no_misc": 0.7763253449527959, "test_runtime": 4.3426, "test_samples_per_second": 471.612, "test_steps_per_second": 14.738}, {"test_loss": 0.07662829756736755, "test_micro_f1": 0.7376038595550791, "test_micro_f1_no_misc": 0.7547304534094966, "test_runtime": 5.6422, "test_samples_per_second": 362.98, "test_steps_per_second": 11.343}, {"test_loss": 0.07979349792003632, "test_micro_f1": 0.7544447307395002, "test_micro_f1_no_misc": 0.7619047619047619, "test_runtime": 5.3242, "test_samples_per_second": 384.661, "test_steps_per_second": 12.021}, {"test_loss": 0.08261920511722565, "test_micro_f1": 0.7222377622377621, "test_micro_f1_no_misc": 0.7412953949831524, "test_runtime": 5.5692, "test_samples_per_second": 367.735, "test_steps_per_second": 11.492}, {"test_loss": 0.0756097286939621, "test_micro_f1": 0.7502070107645598, "test_micro_f1_no_misc": 0.7635968092820886, "test_runtime": 5.469, "test_samples_per_second": 374.477, "test_steps_per_second": 11.702}, {"test_loss": 0.07392408698797226, "test_micro_f1": 0.7391537225495447, "test_micro_f1_no_misc": 0.7493055555555556, "test_runtime": 5.6951, "test_samples_per_second": 359.609, "test_steps_per_second": 11.238}, {"test_loss": 0.06648018956184387, "test_micro_f1": 0.7614926987560844, "test_micro_f1_no_misc": 0.7887220798242403, "test_runtime": 5.566, "test_samples_per_second": 367.948, "test_steps_per_second": 11.498}, {"test_loss": 0.08210103213787079, "test_micro_f1": 0.7435828154552824, "test_micro_f1_no_misc": 0.7468400144456482, "test_runtime": 5.3432, "test_samples_per_second": 383.287, "test_steps_per_second": 11.978}, {"test_loss": 0.07537493109703064, "test_micro_f1": 0.7648648648648648, "test_micro_f1_no_misc": 0.7767341040462428, "test_runtime": 4.646, "test_samples_per_second": 440.812, "test_steps_per_second": 13.775}]}, "total": {"test_micro_f1": 74.83248031044853, "test_micro_f1_se": 0.7948963804181389, "test_micro_f1_no_misc": 76.28319236282975, "test_micro_f1_no_misc_se": 0.9358055734039629}}, "num_model_parameters": 134742537, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.05331414192914963, "test_micro_f1": 0.7625538020086083, "test_micro_f1_no_misc": 0.8053636733035352, "test_runtime": 4.2829, "test_samples_per_second": 478.182, "test_steps_per_second": 14.943}, {"test_loss": 0.050581157207489014, "test_micro_f1": 0.781496803309515, "test_micro_f1_no_misc": 0.8148148148148148, "test_runtime": 4.2926, "test_samples_per_second": 477.101, "test_steps_per_second": 14.909}, {"test_loss": 0.053629662841558456, "test_micro_f1": 0.8043940467753367, "test_micro_f1_no_misc": 0.8319493871095295, "test_runtime": 4.0303, "test_samples_per_second": 508.151, "test_steps_per_second": 15.88}, {"test_loss": 0.04452641308307648, "test_micro_f1": 0.8084656084656086, "test_micro_f1_no_misc": 0.8349282296650719, "test_runtime": 3.943, "test_samples_per_second": 519.396, "test_steps_per_second": 16.231}, {"test_loss": 0.04651924967765808, "test_micro_f1": 0.8260292164674634, "test_micro_f1_no_misc": 0.8585402558314523, "test_runtime": 4.2488, "test_samples_per_second": 482.024, "test_steps_per_second": 15.063}, {"test_loss": 0.04087856039404869, "test_micro_f1": 0.8337300238014282, "test_micro_f1_no_misc": 0.8592195868400918, "test_runtime": 4.3247, "test_samples_per_second": 473.555, "test_steps_per_second": 14.799}, {"test_loss": 0.048167575150728226, "test_micro_f1": 0.7650459027541653, "test_micro_f1_no_misc": 0.8061420345489443, "test_runtime": 3.8185, "test_samples_per_second": 536.336, "test_steps_per_second": 16.76}, {"test_loss": 0.04627238214015961, "test_micro_f1": 0.7917808219178082, "test_micro_f1_no_misc": 0.8191252779836917, "test_runtime": 4.0672, "test_samples_per_second": 503.545, "test_steps_per_second": 15.736}, {"test_loss": 0.04218355938792229, "test_micro_f1": 0.832914121451671, "test_micro_f1_no_misc": 0.8543767648245261, "test_runtime": 3.9626, "test_samples_per_second": 516.836, "test_steps_per_second": 16.151}, {"test_loss": 0.06097305938601494, "test_micro_f1": 0.7736930860033728, "test_micro_f1_no_misc": 0.8134601316752011, "test_runtime": 4.1117, "test_samples_per_second": 498.091, "test_steps_per_second": 15.565}]}, "total": {"test_micro_f1": 79.80103432954976, "test_micro_f1_se": 1.6880728002185679, "test_micro_f1_no_misc": 82.97920156596858, "test_micro_f1_no_misc_se": 1.3210878011987013}}, "num_model_parameters": 134742537, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.062453411519527435, "test_micro_f1": 0.7424522489217499, "test_micro_f1_no_misc": 0.7824337914850821, "test_runtime": 4.0283, "test_samples_per_second": 508.397, "test_steps_per_second": 15.887}, {"test_loss": 0.06486523896455765, "test_micro_f1": 0.761817627325404, "test_micro_f1_no_misc": 0.8027491408934707, "test_runtime": 4.187, "test_samples_per_second": 489.127, "test_steps_per_second": 15.285}, {"test_loss": 0.06583860516548157, "test_micro_f1": 0.7399938893981057, "test_micro_f1_no_misc": 0.7771775827143822, "test_runtime": 3.9173, "test_samples_per_second": 522.809, "test_steps_per_second": 16.338}, {"test_loss": 0.0706605389714241, "test_micro_f1": 0.7254257544069316, "test_micro_f1_no_misc": 0.7657180675049635, "test_runtime": 4.0022, "test_samples_per_second": 511.719, "test_steps_per_second": 15.991}, {"test_loss": 0.07355479896068573, "test_micro_f1": 0.7168566286742651, "test_micro_f1_no_misc": 0.7615514333895447, "test_runtime": 3.9326, "test_samples_per_second": 520.77, "test_steps_per_second": 16.274}, {"test_loss": 0.06592610478401184, "test_micro_f1": 0.7279172821270309, "test_micro_f1_no_misc": 0.7747866053841103, "test_runtime": 3.882, "test_samples_per_second": 527.57, "test_steps_per_second": 16.487}, {"test_loss": 0.06744521111249924, "test_micro_f1": 0.6834904226208575, "test_micro_f1_no_misc": 0.7325505544683627, "test_runtime": 4.1599, "test_samples_per_second": 492.32, "test_steps_per_second": 15.385}, {"test_loss": 0.06362099945545197, "test_micro_f1": 0.694971394158386, "test_micro_f1_no_misc": 0.7456966547580384, "test_runtime": 4.0979, "test_samples_per_second": 499.774, "test_steps_per_second": 15.618}, {"test_loss": 0.07584743946790695, "test_micro_f1": 0.7282305546947628, "test_micro_f1_no_misc": 0.7710184552289816, "test_runtime": 3.766, "test_samples_per_second": 543.818, "test_steps_per_second": 16.994}, {"test_loss": 0.06745916604995728, "test_micro_f1": 0.708018154311649, "test_micro_f1_no_misc": 0.7515268402442945, "test_runtime": 3.9034, "test_samples_per_second": 524.671, "test_steps_per_second": 16.396}]}, "total": {"test_micro_f1": 72.29173956639143, "test_micro_f1_se": 1.4373557593228032, "test_micro_f1_no_misc": 76.65209126071231, "test_micro_f1_no_misc_se": 1.240579340001462}}, "num_model_parameters": 134742537, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.6055998802185059, "test_mcc": 0.353152986288971, "test_macro_f1": 0.672005752137929, "test_runtime": 2.0508, "test_samples_per_second": 998.613, "test_steps_per_second": 31.207}, {"test_loss": 0.6211552619934082, "test_mcc": 0.33557755693180863, "test_macro_f1": 0.6607457682538194, "test_runtime": 2.1068, "test_samples_per_second": 972.072, "test_steps_per_second": 30.377}, {"test_loss": 0.5892957448959351, "test_mcc": 0.3744294684832479, "test_macro_f1": 0.6848926372136128, "test_runtime": 2.1182, "test_samples_per_second": 966.84, "test_steps_per_second": 30.214}, {"test_loss": 0.6295462846755981, "test_mcc": 0.32464755225766295, "test_macro_f1": 0.6622780756192523, "test_runtime": 2.0783, "test_samples_per_second": 985.441, "test_steps_per_second": 30.795}, {"test_loss": 0.6339394450187683, "test_mcc": 0.32253144219302177, "test_macro_f1": 0.6509792611625285, "test_runtime": 2.1428, "test_samples_per_second": 955.742, "test_steps_per_second": 29.867}, {"test_loss": 0.6462085247039795, "test_mcc": 0.34088454345633945, "test_macro_f1": 0.6704063057682472, "test_runtime": 2.0777, "test_samples_per_second": 985.698, "test_steps_per_second": 30.803}, {"test_loss": 0.6425752639770508, "test_mcc": 0.37888945182207073, "test_macro_f1": 0.684296663401141, "test_runtime": 2.0983, "test_samples_per_second": 976.046, "test_steps_per_second": 30.501}, {"test_loss": 0.6243289709091187, "test_mcc": 0.36348371519320966, "test_macro_f1": 0.6810117222486587, "test_runtime": 2.0852, "test_samples_per_second": 982.167, "test_steps_per_second": 30.693}, {"test_loss": 0.6404556035995483, "test_mcc": 0.3292259086092728, "test_macro_f1": 0.6536519286562295, "test_runtime": 2.0848, "test_samples_per_second": 982.367, "test_steps_per_second": 30.699}, {"test_loss": 0.6126288175582886, "test_mcc": 0.36268117381431253, "test_macro_f1": 0.6779996740596729, "test_runtime": 2.1931, "test_samples_per_second": 933.855, "test_steps_per_second": 29.183}]}, "total": {"test_mcc": 34.85503799049918, "test_mcc_se": 1.287394783845606, "test_macro_f1": 66.9826778852109, "test_macro_f1_se": 0.7701697106063734}}, "num_model_parameters": 135327746, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.6669397354125977, "test_mcc": 0.18014487452830327, "test_macro_f1": 0.5131022823330516, "test_runtime": 2.2576, "test_samples_per_second": 907.172, "test_steps_per_second": 28.349}, {"test_loss": 0.6620166897773743, "test_mcc": 0.1908759200829419, "test_macro_f1": 0.5921897631021025, "test_runtime": 2.3139, "test_samples_per_second": 885.089, "test_steps_per_second": 27.659}, {"test_loss": 0.6559600830078125, "test_mcc": 0.2502912802914128, "test_macro_f1": 0.6251335513747707, "test_runtime": 2.2775, "test_samples_per_second": 899.25, "test_steps_per_second": 28.102}, {"test_loss": 0.645567774772644, "test_mcc": 0.2656877370302118, "test_macro_f1": 0.6020512820512821, "test_runtime": 2.3614, "test_samples_per_second": 867.271, "test_steps_per_second": 27.102}, {"test_loss": 0.6789940595626831, "test_mcc": 0.17317764605342512, "test_macro_f1": 0.49479363007774735, "test_runtime": 2.3001, "test_samples_per_second": 890.41, "test_steps_per_second": 27.825}, {"test_loss": 0.6576451063156128, "test_mcc": 0.25471943628046767, "test_macro_f1": 0.6271319499773672, "test_runtime": 2.2513, "test_samples_per_second": 909.708, "test_steps_per_second": 28.428}, {"test_loss": 0.673061728477478, "test_mcc": 0.23958668997394503, "test_macro_f1": 0.5643647786057914, "test_runtime": 2.2055, "test_samples_per_second": 928.585, "test_steps_per_second": 29.018}, {"test_loss": 0.6717262864112854, "test_mcc": 0.2177984997858482, "test_macro_f1": 0.5405732603543233, "test_runtime": 2.2428, "test_samples_per_second": 913.13, "test_steps_per_second": 28.535}, {"test_loss": 0.6691575050354004, "test_mcc": 0.19272221345961948, "test_macro_f1": 0.5666282452219147, "test_runtime": 2.2297, "test_samples_per_second": 918.493, "test_steps_per_second": 28.703}, {"test_loss": 0.6743848323822021, "test_mcc": 0.14286111333457951, "test_macro_f1": 0.5702229976815889, "test_runtime": 2.2812, "test_samples_per_second": 897.787, "test_steps_per_second": 28.056}]}, "total": {"test_mcc": 21.078654108207544, "test_mcc_se": 2.5365357135616953, "test_macro_f1": 56.96191740779939, "test_macro_f1_se": 2.7427897999621176}}, "num_model_parameters": 135327746, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.6692831516265869, "test_mcc": 0.21108569224334553, "test_macro_f1": 0.5030169587575424, "test_runtime": 2.0389, "test_samples_per_second": 1004.465, "test_steps_per_second": 31.39}, {"test_loss": 0.6445974111557007, "test_mcc": 0.24838854332974036, "test_macro_f1": 0.6028889662971091, "test_runtime": 2.1034, "test_samples_per_second": 973.658, "test_steps_per_second": 30.427}, {"test_loss": 0.6557942628860474, "test_mcc": 0.27433495916251766, "test_macro_f1": 0.6252606235704827, "test_runtime": 2.0187, "test_samples_per_second": 1014.536, "test_steps_per_second": 31.704}, {"test_loss": 0.6490817666053772, "test_mcc": 0.24425800876831463, "test_macro_f1": 0.539663379710928, "test_runtime": 2.0609, "test_samples_per_second": 993.748, "test_steps_per_second": 31.055}, {"test_loss": 0.6898766756057739, "test_mcc": -0.004063412117325616, "test_macro_f1": 0.34739222727002206, "test_runtime": 2.1144, "test_samples_per_second": 968.586, "test_steps_per_second": 30.268}, {"test_loss": 0.6344687938690186, "test_mcc": 0.29847277660680005, "test_macro_f1": 0.6451777621906105, "test_runtime": 1.9687, "test_samples_per_second": 1040.269, "test_steps_per_second": 32.508}, {"test_loss": 0.6163312196731567, "test_mcc": 0.3160747556315547, "test_macro_f1": 0.6521254355400696, "test_runtime": 1.991, "test_samples_per_second": 1028.606, "test_steps_per_second": 32.144}, {"test_loss": 0.6632838249206543, "test_mcc": 0.2944432852867701, "test_macro_f1": 0.5996488995487429, "test_runtime": 2.0394, "test_samples_per_second": 1004.208, "test_steps_per_second": 31.381}, {"test_loss": 0.6929046511650085, "test_mcc": 0.0502501337959911, "test_macro_f1": 0.34226959996849265, "test_runtime": 2.0799, "test_samples_per_second": 984.682, "test_steps_per_second": 30.771}, {"test_loss": 0.6739850044250488, "test_mcc": 0.26529806402228917, "test_macro_f1": 0.5964687020814066, "test_runtime": 2.1633, "test_samples_per_second": 946.719, "test_steps_per_second": 29.585}]}, "total": {"test_mcc": 21.985428067299978, "test_mcc_se": 6.740025015848615, "test_macro_f1": 54.539125549354075, "test_macro_f1_se": 7.123366288642312}}, "num_model_parameters": 135327746, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.6647300720214844, "test_mcc": 0.21846508046806912, "test_macro_f1": 0.5974965692595806, "test_runtime": 2.1303, "test_samples_per_second": 961.354, "test_steps_per_second": 30.042}, {"test_loss": 0.6590762734413147, "test_mcc": 0.2293149234850253, "test_macro_f1": 0.6021241736932803, "test_runtime": 2.1303, "test_samples_per_second": 961.379, "test_steps_per_second": 30.043}, {"test_loss": 0.6554871797561646, "test_mcc": 0.23431756965655215, "test_macro_f1": 0.5997049046377587, "test_runtime": 2.2466, "test_samples_per_second": 911.603, "test_steps_per_second": 28.488}, {"test_loss": 0.6547861099243164, "test_mcc": 0.20001192490497471, "test_macro_f1": 0.5969567296285279, "test_runtime": 2.0411, "test_samples_per_second": 1003.366, "test_steps_per_second": 31.355}, {"test_loss": 0.6922657489776611, "test_mcc": 0.011612922918334339, "test_macro_f1": 0.3284209714131399, "test_runtime": 2.092, "test_samples_per_second": 978.976, "test_steps_per_second": 30.593}, {"test_loss": 0.685089647769928, "test_mcc": 0.21880647333260192, "test_macro_f1": 0.5992569620195421, "test_runtime": 2.1251, "test_samples_per_second": 963.723, "test_steps_per_second": 30.116}, {"test_loss": 0.688433051109314, "test_mcc": 0.14004118943011234, "test_macro_f1": 0.5575093197074792, "test_runtime": 2.0759, "test_samples_per_second": 986.567, "test_steps_per_second": 30.83}, {"test_loss": 0.66463303565979, "test_mcc": 0.23841135505718072, "test_macro_f1": 0.599820031244019, "test_runtime": 2.0654, "test_samples_per_second": 991.59, "test_steps_per_second": 30.987}, {"test_loss": 0.6690070033073425, "test_mcc": 0.2113963000577025, "test_macro_f1": 0.5622129521641953, "test_runtime": 2.0722, "test_samples_per_second": 988.327, "test_steps_per_second": 30.885}, {"test_loss": 0.6719188690185547, "test_mcc": 0.20394242181187586, "test_macro_f1": 0.6019595821281493, "test_runtime": 2.1036, "test_samples_per_second": 973.578, "test_steps_per_second": 30.424}]}, "total": {"test_mcc": 19.06320161122429, "test_mcc_se": 4.262203269473027, "test_macro_f1": 56.45462195895672, "test_macro_f1_se": 5.244738251050366}}, "num_model_parameters": 135327746, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_em": 30.441518202943456, "test_f1": 32.852769576769695}, {"test_em": 31.24031007751938, "test_f1": 34.60473777548441}, {"test_em": 28.5935085007728, "test_f1": 30.435842190660814}, {"test_em": 27.180685358255452, "test_f1": 28.66862295717437}, {"test_em": 25.328185328185327, "test_f1": 28.26288687478426}, {"test_em": 20.58596761757903, "test_f1": 22.25680510750129}, {"test_em": 29.916476841305997, "test_f1": 31.108956314128697}, {"test_em": 32.35065942591156, "test_f1": 35.001961639501964}, {"test_em": 26.980392156862745, "test_f1": 28.715780208513785}, {"test_em": 30.124223602484474, "test_f1": 33.923316104644584}]}, "total": {"test_em": 28.274192711182017, "test_em_se": 2.137027764363953, "test_f1": 30.583167874916388, "test_f1_se": 2.3931025050272514}}, "num_model_parameters": 134737154, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_em": 30.441518202943456, "test_f1": 34.27916594937255}, {"test_em": 30.54263565891473, "test_f1": 35.63627529468813}, {"test_em": 29.366306027820713, "test_f1": 33.33468851694194}, {"test_em": 27.414330218068535, "test_f1": 30.497824939319706}, {"test_em": 25.79150579150579, "test_f1": 29.641033429622563}, {"test_em": 30.53199691595991, "test_f1": 33.937322644854454}, {"test_em": 26.80334092634776, "test_f1": 30.571084841901587}, {"test_em": 28.161365399534525, "test_f1": 32.19855555753138}, {"test_em": 25.80392156862745, "test_f1": 29.44569891011343}, {"test_em": 31.677018633540374, "test_f1": 37.15386080087997}]}, "total": {"test_em": 28.653393934326328, "test_em_se": 1.3302400207326652, "test_f1": 32.66955108852257, "test_f1_se": 1.6327835595110058}}, "num_model_parameters": 134737154, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_em": 25.406661502711078, "test_f1": 28.823644658167073}, {"test_em": 30.930232558139537, "test_f1": 35.17835327575625}, {"test_em": 21.561051004636784, "test_f1": 23.23074926831967}, {"test_em": 21.02803738317757, "test_f1": 23.0938622001887}, {"test_em": 21.698841698841697, "test_f1": 24.560371999204385}, {"test_em": 18.272937548188125, "test_f1": 19.220529534716125}, {"test_em": 25.436598329536825, "test_f1": 27.7526244725879}, {"test_em": 24.04965089216447, "test_f1": 26.051757115851487}, {"test_em": 24.07843137254902, "test_f1": 26.35288535294712}, {"test_em": 29.658385093167702, "test_f1": 32.214094005607244}]}, "total": {"test_em": 24.21208273831128, "test_em_se": 2.4139971787619805, "test_f1": 26.647887188334597, "test_f1_se": 2.8774832229759424}}, "num_model_parameters": 134737154, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6708096265792847, "test_mcc": 0.6120040535399026, "test_macro_f1": 0.5505013006146435, "test_runtime": 8.52, "test_samples_per_second": 240.377, "test_steps_per_second": 30.047}, {"test_loss": 0.6629151105880737, "test_mcc": 0.6014958704936213, "test_macro_f1": 0.5455383819213355, "test_runtime": 8.3561, "test_samples_per_second": 245.091, "test_steps_per_second": 30.636}, {"test_loss": 0.7026339173316956, "test_mcc": 0.5928163697252504, "test_macro_f1": 0.5434195172879691, "test_runtime": 8.3757, "test_samples_per_second": 244.517, "test_steps_per_second": 30.565}, {"test_loss": 0.6431138515472412, "test_mcc": 0.6333218942311954, "test_macro_f1": 0.5570461398111882, "test_runtime": 8.177, "test_samples_per_second": 250.458, "test_steps_per_second": 31.307}, {"test_loss": 0.6265652179718018, "test_mcc": 0.5849817836664549, "test_macro_f1": 0.5976573388428353, "test_runtime": 8.1426, "test_samples_per_second": 251.518, "test_steps_per_second": 31.44}, {"test_loss": 0.7265400290489197, "test_mcc": 0.56276513114983, "test_macro_f1": 0.5281132777918471, "test_runtime": 8.3342, "test_samples_per_second": 245.735, "test_steps_per_second": 30.717}, {"test_loss": 0.6442463397979736, "test_mcc": 0.5841911892226294, "test_macro_f1": 0.5908459122407524, "test_runtime": 8.0085, "test_samples_per_second": 255.73, "test_steps_per_second": 31.966}, {"test_loss": 0.6390924453735352, "test_mcc": 0.6204632040234812, "test_macro_f1": 0.5554594543264519, "test_runtime": 8.692, "test_samples_per_second": 235.619, "test_steps_per_second": 29.452}, {"test_loss": 0.6550830602645874, "test_mcc": 0.5956031789556685, "test_macro_f1": 0.5435258024044446, "test_runtime": 8.4908, "test_samples_per_second": 241.203, "test_steps_per_second": 30.15}, {"test_loss": 0.6268987655639648, "test_mcc": 0.6183206508996666, "test_macro_f1": 0.5530385360338648, "test_runtime": 8.3074, "test_samples_per_second": 246.526, "test_steps_per_second": 30.816}]}, "total": {"test_mcc": 60.059633259077, "test_mcc_se": 1.2968878570934215, "test_macro_f1": 55.65145661275332, "test_macro_f1_se": 1.337069474478175}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.9941980838775635, "test_mcc": 0.291227590137015, "test_macro_f1": 0.5052179988816706, "test_runtime": 2.6566, "test_samples_per_second": 770.913, "test_steps_per_second": 24.091}, {"test_loss": 0.9921169877052307, "test_mcc": 0.3036233259963356, "test_macro_f1": 0.5309784711454778, "test_runtime": 2.6418, "test_samples_per_second": 775.227, "test_steps_per_second": 24.226}, {"test_loss": 1.0130295753479004, "test_mcc": 0.23911632535846739, "test_macro_f1": 0.398343564691855, "test_runtime": 2.5784, "test_samples_per_second": 794.294, "test_steps_per_second": 24.822}, {"test_loss": 0.9615553617477417, "test_mcc": 0.3205911146904365, "test_macro_f1": 0.5455441088428076, "test_runtime": 2.5929, "test_samples_per_second": 789.845, "test_steps_per_second": 24.683}, {"test_loss": 1.016440510749817, "test_mcc": 0.3192628009894616, "test_macro_f1": 0.5297893281300449, "test_runtime": 2.5852, "test_samples_per_second": 792.216, "test_steps_per_second": 24.757}, {"test_loss": 1.0170342922210693, "test_mcc": 0.23842573489188038, "test_macro_f1": 0.46438664747678154, "test_runtime": 2.6656, "test_samples_per_second": 768.304, "test_steps_per_second": 24.009}, {"test_loss": 0.9956062436103821, "test_mcc": 0.29045784019564014, "test_macro_f1": 0.5168557937256354, "test_runtime": 2.6049, "test_samples_per_second": 786.217, "test_steps_per_second": 24.569}, {"test_loss": 1.0006980895996094, "test_mcc": 0.25002805836832254, "test_macro_f1": 0.4645803269817688, "test_runtime": 2.581, "test_samples_per_second": 793.485, "test_steps_per_second": 24.796}, {"test_loss": 0.9991145133972168, "test_mcc": 0.29958373059015964, "test_macro_f1": 0.5280220187868884, "test_runtime": 2.5742, "test_samples_per_second": 795.584, "test_steps_per_second": 24.862}, {"test_loss": 1.0187897682189941, "test_mcc": 0.2253853714400324, "test_macro_f1": 0.4541506439225485, "test_runtime": 2.5641, "test_samples_per_second": 798.725, "test_steps_per_second": 24.96}]}, "total": {"test_mcc": 27.777018926577508, "test_mcc_se": 2.2249299156269666, "test_macro_f1": 49.37868902585478, "test_macro_f1_se": 2.891761790162545}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.9495769739151001, "test_mcc": 0.28016668846191023, "test_macro_f1": 0.41245434758695554, "test_runtime": 2.0939, "test_samples_per_second": 978.066, "test_steps_per_second": 30.565}, {"test_loss": 0.9639942049980164, "test_mcc": 0.2675705482375293, "test_macro_f1": 0.4105391953189697, "test_runtime": 1.9492, "test_samples_per_second": 1050.665, "test_steps_per_second": 32.833}, {"test_loss": 0.9428536891937256, "test_mcc": 0.2757550576113959, "test_macro_f1": 0.4127296069966704, "test_runtime": 1.9824, "test_samples_per_second": 1033.068, "test_steps_per_second": 32.283}, {"test_loss": 0.9759705066680908, "test_mcc": 0.2358291650760928, "test_macro_f1": 0.3897451345880563, "test_runtime": 2.0213, "test_samples_per_second": 1013.206, "test_steps_per_second": 31.663}, {"test_loss": 0.9523916244506836, "test_mcc": 0.271960665462614, "test_macro_f1": 0.41296702270672386, "test_runtime": 2.1148, "test_samples_per_second": 968.405, "test_steps_per_second": 30.263}, {"test_loss": 0.9776104092597961, "test_mcc": 0.21498683887964798, "test_macro_f1": 0.38897942032550326, "test_runtime": 2.1434, "test_samples_per_second": 955.505, "test_steps_per_second": 29.86}, {"test_loss": 0.9468660354614258, "test_mcc": 0.2782948506865091, "test_macro_f1": 0.41597197242528433, "test_runtime": 1.9917, "test_samples_per_second": 1028.27, "test_steps_per_second": 32.133}, {"test_loss": 0.9629502296447754, "test_mcc": 0.24292054747447095, "test_macro_f1": 0.3995903212443898, "test_runtime": 2.0331, "test_samples_per_second": 1007.333, "test_steps_per_second": 31.479}, {"test_loss": 0.9443745613098145, "test_mcc": 0.26855399324092627, "test_macro_f1": 0.40810435501269726, "test_runtime": 2.0928, "test_samples_per_second": 978.616, "test_steps_per_second": 30.582}, {"test_loss": 0.9581878185272217, "test_mcc": 0.26204724915479727, "test_macro_f1": 0.40697319626343703, "test_runtime": 2.1151, "test_samples_per_second": 968.288, "test_steps_per_second": 30.259}]}, "total": {"test_mcc": 25.980856042858935, "test_mcc_se": 1.3340014983047093, "test_macro_f1": 40.58054572468688, "test_macro_f1_se": 0.6043004406781883}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.12937846779823303, "test_micro_f1": 0.4378109452736318, "test_micro_f1_no_misc": 0.48, "test_runtime": 5.6145, "test_samples_per_second": 364.768, "test_steps_per_second": 11.399}, {"test_loss": 0.12535415589809418, "test_micro_f1": 0.43021510755377684, "test_micro_f1_no_misc": 0.46784291405805345, "test_runtime": 5.2675, "test_samples_per_second": 388.796, "test_steps_per_second": 12.15}, {"test_loss": 0.12159193307161331, "test_micro_f1": 0.430271299381247, "test_micro_f1_no_misc": 0.514320536258379, "test_runtime": 4.8733, "test_samples_per_second": 420.253, "test_steps_per_second": 13.133}, {"test_loss": 0.13526798784732819, "test_micro_f1": 0.41682242990654206, "test_micro_f1_no_misc": 0.4592760180995475, "test_runtime": 5.6267, "test_samples_per_second": 363.978, "test_steps_per_second": 11.374}, {"test_loss": 0.1481533646583557, "test_micro_f1": 0.4922788956481048, "test_micro_f1_no_misc": 0.5162601626016259, "test_runtime": 4.8271, "test_samples_per_second": 424.271, "test_steps_per_second": 13.258}, {"test_loss": 0.13444635272026062, "test_micro_f1": 0.41133455210237657, "test_micro_f1_no_misc": 0.4586636466591167, "test_runtime": 4.5325, "test_samples_per_second": 451.847, "test_steps_per_second": 14.12}, {"test_loss": 0.12711918354034424, "test_micro_f1": 0.46161137440758293, "test_micro_f1_no_misc": 0.5111607142857143, "test_runtime": 4.5121, "test_samples_per_second": 453.887, "test_steps_per_second": 14.184}, {"test_loss": 0.11559569835662842, "test_micro_f1": 0.4739583333333333, "test_micro_f1_no_misc": 0.5375939849624061, "test_runtime": 5.3883, "test_samples_per_second": 380.08, "test_steps_per_second": 11.878}, {"test_loss": 0.12685677409172058, "test_micro_f1": 0.453125, "test_micro_f1_no_misc": 0.5064138315672058, "test_runtime": 5.2032, "test_samples_per_second": 393.607, "test_steps_per_second": 12.3}, {"test_loss": 0.12815338373184204, "test_micro_f1": 0.44559585492227977, "test_micro_f1_no_misc": 0.5347012673506337, "test_runtime": 4.8728, "test_samples_per_second": 420.289, "test_steps_per_second": 13.134}]}, "total": {"test_micro_f1": 44.530237925288745, "test_micro_f1_se": 1.5774748082724408, "test_micro_f1_no_misc": 49.86233075842682, "test_micro_f1_no_misc_se": 1.8519340675531095}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.1563047617673874, "test_micro_f1": 0.5572615152277876, "test_micro_f1_no_misc": 0.5701088749587595, "test_runtime": 6.3339, "test_samples_per_second": 323.338, "test_steps_per_second": 10.104}, {"test_loss": 0.14998114109039307, "test_micro_f1": 0.5856950067476383, "test_micro_f1_no_misc": 0.6094903339191564, "test_runtime": 5.2305, "test_samples_per_second": 391.547, "test_steps_per_second": 12.236}, {"test_loss": 0.1609896719455719, "test_micro_f1": 0.5529622980251346, "test_micro_f1_no_misc": 0.5792387543252595, "test_runtime": 6.0299, "test_samples_per_second": 339.64, "test_steps_per_second": 10.614}, {"test_loss": 0.15408602356910706, "test_micro_f1": 0.5852546237648848, "test_micro_f1_no_misc": 0.611869031377899, "test_runtime": 5.527, "test_samples_per_second": 370.545, "test_steps_per_second": 11.58}, {"test_loss": 0.16391384601593018, "test_micro_f1": 0.5612582781456954, "test_micro_f1_no_misc": 0.5855758880516685, "test_runtime": 5.9882, "test_samples_per_second": 342.008, "test_steps_per_second": 10.688}, {"test_loss": 0.15815871953964233, "test_micro_f1": 0.5439017880971444, "test_micro_f1_no_misc": 0.5631138595853037, "test_runtime": 5.6435, "test_samples_per_second": 362.895, "test_steps_per_second": 11.34}, {"test_loss": 0.15452295541763306, "test_micro_f1": 0.5625485625485624, "test_micro_f1_no_misc": 0.5856847900894699, "test_runtime": 5.644, "test_samples_per_second": 362.863, "test_steps_per_second": 11.339}, {"test_loss": 0.14759886264801025, "test_micro_f1": 0.5576148267526189, "test_micro_f1_no_misc": 0.5878161738510865, "test_runtime": 6.5421, "test_samples_per_second": 313.05, "test_steps_per_second": 9.783}, {"test_loss": 0.1534159779548645, "test_micro_f1": 0.5414824447334201, "test_micro_f1_no_misc": 0.558855098389982, "test_runtime": 5.8555, "test_samples_per_second": 349.755, "test_steps_per_second": 10.93}, {"test_loss": 0.1534382402896881, "test_micro_f1": 0.5827814569536424, "test_micro_f1_no_misc": 0.5977833392920988, "test_runtime": 5.3789, "test_samples_per_second": 380.745, "test_steps_per_second": 11.898}]}, "total": {"test_micro_f1": 56.30760800996529, "test_micro_f1_se": 1.011137513044768, "test_micro_f1_no_misc": 58.49536143840683, "test_micro_f1_no_misc_se": 1.114760048595419}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.12639707326889038, "test_micro_f1": 0.5942936673625608, "test_micro_f1_no_misc": 0.6216113020236731, "test_runtime": 4.8614, "test_samples_per_second": 421.281, "test_steps_per_second": 13.165}, {"test_loss": 0.12146443128585815, "test_micro_f1": 0.5619273837801154, "test_micro_f1_no_misc": 0.5830882352941176, "test_runtime": 4.4943, "test_samples_per_second": 455.684, "test_steps_per_second": 14.24}, {"test_loss": 0.11805541813373566, "test_micro_f1": 0.5801778070464274, "test_micro_f1_no_misc": 0.6011519078473723, "test_runtime": 4.6424, "test_samples_per_second": 441.147, "test_steps_per_second": 13.786}, {"test_loss": 0.12259043008089066, "test_micro_f1": 0.570299637800461, "test_micro_f1_no_misc": 0.5916817359855335, "test_runtime": 3.9604, "test_samples_per_second": 517.123, "test_steps_per_second": 16.16}, {"test_loss": 0.1196931004524231, "test_micro_f1": 0.5941747572815533, "test_micro_f1_no_misc": 0.622113365990203, "test_runtime": 4.3461, "test_samples_per_second": 471.228, "test_steps_per_second": 14.726}, {"test_loss": 0.11739575862884521, "test_micro_f1": 0.5908794788273616, "test_micro_f1_no_misc": 0.6149486362026214, "test_runtime": 4.6551, "test_samples_per_second": 439.947, "test_steps_per_second": 13.748}, {"test_loss": 0.12434853613376617, "test_micro_f1": 0.5816628327308577, "test_micro_f1_no_misc": 0.604551920341394, "test_runtime": 4.5072, "test_samples_per_second": 454.384, "test_steps_per_second": 14.2}, {"test_loss": 0.10933707654476166, "test_micro_f1": 0.615849563465413, "test_micro_f1_no_misc": 0.6370794559770937, "test_runtime": 4.3931, "test_samples_per_second": 466.187, "test_steps_per_second": 14.568}, {"test_loss": 0.13130377233028412, "test_micro_f1": 0.5377703826955075, "test_micro_f1_no_misc": 0.5606390704429921, "test_runtime": 4.5667, "test_samples_per_second": 448.461, "test_steps_per_second": 14.014}, {"test_loss": 0.12114284187555313, "test_micro_f1": 0.6077529566360053, "test_micro_f1_no_misc": 0.6395431834403996, "test_runtime": 4.6284, "test_samples_per_second": 442.484, "test_steps_per_second": 13.828}]}, "total": {"test_micro_f1": 58.34788467626264, "test_micro_f1_se": 1.4110855825535795, "test_micro_f1_no_misc": 60.764088135453996, "test_micro_f1_no_misc_se": 1.5267270164081048}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.12719741463661194, "test_micro_f1": 0.5470085470085471, "test_micro_f1_no_misc": 0.5799872530274061, "test_runtime": 4.222, "test_samples_per_second": 485.082, "test_steps_per_second": 15.159}, {"test_loss": 0.1398467719554901, "test_micro_f1": 0.5510204081632653, "test_micro_f1_no_misc": 0.5852725533949632, "test_runtime": 4.0886, "test_samples_per_second": 500.911, "test_steps_per_second": 15.653}, {"test_loss": 0.13502755761146545, "test_micro_f1": 0.5539341917024321, "test_micro_f1_no_misc": 0.5902560899437852, "test_runtime": 3.908, "test_samples_per_second": 524.054, "test_steps_per_second": 16.377}, {"test_loss": 0.14183767139911652, "test_micro_f1": 0.5501580914055761, "test_micro_f1_no_misc": 0.5908946195479147, "test_runtime": 4.0243, "test_samples_per_second": 508.91, "test_steps_per_second": 15.903}, {"test_loss": 0.14177069067955017, "test_micro_f1": 0.5415456130156885, "test_micro_f1_no_misc": 0.5867446393762183, "test_runtime": 3.8384, "test_samples_per_second": 533.552, "test_steps_per_second": 16.674}, {"test_loss": 0.1338193416595459, "test_micro_f1": 0.555782114768424, "test_micro_f1_no_misc": 0.5907335907335908, "test_runtime": 4.3111, "test_samples_per_second": 475.048, "test_steps_per_second": 14.845}, {"test_loss": 0.14358799159526825, "test_micro_f1": 0.5739078396169958, "test_micro_f1_no_misc": 0.6064348391290219, "test_runtime": 4.5796, "test_samples_per_second": 447.202, "test_steps_per_second": 13.975}, {"test_loss": 0.12029185891151428, "test_micro_f1": 0.6027802425317953, "test_micro_f1_no_misc": 0.6453074433656958, "test_runtime": 4.6394, "test_samples_per_second": 441.441, "test_steps_per_second": 13.795}, {"test_loss": 0.13628417253494263, "test_micro_f1": 0.5477669328601005, "test_micro_f1_no_misc": 0.5827900912646674, "test_runtime": 4.0052, "test_samples_per_second": 511.333, "test_steps_per_second": 15.979}, {"test_loss": 0.13367362320423126, "test_micro_f1": 0.5663309352517987, "test_micro_f1_no_misc": 0.6037974683544304, "test_runtime": 4.2693, "test_samples_per_second": 479.703, "test_steps_per_second": 14.991}]}, "total": {"test_micro_f1": 55.902349163246235, "test_micro_f1_se": 1.1212222616190397, "test_micro_f1_no_misc": 59.622185881376936, "test_micro_f1_no_misc_se": 1.1902256218023255}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6921950578689575, "test_mcc": 0.06460593204129662, "test_macro_f1": 0.5049030997250227, "test_runtime": 2.2695, "test_samples_per_second": 902.396, "test_steps_per_second": 28.2}, {"test_loss": 0.6922762393951416, "test_mcc": 0.061426630004568016, "test_macro_f1": 0.4664381014777492, "test_runtime": 2.065, "test_samples_per_second": 991.756, "test_steps_per_second": 30.992}, {"test_loss": 0.6923028230667114, "test_mcc": 0.06762487958652906, "test_macro_f1": 0.5059926258726816, "test_runtime": 2.3732, "test_samples_per_second": 862.969, "test_steps_per_second": 26.968}, {"test_loss": 0.6928718686103821, "test_mcc": 0.026709687891844334, "test_macro_f1": 0.48502980919016475, "test_runtime": 2.2576, "test_samples_per_second": 907.16, "test_steps_per_second": 28.349}, {"test_loss": 0.6928834319114685, "test_mcc": 0.036784418758977276, "test_macro_f1": 0.5183323601363239, "test_runtime": 2.5186, "test_samples_per_second": 813.138, "test_steps_per_second": 25.411}, {"test_loss": 0.6933380365371704, "test_mcc": 0.024836682951536942, "test_macro_f1": 0.46131191432396246, "test_runtime": 2.364, "test_samples_per_second": 866.33, "test_steps_per_second": 27.073}, {"test_loss": 0.6931697130203247, "test_mcc": -0.010970560240513058, "test_macro_f1": 0.4702896328777886, "test_runtime": 2.4237, "test_samples_per_second": 844.977, "test_steps_per_second": 26.406}, {"test_loss": 0.6927327513694763, "test_mcc": 0.029091293140392153, "test_macro_f1": 0.44653506462370973, "test_runtime": 2.0706, "test_samples_per_second": 989.062, "test_steps_per_second": 30.908}, {"test_loss": 0.6929029226303101, "test_mcc": 0.007758286042759644, "test_macro_f1": 0.48158395989974945, "test_runtime": 2.1016, "test_samples_per_second": 974.516, "test_steps_per_second": 30.454}, {"test_loss": 0.6929378509521484, "test_mcc": 0.010144411066548524, "test_macro_f1": 0.4975694233163439, "test_runtime": 2.1162, "test_samples_per_second": 967.758, "test_steps_per_second": 30.242}]}, "total": {"test_mcc": 3.1801166124393947, "test_mcc_se": 1.6294424523221769, "test_macro_f1": 48.37985991443497, "test_macro_f1_se": 1.4171028268687116}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6924288272857666, "test_mcc": 0.05375734728167796, "test_macro_f1": 0.5161236287509335, "test_runtime": 2.1919, "test_samples_per_second": 934.334, "test_steps_per_second": 29.198}, {"test_loss": 0.6934231519699097, "test_mcc": 0.016452249138125038, "test_macro_f1": 0.4560735349804699, "test_runtime": 2.3045, "test_samples_per_second": 888.678, "test_steps_per_second": 27.771}, {"test_loss": 0.6925432682037354, "test_mcc": 0.05220389760133993, "test_macro_f1": 0.4528075845722904, "test_runtime": 2.2673, "test_samples_per_second": 903.282, "test_steps_per_second": 28.228}, {"test_loss": 0.6927039623260498, "test_mcc": 0.03815969400635726, "test_macro_f1": 0.5131887813896898, "test_runtime": 2.3586, "test_samples_per_second": 868.317, "test_steps_per_second": 27.135}, {"test_loss": 0.6930620074272156, "test_mcc": 0.020878449988614902, "test_macro_f1": 0.39257371866798346, "test_runtime": 2.2185, "test_samples_per_second": 923.163, "test_steps_per_second": 28.849}, {"test_loss": 0.6928457021713257, "test_mcc": 0.05987374736687178, "test_macro_f1": 0.5297446817946738, "test_runtime": 2.2085, "test_samples_per_second": 927.337, "test_steps_per_second": 28.979}, {"test_loss": 0.6925745010375977, "test_mcc": 0.053831904612884736, "test_macro_f1": 0.42508390866174495, "test_runtime": 2.2017, "test_samples_per_second": 930.184, "test_steps_per_second": 29.068}, {"test_loss": 0.6928954124450684, "test_mcc": 0.018079738148302143, "test_macro_f1": 0.4109529724484732, "test_runtime": 2.2096, "test_samples_per_second": 926.869, "test_steps_per_second": 28.965}, {"test_loss": 0.6926257014274597, "test_mcc": 0.03159742725014024, "test_macro_f1": 0.5137072054569789, "test_runtime": 2.2122, "test_samples_per_second": 925.795, "test_steps_per_second": 28.931}, {"test_loss": 0.6934376955032349, "test_mcc": -0.04100314250510517, "test_macro_f1": 0.475163160491073, "test_runtime": 2.2645, "test_samples_per_second": 904.391, "test_steps_per_second": 28.262}]}, "total": {"test_mcc": 3.0383131288920886, "test_mcc_se": 1.85203264672468, "test_macro_f1": 46.85419177214311, "test_macro_f1_se": 3.0269974944566522}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6919846534729004, "test_mcc": 0.0587670406025357, "test_macro_f1": 0.4943053144888008, "test_runtime": 2.004, "test_samples_per_second": 1021.958, "test_steps_per_second": 31.936}, {"test_loss": 0.6931211948394775, "test_mcc": 0.03117754532686636, "test_macro_f1": 0.4421721249703939, "test_runtime": 2.022, "test_samples_per_second": 1012.864, "test_steps_per_second": 31.652}, {"test_loss": 0.692954957485199, "test_mcc": 0.008076320755049113, "test_macro_f1": 0.495620274288823, "test_runtime": 2.0197, "test_samples_per_second": 1014.026, "test_steps_per_second": 31.688}, {"test_loss": 0.6925265789031982, "test_mcc": 0.05229343156183703, "test_macro_f1": 0.5138231631382316, "test_runtime": 2.0524, "test_samples_per_second": 997.857, "test_steps_per_second": 31.183}, {"test_loss": 0.693056583404541, "test_mcc": 0.03406824537784234, "test_macro_f1": 0.5035552682611506, "test_runtime": 2.0744, "test_samples_per_second": 987.256, "test_steps_per_second": 30.852}, {"test_loss": 0.6927870512008667, "test_mcc": 0.01510793103613907, "test_macro_f1": 0.4524207993864612, "test_runtime": 2.2541, "test_samples_per_second": 908.585, "test_steps_per_second": 28.393}, {"test_loss": 0.6922541856765747, "test_mcc": 0.07727248380446282, "test_macro_f1": 0.48234122266180124, "test_runtime": 2.3346, "test_samples_per_second": 877.231, "test_steps_per_second": 27.413}, {"test_loss": 0.6926321983337402, "test_mcc": 0.03630910711479918, "test_macro_f1": 0.48101449672800334, "test_runtime": 2.3529, "test_samples_per_second": 870.414, "test_steps_per_second": 27.2}, {"test_loss": 0.6932293176651001, "test_mcc": -0.02860719758891855, "test_macro_f1": 0.4834532872882278, "test_runtime": 2.3284, "test_samples_per_second": 879.556, "test_steps_per_second": 27.486}, {"test_loss": 0.6932480335235596, "test_mcc": -0.019682486599761056, "test_macro_f1": 0.4605128205128205, "test_runtime": 2.138, "test_samples_per_second": 957.915, "test_steps_per_second": 29.935}]}, "total": {"test_mcc": 2.6478242139085193, "test_mcc_se": 2.07617329540767, "test_macro_f1": 48.092187717247135, "test_macro_f1_se": 1.420716825252642}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6922421455383301, "test_mcc": 0.05356362913105305, "test_macro_f1": 0.5211107051516259, "test_runtime": 2.4188, "test_samples_per_second": 846.694, "test_steps_per_second": 26.459}, {"test_loss": 0.6926825642585754, "test_mcc": 0.0012870641883734094, "test_macro_f1": 0.46344385099475177, "test_runtime": 2.1939, "test_samples_per_second": 933.503, "test_steps_per_second": 29.172}, {"test_loss": 0.6924570798873901, "test_mcc": 0.050475697471692615, "test_macro_f1": 0.48611334308824805, "test_runtime": 2.2991, "test_samples_per_second": 890.781, "test_steps_per_second": 27.837}, {"test_loss": 0.6920558214187622, "test_mcc": 0.03722224451900188, "test_macro_f1": 0.4757215327268387, "test_runtime": 2.2974, "test_samples_per_second": 891.454, "test_steps_per_second": 27.858}, {"test_loss": 0.6920359134674072, "test_mcc": 0.041150279740398574, "test_macro_f1": 0.5193827438440375, "test_runtime": 2.1454, "test_samples_per_second": 954.608, "test_steps_per_second": 29.832}, {"test_loss": 0.6925873756408691, "test_mcc": 0.06566878103084867, "test_macro_f1": 0.4772533431859368, "test_runtime": 2.2861, "test_samples_per_second": 895.865, "test_steps_per_second": 27.996}, {"test_loss": 0.6922675371170044, "test_mcc": 0.04361579307735369, "test_macro_f1": 0.5154445456149332, "test_runtime": 2.2362, "test_samples_per_second": 915.838, "test_steps_per_second": 28.62}, {"test_loss": 0.6922877430915833, "test_mcc": 0.020195931286233235, "test_macro_f1": 0.4815362473900532, "test_runtime": 2.349, "test_samples_per_second": 871.877, "test_steps_per_second": 27.246}, {"test_loss": 0.6938341856002808, "test_mcc": -0.00969603818795802, "test_macro_f1": 0.43856344999984515, "test_runtime": 2.3793, "test_samples_per_second": 860.757, "test_steps_per_second": 26.899}, {"test_loss": 0.6920021176338196, "test_mcc": 0.04337291023446041, "test_macro_f1": 0.519580030022426, "test_runtime": 2.3484, "test_samples_per_second": 872.065, "test_steps_per_second": 27.252}]}, "total": {"test_mcc": 3.4685629249145755, "test_mcc_se": 1.470254273915669, "test_macro_f1": 48.98149792018696, "test_macro_f1_se": 1.7478740339974486}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_em": 34.00464756003098, "test_f1": 38.64215865012747}, {"test_em": 33.10077519379845, "test_f1": 38.18493849318605}, {"test_em": 32.07109737248841, "test_f1": 36.62179988743769}, {"test_em": 32.398753894081, "test_f1": 37.528160537224245}, {"test_em": 31.89189189189189, "test_f1": 37.087218831800904}, {"test_em": 32.61372397841172, "test_f1": 37.0996311848684}, {"test_em": 32.42217160212604, "test_f1": 37.88927626395967}, {"test_em": 32.195500387897596, "test_f1": 37.60694891654635}, {"test_em": 30.58823529411765, "test_f1": 35.41063720337079}, {"test_em": 29.891304347826086, "test_f1": 34.67285373594265}]}, "total": {"test_em": 32.117810152266976, "test_em_se": 0.7245833601590141, "test_f1": 37.07436237044643, "test_f1_se": 0.7615152023910766}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_em": 31.835786212238574, "test_f1": 38.628587071491395}, {"test_em": 16.434108527131784, "test_f1": 24.028938561804488}, {"test_em": 9.041731066460587, "test_f1": 17.298764736022893}, {"test_em": 9.813084112149532, "test_f1": 17.431562414058092}, {"test_em": 29.72972972972973, "test_f1": 36.517583022669285}, {"test_em": 29.838087895142635, "test_f1": 36.765805812089056}, {"test_em": 28.929384965831435, "test_f1": 35.771117625265546}, {"test_em": 16.058960434445307, "test_f1": 23.374665929281097}, {"test_em": 26.980392156862745, "test_f1": 34.836489926129936}, {"test_em": 29.503105590062113, "test_f1": 36.80787934182813}]}, "total": {"test_em": 22.816437069005445, "test_em_se": 5.555605570093353, "test_f1": 30.146139444063994, "test_f1_se": 5.325264836436955}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_em": 34.77924089852827, "test_f1": 40.28626761405252}, {"test_em": 32.63565891472868, "test_f1": 37.62352069681613}, {"test_em": 29.520865533230292, "test_f1": 35.12868994376025}, {"test_em": 34.57943925233645, "test_f1": 39.53608358298619}, {"test_em": 33.513513513513516, "test_f1": 38.97884386805223}, {"test_em": 34.07864302235929, "test_f1": 39.88507871272577}, {"test_em": 33.712984054669704, "test_f1": 39.30094127118749}, {"test_em": 28.161365399534525, "test_f1": 35.495740048251484}, {"test_em": 31.686274509803923, "test_f1": 37.95371153529961}, {"test_em": 32.37577639751553, "test_f1": 37.76249422037394}]}, "total": {"test_em": 32.50437614962202, "test_em_se": 1.3532746994370024, "test_f1": 38.19513714935056, "test_f1_se": 1.0956912330060657}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.40230780839920044, "test_mcc": 0.74315936035778, "test_macro_f1": 0.7398867527786819, "test_runtime": 14.1196, "test_samples_per_second": 145.047, "test_steps_per_second": 18.131}, {"test_loss": 0.46489423513412476, "test_mcc": 0.7064579931031663, "test_macro_f1": 0.7357597621728965, "test_runtime": 14.7737, "test_samples_per_second": 138.624, "test_steps_per_second": 17.328}, {"test_loss": 0.44640108942985535, "test_mcc": 0.7098673890156542, "test_macro_f1": 0.6905645639514518, "test_runtime": 14.9402, "test_samples_per_second": 137.08, "test_steps_per_second": 17.135}, {"test_loss": 0.41387805342674255, "test_mcc": 0.7305612034704962, "test_macro_f1": 0.7226558521273422, "test_runtime": 14.2034, "test_samples_per_second": 144.191, "test_steps_per_second": 18.024}, {"test_loss": 0.4294086992740631, "test_mcc": 0.7109828816079593, "test_macro_f1": 0.7183074064304757, "test_runtime": 13.9955, "test_samples_per_second": 146.332, "test_steps_per_second": 18.292}, {"test_loss": 0.42225390672683716, "test_mcc": 0.7124658172235242, "test_macro_f1": 0.6654777090041374, "test_runtime": 14.7188, "test_samples_per_second": 139.141, "test_steps_per_second": 17.393}, {"test_loss": 0.41855910420417786, "test_mcc": 0.7375587852010822, "test_macro_f1": 0.7179785925065373, "test_runtime": 14.2945, "test_samples_per_second": 143.271, "test_steps_per_second": 17.909}, {"test_loss": 0.40662044286727905, "test_mcc": 0.7260022969723254, "test_macro_f1": 0.7227478090338066, "test_runtime": 15.2812, "test_samples_per_second": 134.021, "test_steps_per_second": 16.753}, {"test_loss": 0.41298097372055054, "test_mcc": 0.7319063955104509, "test_macro_f1": 0.7179023365817017, "test_runtime": 15.3735, "test_samples_per_second": 133.217, "test_steps_per_second": 16.652}, {"test_loss": 0.4561249017715454, "test_mcc": 0.7194848184345317, "test_macro_f1": 0.7306871297063143, "test_runtime": 14.661, "test_samples_per_second": 139.69, "test_steps_per_second": 17.461}]}, "total": {"test_mcc": 72.28446940896968, "test_mcc_se": 0.7941336970034275, "test_macro_f1": 71.61967914293345, "test_macro_f1_se": 1.3826151281863481}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.8190274238586426, "test_mcc": 0.46429644684109567, "test_macro_f1": 0.644215248061006, "test_runtime": 4.8683, "test_samples_per_second": 420.678, "test_steps_per_second": 13.146}, {"test_loss": 0.8004225492477417, "test_mcc": 0.4756008843506949, "test_macro_f1": 0.6477614389913171, "test_runtime": 4.8469, "test_samples_per_second": 422.536, "test_steps_per_second": 13.204}, {"test_loss": 0.8247822523117065, "test_mcc": 0.45646610900145285, "test_macro_f1": 0.639386725190184, "test_runtime": 4.8853, "test_samples_per_second": 419.22, "test_steps_per_second": 13.101}, {"test_loss": 0.8125756978988647, "test_mcc": 0.46788332514188596, "test_macro_f1": 0.6460530493242526, "test_runtime": 4.7959, "test_samples_per_second": 427.032, "test_steps_per_second": 13.345}, {"test_loss": 0.7963176369667053, "test_mcc": 0.4819598371030375, "test_macro_f1": 0.6527674304782197, "test_runtime": 4.7455, "test_samples_per_second": 431.571, "test_steps_per_second": 13.487}, {"test_loss": 1.0497496128082275, "test_mcc": 0.1786052967085713, "test_macro_f1": 0.41906113149333546, "test_runtime": 4.4844, "test_samples_per_second": 456.695, "test_steps_per_second": 14.272}, {"test_loss": 0.8280668258666992, "test_mcc": 0.4760096141598103, "test_macro_f1": 0.6558554115853449, "test_runtime": 4.3679, "test_samples_per_second": 468.877, "test_steps_per_second": 14.652}, {"test_loss": 0.8296979665756226, "test_mcc": 0.49927418124330514, "test_macro_f1": 0.6672464607076763, "test_runtime": 4.5421, "test_samples_per_second": 450.896, "test_steps_per_second": 14.09}, {"test_loss": 0.7961319088935852, "test_mcc": 0.48536829581796753, "test_macro_f1": 0.6548626560336416, "test_runtime": 4.5026, "test_samples_per_second": 454.85, "test_steps_per_second": 14.214}, {"test_loss": 0.8418195247650146, "test_mcc": 0.4622764789641723, "test_macro_f1": 0.6349421887732545, "test_runtime": 4.317, "test_samples_per_second": 474.404, "test_steps_per_second": 14.825}]}, "total": {"test_mcc": 44.47740469331995, "test_mcc_se": 5.848369855683308, "test_macro_f1": 62.621517406382324, "test_macro_f1_se": 4.546751472856763}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.7272243499755859, "test_mcc": 0.5160462766801692, "test_macro_f1": 0.6597734475515081, "test_runtime": 3.4569, "test_samples_per_second": 592.444, "test_steps_per_second": 18.514}, {"test_loss": 0.7134982347488403, "test_mcc": 0.5333989203490024, "test_macro_f1": 0.6627207593074643, "test_runtime": 3.2666, "test_samples_per_second": 626.954, "test_steps_per_second": 19.592}, {"test_loss": 0.7689571380615234, "test_mcc": 0.47544406230858355, "test_macro_f1": 0.5623894970490567, "test_runtime": 3.3159, "test_samples_per_second": 617.624, "test_steps_per_second": 19.301}, {"test_loss": 0.7773187160491943, "test_mcc": 0.4675959204505176, "test_macro_f1": 0.6202849821803184, "test_runtime": 3.3662, "test_samples_per_second": 608.4, "test_steps_per_second": 19.012}, {"test_loss": 0.7568974494934082, "test_mcc": 0.5043964825015026, "test_macro_f1": 0.6481619710251026, "test_runtime": 3.4641, "test_samples_per_second": 591.204, "test_steps_per_second": 18.475}, {"test_loss": 0.769586980342865, "test_mcc": 0.4989243237327943, "test_macro_f1": 0.6513247515737249, "test_runtime": 3.5933, "test_samples_per_second": 569.944, "test_steps_per_second": 17.811}, {"test_loss": 0.7076254487037659, "test_mcc": 0.5403140093070619, "test_macro_f1": 0.6745354483546242, "test_runtime": 3.8801, "test_samples_per_second": 527.825, "test_steps_per_second": 16.495}, {"test_loss": 0.8041673898696899, "test_mcc": 0.47609014226557006, "test_macro_f1": 0.6027667078276101, "test_runtime": 3.9341, "test_samples_per_second": 520.574, "test_steps_per_second": 16.268}, {"test_loss": 0.7592291831970215, "test_mcc": 0.456008215600889, "test_macro_f1": 0.5988782215971762, "test_runtime": 4.031, "test_samples_per_second": 508.066, "test_steps_per_second": 15.877}, {"test_loss": 0.9873851537704468, "test_mcc": 0.2055102060909425, "test_macro_f1": 0.343764863030591, "test_runtime": 4.0401, "test_samples_per_second": 506.917, "test_steps_per_second": 15.841}]}, "total": {"test_mcc": 46.73728559287033, "test_mcc_se": 5.9613788928062235, "test_macro_f1": 60.24600649497176, "test_macro_f1_se": 6.0392518719796975}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.10396584868431091, "test_micro_f1": 0.38787295476419636, "test_micro_f1_no_misc": 0.41418293936279543, "test_runtime": 7.4433, "test_samples_per_second": 275.148, "test_steps_per_second": 8.598}, {"test_loss": 0.082575723528862, "test_micro_f1": 0.5945668887749872, "test_micro_f1_no_misc": 0.6454183266932271, "test_runtime": 6.9676, "test_samples_per_second": 293.933, "test_steps_per_second": 9.185}, {"test_loss": 0.06512577831745148, "test_micro_f1": 0.6527711984841307, "test_micro_f1_no_misc": 0.7011258955987717, "test_runtime": 6.7068, "test_samples_per_second": 305.363, "test_steps_per_second": 9.543}, {"test_loss": 0.2403356432914734, "test_micro_f1": 0.0, "test_micro_f1_no_misc": 0.0, "test_runtime": 7.012, "test_samples_per_second": 292.071, "test_steps_per_second": 9.127}, {"test_loss": 0.07664339989423752, "test_micro_f1": 0.6060606060606061, "test_micro_f1_no_misc": 0.6758914316125598, "test_runtime": 7.0608, "test_samples_per_second": 290.051, "test_steps_per_second": 9.064}, {"test_loss": 0.07460494339466095, "test_micro_f1": 0.6110338433008808, "test_micro_f1_no_misc": 0.6849015317286653, "test_runtime": 6.1718, "test_samples_per_second": 331.831, "test_steps_per_second": 10.37}, {"test_loss": 0.08170902729034424, "test_micro_f1": 0.6410496719775071, "test_micro_f1_no_misc": 0.7135842880523733, "test_runtime": 6.2123, "test_samples_per_second": 329.669, "test_steps_per_second": 10.302}, {"test_loss": 0.06628511846065521, "test_micro_f1": 0.5907660020986358, "test_micro_f1_no_misc": 0.662227602905569, "test_runtime": 6.9691, "test_samples_per_second": 293.87, "test_steps_per_second": 9.183}, {"test_loss": 0.06926552951335907, "test_micro_f1": 0.6160183066361555, "test_micro_f1_no_misc": 0.6707692307692308, "test_runtime": 6.724, "test_samples_per_second": 304.579, "test_steps_per_second": 9.518}, {"test_loss": 0.07243119180202484, "test_micro_f1": 0.6632605666511843, "test_micro_f1_no_misc": 0.7159855147439214, "test_runtime": 6.4625, "test_samples_per_second": 316.906, "test_steps_per_second": 9.903}]}, "total": {"test_micro_f1": 53.63400038748283, "test_micro_f1_se": 12.625969743973062, "test_micro_f1_no_misc": 58.84086761467115, "test_micro_f1_no_misc_se": 13.91578577080031}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.08888807892799377, "test_micro_f1": 0.721875, "test_micro_f1_no_misc": 0.7524339360222531, "test_runtime": 8.0322, "test_samples_per_second": 254.973, "test_steps_per_second": 7.968}, {"test_loss": 0.07780534029006958, "test_micro_f1": 0.7252032520325203, "test_micro_f1_no_misc": 0.7577464788732394, "test_runtime": 6.2066, "test_samples_per_second": 329.97, "test_steps_per_second": 10.312}, {"test_loss": 0.07652054727077484, "test_micro_f1": 0.7619307335696754, "test_micro_f1_no_misc": 0.7941070786920588, "test_runtime": 7.8928, "test_samples_per_second": 259.476, "test_steps_per_second": 8.109}, {"test_loss": 0.06971558928489685, "test_micro_f1": 0.7439588688946016, "test_micro_f1_no_misc": 0.7711255559356824, "test_runtime": 7.7912, "test_samples_per_second": 262.86, "test_steps_per_second": 8.214}, {"test_loss": 0.0794692263007164, "test_micro_f1": 0.713309647444657, "test_micro_f1_no_misc": 0.7604590892262125, "test_runtime": 7.8446, "test_samples_per_second": 261.07, "test_steps_per_second": 8.158}, {"test_loss": 0.07841172814369202, "test_micro_f1": 0.7528767123287672, "test_micro_f1_no_misc": 0.7795100222717148, "test_runtime": 8.4468, "test_samples_per_second": 242.459, "test_steps_per_second": 7.577}, {"test_loss": 0.08083903789520264, "test_micro_f1": 0.7174262734584451, "test_micro_f1_no_misc": 0.740974412898703, "test_runtime": 8.5202, "test_samples_per_second": 240.371, "test_steps_per_second": 7.512}, {"test_loss": 0.06337828189134598, "test_micro_f1": 0.7888579387186629, "test_micro_f1_no_misc": 0.8257292445774121, "test_runtime": 8.5082, "test_samples_per_second": 240.708, "test_steps_per_second": 7.522}, {"test_loss": 0.0676480233669281, "test_micro_f1": 0.7637142092587638, "test_micro_f1_no_misc": 0.7899099099099098, "test_runtime": 8.6344, "test_samples_per_second": 237.191, "test_steps_per_second": 7.412}, {"test_loss": 0.07251347601413727, "test_micro_f1": 0.7799729364005413, "test_micro_f1_no_misc": 0.813768115942029, "test_runtime": 7.0825, "test_samples_per_second": 289.165, "test_steps_per_second": 9.036}]}, "total": {"test_micro_f1": 74.69125572106634, "test_micro_f1_se": 1.6658475399095392, "test_micro_f1_no_misc": 77.85763844349215, "test_micro_f1_no_misc_se": 1.6970759596387959}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.06837721168994904, "test_micro_f1": 0.6965736488873189, "test_micro_f1_no_misc": 0.7558002359418011, "test_runtime": 6.2504, "test_samples_per_second": 327.661, "test_steps_per_second": 10.239}, {"test_loss": 0.055832214653491974, "test_micro_f1": 0.7899159663865547, "test_micro_f1_no_misc": 0.8100040338846309, "test_runtime": 6.5326, "test_samples_per_second": 313.503, "test_steps_per_second": 9.797}, {"test_loss": 0.060106515884399414, "test_micro_f1": 0.7714970880438506, "test_micro_f1_no_misc": 0.8073254483021748, "test_runtime": 5.9558, "test_samples_per_second": 343.869, "test_steps_per_second": 10.746}, {"test_loss": 0.049849316477775574, "test_micro_f1": 0.8036529680365295, "test_micro_f1_no_misc": 0.8344422700587083, "test_runtime": 6.5551, "test_samples_per_second": 312.428, "test_steps_per_second": 9.763}, {"test_loss": 0.0542212650179863, "test_micro_f1": 0.7746432127447727, "test_micro_f1_no_misc": 0.8188917813313499, "test_runtime": 6.2753, "test_samples_per_second": 326.358, "test_steps_per_second": 10.199}, {"test_loss": 0.055645622313022614, "test_micro_f1": 0.7557046979865771, "test_micro_f1_no_misc": 0.7891811782141533, "test_runtime": 6.5783, "test_samples_per_second": 311.328, "test_steps_per_second": 9.729}, {"test_loss": 0.057871609926223755, "test_micro_f1": 0.7561385805583586, "test_micro_f1_no_misc": 0.783467446964155, "test_runtime": 6.5321, "test_samples_per_second": 313.528, "test_steps_per_second": 9.798}, {"test_loss": 0.05185028910636902, "test_micro_f1": 0.7753547940463829, "test_micro_f1_no_misc": 0.8075639599555061, "test_runtime": 6.2208, "test_samples_per_second": 329.218, "test_steps_per_second": 10.288}, {"test_loss": 0.06154278665781021, "test_micro_f1": 0.7262685536762167, "test_micro_f1_no_misc": 0.7668231611893584, "test_runtime": 5.5129, "test_samples_per_second": 371.496, "test_steps_per_second": 11.609}, {"test_loss": 0.3610811233520508, "test_micro_f1": 0.0, "test_micro_f1_no_misc": 0.0, "test_runtime": 5.8265, "test_samples_per_second": 351.497, "test_steps_per_second": 10.984}]}, "total": {"test_micro_f1": 68.49749510366561, "test_micro_f1_se": 15.039293646953958, "test_micro_f1_no_misc": 71.73499515841837, "test_micro_f1_no_misc_se": 15.69208901216657}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.06195194274187088, "test_micro_f1": 0.7437916414294368, "test_micro_f1_no_misc": 0.7867671143137898, "test_runtime": 5.7281, "test_samples_per_second": 357.534, "test_steps_per_second": 11.173}, {"test_loss": 0.0619070865213871, "test_micro_f1": 0.7551143200962694, "test_micro_f1_no_misc": 0.799206086668872, "test_runtime": 5.7204, "test_samples_per_second": 358.015, "test_steps_per_second": 11.188}, {"test_loss": 0.056432805955410004, "test_micro_f1": 0.756348246674728, "test_micro_f1_no_misc": 0.7940780619111709, "test_runtime": 5.5089, "test_samples_per_second": 371.763, "test_steps_per_second": 11.618}, {"test_loss": 0.07409942150115967, "test_micro_f1": 0.7474571345539088, "test_micro_f1_no_misc": 0.7878186031115524, "test_runtime": 5.6382, "test_samples_per_second": 363.24, "test_steps_per_second": 11.351}, {"test_loss": 0.06911975145339966, "test_micro_f1": 0.7506718423409973, "test_micro_f1_no_misc": 0.8052036973639165, "test_runtime": 5.5354, "test_samples_per_second": 369.983, "test_steps_per_second": 11.562}, {"test_loss": 0.07224169373512268, "test_micro_f1": 0.7444477346757475, "test_micro_f1_no_misc": 0.7879581151832461, "test_runtime": 6.418, "test_samples_per_second": 319.103, "test_steps_per_second": 9.972}, {"test_loss": 0.06143397092819214, "test_micro_f1": 0.7511478420569331, "test_micro_f1_no_misc": 0.7930682976554536, "test_runtime": 6.0534, "test_samples_per_second": 338.324, "test_steps_per_second": 10.573}, {"test_loss": 0.05690677464008331, "test_micro_f1": 0.7629987908101572, "test_micro_f1_no_misc": 0.8009478672985781, "test_runtime": 6.3967, "test_samples_per_second": 320.166, "test_steps_per_second": 10.005}, {"test_loss": 0.059587057679891586, "test_micro_f1": 0.773160972606956, "test_micro_f1_no_misc": 0.799174690508941, "test_runtime": 5.8811, "test_samples_per_second": 348.237, "test_steps_per_second": 10.882}, {"test_loss": 0.054953932762145996, "test_micro_f1": 0.7904155292690324, "test_micro_f1_no_misc": 0.8257804632426989, "test_runtime": 6.2341, "test_samples_per_second": 328.517, "test_steps_per_second": 10.266}]}, "total": {"test_micro_f1": 75.75554054514167, "test_micro_f1_se": 0.9034056659493978, "test_micro_f1_no_misc": 79.8000299725822, "test_micro_f1_no_misc_se": 0.7173448737298784}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.6911131143569946, "test_mcc": 0.08951485685284054, "test_macro_f1": 0.5010049925436036, "test_runtime": 3.4905, "test_samples_per_second": 586.73, "test_steps_per_second": 18.335}, {"test_loss": 0.4739167094230652, "test_mcc": 0.5930368894730565, "test_macro_f1": 0.7752561290014213, "test_runtime": 3.6332, "test_samples_per_second": 563.683, "test_steps_per_second": 17.615}, {"test_loss": 0.445473313331604, "test_mcc": 0.6248343592572463, "test_macro_f1": 0.7968692919571836, "test_runtime": 3.588, "test_samples_per_second": 570.785, "test_steps_per_second": 17.837}, {"test_loss": 0.4348312318325043, "test_mcc": 0.6110873976258485, "test_macro_f1": 0.8000836359210255, "test_runtime": 3.5555, "test_samples_per_second": 576.013, "test_steps_per_second": 18.0}, {"test_loss": 0.6912524700164795, "test_mcc": 0.04111748185778208, "test_macro_f1": 0.4874655445189281, "test_runtime": 3.5134, "test_samples_per_second": 582.914, "test_steps_per_second": 18.216}, {"test_loss": 0.44261521100997925, "test_mcc": 0.6048107687575902, "test_macro_f1": 0.7926149952937183, "test_runtime": 3.7167, "test_samples_per_second": 551.023, "test_steps_per_second": 17.219}, {"test_loss": 0.6962481737136841, "test_mcc": 0.01923140331991817, "test_macro_f1": 0.48551481174082456, "test_runtime": 3.5351, "test_samples_per_second": 579.334, "test_steps_per_second": 18.104}, {"test_loss": 0.6944787502288818, "test_mcc": 0.027196828844442775, "test_macro_f1": 0.5056705376811989, "test_runtime": 3.7346, "test_samples_per_second": 548.378, "test_steps_per_second": 17.137}, {"test_loss": 0.42361676692962646, "test_mcc": 0.6483286013262085, "test_macro_f1": 0.8226332470793587, "test_runtime": 3.6489, "test_samples_per_second": 561.268, "test_steps_per_second": 17.54}, {"test_loss": 0.5380309820175171, "test_mcc": 0.5021716266842968, "test_macro_f1": 0.7260214119411521, "test_runtime": 3.1918, "test_samples_per_second": 641.641, "test_steps_per_second": 20.051}]}, "total": {"test_mcc": 37.613302139992314, "test_mcc_se": 17.89099974017173, "test_macro_f1": 66.93134597678414, "test_macro_f1_se": 9.433340376179375}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.5531445741653442, "test_mcc": 0.5075894937860485, "test_macro_f1": 0.7245254212218586, "test_runtime": 3.6939, "test_samples_per_second": 554.431, "test_steps_per_second": 17.326}, {"test_loss": 0.5271139144897461, "test_mcc": 0.5472353579277452, "test_macro_f1": 0.7442923180892178, "test_runtime": 4.0876, "test_samples_per_second": 501.027, "test_steps_per_second": 15.657}, {"test_loss": 0.6953006982803345, "test_mcc": 0.02948369534660011, "test_macro_f1": 0.5069297671648094, "test_runtime": 3.8878, "test_samples_per_second": 526.776, "test_steps_per_second": 16.462}, {"test_loss": 0.693321168422699, "test_mcc": 0.05308606160822492, "test_macro_f1": 0.4982358853290392, "test_runtime": 4.3773, "test_samples_per_second": 467.866, "test_steps_per_second": 14.621}, {"test_loss": 0.4549405574798584, "test_mcc": 0.5966584312604625, "test_macro_f1": 0.798329025275871, "test_runtime": 4.0769, "test_samples_per_second": 502.339, "test_steps_per_second": 15.698}, {"test_loss": 0.693222165107727, "test_mcc": 0.028987492712412855, "test_macro_f1": 0.5107007975162399, "test_runtime": 4.2062, "test_samples_per_second": 486.899, "test_steps_per_second": 15.216}, {"test_loss": 0.4871523976325989, "test_mcc": 0.5706428397681877, "test_macro_f1": 0.7694867696704889, "test_runtime": 3.4776, "test_samples_per_second": 588.919, "test_steps_per_second": 18.404}, {"test_loss": 0.6850518584251404, "test_mcc": 0.11476947943954587, "test_macro_f1": 0.5550268363253058, "test_runtime": 3.987, "test_samples_per_second": 513.669, "test_steps_per_second": 16.052}, {"test_loss": 0.7013407945632935, "test_mcc": -0.0031377878085834345, "test_macro_f1": 0.49591475311421274, "test_runtime": 3.6693, "test_samples_per_second": 558.15, "test_steps_per_second": 17.442}, {"test_loss": 0.4573638141155243, "test_mcc": 0.5921801929544188, "test_macro_f1": 0.7887662330636989, "test_runtime": 4.1882, "test_samples_per_second": 488.996, "test_steps_per_second": 15.281}]}, "total": {"test_mcc": 30.37495256995063, "test_mcc_se": 17.093095145090828, "test_macro_f1": 63.922078067707425, "test_macro_f1_se": 8.379129016046356}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.6834100484848022, "test_mcc": 0.12344613900984594, "test_macro_f1": 0.49335943782805813, "test_runtime": 3.3236, "test_samples_per_second": 616.203, "test_steps_per_second": 19.256}, {"test_loss": 0.7010065317153931, "test_mcc": -0.03992179867406661, "test_macro_f1": 0.4789833822091887, "test_runtime": 3.2114, "test_samples_per_second": 637.72, "test_steps_per_second": 19.929}, {"test_loss": 0.694624662399292, "test_mcc": 0.011696322175605572, "test_macro_f1": 0.33455387263497494, "test_runtime": 3.1853, "test_samples_per_second": 642.963, "test_steps_per_second": 20.093}, {"test_loss": 0.7005385160446167, "test_mcc": -0.017516997665800282, "test_macro_f1": 0.46150596463365134, "test_runtime": 3.2726, "test_samples_per_second": 625.802, "test_steps_per_second": 19.556}, {"test_loss": 0.693997859954834, "test_mcc": 0.04293062507813794, "test_macro_f1": 0.5214474079513971, "test_runtime": 3.2848, "test_samples_per_second": 623.482, "test_steps_per_second": 19.484}, {"test_loss": 0.6969674825668335, "test_mcc": 0.0033964494522221345, "test_macro_f1": 0.44792404493797133, "test_runtime": 3.1294, "test_samples_per_second": 654.433, "test_steps_per_second": 20.451}, {"test_loss": 0.7021108269691467, "test_mcc": -0.03244108556994156, "test_macro_f1": 0.47890616821560256, "test_runtime": 3.1104, "test_samples_per_second": 658.429, "test_steps_per_second": 20.576}, {"test_loss": 0.6907554864883423, "test_mcc": 0.07337525302296243, "test_macro_f1": 0.5353506151117118, "test_runtime": 3.1947, "test_samples_per_second": 641.067, "test_steps_per_second": 20.033}, {"test_loss": 0.4442339539527893, "test_mcc": 0.6219324267511384, "test_macro_f1": 0.7943264126974353, "test_runtime": 3.146, "test_samples_per_second": 650.988, "test_steps_per_second": 20.343}, {"test_loss": 0.7005642652511597, "test_mcc": 0.01480891083119775, "test_macro_f1": 0.4836195072874084, "test_runtime": 3.219, "test_samples_per_second": 636.217, "test_steps_per_second": 19.882}]}, "total": {"test_mcc": 8.017062444113018, "test_mcc_se": 12.193259116051337, "test_macro_f1": 50.299768135074, "test_macro_f1_se": 7.187053193746783}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_loss": 0.5285488367080688, "test_mcc": 0.5023435874032302, "test_macro_f1": 0.731532533566378, "test_runtime": 3.4472, "test_samples_per_second": 594.109, "test_steps_per_second": 18.566}, {"test_loss": 0.7008452415466309, "test_mcc": 0.006517279609606932, "test_macro_f1": 0.4531184693261505, "test_runtime": 3.4795, "test_samples_per_second": 588.595, "test_steps_per_second": 18.394}, {"test_loss": 0.6959928274154663, "test_mcc": 0.009573222246088923, "test_macro_f1": 0.4981047258595438, "test_runtime": 3.5304, "test_samples_per_second": 580.104, "test_steps_per_second": 18.128}, {"test_loss": 0.7020117044448853, "test_mcc": -0.018662815102286137, "test_macro_f1": 0.4787351496471902, "test_runtime": 3.3027, "test_samples_per_second": 620.096, "test_steps_per_second": 19.378}, {"test_loss": 0.6884403228759766, "test_mcc": 0.06487286206013007, "test_macro_f1": 0.5260420920798279, "test_runtime": 3.3854, "test_samples_per_second": 604.953, "test_steps_per_second": 18.905}, {"test_loss": 0.6964327692985535, "test_mcc": -0.0009527166848891565, "test_macro_f1": 0.49654745118555166, "test_runtime": 3.5744, "test_samples_per_second": 572.965, "test_steps_per_second": 17.905}, {"test_loss": 0.5018370151519775, "test_mcc": 0.5331904609611906, "test_macro_f1": 0.7665835316334365, "test_runtime": 3.4371, "test_samples_per_second": 595.856, "test_steps_per_second": 18.621}, {"test_loss": 0.6853595972061157, "test_mcc": 0.11625989995742084, "test_macro_f1": 0.5315997541785117, "test_runtime": 3.3692, "test_samples_per_second": 607.854, "test_steps_per_second": 18.995}, {"test_loss": 0.6922251582145691, "test_mcc": 0.07232017974069054, "test_macro_f1": 0.5187987427010976, "test_runtime": 3.3842, "test_samples_per_second": 605.167, "test_steps_per_second": 18.911}, {"test_loss": 0.560592532157898, "test_mcc": 0.4183505536371162, "test_macro_f1": 0.6857044608619356, "test_runtime": 3.5417, "test_samples_per_second": 578.25, "test_steps_per_second": 18.07}]}, "total": {"test_mcc": 17.03812513828299, "test_mcc_se": 13.778969075493436, "test_macro_f1": 56.86766911039622, "test_macro_f1_se": 7.057544628506143}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_em": 34.856700232378, "test_f1": 39.004923066300535}, {"test_em": 35.03875968992248, "test_f1": 38.56990994242166}, {"test_em": 26.043276661514682, "test_f1": 31.070093483056883}, {"test_em": 35.2803738317757, "test_f1": 38.96837994777854}, {"test_em": 34.5945945945946, "test_f1": 38.34815513392903}, {"test_em": 30.994602929838088, "test_f1": 34.62605421956724}, {"test_em": 37.28170083523159, "test_f1": 41.6530497237247}, {"test_em": 38.78975950349108, "test_f1": 42.624733130257304}, {"test_em": 35.21568627450981, "test_f1": 40.37714906214982}, {"test_em": 38.50931677018634, "test_f1": 41.99239376611355}]}, "total": {"test_em": 34.660477132344234, "test_em_se": 2.3311149547465337, "test_f1": 38.72348414752993, "test_f1_se": 2.1951361749707154}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_em": 37.33539891556933, "test_f1": 41.54542329613614}, {"test_em": 34.651162790697676, "test_f1": 38.99800514736076}, {"test_em": 30.525502318392583, "test_f1": 35.66630631586298}, {"test_em": 37.22741433021807, "test_f1": 40.8319110947663}, {"test_em": 37.22007722007722, "test_f1": 41.058598146391176}, {"test_em": 33.8473400154202, "test_f1": 38.30761053588918}, {"test_em": 35.535307517084284, "test_f1": 39.92695052396706}, {"test_em": 35.60899922420481, "test_f1": 40.03546006852611}, {"test_em": 38.666666666666664, "test_f1": 43.31276036832039}, {"test_em": 34.3944099378882, "test_f1": 39.94820501878027}]}, "total": {"test_em": 35.5012278936219, "test_em_se": 1.4428459743129156, "test_f1": 39.96312305160004, "test_f1_se": 1.270564102473817}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_em": 37.10302091402014, "test_f1": 42.015491933584094}, {"test_em": 34.8062015503876, "test_f1": 39.681041005218425}, {"test_em": 38.02163833075734, "test_f1": 42.29748638249408}, {"test_em": 40.809968847352025, "test_f1": 45.21066751462884}, {"test_em": 38.455598455598455, "test_f1": 43.494700333921145}, {"test_em": 34.38704703161141, "test_f1": 39.078245541381314}, {"test_em": 38.1169324221716, "test_f1": 43.055861007085745}, {"test_em": 35.53141970519783, "test_f1": 40.51125561008021}, {"test_em": 39.13725490196079, "test_f1": 43.80020860960317}, {"test_em": 34.54968944099379, "test_f1": 39.4426036662108}]}, "total": {"test_em": 37.0918771600051, "test_em_se": 1.3582577642680338, "test_f1": 41.85875616042078, "test_f1_se": 1.2977871649419863}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.5993411540985107, "test_mcc": 0.6268000477761266, "test_macro_f1": 0.555665065904651, "test_runtime": 15.3298, "test_samples_per_second": 133.596, "test_steps_per_second": 16.7}, {"test_loss": 0.5479278564453125, "test_mcc": 0.6298345028235887, "test_macro_f1": 0.5714179682174358, "test_runtime": 14.7777, "test_samples_per_second": 138.587, "test_steps_per_second": 17.323}, {"test_loss": 0.626685619354248, "test_mcc": 0.6060804281449191, "test_macro_f1": 0.6115464891015714, "test_runtime": 14.9294, "test_samples_per_second": 137.179, "test_steps_per_second": 17.147}, {"test_loss": 0.6562432050704956, "test_mcc": 0.5541077713913264, "test_macro_f1": 0.5266395317970493, "test_runtime": 14.4803, "test_samples_per_second": 141.434, "test_steps_per_second": 17.679}, {"test_loss": 0.5013464689254761, "test_mcc": 0.6650228582555284, "test_macro_f1": 0.6691919022878631, "test_runtime": 14.5014, "test_samples_per_second": 141.227, "test_steps_per_second": 17.653}, {"test_loss": 0.556175708770752, "test_mcc": 0.6345084268823736, "test_macro_f1": 0.6430432230456967, "test_runtime": 14.8953, "test_samples_per_second": 137.493, "test_steps_per_second": 17.187}, {"test_loss": 0.48550426959991455, "test_mcc": 0.7083256226510957, "test_macro_f1": 0.7056853948617499, "test_runtime": 14.18, "test_samples_per_second": 144.429, "test_steps_per_second": 18.054}, {"test_loss": 0.5542936325073242, "test_mcc": 0.6383973387206778, "test_macro_f1": 0.6376593290085618, "test_runtime": 15.4228, "test_samples_per_second": 132.79, "test_steps_per_second": 16.599}, {"test_loss": 0.5363532304763794, "test_mcc": 0.6366540348914722, "test_macro_f1": 0.5720727013384805, "test_runtime": 15.2705, "test_samples_per_second": 134.115, "test_steps_per_second": 16.764}, {"test_loss": 0.46372026205062866, "test_mcc": 0.7025339458501626, "test_macro_f1": 0.7336763250559372, "test_runtime": 13.4799, "test_samples_per_second": 151.929, "test_steps_per_second": 18.991}]}, "total": {"test_mcc": 64.02264977387271, "test_mcc_se": 2.776015198462798, "test_macro_f1": 62.26597930618997, "test_macro_f1_se": 4.185419592621477}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.8382116556167603, "test_mcc": 0.43727513795485096, "test_macro_f1": 0.6185599186466068, "test_runtime": 4.3795, "test_samples_per_second": 467.632, "test_steps_per_second": 14.613}, {"test_loss": 0.8396327495574951, "test_mcc": 0.42747704374321144, "test_macro_f1": 0.615670748244943, "test_runtime": 4.3952, "test_samples_per_second": 465.964, "test_steps_per_second": 14.561}, {"test_loss": 0.9105833768844604, "test_mcc": 0.44355764454977314, "test_macro_f1": 0.6237212071804218, "test_runtime": 4.42, "test_samples_per_second": 463.351, "test_steps_per_second": 14.48}, {"test_loss": 0.8182753324508667, "test_mcc": 0.4791970693168432, "test_macro_f1": 0.6536693851214644, "test_runtime": 4.3536, "test_samples_per_second": 470.411, "test_steps_per_second": 14.7}, {"test_loss": 0.8805443048477173, "test_mcc": 0.42321233140776876, "test_macro_f1": 0.6157569048446893, "test_runtime": 4.3586, "test_samples_per_second": 469.872, "test_steps_per_second": 14.683}, {"test_loss": 0.881123960018158, "test_mcc": 0.4038178074380261, "test_macro_f1": 0.6082273205874725, "test_runtime": 4.4813, "test_samples_per_second": 457.006, "test_steps_per_second": 14.281}, {"test_loss": 0.851491391658783, "test_mcc": 0.42578928737945804, "test_macro_f1": 0.6072140568847675, "test_runtime": 4.3497, "test_samples_per_second": 470.835, "test_steps_per_second": 14.714}, {"test_loss": 0.8380550742149353, "test_mcc": 0.4713541773980313, "test_macro_f1": 0.644330416372077, "test_runtime": 4.4732, "test_samples_per_second": 457.839, "test_steps_per_second": 14.307}, {"test_loss": 0.8106464147567749, "test_mcc": 0.4591846257873122, "test_macro_f1": 0.6310162580895425, "test_runtime": 4.481, "test_samples_per_second": 457.045, "test_steps_per_second": 14.283}, {"test_loss": 0.9083487391471863, "test_mcc": 0.4192627807832203, "test_macro_f1": 0.6124861371913589, "test_runtime": 4.2804, "test_samples_per_second": 478.458, "test_steps_per_second": 14.952}]}, "total": {"test_mcc": 43.90127905758495, "test_mcc_se": 1.500912771950637, "test_macro_f1": 62.30652353163344, "test_macro_f1_se": 0.9611330253235107}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.8476351499557495, "test_mcc": 0.40489185407760864, "test_macro_f1": 0.5706251279255774, "test_runtime": 3.8413, "test_samples_per_second": 533.154, "test_steps_per_second": 16.661}, {"test_loss": 0.8510514497756958, "test_mcc": 0.4157125851410756, "test_macro_f1": 0.5936636706808341, "test_runtime": 3.6843, "test_samples_per_second": 555.869, "test_steps_per_second": 17.371}, {"test_loss": 0.8367505073547363, "test_mcc": 0.37407362952476625, "test_macro_f1": 0.4936907803164367, "test_runtime": 3.7128, "test_samples_per_second": 551.61, "test_steps_per_second": 17.238}, {"test_loss": 0.9993756413459778, "test_mcc": 0.10571862120826793, "test_macro_f1": 0.2603332948708535, "test_runtime": 3.4089, "test_samples_per_second": 600.777, "test_steps_per_second": 18.774}, {"test_loss": 0.9002211093902588, "test_mcc": 0.4037952490530524, "test_macro_f1": 0.567849556684252, "test_runtime": 3.6945, "test_samples_per_second": 554.344, "test_steps_per_second": 17.323}, {"test_loss": 0.9974775910377502, "test_mcc": 0.07857896342238908, "test_macro_f1": 0.29785416177708546, "test_runtime": 3.5066, "test_samples_per_second": 584.033, "test_steps_per_second": 18.251}, {"test_loss": 0.7982510328292847, "test_mcc": 0.4442247142802971, "test_macro_f1": 0.5957785692947882, "test_runtime": 3.5951, "test_samples_per_second": 569.658, "test_steps_per_second": 17.802}, {"test_loss": 0.9957424402236938, "test_mcc": 0.14665479436656845, "test_macro_f1": 0.34997018424520204, "test_runtime": 3.8445, "test_samples_per_second": 532.713, "test_steps_per_second": 16.647}, {"test_loss": 0.8508079051971436, "test_mcc": 0.4099358151055013, "test_macro_f1": 0.5800727141511487, "test_runtime": 3.859, "test_samples_per_second": 530.701, "test_steps_per_second": 16.584}, {"test_loss": 0.7929000854492188, "test_mcc": 0.4452595938727004, "test_macro_f1": 0.5986195235331757, "test_runtime": 3.7471, "test_samples_per_second": 546.563, "test_steps_per_second": 17.08}]}, "total": {"test_mcc": 32.28845820052227, "test_mcc_se": 9.232349054251571, "test_macro_f1": 49.08457583479354, "test_macro_f1_se": 8.358816178824382}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.0839337557554245, "test_micro_f1": 0.5873910814966684, "test_micro_f1_no_misc": 0.6363131593559133, "test_runtime": 7.3803, "test_samples_per_second": 277.496, "test_steps_per_second": 8.672}, {"test_loss": 0.08044351637363434, "test_micro_f1": 0.6017607457276023, "test_micro_f1_no_misc": 0.6547137073452862, "test_runtime": 6.953, "test_samples_per_second": 294.549, "test_steps_per_second": 9.205}, {"test_loss": 0.07467146962881088, "test_micro_f1": 0.5980160604629191, "test_micro_f1_no_misc": 0.6518753301637612, "test_runtime": 6.3249, "test_samples_per_second": 323.799, "test_steps_per_second": 10.119}, {"test_loss": 0.07904418557882309, "test_micro_f1": 0.5914691943127962, "test_micro_f1_no_misc": 0.6584130557118739, "test_runtime": 7.2376, "test_samples_per_second": 282.965, "test_steps_per_second": 8.843}, {"test_loss": 0.0771576315164566, "test_micro_f1": 0.6266416510318948, "test_micro_f1_no_misc": 0.6798748696558916, "test_runtime": 7.4253, "test_samples_per_second": 275.812, "test_steps_per_second": 8.619}, {"test_loss": 0.08376207947731018, "test_micro_f1": 0.5780510879848628, "test_micro_f1_no_misc": 0.6187341772151899, "test_runtime": 6.2973, "test_samples_per_second": 325.219, "test_steps_per_second": 10.163}, {"test_loss": 0.08541683852672577, "test_micro_f1": 0.5824228028503563, "test_micro_f1_no_misc": 0.6306400839454354, "test_runtime": 6.1555, "test_samples_per_second": 332.711, "test_steps_per_second": 10.397}, {"test_loss": 0.06743715703487396, "test_micro_f1": 0.6110531803962461, "test_micro_f1_no_misc": 0.667065868263473, "test_runtime": 7.0031, "test_samples_per_second": 292.441, "test_steps_per_second": 9.139}, {"test_loss": 0.07638078182935715, "test_micro_f1": 0.6403669724770642, "test_micro_f1_no_misc": 0.7054347826086956, "test_runtime": 6.7739, "test_samples_per_second": 302.337, "test_steps_per_second": 9.448}, {"test_loss": 0.0795636922121048, "test_micro_f1": 0.6354515050167224, "test_micro_f1_no_misc": 0.6923494302767227, "test_runtime": 6.501, "test_samples_per_second": 315.027, "test_steps_per_second": 9.845}]}, "total": {"test_micro_f1": 60.52624281757133, "test_micro_f1_se": 1.3814298594619536, "test_micro_f1_no_misc": 65.95414464542243, "test_micro_f1_no_misc_se": 1.7006822727860027}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.0778903067111969, "test_micro_f1": 0.7382449082222781, "test_micro_f1_no_misc": 0.7768096514745307, "test_runtime": 7.9151, "test_samples_per_second": 258.747, "test_steps_per_second": 8.086}, {"test_loss": 0.07043936848640442, "test_micro_f1": 0.7522075055187638, "test_micro_f1_no_misc": 0.7910764872521248, "test_runtime": 6.1106, "test_samples_per_second": 335.156, "test_steps_per_second": 10.474}, {"test_loss": 0.07038155198097229, "test_micro_f1": 0.7530536378120022, "test_micro_f1_no_misc": 0.7763864042933811, "test_runtime": 7.8626, "test_samples_per_second": 260.475, "test_steps_per_second": 8.14}, {"test_loss": 0.0678015947341919, "test_micro_f1": 0.7726460831844859, "test_micro_f1_no_misc": 0.7975334018499485, "test_runtime": 7.7668, "test_samples_per_second": 263.686, "test_steps_per_second": 8.24}, {"test_loss": 0.07720958441495895, "test_micro_f1": 0.7223880597014924, "test_micro_f1_no_misc": 0.7627671133647229, "test_runtime": 7.8218, "test_samples_per_second": 261.833, "test_steps_per_second": 8.182}, {"test_loss": 0.07621927559375763, "test_micro_f1": 0.7515958923119622, "test_micro_f1_no_misc": 0.7769314472252449, "test_runtime": 7.8926, "test_samples_per_second": 259.483, "test_steps_per_second": 8.109}, {"test_loss": 0.0766763687133789, "test_micro_f1": 0.7339257710402509, "test_micro_f1_no_misc": 0.7753273604410752, "test_runtime": 8.3986, "test_samples_per_second": 243.852, "test_steps_per_second": 7.62}, {"test_loss": 0.07063928246498108, "test_micro_f1": 0.757485837604532, "test_micro_f1_no_misc": 0.7991021324354658, "test_runtime": 8.6854, "test_samples_per_second": 235.799, "test_steps_per_second": 7.369}, {"test_loss": 0.0796147957444191, "test_micro_f1": 0.7012179321067634, "test_micro_f1_no_misc": 0.718070652173913, "test_runtime": 8.345, "test_samples_per_second": 245.417, "test_steps_per_second": 7.669}, {"test_loss": 0.06854832172393799, "test_micro_f1": 0.771283693621564, "test_micro_f1_no_misc": 0.8007079646017699, "test_runtime": 6.9243, "test_samples_per_second": 295.772, "test_steps_per_second": 9.243}]}, "total": {"test_micro_f1": 74.54049321124094, "test_micro_f1_se": 1.3651616985950628, "test_micro_f1_no_misc": 77.74712615112176, "test_micro_f1_no_misc_se": 1.5106809127301126}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.07525455951690674, "test_micro_f1": 0.6929243638898571, "test_micro_f1_no_misc": 0.7477227722772276, "test_runtime": 6.282, "test_samples_per_second": 326.009, "test_steps_per_second": 10.188}, {"test_loss": 0.06710681319236755, "test_micro_f1": 0.7321048901488306, "test_micro_f1_no_misc": 0.7784045124899275, "test_runtime": 6.5344, "test_samples_per_second": 313.42, "test_steps_per_second": 9.794}, {"test_loss": 0.06592997908592224, "test_micro_f1": 0.7551299589603283, "test_micro_f1_no_misc": 0.7879245283018866, "test_runtime": 6.2652, "test_samples_per_second": 326.884, "test_steps_per_second": 10.215}, {"test_loss": 0.06206401810050011, "test_micro_f1": 0.7595108695652174, "test_micro_f1_no_misc": 0.7905739262637781, "test_runtime": 5.9845, "test_samples_per_second": 342.219, "test_steps_per_second": 10.694}, {"test_loss": 0.07867558300495148, "test_micro_f1": 0.6687558759009714, "test_micro_f1_no_misc": 0.7059219380888291, "test_runtime": 6.5777, "test_samples_per_second": 311.354, "test_steps_per_second": 9.73}, {"test_loss": 0.06457198411226273, "test_micro_f1": 0.7265943012211669, "test_micro_f1_no_misc": 0.7670304855099737, "test_runtime": 6.4746, "test_samples_per_second": 316.315, "test_steps_per_second": 9.885}, {"test_loss": 0.07054047286510468, "test_micro_f1": 0.7182539682539681, "test_micro_f1_no_misc": 0.7601476014760148, "test_runtime": 6.4449, "test_samples_per_second": 317.77, "test_steps_per_second": 9.93}, {"test_loss": 0.08322708308696747, "test_micro_f1": 0.6568144499178983, "test_micro_f1_no_misc": 0.6835799859055673, "test_runtime": 5.6766, "test_samples_per_second": 360.781, "test_steps_per_second": 11.274}, {"test_loss": 0.0670270025730133, "test_micro_f1": 0.7252595155709342, "test_micro_f1_no_misc": 0.765793528505393, "test_runtime": 6.3612, "test_samples_per_second": 321.953, "test_steps_per_second": 10.061}, {"test_loss": 0.0651690661907196, "test_micro_f1": 0.7889344262295082, "test_micro_f1_no_misc": 0.8272450532724506, "test_runtime": 6.224, "test_samples_per_second": 329.05, "test_steps_per_second": 10.283}]}, "total": {"test_micro_f1": 72.24282619658679, "test_micro_f1_se": 2.5354385856161006, "test_micro_f1_no_misc": 76.14344332091049, "test_micro_f1_no_misc_se": 2.576552487442888}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.08049255609512329, "test_micro_f1": 0.7045660719685516, "test_micro_f1_no_misc": 0.74, "test_runtime": 6.6804, "test_samples_per_second": 306.569, "test_steps_per_second": 9.58}, {"test_loss": 0.08313634991645813, "test_micro_f1": 0.6773333333333333, "test_micro_f1_no_misc": 0.7189583994919021, "test_runtime": 6.6428, "test_samples_per_second": 308.305, "test_steps_per_second": 9.635}, {"test_loss": 0.0741802453994751, "test_micro_f1": 0.7197640117994101, "test_micro_f1_no_misc": 0.7576656775469832, "test_runtime": 6.0426, "test_samples_per_second": 338.928, "test_steps_per_second": 10.591}, {"test_loss": 0.09906089305877686, "test_micro_f1": 0.6368547418967588, "test_micro_f1_no_misc": 0.681728880157171, "test_runtime": 6.473, "test_samples_per_second": 316.39, "test_steps_per_second": 9.887}, {"test_loss": 0.0883302241563797, "test_micro_f1": 0.6976336546888695, "test_micro_f1_no_misc": 0.7469304229195088, "test_runtime": 6.4053, "test_samples_per_second": 319.735, "test_steps_per_second": 9.992}, {"test_loss": 0.08716544508934021, "test_micro_f1": 0.68053148469093, "test_micro_f1_no_misc": 0.722860791826309, "test_runtime": 5.7171, "test_samples_per_second": 358.224, "test_steps_per_second": 11.194}, {"test_loss": 0.0740811824798584, "test_micro_f1": 0.7064137308039747, "test_micro_f1_no_misc": 0.7519147519147519, "test_runtime": 5.7568, "test_samples_per_second": 355.751, "test_steps_per_second": 11.117}, {"test_loss": 0.08222680538892746, "test_micro_f1": 0.660751257024549, "test_micro_f1_no_misc": 0.7032546266751754, "test_runtime": 5.9755, "test_samples_per_second": 342.73, "test_steps_per_second": 10.71}, {"test_loss": 0.08559703081846237, "test_micro_f1": 0.6670647954613317, "test_micro_f1_no_misc": 0.7178807947019867, "test_runtime": 5.2916, "test_samples_per_second": 387.03, "test_steps_per_second": 12.095}, {"test_loss": 0.07772738486528397, "test_micro_f1": 0.7098293113596232, "test_micro_f1_no_misc": 0.747011308562197, "test_runtime": 5.4751, "test_samples_per_second": 374.06, "test_steps_per_second": 11.689}]}, "total": {"test_micro_f1": 68.60742393027331, "test_micro_f1_se": 1.6163714860937948, "test_micro_f1_no_misc": 72.88205653795985, "test_micro_f1_no_misc_se": 1.5002410726770161}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.6993263959884644, "test_mcc": 0.015372091705232675, "test_macro_f1": 0.43653705062362436, "test_runtime": 3.0662, "test_samples_per_second": 667.936, "test_steps_per_second": 20.873}, {"test_loss": 0.6984250545501709, "test_mcc": 0.01881447190485789, "test_macro_f1": 0.5052972114831398, "test_runtime": 3.1558, "test_samples_per_second": 648.966, "test_steps_per_second": 20.28}, {"test_loss": 0.7026499509811401, "test_mcc": 0.013164165943065574, "test_macro_f1": 0.5054612489438512, "test_runtime": 3.1717, "test_samples_per_second": 645.717, "test_steps_per_second": 20.179}, {"test_loss": 0.6973211765289307, "test_mcc": 0.0017402909441422403, "test_macro_f1": 0.4704823136323706, "test_runtime": 3.1494, "test_samples_per_second": 650.287, "test_steps_per_second": 20.321}, {"test_loss": 0.6939570903778076, "test_mcc": 0.0018428007075564365, "test_macro_f1": 0.4998872116646771, "test_runtime": 3.1568, "test_samples_per_second": 648.752, "test_steps_per_second": 20.273}, {"test_loss": 0.6947935223579407, "test_mcc": 0.027337755632658698, "test_macro_f1": 0.5102315338629698, "test_runtime": 3.1526, "test_samples_per_second": 649.624, "test_steps_per_second": 20.301}, {"test_loss": 0.6988136768341064, "test_mcc": -0.0056496441700691425, "test_macro_f1": 0.48749384413907326, "test_runtime": 3.096, "test_samples_per_second": 661.499, "test_steps_per_second": 20.672}, {"test_loss": 0.6969518661499023, "test_mcc": -0.011741524501681649, "test_macro_f1": 0.46922220439051965, "test_runtime": 3.2207, "test_samples_per_second": 635.892, "test_steps_per_second": 19.872}, {"test_loss": 0.6936795711517334, "test_mcc": 0.0, "test_macro_f1": 0.3298429319371728, "test_runtime": 3.1777, "test_samples_per_second": 644.501, "test_steps_per_second": 20.141}, {"test_loss": 0.6965981721878052, "test_mcc": 0.01935582367810507, "test_macro_f1": 0.5096604095384085, "test_runtime": 3.2091, "test_samples_per_second": 638.183, "test_steps_per_second": 19.943}]}, "total": {"test_mcc": 0.8023623184386779, "test_mcc_se": 0.7779888089760758, "test_macro_f1": 47.24115960215808, "test_macro_f1_se": 3.432372961195539}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.6895710229873657, "test_mcc": 0.08715301586819073, "test_macro_f1": 0.5434177336220354, "test_runtime": 3.5274, "test_samples_per_second": 580.599, "test_steps_per_second": 18.144}, {"test_loss": 0.6946506500244141, "test_mcc": -0.0007198466006197015, "test_macro_f1": 0.40829783616621407, "test_runtime": 3.685, "test_samples_per_second": 555.768, "test_steps_per_second": 17.368}, {"test_loss": 0.6937073469161987, "test_mcc": 0.07677867788286735, "test_macro_f1": 0.5323194554388627, "test_runtime": 3.531, "test_samples_per_second": 580.011, "test_steps_per_second": 18.125}, {"test_loss": 0.4641888439655304, "test_mcc": 0.58562897478511, "test_macro_f1": 0.7722631913603288, "test_runtime": 3.6833, "test_samples_per_second": 556.03, "test_steps_per_second": 17.376}, {"test_loss": 0.6812492609024048, "test_mcc": 0.15228188330063175, "test_macro_f1": 0.5560296389035092, "test_runtime": 3.5151, "test_samples_per_second": 582.634, "test_steps_per_second": 18.207}, {"test_loss": 0.6939700841903687, "test_mcc": 0.07015502289253855, "test_macro_f1": 0.5350693450847974, "test_runtime": 3.559, "test_samples_per_second": 575.442, "test_steps_per_second": 17.983}, {"test_loss": 0.6986676454544067, "test_mcc": 0.013827851363698565, "test_macro_f1": 0.49346765767546563, "test_runtime": 3.3918, "test_samples_per_second": 603.817, "test_steps_per_second": 18.869}, {"test_loss": 0.48564597964286804, "test_mcc": 0.5914143974111242, "test_macro_f1": 0.7730243811614177, "test_runtime": 3.4935, "test_samples_per_second": 586.231, "test_steps_per_second": 18.32}, {"test_loss": 0.6864972114562988, "test_mcc": 0.12156328582740084, "test_macro_f1": 0.557101842530349, "test_runtime": 3.5293, "test_samples_per_second": 580.277, "test_steps_per_second": 18.134}, {"test_loss": 0.6958673000335693, "test_mcc": 0.01785216756303295, "test_macro_f1": 0.47610711275367956, "test_runtime": 3.6069, "test_samples_per_second": 567.794, "test_steps_per_second": 17.744}]}, "total": {"test_mcc": 17.159354302939754, "test_mcc_se": 13.938817567064754, "test_macro_f1": 56.47098194696658, "test_macro_f1_se": 7.344647272472887}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.6937156915664673, "test_mcc": 0.01577154674938464, "test_macro_f1": 0.5029076795085641, "test_runtime": 3.132, "test_samples_per_second": 653.889, "test_steps_per_second": 20.434}, {"test_loss": 0.7027479410171509, "test_mcc": -0.052489026785783925, "test_macro_f1": 0.45894695437506794, "test_runtime": 3.1641, "test_samples_per_second": 647.264, "test_steps_per_second": 20.227}, {"test_loss": 0.7089939117431641, "test_mcc": 0.014912914290586948, "test_macro_f1": 0.503699539995182, "test_runtime": 3.22, "test_samples_per_second": 636.034, "test_steps_per_second": 19.876}, {"test_loss": 0.6976031064987183, "test_mcc": -0.017104572897133387, "test_macro_f1": 0.48712814252332226, "test_runtime": 3.259, "test_samples_per_second": 628.423, "test_steps_per_second": 19.638}, {"test_loss": 0.6949034333229065, "test_mcc": 0.019454387129804112, "test_macro_f1": 0.5006974042574683, "test_runtime": 3.1856, "test_samples_per_second": 642.888, "test_steps_per_second": 20.09}, {"test_loss": 0.6952106952667236, "test_mcc": 0.045853321223785895, "test_macro_f1": 0.5218699870139791, "test_runtime": 3.0796, "test_samples_per_second": 665.028, "test_steps_per_second": 20.782}, {"test_loss": 0.6963299512863159, "test_mcc": 0.01457214487779264, "test_macro_f1": 0.4448908003538367, "test_runtime": 3.0503, "test_samples_per_second": 671.402, "test_steps_per_second": 20.981}, {"test_loss": 0.6940487623214722, "test_mcc": -0.0032169695029560822, "test_macro_f1": 0.4983714271745209, "test_runtime": 3.2095, "test_samples_per_second": 638.098, "test_steps_per_second": 19.941}, {"test_loss": 0.6944831013679504, "test_mcc": 0.0010242075229257859, "test_macro_f1": 0.49357404019497864, "test_runtime": 3.3714, "test_samples_per_second": 607.468, "test_steps_per_second": 18.983}, {"test_loss": 0.6948387026786804, "test_mcc": 0.005743187041727548, "test_macro_f1": 0.502139531322528, "test_runtime": 3.2313, "test_samples_per_second": 633.796, "test_steps_per_second": 19.806}]}, "total": {"test_mcc": 0.4452113965013419, "test_mcc_se": 1.6080917919089233, "test_macro_f1": 49.142255067194476, "test_macro_f1_se": 1.4166613243820494}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_loss": 0.6950696706771851, "test_mcc": 0.015993770624986012, "test_macro_f1": 0.5077823452076935, "test_runtime": 3.389, "test_samples_per_second": 604.306, "test_steps_per_second": 18.885}, {"test_loss": 0.6931235790252686, "test_mcc": 0.02682525838968882, "test_macro_f1": 0.5131964809384164, "test_runtime": 3.4599, "test_samples_per_second": 591.929, "test_steps_per_second": 18.498}, {"test_loss": 0.6986855268478394, "test_mcc": 0.0007662883192811818, "test_macro_f1": 0.48294049192291766, "test_runtime": 3.4827, "test_samples_per_second": 588.058, "test_steps_per_second": 18.377}, {"test_loss": 0.7049528360366821, "test_mcc": -0.012251837718233289, "test_macro_f1": 0.49129047019901084, "test_runtime": 3.3312, "test_samples_per_second": 614.792, "test_steps_per_second": 19.212}, {"test_loss": 0.6929512023925781, "test_mcc": 0.002687565016266495, "test_macro_f1": 0.3470928793434406, "test_runtime": 3.3349, "test_samples_per_second": 614.117, "test_steps_per_second": 19.191}, {"test_loss": 0.6922692060470581, "test_mcc": 0.02097263478631015, "test_macro_f1": 0.4306346934742832, "test_runtime": 3.5192, "test_samples_per_second": 581.954, "test_steps_per_second": 18.186}, {"test_loss": 0.6986674070358276, "test_mcc": -0.04964606198875026, "test_macro_f1": 0.47493697960430825, "test_runtime": 3.4112, "test_samples_per_second": 600.378, "test_steps_per_second": 18.762}, {"test_loss": 0.6947472095489502, "test_mcc": -0.03769500375236359, "test_macro_f1": 0.41445334605305306, "test_runtime": 3.3958, "test_samples_per_second": 603.097, "test_steps_per_second": 18.847}, {"test_loss": 0.6915589570999146, "test_mcc": 0.041863170624853535, "test_macro_f1": 0.5178571428571429, "test_runtime": 3.3838, "test_samples_per_second": 605.246, "test_steps_per_second": 18.914}, {"test_loss": 0.6950963735580444, "test_mcc": -0.017799785576245935, "test_macro_f1": 0.40851282155829416, "test_runtime": 3.4638, "test_samples_per_second": 591.258, "test_steps_per_second": 18.477}]}, "total": {"test_mcc": -0.08284001274206897, "test_mcc_se": 1.7917664057899205, "test_macro_f1": 45.88697651158561, "test_macro_f1_se": 3.488575618972497}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_em": 33.46243222308288, "test_f1": 37.24725709064046}, {"test_em": 34.8062015503876, "test_f1": 37.975286993210005}, {"test_em": 30.91190108191654, "test_f1": 34.80277692662431}, {"test_em": 31.931464174454828, "test_f1": 36.095190199426035}, {"test_em": 35.21235521235521, "test_f1": 39.56354855049162}, {"test_em": 27.833461835003856, "test_f1": 31.24300649488439}, {"test_em": 30.372057706909644, "test_f1": 33.83518109217739}, {"test_em": 26.687354538401863, "test_f1": 31.307133637455482}, {"test_em": 25.88235294117647, "test_f1": 29.809498872401807}, {"test_em": 34.47204968944099, "test_f1": 38.74371933098219}]}, "total": {"test_em": 31.15716309531299, "test_em_se": 2.128991606323737, "test_f1": 35.06225991882937, "test_f1_se": 2.12703751447296}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_em": 36.17350890782339, "test_f1": 40.69274483791973}, {"test_em": 31.472868217054263, "test_f1": 36.10246959582766}, {"test_em": 30.370942812983, "test_f1": 34.695204295472976}, {"test_em": 33.64485981308411, "test_f1": 37.786196926177695}, {"test_em": 31.969111969111967, "test_f1": 36.36828627275332}, {"test_em": 30.994602929838088, "test_f1": 34.64147529439905}, {"test_em": 32.95368261199696, "test_f1": 37.10509971173103}, {"test_em": 35.06594259115594, "test_f1": 38.98716957648779}, {"test_em": 35.372549019607845, "test_f1": 40.17466823429309}, {"test_em": 32.298136645962735, "test_f1": 36.78537035330152}]}, "total": {"test_em": 33.031620551861835, "test_em_se": 1.2257148029094023, "test_f1": 37.33386850983639, "test_f1_se": 1.2952422965816712}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_em": 37.8001549186677, "test_f1": 42.26966745139711}, {"test_em": 34.10852713178294, "test_f1": 37.5055533967753}, {"test_em": 38.25347758887172, "test_f1": 42.584631631095036}, {"test_em": 31.61993769470405, "test_f1": 36.552683703792106}, {"test_em": 34.20849420849421, "test_f1": 38.876184335936664}, {"test_em": 35.774865073245955, "test_f1": 40.51418152076939}, {"test_em": 34.77600607441154, "test_f1": 39.07484062770712}, {"test_em": 35.53141970519783, "test_f1": 39.40223772796097}, {"test_em": 39.05882352941177, "test_f1": 42.97109040548715}, {"test_em": 36.18012422360248, "test_f1": 40.2743730551151}]}, "total": {"test_em": 35.73118301483902, "test_em_se": 1.3816951560692436, "test_f1": 40.0025443856036, "test_f1_se": 1.3322417061966718}}, "num_model_parameters": 124056578, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.6199767589569092, "test_mcc": 0.5902124247157762, "test_macro_f1": 0.5419792365029549, "test_runtime": 14.2655, "test_samples_per_second": 143.563, "test_steps_per_second": 17.945}, {"test_loss": 0.6806046962738037, "test_mcc": 0.5385539797924371, "test_macro_f1": 0.5166426372306075, "test_runtime": 13.2866, "test_samples_per_second": 154.141, "test_steps_per_second": 19.268}, {"test_loss": 0.6381521224975586, "test_mcc": 0.5672636227406936, "test_macro_f1": 0.5428707331224726, "test_runtime": 13.5812, "test_samples_per_second": 150.797, "test_steps_per_second": 18.85}, {"test_loss": 0.6948767900466919, "test_mcc": 0.5317664352698772, "test_macro_f1": 0.5201255647882964, "test_runtime": 12.8, "test_samples_per_second": 159.999, "test_steps_per_second": 20.0}, {"test_loss": 0.6236840486526489, "test_mcc": 0.596633390481893, "test_macro_f1": 0.5625028398281078, "test_runtime": 12.6682, "test_samples_per_second": 161.664, "test_steps_per_second": 20.208}, {"test_loss": 0.6313248872756958, "test_mcc": 0.5560083011884882, "test_macro_f1": 0.5292040681846009, "test_runtime": 13.1827, "test_samples_per_second": 155.355, "test_steps_per_second": 19.419}, {"test_loss": 0.6447974443435669, "test_mcc": 0.5487722056878707, "test_macro_f1": 0.5230682250241204, "test_runtime": 12.5529, "test_samples_per_second": 163.15, "test_steps_per_second": 20.394}, {"test_loss": 0.6255884170532227, "test_mcc": 0.5935221132891756, "test_macro_f1": 0.5411906350655095, "test_runtime": 13.5612, "test_samples_per_second": 151.019, "test_steps_per_second": 18.877}, {"test_loss": 0.6595330238342285, "test_mcc": 0.5623126777801181, "test_macro_f1": 0.5356032221755035, "test_runtime": 13.4809, "test_samples_per_second": 151.918, "test_steps_per_second": 18.99}, {"test_loss": 0.6326617002487183, "test_mcc": 0.5717770781641035, "test_macro_f1": 0.5337140177453108, "test_runtime": 13.1208, "test_samples_per_second": 156.088, "test_steps_per_second": 19.511}]}, "total": {"test_mcc": 56.568222291104334, "test_mcc_se": 1.4090694114017646, "test_macro_f1": 53.46901179667485, "test_macro_f1_se": 0.8368400182275727}}, "num_model_parameters": 14245891, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 1.0303692817687988, "test_mcc": 0.192682140463764, "test_macro_f1": 0.386286365585011, "test_runtime": 5.5277, "test_samples_per_second": 370.496, "test_steps_per_second": 11.578}, {"test_loss": 1.0085622072219849, "test_mcc": 0.24589474552802135, "test_macro_f1": 0.4798114471174797, "test_runtime": 5.5043, "test_samples_per_second": 372.07, "test_steps_per_second": 11.627}, {"test_loss": 1.0580588579177856, "test_mcc": 0.20126054314561795, "test_macro_f1": 0.41068745847200194, "test_runtime": 5.4259, "test_samples_per_second": 377.448, "test_steps_per_second": 11.795}, {"test_loss": 1.0318455696105957, "test_mcc": 0.20441726496939353, "test_macro_f1": 0.42178499730602076, "test_runtime": 5.4521, "test_samples_per_second": 375.636, "test_steps_per_second": 11.739}, {"test_loss": 1.0230112075805664, "test_mcc": 0.21252019631089483, "test_macro_f1": 0.430135395738852, "test_runtime": 5.3469, "test_samples_per_second": 383.022, "test_steps_per_second": 11.969}, {"test_loss": 1.0685157775878906, "test_mcc": 0.14301815991682115, "test_macro_f1": 0.3631912627400306, "test_runtime": 5.3716, "test_samples_per_second": 381.263, "test_steps_per_second": 11.914}, {"test_loss": 1.014221429824829, "test_mcc": 0.21925714225964937, "test_macro_f1": 0.45119987633759395, "test_runtime": 5.4391, "test_samples_per_second": 376.529, "test_steps_per_second": 11.767}, {"test_loss": 1.0452854633331299, "test_mcc": 0.18004649972795547, "test_macro_f1": 0.42654135953519995, "test_runtime": 6.1714, "test_samples_per_second": 331.854, "test_steps_per_second": 10.37}, {"test_loss": 1.0327258110046387, "test_mcc": 0.19270368866889964, "test_macro_f1": 0.42626124674312443, "test_runtime": 5.7532, "test_samples_per_second": 355.976, "test_steps_per_second": 11.124}, {"test_loss": 1.0467429161071777, "test_mcc": 0.1874508541318134, "test_macro_f1": 0.41322713372042724, "test_runtime": 5.8131, "test_samples_per_second": 352.31, "test_steps_per_second": 11.01}]}, "total": {"test_mcc": 19.792512351228307, "test_mcc_se": 1.6684080536585326, "test_macro_f1": 42.09126543295742, "test_macro_f1_se": 1.9845481621723382}}, "num_model_parameters": 14245891, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.9966262578964233, "test_mcc": 0.1916971368008239, "test_macro_f1": 0.3772744486823911, "test_runtime": 4.6185, "test_samples_per_second": 443.436, "test_steps_per_second": 13.857}, {"test_loss": 0.9305745363235474, "test_mcc": 0.23083978411889577, "test_macro_f1": 0.3962227631637562, "test_runtime": 4.4963, "test_samples_per_second": 455.483, "test_steps_per_second": 14.234}, {"test_loss": 0.9764713048934937, "test_mcc": 0.13660058731193586, "test_macro_f1": 0.33611265526681794, "test_runtime": 4.4816, "test_samples_per_second": 456.982, "test_steps_per_second": 14.281}, {"test_loss": 0.9834297299385071, "test_mcc": 0.19676392832587797, "test_macro_f1": 0.3780597151211884, "test_runtime": 4.496, "test_samples_per_second": 455.518, "test_steps_per_second": 14.235}, {"test_loss": 0.9988855719566345, "test_mcc": 0.0851844297402566, "test_macro_f1": 0.3063734917862103, "test_runtime": 4.3237, "test_samples_per_second": 473.673, "test_steps_per_second": 14.802}, {"test_loss": 0.9549881219863892, "test_mcc": 0.20281240823616964, "test_macro_f1": 0.38436325074713196, "test_runtime": 4.4688, "test_samples_per_second": 458.288, "test_steps_per_second": 14.322}, {"test_loss": 0.9371893405914307, "test_mcc": 0.20932794392749954, "test_macro_f1": 0.38716178468915824, "test_runtime": 4.4611, "test_samples_per_second": 459.081, "test_steps_per_second": 14.346}, {"test_loss": 0.9477598667144775, "test_mcc": 0.2791671052323654, "test_macro_f1": 0.4211674466556185, "test_runtime": 4.4067, "test_samples_per_second": 464.75, "test_steps_per_second": 14.523}, {"test_loss": 0.9460805654525757, "test_mcc": 0.25747695774847157, "test_macro_f1": 0.4071957671957673, "test_runtime": 4.5115, "test_samples_per_second": 453.946, "test_steps_per_second": 14.186}, {"test_loss": 0.9844317436218262, "test_mcc": 0.09468974487008414, "test_macro_f1": 0.2819395349392956, "test_runtime": 4.7195, "test_samples_per_second": 433.948, "test_steps_per_second": 13.561}]}, "total": {"test_mcc": 18.845600263123803, "test_mcc_se": 4.009155135613175, "test_macro_f1": 36.75870858247335, "test_macro_f1_se": 2.7872980359760127}}, "num_model_parameters": 14245891, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.11466360092163086, "test_micro_f1": 0.35587529976019183, "test_micro_f1_no_misc": 0.3787646758550281, "test_runtime": 7.3157, "test_samples_per_second": 279.944, "test_steps_per_second": 8.748}, {"test_loss": 0.10475756973028183, "test_micro_f1": 0.3934267762203963, "test_micro_f1_no_misc": 0.4153061224489796, "test_runtime": 6.3005, "test_samples_per_second": 325.052, "test_steps_per_second": 10.158}, {"test_loss": 0.11766783893108368, "test_micro_f1": 0.269833729216152, "test_micro_f1_no_misc": 0.282727725236436, "test_runtime": 6.2814, "test_samples_per_second": 326.042, "test_steps_per_second": 10.189}, {"test_loss": 0.10068196803331375, "test_micro_f1": 0.510406342913776, "test_micro_f1_no_misc": 0.5372978612415233, "test_runtime": 7.2991, "test_samples_per_second": 280.584, "test_steps_per_second": 8.768}, {"test_loss": 0.1145138144493103, "test_micro_f1": 0.3710198431010614, "test_micro_f1_no_misc": 0.3902912621359223, "test_runtime": 7.4689, "test_samples_per_second": 274.205, "test_steps_per_second": 8.569}, {"test_loss": 0.10122726112604141, "test_micro_f1": 0.5578102878716376, "test_micro_f1_no_misc": 0.6044125192406363, "test_runtime": 5.5946, "test_samples_per_second": 366.07, "test_steps_per_second": 11.44}, {"test_loss": 0.09954355657100677, "test_micro_f1": 0.5876140182429188, "test_micro_f1_no_misc": 0.6257731958762887, "test_runtime": 6.5466, "test_samples_per_second": 312.833, "test_steps_per_second": 9.776}, {"test_loss": 0.12605679035186768, "test_micro_f1": 0.23995535714285712, "test_micro_f1_no_misc": 0.25413711583924353, "test_runtime": 6.8148, "test_samples_per_second": 300.522, "test_steps_per_second": 9.391}, {"test_loss": 0.0939115583896637, "test_micro_f1": 0.5536460752438458, "test_micro_f1_no_misc": 0.5862580326248147, "test_runtime": 6.4264, "test_samples_per_second": 318.685, "test_steps_per_second": 9.959}, {"test_loss": 0.09158019721508026, "test_micro_f1": 0.5947743467933492, "test_micro_f1_no_misc": 0.644456012493493, "test_runtime": 7.1023, "test_samples_per_second": 288.356, "test_steps_per_second": 9.011}]}, "total": {"test_micro_f1": 44.34362076506185, "test_micro_f1_se": 8.27330991250832, "test_micro_f1_no_misc": 47.19424522992366, "test_micro_f1_no_misc_se": 9.00819905406661}}, "num_model_parameters": 13659913, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.12307677417993546, "test_micro_f1": 0.6543400102722137, "test_micro_f1_no_misc": 0.6882982395581636, "test_runtime": 10.6501, "test_samples_per_second": 192.299, "test_steps_per_second": 6.009}, {"test_loss": 0.12118765711784363, "test_micro_f1": 0.5715064015254699, "test_micro_f1_no_misc": 0.6043478260869566, "test_runtime": 8.7345, "test_samples_per_second": 234.472, "test_steps_per_second": 7.327}, {"test_loss": 0.12623199820518494, "test_micro_f1": 0.6172122492080253, "test_micro_f1_no_misc": 0.6513464991023338, "test_runtime": 10.1912, "test_samples_per_second": 200.958, "test_steps_per_second": 6.28}, {"test_loss": 0.11893312633037567, "test_micro_f1": 0.646033810143043, "test_micro_f1_no_misc": 0.6701101928374655, "test_runtime": 9.8623, "test_samples_per_second": 207.659, "test_steps_per_second": 6.489}, {"test_loss": 0.12902921438217163, "test_micro_f1": 0.5675006873797085, "test_micro_f1_no_misc": 0.6056547619047619, "test_runtime": 11.1195, "test_samples_per_second": 184.181, "test_steps_per_second": 5.756}, {"test_loss": 0.1298663169145584, "test_micro_f1": 0.6105901820187535, "test_micro_f1_no_misc": 0.6362297496318114, "test_runtime": 10.183, "test_samples_per_second": 201.119, "test_steps_per_second": 6.285}, {"test_loss": 0.11998622119426727, "test_micro_f1": 0.615056059797117, "test_micro_f1_no_misc": 0.6423146473779386, "test_runtime": 11.1213, "test_samples_per_second": 184.151, "test_steps_per_second": 5.755}, {"test_loss": 0.11144795268774033, "test_micro_f1": 0.6498096791734639, "test_micro_f1_no_misc": 0.6780152118797538, "test_runtime": 9.9539, "test_samples_per_second": 205.749, "test_steps_per_second": 6.43}, {"test_loss": 0.12237060070037842, "test_micro_f1": 0.6382863340563991, "test_micro_f1_no_misc": 0.6688358640636298, "test_runtime": 10.3576, "test_samples_per_second": 197.73, "test_steps_per_second": 6.179}, {"test_loss": 0.11416240781545639, "test_micro_f1": 0.6781578238621061, "test_micro_f1_no_misc": 0.7020437432771603, "test_runtime": 8.8713, "test_samples_per_second": 230.857, "test_steps_per_second": 7.214}]}, "total": {"test_micro_f1": 62.484932374363, "test_micro_f1_se": 2.2112936350834067, "test_micro_f1_no_misc": 65.47196735719976, "test_micro_f1_no_misc_se": 2.0450203243414995}}, "num_model_parameters": 13659913, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.09237172454595566, "test_micro_f1": 0.6374031722611583, "test_micro_f1_no_misc": 0.6806324110671937, "test_runtime": 8.3166, "test_samples_per_second": 246.253, "test_steps_per_second": 7.695}, {"test_loss": 0.09781236946582794, "test_micro_f1": 0.5982142857142858, "test_micro_f1_no_misc": 0.6317034700315458, "test_runtime": 8.3938, "test_samples_per_second": 243.99, "test_steps_per_second": 7.625}, {"test_loss": 0.09275639057159424, "test_micro_f1": 0.6558284330681424, "test_micro_f1_no_misc": 0.7072072072072072, "test_runtime": 7.4933, "test_samples_per_second": 273.311, "test_steps_per_second": 8.541}, {"test_loss": 0.10173828899860382, "test_micro_f1": 0.6140472878998608, "test_micro_f1_no_misc": 0.6528343831048536, "test_runtime": 7.813, "test_samples_per_second": 262.128, "test_steps_per_second": 8.192}, {"test_loss": 0.10344098508358002, "test_micro_f1": 0.6119704102219234, "test_micro_f1_no_misc": 0.6474564212024191, "test_runtime": 8.4663, "test_samples_per_second": 241.901, "test_steps_per_second": 7.559}, {"test_loss": 0.09503884613513947, "test_micro_f1": 0.6392318244170097, "test_micro_f1_no_misc": 0.6781398755034785, "test_runtime": 8.3133, "test_samples_per_second": 246.352, "test_steps_per_second": 7.698}, {"test_loss": 0.10072723031044006, "test_micro_f1": 0.6329537843268586, "test_micro_f1_no_misc": 0.6769340974212034, "test_runtime": 7.7831, "test_samples_per_second": 263.135, "test_steps_per_second": 8.223}, {"test_loss": 0.09665125608444214, "test_micro_f1": 0.6421703296703296, "test_micro_f1_no_misc": 0.6724511930585683, "test_runtime": 7.601, "test_samples_per_second": 269.438, "test_steps_per_second": 8.42}, {"test_loss": 0.09390632808208466, "test_micro_f1": 0.6365932876217972, "test_micro_f1_no_misc": 0.6787225856098499, "test_runtime": 7.2235, "test_samples_per_second": 283.518, "test_steps_per_second": 8.86}, {"test_loss": 0.1032976359128952, "test_micro_f1": 0.630360789652825, "test_micro_f1_no_misc": 0.6707848837209303, "test_runtime": 7.5123, "test_samples_per_second": 272.618, "test_steps_per_second": 8.519}]}, "total": {"test_micro_f1": 62.98773604854191, "test_micro_f1_se": 1.052925514213234, "test_micro_f1_no_misc": 66.9686652792725, "test_micro_f1_no_misc_se": 1.3006068800106059}}, "num_model_parameters": 13659913, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.10652995109558105, "test_micro_f1": 0.6399241945672773, "test_micro_f1_no_misc": 0.6764607679465776, "test_runtime": 7.3395, "test_samples_per_second": 279.039, "test_steps_per_second": 8.72}, {"test_loss": 0.11479783058166504, "test_micro_f1": 0.6194744976816073, "test_micro_f1_no_misc": 0.6589937520552449, "test_runtime": 7.4071, "test_samples_per_second": 276.49, "test_steps_per_second": 8.64}, {"test_loss": 0.11576594412326813, "test_micro_f1": 0.5872524752475249, "test_micro_f1_no_misc": 0.6324558480506499, "test_runtime": 6.982, "test_samples_per_second": 293.327, "test_steps_per_second": 9.166}, {"test_loss": 0.1235429123044014, "test_micro_f1": 0.613664596273292, "test_micro_f1_no_misc": 0.6560319042871386, "test_runtime": 7.2353, "test_samples_per_second": 283.058, "test_steps_per_second": 8.846}, {"test_loss": 0.1252823770046234, "test_micro_f1": 0.5847533632286995, "test_micro_f1_no_misc": 0.6317829457364342, "test_runtime": 6.7188, "test_samples_per_second": 304.818, "test_steps_per_second": 9.526}, {"test_loss": 0.12768277525901794, "test_micro_f1": 0.5053763440860214, "test_micro_f1_no_misc": 0.5390251672507168, "test_runtime": 7.092, "test_samples_per_second": 288.775, "test_steps_per_second": 9.024}, {"test_loss": 0.10711142420768738, "test_micro_f1": 0.617775015537601, "test_micro_f1_no_misc": 0.6587143803843605, "test_runtime": 7.4977, "test_samples_per_second": 273.152, "test_steps_per_second": 8.536}, {"test_loss": 0.11538384854793549, "test_micro_f1": 0.605125038592158, "test_micro_f1_no_misc": 0.6413612565445026, "test_runtime": 7.446, "test_samples_per_second": 275.048, "test_steps_per_second": 8.595}, {"test_loss": 0.12627989053726196, "test_micro_f1": 0.5743200506008854, "test_micro_f1_no_misc": 0.6130992572586091, "test_runtime": 6.7683, "test_samples_per_second": 302.587, "test_steps_per_second": 9.456}, {"test_loss": 0.11296163499355316, "test_micro_f1": 0.6471329552614997, "test_micro_f1_no_misc": 0.6823920265780731, "test_runtime": 7.0962, "test_samples_per_second": 288.607, "test_steps_per_second": 9.019}]}, "total": {"test_micro_f1": 59.947985310765674, "test_micro_f1_se": 2.5073875418845604, "test_micro_f1_no_misc": 63.90317306092308, "test_micro_f1_no_misc_se": 2.5413711592506716}}, "num_model_parameters": 13659913, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.6652258038520813, "test_mcc": 0.22642426691660517, "test_macro_f1": 0.5965025510724016, "test_runtime": 2.9475, "test_samples_per_second": 694.827, "test_steps_per_second": 21.713}, {"test_loss": 0.688474714756012, "test_mcc": 0.10372803066696197, "test_macro_f1": 0.5361084782737775, "test_runtime": 2.9035, "test_samples_per_second": 705.366, "test_steps_per_second": 22.043}, {"test_loss": 0.6491997241973877, "test_mcc": 0.2540222797627872, "test_macro_f1": 0.6052305314510167, "test_runtime": 3.0056, "test_samples_per_second": 681.404, "test_steps_per_second": 21.294}, {"test_loss": 0.6494779586791992, "test_mcc": 0.28421534887068045, "test_macro_f1": 0.6272341918148472, "test_runtime": 3.1645, "test_samples_per_second": 647.176, "test_steps_per_second": 20.224}, {"test_loss": 0.672690212726593, "test_mcc": 0.17754812876340423, "test_macro_f1": 0.5887538431746269, "test_runtime": 3.2669, "test_samples_per_second": 626.886, "test_steps_per_second": 19.59}, {"test_loss": 0.6778154373168945, "test_mcc": 0.1761596960097804, "test_macro_f1": 0.5773970382235645, "test_runtime": 2.8664, "test_samples_per_second": 714.487, "test_steps_per_second": 22.328}, {"test_loss": 0.6615709066390991, "test_mcc": 0.24073226917373058, "test_macro_f1": 0.592395225371805, "test_runtime": 3.1784, "test_samples_per_second": 644.35, "test_steps_per_second": 20.136}, {"test_loss": 0.6518712639808655, "test_mcc": 0.2568206883893244, "test_macro_f1": 0.6156842056263286, "test_runtime": 3.0025, "test_samples_per_second": 682.101, "test_steps_per_second": 21.316}, {"test_loss": 0.6849368810653687, "test_mcc": 0.10144013972137475, "test_macro_f1": 0.5463626207689443, "test_runtime": 3.1226, "test_samples_per_second": 655.864, "test_steps_per_second": 20.496}, {"test_loss": 0.6545029878616333, "test_mcc": 0.2708228083671001, "test_macro_f1": 0.6188773077434326, "test_runtime": 3.2237, "test_samples_per_second": 635.301, "test_steps_per_second": 19.853}]}, "total": {"test_mcc": 20.919136566417492, "test_mcc_se": 4.1228607568327735, "test_macro_f1": 59.04545993520745, "test_macro_f1_se": 1.8624916144386388}}, "num_model_parameters": 14245122, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.6901829242706299, "test_mcc": 0.09792559683929443, "test_macro_f1": 0.5404109178608243, "test_runtime": 4.5452, "test_samples_per_second": 450.589, "test_steps_per_second": 14.081}, {"test_loss": 0.6915379166603088, "test_mcc": 0.03776372569345749, "test_macro_f1": 0.5118676288047855, "test_runtime": 4.8057, "test_samples_per_second": 426.159, "test_steps_per_second": 13.317}, {"test_loss": 0.6923027038574219, "test_mcc": 0.04485754193168337, "test_macro_f1": 0.5148161608109323, "test_runtime": 4.9795, "test_samples_per_second": 411.288, "test_steps_per_second": 12.853}, {"test_loss": 0.6904375553131104, "test_mcc": 0.057538517972603564, "test_macro_f1": 0.5287590462540145, "test_runtime": 5.3107, "test_samples_per_second": 385.634, "test_steps_per_second": 12.051}, {"test_loss": 0.6882501840591431, "test_mcc": 0.08939998472259071, "test_macro_f1": 0.544150909546788, "test_runtime": 4.8369, "test_samples_per_second": 423.407, "test_steps_per_second": 13.231}, {"test_loss": 0.6905968189239502, "test_mcc": 0.023277234830067786, "test_macro_f1": 0.46068538847510887, "test_runtime": 4.6717, "test_samples_per_second": 438.382, "test_steps_per_second": 13.699}, {"test_loss": 0.687545120716095, "test_mcc": 0.10011332509753343, "test_macro_f1": 0.5421523280912734, "test_runtime": 4.7162, "test_samples_per_second": 434.247, "test_steps_per_second": 13.57}, {"test_loss": 0.6918947696685791, "test_mcc": 0.039941804278986304, "test_macro_f1": 0.5193618819282729, "test_runtime": 4.7299, "test_samples_per_second": 432.991, "test_steps_per_second": 13.531}, {"test_loss": 0.6917879581451416, "test_mcc": 0.056030933544040575, "test_macro_f1": 0.5185464796610297, "test_runtime": 4.8869, "test_samples_per_second": 419.078, "test_steps_per_second": 13.096}, {"test_loss": 0.6907587051391602, "test_mcc": 0.06818855140724123, "test_macro_f1": 0.522967109648798, "test_runtime": 4.7779, "test_samples_per_second": 428.643, "test_steps_per_second": 13.395}]}, "total": {"test_mcc": 6.150372163174989, "test_mcc_se": 1.65960561576645, "test_macro_f1": 52.03717851081828, "test_macro_f1_se": 1.4881795743307569}}, "num_model_parameters": 14245122, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.6848555207252502, "test_mcc": 0.12044538032891361, "test_macro_f1": 0.5594052906706531, "test_runtime": 4.1016, "test_samples_per_second": 499.323, "test_steps_per_second": 15.604}, {"test_loss": 0.6916953325271606, "test_mcc": 0.07164478330034788, "test_macro_f1": 0.5357072970509205, "test_runtime": 4.4916, "test_samples_per_second": 455.967, "test_steps_per_second": 14.249}, {"test_loss": 0.6867159008979797, "test_mcc": 0.08554944150365124, "test_macro_f1": 0.5399744537404312, "test_runtime": 4.0451, "test_samples_per_second": 506.287, "test_steps_per_second": 15.821}, {"test_loss": 0.6921482086181641, "test_mcc": 0.04765052710816912, "test_macro_f1": 0.4802856043921926, "test_runtime": 4.3592, "test_samples_per_second": 469.811, "test_steps_per_second": 14.682}, {"test_loss": 0.6935638189315796, "test_mcc": 0.0456407109304815, "test_macro_f1": 0.5165449584841876, "test_runtime": 4.4221, "test_samples_per_second": 463.129, "test_steps_per_second": 14.473}, {"test_loss": 0.6904356479644775, "test_mcc": 0.07353646785086686, "test_macro_f1": 0.49869536557694905, "test_runtime": 4.3636, "test_samples_per_second": 469.342, "test_steps_per_second": 14.667}, {"test_loss": 0.6895850896835327, "test_mcc": 0.06054569561309782, "test_macro_f1": 0.5110423834126498, "test_runtime": 4.1092, "test_samples_per_second": 498.397, "test_steps_per_second": 15.575}, {"test_loss": 0.6971345543861389, "test_mcc": -0.029692539947834558, "test_macro_f1": 0.48112839066616125, "test_runtime": 4.1492, "test_samples_per_second": 493.594, "test_steps_per_second": 15.425}, {"test_loss": 0.6898684501647949, "test_mcc": 0.05320180561807422, "test_macro_f1": 0.523915482906306, "test_runtime": 4.3233, "test_samples_per_second": 473.717, "test_steps_per_second": 14.804}, {"test_loss": 0.6899691820144653, "test_mcc": 0.054529940849770024, "test_macro_f1": 0.5119600287543, "test_runtime": 4.1068, "test_samples_per_second": 498.681, "test_steps_per_second": 15.584}]}, "total": {"test_mcc": 5.830522131555377, "test_mcc_se": 2.362540176612366, "test_macro_f1": 51.58659255654751, "test_macro_f1_se": 1.5655263023716708}}, "num_model_parameters": 14245122, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.6958918571472168, "test_mcc": -0.019411117005825144, "test_macro_f1": 0.48702968412843833, "test_runtime": 4.0812, "test_samples_per_second": 501.818, "test_steps_per_second": 15.682}, {"test_loss": 0.6901781558990479, "test_mcc": 0.08532536685335396, "test_macro_f1": 0.5418322617653386, "test_runtime": 4.5275, "test_samples_per_second": 452.342, "test_steps_per_second": 14.136}, {"test_loss": 0.6889021992683411, "test_mcc": 0.05687399429008295, "test_macro_f1": 0.5278876304749359, "test_runtime": 4.4364, "test_samples_per_second": 461.64, "test_steps_per_second": 14.426}, {"test_loss": 0.6931405663490295, "test_mcc": 0.013392617321462323, "test_macro_f1": 0.5064399518007765, "test_runtime": 4.2847, "test_samples_per_second": 477.981, "test_steps_per_second": 14.937}, {"test_loss": 0.6937259435653687, "test_mcc": -0.009937710906628662, "test_macro_f1": 0.48877282003520994, "test_runtime": 4.3093, "test_samples_per_second": 475.248, "test_steps_per_second": 14.851}, {"test_loss": 0.6909777522087097, "test_mcc": 0.08031606767096021, "test_macro_f1": 0.5400640417519575, "test_runtime": 4.2045, "test_samples_per_second": 487.095, "test_steps_per_second": 15.222}, {"test_loss": 0.6908342242240906, "test_mcc": 0.05365274479030419, "test_macro_f1": 0.5260616471037312, "test_runtime": 4.2956, "test_samples_per_second": 476.764, "test_steps_per_second": 14.899}, {"test_loss": 0.6927953362464905, "test_mcc": 0.023052952366075335, "test_macro_f1": 0.5094378621356429, "test_runtime": 4.0183, "test_samples_per_second": 509.663, "test_steps_per_second": 15.927}, {"test_loss": 0.6934043169021606, "test_mcc": 0.04572224213872487, "test_macro_f1": 0.5086675079166162, "test_runtime": 3.9993, "test_samples_per_second": 512.086, "test_steps_per_second": 16.003}, {"test_loss": 0.6901299953460693, "test_mcc": 0.0726569241444726, "test_macro_f1": 0.5300820915177106, "test_runtime": 4.2456, "test_samples_per_second": 482.38, "test_steps_per_second": 15.074}]}, "total": {"test_mcc": 4.016440816629826, "test_mcc_se": 2.288389212224477, "test_macro_f1": 51.66275498630357, "test_macro_f1_se": 1.2138862326054902}}, "num_model_parameters": 14245122, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_em": 17.660728117738188, "test_f1": 22.15589683825963}, {"test_em": 25.58139534883721, "test_f1": 30.523778672907483}, {"test_em": 21.097372488408038, "test_f1": 26.856178106243917}, {"test_em": 33.021806853582554, "test_f1": 39.034890517938614}, {"test_em": 26.409266409266408, "test_f1": 32.699507481904675}, {"test_em": 23.053199691595992, "test_f1": 28.703312333176207}, {"test_em": 25.89217919514047, "test_f1": 32.11781953483119}, {"test_em": 24.980605120248253, "test_f1": 30.560034676919173}, {"test_em": 20.07843137254902, "test_f1": 24.797190342118412}, {"test_em": 23.059006211180126, "test_f1": 27.51828470249165}]}, "total": {"test_em": 24.083399080854626, "test_em_se": 2.6128675004915096, "test_f1": 29.4966893206791, "test_f1_se": 2.9055314983358054}}, "num_model_parameters": 13654530, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_em": 9.450038729666925, "test_f1": 13.564912494666718}, {"test_em": 27.906976744186046, "test_f1": 34.25679674482687}, {"test_em": 24.18856259659969, "test_f1": 31.495356976489255}, {"test_em": 28.193146417445483, "test_f1": 35.29302256102336}, {"test_em": 27.335907335907336, "test_f1": 34.34771295142814}, {"test_em": 26.522744795682343, "test_f1": 32.9864387079418}, {"test_em": 26.347760060744115, "test_f1": 33.08218726222987}, {"test_em": 26.377036462373933, "test_f1": 32.71856025551862}, {"test_em": 27.45098039215686, "test_f1": 33.45561263304846}, {"test_em": 26.86335403726708, "test_f1": 32.96221669659261}]}, "total": {"test_em": 25.06365075720298, "test_em_se": 3.469644166623252, "test_f1": 31.41628172837657, "test_f1_se": 3.9409265930984896}}, "num_model_parameters": 13654530, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_em": 18.82261812548412, "test_f1": 24.518320417616113}, {"test_em": 26.976744186046513, "test_f1": 34.308323865291776}, {"test_em": 30.293663060278206, "test_f1": 37.08993744569229}, {"test_em": 27.9595015576324, "test_f1": 35.43509581528215}, {"test_em": 22.7027027027027, "test_f1": 29.3634561368019}, {"test_em": 32.76792598303778, "test_f1": 38.929935501501}, {"test_em": 31.43507972665148, "test_f1": 38.270335787987634}, {"test_em": 32.660977501939485, "test_f1": 39.20892862900957}, {"test_em": 29.80392156862745, "test_f1": 35.70223895408588}, {"test_em": 32.99689440993789, "test_f1": 38.97978527038626}]}, "total": {"test_em": 28.642002882233804, "test_em_se": 2.9141471140018407, "test_f1": 35.18063578236546, "test_f1_se": 2.969124374442927}}, "num_model_parameters": 13654530, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.6929299831390381, "test_mcc": 0.5660148195104591, "test_macro_f1": 0.5321191254530523, "test_runtime": 15.473, "test_samples_per_second": 132.359, "test_steps_per_second": 16.545}, {"test_loss": 0.9210000038146973, "test_mcc": 0.301126720167287, "test_macro_f1": 0.35695933783596673, "test_runtime": 14.6744, "test_samples_per_second": 139.563, "test_steps_per_second": 17.445}, {"test_loss": 0.6486464738845825, "test_mcc": 0.5805137247941776, "test_macro_f1": 0.5379212103350034, "test_runtime": 20.2502, "test_samples_per_second": 101.135, "test_steps_per_second": 50.567}, {"test_loss": 0.7033949494361877, "test_mcc": 0.5075427561679252, "test_macro_f1": 0.5026092663835325, "test_runtime": 19.9165, "test_samples_per_second": 102.829, "test_steps_per_second": 51.415}, {"test_loss": 0.6194477081298828, "test_mcc": 0.6091982540128534, "test_macro_f1": 0.5488596364755889, "test_runtime": 20.1402, "test_samples_per_second": 101.687, "test_steps_per_second": 50.844}, {"test_loss": 0.7135931849479675, "test_mcc": 0.5423659970237805, "test_macro_f1": 0.517435978823942, "test_runtime": 20.3845, "test_samples_per_second": 100.469, "test_steps_per_second": 50.234}, {"test_loss": 0.7093366384506226, "test_mcc": 0.536590139609586, "test_macro_f1": 0.5143426862270332, "test_runtime": 19.3096, "test_samples_per_second": 106.061, "test_steps_per_second": 53.031}, {"test_loss": 0.7892900705337524, "test_mcc": 0.4563592335616216, "test_macro_f1": 0.489288648542594, "test_runtime": 19.8077, "test_samples_per_second": 103.394, "test_steps_per_second": 51.697}, {"test_loss": 0.7434335350990295, "test_mcc": 0.49986874772456397, "test_macro_f1": 0.4993177683444512, "test_runtime": 19.4724, "test_samples_per_second": 105.174, "test_steps_per_second": 52.587}, {"test_loss": 0.7029334306716919, "test_mcc": 0.5110557766736651, "test_macro_f1": 0.5099457206512797, "test_runtime": 20.3244, "test_samples_per_second": 100.766, "test_steps_per_second": 50.383}]}, "total": {"test_mcc": 51.1063616924592, "test_mcc_se": 5.320099122225756, "test_macro_f1": 50.08799379072444, "test_macro_f1_se": 3.3339503812084574}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 1.0478177070617676, "test_mcc": 0.15659033546197187, "test_macro_f1": 0.38184106722698047, "test_runtime": 4.6022, "test_samples_per_second": 445.003, "test_steps_per_second": 13.906}, {"test_loss": 1.0560429096221924, "test_mcc": 0.2154589708900881, "test_macro_f1": 0.43813298422447594, "test_runtime": 4.4676, "test_samples_per_second": 458.414, "test_steps_per_second": 14.325}, {"test_loss": 1.043399691581726, "test_mcc": 0.1935286876847674, "test_macro_f1": 0.387147116449442, "test_runtime": 4.6639, "test_samples_per_second": 439.116, "test_steps_per_second": 13.722}, {"test_loss": 1.0293734073638916, "test_mcc": 0.19009180595297528, "test_macro_f1": 0.3644560742821083, "test_runtime": 4.3526, "test_samples_per_second": 470.522, "test_steps_per_second": 14.704}, {"test_loss": 1.0820214748382568, "test_mcc": 0.01911256650499655, "test_macro_f1": 0.18880958780946733, "test_runtime": 4.2527, "test_samples_per_second": 481.581, "test_steps_per_second": 15.049}, {"test_loss": 1.0557715892791748, "test_mcc": 0.1813420376943779, "test_macro_f1": 0.3762220208568377, "test_runtime": 4.376, "test_samples_per_second": 468.008, "test_steps_per_second": 14.625}, {"test_loss": 1.049741268157959, "test_mcc": 0.22530142158465774, "test_macro_f1": 0.43152187301384054, "test_runtime": 4.5581, "test_samples_per_second": 449.314, "test_steps_per_second": 14.041}, {"test_loss": 1.060864806175232, "test_mcc": 0.23827866396963035, "test_macro_f1": 0.4603571090360315, "test_runtime": 4.3891, "test_samples_per_second": 466.61, "test_steps_per_second": 14.582}, {"test_loss": 1.106931209564209, "test_mcc": 0.14695420923134359, "test_macro_f1": 0.298053424268258, "test_runtime": 4.567, "test_samples_per_second": 448.433, "test_steps_per_second": 14.014}, {"test_loss": 1.0471625328063965, "test_mcc": 0.17057615066562873, "test_macro_f1": 0.3563817957059879, "test_runtime": 4.4559, "test_samples_per_second": 459.62, "test_steps_per_second": 14.363}]}, "total": {"test_mcc": 17.372348496404374, "test_mcc_se": 3.8214301925342573, "test_macro_f1": 36.8292305287343, "test_macro_f1_se": 4.85658765171308}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.9952722787857056, "test_mcc": 0.18660783772989692, "test_macro_f1": 0.36565987102851816, "test_runtime": 3.7072, "test_samples_per_second": 552.432, "test_steps_per_second": 17.264}, {"test_loss": 0.9829466938972473, "test_mcc": 0.12928552097892368, "test_macro_f1": 0.3552147489884581, "test_runtime": 3.7984, "test_samples_per_second": 539.174, "test_steps_per_second": 16.849}, {"test_loss": 0.9753366708755493, "test_mcc": 0.15493930392253813, "test_macro_f1": 0.32586387619022456, "test_runtime": 3.5938, "test_samples_per_second": 569.871, "test_steps_per_second": 17.808}, {"test_loss": 0.9913307428359985, "test_mcc": 0.049802312641936894, "test_macro_f1": 0.22522774616795693, "test_runtime": 3.9443, "test_samples_per_second": 519.23, "test_steps_per_second": 16.226}, {"test_loss": 1.0034070014953613, "test_mcc": 0.14207530187794987, "test_macro_f1": 0.3442706087270347, "test_runtime": 3.6821, "test_samples_per_second": 556.207, "test_steps_per_second": 17.381}, {"test_loss": 0.9827065467834473, "test_mcc": 0.08042583097059715, "test_macro_f1": 0.3020067804818985, "test_runtime": 3.7262, "test_samples_per_second": 549.623, "test_steps_per_second": 17.176}, {"test_loss": 0.9688370227813721, "test_mcc": 0.1556442481680683, "test_macro_f1": 0.3580373199941902, "test_runtime": 3.6095, "test_samples_per_second": 567.39, "test_steps_per_second": 17.731}, {"test_loss": 1.0028889179229736, "test_mcc": 0.05240190007944387, "test_macro_f1": 0.2244457654104698, "test_runtime": 3.6984, "test_samples_per_second": 553.757, "test_steps_per_second": 17.305}, {"test_loss": 0.9852980971336365, "test_mcc": 0.16027942367972295, "test_macro_f1": 0.36681244588083683, "test_runtime": 3.7243, "test_samples_per_second": 549.902, "test_steps_per_second": 17.184}, {"test_loss": 0.9937175512313843, "test_mcc": 0.14864127737785057, "test_macro_f1": 0.3596545661392077, "test_runtime": 3.8199, "test_samples_per_second": 536.146, "test_steps_per_second": 16.755}]}, "total": {"test_mcc": 12.601029574269281, "test_mcc_se": 2.9686263752884807, "test_macro_f1": 32.27193729008796, "test_macro_f1_se": 3.427433940304842}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.2087778002023697, "test_micro_f1": 0.09523809523809523, "test_micro_f1_no_misc": 0.10615711252653928, "test_runtime": 7.5026, "test_samples_per_second": 272.973, "test_steps_per_second": 8.53}, {"test_loss": 0.22516348958015442, "test_micro_f1": 0.0, "test_micro_f1_no_misc": 0.0, "test_runtime": 7.1871, "test_samples_per_second": 284.956, "test_steps_per_second": 8.905}, {"test_loss": 0.20706984400749207, "test_micro_f1": 0.11948051948051948, "test_micro_f1_no_misc": 0.1236111111111111, "test_runtime": 6.672, "test_samples_per_second": 306.956, "test_steps_per_second": 9.592}, {"test_loss": 0.20405924320220947, "test_micro_f1": 0.15773809523809526, "test_micro_f1_no_misc": 0.16329830234438159, "test_runtime": 7.442, "test_samples_per_second": 275.196, "test_steps_per_second": 8.6}, {"test_loss": 0.22130624949932098, "test_micro_f1": 0.12302284710017575, "test_micro_f1_no_misc": 0.12931575643440052, "test_runtime": 7.4269, "test_samples_per_second": 275.755, "test_steps_per_second": 8.617}, {"test_loss": 0.2216109335422516, "test_micro_f1": 0.14461315979754155, "test_micro_f1_no_misc": 0.14832925835370825, "test_runtime": 6.0415, "test_samples_per_second": 338.986, "test_steps_per_second": 10.593}, {"test_loss": 0.23400680720806122, "test_micro_f1": 0.13289401427786932, "test_micro_f1_no_misc": 0.1387213510253317, "test_runtime": 6.5942, "test_samples_per_second": 310.577, "test_steps_per_second": 9.706}, {"test_loss": 0.201382577419281, "test_micro_f1": 0.10477657935285054, "test_micro_f1_no_misc": 0.11323896752706078, "test_runtime": 7.3744, "test_samples_per_second": 277.717, "test_steps_per_second": 8.679}, {"test_loss": 0.2072872668504715, "test_micro_f1": 0.08997632202052092, "test_micro_f1_no_misc": 0.0920138888888889, "test_runtime": 7.2006, "test_samples_per_second": 284.421, "test_steps_per_second": 8.888}, {"test_loss": 0.20594775676727295, "test_micro_f1": 0.1629735525375268, "test_micro_f1_no_misc": 0.1763779527559055, "test_runtime": 7.2013, "test_samples_per_second": 284.393, "test_steps_per_second": 8.887}]}, "total": {"test_micro_f1": 11.307131850431947, "test_micro_f1_se": 2.9011693293860574, "test_micro_f1_no_misc": 11.910637009673279, "test_micro_f1_no_misc_se": 3.0447471040747076}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.3183855414390564, "test_micro_f1": 0.12903225806451613, "test_micro_f1_no_misc": 0.07889793362554791, "test_runtime": 8.9397, "test_samples_per_second": 229.09, "test_steps_per_second": 7.159}, {"test_loss": 0.286021888256073, "test_micro_f1": 0.19515570934256057, "test_micro_f1_no_misc": 0.16696914700544466, "test_runtime": 6.7044, "test_samples_per_second": 305.473, "test_steps_per_second": 9.546}, {"test_loss": 0.30111563205718994, "test_micro_f1": 0.1630170316301703, "test_micro_f1_no_misc": 0.11798071469086785, "test_runtime": 8.5269, "test_samples_per_second": 240.18, "test_steps_per_second": 7.506}, {"test_loss": 0.2855943739414215, "test_micro_f1": 0.24055944055944056, "test_micro_f1_no_misc": 0.19744483159117307, "test_runtime": 8.5092, "test_samples_per_second": 240.681, "test_steps_per_second": 7.521}, {"test_loss": 0.3043500483036041, "test_micro_f1": 0.24285309934899518, "test_micro_f1_no_misc": 0.2223021582733813, "test_runtime": 8.6424, "test_samples_per_second": 236.971, "test_steps_per_second": 7.405}, {"test_loss": 0.31026631593704224, "test_micro_f1": 0.1383960255500355, "test_micro_f1_no_misc": 0.10952600092038656, "test_runtime": 8.3293, "test_samples_per_second": 245.879, "test_steps_per_second": 7.684}, {"test_loss": 0.3002481758594513, "test_micro_f1": 0.16273764258555135, "test_micro_f1_no_misc": 0.14683301343570057, "test_runtime": 8.4253, "test_samples_per_second": 243.076, "test_steps_per_second": 7.596}, {"test_loss": 0.28220489621162415, "test_micro_f1": 0.23975198070961076, "test_micro_f1_no_misc": 0.20757238307349665, "test_runtime": 8.7102, "test_samples_per_second": 235.126, "test_steps_per_second": 7.348}, {"test_loss": 0.29249292612075806, "test_micro_f1": 0.24817518248175183, "test_micro_f1_no_misc": 0.20618556701030927, "test_runtime": 8.153, "test_samples_per_second": 251.197, "test_steps_per_second": 7.85}, {"test_loss": 0.29778042435646057, "test_micro_f1": 0.17160686427457097, "test_micro_f1_no_misc": 0.13986727922409392, "test_runtime": 7.1804, "test_samples_per_second": 285.221, "test_steps_per_second": 8.913}]}, "total": {"test_micro_f1": 19.31285234547203, "test_micro_f1_se": 2.8722663886330566, "test_micro_f1_no_misc": 15.935790288504018, "test_micro_f1_no_misc_se": 3.007735841845217}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.2488420009613037, "test_micro_f1": 0.30963665086887837, "test_micro_f1_no_misc": 0.33408172429277055, "test_runtime": 6.8988, "test_samples_per_second": 296.863, "test_steps_per_second": 9.277}, {"test_loss": 0.2513848841190338, "test_micro_f1": 0.24070021881838077, "test_micro_f1_no_misc": 0.2593469001419782, "test_runtime": 6.5367, "test_samples_per_second": 313.308, "test_steps_per_second": 9.791}, {"test_loss": 0.26714539527893066, "test_micro_f1": 0.24146981627296588, "test_micro_f1_no_misc": 0.26199616122840697, "test_runtime": 5.9621, "test_samples_per_second": 343.502, "test_steps_per_second": 10.734}, {"test_loss": 0.26596537232398987, "test_micro_f1": 0.2982321291314374, "test_micro_f1_no_misc": 0.3171334431630972, "test_runtime": 6.3388, "test_samples_per_second": 323.088, "test_steps_per_second": 10.097}, {"test_loss": 0.27019810676574707, "test_micro_f1": 0.2222222222222222, "test_micro_f1_no_misc": 0.24008350730688935, "test_runtime": 6.5152, "test_samples_per_second": 314.341, "test_steps_per_second": 9.823}, {"test_loss": 0.2686975300312042, "test_micro_f1": 0.21591541457985533, "test_micro_f1_no_misc": 0.23701893708002444, "test_runtime": 6.5349, "test_samples_per_second": 313.392, "test_steps_per_second": 9.793}, {"test_loss": 0.274755597114563, "test_micro_f1": 0.1855779427359491, "test_micro_f1_no_misc": 0.19965377957299482, "test_runtime": 5.879, "test_samples_per_second": 348.359, "test_steps_per_second": 10.886}, {"test_loss": 0.257560670375824, "test_micro_f1": 0.2502744237102086, "test_micro_f1_no_misc": 0.2709447415329768, "test_runtime": 6.2821, "test_samples_per_second": 326.005, "test_steps_per_second": 10.188}, {"test_loss": 0.2876625955104828, "test_micro_f1": 0.13026819923371646, "test_micro_f1_no_misc": 0.1451957295373665, "test_runtime": 5.9428, "test_samples_per_second": 344.618, "test_steps_per_second": 10.769}, {"test_loss": 0.272246390581131, "test_micro_f1": 0.2598652550529355, "test_micro_f1_no_misc": 0.2837333333333334, "test_runtime": 6.5532, "test_samples_per_second": 312.518, "test_steps_per_second": 9.766}]}, "total": {"test_micro_f1": 23.541622726265494, "test_micro_f1_se": 3.2293389778691424, "test_micro_f1_no_misc": 25.491882571898383, "test_micro_f1_no_misc_se": 3.3902965138309593}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.25567716360092163, "test_micro_f1": 0.24242424242424243, "test_micro_f1_no_misc": 0.26105624731644483, "test_runtime": 6.0852, "test_samples_per_second": 336.554, "test_steps_per_second": 10.517}, {"test_loss": 0.25576746463775635, "test_micro_f1": 0.2193211488250653, "test_micro_f1_no_misc": 0.23667205169628433, "test_runtime": 6.0752, "test_samples_per_second": 337.106, "test_steps_per_second": 10.535}, {"test_loss": 0.25727522373199463, "test_micro_f1": 0.2719054242002782, "test_micro_f1_no_misc": 0.2916041979010495, "test_runtime": 6.6347, "test_samples_per_second": 308.681, "test_steps_per_second": 9.646}, {"test_loss": 0.2745708227157593, "test_micro_f1": 0.2569128456422821, "test_micro_f1_no_misc": 0.27796869033982435, "test_runtime": 6.4118, "test_samples_per_second": 319.412, "test_steps_per_second": 9.982}, {"test_loss": 0.2548965811729431, "test_micro_f1": 0.2536617842876165, "test_micro_f1_no_misc": 0.2748091603053435, "test_runtime": 6.149, "test_samples_per_second": 333.064, "test_steps_per_second": 10.408}, {"test_loss": 0.2590716481208801, "test_micro_f1": 0.2666666666666667, "test_micro_f1_no_misc": 0.2850796001480933, "test_runtime": 6.1692, "test_samples_per_second": 331.973, "test_steps_per_second": 10.374}, {"test_loss": 0.2610241770744324, "test_micro_f1": 0.24577464788732395, "test_micro_f1_no_misc": 0.2650695517774343, "test_runtime": 6.7458, "test_samples_per_second": 303.595, "test_steps_per_second": 9.487}, {"test_loss": 0.2674095034599304, "test_micro_f1": 0.18190342240975152, "test_micro_f1_no_misc": 0.19877049180327871, "test_runtime": 6.5931, "test_samples_per_second": 310.629, "test_steps_per_second": 9.707}, {"test_loss": 0.25671297311782837, "test_micro_f1": 0.22461005199306758, "test_micro_f1_no_misc": 0.2434259954921112, "test_runtime": 5.5808, "test_samples_per_second": 366.974, "test_steps_per_second": 11.468}, {"test_loss": 0.254381000995636, "test_micro_f1": 0.24678816850911264, "test_micro_f1_no_misc": 0.2595516261446164, "test_runtime": 5.9021, "test_samples_per_second": 346.995, "test_steps_per_second": 10.844}]}, "total": {"test_micro_f1": 24.099684028454067, "test_micro_f1_se": 1.6420385965000062, "test_micro_f1_no_misc": 25.940076129244805, "test_micro_f1_no_misc_se": 1.698838331877319}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.6918999552726746, "test_mcc": 0.0, "test_macro_f1": 0.3402061855670103, "test_runtime": 3.2905, "test_samples_per_second": 622.405, "test_steps_per_second": 19.45}, {"test_loss": 0.6927347183227539, "test_mcc": 0.03161449111483098, "test_macro_f1": 0.4160435026513615, "test_runtime": 3.4916, "test_samples_per_second": 586.554, "test_steps_per_second": 18.33}, {"test_loss": 0.6936849355697632, "test_mcc": -0.002151022237073631, "test_macro_f1": 0.37949009278865187, "test_runtime": 3.3986, "test_samples_per_second": 602.601, "test_steps_per_second": 18.831}, {"test_loss": 0.6942320466041565, "test_mcc": 0.0, "test_macro_f1": 0.32830436208592984, "test_runtime": 3.3392, "test_samples_per_second": 613.326, "test_steps_per_second": 19.166}, {"test_loss": 0.6930606365203857, "test_mcc": 0.019794360796732188, "test_macro_f1": 0.45313751668891855, "test_runtime": 3.3538, "test_samples_per_second": 610.646, "test_steps_per_second": 19.083}, {"test_loss": 0.6947216987609863, "test_mcc": 0.008061796653055996, "test_macro_f1": 0.41164975404075893, "test_runtime": 3.2943, "test_samples_per_second": 621.684, "test_steps_per_second": 19.428}, {"test_loss": 0.6933836936950684, "test_mcc": 0.00016075938883242834, "test_macro_f1": 0.49919714966639445, "test_runtime": 3.3665, "test_samples_per_second": 608.355, "test_steps_per_second": 19.011}, {"test_loss": 0.6925386786460876, "test_mcc": 0.029560393201131713, "test_macro_f1": 0.42138188140495175, "test_runtime": 3.4403, "test_samples_per_second": 595.293, "test_steps_per_second": 18.603}, {"test_loss": 0.6934772729873657, "test_mcc": -0.000691293696594692, "test_macro_f1": 0.3315356301753012, "test_runtime": 3.393, "test_samples_per_second": 603.593, "test_steps_per_second": 18.862}, {"test_loss": 0.6928819417953491, "test_mcc": 0.0, "test_macro_f1": 0.335280753002272, "test_runtime": 3.3472, "test_samples_per_second": 611.851, "test_steps_per_second": 19.12}]}, "total": {"test_mcc": 0.8634948522091499, "test_mcc_se": 0.823720802920956, "test_macro_f1": 39.1622682807155, "test_macro_f1_se": 3.627285440853819}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.6932685375213623, "test_mcc": 0.01764573687642094, "test_macro_f1": 0.33544283858252333, "test_runtime": 3.7313, "test_samples_per_second": 548.875, "test_steps_per_second": 17.152}, {"test_loss": 0.6934749484062195, "test_mcc": 0.0, "test_macro_f1": 0.3382875605815832, "test_runtime": 3.8723, "test_samples_per_second": 528.883, "test_steps_per_second": 16.528}, {"test_loss": 0.6941724419593811, "test_mcc": 0.032384458788039944, "test_macro_f1": 0.34329515372657676, "test_runtime": 3.7478, "test_samples_per_second": 546.454, "test_steps_per_second": 17.077}, {"test_loss": 0.6924511790275574, "test_mcc": 0.014651071697968022, "test_macro_f1": 0.5003673940002962, "test_runtime": 3.8961, "test_samples_per_second": 525.651, "test_steps_per_second": 16.427}, {"test_loss": 0.6959303617477417, "test_mcc": 0.03786197855859691, "test_macro_f1": 0.3407612837945419, "test_runtime": 3.7325, "test_samples_per_second": 548.699, "test_steps_per_second": 17.147}, {"test_loss": 0.6975744962692261, "test_mcc": 0.0, "test_macro_f1": 0.3354964308890331, "test_runtime": 3.7369, "test_samples_per_second": 548.05, "test_steps_per_second": 17.127}, {"test_loss": 0.6926132440567017, "test_mcc": 0.03154268868057589, "test_macro_f1": 0.3498041157907436, "test_runtime": 3.6612, "test_samples_per_second": 559.382, "test_steps_per_second": 17.481}, {"test_loss": 0.7101366519927979, "test_mcc": 0.0, "test_macro_f1": 0.33657272432782637, "test_runtime": 3.7251, "test_samples_per_second": 549.782, "test_steps_per_second": 17.181}, {"test_loss": 0.6961174011230469, "test_mcc": 0.0, "test_macro_f1": 0.3302812295618051, "test_runtime": 3.7978, "test_samples_per_second": 539.262, "test_steps_per_second": 16.852}, {"test_loss": 0.6951910853385925, "test_mcc": 0.0, "test_macro_f1": 0.3342002600780234, "test_runtime": 3.8396, "test_samples_per_second": 533.384, "test_steps_per_second": 16.668}]}, "total": {"test_mcc": 1.340859346016017, "test_mcc_se": 0.9702266051675262, "test_macro_f1": 35.44508991332953, "test_macro_f1_se": 3.1953807647272425}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.693497896194458, "test_mcc": 0.0, "test_macro_f1": 0.3263157894736842, "test_runtime": 3.3071, "test_samples_per_second": 619.269, "test_steps_per_second": 19.352}, {"test_loss": 0.6933780312538147, "test_mcc": -0.0013866638267820575, "test_macro_f1": 0.3365231259968102, "test_runtime": 3.546, "test_samples_per_second": 577.556, "test_steps_per_second": 18.049}, {"test_loss": 0.6959681510925293, "test_mcc": -0.005752922210231913, "test_macro_f1": 0.34379174888217084, "test_runtime": 3.6074, "test_samples_per_second": 567.722, "test_steps_per_second": 17.741}, {"test_loss": 0.6931004524230957, "test_mcc": 0.0035459042904260035, "test_macro_f1": 0.4463158802743931, "test_runtime": 3.6687, "test_samples_per_second": 558.23, "test_steps_per_second": 17.445}, {"test_loss": 0.6923788785934448, "test_mcc": 0.04315856508465215, "test_macro_f1": 0.52124284502508, "test_runtime": 3.4116, "test_samples_per_second": 600.304, "test_steps_per_second": 18.76}, {"test_loss": 0.6945498585700989, "test_mcc": -0.02703106827174843, "test_macro_f1": 0.3631869219084516, "test_runtime": 3.4593, "test_samples_per_second": 592.031, "test_steps_per_second": 18.501}, {"test_loss": 0.7027089595794678, "test_mcc": 0.0, "test_macro_f1": 0.3272010512483574, "test_runtime": 3.845, "test_samples_per_second": 532.639, "test_steps_per_second": 16.645}, {"test_loss": 0.6948707103729248, "test_mcc": 0.0, "test_macro_f1": 0.330718954248366, "test_runtime": 3.3989, "test_samples_per_second": 602.54, "test_steps_per_second": 18.829}, {"test_loss": 0.6936101913452148, "test_mcc": 0.0, "test_macro_f1": 0.3298429319371728, "test_runtime": 3.3321, "test_samples_per_second": 614.621, "test_steps_per_second": 19.207}, {"test_loss": 0.6933598518371582, "test_mcc": 0.03733894481639765, "test_macro_f1": 0.3673919311276691, "test_runtime": 3.6407, "test_samples_per_second": 562.529, "test_steps_per_second": 17.579}]}, "total": {"test_mcc": 0.4987275988271341, "test_mcc_se": 1.2713001057840874, "test_macro_f1": 36.925311801221554, "test_macro_f1_se": 3.998131928806106}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_loss": 0.697613000869751, "test_mcc": 0.0, "test_macro_f1": 0.3236459709379128, "test_runtime": 3.9072, "test_samples_per_second": 524.164, "test_steps_per_second": 16.38}, {"test_loss": 0.6927590370178223, "test_mcc": 0.018616640642147932, "test_macro_f1": 0.47999493196158427, "test_runtime": 3.6191, "test_samples_per_second": 565.88, "test_steps_per_second": 17.684}, {"test_loss": 0.6952006816864014, "test_mcc": 0.0, "test_macro_f1": 0.33289902280130296, "test_runtime": 3.9456, "test_samples_per_second": 519.065, "test_steps_per_second": 16.221}, {"test_loss": 0.6933668851852417, "test_mcc": 0.05099204441649349, "test_macro_f1": 0.3455523053854643, "test_runtime": 3.6862, "test_samples_per_second": 555.578, "test_steps_per_second": 17.362}, {"test_loss": 0.6913750767707825, "test_mcc": 0.06799202521494649, "test_macro_f1": 0.40928013744358166, "test_runtime": 3.4818, "test_samples_per_second": 588.21, "test_steps_per_second": 18.382}, {"test_loss": 0.693848729133606, "test_mcc": 0.0, "test_macro_f1": 0.32319894249834763, "test_runtime": 4.0396, "test_samples_per_second": 506.979, "test_steps_per_second": 15.843}, {"test_loss": 0.69438636302948, "test_mcc": -0.0002529999285650036, "test_macro_f1": 0.3648525023589085, "test_runtime": 3.6277, "test_samples_per_second": 564.549, "test_steps_per_second": 17.642}, {"test_loss": 0.6962801218032837, "test_mcc": 0.0, "test_macro_f1": 0.34401024983984624, "test_runtime": 3.849, "test_samples_per_second": 532.087, "test_steps_per_second": 16.628}, {"test_loss": 0.7105280160903931, "test_mcc": 0.0, "test_macro_f1": 0.32230311052283256, "test_runtime": 3.4969, "test_samples_per_second": 585.669, "test_steps_per_second": 18.302}, {"test_loss": 0.6918765306472778, "test_mcc": 0.04565759536181049, "test_macro_f1": 0.5211114588617044, "test_runtime": 3.8056, "test_samples_per_second": 538.151, "test_steps_per_second": 16.817}]}, "total": {"test_mcc": 1.830053057068334, "test_mcc_se": 1.6405392833548578, "test_macro_f1": 37.66848632611485, "test_macro_f1_se": 4.3982377519439275}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_em": 5.809450038729667, "test_f1": 11.232433521302893}, {"test_em": 7.51937984496124, "test_f1": 13.79874377032629}, {"test_em": 4.327666151468315, "test_f1": 9.909135041106227}, {"test_em": 5.140186915887851, "test_f1": 11.250810129201117}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 5.165767154973015, "test_f1": 11.035162206217729}, {"test_em": 7.517084282460137, "test_f1": 13.76776085491577}, {"test_em": 6.594259115593483, "test_f1": 14.289919157692477}, {"test_em": 0.47058823529411764, "test_f1": 2.0055609997697044}, {"test_em": 4.270186335403727, "test_f1": 10.041152113921653}]}, "total": {"test_em": 4.681456807477155, "test_em_se": 1.6190613026531635, "test_f1": 9.733067779445385, "test_f1_se": 3.025105046407842}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_em": 1.0844306738962044, "test_f1": 5.116649781885067}, {"test_em": 4.573643410852713, "test_f1": 11.760985121379358}, {"test_em": 9.19629057187017, "test_f1": 16.102844159355556}, {"test_em": 4.984423676012461, "test_f1": 12.53711785917368}, {"test_em": 0.6177606177606177, "test_f1": 3.1527139724839848}, {"test_em": 4.703161141094834, "test_f1": 10.64586580888531}, {"test_em": 3.644646924829157, "test_f1": 9.80290088608289}, {"test_em": 4.809930178432894, "test_f1": 11.373107845613402}, {"test_em": 5.176470588235294, "test_f1": 11.89809494639692}, {"test_em": 5.434782608695652, "test_f1": 12.599318971712902}]}, "total": {"test_em": 4.422554039168, "test_em_se": 1.477942581462691, "test_f1": 10.498959935296906, "test_f1_se": 2.3349351567722803}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_em": 7.126258714175058, "test_f1": 14.462990324673818}, {"test_em": 1.4728682170542635, "test_f1": 4.1157164506948645}, {"test_em": 11.823802163833076, "test_f1": 17.532505320622324}, {"test_em": 10.669781931464174, "test_f1": 18.004432181920144}, {"test_em": 9.806949806949808, "test_f1": 16.299650648892058}, {"test_em": 5.397070161912104, "test_f1": 12.496768109609931}, {"test_em": 5.3910402429764614, "test_f1": 11.97920695479715}, {"test_em": 8.844065166795966, "test_f1": 15.571429232979444}, {"test_em": 8.156862745098039, "test_f1": 15.881223523638408}, {"test_em": 14.285714285714286, "test_f1": 21.050190166292857}]}, "total": {"test_em": 8.297441343597324, "test_em_se": 2.275679170058917, "test_f1": 14.739411291412102, "test_f1_se": 2.835086372567719}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.6816264986991882, "test_mcc": 0.5795923768367406, "test_macro_f1": 0.5376123544670326, "test_runtime": 6.0931, "test_samples_per_second": 336.118, "test_steps_per_second": 10.504}, {"test_loss": 0.6999704837799072, "test_mcc": 0.5445661640349257, "test_macro_f1": 0.5234827292976133, "test_runtime": 5.8748, "test_samples_per_second": 348.608, "test_steps_per_second": 10.894}, {"test_loss": 0.6875827312469482, "test_mcc": 0.5531554616021617, "test_macro_f1": 0.5280381098903476, "test_runtime": 6.1625, "test_samples_per_second": 332.331, "test_steps_per_second": 10.385}, {"test_loss": 0.7879223823547363, "test_mcc": 0.4700414352001145, "test_macro_f1": 0.4943004915208699, "test_runtime": 5.9005, "test_samples_per_second": 347.091, "test_steps_per_second": 10.847}, {"test_loss": 0.6658998727798462, "test_mcc": 0.5824576463083541, "test_macro_f1": 0.5367314670142634, "test_runtime": 6.0538, "test_samples_per_second": 338.299, "test_steps_per_second": 10.572}, {"test_loss": 0.6717180013656616, "test_mcc": 0.5723435042245, "test_macro_f1": 0.5344432041278127, "test_runtime": 6.003, "test_samples_per_second": 341.163, "test_steps_per_second": 10.661}, {"test_loss": 0.6395977735519409, "test_mcc": 0.6063357754422242, "test_macro_f1": 0.5476549006974324, "test_runtime": 5.6925, "test_samples_per_second": 359.771, "test_steps_per_second": 11.243}, {"test_loss": 0.6307332515716553, "test_mcc": 0.6046780562622521, "test_macro_f1": 0.5464082048963488, "test_runtime": 6.1393, "test_samples_per_second": 333.587, "test_steps_per_second": 10.425}, {"test_loss": 0.7531511783599854, "test_mcc": 0.4956124023054263, "test_macro_f1": 0.502049078626603, "test_runtime": 5.6361, "test_samples_per_second": 363.374, "test_steps_per_second": 11.355}, {"test_loss": 0.7017141580581665, "test_mcc": 0.5455740543619207, "test_macro_f1": 0.5243726662094343, "test_runtime": 5.7273, "test_samples_per_second": 357.585, "test_steps_per_second": 11.175}]}, "total": {"test_mcc": 55.5435687657862, "test_mcc_se": 2.749193561484041, "test_macro_f1": 52.750932067477564, "test_macro_f1_se": 1.0884604215920834}}, "num_model_parameters": 13549571, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 1.0254918336868286, "test_mcc": 0.1885351274628944, "test_macro_f1": 0.3630426097342176, "test_runtime": 1.7275, "test_samples_per_second": 1185.562, "test_steps_per_second": 37.049}, {"test_loss": 1.021658182144165, "test_mcc": 0.2181064847662888, "test_macro_f1": 0.37317389915138127, "test_runtime": 2.2864, "test_samples_per_second": 895.731, "test_steps_per_second": 27.992}, {"test_loss": 1.0392534732818604, "test_mcc": 0.1983870180154707, "test_macro_f1": 0.3672634992245876, "test_runtime": 2.0273, "test_samples_per_second": 1010.188, "test_steps_per_second": 31.568}, {"test_loss": 1.0408105850219727, "test_mcc": 0.19042493622969003, "test_macro_f1": 0.36589265485565714, "test_runtime": 1.7968, "test_samples_per_second": 1139.774, "test_steps_per_second": 35.618}, {"test_loss": 1.0227618217468262, "test_mcc": 0.20691745161980635, "test_macro_f1": 0.375269876360995, "test_runtime": 1.7837, "test_samples_per_second": 1148.177, "test_steps_per_second": 35.881}, {"test_loss": 1.0386922359466553, "test_mcc": 0.19034080668540543, "test_macro_f1": 0.3627117172631733, "test_runtime": 1.9407, "test_samples_per_second": 1055.279, "test_steps_per_second": 32.977}, {"test_loss": 1.0134402513504028, "test_mcc": 0.2279251259019401, "test_macro_f1": 0.3826649610150265, "test_runtime": 2.0809, "test_samples_per_second": 984.171, "test_steps_per_second": 30.755}, {"test_loss": 1.0222536325454712, "test_mcc": 0.20848330655483693, "test_macro_f1": 0.3731924035536693, "test_runtime": 1.9614, "test_samples_per_second": 1044.168, "test_steps_per_second": 32.63}, {"test_loss": 1.0233888626098633, "test_mcc": 0.23209000076475336, "test_macro_f1": 0.3852119460500963, "test_runtime": 1.9949, "test_samples_per_second": 1026.612, "test_steps_per_second": 32.082}, {"test_loss": 1.0922120809555054, "test_mcc": 0.0, "test_macro_f1": 0.17465465465465466, "test_runtime": 2.0228, "test_samples_per_second": 1012.44, "test_steps_per_second": 31.639}]}, "total": {"test_mcc": 18.61210258001086, "test_mcc_se": 4.165480920354461, "test_macro_f1": 35.23078221863459, "test_macro_f1_se": 3.8979093519236208}}, "num_model_parameters": 13549571, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 1.001578688621521, "test_mcc": 0.17070171800181339, "test_macro_f1": 0.3605973217423071, "test_runtime": 1.889, "test_samples_per_second": 1084.195, "test_steps_per_second": 33.881}, {"test_loss": 1.0005629062652588, "test_mcc": 0.20197420253858814, "test_macro_f1": 0.3801056312237514, "test_runtime": 1.5891, "test_samples_per_second": 1288.754, "test_steps_per_second": 40.274}, {"test_loss": 0.9878538250923157, "test_mcc": 0.0, "test_macro_f1": 0.2196027068325693, "test_runtime": 1.5038, "test_samples_per_second": 1361.85, "test_steps_per_second": 42.558}, {"test_loss": 0.979485273361206, "test_mcc": 0.25291581010129005, "test_macro_f1": 0.4030341022678188, "test_runtime": 1.5797, "test_samples_per_second": 1296.455, "test_steps_per_second": 40.514}, {"test_loss": 0.9780335426330566, "test_mcc": 0.16951096967528498, "test_macro_f1": 0.3712808566059571, "test_runtime": 1.9837, "test_samples_per_second": 1032.417, "test_steps_per_second": 32.263}, {"test_loss": 0.9955237507820129, "test_mcc": 0.0, "test_macro_f1": 0.21857564817853625, "test_runtime": 1.6125, "test_samples_per_second": 1270.048, "test_steps_per_second": 39.689}, {"test_loss": 0.950813889503479, "test_mcc": 0.20017508877027912, "test_macro_f1": 0.38120087419052046, "test_runtime": 1.8533, "test_samples_per_second": 1105.042, "test_steps_per_second": 34.533}, {"test_loss": 0.9768615961074829, "test_mcc": 0.22293275616284944, "test_macro_f1": 0.3923027041204244, "test_runtime": 1.8473, "test_samples_per_second": 1108.65, "test_steps_per_second": 34.645}, {"test_loss": 0.981216311454773, "test_mcc": 0.17426400486647906, "test_macro_f1": 0.368260492856999, "test_runtime": 1.6084, "test_samples_per_second": 1273.277, "test_steps_per_second": 39.79}, {"test_loss": 0.9950498342514038, "test_mcc": 0.1363510953454154, "test_macro_f1": 0.3197802677187799, "test_runtime": 1.7999, "test_samples_per_second": 1137.837, "test_steps_per_second": 35.557}]}, "total": {"test_mcc": 15.288256454619994, "test_mcc_se": 5.37288280671247, "test_macro_f1": 34.14740605737664, "test_macro_f1_se": 4.226149282649984}}, "num_model_parameters": 13549571, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.20345242321491241, "test_micro_f1": 0.1144981412639405, "test_micro_f1_no_misc": 0.12664473684210525, "test_runtime": 4.2503, "test_samples_per_second": 481.845, "test_steps_per_second": 15.058}, {"test_loss": 0.19817639887332916, "test_micro_f1": 0.08831168831168831, "test_micro_f1_no_misc": 0.09836065573770492, "test_runtime": 3.7313, "test_samples_per_second": 548.867, "test_steps_per_second": 17.152}, {"test_loss": 0.203066885471344, "test_micro_f1": 0.08536585365853659, "test_micro_f1_no_misc": 0.09248554913294797, "test_runtime": 3.8033, "test_samples_per_second": 538.486, "test_steps_per_second": 16.828}, {"test_loss": 0.2067553848028183, "test_micro_f1": 0.10690121786197564, "test_micro_f1_no_misc": 0.11037527593818985, "test_runtime": 4.0174, "test_samples_per_second": 509.78, "test_steps_per_second": 15.931}, {"test_loss": 0.21580186486244202, "test_micro_f1": 0.08558558558558557, "test_micro_f1_no_misc": 0.0929853181076672, "test_runtime": 4.4908, "test_samples_per_second": 456.047, "test_steps_per_second": 14.251}, {"test_loss": 0.220149964094162, "test_micro_f1": 0.13238157040882545, "test_micro_f1_no_misc": 0.14676258992805757, "test_runtime": 3.1753, "test_samples_per_second": 644.977, "test_steps_per_second": 20.156}, {"test_loss": 0.22268164157867432, "test_micro_f1": 0.08068269976726145, "test_micro_f1_no_misc": 0.08873720136518773, "test_runtime": 4.0656, "test_samples_per_second": 503.742, "test_steps_per_second": 15.742}, {"test_loss": 0.1880296766757965, "test_micro_f1": 0.0912162162162162, "test_micro_f1_no_misc": 0.10027855153203342, "test_runtime": 3.8367, "test_samples_per_second": 533.793, "test_steps_per_second": 16.681}, {"test_loss": 0.20200355350971222, "test_micro_f1": 0.09658246656760773, "test_micro_f1_no_misc": 0.0993485342019544, "test_runtime": 3.9568, "test_samples_per_second": 517.584, "test_steps_per_second": 16.175}, {"test_loss": 0.20360776782035828, "test_micro_f1": 0.08992248062015505, "test_micro_f1_no_misc": 0.09838846480067853, "test_runtime": 4.1423, "test_samples_per_second": 494.415, "test_steps_per_second": 15.45}]}, "total": {"test_micro_f1": 9.714479202617925, "test_micro_f1_se": 1.0008942937966427, "test_micro_f1_no_misc": 10.54366877586527, "test_micro_f1_no_misc_se": 1.121577980697299}}, "num_model_parameters": 13485321, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.31733354926109314, "test_micro_f1": 0.14968033095148553, "test_micro_f1_no_misc": 0.08267922553636839, "test_runtime": 4.6919, "test_samples_per_second": 436.501, "test_steps_per_second": 13.641}, {"test_loss": 0.30294954776763916, "test_micro_f1": 0.12728857890148212, "test_micro_f1_no_misc": 0.07489760093622001, "test_runtime": 4.5656, "test_samples_per_second": 448.573, "test_steps_per_second": 14.018}, {"test_loss": 0.30791521072387695, "test_micro_f1": 0.18517253160232322, "test_micro_f1_no_misc": 0.14142335766423356, "test_runtime": 4.7502, "test_samples_per_second": 431.136, "test_steps_per_second": 13.473}, {"test_loss": 0.30834248661994934, "test_micro_f1": 0.16823785351704132, "test_micro_f1_no_misc": 0.10840377921432123, "test_runtime": 4.6582, "test_samples_per_second": 439.657, "test_steps_per_second": 13.739}, {"test_loss": 0.30814534425735474, "test_micro_f1": 0.14386109962794544, "test_micro_f1_no_misc": 0.1029082774049217, "test_runtime": 4.1721, "test_samples_per_second": 490.884, "test_steps_per_second": 15.34}, {"test_loss": 0.30931776762008667, "test_micro_f1": 0.15130568356374807, "test_micro_f1_no_misc": 0.10483042137718396, "test_runtime": 4.5636, "test_samples_per_second": 448.772, "test_steps_per_second": 14.024}, {"test_loss": 0.30115896463394165, "test_micro_f1": 0.14856289660321015, "test_micro_f1_no_misc": 0.10646766169154229, "test_runtime": 4.8201, "test_samples_per_second": 424.883, "test_steps_per_second": 13.278}, {"test_loss": 0.28649866580963135, "test_micro_f1": 0.156055900621118, "test_micro_f1_no_misc": 0.1142263759086189, "test_runtime": 4.35, "test_samples_per_second": 470.8, "test_steps_per_second": 14.713}, {"test_loss": 0.300754576921463, "test_micro_f1": 0.1575037147102526, "test_micro_f1_no_misc": 0.09566968781470293, "test_runtime": 4.253, "test_samples_per_second": 481.537, "test_steps_per_second": 15.048}, {"test_loss": 0.29919904470443726, "test_micro_f1": 0.1385518590998043, "test_micro_f1_no_misc": 0.07375271149674621, "test_runtime": 4.0691, "test_samples_per_second": 503.305, "test_steps_per_second": 15.728}]}, "total": {"test_micro_f1": 15.262204491984107, "test_micro_f1_se": 0.9870268208924636, "test_micro_f1_no_misc": 10.052590990448593, "test_micro_f1_no_misc_se": 1.2562998879122158}}, "num_model_parameters": 13485321, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.2725237011909485, "test_micro_f1": 0.19398293668612485, "test_micro_f1_no_misc": 0.210213187902826, "test_runtime": 3.6749, "test_samples_per_second": 557.297, "test_steps_per_second": 17.416}, {"test_loss": 0.26694583892822266, "test_micro_f1": 0.2027231467473525, "test_micro_f1_no_misc": 0.21710526315789472, "test_runtime": 3.5265, "test_samples_per_second": 580.738, "test_steps_per_second": 18.148}, {"test_loss": 0.2780904471874237, "test_micro_f1": 0.15211267605633802, "test_micro_f1_no_misc": 0.16563786008230455, "test_runtime": 3.5433, "test_samples_per_second": 577.99, "test_steps_per_second": 18.062}, {"test_loss": 0.2828831672668457, "test_micro_f1": 0.13303769401330376, "test_micro_f1_no_misc": 0.14571948998178508, "test_runtime": 3.4972, "test_samples_per_second": 585.617, "test_steps_per_second": 18.301}, {"test_loss": 0.27892613410949707, "test_micro_f1": 0.1871345029239766, "test_micro_f1_no_misc": 0.20068192888455919, "test_runtime": 3.5509, "test_samples_per_second": 576.755, "test_steps_per_second": 18.024}, {"test_loss": 0.27545857429504395, "test_micro_f1": 0.20629047178538393, "test_micro_f1_no_misc": 0.21515151515151515, "test_runtime": 3.5908, "test_samples_per_second": 570.344, "test_steps_per_second": 17.823}, {"test_loss": 0.287921667098999, "test_micro_f1": 0.11334745762711865, "test_micro_f1_no_misc": 0.12291786329695577, "test_runtime": 3.2786, "test_samples_per_second": 624.655, "test_steps_per_second": 19.52}, {"test_loss": 0.27324140071868896, "test_micro_f1": 0.19808861859252822, "test_micro_f1_no_misc": 0.21013824884792626, "test_runtime": 3.4757, "test_samples_per_second": 589.232, "test_steps_per_second": 18.414}, {"test_loss": 0.2656155824661255, "test_micro_f1": 0.15710594315245477, "test_micro_f1_no_misc": 0.1713641488162345, "test_runtime": 3.5051, "test_samples_per_second": 584.29, "test_steps_per_second": 18.259}, {"test_loss": 0.2875726521015167, "test_micro_f1": 0.16451458632233382, "test_micro_f1_no_misc": 0.1786085150571132, "test_runtime": 3.3605, "test_samples_per_second": 609.43, "test_steps_per_second": 19.045}]}, "total": {"test_micro_f1": 17.08338033906915, "test_micro_f1_se": 1.9741716994116414, "test_micro_f1_no_misc": 18.375380211791146, "test_micro_f1_no_misc_se": 2.006990779708907}}, "num_model_parameters": 13485321, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.29064661264419556, "test_micro_f1": 0.1000893655049151, "test_micro_f1_no_misc": 0.10836961780358008, "test_runtime": 3.6055, "test_samples_per_second": 568.027, "test_steps_per_second": 17.751}, {"test_loss": 0.2938455641269684, "test_micro_f1": 0.12686905301314, "test_micro_f1_no_misc": 0.13909587680079485, "test_runtime": 3.4707, "test_samples_per_second": 590.081, "test_steps_per_second": 18.44}, {"test_loss": 0.2911152243614197, "test_micro_f1": 0.11682435211846975, "test_micro_f1_no_misc": 0.1274113952445043, "test_runtime": 3.3612, "test_samples_per_second": 609.314, "test_steps_per_second": 19.041}, {"test_loss": 0.3026660084724426, "test_micro_f1": 0.11345755693581781, "test_micro_f1_no_misc": 0.12403802625622454, "test_runtime": 3.4378, "test_samples_per_second": 595.737, "test_steps_per_second": 18.617}, {"test_loss": 0.29089468717575073, "test_micro_f1": 0.11968085106382978, "test_micro_f1_no_misc": 0.1341948310139165, "test_runtime": 3.3105, "test_samples_per_second": 618.631, "test_steps_per_second": 19.332}, {"test_loss": 0.2970539629459381, "test_micro_f1": 0.11390728476821192, "test_micro_f1_no_misc": 0.12542537676227516, "test_runtime": 3.3175, "test_samples_per_second": 617.338, "test_steps_per_second": 19.292}, {"test_loss": 0.28201431035995483, "test_micro_f1": 0.10823754789272029, "test_micro_f1_no_misc": 0.11919831223628694, "test_runtime": 3.544, "test_samples_per_second": 577.876, "test_steps_per_second": 18.059}, {"test_loss": 0.28337085247039795, "test_micro_f1": 0.15222173339199296, "test_micro_f1_no_misc": 0.1653919694072658, "test_runtime": 3.8699, "test_samples_per_second": 529.218, "test_steps_per_second": 16.538}, {"test_loss": 0.29600441455841064, "test_micro_f1": 0.07916666666666666, "test_micro_f1_no_misc": 0.08837209302325581, "test_runtime": 3.8177, "test_samples_per_second": 536.454, "test_steps_per_second": 16.764}, {"test_loss": 0.28780144453048706, "test_micro_f1": 0.1342572542226072, "test_micro_f1_no_misc": 0.14432029795158285, "test_runtime": 3.8015, "test_samples_per_second": 538.728, "test_steps_per_second": 16.835}]}, "total": {"test_micro_f1": 11.647116655783716, "test_micro_f1_se": 1.2146427348070576, "test_micro_f1_no_misc": 12.75817796499687, "test_micro_f1_no_misc_se": 1.286937623943525}}, "num_model_parameters": 13485321, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.6932981610298157, "test_mcc": 0.0, "test_macro_f1": 0.3263157894736842, "test_runtime": 1.469, "test_samples_per_second": 1394.149, "test_steps_per_second": 43.567}, {"test_loss": 0.6931148767471313, "test_mcc": 0.0, "test_macro_f1": 0.33093760209082, "test_runtime": 1.7003, "test_samples_per_second": 1204.496, "test_steps_per_second": 37.64}, {"test_loss": 0.6933556199073792, "test_mcc": 0.0, "test_macro_f1": 0.3254281949934124, "test_runtime": 1.9011, "test_samples_per_second": 1077.298, "test_steps_per_second": 33.666}, {"test_loss": 0.693195641040802, "test_mcc": -0.024096847350503, "test_macro_f1": 0.4847128231823702, "test_runtime": 1.8214, "test_samples_per_second": 1124.386, "test_steps_per_second": 35.137}, {"test_loss": 0.6931477785110474, "test_mcc": 0.0, "test_macro_f1": 0.33571196886149857, "test_runtime": 2.071, "test_samples_per_second": 988.881, "test_steps_per_second": 30.903}, {"test_loss": 0.6932809352874756, "test_mcc": 0.0, "test_macro_f1": 0.3324641460234681, "test_runtime": 1.5398, "test_samples_per_second": 1330.033, "test_steps_per_second": 41.564}, {"test_loss": 0.6931543946266174, "test_mcc": 0.005992078994029702, "test_macro_f1": 0.3390892264176665, "test_runtime": 1.5197, "test_samples_per_second": 1347.612, "test_steps_per_second": 42.113}, {"test_loss": 0.6931537389755249, "test_mcc": 0.0062348562359229925, "test_macro_f1": 0.35842692710678864, "test_runtime": 1.8724, "test_samples_per_second": 1093.781, "test_steps_per_second": 34.181}, {"test_loss": 0.6932977437973022, "test_mcc": 0.0, "test_macro_f1": 0.3298429319371728, "test_runtime": 1.8992, "test_samples_per_second": 1078.351, "test_steps_per_second": 33.698}, {"test_loss": 0.6930848360061646, "test_mcc": -0.0028801152341889234, "test_macro_f1": 0.369808974434616, "test_runtime": 1.8958, "test_samples_per_second": 1080.308, "test_steps_per_second": 33.76}]}, "total": {"test_mcc": -0.1475002735473923, "test_mcc_se": 0.5234725968477217, "test_macro_f1": 35.32738584521498, "test_macro_f1_se": 2.9988547024229573}}, "num_model_parameters": 13549314, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.6931596994400024, "test_mcc": -0.045678509859916006, "test_macro_f1": 0.46272737685716503, "test_runtime": 1.6263, "test_samples_per_second": 1259.299, "test_steps_per_second": 39.353}, {"test_loss": 0.6929174661636353, "test_mcc": 0.0, "test_macro_f1": 0.3382875605815832, "test_runtime": 1.7329, "test_samples_per_second": 1181.814, "test_steps_per_second": 36.932}, {"test_loss": 0.6927775144577026, "test_mcc": 0.0, "test_macro_f1": 0.3410553410553411, "test_runtime": 1.7867, "test_samples_per_second": 1146.277, "test_steps_per_second": 35.821}, {"test_loss": 0.6930750608444214, "test_mcc": 0.03851349506537684, "test_macro_f1": 0.4442376355063591, "test_runtime": 1.9326, "test_samples_per_second": 1059.711, "test_steps_per_second": 33.116}, {"test_loss": 0.693148136138916, "test_mcc": 0.0, "test_macro_f1": 0.33484897694056515, "test_runtime": 1.6854, "test_samples_per_second": 1215.123, "test_steps_per_second": 37.973}, {"test_loss": 0.6931953430175781, "test_mcc": -0.0005293811943557994, "test_macro_f1": 0.3337092227144583, "test_runtime": 1.6661, "test_samples_per_second": 1229.187, "test_steps_per_second": 38.412}, {"test_loss": 0.6931229829788208, "test_mcc": 0.03137217639959084, "test_macro_f1": 0.36525847728322125, "test_runtime": 1.6286, "test_samples_per_second": 1257.558, "test_steps_per_second": 39.299}, {"test_loss": 0.6930294632911682, "test_mcc": 0.0, "test_macro_f1": 0.33657272432782637, "test_runtime": 2.0735, "test_samples_per_second": 987.686, "test_steps_per_second": 30.865}, {"test_loss": 0.6931097507476807, "test_mcc": 0.006000939487707782, "test_macro_f1": 0.4928078217136962, "test_runtime": 1.6212, "test_samples_per_second": 1263.276, "test_steps_per_second": 39.477}, {"test_loss": 0.6931709051132202, "test_mcc": 0.0, "test_macro_f1": 0.3342002600780234, "test_runtime": 1.662, "test_samples_per_second": 1232.216, "test_steps_per_second": 38.507}]}, "total": {"test_mcc": 0.29678719898403655, "test_mcc_se": 1.3862738665268766, "test_macro_f1": 37.83705397058239, "test_macro_f1_se": 3.8821563577913896}}, "num_model_parameters": 13549314, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.6932685375213623, "test_mcc": 0.0, "test_macro_f1": 0.3263157894736842, "test_runtime": 1.8097, "test_samples_per_second": 1131.671, "test_steps_per_second": 35.365}, {"test_loss": 0.6930240392684937, "test_mcc": 0.0, "test_macro_f1": 0.33678756476683935, "test_runtime": 2.1192, "test_samples_per_second": 966.425, "test_steps_per_second": 30.201}, {"test_loss": 0.6929274797439575, "test_mcc": 0.0, "test_macro_f1": 0.3414790996784566, "test_runtime": 1.9002, "test_samples_per_second": 1077.754, "test_steps_per_second": 33.68}, {"test_loss": 0.6931237578392029, "test_mcc": -0.019995172873101055, "test_macro_f1": 0.3893283113622097, "test_runtime": 1.9117, "test_samples_per_second": 1071.27, "test_steps_per_second": 33.477}, {"test_loss": 0.6931500434875488, "test_mcc": 0.0, "test_macro_f1": 0.3339837398373984, "test_runtime": 1.7696, "test_samples_per_second": 1157.312, "test_steps_per_second": 36.166}, {"test_loss": 0.6931462287902832, "test_mcc": 0.022477053201163496, "test_macro_f1": 0.47622983583263445, "test_runtime": 1.6028, "test_samples_per_second": 1277.737, "test_steps_per_second": 39.929}, {"test_loss": 0.692979097366333, "test_mcc": 0.0, "test_macro_f1": 0.3393548387096774, "test_runtime": 1.784, "test_samples_per_second": 1147.976, "test_steps_per_second": 35.874}, {"test_loss": 0.693048357963562, "test_mcc": 0.025349485142298317, "test_macro_f1": 0.4017678228204544, "test_runtime": 1.5884, "test_samples_per_second": 1289.365, "test_steps_per_second": 40.293}, {"test_loss": 0.6930471658706665, "test_mcc": 0.0, "test_macro_f1": 0.33678756476683935, "test_runtime": 1.6008, "test_samples_per_second": 1279.366, "test_steps_per_second": 39.98}, {"test_loss": 0.6930556297302246, "test_mcc": -0.010954118468070213, "test_macro_f1": 0.346976692832144, "test_runtime": 1.7867, "test_samples_per_second": 1146.23, "test_steps_per_second": 35.82}]}, "total": {"test_mcc": 0.16877247002290546, "test_mcc_se": 0.83645290222525, "test_macro_f1": 36.29011260080338, "test_macro_f1_se": 2.9113950648468547}}, "num_model_parameters": 13549314, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_loss": 0.6926875114440918, "test_mcc": 0.0, "test_macro_f1": 0.3427471116816431, "test_runtime": 1.5454, "test_samples_per_second": 1325.193, "test_steps_per_second": 41.412}, {"test_loss": 0.6931235790252686, "test_mcc": 0.0, "test_macro_f1": 0.33571196886149857, "test_runtime": 1.5763, "test_samples_per_second": 1299.227, "test_steps_per_second": 40.601}, {"test_loss": 0.6931456327438354, "test_mcc": 0.0, "test_macro_f1": 0.33376707872478856, "test_runtime": 1.6304, "test_samples_per_second": 1256.129, "test_steps_per_second": 39.254}, {"test_loss": 0.6929482221603394, "test_mcc": 0.0, "test_macro_f1": 0.3399935546245569, "test_runtime": 1.8525, "test_samples_per_second": 1105.545, "test_steps_per_second": 34.548}, {"test_loss": 0.6927729249000549, "test_mcc": 0.0, "test_macro_f1": 0.3399935546245569, "test_runtime": 1.8519, "test_samples_per_second": 1105.869, "test_steps_per_second": 34.558}, {"test_loss": 0.6929957866668701, "test_mcc": 0.03532630486036192, "test_macro_f1": 0.4772462864694907, "test_runtime": 1.5437, "test_samples_per_second": 1326.688, "test_steps_per_second": 41.459}, {"test_loss": 0.6933609247207642, "test_mcc": 0.0, "test_macro_f1": 0.33050016345210853, "test_runtime": 1.5796, "test_samples_per_second": 1296.518, "test_steps_per_second": 40.516}, {"test_loss": 0.6935619711875916, "test_mcc": 0.0, "test_macro_f1": 0.32230311052283256, "test_runtime": 1.6392, "test_samples_per_second": 1249.399, "test_steps_per_second": 39.044}, {"test_loss": 0.6932610273361206, "test_mcc": 0.002082418535927812, "test_macro_f1": 0.35683815107184735, "test_runtime": 1.5377, "test_samples_per_second": 1331.859, "test_steps_per_second": 41.621}, {"test_loss": 0.6931113004684448, "test_mcc": 0.0, "test_macro_f1": 0.3289646133682831, "test_runtime": 1.7928, "test_samples_per_second": 1142.344, "test_steps_per_second": 35.698}]}, "total": {"test_mcc": 0.37408723396289734, "test_mcc_se": 0.689055469369835, "test_macro_f1": 35.080655934016065, "test_macro_f1_se": 2.813299079003316}}, "num_model_parameters": 13549314, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.07751937984496124, "test_f1": 0.4804411781155968}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.11258363127584621}, {"test_em": 0.0, "test_f1": 0.031031807602792862}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.11291891338475192}]}, "total": {"test_em": 0.007751937984496124, "test_em_se": 0.015193798449612403, "test_f1": 0.07369755303789878, "test_f1_se": 0.09306254855972061}}, "num_model_parameters": 13483522, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_em": 0.07745933384972889, "test_f1": 0.3581911423529868}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.04450378282153984}, {"test_em": 0.0, "test_f1": 0.08273579702151132}, {"test_em": 0.5397070161912105, "test_f1": 1.4090522746900522}, {"test_em": 0.30372057706909644, "test_f1": 0.9517576829649722}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.10605336692293213}]}, "total": {"test_em": 0.09208869271100359, "test_em_se": 0.11404859722923542, "test_f1": 0.29522940467739944, "test_f1_se": 0.3042065506257906}}, "num_model_parameters": 13483522, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_em": 0.30983733539891556, "test_f1": 1.9858191067419988}, {"test_em": 0.0, "test_f1": 0.3328393372853017}, {"test_em": 0.0, "test_f1": 0.06071980569662177}, {"test_em": 0.0, "test_f1": 0.02225189141076992}, {"test_em": 0.07722007722007722, "test_f1": 0.22038228429205872}, {"test_em": 0.15420200462606015, "test_f1": 1.1361138142799332}, {"test_em": 0.22779043280182232, "test_f1": 1.16489340159446}, {"test_em": 0.0, "test_f1": 0.1791717462780302}, {"test_em": 1.1764705882352942, "test_f1": 4.080204289528637}, {"test_em": 0.2329192546583851, "test_f1": 1.467549907285355}]}, "total": {"test_em": 0.21784396929405542, "test_em_se": 0.220726452828761, "test_f1": 1.0649945584393163, "test_f1_se": 0.7798096288784541}}, "num_model_parameters": 13483522, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.4063079357147217, "test_mcc": 0.7362782615728694, "test_macro_f1": 0.615348038568221, "test_runtime": 14.5098, "test_samples_per_second": 141.146, "test_steps_per_second": 17.643}, {"test_loss": 0.4608878791332245, "test_mcc": 0.7100976868987255, "test_macro_f1": 0.588067749339593, "test_runtime": 13.6338, "test_samples_per_second": 150.215, "test_steps_per_second": 18.777}, {"test_loss": 0.393616259098053, "test_mcc": 0.743931227069265, "test_macro_f1": 0.7149596019757941, "test_runtime": 17.1084, "test_samples_per_second": 119.708, "test_steps_per_second": 59.854}, {"test_loss": 0.364517480134964, "test_mcc": 0.7742067073672411, "test_macro_f1": 0.7352344671905308, "test_runtime": 17.073, "test_samples_per_second": 119.955, "test_steps_per_second": 59.978}, {"test_loss": 0.3708018362522125, "test_mcc": 0.7497488915573205, "test_macro_f1": 0.7435948372572446, "test_runtime": 16.9781, "test_samples_per_second": 120.626, "test_steps_per_second": 60.313}, {"test_loss": 0.39354902505874634, "test_mcc": 0.7522754575924465, "test_macro_f1": 0.7447075965840427, "test_runtime": 17.282, "test_samples_per_second": 118.505, "test_steps_per_second": 59.252}, {"test_loss": 0.37058353424072266, "test_mcc": 0.7549114055273979, "test_macro_f1": 0.7254967342086295, "test_runtime": 17.1473, "test_samples_per_second": 119.436, "test_steps_per_second": 59.718}, {"test_loss": 0.3976331949234009, "test_mcc": 0.7365680538371988, "test_macro_f1": 0.6977622963105393, "test_runtime": 17.3314, "test_samples_per_second": 118.167, "test_steps_per_second": 59.084}, {"test_loss": 0.416362464427948, "test_mcc": 0.7427064499643296, "test_macro_f1": 0.7422661463216644, "test_runtime": 17.2957, "test_samples_per_second": 118.411, "test_steps_per_second": 59.205}, {"test_loss": 0.3585430383682251, "test_mcc": 0.7719652144672324, "test_macro_f1": 0.7753483204249596, "test_runtime": 17.3607, "test_samples_per_second": 117.967, "test_steps_per_second": 58.984}]}, "total": {"test_mcc": 74.72689355854027, "test_mcc_se": 1.1455030698647628, "test_macro_f1": 70.8278578818122, "test_macro_f1_se": 3.7241638068822884}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.7607835531234741, "test_mcc": 0.5278602161220649, "test_macro_f1": 0.6903845406875121, "test_runtime": 4.3392, "test_samples_per_second": 471.974, "test_steps_per_second": 14.749}, {"test_loss": 0.7918058633804321, "test_mcc": 0.5181512587406844, "test_macro_f1": 0.6644040897043348, "test_runtime": 4.3337, "test_samples_per_second": 472.573, "test_steps_per_second": 14.768}, {"test_loss": 0.7902343273162842, "test_mcc": 0.515425870171477, "test_macro_f1": 0.6816936572199731, "test_runtime": 4.3261, "test_samples_per_second": 473.409, "test_steps_per_second": 14.794}, {"test_loss": 0.8266131281852722, "test_mcc": 0.4878936429877502, "test_macro_f1": 0.6488033124116791, "test_runtime": 4.2723, "test_samples_per_second": 479.371, "test_steps_per_second": 14.98}, {"test_loss": 0.763351559638977, "test_mcc": 0.5487661828391587, "test_macro_f1": 0.7028448277772968, "test_runtime": 4.2487, "test_samples_per_second": 482.034, "test_steps_per_second": 15.064}, {"test_loss": 0.897692084312439, "test_mcc": 0.4865149712375857, "test_macro_f1": 0.6526461200790358, "test_runtime": 4.2552, "test_samples_per_second": 481.295, "test_steps_per_second": 15.04}, {"test_loss": 0.7441689372062683, "test_mcc": 0.5280325744539381, "test_macro_f1": 0.6872073160546118, "test_runtime": 4.2595, "test_samples_per_second": 480.805, "test_steps_per_second": 15.025}, {"test_loss": 0.7962095737457275, "test_mcc": 0.5012651961818849, "test_macro_f1": 0.6628250968497483, "test_runtime": 4.3708, "test_samples_per_second": 468.559, "test_steps_per_second": 14.642}, {"test_loss": 0.7907381057739258, "test_mcc": 0.5233477717223539, "test_macro_f1": 0.67020538018058, "test_runtime": 4.321, "test_samples_per_second": 473.966, "test_steps_per_second": 14.811}, {"test_loss": 0.8712183237075806, "test_mcc": 0.49612640000447816, "test_macro_f1": 0.6430736862525003, "test_runtime": 4.2223, "test_samples_per_second": 485.047, "test_steps_per_second": 15.158}]}, "total": {"test_mcc": 51.33384084461375, "test_mcc_se": 1.2428085689666417, "test_macro_f1": 67.04088027217271, "test_macro_f1_se": 1.2194415601231587}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.6419888138771057, "test_mcc": 0.6108446606135799, "test_macro_f1": 0.7371298075534919, "test_runtime": 3.6689, "test_samples_per_second": 558.201, "test_steps_per_second": 17.444}, {"test_loss": 0.6501664519309998, "test_mcc": 0.588436226094553, "test_macro_f1": 0.7157990838004582, "test_runtime": 3.4034, "test_samples_per_second": 601.743, "test_steps_per_second": 18.804}, {"test_loss": 0.6722630858421326, "test_mcc": 0.5766016889532194, "test_macro_f1": 0.7067028957171422, "test_runtime": 3.5368, "test_samples_per_second": 579.057, "test_steps_per_second": 18.096}, {"test_loss": 0.6867117881774902, "test_mcc": 0.5869646254624885, "test_macro_f1": 0.7225262226854324, "test_runtime": 3.5496, "test_samples_per_second": 576.963, "test_steps_per_second": 18.03}, {"test_loss": 0.6961624622344971, "test_mcc": 0.5671548671018267, "test_macro_f1": 0.697035283353498, "test_runtime": 3.5514, "test_samples_per_second": 576.668, "test_steps_per_second": 18.021}, {"test_loss": 0.7297123670578003, "test_mcc": 0.5810524203789352, "test_macro_f1": 0.7120753768074469, "test_runtime": 3.6269, "test_samples_per_second": 564.662, "test_steps_per_second": 17.646}, {"test_loss": 0.6792716979980469, "test_mcc": 0.5677839997390047, "test_macro_f1": 0.6716069018700598, "test_runtime": 3.4567, "test_samples_per_second": 592.473, "test_steps_per_second": 18.515}, {"test_loss": 0.6487342715263367, "test_mcc": 0.5810187667755149, "test_macro_f1": 0.7083589361874895, "test_runtime": 3.5841, "test_samples_per_second": 571.406, "test_steps_per_second": 17.856}, {"test_loss": 0.7012250423431396, "test_mcc": 0.5703071239692007, "test_macro_f1": 0.7112417151865945, "test_runtime": 3.6674, "test_samples_per_second": 558.427, "test_steps_per_second": 17.451}, {"test_loss": 0.8073096871376038, "test_mcc": 0.5132756452814887, "test_macro_f1": 0.660975241465893, "test_runtime": 3.6665, "test_samples_per_second": 558.574, "test_steps_per_second": 17.455}]}, "total": {"test_mcc": 57.43440024369812, "test_mcc_se": 1.5495407594382649, "test_macro_f1": 70.43451464627506, "test_macro_f1_se": 1.412128614081802}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.0547531358897686, "test_micro_f1": 0.742973939703628, "test_micro_f1_no_misc": 0.8222357971899816, "test_runtime": 7.2633, "test_samples_per_second": 281.964, "test_steps_per_second": 8.811}, {"test_loss": 0.04875714331865311, "test_micro_f1": 0.7413972888425443, "test_micro_f1_no_misc": 0.8036036036036036, "test_runtime": 6.9948, "test_samples_per_second": 292.787, "test_steps_per_second": 9.15}, {"test_loss": 0.047643695026636124, "test_micro_f1": 0.7333333333333333, "test_micro_f1_no_misc": 0.793047256925584, "test_runtime": 6.6069, "test_samples_per_second": 309.977, "test_steps_per_second": 9.687}, {"test_loss": 0.04815800487995148, "test_micro_f1": 0.7536372453928224, "test_micro_f1_no_misc": 0.8020022246941045, "test_runtime": 7.2924, "test_samples_per_second": 280.839, "test_steps_per_second": 8.776}, {"test_loss": 0.056729525327682495, "test_micro_f1": 0.727188940092166, "test_micro_f1_no_misc": 0.7727737973387921, "test_runtime": 7.3053, "test_samples_per_second": 280.344, "test_steps_per_second": 8.761}, {"test_loss": 0.053692884743213654, "test_micro_f1": 0.7413162705667278, "test_micro_f1_no_misc": 0.7967654986522911, "test_runtime": 5.8582, "test_samples_per_second": 349.598, "test_steps_per_second": 10.925}, {"test_loss": 0.058166343718767166, "test_micro_f1": 0.7510668563300142, "test_micro_f1_no_misc": 0.8183831672203765, "test_runtime": 5.9268, "test_samples_per_second": 345.549, "test_steps_per_second": 10.798}, {"test_loss": 0.052309516817331314, "test_micro_f1": 0.7168234064785788, "test_micro_f1_no_misc": 0.7944862155388471, "test_runtime": 7.0436, "test_samples_per_second": 290.762, "test_steps_per_second": 9.086}, {"test_loss": 0.050411343574523926, "test_micro_f1": 0.7140186915887851, "test_micro_f1_no_misc": 0.7821290678433535, "test_runtime": 6.5357, "test_samples_per_second": 313.354, "test_steps_per_second": 9.792}, {"test_loss": 0.05579865351319313, "test_micro_f1": 0.7233009708737864, "test_micro_f1_no_misc": 0.7890847072200114, "test_runtime": 7.2284, "test_samples_per_second": 283.326, "test_steps_per_second": 8.854}]}, "total": {"test_micro_f1": 73.45056943202385, "test_micro_f1_se": 0.856518074324581, "test_micro_f1_no_misc": 79.74511336226946, "test_micro_f1_no_misc_se": 0.9362026340343277}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.0547822043299675, "test_micro_f1": 0.8034623217922607, "test_micro_f1_no_misc": 0.8179366149696561, "test_runtime": 8.1198, "test_samples_per_second": 252.224, "test_steps_per_second": 7.882}, {"test_loss": 0.05216046795248985, "test_micro_f1": 0.8395543175487465, "test_micro_f1_no_misc": 0.8645256552233296, "test_runtime": 6.6522, "test_samples_per_second": 307.87, "test_steps_per_second": 9.621}, {"test_loss": 0.05545205622911453, "test_micro_f1": 0.8149324861000795, "test_micro_f1_no_misc": 0.8469750889679715, "test_runtime": 8.1493, "test_samples_per_second": 251.309, "test_steps_per_second": 7.853}, {"test_loss": 0.05530475080013275, "test_micro_f1": 0.80419759406194, "test_micro_f1_no_misc": 0.8290833907649896, "test_runtime": 7.788, "test_samples_per_second": 262.968, "test_steps_per_second": 8.218}, {"test_loss": 0.06029761955142021, "test_micro_f1": 0.8389280677009874, "test_micro_f1_no_misc": 0.8546153846153847, "test_runtime": 8.1109, "test_samples_per_second": 252.499, "test_steps_per_second": 7.891}, {"test_loss": 0.05240917205810547, "test_micro_f1": 0.8631813125695217, "test_micro_f1_no_misc": 0.8742020277882087, "test_runtime": 8.1093, "test_samples_per_second": 252.549, "test_steps_per_second": 7.892}, {"test_loss": 0.051952846348285675, "test_micro_f1": 0.8460309003729355, "test_micro_f1_no_misc": 0.8693790149892933, "test_runtime": 8.2031, "test_samples_per_second": 249.663, "test_steps_per_second": 7.802}, {"test_loss": 0.04654783010482788, "test_micro_f1": 0.844173816772765, "test_micro_f1_no_misc": 0.864664441972562, "test_runtime": 8.1245, "test_samples_per_second": 252.079, "test_steps_per_second": 7.877}, {"test_loss": 0.05659984424710274, "test_micro_f1": 0.8309670506295205, "test_micro_f1_no_misc": 0.838803792851933, "test_runtime": 7.8122, "test_samples_per_second": 262.153, "test_steps_per_second": 8.192}, {"test_loss": 0.04905933886766434, "test_micro_f1": 0.8535475234270414, "test_micro_f1_no_misc": 0.8755426917510853, "test_runtime": 6.9998, "test_samples_per_second": 292.578, "test_steps_per_second": 9.143}]}, "total": {"test_micro_f1": 83.38975390975799, "test_micro_f1_se": 1.2618701898444329, "test_micro_f1_no_misc": 85.35728103894414, "test_micro_f1_no_misc_se": 1.2281061669404558}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.03892500698566437, "test_micro_f1": 0.873311427528295, "test_micro_f1_no_misc": 0.9081926718814326, "test_runtime": 6.3143, "test_samples_per_second": 324.341, "test_steps_per_second": 10.136}, {"test_loss": 0.028527677059173584, "test_micro_f1": 0.8762541806020068, "test_micro_f1_no_misc": 0.9106844741235391, "test_runtime": 6.2765, "test_samples_per_second": 326.298, "test_steps_per_second": 10.197}, {"test_loss": 0.033474065363407135, "test_micro_f1": 0.8951297547102737, "test_micro_f1_no_misc": 0.9265944645006017, "test_runtime": 5.8577, "test_samples_per_second": 349.625, "test_steps_per_second": 10.926}, {"test_loss": 0.024414679035544395, "test_micro_f1": 0.9091551785083068, "test_micro_f1_no_misc": 0.9234468937875753, "test_runtime": 5.7606, "test_samples_per_second": 355.519, "test_steps_per_second": 11.11}, {"test_loss": 0.027161281555891037, "test_micro_f1": 0.9108776685869195, "test_micro_f1_no_misc": 0.9304446978335233, "test_runtime": 6.3815, "test_samples_per_second": 320.93, "test_steps_per_second": 10.029}, {"test_loss": 0.026167351752519608, "test_micro_f1": 0.8965280165005156, "test_micro_f1_no_misc": 0.9187333078977489, "test_runtime": 6.3724, "test_samples_per_second": 321.386, "test_steps_per_second": 10.043}, {"test_loss": 0.02759392186999321, "test_micro_f1": 0.9039195282691641, "test_micro_f1_no_misc": 0.9215987701767873, "test_runtime": 5.8273, "test_samples_per_second": 351.448, "test_steps_per_second": 10.983}, {"test_loss": 0.02716745436191559, "test_micro_f1": 0.9014280738418669, "test_micro_f1_no_misc": 0.9232505643340858, "test_runtime": 5.7036, "test_samples_per_second": 359.074, "test_steps_per_second": 11.221}, {"test_loss": 0.030176734551787376, "test_micro_f1": 0.8659420289855072, "test_micro_f1_no_misc": 0.8894289185905224, "test_runtime": 5.8297, "test_samples_per_second": 351.306, "test_steps_per_second": 10.978}, {"test_loss": 0.036515235900878906, "test_micro_f1": 0.8935583878746126, "test_micro_f1_no_misc": 0.9131931166347994, "test_runtime": 6.3726, "test_samples_per_second": 321.377, "test_steps_per_second": 10.043}]}, "total": {"test_micro_f1": 89.2610424540747, "test_micro_f1_se": 0.9661477702309145, "test_micro_f1_no_misc": 91.65567879760616, "test_micro_f1_no_misc_se": 0.735615647928845}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.03714939206838608, "test_micro_f1": 0.8225108225108225, "test_micro_f1_no_misc": 0.8564690026954178, "test_runtime": 5.8939, "test_samples_per_second": 347.478, "test_steps_per_second": 10.859}, {"test_loss": 0.04006180912256241, "test_micro_f1": 0.8668486502881407, "test_micro_f1_no_misc": 0.8958404950154693, "test_runtime": 5.9776, "test_samples_per_second": 342.614, "test_steps_per_second": 10.707}, {"test_loss": 0.04423225671052933, "test_micro_f1": 0.8283559577677225, "test_micro_f1_no_misc": 0.8718123087385243, "test_runtime": 5.823, "test_samples_per_second": 351.71, "test_steps_per_second": 10.991}, {"test_loss": 0.046347036957740784, "test_micro_f1": 0.8399394856278366, "test_micro_f1_no_misc": 0.8733535967578521, "test_runtime": 6.0182, "test_samples_per_second": 340.301, "test_steps_per_second": 10.634}, {"test_loss": 0.048900917172431946, "test_micro_f1": 0.8237766436505553, "test_micro_f1_no_misc": 0.861293670010377, "test_runtime": 5.8949, "test_samples_per_second": 347.417, "test_steps_per_second": 10.857}, {"test_loss": 0.0482594259083271, "test_micro_f1": 0.8479427549194992, "test_micro_f1_no_misc": 0.8821954484605088, "test_runtime": 6.0465, "test_samples_per_second": 338.706, "test_steps_per_second": 10.585}, {"test_loss": 0.03613687679171562, "test_micro_f1": 0.8564310183743382, "test_micro_f1_no_misc": 0.8866855524079319, "test_runtime": 6.072, "test_samples_per_second": 337.287, "test_steps_per_second": 10.54}, {"test_loss": 0.03929658979177475, "test_micro_f1": 0.8654612319950965, "test_micro_f1_no_misc": 0.8907103825136612, "test_runtime": 5.9822, "test_samples_per_second": 342.346, "test_steps_per_second": 10.698}, {"test_loss": 0.044739700853824615, "test_micro_f1": 0.8414259373079287, "test_micro_f1_no_misc": 0.8738483345145286, "test_runtime": 5.6215, "test_samples_per_second": 364.313, "test_steps_per_second": 11.385}, {"test_loss": 0.037778086960315704, "test_micro_f1": 0.8578401464307506, "test_micro_f1_no_misc": 0.8815261044176705, "test_runtime": 5.7596, "test_samples_per_second": 355.58, "test_steps_per_second": 11.112}]}, "total": {"test_micro_f1": 84.50532648872692, "test_micro_f1_se": 1.0271670308126706, "test_micro_f1_no_misc": 87.73734895531942, "test_micro_f1_no_misc_se": 0.7733612866720679}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.6934990882873535, "test_mcc": 0.08847307890979804, "test_macro_f1": 0.5428220293417314, "test_runtime": 3.1806, "test_samples_per_second": 643.908, "test_steps_per_second": 20.122}, {"test_loss": 0.3896603286266327, "test_mcc": 0.7389415961746751, "test_macro_f1": 0.8635644291332732, "test_runtime": 3.3012, "test_samples_per_second": 620.378, "test_steps_per_second": 19.387}, {"test_loss": 0.6844218373298645, "test_mcc": 0.1512947826751203, "test_macro_f1": 0.5756473913375602, "test_runtime": 3.3503, "test_samples_per_second": 611.282, "test_steps_per_second": 19.103}, {"test_loss": 0.3755611181259155, "test_mcc": 0.6961185123848301, "test_macro_f1": 0.8374864682470637, "test_runtime": 3.1977, "test_samples_per_second": 640.461, "test_steps_per_second": 20.014}, {"test_loss": 0.36275702714920044, "test_mcc": 0.7510087237478479, "test_macro_f1": 0.871244668148643, "test_runtime": 3.2637, "test_samples_per_second": 627.508, "test_steps_per_second": 19.61}, {"test_loss": 0.3929785192012787, "test_mcc": 0.7044864776709653, "test_macro_f1": 0.8420251328911503, "test_runtime": 3.2613, "test_samples_per_second": 627.967, "test_steps_per_second": 19.624}, {"test_loss": 0.44062018394470215, "test_mcc": 0.6986748048002056, "test_macro_f1": 0.8316783821453966, "test_runtime": 3.229, "test_samples_per_second": 634.261, "test_steps_per_second": 19.821}, {"test_loss": 0.4457990527153015, "test_mcc": 0.6596457811369955, "test_macro_f1": 0.8059264643243729, "test_runtime": 3.2786, "test_samples_per_second": 624.654, "test_steps_per_second": 19.52}, {"test_loss": 0.6765190362930298, "test_mcc": 0.2107707057571082, "test_macro_f1": 0.6009032977594602, "test_runtime": 3.2563, "test_samples_per_second": 628.937, "test_steps_per_second": 19.654}, {"test_loss": 0.4553511142730713, "test_mcc": 0.6558759430436982, "test_macro_f1": 0.8074465960297162, "test_runtime": 3.2498, "test_samples_per_second": 630.19, "test_steps_per_second": 19.693}]}, "total": {"test_mcc": 53.55290406301243, "test_mcc_se": 16.67743375206384, "test_macro_f1": 75.78744859358368, "test_macro_f1_se": 8.048212574974345}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.45709455013275146, "test_mcc": 0.6805273353420194, "test_macro_f1": 0.8308747468249899, "test_runtime": 3.6426, "test_samples_per_second": 562.24, "test_steps_per_second": 17.57}, {"test_loss": 0.41455474495887756, "test_mcc": 0.7255953691150867, "test_macro_f1": 0.8612752056906474, "test_runtime": 3.7547, "test_samples_per_second": 545.448, "test_steps_per_second": 17.045}, {"test_loss": 0.6896275281906128, "test_mcc": 0.0883981427146236, "test_macro_f1": 0.5091164559054467, "test_runtime": 3.6977, "test_samples_per_second": 553.854, "test_steps_per_second": 17.308}, {"test_loss": 0.6880098581314087, "test_mcc": 0.09876372076079674, "test_macro_f1": 0.5477926733099145, "test_runtime": 3.8247, "test_samples_per_second": 535.473, "test_steps_per_second": 16.734}, {"test_loss": 0.4666815400123596, "test_mcc": 0.6533021246876853, "test_macro_f1": 0.8114136608780276, "test_runtime": 3.6322, "test_samples_per_second": 563.853, "test_steps_per_second": 17.62}, {"test_loss": 0.4000699520111084, "test_mcc": 0.7171480863622482, "test_macro_f1": 0.8527764654686386, "test_runtime": 3.6339, "test_samples_per_second": 563.576, "test_steps_per_second": 17.612}, {"test_loss": 0.6892908811569214, "test_mcc": 0.055331828652510164, "test_macro_f1": 0.5239452192062782, "test_runtime": 3.5519, "test_samples_per_second": 576.596, "test_steps_per_second": 18.019}, {"test_loss": 0.46398040652275085, "test_mcc": 0.7022702082823313, "test_macro_f1": 0.8358567790761438, "test_runtime": 3.6154, "test_samples_per_second": 566.463, "test_steps_per_second": 17.702}, {"test_loss": 0.6923210024833679, "test_mcc": 0.1065182744807968, "test_macro_f1": 0.48201167918387733, "test_runtime": 3.6328, "test_samples_per_second": 563.746, "test_steps_per_second": 17.617}, {"test_loss": 0.4897325932979584, "test_mcc": 0.6172939043683797, "test_macro_f1": 0.7958830980205082, "test_runtime": 3.6882, "test_samples_per_second": 555.284, "test_steps_per_second": 17.353}]}, "total": {"test_mcc": 44.45148994766478, "test_mcc_se": 19.170492793439877, "test_macro_f1": 70.50945983564472, "test_macro_f1_se": 10.213763309434228}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.43660300970077515, "test_mcc": 0.6767674125492653, "test_macro_f1": 0.8182212666916509, "test_runtime": 3.2934, "test_samples_per_second": 621.852, "test_steps_per_second": 19.433}, {"test_loss": 0.41173964738845825, "test_mcc": 0.7656669357832946, "test_macro_f1": 0.8741327371846764, "test_runtime": 3.2627, "test_samples_per_second": 627.707, "test_steps_per_second": 19.616}, {"test_loss": 0.44240158796310425, "test_mcc": 0.6521764252832171, "test_macro_f1": 0.8023294502695253, "test_runtime": 3.3162, "test_samples_per_second": 617.577, "test_steps_per_second": 19.299}, {"test_loss": 0.3788633644580841, "test_mcc": 0.7236086510964997, "test_macro_f1": 0.8514064150636748, "test_runtime": 3.4021, "test_samples_per_second": 601.986, "test_steps_per_second": 18.812}, {"test_loss": 0.3331978917121887, "test_mcc": 0.7532116570874123, "test_macro_f1": 0.8694940079349145, "test_runtime": 3.3697, "test_samples_per_second": 607.773, "test_steps_per_second": 18.993}, {"test_loss": 0.4962373375892639, "test_mcc": 0.6687358223269596, "test_macro_f1": 0.811353335938688, "test_runtime": 3.2158, "test_samples_per_second": 636.857, "test_steps_per_second": 19.902}, {"test_loss": 0.4779598116874695, "test_mcc": 0.6220920163961646, "test_macro_f1": 0.7890076007723066, "test_runtime": 3.2529, "test_samples_per_second": 629.596, "test_steps_per_second": 19.675}, {"test_loss": 0.4041880667209625, "test_mcc": 0.6992725266269294, "test_macro_f1": 0.8345267994470729, "test_runtime": 3.2847, "test_samples_per_second": 623.498, "test_steps_per_second": 19.484}, {"test_loss": 0.6877121329307556, "test_mcc": 0.11798224284703264, "test_macro_f1": 0.5585112268452279, "test_runtime": 3.2096, "test_samples_per_second": 638.085, "test_steps_per_second": 19.94}, {"test_loss": 0.42627114057540894, "test_mcc": 0.6511510157717196, "test_macro_f1": 0.8094162138827312, "test_runtime": 3.3424, "test_samples_per_second": 612.725, "test_steps_per_second": 19.148}]}, "total": {"test_mcc": 63.30664705768496, "test_mcc_se": 11.575351981265943, "test_macro_f1": 80.18399054030468, "test_macro_f1_se": 5.586615526514278}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_loss": 0.40006768703460693, "test_mcc": 0.7192195978465875, "test_macro_f1": 0.8503903875824022, "test_runtime": 3.4899, "test_samples_per_second": 586.838, "test_steps_per_second": 18.339}, {"test_loss": 0.4339974820613861, "test_mcc": 0.6369773532065853, "test_macro_f1": 0.7967619369469865, "test_runtime": 3.5785, "test_samples_per_second": 572.299, "test_steps_per_second": 17.884}, {"test_loss": 0.38834965229034424, "test_mcc": 0.7193538316557865, "test_macro_f1": 0.8523235959204394, "test_runtime": 3.6238, "test_samples_per_second": 565.151, "test_steps_per_second": 17.661}, {"test_loss": 0.48091351985931396, "test_mcc": 0.6001408161374597, "test_macro_f1": 0.7656464753540742, "test_runtime": 3.4375, "test_samples_per_second": 595.78, "test_steps_per_second": 18.618}, {"test_loss": 0.4119848608970642, "test_mcc": 0.6764987821360781, "test_macro_f1": 0.8210036335068251, "test_runtime": 3.4819, "test_samples_per_second": 588.179, "test_steps_per_second": 18.381}, {"test_loss": 0.6848893165588379, "test_mcc": 0.12254573575113095, "test_macro_f1": 0.5121398225100628, "test_runtime": 3.597, "test_samples_per_second": 569.36, "test_steps_per_second": 17.792}, {"test_loss": 0.4285624623298645, "test_mcc": 0.6613126122716548, "test_macro_f1": 0.8169461979906985, "test_runtime": 3.4965, "test_samples_per_second": 585.723, "test_steps_per_second": 18.304}, {"test_loss": 0.3786218464374542, "test_mcc": 0.7543214591610617, "test_macro_f1": 0.8720554178568004, "test_runtime": 3.4823, "test_samples_per_second": 588.115, "test_steps_per_second": 18.379}, {"test_loss": 0.3964401185512543, "test_mcc": 0.7070604426166589, "test_macro_f1": 0.8454034005018156, "test_runtime": 3.4828, "test_samples_per_second": 588.03, "test_steps_per_second": 18.376}, {"test_loss": 0.3786643147468567, "test_mcc": 0.6817731933630753, "test_macro_f1": 0.83266291230893, "test_runtime": 3.5637, "test_samples_per_second": 574.678, "test_steps_per_second": 17.959}]}, "total": {"test_mcc": 62.79203824146079, "test_mcc_se": 11.345604980235201, "test_macro_f1": 79.65333780479035, "test_macro_f1_se": 6.4762291004021435}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_em": 38.342370255615805, "test_f1": 42.21643469417648}, {"test_em": 33.95348837209303, "test_f1": 38.09059689291151}, {"test_em": 39.258114374034, "test_f1": 43.04424968625901}, {"test_em": 37.30529595015577, "test_f1": 41.79873120740358}, {"test_em": 43.552123552123554, "test_f1": 47.08422476575272}, {"test_em": 39.39861218195836, "test_f1": 43.445912712772895}, {"test_em": 42.74867122247532, "test_f1": 46.53469404825676}, {"test_em": 43.67726920093095, "test_f1": 48.03222008791755}, {"test_em": 40.3921568627451, "test_f1": 44.285093974804404}, {"test_em": 40.52795031055901, "test_f1": 43.82786059208313}]}, "total": {"test_em": 39.91560522826909, "test_em_se": 1.865583105992864, "test_f1": 43.8360018662338, "test_f1_se": 1.8035559581080332}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_em": 44.306738962044925, "test_f1": 48.80914207367038}, {"test_em": 41.627906976744185, "test_f1": 46.3665263558712}, {"test_em": 41.190108191653785, "test_f1": 45.9959526712496}, {"test_em": 44.626168224299064, "test_f1": 48.23021604322782}, {"test_em": 37.83783783783784, "test_f1": 42.05299544727079}, {"test_em": 39.629915188897456, "test_f1": 44.93534093209556}, {"test_em": 40.92634776006074, "test_f1": 46.15801470586832}, {"test_em": 37.23816912335143, "test_f1": 41.71952397563729}, {"test_em": 38.8235294117647, "test_f1": 43.950897155482835}, {"test_em": 36.25776397515528, "test_f1": 41.12506478003661}]}, "total": {"test_em": 40.24644856518094, "test_em_se": 1.7542292484552164, "test_f1": 44.934367414041034, "test_f1_se": 1.6614123569373733}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_em": 43.532145623547635, "test_f1": 48.39252313904765}, {"test_em": 41.70542635658915, "test_f1": 45.744984814547045}, {"test_em": 42.349304482225655, "test_f1": 46.25853398503184}, {"test_em": 38.940809968847354, "test_f1": 44.02209986296821}, {"test_em": 41.46718146718147, "test_f1": 46.134939945200884}, {"test_em": 42.17424826522745, "test_f1": 46.59364576716716}, {"test_em": 41.98936977980258, "test_f1": 46.545012544046365}, {"test_em": 42.90147401086113, "test_f1": 46.99633384662337}, {"test_em": 42.666666666666664, "test_f1": 47.52338669871603}, {"test_em": 40.29503105590062, "test_f1": 44.26193130967855}]}, "total": {"test_em": 41.80216576768497, "test_em_se": 0.8264578159377951, "test_f1": 46.247339191302714, "test_f1_se": 0.8304865222904932}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.3952951431274414, "test_mcc": 0.7356997240011113, "test_macro_f1": 0.7392684938543314, "test_runtime": 14.5362, "test_samples_per_second": 140.89, "test_steps_per_second": 17.611}, {"test_loss": 0.440586656332016, "test_mcc": 0.7154136651416674, "test_macro_f1": 0.7367457932912426, "test_runtime": 13.7788, "test_samples_per_second": 148.634, "test_steps_per_second": 18.579}, {"test_loss": 0.4123765826225281, "test_mcc": 0.7277651538899598, "test_macro_f1": 0.6700312875150424, "test_runtime": 17.2727, "test_samples_per_second": 118.569, "test_steps_per_second": 59.284}, {"test_loss": 0.3696615397930145, "test_mcc": 0.7585383837314901, "test_macro_f1": 0.7179316130283496, "test_runtime": 17.1962, "test_samples_per_second": 119.096, "test_steps_per_second": 59.548}, {"test_loss": 0.40094417333602905, "test_mcc": 0.7361229174057037, "test_macro_f1": 0.7094886032476331, "test_runtime": 17.1969, "test_samples_per_second": 119.091, "test_steps_per_second": 59.545}, {"test_loss": 0.42986249923706055, "test_mcc": 0.7367570482175376, "test_macro_f1": 0.728313322200373, "test_runtime": 17.587, "test_samples_per_second": 116.45, "test_steps_per_second": 58.225}, {"test_loss": 0.4401529133319855, "test_mcc": 0.7175199384569861, "test_macro_f1": 0.7173095130350711, "test_runtime": 17.1619, "test_samples_per_second": 119.334, "test_steps_per_second": 59.667}, {"test_loss": 0.4550529718399048, "test_mcc": 0.7283744702833588, "test_macro_f1": 0.7358694724266849, "test_runtime": 17.5928, "test_samples_per_second": 116.411, "test_steps_per_second": 58.206}, {"test_loss": 0.4213344156742096, "test_mcc": 0.733359972690968, "test_macro_f1": 0.7295835835595851, "test_runtime": 17.3924, "test_samples_per_second": 117.752, "test_steps_per_second": 58.876}, {"test_loss": 0.40208232402801514, "test_mcc": 0.7375627884854872, "test_macro_f1": 0.7025196976210015, "test_runtime": 17.5013, "test_samples_per_second": 117.02, "test_steps_per_second": 58.51}]}, "total": {"test_mcc": 73.2711406230427, "test_mcc_se": 0.7452560335597469, "test_macro_f1": 71.87061379779315, "test_macro_f1_se": 1.3021167421778959}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.7750935554504395, "test_mcc": 0.5054143654486554, "test_macro_f1": 0.6589553187641094, "test_runtime": 4.3758, "test_samples_per_second": 468.029, "test_steps_per_second": 14.626}, {"test_loss": 0.7618544697761536, "test_mcc": 0.5120593614931495, "test_macro_f1": 0.6718799889336529, "test_runtime": 4.3565, "test_samples_per_second": 470.104, "test_steps_per_second": 14.691}, {"test_loss": 0.7969927787780762, "test_mcc": 0.4626137347508272, "test_macro_f1": 0.6435524659877861, "test_runtime": 4.363, "test_samples_per_second": 469.403, "test_steps_per_second": 14.669}, {"test_loss": 0.8090196847915649, "test_mcc": 0.48904129346893166, "test_macro_f1": 0.6531783481971022, "test_runtime": 4.3009, "test_samples_per_second": 476.184, "test_steps_per_second": 14.881}, {"test_loss": 0.8158232569694519, "test_mcc": 0.4798348925239493, "test_macro_f1": 0.6554092001459547, "test_runtime": 4.2681, "test_samples_per_second": 479.842, "test_steps_per_second": 14.995}, {"test_loss": 0.8080919981002808, "test_mcc": 0.4667521691201039, "test_macro_f1": 0.6439549879061429, "test_runtime": 4.2982, "test_samples_per_second": 476.483, "test_steps_per_second": 14.89}, {"test_loss": 0.8167886734008789, "test_mcc": 0.46119760932243103, "test_macro_f1": 0.645198713061638, "test_runtime": 4.2585, "test_samples_per_second": 480.917, "test_steps_per_second": 15.029}, {"test_loss": 0.8248876333236694, "test_mcc": 0.4748048721737809, "test_macro_f1": 0.6317713234566791, "test_runtime": 4.3444, "test_samples_per_second": 471.409, "test_steps_per_second": 14.732}, {"test_loss": 0.7641757130622864, "test_mcc": 0.48146391796967414, "test_macro_f1": 0.6573364462592415, "test_runtime": 4.2985, "test_samples_per_second": 476.443, "test_steps_per_second": 14.889}, {"test_loss": 0.8501905202865601, "test_mcc": 0.44956879897481655, "test_macro_f1": 0.628593799364237, "test_runtime": 4.2664, "test_samples_per_second": 480.031, "test_steps_per_second": 15.001}]}, "total": {"test_mcc": 47.82751015246319, "test_mcc_se": 1.2244065726934201, "test_macro_f1": 64.89830592076544, "test_macro_f1_se": 0.8090393276942357}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.7117033004760742, "test_mcc": 0.522174818797135, "test_macro_f1": 0.6751916457151252, "test_runtime": 3.6987, "test_samples_per_second": 553.702, "test_steps_per_second": 17.303}, {"test_loss": 0.6937546730041504, "test_mcc": 0.5323291854522966, "test_macro_f1": 0.6595967130110467, "test_runtime": 3.4276, "test_samples_per_second": 597.499, "test_steps_per_second": 18.672}, {"test_loss": 0.722632884979248, "test_mcc": 0.5228226570570592, "test_macro_f1": 0.6555829957233424, "test_runtime": 3.6096, "test_samples_per_second": 567.378, "test_steps_per_second": 17.731}, {"test_loss": 0.73279869556427, "test_mcc": 0.5309884664364992, "test_macro_f1": 0.6571495679345699, "test_runtime": 3.5897, "test_samples_per_second": 570.52, "test_steps_per_second": 17.829}, {"test_loss": 0.7474221587181091, "test_mcc": 0.5401593998348564, "test_macro_f1": 0.6688746313286072, "test_runtime": 3.603, "test_samples_per_second": 568.419, "test_steps_per_second": 17.763}, {"test_loss": 0.7019667625427246, "test_mcc": 0.5649809286966538, "test_macro_f1": 0.6960169087878066, "test_runtime": 3.6405, "test_samples_per_second": 562.558, "test_steps_per_second": 17.58}, {"test_loss": 0.739392876625061, "test_mcc": 0.5312181627590495, "test_macro_f1": 0.6759563743976541, "test_runtime": 3.4902, "test_samples_per_second": 586.783, "test_steps_per_second": 18.337}, {"test_loss": 0.8495389223098755, "test_mcc": 0.3960335582518034, "test_macro_f1": 0.5423837788917857, "test_runtime": 3.6134, "test_samples_per_second": 566.786, "test_steps_per_second": 17.712}, {"test_loss": 0.7317174673080444, "test_mcc": 0.5260600094473508, "test_macro_f1": 0.6634024648948821, "test_runtime": 3.7603, "test_samples_per_second": 544.638, "test_steps_per_second": 17.02}, {"test_loss": 0.7186739444732666, "test_mcc": 0.5527157112558672, "test_macro_f1": 0.666077096164189, "test_runtime": 3.6643, "test_samples_per_second": 558.91, "test_steps_per_second": 17.466}]}, "total": {"test_mcc": 52.19482897988572, "test_mcc_se": 2.8685534887424624, "test_macro_f1": 65.60232176849009, "test_macro_f1_se": 2.5815432804076837}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.054912764579057693, "test_micro_f1": 0.7300796812749003, "test_micro_f1_no_misc": 0.7935034802784223, "test_runtime": 7.3619, "test_samples_per_second": 278.189, "test_steps_per_second": 8.693}, {"test_loss": 0.05139192193746567, "test_micro_f1": 0.7176835573940021, "test_micro_f1_no_misc": 0.7822435512897421, "test_runtime": 7.1081, "test_samples_per_second": 288.122, "test_steps_per_second": 9.004}, {"test_loss": 0.0510420985519886, "test_micro_f1": 0.7193901858027633, "test_micro_f1_no_misc": 0.7697194282689253, "test_runtime": 6.5792, "test_samples_per_second": 311.285, "test_steps_per_second": 9.728}, {"test_loss": 0.05280151963233948, "test_micro_f1": 0.7134000953743443, "test_micro_f1_no_misc": 0.7632432432432433, "test_runtime": 7.2676, "test_samples_per_second": 281.799, "test_steps_per_second": 8.806}, {"test_loss": 0.05148927867412567, "test_micro_f1": 0.7367928938756427, "test_micro_f1_no_misc": 0.7899686520376175, "test_runtime": 7.3286, "test_samples_per_second": 279.452, "test_steps_per_second": 8.733}, {"test_loss": 0.05112750083208084, "test_micro_f1": 0.7098540145985401, "test_micro_f1_no_misc": 0.7688229056203605, "test_runtime": 5.8708, "test_samples_per_second": 348.846, "test_steps_per_second": 10.901}, {"test_loss": 0.05446041375398636, "test_micro_f1": 0.7042389210019268, "test_micro_f1_no_misc": 0.7637752318603382, "test_runtime": 5.9995, "test_samples_per_second": 341.362, "test_steps_per_second": 10.668}, {"test_loss": 0.04767673835158348, "test_micro_f1": 0.6980433632998414, "test_micro_f1_no_misc": 0.7748303516347933, "test_runtime": 7.0585, "test_samples_per_second": 290.145, "test_steps_per_second": 9.067}, {"test_loss": 0.04789411276578903, "test_micro_f1": 0.7418147801683818, "test_micro_f1_no_misc": 0.7942887361184559, "test_runtime": 6.6596, "test_samples_per_second": 307.528, "test_steps_per_second": 9.61}, {"test_loss": 0.04903866723179817, "test_micro_f1": 0.7384907451352635, "test_micro_f1_no_misc": 0.7967567567567567, "test_runtime": 7.2409, "test_samples_per_second": 282.839, "test_steps_per_second": 8.839}]}, "total": {"test_micro_f1": 72.09788237925606, "test_micro_f1_se": 0.9410167627133715, "test_micro_f1_no_misc": 77.97152337108655, "test_micro_f1_no_misc_se": 0.8192165242383592}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.05966038256883621, "test_micro_f1": 0.7961557916034396, "test_micro_f1_no_misc": 0.8249744114636642, "test_runtime": 8.1167, "test_samples_per_second": 252.319, "test_steps_per_second": 7.885}, {"test_loss": 0.04943830519914627, "test_micro_f1": 0.8344519015659955, "test_micro_f1_no_misc": 0.8638392857142858, "test_runtime": 6.6855, "test_samples_per_second": 306.336, "test_steps_per_second": 9.573}, {"test_loss": 0.06137898191809654, "test_micro_f1": 0.7924427887174028, "test_micro_f1_no_misc": 0.827708703374778, "test_runtime": 8.1902, "test_samples_per_second": 250.054, "test_steps_per_second": 7.814}, {"test_loss": 0.05980115383863449, "test_micro_f1": 0.8104838709677419, "test_micro_f1_no_misc": 0.8448393711551606, "test_runtime": 7.9023, "test_samples_per_second": 259.166, "test_steps_per_second": 8.099}, {"test_loss": 0.060404546558856964, "test_micro_f1": 0.8088737201365187, "test_micro_f1_no_misc": 0.8326407253494522, "test_runtime": 8.1538, "test_samples_per_second": 251.17, "test_steps_per_second": 7.849}, {"test_loss": 0.057120632380247116, "test_micro_f1": 0.8302502720348205, "test_micro_f1_no_misc": 0.8570364854802681, "test_runtime": 8.0031, "test_samples_per_second": 255.902, "test_steps_per_second": 7.997}, {"test_loss": 0.05920785292983055, "test_micro_f1": 0.8137748344370861, "test_micro_f1_no_misc": 0.8376188798872843, "test_runtime": 8.2076, "test_samples_per_second": 249.525, "test_steps_per_second": 7.798}, {"test_loss": 0.055137112736701965, "test_micro_f1": 0.8158961881589619, "test_micro_f1_no_misc": 0.8487057965730951, "test_runtime": 8.0391, "test_samples_per_second": 254.755, "test_steps_per_second": 7.961}, {"test_loss": 0.05818743631243706, "test_micro_f1": 0.817773075905845, "test_micro_f1_no_misc": 0.8380255941499085, "test_runtime": 7.8191, "test_samples_per_second": 261.924, "test_steps_per_second": 8.185}, {"test_loss": 0.05449526757001877, "test_micro_f1": 0.8352469959946596, "test_micro_f1_no_misc": 0.8615494978479197, "test_runtime": 6.9808, "test_samples_per_second": 293.378, "test_steps_per_second": 9.168}]}, "total": {"test_micro_f1": 81.55349439522472, "test_micro_f1_se": 0.9123021134828854, "test_micro_f1_no_misc": 84.36938750995819, "test_micro_f1_no_misc_se": 0.8583986356212744}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.033347465097904205, "test_micro_f1": 0.8886438809261301, "test_micro_f1_no_misc": 0.9251870324189526, "test_runtime": 6.2775, "test_samples_per_second": 326.243, "test_steps_per_second": 10.195}, {"test_loss": 0.03082549199461937, "test_micro_f1": 0.8785954426596936, "test_micro_f1_no_misc": 0.9092422980849291, "test_runtime": 6.2748, "test_samples_per_second": 326.383, "test_steps_per_second": 10.199}, {"test_loss": 0.03668392822146416, "test_micro_f1": 0.8846153846153845, "test_micro_f1_no_misc": 0.9113320079522862, "test_runtime": 5.9213, "test_samples_per_second": 345.871, "test_steps_per_second": 10.808}, {"test_loss": 0.028717441484332085, "test_micro_f1": 0.8666666666666667, "test_micro_f1_no_misc": 0.8917748917748919, "test_runtime": 5.8129, "test_samples_per_second": 352.321, "test_steps_per_second": 11.01}, {"test_loss": 0.03331626206636429, "test_micro_f1": 0.8540972684876749, "test_micro_f1_no_misc": 0.8825046040515653, "test_runtime": 6.3773, "test_samples_per_second": 321.139, "test_steps_per_second": 10.036}, {"test_loss": 0.04263927415013313, "test_micro_f1": 0.8312646762831264, "test_micro_f1_no_misc": 0.868450810403317, "test_runtime": 6.3434, "test_samples_per_second": 322.853, "test_steps_per_second": 10.089}, {"test_loss": 0.02860836684703827, "test_micro_f1": 0.8908026179813986, "test_micro_f1_no_misc": 0.9142857142857143, "test_runtime": 5.9606, "test_samples_per_second": 343.589, "test_steps_per_second": 10.737}, {"test_loss": 0.030938761308789253, "test_micro_f1": 0.8956158663883089, "test_micro_f1_no_misc": 0.9176737160120847, "test_runtime": 5.7823, "test_samples_per_second": 354.183, "test_steps_per_second": 11.068}, {"test_loss": 0.03019569255411625, "test_micro_f1": 0.8949837603753158, "test_micro_f1_no_misc": 0.9166666666666666, "test_runtime": 5.9941, "test_samples_per_second": 341.671, "test_steps_per_second": 10.677}, {"test_loss": 0.03844952583312988, "test_micro_f1": 0.8977900552486188, "test_micro_f1_no_misc": 0.9229589881180529, "test_runtime": 6.3391, "test_samples_per_second": 323.073, "test_steps_per_second": 10.096}]}, "total": {"test_micro_f1": 87.8307561963232, "test_micro_f1_se": 1.3380993676857547, "test_micro_f1_no_misc": 90.6007672976846, "test_micro_f1_no_misc_se": 1.1646438026479706}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.03521794080734253, "test_micro_f1": 0.8572309589885908, "test_micro_f1_no_misc": 0.889500860585198, "test_runtime": 5.8694, "test_samples_per_second": 348.93, "test_steps_per_second": 10.904}, {"test_loss": 0.04172772169113159, "test_micro_f1": 0.8515031885818403, "test_micro_f1_no_misc": 0.8821731748726656, "test_runtime": 6.0131, "test_samples_per_second": 340.588, "test_steps_per_second": 10.643}, {"test_loss": 0.04517626762390137, "test_micro_f1": 0.8095815645845966, "test_micro_f1_no_misc": 0.8472873409243136, "test_runtime": 5.9219, "test_samples_per_second": 345.834, "test_steps_per_second": 10.807}, {"test_loss": 0.045345596969127655, "test_micro_f1": 0.8281622911694512, "test_micro_f1_no_misc": 0.8611670020120724, "test_runtime": 6.0619, "test_samples_per_second": 337.849, "test_steps_per_second": 10.558}, {"test_loss": 0.04884188249707222, "test_micro_f1": 0.8329268292682926, "test_micro_f1_no_misc": 0.8700173310225303, "test_runtime": 5.938, "test_samples_per_second": 344.895, "test_steps_per_second": 10.778}, {"test_loss": 0.04554406553506851, "test_micro_f1": 0.8335315101070154, "test_micro_f1_no_misc": 0.8660415271265909, "test_runtime": 6.0287, "test_samples_per_second": 339.71, "test_steps_per_second": 10.616}, {"test_loss": 0.04167906939983368, "test_micro_f1": 0.8142901139513397, "test_micro_f1_no_misc": 0.8507765023632682, "test_runtime": 6.0571, "test_samples_per_second": 338.116, "test_steps_per_second": 10.566}, {"test_loss": 0.040245406329631805, "test_micro_f1": 0.8388087196806878, "test_micro_f1_no_misc": 0.8657627118644068, "test_runtime": 6.0615, "test_samples_per_second": 337.868, "test_steps_per_second": 10.558}, {"test_loss": 0.046701718121767044, "test_micro_f1": 0.8290282902829028, "test_micro_f1_no_misc": 0.8645071403692093, "test_runtime": 5.538, "test_samples_per_second": 369.811, "test_steps_per_second": 11.557}, {"test_loss": 0.04168101027607918, "test_micro_f1": 0.8525700215450909, "test_micro_f1_no_misc": 0.8787675820495646, "test_runtime": 5.7649, "test_samples_per_second": 355.252, "test_steps_per_second": 11.102}]}, "total": {"test_micro_f1": 83.47633488159808, "test_micro_f1_se": 0.9806724964341158, "test_micro_f1_no_misc": 86.76001173189819, "test_micro_f1_no_misc_se": 0.8199193812597328}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.6872255802154541, "test_mcc": 0.09824861490078951, "test_macro_f1": 0.5490818085863434, "test_runtime": 3.2101, "test_samples_per_second": 637.992, "test_steps_per_second": 19.937}, {"test_loss": 0.6854349374771118, "test_mcc": 0.10880551326811214, "test_macro_f1": 0.5219925010164285, "test_runtime": 3.3815, "test_samples_per_second": 605.652, "test_steps_per_second": 18.927}, {"test_loss": 0.40158870816230774, "test_mcc": 0.6599847402065331, "test_macro_f1": 0.8221497739224932, "test_runtime": 3.3397, "test_samples_per_second": 613.23, "test_steps_per_second": 19.163}, {"test_loss": 0.48105889558792114, "test_mcc": 0.6600752494096849, "test_macro_f1": 0.8129252108835374, "test_runtime": 3.293, "test_samples_per_second": 621.917, "test_steps_per_second": 19.435}, {"test_loss": 0.4743390679359436, "test_mcc": 0.6399555165506162, "test_macro_f1": 0.8024555814429952, "test_runtime": 3.2735, "test_samples_per_second": 625.624, "test_steps_per_second": 19.551}, {"test_loss": 0.5134894847869873, "test_mcc": 0.6516519650799016, "test_macro_f1": 0.808928488128003, "test_runtime": 3.2411, "test_samples_per_second": 631.88, "test_steps_per_second": 19.746}, {"test_loss": 0.6881852746009827, "test_mcc": 0.0683436908216582, "test_macro_f1": 0.534163694279665, "test_runtime": 3.2876, "test_samples_per_second": 622.939, "test_steps_per_second": 19.467}, {"test_loss": 0.5054804086685181, "test_mcc": 0.5549107800841651, "test_macro_f1": 0.7596351021044905, "test_runtime": 3.297, "test_samples_per_second": 621.172, "test_steps_per_second": 19.412}, {"test_loss": 0.42787858843803406, "test_mcc": 0.6427181304982089, "test_macro_f1": 0.8062784746926294, "test_runtime": 3.2919, "test_samples_per_second": 622.129, "test_steps_per_second": 19.442}, {"test_loss": 0.5131969451904297, "test_mcc": 0.6339322328336108, "test_macro_f1": 0.7925299506694855, "test_runtime": 3.2696, "test_samples_per_second": 626.374, "test_steps_per_second": 19.574}]}, "total": {"test_mcc": 47.1862643365328, "test_mcc_se": 16.372146594804228, "test_macro_f1": 72.1014058572607, "test_macro_f1_se": 8.028220704421619}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.4562358558177948, "test_mcc": 0.5819030786262658, "test_macro_f1": 0.7859991952870243, "test_runtime": 3.7275, "test_samples_per_second": 549.437, "test_steps_per_second": 17.17}, {"test_loss": 0.48183608055114746, "test_mcc": 0.6281353675835065, "test_macro_f1": 0.7943296268265705, "test_runtime": 3.7967, "test_samples_per_second": 539.409, "test_steps_per_second": 16.857}, {"test_loss": 0.4934636950492859, "test_mcc": 0.5782196857543129, "test_macro_f1": 0.7660128498208237, "test_runtime": 3.7446, "test_samples_per_second": 546.919, "test_steps_per_second": 17.091}, {"test_loss": 0.48115187883377075, "test_mcc": 0.6190385598967475, "test_macro_f1": 0.7882456250392023, "test_runtime": 3.8424, "test_samples_per_second": 533.004, "test_steps_per_second": 16.656}, {"test_loss": 0.5014707446098328, "test_mcc": 0.6020151364177665, "test_macro_f1": 0.7801183152424819, "test_runtime": 3.6711, "test_samples_per_second": 557.872, "test_steps_per_second": 17.433}, {"test_loss": 0.5028103590011597, "test_mcc": 0.5682511341506673, "test_macro_f1": 0.7539048224358466, "test_runtime": 3.6658, "test_samples_per_second": 558.679, "test_steps_per_second": 17.459}, {"test_loss": 0.7003996968269348, "test_mcc": 0.009608873618470673, "test_macro_f1": 0.501185836066516, "test_runtime": 3.5818, "test_samples_per_second": 571.779, "test_steps_per_second": 17.868}, {"test_loss": 0.47504615783691406, "test_mcc": 0.624220523933039, "test_macro_f1": 0.7987546699875467, "test_runtime": 3.69, "test_samples_per_second": 555.013, "test_steps_per_second": 17.344}, {"test_loss": 0.43720558285713196, "test_mcc": 0.6625197616135544, "test_macro_f1": 0.8190742466604536, "test_runtime": 3.6804, "test_samples_per_second": 556.462, "test_steps_per_second": 17.389}, {"test_loss": 0.4672990143299103, "test_mcc": 0.6254640746726089, "test_macro_f1": 0.7940076885702839, "test_runtime": 3.7368, "test_samples_per_second": 548.059, "test_steps_per_second": 17.127}]}, "total": {"test_mcc": 54.99376196266938, "test_mcc_se": 11.897324385185575, "test_macro_f1": 75.8163287593675, "test_macro_f1_se": 5.704224830926555}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.4534042477607727, "test_mcc": 0.6617012938666443, "test_macro_f1": 0.8051405294850205, "test_runtime": 3.3414, "test_samples_per_second": 612.921, "test_steps_per_second": 19.154}, {"test_loss": 0.43443921208381653, "test_mcc": 0.712314517257928, "test_macro_f1": 0.8429138735484468, "test_runtime": 3.31, "test_samples_per_second": 618.723, "test_steps_per_second": 19.335}, {"test_loss": 0.4930807948112488, "test_mcc": 0.6531464747032446, "test_macro_f1": 0.7998068332025129, "test_runtime": 3.3459, "test_samples_per_second": 612.096, "test_steps_per_second": 19.128}, {"test_loss": 0.49491405487060547, "test_mcc": 0.6021009703049361, "test_macro_f1": 0.7658521778115941, "test_runtime": 3.4128, "test_samples_per_second": 600.09, "test_steps_per_second": 18.753}, {"test_loss": 0.4451643228530884, "test_mcc": 0.7045243550695116, "test_macro_f1": 0.8380889467031789, "test_runtime": 3.432, "test_samples_per_second": 596.738, "test_steps_per_second": 18.648}, {"test_loss": 0.51189124584198, "test_mcc": 0.607195320256209, "test_macro_f1": 0.7789971617786187, "test_runtime": 3.246, "test_samples_per_second": 630.927, "test_steps_per_second": 19.716}, {"test_loss": 0.42421841621398926, "test_mcc": 0.6491069817672288, "test_macro_f1": 0.8103399280105303, "test_runtime": 3.3034, "test_samples_per_second": 619.963, "test_steps_per_second": 19.374}, {"test_loss": 0.6770734190940857, "test_mcc": 0.17812714560259435, "test_macro_f1": 0.585758832150894, "test_runtime": 3.2855, "test_samples_per_second": 623.343, "test_steps_per_second": 19.479}, {"test_loss": 0.49231696128845215, "test_mcc": 0.661174516995343, "test_macro_f1": 0.8100068031418146, "test_runtime": 3.304, "test_samples_per_second": 619.858, "test_steps_per_second": 19.371}, {"test_loss": 0.6869521141052246, "test_mcc": 0.06847863097023547, "test_macro_f1": 0.5302752293577981, "test_runtime": 3.3507, "test_samples_per_second": 611.221, "test_steps_per_second": 19.101}]}, "total": {"test_mcc": 54.978702067938755, "test_mcc_se": 14.188915950564896, "test_macro_f1": 75.6718031519041, "test_macro_f1_se": 6.696284723421525}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_loss": 0.5232887268066406, "test_mcc": 0.5383396078359581, "test_macro_f1": 0.7454025863540916, "test_runtime": 3.5712, "test_samples_per_second": 573.473, "test_steps_per_second": 17.921}, {"test_loss": 0.45971161127090454, "test_mcc": 0.6330729117234505, "test_macro_f1": 0.7934535573062204, "test_runtime": 3.6356, "test_samples_per_second": 563.311, "test_steps_per_second": 17.603}, {"test_loss": 0.4959073066711426, "test_mcc": 0.6035370861164111, "test_macro_f1": 0.7760618424722245, "test_runtime": 3.6583, "test_samples_per_second": 559.823, "test_steps_per_second": 17.494}, {"test_loss": 0.41342777013778687, "test_mcc": 0.6571450547761318, "test_macro_f1": 0.8182072430619648, "test_runtime": 3.4622, "test_samples_per_second": 591.527, "test_steps_per_second": 18.485}, {"test_loss": 0.4199860394001007, "test_mcc": 0.67819406798057, "test_macro_f1": 0.8247144763149348, "test_runtime": 3.5033, "test_samples_per_second": 584.587, "test_steps_per_second": 18.268}, {"test_loss": 0.4594587981700897, "test_mcc": 0.628043683005866, "test_macro_f1": 0.8125327496124104, "test_runtime": 3.6159, "test_samples_per_second": 566.387, "test_steps_per_second": 17.7}, {"test_loss": 0.4416661262512207, "test_mcc": 0.6485341685296848, "test_macro_f1": 0.8147783251231527, "test_runtime": 3.5004, "test_samples_per_second": 585.08, "test_steps_per_second": 18.284}, {"test_loss": 0.4140270948410034, "test_mcc": 0.6655784290469762, "test_macro_f1": 0.8235681864162361, "test_runtime": 3.5559, "test_samples_per_second": 575.943, "test_steps_per_second": 17.998}, {"test_loss": 0.6876538395881653, "test_mcc": 0.09590458286820969, "test_macro_f1": 0.5478265767889243, "test_runtime": 3.5226, "test_samples_per_second": 581.395, "test_steps_per_second": 18.169}, {"test_loss": 0.40687376260757446, "test_mcc": 0.6845745196364312, "test_macro_f1": 0.8316106053458453, "test_runtime": 3.6149, "test_samples_per_second": 566.537, "test_steps_per_second": 17.704}]}, "total": {"test_mcc": 58.32924111519689, "test_mcc_se": 10.936346281111293, "test_macro_f1": 77.88156148796006, "test_macro_f1_se": 5.290503172896708}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_em": 36.405886909372576, "test_f1": 41.02663572488241}, {"test_em": 40.310077519379846, "test_f1": 44.54631704093143}, {"test_em": 37.480680061823804, "test_f1": 42.515571961514425}, {"test_em": 38.70716510903427, "test_f1": 43.63009849678348}, {"test_em": 40.30888030888031, "test_f1": 44.667609081325594}, {"test_em": 43.87047031611411, "test_f1": 47.613739166371886}, {"test_em": 40.546697038724375, "test_f1": 44.716475353523386}, {"test_em": 40.108611326609775, "test_f1": 44.374397107724135}, {"test_em": 38.745098039215684, "test_f1": 43.216319952607}, {"test_em": 31.133540372670808, "test_f1": 35.56197867002654}]}, "total": {"test_em": 38.76171070018256, "test_em_se": 2.0791412838840593, "test_f1": 43.18691425556903, "test_f1_se": 1.9691396003315713}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_em": 40.43377226955848, "test_f1": 45.33954615336676}, {"test_em": 38.75968992248062, "test_f1": 43.7274308458879}, {"test_em": 37.17156105100464, "test_f1": 42.13751293329571}, {"test_em": 40.57632398753894, "test_f1": 44.79773903531535}, {"test_em": 38.91891891891892, "test_f1": 43.570029191435644}, {"test_em": 40.01542020046261, "test_f1": 44.79290435850576}, {"test_em": 33.10554290053151, "test_f1": 38.02633328397275}, {"test_em": 32.73855702094647, "test_f1": 37.44909997262081}, {"test_em": 36.627450980392155, "test_f1": 41.51586778425244}, {"test_em": 33.38509316770186, "test_f1": 38.608056023319335}]}, "total": {"test_em": 37.17323304195362, "test_em_se": 1.9238950126648613, "test_f1": 41.99645195819725, "test_f1_se": 1.8535379404882792}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_em": 41.673121611154144, "test_f1": 46.31903798303579}, {"test_em": 40.85271317829457, "test_f1": 45.18079303810456}, {"test_em": 38.33075734157651, "test_f1": 42.92288119376469}, {"test_em": 39.875389408099686, "test_f1": 44.389342989178445}, {"test_em": 38.53281853281853, "test_f1": 42.95395001362924}, {"test_em": 39.244410177332306, "test_f1": 43.14196391315295}, {"test_em": 37.88914198936978, "test_f1": 43.0832844833141}, {"test_em": 38.86733902249806, "test_f1": 43.913489364713634}, {"test_em": 42.11764705882353, "test_f1": 46.9663106933985}, {"test_em": 36.49068322981366, "test_f1": 40.85935016098901}]}, "total": {"test_em": 39.387402154978076, "test_em_se": 1.090058942685219, "test_f1": 43.97304038332809, "test_f1_se": 1.1205703287699817}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.7451680898666382, "test_mcc": 0.5199369509942637, "test_macro_f1": 0.5126905301235363, "test_runtime": 6.138, "test_samples_per_second": 333.657, "test_steps_per_second": 10.427}, {"test_loss": 0.7429503202438354, "test_mcc": 0.5199857592814692, "test_macro_f1": 0.5103122769771445, "test_runtime": 6.0276, "test_samples_per_second": 339.772, "test_steps_per_second": 10.618}, {"test_loss": 0.7306475043296814, "test_mcc": 0.5134561069840274, "test_macro_f1": 0.5115584770026019, "test_runtime": 6.2304, "test_samples_per_second": 328.709, "test_steps_per_second": 10.272}, {"test_loss": 0.7112200260162354, "test_mcc": 0.5387922678811798, "test_macro_f1": 0.5214037994525799, "test_runtime": 6.0318, "test_samples_per_second": 339.536, "test_steps_per_second": 10.611}, {"test_loss": 0.720223069190979, "test_mcc": 0.5321102111067737, "test_macro_f1": 0.519205171801214, "test_runtime": 5.8678, "test_samples_per_second": 349.023, "test_steps_per_second": 10.907}, {"test_loss": 0.7482074499130249, "test_mcc": 0.515336927537085, "test_macro_f1": 0.5116865401987353, "test_runtime": 6.1563, "test_samples_per_second": 332.67, "test_steps_per_second": 10.396}, {"test_loss": 0.6796048879623413, "test_mcc": 0.590854928640124, "test_macro_f1": 0.540261630340849, "test_runtime": 5.8624, "test_samples_per_second": 349.344, "test_steps_per_second": 10.917}, {"test_loss": 0.7234240770339966, "test_mcc": 0.536931088397435, "test_macro_f1": 0.518471520426387, "test_runtime": 6.2507, "test_samples_per_second": 327.642, "test_steps_per_second": 10.239}, {"test_loss": 0.7293626070022583, "test_mcc": 0.5446401891677938, "test_macro_f1": 0.5237279581848253, "test_runtime": 6.1941, "test_samples_per_second": 330.64, "test_steps_per_second": 10.332}, {"test_loss": 0.7043616771697998, "test_mcc": 0.5579205208185504, "test_macro_f1": 0.5287852201509029, "test_runtime": 6.1432, "test_samples_per_second": 333.377, "test_steps_per_second": 10.418}]}, "total": {"test_mcc": 53.69964950808701, "test_mcc_se": 1.4649470802189735, "test_macro_f1": 51.98103124658775, "test_macro_f1_se": 0.5821062593035741}}, "num_model_parameters": 13014875, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 1.0254026651382446, "test_mcc": 0.35721458336483375, "test_macro_f1": 0.5685961672468127, "test_runtime": 2.4366, "test_samples_per_second": 840.514, "test_steps_per_second": 26.266}, {"test_loss": 0.9677945375442505, "test_mcc": 0.35654909423107056, "test_macro_f1": 0.5603044947847612, "test_runtime": 2.4244, "test_samples_per_second": 844.735, "test_steps_per_second": 26.398}, {"test_loss": 0.9873011708259583, "test_mcc": 0.2681431655942835, "test_macro_f1": 0.45281018648282795, "test_runtime": 2.4328, "test_samples_per_second": 841.841, "test_steps_per_second": 26.308}, {"test_loss": 0.9549570083618164, "test_mcc": 0.3526409923887197, "test_macro_f1": 0.5675172667302393, "test_runtime": 2.4091, "test_samples_per_second": 850.11, "test_steps_per_second": 26.566}, {"test_loss": 0.9781023263931274, "test_mcc": 0.25388177005249346, "test_macro_f1": 0.40822180669327635, "test_runtime": 2.4239, "test_samples_per_second": 844.916, "test_steps_per_second": 26.404}, {"test_loss": 0.9967801570892334, "test_mcc": 0.3181990817258167, "test_macro_f1": 0.5362105491570293, "test_runtime": 2.3963, "test_samples_per_second": 854.657, "test_steps_per_second": 26.708}, {"test_loss": 0.9731016755104065, "test_mcc": 0.2733582393075924, "test_macro_f1": 0.41629733780697714, "test_runtime": 2.4144, "test_samples_per_second": 848.254, "test_steps_per_second": 26.508}, {"test_loss": 1.0092543363571167, "test_mcc": 0.2510800437414014, "test_macro_f1": 0.3964896638980426, "test_runtime": 2.4229, "test_samples_per_second": 845.272, "test_steps_per_second": 26.415}, {"test_loss": 1.0189234018325806, "test_mcc": 0.28062439156449004, "test_macro_f1": 0.4731122170559921, "test_runtime": 2.4655, "test_samples_per_second": 830.657, "test_steps_per_second": 25.958}, {"test_loss": 1.0139880180358887, "test_mcc": 0.24032554973724848, "test_macro_f1": 0.4015688720406816, "test_runtime": 2.3949, "test_samples_per_second": 855.152, "test_steps_per_second": 26.723}]}, "total": {"test_mcc": 29.520169117079497, "test_mcc_se": 2.8868537394262863, "test_macro_f1": 47.8112856189664, "test_macro_f1_se": 4.536018627772652}}, "num_model_parameters": 13014875, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.9101234078407288, "test_mcc": 0.3251918760012086, "test_macro_f1": 0.4311314369497799, "test_runtime": 2.3081, "test_samples_per_second": 887.321, "test_steps_per_second": 27.729}, {"test_loss": 0.8854242563247681, "test_mcc": 0.34576020251135486, "test_macro_f1": 0.44172783914792113, "test_runtime": 2.248, "test_samples_per_second": 911.047, "test_steps_per_second": 28.47}, {"test_loss": 0.8992820978164673, "test_mcc": 0.2741308764364558, "test_macro_f1": 0.40688474039924577, "test_runtime": 2.271, "test_samples_per_second": 901.817, "test_steps_per_second": 28.182}, {"test_loss": 0.9097393155097961, "test_mcc": 0.3181168495481807, "test_macro_f1": 0.42957830614952747, "test_runtime": 2.2962, "test_samples_per_second": 891.909, "test_steps_per_second": 27.872}, {"test_loss": 0.9120239615440369, "test_mcc": 0.32889266973745707, "test_macro_f1": 0.43137745696014873, "test_runtime": 2.2872, "test_samples_per_second": 895.406, "test_steps_per_second": 27.981}, {"test_loss": 0.9226541519165039, "test_mcc": 0.2979355404079826, "test_macro_f1": 0.423132491863142, "test_runtime": 2.3301, "test_samples_per_second": 878.945, "test_steps_per_second": 27.467}, {"test_loss": 0.8913677334785461, "test_mcc": 0.33904682313239776, "test_macro_f1": 0.4376808479350249, "test_runtime": 2.2743, "test_samples_per_second": 900.5, "test_steps_per_second": 28.141}, {"test_loss": 0.8905529975891113, "test_mcc": 0.3640195579280102, "test_macro_f1": 0.4491401880627455, "test_runtime": 2.2637, "test_samples_per_second": 904.704, "test_steps_per_second": 28.272}, {"test_loss": 0.930988073348999, "test_mcc": 0.3224300186356973, "test_macro_f1": 0.42580458584896047, "test_runtime": 2.3013, "test_samples_per_second": 889.919, "test_steps_per_second": 27.81}, {"test_loss": 0.8933501839637756, "test_mcc": 0.3335213860589483, "test_macro_f1": 0.43566189035606134, "test_runtime": 2.3019, "test_samples_per_second": 889.687, "test_steps_per_second": 27.803}]}, "total": {"test_mcc": 32.49045800397693, "test_mcc_se": 1.547817277395904, "test_macro_f1": 43.12119783672557, "test_macro_f1_se": 0.7105093205891247}}, "num_model_parameters": 13014875, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.10576459020376205, "test_micro_f1": 0.46977730646871685, "test_micro_f1_no_misc": 0.5097115950559152, "test_runtime": 4.213, "test_samples_per_second": 486.118, "test_steps_per_second": 15.191}, {"test_loss": 0.09940516948699951, "test_micro_f1": 0.5153970826580226, "test_micro_f1_no_misc": 0.5512744516893895, "test_runtime": 4.1495, "test_samples_per_second": 493.55, "test_steps_per_second": 15.423}, {"test_loss": 0.09895949065685272, "test_micro_f1": 0.5192697768762677, "test_micro_f1_no_misc": 0.5525885558583106, "test_runtime": 4.1179, "test_samples_per_second": 497.345, "test_steps_per_second": 15.542}, {"test_loss": 0.09944107383489609, "test_micro_f1": 0.5227391531625719, "test_micro_f1_no_misc": 0.5579831932773109, "test_runtime": 3.9926, "test_samples_per_second": 512.955, "test_steps_per_second": 16.03}, {"test_loss": 0.10333233326673508, "test_micro_f1": 0.5156794425087109, "test_micro_f1_no_misc": 0.5525164113785558, "test_runtime": 4.2635, "test_samples_per_second": 480.356, "test_steps_per_second": 15.011}, {"test_loss": 0.10252167284488678, "test_micro_f1": 0.5190913484775254, "test_micro_f1_no_misc": 0.5635478637101136, "test_runtime": 3.751, "test_samples_per_second": 545.989, "test_steps_per_second": 17.062}, {"test_loss": 0.10583165287971497, "test_micro_f1": 0.5110887096774194, "test_micro_f1_no_misc": 0.5569904548006739, "test_runtime": 3.9651, "test_samples_per_second": 516.505, "test_steps_per_second": 16.141}, {"test_loss": 0.08922794461250305, "test_micro_f1": 0.5320366132723112, "test_micro_f1_no_misc": 0.5623471882640587, "test_runtime": 4.1857, "test_samples_per_second": 489.285, "test_steps_per_second": 15.29}, {"test_loss": 0.09722991287708282, "test_micro_f1": 0.5104008117706748, "test_micro_f1_no_misc": 0.5430752453653218, "test_runtime": 4.0436, "test_samples_per_second": 506.48, "test_steps_per_second": 15.827}, {"test_loss": 0.10024446994066238, "test_micro_f1": 0.5213890286864621, "test_micro_f1_no_misc": 0.5562194459532863, "test_runtime": 4.0106, "test_samples_per_second": 510.649, "test_steps_per_second": 15.958}]}, "total": {"test_micro_f1": 51.36869273558682, "test_micro_f1_se": 1.0311187568046327, "test_micro_f1_no_misc": 55.06254405352936, "test_micro_f1_no_misc_se": 0.9622272009811252}}, "num_model_parameters": 12950625, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.08300676941871643, "test_micro_f1": 0.7141762452107279, "test_micro_f1_no_misc": 0.7517146776406035, "test_runtime": 4.5849, "test_samples_per_second": 446.683, "test_steps_per_second": 13.959}, {"test_loss": 0.07863686978816986, "test_micro_f1": 0.7435826662986477, "test_micro_f1_no_misc": 0.771397616468039, "test_runtime": 3.8402, "test_samples_per_second": 533.307, "test_steps_per_second": 16.666}, {"test_loss": 0.07871751487255096, "test_micro_f1": 0.7458355722729716, "test_micro_f1_no_misc": 0.7821782178217822, "test_runtime": 4.3451, "test_samples_per_second": 471.337, "test_steps_per_second": 14.729}, {"test_loss": 0.08166225254535675, "test_micro_f1": 0.738830737809548, "test_micro_f1_no_misc": 0.7739463601532567, "test_runtime": 4.298, "test_samples_per_second": 476.506, "test_steps_per_second": 14.891}, {"test_loss": 0.08329513669013977, "test_micro_f1": 0.7110104726861024, "test_micro_f1_no_misc": 0.7521888085268367, "test_runtime": 4.3913, "test_samples_per_second": 466.372, "test_steps_per_second": 14.574}, {"test_loss": 0.08306850492954254, "test_micro_f1": 0.7358594179022515, "test_micro_f1_no_misc": 0.7661909989023051, "test_runtime": 4.4164, "test_samples_per_second": 463.725, "test_steps_per_second": 14.491}, {"test_loss": 0.07532995939254761, "test_micro_f1": 0.752375923970433, "test_micro_f1_no_misc": 0.7807786741494213, "test_runtime": 4.5034, "test_samples_per_second": 454.769, "test_steps_per_second": 14.212}, {"test_loss": 0.07831545174121857, "test_micro_f1": 0.7317205762435444, "test_micro_f1_no_misc": 0.7681834467932641, "test_runtime": 4.4835, "test_samples_per_second": 456.784, "test_steps_per_second": 14.274}, {"test_loss": 0.07973966002464294, "test_micro_f1": 0.7335640138408305, "test_micro_f1_no_misc": 0.7617328519855596, "test_runtime": 4.2953, "test_samples_per_second": 476.804, "test_steps_per_second": 14.9}, {"test_loss": 0.07739774882793427, "test_micro_f1": 0.750797024442083, "test_micro_f1_no_misc": 0.7800289435600579, "test_runtime": 3.9668, "test_samples_per_second": 516.283, "test_steps_per_second": 16.134}]}, "total": {"test_micro_f1": 73.5775265067714, "test_micro_f1_se": 0.8701571411908009, "test_micro_f1_no_misc": 76.88340596001126, "test_micro_f1_no_misc_se": 0.6873200441710547}}, "num_model_parameters": 12950625, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.06435564160346985, "test_micro_f1": 0.7092813289996389, "test_micro_f1_no_misc": 0.7420127795527157, "test_runtime": 3.813, "test_samples_per_second": 537.103, "test_steps_per_second": 16.784}, {"test_loss": 0.06676691770553589, "test_micro_f1": 0.7075575027382256, "test_micro_f1_no_misc": 0.7451768488745981, "test_runtime": 3.9097, "test_samples_per_second": 523.83, "test_steps_per_second": 16.37}, {"test_loss": 0.06622852385044098, "test_micro_f1": 0.7191249117854623, "test_micro_f1_no_misc": 0.7536679536679536, "test_runtime": 3.8264, "test_samples_per_second": 535.223, "test_steps_per_second": 16.726}, {"test_loss": 0.06676534563302994, "test_micro_f1": 0.7320490367775833, "test_micro_f1_no_misc": 0.7601078167115903, "test_runtime": 3.8847, "test_samples_per_second": 527.203, "test_steps_per_second": 16.475}, {"test_loss": 0.062359705567359924, "test_micro_f1": 0.741424802110818, "test_micro_f1_no_misc": 0.7780584626488632, "test_runtime": 4.0291, "test_samples_per_second": 508.305, "test_steps_per_second": 15.885}, {"test_loss": 0.06377986073493958, "test_micro_f1": 0.7533356140951077, "test_micro_f1_no_misc": 0.7873303167420815, "test_runtime": 3.8354, "test_samples_per_second": 533.97, "test_steps_per_second": 16.687}, {"test_loss": 0.0694349929690361, "test_micro_f1": 0.6964467005076143, "test_micro_f1_no_misc": 0.727475800446761, "test_runtime": 3.7527, "test_samples_per_second": 545.738, "test_steps_per_second": 17.054}, {"test_loss": 0.0669785887002945, "test_micro_f1": 0.732625813077713, "test_micro_f1_no_misc": 0.7604702424687729, "test_runtime": 3.8169, "test_samples_per_second": 536.565, "test_steps_per_second": 16.768}, {"test_loss": 0.06086526811122894, "test_micro_f1": 0.7396679618509361, "test_micro_f1_no_misc": 0.7754783287778212, "test_runtime": 3.89, "test_samples_per_second": 526.484, "test_steps_per_second": 16.453}, {"test_loss": 0.06813022494316101, "test_micro_f1": 0.7462482946793997, "test_micro_f1_no_misc": 0.7771514468245021, "test_runtime": 4.0492, "test_samples_per_second": 505.781, "test_steps_per_second": 15.806}]}, "total": {"test_micro_f1": 72.77761966622498, "test_micro_f1_se": 1.163449728206461, "test_micro_f1_no_misc": 76.0692999671566, "test_micro_f1_no_misc_se": 1.176620433930873}}, "num_model_parameters": 12950625, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.08008672297000885, "test_micro_f1": 0.6603042051893826, "test_micro_f1_no_misc": 0.705805182026894, "test_runtime": 4.0786, "test_samples_per_second": 502.135, "test_steps_per_second": 15.692}, {"test_loss": 0.085228331387043, "test_micro_f1": 0.6712907117008443, "test_micro_f1_no_misc": 0.7063098777667658, "test_runtime": 4.1472, "test_samples_per_second": 493.83, "test_steps_per_second": 15.432}, {"test_loss": 0.08264333009719849, "test_micro_f1": 0.6359281437125749, "test_micro_f1_no_misc": 0.6786286446651715, "test_runtime": 4.0507, "test_samples_per_second": 505.597, "test_steps_per_second": 15.8}, {"test_loss": 0.08743176609277725, "test_micro_f1": 0.7033033033033033, "test_micro_f1_no_misc": 0.7468269873079492, "test_runtime": 4.0704, "test_samples_per_second": 503.142, "test_steps_per_second": 15.723}, {"test_loss": 0.08854862302541733, "test_micro_f1": 0.6654687032045522, "test_micro_f1_no_misc": 0.7138024357239512, "test_runtime": 3.9432, "test_samples_per_second": 519.375, "test_steps_per_second": 16.23}, {"test_loss": 0.08313640207052231, "test_micro_f1": 0.6940119760479042, "test_micro_f1_no_misc": 0.7320653987320656, "test_runtime": 3.9162, "test_samples_per_second": 522.954, "test_steps_per_second": 16.342}, {"test_loss": 0.07746090739965439, "test_micro_f1": 0.6547911547911548, "test_micro_f1_no_misc": 0.7030625832223703, "test_runtime": 4.1299, "test_samples_per_second": 495.891, "test_steps_per_second": 15.497}, {"test_loss": 0.07898721098899841, "test_micro_f1": 0.6686856450635978, "test_micro_f1_no_misc": 0.7070641607258589, "test_runtime": 4.159, "test_samples_per_second": 492.422, "test_steps_per_second": 15.388}, {"test_loss": 0.08262166380882263, "test_micro_f1": 0.6674884437596302, "test_micro_f1_no_misc": 0.7109295199182839, "test_runtime": 3.809, "test_samples_per_second": 537.675, "test_steps_per_second": 16.802}, {"test_loss": 0.08549223095178604, "test_micro_f1": 0.6520012221203788, "test_micro_f1_no_misc": 0.6897220426632191, "test_runtime": 3.8963, "test_samples_per_second": 525.631, "test_steps_per_second": 16.426}]}, "total": {"test_micro_f1": 66.73273508893324, "test_micro_f1_se": 1.2143309154606308, "test_micro_f1_no_misc": 70.9421683275253, "test_micro_f1_no_misc_se": 1.1937250573875906}}, "num_model_parameters": 12950625, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6790580153465271, "test_mcc": 0.1276670492174249, "test_macro_f1": 0.5518664502666357, "test_runtime": 2.2183, "test_samples_per_second": 923.223, "test_steps_per_second": 28.851}, {"test_loss": 0.6713622808456421, "test_mcc": 0.17794476795984038, "test_macro_f1": 0.5832420969073795, "test_runtime": 2.2613, "test_samples_per_second": 905.682, "test_steps_per_second": 28.303}, {"test_loss": 0.6761621236801147, "test_mcc": 0.1633738490822997, "test_macro_f1": 0.5779389569515343, "test_runtime": 2.2467, "test_samples_per_second": 911.56, "test_steps_per_second": 28.486}, {"test_loss": 0.6745116710662842, "test_mcc": 0.1832609588064557, "test_macro_f1": 0.5897497902663935, "test_runtime": 2.198, "test_samples_per_second": 931.74, "test_steps_per_second": 29.117}, {"test_loss": 0.6882709264755249, "test_mcc": 0.10254253511762988, "test_macro_f1": 0.5458854044142041, "test_runtime": 2.2325, "test_samples_per_second": 917.378, "test_steps_per_second": 28.668}, {"test_loss": 0.6884965300559998, "test_mcc": 0.11227884041380157, "test_macro_f1": 0.5526792211264009, "test_runtime": 2.2456, "test_samples_per_second": 911.995, "test_steps_per_second": 28.5}, {"test_loss": 0.6894906163215637, "test_mcc": 0.08330090027970474, "test_macro_f1": 0.5293952344710497, "test_runtime": 2.2415, "test_samples_per_second": 913.672, "test_steps_per_second": 28.552}, {"test_loss": 0.6733560562133789, "test_mcc": 0.16839954420035094, "test_macro_f1": 0.5547354854776951, "test_runtime": 2.2208, "test_samples_per_second": 922.172, "test_steps_per_second": 28.818}, {"test_loss": 0.6817866563796997, "test_mcc": 0.10442498687928421, "test_macro_f1": 0.5511415459561375, "test_runtime": 2.2253, "test_samples_per_second": 920.328, "test_steps_per_second": 28.76}, {"test_loss": 0.6921047568321228, "test_mcc": 0.015257677300482546, "test_macro_f1": 0.481725060876215, "test_runtime": 2.2461, "test_samples_per_second": 911.808, "test_steps_per_second": 28.494}]}, "total": {"test_mcc": 12.384511092572744, "test_mcc_se": 3.228486517135814, "test_macro_f1": 55.18359246713646, "test_macro_f1_se": 1.9125272224270122}}, "num_model_parameters": 13014618, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.4974551200866699, "test_mcc": 0.5583844222251699, "test_macro_f1": 0.7777471812994324, "test_runtime": 2.2276, "test_samples_per_second": 919.385, "test_steps_per_second": 28.731}, {"test_loss": 0.5260303020477295, "test_mcc": 0.5770478996156645, "test_macro_f1": 0.7803810254479975, "test_runtime": 2.2087, "test_samples_per_second": 927.258, "test_steps_per_second": 28.977}, {"test_loss": 0.4534320533275604, "test_mcc": 0.6202538264036951, "test_macro_f1": 0.8082490918047804, "test_runtime": 2.201, "test_samples_per_second": 930.48, "test_steps_per_second": 29.077}, {"test_loss": 0.4779922366142273, "test_mcc": 0.5868744390094256, "test_macro_f1": 0.7912993555609777, "test_runtime": 2.2442, "test_samples_per_second": 912.584, "test_steps_per_second": 28.518}, {"test_loss": 0.5254265069961548, "test_mcc": 0.5333849761975057, "test_macro_f1": 0.7522621683896407, "test_runtime": 2.2259, "test_samples_per_second": 920.075, "test_steps_per_second": 28.752}, {"test_loss": 0.4944056272506714, "test_mcc": 0.5617489863213948, "test_macro_f1": 0.779039138134748, "test_runtime": 2.2047, "test_samples_per_second": 928.945, "test_steps_per_second": 29.03}, {"test_loss": 0.5221742391586304, "test_mcc": 0.5260604073255594, "test_macro_f1": 0.7609431539628808, "test_runtime": 2.1988, "test_samples_per_second": 931.431, "test_steps_per_second": 29.107}, {"test_loss": 0.4582507610321045, "test_mcc": 0.6187025724248127, "test_macro_f1": 0.805899367402198, "test_runtime": 2.2073, "test_samples_per_second": 927.843, "test_steps_per_second": 28.995}, {"test_loss": 0.5149353742599487, "test_mcc": 0.5441858218190398, "test_macro_f1": 0.7716498642074792, "test_runtime": 2.2234, "test_samples_per_second": 921.108, "test_steps_per_second": 28.785}, {"test_loss": 0.4798084795475006, "test_mcc": 0.5830657173147197, "test_macro_f1": 0.7863420354921451, "test_runtime": 2.2414, "test_samples_per_second": 913.711, "test_steps_per_second": 28.553}]}, "total": {"test_mcc": 57.09709068656987, "test_mcc_se": 2.0172891583229653, "test_macro_f1": 78.13812381702279, "test_macro_f1_se": 1.0983048603752235}}, "num_model_parameters": 13014618, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6023616790771484, "test_mcc": 0.37175369058305996, "test_macro_f1": 0.6834521652112857, "test_runtime": 2.2278, "test_samples_per_second": 919.296, "test_steps_per_second": 28.728}, {"test_loss": 0.5982038378715515, "test_mcc": 0.40473336593317777, "test_macro_f1": 0.6942280436656341, "test_runtime": 2.2553, "test_samples_per_second": 908.077, "test_steps_per_second": 28.377}, {"test_loss": 0.6114257574081421, "test_mcc": 0.35437699152949315, "test_macro_f1": 0.6663100370567964, "test_runtime": 2.235, "test_samples_per_second": 916.315, "test_steps_per_second": 28.635}, {"test_loss": 0.5840758085250854, "test_mcc": 0.4291634987417575, "test_macro_f1": 0.7029838480268132, "test_runtime": 2.2385, "test_samples_per_second": 914.911, "test_steps_per_second": 28.591}, {"test_loss": 0.6292928457260132, "test_mcc": 0.320801611247061, "test_macro_f1": 0.6544523158454407, "test_runtime": 2.2598, "test_samples_per_second": 906.272, "test_steps_per_second": 28.321}, {"test_loss": 0.605222225189209, "test_mcc": 0.33630478271132613, "test_macro_f1": 0.6638886592850015, "test_runtime": 2.2162, "test_samples_per_second": 924.108, "test_steps_per_second": 28.878}, {"test_loss": 0.6255171298980713, "test_mcc": 0.32099644143412104, "test_macro_f1": 0.6561888553135817, "test_runtime": 2.2465, "test_samples_per_second": 911.65, "test_steps_per_second": 28.489}, {"test_loss": 0.6197596788406372, "test_mcc": 0.3299557917107385, "test_macro_f1": 0.6507595561397251, "test_runtime": 2.252, "test_samples_per_second": 909.398, "test_steps_per_second": 28.419}, {"test_loss": 0.6306743025779724, "test_mcc": 0.3124594524024122, "test_macro_f1": 0.6482758620689655, "test_runtime": 2.2347, "test_samples_per_second": 916.465, "test_steps_per_second": 28.64}, {"test_loss": 0.624192476272583, "test_mcc": 0.36265150972535737, "test_macro_f1": 0.6635426438351504, "test_runtime": 2.2442, "test_samples_per_second": 912.555, "test_steps_per_second": 28.517}]}, "total": {"test_mcc": 35.43197136018505, "test_mcc_se": 2.3934497038059224, "test_macro_f1": 66.84081986448393, "test_macro_f1_se": 1.1683214172194396}}, "num_model_parameters": 13014618, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6598502397537231, "test_mcc": 0.22588707354529963, "test_macro_f1": 0.6122677104673832, "test_runtime": 2.3249, "test_samples_per_second": 880.91, "test_steps_per_second": 27.528}, {"test_loss": 0.6472321152687073, "test_mcc": 0.2521614700630155, "test_macro_f1": 0.6213663402376676, "test_runtime": 2.4023, "test_samples_per_second": 852.52, "test_steps_per_second": 26.641}, {"test_loss": 0.6549267768859863, "test_mcc": 0.2391229693462222, "test_macro_f1": 0.5935588605359149, "test_runtime": 2.3638, "test_samples_per_second": 866.392, "test_steps_per_second": 27.075}, {"test_loss": 0.6648739576339722, "test_mcc": 0.17891256126549604, "test_macro_f1": 0.5892840833894708, "test_runtime": 2.3092, "test_samples_per_second": 886.875, "test_steps_per_second": 27.715}, {"test_loss": 0.6527931690216064, "test_mcc": 0.23942400129605054, "test_macro_f1": 0.6180042791886106, "test_runtime": 2.3423, "test_samples_per_second": 874.344, "test_steps_per_second": 27.323}, {"test_loss": 0.6681679487228394, "test_mcc": 0.16980813132880823, "test_macro_f1": 0.5840480299149855, "test_runtime": 2.3833, "test_samples_per_second": 859.308, "test_steps_per_second": 26.853}, {"test_loss": 0.6778331995010376, "test_mcc": 0.16766151737159465, "test_macro_f1": 0.5824917882514704, "test_runtime": 2.3511, "test_samples_per_second": 871.097, "test_steps_per_second": 27.222}, {"test_loss": 0.6528611183166504, "test_mcc": 0.2305081331817463, "test_macro_f1": 0.6110652034979256, "test_runtime": 2.3546, "test_samples_per_second": 869.79, "test_steps_per_second": 27.181}, {"test_loss": 0.6577186584472656, "test_mcc": 0.219837073065656, "test_macro_f1": 0.6098039215686275, "test_runtime": 2.3604, "test_samples_per_second": 867.658, "test_steps_per_second": 27.114}, {"test_loss": 0.6717891693115234, "test_mcc": 0.18804741414933193, "test_macro_f1": 0.5874035180498369, "test_runtime": 2.379, "test_samples_per_second": 860.853, "test_steps_per_second": 26.902}]}, "total": {"test_mcc": 21.11370344613221, "test_mcc_se": 1.971357872172401, "test_macro_f1": 60.092937351018925, "test_macro_f1_se": 0.9278904126250981}}, "num_model_parameters": 13014618, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_em": 32.30054221533695, "test_f1": 35.43285883847233}, {"test_em": 26.82170542635659, "test_f1": 31.18408569657995}, {"test_em": 30.834621329211746, "test_f1": 35.39425950633311}, {"test_em": 31.61993769470405, "test_f1": 35.747550983851355}, {"test_em": 30.81081081081081, "test_f1": 34.879168948464965}, {"test_em": 34.00154202004626, "test_f1": 37.91032080529636}, {"test_em": 31.43507972665148, "test_f1": 35.033975743810934}, {"test_em": 30.17843289371606, "test_f1": 34.261451322155345}, {"test_em": 31.607843137254903, "test_f1": 36.170671713064735}, {"test_em": 25.46583850931677, "test_f1": 30.19216475432579}]}, "total": {"test_em": 30.507635376340563, "test_em_se": 1.5740145097588296, "test_f1": 34.62065083123549, "test_f1_se": 1.4245170646436958}}, "num_model_parameters": 12948826, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_em": 24.9419054996127, "test_f1": 30.282265961866106}, {"test_em": 28.217054263565892, "test_f1": 33.3322111491706}, {"test_em": 27.202472952086552, "test_f1": 32.82073477452483}, {"test_em": 25.46728971962617, "test_f1": 30.485475792234144}, {"test_em": 23.62934362934363, "test_f1": 29.475686697933508}, {"test_em": 26.908249807247493, "test_f1": 32.7657991333656}, {"test_em": 31.814730447987852, "test_f1": 35.7768482864617}, {"test_em": 25.91155934833204, "test_f1": 30.908398373115325}, {"test_em": 28.07843137254902, "test_f1": 33.05571339969446}, {"test_em": 24.53416149068323, "test_f1": 30.681382072599884}]}, "total": {"test_em": 26.670519853103457, "test_em_se": 1.460913041785085, "test_f1": 31.958451564096617, "test_f1_se": 1.1858241220393575}}, "num_model_parameters": 12948826, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_em": 28.195197521301317, "test_f1": 33.3157186962167}, {"test_em": 27.131782945736433, "test_f1": 32.67934684094955}, {"test_em": 28.979907264296756, "test_f1": 34.6877248549171}, {"test_em": 23.67601246105919, "test_f1": 30.208064827198406}, {"test_em": 28.10810810810811, "test_f1": 33.62879733709304}, {"test_em": 31.38010794140324, "test_f1": 35.11525668006687}, {"test_em": 25.360668185269553, "test_f1": 29.925153641840183}, {"test_em": 34.91078355314197, "test_f1": 39.68261454383609}, {"test_em": 29.176470588235293, "test_f1": 34.05620794619158}, {"test_em": 28.027950310559007, "test_f1": 33.31154347487646}]}, "total": {"test_em": 28.494698887911085, "test_em_se": 1.9109123573129814, "test_f1": 33.661042884318604, "test_f1_se": 1.6869464650436965}}, "num_model_parameters": 12948826, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.43686285614967346, "test_mcc": 0.7216171199290352, "test_macro_f1": 0.6675132399215181, "test_runtime": 7.2244, "test_samples_per_second": 283.482, "test_steps_per_second": 35.435}, {"test_loss": 0.46534958481788635, "test_mcc": 0.6856221727947133, "test_macro_f1": 0.5860484375479219, "test_runtime": 6.8497, "test_samples_per_second": 298.989, "test_steps_per_second": 37.374}, {"test_loss": 0.4982243776321411, "test_mcc": 0.6992654758329845, "test_macro_f1": 0.711361900676912, "test_runtime": 7.1443, "test_samples_per_second": 286.662, "test_steps_per_second": 35.833}, {"test_loss": 0.45940035581588745, "test_mcc": 0.7014903027755611, "test_macro_f1": 0.7057163125766858, "test_runtime": 6.8655, "test_samples_per_second": 298.302, "test_steps_per_second": 37.288}, {"test_loss": 0.40386533737182617, "test_mcc": 0.7370877405721268, "test_macro_f1": 0.7558481893953511, "test_runtime": 6.7165, "test_samples_per_second": 304.919, "test_steps_per_second": 38.115}, {"test_loss": 0.4454554319381714, "test_mcc": 0.7149482024476211, "test_macro_f1": 0.7278286294510211, "test_runtime": 6.8696, "test_samples_per_second": 298.127, "test_steps_per_second": 37.266}, {"test_loss": 0.41869693994522095, "test_mcc": 0.7402713910065278, "test_macro_f1": 0.7089831106609492, "test_runtime": 6.5862, "test_samples_per_second": 310.955, "test_steps_per_second": 38.869}, {"test_loss": 0.47365468740463257, "test_mcc": 0.7004082609680091, "test_macro_f1": 0.6949066002228165, "test_runtime": 7.2788, "test_samples_per_second": 281.363, "test_steps_per_second": 35.17}, {"test_loss": 0.4409205913543701, "test_mcc": 0.7056540405221088, "test_macro_f1": 0.6761405059953155, "test_runtime": 7.1174, "test_samples_per_second": 287.747, "test_steps_per_second": 35.968}, {"test_loss": 0.4478667378425598, "test_mcc": 0.7217359566843349, "test_macro_f1": 0.7389927982653584, "test_runtime": 6.9302, "test_samples_per_second": 295.519, "test_steps_per_second": 36.94}]}, "total": {"test_mcc": 71.28100663533023, "test_mcc_se": 1.0856200718038311, "test_macro_f1": 69.7333972471385, "test_macro_f1_se": 2.9378828586939565}}, "num_model_parameters": 82166019, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.9834824204444885, "test_mcc": 0.33083217396669656, "test_macro_f1": 0.5553280894211059, "test_runtime": 2.7593, "test_samples_per_second": 742.204, "test_steps_per_second": 23.194}, {"test_loss": 1.0241224765777588, "test_mcc": 0.3051233579342351, "test_macro_f1": 0.5320790648804833, "test_runtime": 2.7217, "test_samples_per_second": 752.48, "test_steps_per_second": 23.515}, {"test_loss": 1.0087435245513916, "test_mcc": 0.3123641897115504, "test_macro_f1": 0.5417710099882455, "test_runtime": 2.7284, "test_samples_per_second": 750.622, "test_steps_per_second": 23.457}, {"test_loss": 0.9987941980361938, "test_mcc": 0.3295627739852451, "test_macro_f1": 0.5406902611039924, "test_runtime": 2.7499, "test_samples_per_second": 744.755, "test_steps_per_second": 23.274}, {"test_loss": 0.9895027875900269, "test_mcc": 0.32483538971158754, "test_macro_f1": 0.5350551622657125, "test_runtime": 2.7002, "test_samples_per_second": 758.454, "test_steps_per_second": 23.702}, {"test_loss": 1.0042481422424316, "test_mcc": 0.3221626471429564, "test_macro_f1": 0.527266923093816, "test_runtime": 2.7446, "test_samples_per_second": 746.19, "test_steps_per_second": 23.318}, {"test_loss": 1.0258325338363647, "test_mcc": 0.2857861530205259, "test_macro_f1": 0.48535301002638837, "test_runtime": 2.7556, "test_samples_per_second": 743.21, "test_steps_per_second": 23.225}, {"test_loss": 0.9909197092056274, "test_mcc": 0.310707260329641, "test_macro_f1": 0.5412861222604034, "test_runtime": 2.7351, "test_samples_per_second": 748.774, "test_steps_per_second": 23.399}, {"test_loss": 1.0004029273986816, "test_mcc": 0.2937576716536717, "test_macro_f1": 0.5250566114033938, "test_runtime": 2.7175, "test_samples_per_second": 753.633, "test_steps_per_second": 23.551}, {"test_loss": 1.0000271797180176, "test_mcc": 0.3030055454025784, "test_macro_f1": 0.5208832144213403, "test_runtime": 2.723, "test_samples_per_second": 752.123, "test_steps_per_second": 23.504}]}, "total": {"test_mcc": 31.181371628586884, "test_mcc_se": 0.9424142455511488, "test_macro_f1": 53.04769468864882, "test_macro_f1_se": 1.1609690526837984}}, "num_model_parameters": 82166019, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.8961071968078613, "test_mcc": 0.3501496964074078, "test_macro_f1": 0.5137004551554046, "test_runtime": 2.2413, "test_samples_per_second": 913.761, "test_steps_per_second": 28.555}, {"test_loss": 0.9132547378540039, "test_mcc": 0.32326168629153906, "test_macro_f1": 0.4985208952267776, "test_runtime": 2.1021, "test_samples_per_second": 974.264, "test_steps_per_second": 30.446}, {"test_loss": 0.8708521127700806, "test_mcc": 0.3378427743977556, "test_macro_f1": 0.5307486740446477, "test_runtime": 2.0908, "test_samples_per_second": 979.548, "test_steps_per_second": 30.611}, {"test_loss": 0.9235106706619263, "test_mcc": 0.3248254349992075, "test_macro_f1": 0.43498698698698696, "test_runtime": 2.1532, "test_samples_per_second": 951.164, "test_steps_per_second": 29.724}, {"test_loss": 0.9110709428787231, "test_mcc": 0.3239756738150091, "test_macro_f1": 0.4400562981935377, "test_runtime": 2.1773, "test_samples_per_second": 940.614, "test_steps_per_second": 29.394}, {"test_loss": 0.9350894689559937, "test_mcc": 0.3101495402330247, "test_macro_f1": 0.4569153194100546, "test_runtime": 2.2316, "test_samples_per_second": 917.721, "test_steps_per_second": 28.679}, {"test_loss": 0.902697741985321, "test_mcc": 0.3867949593260255, "test_macro_f1": 0.5727674909441633, "test_runtime": 2.1596, "test_samples_per_second": 948.337, "test_steps_per_second": 29.636}, {"test_loss": 0.8791893720626831, "test_mcc": 0.2923446527099115, "test_macro_f1": 0.4229152178785594, "test_runtime": 2.1681, "test_samples_per_second": 944.609, "test_steps_per_second": 29.519}, {"test_loss": 0.9485338926315308, "test_mcc": 0.3072494514234988, "test_macro_f1": 0.4414969222382579, "test_runtime": 2.2201, "test_samples_per_second": 922.469, "test_steps_per_second": 28.827}, {"test_loss": 0.916113018989563, "test_mcc": 0.38530929590017576, "test_macro_f1": 0.5508927565117058, "test_runtime": 2.2105, "test_samples_per_second": 926.502, "test_steps_per_second": 28.953}]}, "total": {"test_mcc": 33.41903165503555, "test_mcc_se": 1.9616048398567187, "test_macro_f1": 48.63001016590095, "test_macro_f1_se": 3.3431636829628393}}, "num_model_parameters": 82166019, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.05492858216166496, "test_micro_f1": 0.7483064095883272, "test_micro_f1_no_misc": 0.8238153098420413, "test_runtime": 4.1332, "test_samples_per_second": 495.495, "test_steps_per_second": 15.484}, {"test_loss": 0.05041620135307312, "test_micro_f1": 0.729559748427673, "test_micro_f1_no_misc": 0.7985392574558734, "test_runtime": 3.8535, "test_samples_per_second": 531.466, "test_steps_per_second": 16.608}, {"test_loss": 0.04781167954206467, "test_micro_f1": 0.7235294117647059, "test_micro_f1_no_misc": 0.7822222222222223, "test_runtime": 3.7425, "test_samples_per_second": 547.224, "test_steps_per_second": 17.101}, {"test_loss": 0.048594433814287186, "test_micro_f1": 0.7185805815672746, "test_micro_f1_no_misc": 0.7699890470974808, "test_runtime": 4.149, "test_samples_per_second": 493.619, "test_steps_per_second": 15.426}, {"test_loss": 0.051216065883636475, "test_micro_f1": 0.7410926365795725, "test_micro_f1_no_misc": 0.8026243849097867, "test_runtime": 4.069, "test_samples_per_second": 503.313, "test_steps_per_second": 15.729}, {"test_loss": 0.04521828889846802, "test_micro_f1": 0.7862846406763739, "test_micro_f1_no_misc": 0.8398921832884098, "test_runtime": 3.2924, "test_samples_per_second": 622.029, "test_steps_per_second": 19.438}, {"test_loss": 0.054512105882167816, "test_micro_f1": 0.7259615384615384, "test_micro_f1_no_misc": 0.8065984072810012, "test_runtime": 3.5149, "test_samples_per_second": 582.665, "test_steps_per_second": 18.208}, {"test_loss": 0.04628106579184532, "test_micro_f1": 0.7078774617067833, "test_micro_f1_no_misc": 0.7686613201727328, "test_runtime": 4.0229, "test_samples_per_second": 509.091, "test_steps_per_second": 15.909}, {"test_loss": 0.04579667001962662, "test_micro_f1": 0.744893111638955, "test_micro_f1_no_misc": 0.8038075092543626, "test_runtime": 3.7515, "test_samples_per_second": 545.922, "test_steps_per_second": 17.06}, {"test_loss": 0.04914120212197304, "test_micro_f1": 0.7514619883040935, "test_micro_f1_no_misc": 0.8163037409268564, "test_runtime": 4.0648, "test_samples_per_second": 503.838, "test_steps_per_second": 15.745}]}, "total": {"test_micro_f1": 73.77547528715297, "test_micro_f1_se": 1.3681637876951867, "test_micro_f1_no_misc": 80.12453382450768, "test_micro_f1_no_misc_se": 1.4125809074372142}}, "num_model_parameters": 81580041, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.07406765222549438, "test_micro_f1": 0.7481114873665017, "test_micro_f1_no_misc": 0.7661795407098121, "test_runtime": 5.6923, "test_samples_per_second": 359.782, "test_steps_per_second": 11.243}, {"test_loss": 0.0775335505604744, "test_micro_f1": 0.706945228684359, "test_micro_f1_no_misc": 0.7375318529304696, "test_runtime": 4.7502, "test_samples_per_second": 431.144, "test_steps_per_second": 13.473}, {"test_loss": 0.07711464166641235, "test_micro_f1": 0.7473233404710921, "test_micro_f1_no_misc": 0.7825768667642752, "test_runtime": 5.724, "test_samples_per_second": 357.79, "test_steps_per_second": 11.181}, {"test_loss": 0.08500094711780548, "test_micro_f1": 0.7424000000000001, "test_micro_f1_no_misc": 0.7626935541951746, "test_runtime": 5.4755, "test_samples_per_second": 374.029, "test_steps_per_second": 11.688}, {"test_loss": 0.08170738816261292, "test_micro_f1": 0.7455115417497862, "test_micro_f1_no_misc": 0.7617951668584579, "test_runtime": 5.8562, "test_samples_per_second": 349.714, "test_steps_per_second": 10.929}, {"test_loss": 0.08896436542272568, "test_micro_f1": 0.7596153846153846, "test_micro_f1_no_misc": 0.7728813559322033, "test_runtime": 5.573, "test_samples_per_second": 367.487, "test_steps_per_second": 11.484}, {"test_loss": 0.08070738613605499, "test_micro_f1": 0.7265795206971679, "test_micro_f1_no_misc": 0.743893928820656, "test_runtime": 5.9073, "test_samples_per_second": 346.69, "test_steps_per_second": 10.834}, {"test_loss": 0.07522579282522202, "test_micro_f1": 0.7654320987654321, "test_micro_f1_no_misc": 0.8001480384900075, "test_runtime": 5.6121, "test_samples_per_second": 364.927, "test_steps_per_second": 11.404}, {"test_loss": 0.08006390929222107, "test_micro_f1": 0.7572238725357817, "test_micro_f1_no_misc": 0.7730418943533697, "test_runtime": 5.5181, "test_samples_per_second": 371.145, "test_steps_per_second": 11.598}, {"test_loss": 0.08556349575519562, "test_micro_f1": 0.7839871037076841, "test_micro_f1_no_misc": 0.8157319737800436, "test_runtime": 4.7235, "test_samples_per_second": 433.578, "test_steps_per_second": 13.549}]}, "total": {"test_micro_f1": 74.8312957859319, "test_micro_f1_se": 1.3067191220892198, "test_micro_f1_no_misc": 77.1647417283447, "test_micro_f1_no_misc_se": 1.4638046105936395}}, "num_model_parameters": 81580041, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.06461057811975479, "test_micro_f1": 0.7611395178962747, "test_micro_f1_no_misc": 0.7934560327198363, "test_runtime": 4.3607, "test_samples_per_second": 469.646, "test_steps_per_second": 14.676}, {"test_loss": 0.05050963908433914, "test_micro_f1": 0.7689450222882616, "test_micro_f1_no_misc": 0.8108786610878662, "test_runtime": 4.3868, "test_samples_per_second": 466.856, "test_steps_per_second": 14.589}, {"test_loss": 0.06320827454328537, "test_micro_f1": 0.7777017783857729, "test_micro_f1_no_misc": 0.818426103646833, "test_runtime": 4.2457, "test_samples_per_second": 482.37, "test_steps_per_second": 15.074}, {"test_loss": 0.04934195801615715, "test_micro_f1": 0.7833682739343116, "test_micro_f1_no_misc": 0.8199052132701421, "test_runtime": 4.2297, "test_samples_per_second": 484.189, "test_steps_per_second": 15.131}, {"test_loss": 0.053460493683815, "test_micro_f1": 0.7829276425475159, "test_micro_f1_no_misc": 0.8182152038193169, "test_runtime": 4.4289, "test_samples_per_second": 462.42, "test_steps_per_second": 14.451}, {"test_loss": 0.0505436435341835, "test_micro_f1": 0.8168535507985049, "test_micro_f1_no_misc": 0.844022770398482, "test_runtime": 4.462, "test_samples_per_second": 458.99, "test_steps_per_second": 14.343}, {"test_loss": 0.05760574713349342, "test_micro_f1": 0.7987825498816368, "test_micro_f1_no_misc": 0.8300751879699247, "test_runtime": 4.1135, "test_samples_per_second": 497.87, "test_steps_per_second": 15.558}, {"test_loss": 0.058244191110134125, "test_micro_f1": 0.7860352575181472, "test_micro_f1_no_misc": 0.8141527001862198, "test_runtime": 4.1725, "test_samples_per_second": 490.839, "test_steps_per_second": 15.339}, {"test_loss": 0.055158622562885284, "test_micro_f1": 0.7683655536028119, "test_micro_f1_no_misc": 0.806286836935167, "test_runtime": 4.2024, "test_samples_per_second": 487.342, "test_steps_per_second": 15.229}, {"test_loss": 0.06251800060272217, "test_micro_f1": 0.7857631759069131, "test_micro_f1_no_misc": 0.826879271070615, "test_runtime": 4.1981, "test_samples_per_second": 487.842, "test_steps_per_second": 15.245}]}, "total": {"test_micro_f1": 78.29882322760152, "test_micro_f1_se": 0.9972273430279618, "test_micro_f1_no_misc": 81.82297981104402, "test_micro_f1_no_misc_se": 0.8544155211887885}}, "num_model_parameters": 81580041, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.06639686226844788, "test_micro_f1": 0.7147277227722771, "test_micro_f1_no_misc": 0.7547802750754781, "test_runtime": 4.2323, "test_samples_per_second": 483.903, "test_steps_per_second": 15.122}, {"test_loss": 0.06846994161605835, "test_micro_f1": 0.7374847374847374, "test_micro_f1_no_misc": 0.7715053763440859, "test_runtime": 4.279, "test_samples_per_second": 478.619, "test_steps_per_second": 14.957}, {"test_loss": 0.0682230144739151, "test_micro_f1": 0.726779252110977, "test_micro_f1_no_misc": 0.7662162162162162, "test_runtime": 4.0678, "test_samples_per_second": 503.463, "test_steps_per_second": 15.733}, {"test_loss": 0.07852225750684738, "test_micro_f1": 0.7306295399515738, "test_micro_f1_no_misc": 0.7660300136425647, "test_runtime": 4.2236, "test_samples_per_second": 484.897, "test_steps_per_second": 15.153}, {"test_loss": 0.07653264701366425, "test_micro_f1": 0.7, "test_micro_f1_no_misc": 0.7352546916890079, "test_runtime": 4.1114, "test_samples_per_second": 498.121, "test_steps_per_second": 15.566}, {"test_loss": 0.07563849538564682, "test_micro_f1": 0.7156072814085348, "test_micro_f1_no_misc": 0.7518104015799869, "test_runtime": 3.9491, "test_samples_per_second": 518.596, "test_steps_per_second": 16.206}, {"test_loss": 0.06354120373725891, "test_micro_f1": 0.7301092043681748, "test_micro_f1_no_misc": 0.7730690362269309, "test_runtime": 4.288, "test_samples_per_second": 477.613, "test_steps_per_second": 14.925}, {"test_loss": 0.06616511940956116, "test_micro_f1": 0.7127206329884359, "test_micro_f1_no_misc": 0.7536037546094536, "test_runtime": 4.2795, "test_samples_per_second": 478.559, "test_steps_per_second": 14.955}, {"test_loss": 0.0794086828827858, "test_micro_f1": 0.6882316697473814, "test_micro_f1_no_misc": 0.7285037237643873, "test_runtime": 3.9489, "test_samples_per_second": 518.619, "test_steps_per_second": 16.207}, {"test_loss": 0.07326396554708481, "test_micro_f1": 0.7521206409048068, "test_micro_f1_no_misc": 0.7877325982081324, "test_runtime": 4.1814, "test_samples_per_second": 489.789, "test_steps_per_second": 15.306}]}, "total": {"test_micro_f1": 72.084106817369, "test_micro_f1_se": 1.1504656334723786, "test_micro_f1_no_misc": 75.88506087356242, "test_micro_f1_no_misc_se": 1.1075174603411249}}, "num_model_parameters": 81580041, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.49407583475112915, "test_mcc": 0.5752071395322285, "test_macro_f1": 0.7779072278230159, "test_runtime": 1.5319, "test_samples_per_second": 1336.893, "test_steps_per_second": 41.778}, {"test_loss": 0.49488645792007446, "test_mcc": 0.5362873633584374, "test_macro_f1": 0.7527270470308935, "test_runtime": 1.605, "test_samples_per_second": 1276.051, "test_steps_per_second": 39.877}, {"test_loss": 0.5243409872055054, "test_mcc": 0.5536051887905671, "test_macro_f1": 0.7615094339622641, "test_runtime": 1.5803, "test_samples_per_second": 1295.937, "test_steps_per_second": 40.498}, {"test_loss": 0.5064514875411987, "test_mcc": 0.526939492420391, "test_macro_f1": 0.7604980339186553, "test_runtime": 1.5559, "test_samples_per_second": 1316.283, "test_steps_per_second": 41.134}, {"test_loss": 0.5681235194206238, "test_mcc": 0.4979610969299974, "test_macro_f1": 0.7122995167530946, "test_runtime": 1.5913, "test_samples_per_second": 1287.013, "test_steps_per_second": 40.219}, {"test_loss": 0.5456502437591553, "test_mcc": 0.5143363032334989, "test_macro_f1": 0.7366541013342722, "test_runtime": 1.5781, "test_samples_per_second": 1297.779, "test_steps_per_second": 40.556}, {"test_loss": 0.5804380178451538, "test_mcc": 0.46720899756221845, "test_macro_f1": 0.709330123827213, "test_runtime": 1.5499, "test_samples_per_second": 1321.348, "test_steps_per_second": 41.292}, {"test_loss": 0.6050670742988586, "test_mcc": 0.420137790898366, "test_macro_f1": 0.663298889006561, "test_runtime": 1.625, "test_samples_per_second": 1260.33, "test_steps_per_second": 39.385}, {"test_loss": 0.4852020740509033, "test_mcc": 0.5616478681819612, "test_macro_f1": 0.7757994590834735, "test_runtime": 1.5746, "test_samples_per_second": 1300.633, "test_steps_per_second": 40.645}, {"test_loss": 0.5442831516265869, "test_mcc": 0.5051413412412098, "test_macro_f1": 0.7319808931691419, "test_runtime": 1.5856, "test_samples_per_second": 1291.638, "test_steps_per_second": 40.364}]}, "total": {"test_mcc": 51.58472582148874, "test_mcc_se": 2.888781521726692, "test_macro_f1": 73.82004725908585, "test_macro_f1_se": 2.2056652049067016}}, "num_model_parameters": 82165250, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.6911416053771973, "test_mcc": 0.06004256001869673, "test_macro_f1": 0.5280680977621407, "test_runtime": 2.3206, "test_samples_per_second": 882.524, "test_steps_per_second": 27.579}, {"test_loss": 0.6745564937591553, "test_mcc": 0.1910649789364269, "test_macro_f1": 0.5557091752074305, "test_runtime": 2.4683, "test_samples_per_second": 829.711, "test_steps_per_second": 25.928}, {"test_loss": 0.6921485662460327, "test_mcc": 0.03516423167689879, "test_macro_f1": 0.49598115900368656, "test_runtime": 2.4495, "test_samples_per_second": 836.078, "test_steps_per_second": 26.127}, {"test_loss": 0.6624823212623596, "test_mcc": 0.19231488263086707, "test_macro_f1": 0.5919568642201107, "test_runtime": 2.5352, "test_samples_per_second": 807.841, "test_steps_per_second": 25.245}, {"test_loss": 0.6891655921936035, "test_mcc": 0.09426746727131166, "test_macro_f1": 0.43873069991857305, "test_runtime": 2.4588, "test_samples_per_second": 832.939, "test_steps_per_second": 26.029}, {"test_loss": 0.6865025758743286, "test_mcc": 0.12172179225284284, "test_macro_f1": 0.5038737457543794, "test_runtime": 2.3767, "test_samples_per_second": 861.681, "test_steps_per_second": 26.928}, {"test_loss": 0.6675839424133301, "test_mcc": 0.19150524398745528, "test_macro_f1": 0.5943304007820137, "test_runtime": 2.352, "test_samples_per_second": 870.74, "test_steps_per_second": 27.211}, {"test_loss": 0.688107967376709, "test_mcc": 0.09801888142859293, "test_macro_f1": 0.5317936204409257, "test_runtime": 2.3631, "test_samples_per_second": 866.669, "test_steps_per_second": 27.083}, {"test_loss": 0.6629074811935425, "test_mcc": 0.1974296498690963, "test_macro_f1": 0.5563581634151125, "test_runtime": 2.3674, "test_samples_per_second": 865.075, "test_steps_per_second": 27.034}, {"test_loss": 0.6861080527305603, "test_mcc": 0.1432838116023749, "test_macro_f1": 0.5639313235095309, "test_runtime": 2.4366, "test_samples_per_second": 840.528, "test_steps_per_second": 26.267}]}, "total": {"test_mcc": 13.248134996745636, "test_mcc_se": 3.7138203674578416, "test_macro_f1": 53.60733250013902, "test_macro_f1_se": 2.9430579746053365}}, "num_model_parameters": 82165250, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.6625965237617493, "test_mcc": 0.23766128001652617, "test_macro_f1": 0.5849561914346741, "test_runtime": 2.1249, "test_samples_per_second": 963.819, "test_steps_per_second": 30.119}, {"test_loss": 0.6731929779052734, "test_mcc": 0.18852376833937307, "test_macro_f1": 0.5264985656047109, "test_runtime": 2.1554, "test_samples_per_second": 950.151, "test_steps_per_second": 29.692}, {"test_loss": 0.6788581609725952, "test_mcc": 0.15591203628644448, "test_macro_f1": 0.5554160494008242, "test_runtime": 2.1484, "test_samples_per_second": 953.281, "test_steps_per_second": 29.79}, {"test_loss": 0.6910198330879211, "test_mcc": 0.08294048623778709, "test_macro_f1": 0.5145234672312943, "test_runtime": 2.1852, "test_samples_per_second": 937.209, "test_steps_per_second": 29.288}, {"test_loss": 0.6670345664024353, "test_mcc": 0.16479391257747564, "test_macro_f1": 0.5620715947834813, "test_runtime": 2.1705, "test_samples_per_second": 943.574, "test_steps_per_second": 29.487}, {"test_loss": 0.6715519428253174, "test_mcc": 0.19923628077777555, "test_macro_f1": 0.5738102842542319, "test_runtime": 2.1063, "test_samples_per_second": 972.311, "test_steps_per_second": 30.385}, {"test_loss": 0.6942874789237976, "test_mcc": 0.05261613805231874, "test_macro_f1": 0.3532042746423572, "test_runtime": 2.1155, "test_samples_per_second": 968.089, "test_steps_per_second": 30.253}, {"test_loss": 0.6875285506248474, "test_mcc": 0.09443797070953934, "test_macro_f1": 0.4725299617208727, "test_runtime": 2.112, "test_samples_per_second": 969.704, "test_steps_per_second": 30.303}, {"test_loss": 0.6696040034294128, "test_mcc": 0.23386770300838694, "test_macro_f1": 0.6036654331936756, "test_runtime": 2.0784, "test_samples_per_second": 985.397, "test_steps_per_second": 30.794}, {"test_loss": 0.6913046836853027, "test_mcc": 0.08919257322415804, "test_macro_f1": 0.5406008365047592, "test_runtime": 2.1453, "test_samples_per_second": 954.654, "test_steps_per_second": 29.833}]}, "total": {"test_mcc": 14.991821492297849, "test_mcc_se": 4.113697446516109, "test_macro_f1": 52.87276658770882, "test_macro_f1_se": 4.476558241883644}}, "num_model_parameters": 82165250, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_loss": 0.6645696759223938, "test_mcc": 0.16319796591783894, "test_macro_f1": 0.5295634002775607, "test_runtime": 2.1459, "test_samples_per_second": 954.373, "test_steps_per_second": 29.824}, {"test_loss": 0.6673636436462402, "test_mcc": 0.2233351866698547, "test_macro_f1": 0.6093441644866676, "test_runtime": 2.2041, "test_samples_per_second": 929.191, "test_steps_per_second": 29.037}, {"test_loss": 0.6929314136505127, "test_mcc": 0.03968456767049504, "test_macro_f1": 0.44400781776608095, "test_runtime": 2.2059, "test_samples_per_second": 928.424, "test_steps_per_second": 29.013}, {"test_loss": 0.6629420518875122, "test_mcc": 0.2088031203858168, "test_macro_f1": 0.5925757759731938, "test_runtime": 2.0946, "test_samples_per_second": 977.772, "test_steps_per_second": 30.555}, {"test_loss": 0.6634327173233032, "test_mcc": 0.2138378972278266, "test_macro_f1": 0.6042483506778374, "test_runtime": 2.1495, "test_samples_per_second": 952.768, "test_steps_per_second": 29.774}, {"test_loss": 0.6907098889350891, "test_mcc": 0.09405861509341454, "test_macro_f1": 0.5401118571020512, "test_runtime": 2.2128, "test_samples_per_second": 925.504, "test_steps_per_second": 28.922}, {"test_loss": 0.6888718605041504, "test_mcc": 0.0473662537694022, "test_macro_f1": 0.40984738006087285, "test_runtime": 2.1391, "test_samples_per_second": 957.429, "test_steps_per_second": 29.92}, {"test_loss": 0.6707192659378052, "test_mcc": 0.16994946821680643, "test_macro_f1": 0.5845650541362513, "test_runtime": 2.1606, "test_samples_per_second": 947.881, "test_steps_per_second": 29.621}, {"test_loss": 0.6913431882858276, "test_mcc": 0.04807623453870184, "test_macro_f1": 0.44472776258874214, "test_runtime": 2.169, "test_samples_per_second": 944.234, "test_steps_per_second": 29.507}, {"test_loss": 0.6743600368499756, "test_mcc": 0.15513288434653502, "test_macro_f1": 0.5748407459662692, "test_runtime": 2.2082, "test_samples_per_second": 927.44, "test_steps_per_second": 28.982}]}, "total": {"test_mcc": 13.63442193836692, "test_mcc_se": 4.520099654734014, "test_macro_f1": 53.33832309035527, "test_macro_f1_se": 4.610641383530724}}, "num_model_parameters": 82165250, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_em": 32.997676219984506, "test_f1": 36.83666239447753}, {"test_em": 33.48837209302326, "test_f1": 36.28128845365508}, {"test_em": 29.366306027820713, "test_f1": 33.32739351797903}, {"test_em": 34.26791277258567, "test_f1": 38.19218587620835}, {"test_em": 32.432432432432435, "test_f1": 35.88684318870079}, {"test_em": 31.919814957594447, "test_f1": 35.363608788053334}, {"test_em": 30.29612756264237, "test_f1": 33.60175880033495}, {"test_em": 30.721489526764934, "test_f1": 35.00364420309203}, {"test_em": 34.431372549019606, "test_f1": 38.01690444631621}, {"test_em": 31.133540372670808, "test_f1": 34.71764116105548}]}, "total": {"test_em": 32.105504451453875, "test_em_se": 1.0650053225842941, "test_f1": 35.72279308298728, "test_f1_se": 1.0295676509356706}}, "num_model_parameters": 81574658, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_em": 31.913245546088305, "test_f1": 35.62602040877457}, {"test_em": 34.031007751937985, "test_f1": 37.398102530710624}, {"test_em": 34.46676970633694, "test_f1": 38.10067223980659}, {"test_em": 30.062305295950157, "test_f1": 33.828474191546015}, {"test_em": 29.652509652509654, "test_f1": 33.81813210246186}, {"test_em": 35.774865073245955, "test_f1": 39.053471371621626}, {"test_em": 31.58694001518603, "test_f1": 35.075759287048335}, {"test_em": 33.12645461598138, "test_f1": 37.732065931034285}, {"test_em": 32.94117647058823, "test_f1": 37.55840559671889}, {"test_em": 32.68633540372671, "test_f1": 36.718508763114365}]}, "total": {"test_em": 32.62416095315514, "test_em_se": 1.1802221851351142, "test_f1": 36.49096124228372, "test_f1_se": 1.1258558259253049}}, "num_model_parameters": 81574658, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_em": 37.955073586367156, "test_f1": 43.15456046110503}, {"test_em": 37.2093023255814, "test_f1": 41.598793624169836}, {"test_em": 39.10355486862442, "test_f1": 44.056881025517875}, {"test_em": 40.42056074766355, "test_f1": 45.38703254400486}, {"test_em": 35.5984555984556, "test_f1": 40.41143504960979}, {"test_em": 35.92906707787201, "test_f1": 40.22503531659798}, {"test_em": 39.48367501898254, "test_f1": 44.72184787130052}, {"test_em": 37.85880527540729, "test_f1": 42.991276253969104}, {"test_em": 45.333333333333336, "test_f1": 50.307660233356835}, {"test_em": 38.35403726708075, "test_f1": 44.487232645572846}]}, "total": {"test_em": 38.7245865099368, "test_em_se": 1.7116141223980368, "test_f1": 43.734175502520465, "test_f1_se": 1.805751711737904}}, "num_model_parameters": 81574658, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "gpt2", "results": {"raw": {"test": [{"test_loss": 0.7489789724349976, "test_mcc": 0.4961537235103528, "test_macro_f1": 0.5146235353450019, "test_runtime": 24.0601, "test_samples_per_second": 85.12, "test_steps_per_second": 42.56, "epoch": 11.25}, {"test_loss": 0.7266066670417786, "test_mcc": 0.5034265232051938, "test_macro_f1": 0.5077824963139465, "test_runtime": 23.2828, "test_samples_per_second": 87.962, "test_steps_per_second": 43.981, "epoch": 13.12}, {"test_loss": 0.7481948137283325, "test_mcc": 0.4818408762006389, "test_macro_f1": 0.5057240415099852, "test_runtime": 23.4963, "test_samples_per_second": 87.163, "test_steps_per_second": 43.581, "epoch": 11.25}, {"test_loss": 0.7482638359069824, "test_mcc": 0.45853549059456206, "test_macro_f1": 0.4893879477039704, "test_runtime": 23.0981, "test_samples_per_second": 88.665, "test_steps_per_second": 44.333, "epoch": 8.44}, {"test_loss": 0.8153641819953918, "test_mcc": 0.41370604238864955, "test_macro_f1": 0.4690031911500858, "test_runtime": 23.0037, "test_samples_per_second": 89.029, "test_steps_per_second": 44.515, "epoch": 5.62}, {"test_loss": 0.7759896516799927, "test_mcc": 0.446504131264684, "test_macro_f1": 0.4811967277029389, "test_runtime": 23.5594, "test_samples_per_second": 86.929, "test_steps_per_second": 43.465, "epoch": 9.38}, {"test_loss": 0.8282263278961182, "test_mcc": 0.39102362209909924, "test_macro_f1": 0.4628389741337506, "test_runtime": 23.3895, "test_samples_per_second": 87.561, "test_steps_per_second": 43.78, "epoch": 5.62}, {"test_loss": 0.7668681144714355, "test_mcc": 0.457283804909104, "test_macro_f1": 0.48935178596904927, "test_runtime": 24.0728, "test_samples_per_second": 85.075, "test_steps_per_second": 42.538, "epoch": 6.56}, {"test_loss": 0.782910943031311, "test_mcc": 0.4584624367346217, "test_macro_f1": 0.4933352135082087, "test_runtime": 24.0054, "test_samples_per_second": 85.314, "test_steps_per_second": 42.657, "epoch": 9.38}, {"test_loss": 0.8543530106544495, "test_mcc": 0.39532885689739516, "test_macro_f1": 0.46739218622530077, "test_runtime": 23.6278, "test_samples_per_second": 86.677, "test_steps_per_second": 43.339, "epoch": 4.69}]}, "total": {"test_mcc": 45.02265507804301, "test_mcc_se": 2.4438534360491913, "test_macro_f1": 48.806360995622384, "test_macro_f1_se": 1.1147715605221553}}, "num_model_parameters": 124442112, "max_sequence_length": 1024, "vocabulary_size": 50257}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "gpt2", "results": {"raw": {"test": [{"test_loss": 1.0563323497772217, "test_mcc": 0.16054007730592829, "test_macro_f1": 0.34587399267169827, "test_runtime": 6.6729, "test_samples_per_second": 306.911, "test_steps_per_second": 9.591, "epoch": 9.38}, {"test_loss": 1.043438196182251, "test_mcc": 0.16975790072522678, "test_macro_f1": 0.40429164415911156, "test_runtime": 6.6983, "test_samples_per_second": 305.751, "test_steps_per_second": 9.555, "epoch": 7.5}, {"test_loss": 1.079829216003418, "test_mcc": 0.1687895049970935, "test_macro_f1": 0.3596102396922529, "test_runtime": 6.6185, "test_samples_per_second": 309.434, "test_steps_per_second": 9.67, "epoch": 9.38}, {"test_loss": 1.037103295326233, "test_mcc": 0.18116612287940592, "test_macro_f1": 0.3659844429616627, "test_runtime": 6.6379, "test_samples_per_second": 308.531, "test_steps_per_second": 9.642, "epoch": 8.44}, {"test_loss": 1.0600926876068115, "test_mcc": 0.14450201122538434, "test_macro_f1": 0.3559199711091073, "test_runtime": 6.6028, "test_samples_per_second": 310.17, "test_steps_per_second": 9.693, "epoch": 6.56}, {"test_loss": 1.07120680809021, "test_mcc": 0.1383285507257923, "test_macro_f1": 0.352254463382547, "test_runtime": 6.6894, "test_samples_per_second": 306.158, "test_steps_per_second": 9.567, "epoch": 5.62}, {"test_loss": 1.0473549365997314, "test_mcc": 0.18743109254548132, "test_macro_f1": 0.37714950256244567, "test_runtime": 6.7347, "test_samples_per_second": 304.096, "test_steps_per_second": 9.503, "epoch": 6.56}, {"test_loss": 1.1087452173233032, "test_mcc": 0.12492255923808067, "test_macro_f1": 0.3350032429799588, "test_runtime": 6.8158, "test_samples_per_second": 300.477, "test_steps_per_second": 9.39, "epoch": 6.56}, {"test_loss": 1.0697027444839478, "test_mcc": 0.17591530150332244, "test_macro_f1": 0.3997606654267842, "test_runtime": 6.8326, "test_samples_per_second": 299.739, "test_steps_per_second": 9.367, "epoch": 8.44}, {"test_loss": 1.0766268968582153, "test_mcc": 0.13428888187870802, "test_macro_f1": 0.34310490237973656, "test_runtime": 6.7092, "test_samples_per_second": 305.251, "test_steps_per_second": 9.539, "epoch": 7.5}]}, "total": {"test_mcc": 15.856420030244237, "test_mcc_se": 1.3400888728859057, "test_macro_f1": 36.38953067325305, "test_macro_f1_se": 1.4473159398776512}}, "num_model_parameters": 124442112, "max_sequence_length": 1024, "vocabulary_size": 50257}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "gpt2", "results": {"raw": {"test": [{"test_loss": 1.0015885829925537, "test_mcc": 0.08603080046802271, "test_macro_f1": 0.3052188348162825, "test_runtime": 5.6257, "test_samples_per_second": 364.044, "test_steps_per_second": 11.376, "epoch": 7.5}, {"test_loss": 0.9753018617630005, "test_mcc": 0.0990801015434462, "test_macro_f1": 0.3132991468408026, "test_runtime": 5.24, "test_samples_per_second": 390.84, "test_steps_per_second": 12.214, "epoch": 9.38}, {"test_loss": 0.9973737001419067, "test_mcc": 0.1558956060726035, "test_macro_f1": 0.36166841289158347, "test_runtime": 5.1991, "test_samples_per_second": 393.913, "test_steps_per_second": 12.31, "epoch": 5.62}, {"test_loss": 1.0153486728668213, "test_mcc": 0.15143733621278, "test_macro_f1": 0.35645384012418896, "test_runtime": 5.4949, "test_samples_per_second": 372.71, "test_steps_per_second": 11.647, "epoch": 6.56}, {"test_loss": 0.999727189540863, "test_mcc": 0.09089701144663392, "test_macro_f1": 0.3220043873337916, "test_runtime": 5.4832, "test_samples_per_second": 373.508, "test_steps_per_second": 11.672, "epoch": 5.62}, {"test_loss": 0.9771872162818909, "test_mcc": 0.113241734566924, "test_macro_f1": 0.3350887627987685, "test_runtime": 5.5604, "test_samples_per_second": 368.321, "test_steps_per_second": 11.51, "epoch": 7.5}, {"test_loss": 0.9593281149864197, "test_mcc": 0.12195860039437402, "test_macro_f1": 0.3372019793072425, "test_runtime": 5.2994, "test_samples_per_second": 386.457, "test_steps_per_second": 12.077, "epoch": 11.25}, {"test_loss": 0.9908642768859863, "test_mcc": 0.09414354255728925, "test_macro_f1": 0.3170281907547323, "test_runtime": 5.5123, "test_samples_per_second": 371.535, "test_steps_per_second": 11.61, "epoch": 8.44}, {"test_loss": 0.9928135871887207, "test_mcc": 0.11700144240814749, "test_macro_f1": 0.32687710014359334, "test_runtime": 5.6787, "test_samples_per_second": 360.646, "test_steps_per_second": 11.27, "epoch": 7.5}, {"test_loss": 0.9888989925384521, "test_mcc": 0.09254710632731665, "test_macro_f1": 0.3199197407522613, "test_runtime": 5.5834, "test_samples_per_second": 366.805, "test_steps_per_second": 11.463, "epoch": 11.25}]}, "total": {"test_mcc": 11.222332819975378, "test_mcc_se": 1.5448655386136778, "test_macro_f1": 32.947603957632474, "test_macro_f1_se": 1.1343001533856207}}, "num_model_parameters": 124442112, "max_sequence_length": 1024, "vocabulary_size": 50257}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "gpt2", "results": {"raw": {"test": [{"test_loss": 0.12021949887275696, "test_micro_f1": 0.34640198511166254, "test_micro_f1_no_misc": 0.36816976127320955, "test_runtime": 14.5486, "test_samples_per_second": 140.77, "test_steps_per_second": 17.596, "epoch": 17.81}, {"test_loss": 0.11847332119941711, "test_micro_f1": 0.3041940373926226, "test_micro_f1_no_misc": 0.3204715969989282, "test_runtime": 14.0106, "test_samples_per_second": 146.175, "test_steps_per_second": 18.272, "epoch": 15.0}, {"test_loss": 0.11053101718425751, "test_micro_f1": 0.352497643732328, "test_micro_f1_no_misc": 0.37059115747640337, "test_runtime": 14.0209, "test_samples_per_second": 146.067, "test_steps_per_second": 18.258, "epoch": 15.0}, {"test_loss": 0.11833506077528, "test_micro_f1": 0.30355515041020964, "test_micro_f1_no_misc": 0.3167464114832536, "test_runtime": 14.2253, "test_samples_per_second": 143.968, "test_steps_per_second": 17.996, "epoch": 16.88}, {"test_loss": 0.11699054390192032, "test_micro_f1": 0.3559322033898305, "test_micro_f1_no_misc": 0.3750623441396509, "test_runtime": 14.4704, "test_samples_per_second": 141.53, "test_steps_per_second": 17.691, "epoch": 14.06}, {"test_loss": 0.1164894551038742, "test_micro_f1": 0.2666666666666667, "test_micro_f1_no_misc": 0.2843511450381679, "test_runtime": 11.4119, "test_samples_per_second": 179.462, "test_steps_per_second": 22.433, "epoch": 12.19}, {"test_loss": 0.11649884283542633, "test_micro_f1": 0.3814338235294118, "test_micro_f1_no_misc": 0.4086870681145114, "test_runtime": 13.1448, "test_samples_per_second": 155.804, "test_steps_per_second": 19.475, "epoch": 15.0}, {"test_loss": 0.1051902025938034, "test_micro_f1": 0.39187076602397086, "test_micro_f1_no_misc": 0.41513633834168057, "test_runtime": 14.539, "test_samples_per_second": 140.862, "test_steps_per_second": 17.608, "epoch": 19.69}, {"test_loss": 0.11361515522003174, "test_micro_f1": 0.28811312417145385, "test_micro_f1_no_misc": 0.3036795528644621, "test_runtime": 13.3773, "test_samples_per_second": 153.095, "test_steps_per_second": 19.137, "epoch": 14.06}, {"test_loss": 0.11284691095352173, "test_micro_f1": 0.3259393390674513, "test_micro_f1_no_misc": 0.3431839847473785, "test_runtime": 14.3889, "test_samples_per_second": 142.332, "test_steps_per_second": 17.792, "epoch": 14.06}]}, "total": {"test_micro_f1": 33.16604739495608, "test_micro_f1_se": 2.533796028706175, "test_micro_f1_no_misc": 35.060793604776464, "test_micro_f1_no_misc_se": 2.7366025036676063}}, "num_model_parameters": 124446729, "max_sequence_length": 1024, "vocabulary_size": 50257}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "gpt2", "results": {"raw": {"test": [{"test_loss": 0.18428003787994385, "test_micro_f1": 0.4003048006096013, "test_micro_f1_no_misc": 0.447247000922793, "test_runtime": 14.9353, "test_samples_per_second": 137.125, "test_steps_per_second": 17.141, "epoch": 16.88}, {"test_loss": 0.16477090120315552, "test_micro_f1": 0.3860335195530726, "test_micro_f1_no_misc": 0.4418604651162791, "test_runtime": 12.4241, "test_samples_per_second": 164.841, "test_steps_per_second": 20.605, "epoch": 18.75}, {"test_loss": 0.17654049396514893, "test_micro_f1": 0.41544317563893424, "test_micro_f1_no_misc": 0.48101265822784806, "test_runtime": 15.1127, "test_samples_per_second": 135.515, "test_steps_per_second": 16.939, "epoch": 26.25}, {"test_loss": 0.17354628443717957, "test_micro_f1": 0.43162393162393164, "test_micro_f1_no_misc": 0.49257034460954785, "test_runtime": 14.3305, "test_samples_per_second": 142.912, "test_steps_per_second": 17.864, "epoch": 17.81}, {"test_loss": 0.1798216849565506, "test_micro_f1": 0.3616173120728929, "test_micro_f1_no_misc": 0.4078992168879809, "test_runtime": 15.1077, "test_samples_per_second": 135.56, "test_steps_per_second": 16.945, "epoch": 16.88}, {"test_loss": 0.1729554831981659, "test_micro_f1": 0.4035575319622012, "test_micro_f1_no_misc": 0.453572661373835, "test_runtime": 15.2538, "test_samples_per_second": 134.262, "test_steps_per_second": 16.783, "epoch": 21.56}, {"test_loss": 0.17011845111846924, "test_micro_f1": 0.40333871836295093, "test_micro_f1_no_misc": 0.4580559254327563, "test_runtime": 15.8372, "test_samples_per_second": 129.316, "test_steps_per_second": 16.164, "epoch": 15.94}, {"test_loss": 0.1670498251914978, "test_micro_f1": 0.4314493564633464, "test_micro_f1_no_misc": 0.48337765957446804, "test_runtime": 14.912, "test_samples_per_second": 137.339, "test_steps_per_second": 17.167, "epoch": 18.75}, {"test_loss": 0.1768036037683487, "test_micro_f1": 0.415124698310539, "test_micro_f1_no_misc": 0.46291208791208793, "test_runtime": 14.4689, "test_samples_per_second": 141.545, "test_steps_per_second": 17.693, "epoch": 24.38}, {"test_loss": 0.17312420904636383, "test_micro_f1": 0.4236130090188576, "test_micro_f1_no_misc": 0.4865582475937604, "test_runtime": 12.2508, "test_samples_per_second": 167.173, "test_steps_per_second": 20.897, "epoch": 22.5}]}, "total": {"test_micro_f1": 40.72106053616327, "test_micro_f1_se": 1.336736354019735, "test_micro_f1_no_misc": 46.15066267651356, "test_micro_f1_no_misc_se": 1.599167173644829}}, "num_model_parameters": 124446729, "max_sequence_length": 1024, "vocabulary_size": 50257}

{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.5009567737579346, "test_mcc": 0.6767507529204965, "test_macro_f1": 0.6900835310358603, "test_runtime": 14.7601, "test_samples_per_second": 138.753, "test_steps_per_second": 34.688}, {"test_loss": 0.6049308776855469, "test_mcc": 0.6193624749389628, "test_macro_f1": 0.64313905236574, "test_runtime": 14.2288, "test_samples_per_second": 143.933, "test_steps_per_second": 35.983}, {"test_loss": 0.591160774230957, "test_mcc": 0.6202844334828563, "test_macro_f1": 0.5779163372872788, "test_runtime": 14.626, "test_samples_per_second": 140.025, "test_steps_per_second": 35.006}, {"test_loss": 0.5234402418136597, "test_mcc": 0.6566715568939794, "test_macro_f1": 0.6216792430231165, "test_runtime": 14.2546, "test_samples_per_second": 143.673, "test_steps_per_second": 35.918}, {"test_loss": 0.5410598516464233, "test_mcc": 0.6545764119459762, "test_macro_f1": 0.5671840625497392, "test_runtime": 14.3014, "test_samples_per_second": 143.203, "test_steps_per_second": 35.801}, {"test_loss": 0.5642852187156677, "test_mcc": 0.6355756136204483, "test_macro_f1": 0.6488507364168377, "test_runtime": 14.7406, "test_samples_per_second": 138.936, "test_steps_per_second": 34.734}, {"test_loss": 0.5737485289573669, "test_mcc": 0.6247564828622852, "test_macro_f1": 0.6711614853716004, "test_runtime": 14.3162, "test_samples_per_second": 143.055, "test_steps_per_second": 35.764}, {"test_loss": 0.6231159567832947, "test_mcc": 0.5979970352615526, "test_macro_f1": 0.6489400247963523, "test_runtime": 14.9333, "test_samples_per_second": 137.143, "test_steps_per_second": 34.286}, {"test_loss": 0.5286059379577637, "test_mcc": 0.6606747339128592, "test_macro_f1": 0.5874892033496516, "test_runtime": 14.8117, "test_samples_per_second": 138.269, "test_steps_per_second": 34.567}, {"test_loss": 0.4968542456626892, "test_mcc": 0.6779128421623597, "test_macro_f1": 0.705277028390687, "test_runtime": 14.5764, "test_samples_per_second": 140.501, "test_steps_per_second": 35.125}]}, "total": {"test_mcc": 64.24562338001778, "test_mcc_se": 1.662643850342742, "test_macro_f1": 63.61720704586864, "test_macro_f1_se": 2.9226461419929914}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 1.022699236869812, "test_mcc": 0.20938055838048308, "test_macro_f1": 0.40680546367577336, "test_runtime": 5.3528, "test_samples_per_second": 382.606, "test_steps_per_second": 11.956}, {"test_loss": 0.9948000907897949, "test_mcc": 0.25444340052585596, "test_macro_f1": 0.4225093733405818, "test_runtime": 5.3158, "test_samples_per_second": 385.266, "test_steps_per_second": 12.04}, {"test_loss": 0.9938206672668457, "test_mcc": 0.26592690003949365, "test_macro_f1": 0.4700750942310952, "test_runtime": 5.3501, "test_samples_per_second": 382.797, "test_steps_per_second": 11.962}, {"test_loss": 1.0213909149169922, "test_mcc": 0.24997309373709012, "test_macro_f1": 0.4770510154607435, "test_runtime": 5.3386, "test_samples_per_second": 383.622, "test_steps_per_second": 11.988}, {"test_loss": 1.029026985168457, "test_mcc": 0.21909285144388826, "test_macro_f1": 0.41809982536932794, "test_runtime": 5.3193, "test_samples_per_second": 385.015, "test_steps_per_second": 12.032}, {"test_loss": 1.024764895439148, "test_mcc": 0.2763676180410868, "test_macro_f1": 0.49165179396917447, "test_runtime": 5.3632, "test_samples_per_second": 381.863, "test_steps_per_second": 11.933}, {"test_loss": 1.0080137252807617, "test_mcc": 0.28288110989160953, "test_macro_f1": 0.47584534922424115, "test_runtime": 5.3717, "test_samples_per_second": 381.256, "test_steps_per_second": 11.914}, {"test_loss": 1.0571706295013428, "test_mcc": 0.1848451736728492, "test_macro_f1": 0.3530644718490023, "test_runtime": 5.3797, "test_samples_per_second": 380.692, "test_steps_per_second": 11.897}, {"test_loss": 1.0073928833007812, "test_mcc": 0.24314515248074625, "test_macro_f1": 0.39901811030771545, "test_runtime": 5.3092, "test_samples_per_second": 385.748, "test_steps_per_second": 12.055}, {"test_loss": 1.0519179105758667, "test_mcc": 0.2305297929307648, "test_macro_f1": 0.4612936926252604, "test_runtime": 5.3193, "test_samples_per_second": 385.015, "test_steps_per_second": 12.032}]}, "total": {"test_mcc": 24.165856511438676, "test_mcc_se": 1.9193387939106674, "test_macro_f1": 43.754141900529156, "test_macro_f1_se": 2.752370069593025}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.9269747734069824, "test_mcc": 0.2576359099405685, "test_macro_f1": 0.4330461583069592, "test_runtime": 4.3946, "test_samples_per_second": 466.024, "test_steps_per_second": 14.563}, {"test_loss": 0.946921169757843, "test_mcc": 0.2624522545278894, "test_macro_f1": 0.3842970756995401, "test_runtime": 4.1398, "test_samples_per_second": 494.708, "test_steps_per_second": 15.46}, {"test_loss": 0.9343949556350708, "test_mcc": 0.20832137331687292, "test_macro_f1": 0.3740777292165986, "test_runtime": 4.1216, "test_samples_per_second": 496.9, "test_steps_per_second": 15.528}, {"test_loss": 0.9350747466087341, "test_mcc": 0.28246677139133597, "test_macro_f1": 0.4198877017681011, "test_runtime": 4.1922, "test_samples_per_second": 488.526, "test_steps_per_second": 15.266}, {"test_loss": 0.939643144607544, "test_mcc": 0.32608511810644963, "test_macro_f1": 0.5253826769600703, "test_runtime": 4.2767, "test_samples_per_second": 478.877, "test_steps_per_second": 14.965}, {"test_loss": 0.9096161127090454, "test_mcc": 0.2859960731769565, "test_macro_f1": 0.4456396019570474, "test_runtime": 4.3772, "test_samples_per_second": 467.88, "test_steps_per_second": 14.621}, {"test_loss": 0.930400013923645, "test_mcc": 0.24672660941187288, "test_macro_f1": 0.4086092661010112, "test_runtime": 4.2402, "test_samples_per_second": 482.994, "test_steps_per_second": 15.094}, {"test_loss": 0.9200374484062195, "test_mcc": 0.2431241789701552, "test_macro_f1": 0.39788029093281946, "test_runtime": 4.2722, "test_samples_per_second": 479.374, "test_steps_per_second": 14.98}, {"test_loss": 0.9389991760253906, "test_mcc": 0.2149230681847147, "test_macro_f1": 0.3818608571613824, "test_runtime": 4.3996, "test_samples_per_second": 465.496, "test_steps_per_second": 14.547}, {"test_loss": 0.9696153402328491, "test_mcc": 0.23993035983768318, "test_macro_f1": 0.39431780447644577, "test_runtime": 4.4946, "test_samples_per_second": 455.662, "test_steps_per_second": 14.239}]}, "total": {"test_mcc": 25.676617168644988, "test_mcc_se": 2.168948337106942, "test_macro_f1": 41.64999162579976, "test_macro_f1_se": 2.76625995477753}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.08333513885736465, "test_micro_f1": 0.5778219791148682, "test_micro_f1_no_misc": 0.6768853464132434, "test_runtime": 7.402, "test_samples_per_second": 276.681, "test_steps_per_second": 8.646}, {"test_loss": 0.06799744069576263, "test_micro_f1": 0.6219448777951119, "test_micro_f1_no_misc": 0.669683257918552, "test_runtime": 6.8511, "test_samples_per_second": 298.93, "test_steps_per_second": 9.342}, {"test_loss": 0.06688964366912842, "test_micro_f1": 0.6508172362555722, "test_micro_f1_no_misc": 0.6957494407158836, "test_runtime": 6.8487, "test_samples_per_second": 299.033, "test_steps_per_second": 9.345}, {"test_loss": 0.06838636100292206, "test_micro_f1": 0.6457225712904785, "test_micro_f1_no_misc": 0.6885593220338982, "test_runtime": 7.2769, "test_samples_per_second": 281.437, "test_steps_per_second": 8.795}, {"test_loss": 0.07643957436084747, "test_micro_f1": 0.6509615384615385, "test_micro_f1_no_misc": 0.6912681912681913, "test_runtime": 7.1868, "test_samples_per_second": 284.966, "test_steps_per_second": 8.905}, {"test_loss": 0.07277350127696991, "test_micro_f1": 0.6509877704609596, "test_micro_f1_no_misc": 0.7007534983853605, "test_runtime": 6.0431, "test_samples_per_second": 338.9, "test_steps_per_second": 10.591}, {"test_loss": 0.08169598877429962, "test_micro_f1": 0.6153846153846154, "test_micro_f1_no_misc": 0.6684694429421308, "test_runtime": 6.3945, "test_samples_per_second": 320.276, "test_steps_per_second": 10.009}, {"test_loss": 0.06710159778594971, "test_micro_f1": 0.6498659517426274, "test_micro_f1_no_misc": 0.7076923076923076, "test_runtime": 7.1732, "test_samples_per_second": 285.505, "test_steps_per_second": 8.922}, {"test_loss": 0.07163403928279877, "test_micro_f1": 0.6222430783669639, "test_micro_f1_no_misc": 0.6712328767123288, "test_runtime": 6.783, "test_samples_per_second": 301.932, "test_steps_per_second": 9.435}, {"test_loss": 0.07313495874404907, "test_micro_f1": 0.6430260047281324, "test_micro_f1_no_misc": 0.7123893805309734, "test_runtime": 7.2312, "test_samples_per_second": 283.215, "test_steps_per_second": 8.85}]}, "total": {"test_micro_f1": 63.28775623600868, "test_micro_f1_se": 1.4758926561111865, "test_micro_f1_no_misc": 68.8268306461287, "test_micro_f1_no_misc_se": 0.9988152855351019}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.10385581851005554, "test_micro_f1": 0.6510562484092645, "test_micro_f1_no_misc": 0.6728415481309957, "test_runtime": 10.4098, "test_samples_per_second": 196.739, "test_steps_per_second": 6.148}, {"test_loss": 0.10242658853530884, "test_micro_f1": 0.6432681242807825, "test_micro_f1_no_misc": 0.6609009009009009, "test_runtime": 8.1949, "test_samples_per_second": 249.911, "test_steps_per_second": 7.81}, {"test_loss": 0.09389518201351166, "test_micro_f1": 0.7039701572075674, "test_micro_f1_no_misc": 0.7125220458553791, "test_runtime": 10.5089, "test_samples_per_second": 194.883, "test_steps_per_second": 6.09}, {"test_loss": 0.0925954282283783, "test_micro_f1": 0.6926429120738272, "test_micro_f1_no_misc": 0.7062374245472838, "test_runtime": 10.1063, "test_samples_per_second": 202.646, "test_steps_per_second": 6.333}, {"test_loss": 0.10545124113559723, "test_micro_f1": 0.6026323158779053, "test_micro_f1_no_misc": 0.6331205407435223, "test_runtime": 10.7263, "test_samples_per_second": 190.932, "test_steps_per_second": 5.967}, {"test_loss": 0.09892302751541138, "test_micro_f1": 0.648108108108108, "test_micro_f1_no_misc": 0.6520960229308491, "test_runtime": 10.2647, "test_samples_per_second": 199.519, "test_steps_per_second": 6.235}, {"test_loss": 0.09076475352048874, "test_micro_f1": 0.6819943167140274, "test_micro_f1_no_misc": 0.6893004115226338, "test_runtime": 10.7121, "test_samples_per_second": 191.186, "test_steps_per_second": 5.975}, {"test_loss": 0.08925611525774002, "test_micro_f1": 0.6563002680965148, "test_micro_f1_no_misc": 0.6813031161473088, "test_runtime": 10.4458, "test_samples_per_second": 196.059, "test_steps_per_second": 6.127}, {"test_loss": 0.1005929708480835, "test_micro_f1": 0.6652360515021458, "test_micro_f1_no_misc": 0.673167208378476, "test_runtime": 10.0626, "test_samples_per_second": 203.526, "test_steps_per_second": 6.36}, {"test_loss": 0.09571968764066696, "test_micro_f1": 0.7165483342435828, "test_micro_f1_no_misc": 0.7233285917496444, "test_runtime": 8.2715, "test_samples_per_second": 247.598, "test_steps_per_second": 7.737}]}, "total": {"test_micro_f1": 66.61756836513726, "test_micro_f1_se": 2.079666495402546, "test_micro_f1_no_misc": 68.04817810906994, "test_micro_f1_no_misc_se": 1.746777920769552}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.08656079322099686, "test_micro_f1": 0.6204667863554758, "test_micro_f1_no_misc": 0.6650812524772097, "test_runtime": 7.8637, "test_samples_per_second": 260.436, "test_steps_per_second": 8.139}, {"test_loss": 0.08576560020446777, "test_micro_f1": 0.6105941302791696, "test_micro_f1_no_misc": 0.6458414681764936, "test_runtime": 7.7912, "test_samples_per_second": 262.861, "test_steps_per_second": 8.214}, {"test_loss": 0.07620088756084442, "test_micro_f1": 0.6487418131678732, "test_micro_f1_no_misc": 0.69453125, "test_runtime": 7.5567, "test_samples_per_second": 271.018, "test_steps_per_second": 8.469}, {"test_loss": 0.07353471219539642, "test_micro_f1": 0.6698434309053779, "test_micro_f1_no_misc": 0.7010689273866568, "test_runtime": 7.7396, "test_samples_per_second": 264.613, "test_steps_per_second": 8.269}, {"test_loss": 0.0802885890007019, "test_micro_f1": 0.6476938174681061, "test_micro_f1_no_misc": 0.6902465166130761, "test_runtime": 7.9915, "test_samples_per_second": 256.272, "test_steps_per_second": 8.009}, {"test_loss": 0.07776445150375366, "test_micro_f1": 0.628494442573257, "test_micro_f1_no_misc": 0.6619718309859155, "test_runtime": 7.9848, "test_samples_per_second": 256.487, "test_steps_per_second": 8.015}, {"test_loss": 0.0841209888458252, "test_micro_f1": 0.631071305545987, "test_micro_f1_no_misc": 0.6597709641669744, "test_runtime": 7.2627, "test_samples_per_second": 281.991, "test_steps_per_second": 8.812}, {"test_loss": 0.07168160378932953, "test_micro_f1": 0.6682642930503252, "test_micro_f1_no_misc": 0.7073170731707317, "test_runtime": 7.5378, "test_samples_per_second": 271.697, "test_steps_per_second": 8.491}, {"test_loss": 0.0721718817949295, "test_micro_f1": 0.6817548746518106, "test_micro_f1_no_misc": 0.724477729601892, "test_runtime": 7.3908, "test_samples_per_second": 277.102, "test_steps_per_second": 8.659}, {"test_loss": 0.08408340811729431, "test_micro_f1": 0.6764305177111716, "test_micro_f1_no_misc": 0.712609970674487, "test_runtime": 7.3855, "test_samples_per_second": 277.298, "test_steps_per_second": 8.666}]}, "total": {"test_micro_f1": 64.83355411708554, "test_micro_f1_se": 1.5542339325875687, "test_micro_f1_no_misc": 68.62916983253436, "test_micro_f1_no_misc_se": 1.6366877020534794}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.09843629598617554, "test_micro_f1": 0.5359165424739195, "test_micro_f1_no_misc": 0.5646984924623115, "test_runtime": 7.0929, "test_samples_per_second": 288.738, "test_steps_per_second": 9.023}, {"test_loss": 0.09326571226119995, "test_micro_f1": 0.6210239321417752, "test_micro_f1_no_misc": 0.6595102314659511, "test_runtime": 7.7242, "test_samples_per_second": 265.142, "test_steps_per_second": 8.286}, {"test_loss": 0.09238703548908234, "test_micro_f1": 0.6525037936267072, "test_micro_f1_no_misc": 0.6956521739130436, "test_runtime": 7.0253, "test_samples_per_second": 291.52, "test_steps_per_second": 9.11}, {"test_loss": 0.09619524329900742, "test_micro_f1": 0.6676664667066586, "test_micro_f1_no_misc": 0.7050599201065246, "test_runtime": 7.2042, "test_samples_per_second": 284.278, "test_steps_per_second": 8.884}, {"test_loss": 0.09817515313625336, "test_micro_f1": 0.6337051552607778, "test_micro_f1_no_misc": 0.6748299319727892, "test_runtime": 6.5449, "test_samples_per_second": 312.917, "test_steps_per_second": 9.779}, {"test_loss": 0.09852490574121475, "test_micro_f1": 0.6424747174301011, "test_micro_f1_no_misc": 0.6928452579034942, "test_runtime": 6.5607, "test_samples_per_second": 312.16, "test_steps_per_second": 9.755}, {"test_loss": 0.08236594498157501, "test_micro_f1": 0.6283267054144999, "test_micro_f1_no_misc": 0.6754357119368628, "test_runtime": 7.7824, "test_samples_per_second": 263.16, "test_steps_per_second": 8.224}, {"test_loss": 0.08291438966989517, "test_micro_f1": 0.6652656859801862, "test_micro_f1_no_misc": 0.708671646638519, "test_runtime": 7.7536, "test_samples_per_second": 264.135, "test_steps_per_second": 8.254}, {"test_loss": 0.09438187628984451, "test_micro_f1": 0.6357738646895273, "test_micro_f1_no_misc": 0.6778749159381304, "test_runtime": 6.6042, "test_samples_per_second": 310.107, "test_steps_per_second": 9.691}, {"test_loss": 0.08678086847066879, "test_micro_f1": 0.6875570428962579, "test_micro_f1_no_misc": 0.7150874876196764, "test_runtime": 7.1414, "test_samples_per_second": 286.778, "test_steps_per_second": 8.962}]}, "total": {"test_micro_f1": 63.70213906620411, "test_micro_f1_se": 2.540989379570852, "test_micro_f1_no_misc": 67.69665769957302, "test_micro_f1_no_misc_se": 2.6751200585845174}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6109268069267273, "test_mcc": 0.3695436417944134, "test_macro_f1": 0.6171280345586756, "test_runtime": 3.4734, "test_samples_per_second": 589.624, "test_steps_per_second": 18.426}, {"test_loss": 0.6454979181289673, "test_mcc": 0.3265248928055525, "test_macro_f1": 0.6044618804961818, "test_runtime": 3.6311, "test_samples_per_second": 564.017, "test_steps_per_second": 17.626}, {"test_loss": 0.6866667866706848, "test_mcc": 0.17240427216745458, "test_macro_f1": 0.5713704701692444, "test_runtime": 3.6086, "test_samples_per_second": 567.527, "test_steps_per_second": 17.735}, {"test_loss": 0.6882486939430237, "test_mcc": 0.08459557744186814, "test_macro_f1": 0.4245213398144139, "test_runtime": 3.5583, "test_samples_per_second": 575.561, "test_steps_per_second": 17.986}, {"test_loss": 0.6276520490646362, "test_mcc": 0.39247632711700137, "test_macro_f1": 0.6644768518692215, "test_runtime": 3.6146, "test_samples_per_second": 566.597, "test_steps_per_second": 17.706}, {"test_loss": 0.5677735805511475, "test_mcc": 0.45482282269386504, "test_macro_f1": 0.718548922184332, "test_runtime": 3.5502, "test_samples_per_second": 576.875, "test_steps_per_second": 18.027}, {"test_loss": 0.6127386093139648, "test_mcc": 0.39639898993262396, "test_macro_f1": 0.6461828080330132, "test_runtime": 3.6784, "test_samples_per_second": 556.756, "test_steps_per_second": 17.399}, {"test_loss": 0.576533317565918, "test_mcc": 0.42046579192278033, "test_macro_f1": 0.6898824945389465, "test_runtime": 3.639, "test_samples_per_second": 562.787, "test_steps_per_second": 17.587}, {"test_loss": 0.6802561283111572, "test_mcc": 0.22792051235203406, "test_macro_f1": 0.5230041170414532, "test_runtime": 3.6236, "test_samples_per_second": 565.19, "test_steps_per_second": 17.662}, {"test_loss": 0.6937781572341919, "test_mcc": 0.016362280038848837, "test_macro_f1": 0.47362485183039804, "test_runtime": 3.6171, "test_samples_per_second": 566.206, "test_steps_per_second": 17.694}]}, "total": {"test_mcc": 28.615151082664426, "test_mcc_se": 9.428719950987094, "test_macro_f1": 59.332017705358794, "test_macro_f1_se": 5.9090147333572105}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6935571432113647, "test_mcc": 0.004788412925580909, "test_macro_f1": 0.49230504851316087, "test_runtime": 4.7513, "test_samples_per_second": 431.041, "test_steps_per_second": 13.47}, {"test_loss": 0.6922372579574585, "test_mcc": 0.020715528920540183, "test_macro_f1": 0.47721828454031845, "test_runtime": 4.9362, "test_samples_per_second": 414.896, "test_steps_per_second": 12.965}, {"test_loss": 0.6899881362915039, "test_mcc": 0.10113257549270734, "test_macro_f1": 0.50354186763188, "test_runtime": 4.8075, "test_samples_per_second": 426.0, "test_steps_per_second": 13.312}, {"test_loss": 0.6800103783607483, "test_mcc": 0.18309434603443, "test_macro_f1": 0.573743131111146, "test_runtime": 4.9837, "test_samples_per_second": 410.94, "test_steps_per_second": 12.842}, {"test_loss": 0.6828935146331787, "test_mcc": 0.12814873076715017, "test_macro_f1": 0.552176144050007, "test_runtime": 4.8238, "test_samples_per_second": 424.564, "test_steps_per_second": 13.268}, {"test_loss": 0.6816816329956055, "test_mcc": 0.1598999952884226, "test_macro_f1": 0.5108261500920512, "test_runtime": 4.7644, "test_samples_per_second": 429.857, "test_steps_per_second": 13.433}, {"test_loss": 0.6908923387527466, "test_mcc": 0.06723774182859217, "test_macro_f1": 0.5169413454964885, "test_runtime": 4.7454, "test_samples_per_second": 431.576, "test_steps_per_second": 13.487}, {"test_loss": 0.6919625997543335, "test_mcc": 0.032328874394762806, "test_macro_f1": 0.513699552683837, "test_runtime": 4.6958, "test_samples_per_second": 436.13, "test_steps_per_second": 13.629}, {"test_loss": 0.689682126045227, "test_mcc": 0.07776546798063207, "test_macro_f1": 0.5384940057111176, "test_runtime": 4.6991, "test_samples_per_second": 435.827, "test_steps_per_second": 13.62}, {"test_loss": 0.6931597590446472, "test_mcc": 0.03868154428657386, "test_macro_f1": 0.4988598991231597, "test_runtime": 4.8022, "test_samples_per_second": 426.469, "test_steps_per_second": 13.327}]}, "total": {"test_mcc": 8.137932179193921, "test_mcc_se": 3.75751106896523, "test_macro_f1": 51.77805428953166, "test_macro_f1_se": 1.808762125518977}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.690674901008606, "test_mcc": 0.06276789359099708, "test_macro_f1": 0.41631095372895577, "test_runtime": 4.2633, "test_samples_per_second": 480.382, "test_steps_per_second": 15.012}, {"test_loss": 0.6925686001777649, "test_mcc": 0.04650494823320662, "test_macro_f1": 0.42311230833567604, "test_runtime": 4.31, "test_samples_per_second": 475.176, "test_steps_per_second": 14.849}, {"test_loss": 0.6900498867034912, "test_mcc": 0.04354879606932922, "test_macro_f1": 0.44238149569546725, "test_runtime": 4.3167, "test_samples_per_second": 474.436, "test_steps_per_second": 14.826}, {"test_loss": 0.6925312280654907, "test_mcc": 0.017903495095138937, "test_macro_f1": 0.5001711302019046, "test_runtime": 4.4006, "test_samples_per_second": 465.388, "test_steps_per_second": 14.543}, {"test_loss": 0.6959934830665588, "test_mcc": -0.057225706174062474, "test_macro_f1": 0.42223625760542327, "test_runtime": 4.3031, "test_samples_per_second": 475.94, "test_steps_per_second": 14.873}, {"test_loss": 0.6897698044776917, "test_mcc": 0.09291331478674658, "test_macro_f1": 0.5165683543233237, "test_runtime": 4.1612, "test_samples_per_second": 492.169, "test_steps_per_second": 15.38}, {"test_loss": 0.6961485147476196, "test_mcc": -0.03542470696830841, "test_macro_f1": 0.4733033857496465, "test_runtime": 4.2007, "test_samples_per_second": 487.538, "test_steps_per_second": 15.236}, {"test_loss": 0.6851305365562439, "test_mcc": 0.10970904951887261, "test_macro_f1": 0.48358515119206397, "test_runtime": 4.2146, "test_samples_per_second": 485.931, "test_steps_per_second": 15.185}, {"test_loss": 0.6668247580528259, "test_mcc": 0.2347457497496023, "test_macro_f1": 0.5964294642725843, "test_runtime": 4.24, "test_samples_per_second": 483.018, "test_steps_per_second": 15.094}, {"test_loss": 0.6684024930000305, "test_mcc": 0.1578537046700633, "test_macro_f1": 0.5456061734819301, "test_runtime": 4.4029, "test_samples_per_second": 465.143, "test_steps_per_second": 14.536}]}, "total": {"test_mcc": 6.7329653857158585, "test_mcc_se": 5.395787350381853, "test_macro_f1": 48.197046745869756, "test_macro_f1_se": 3.676547963185793}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6975672245025635, "test_mcc": 0.03293067718717487, "test_macro_f1": 0.39005261590390156, "test_runtime": 4.2852, "test_samples_per_second": 477.919, "test_steps_per_second": 14.935}, {"test_loss": 0.6919114589691162, "test_mcc": 0.0283067784917523, "test_macro_f1": 0.42138188140495175, "test_runtime": 4.3836, "test_samples_per_second": 467.191, "test_steps_per_second": 14.6}, {"test_loss": 0.6902399063110352, "test_mcc": 0.06405762882010982, "test_macro_f1": 0.5196904449853336, "test_runtime": 4.3921, "test_samples_per_second": 466.292, "test_steps_per_second": 14.572}, {"test_loss": 0.6944200992584229, "test_mcc": -0.01983311412033422, "test_macro_f1": 0.48141568145312164, "test_runtime": 4.13, "test_samples_per_second": 495.886, "test_steps_per_second": 15.496}, {"test_loss": 0.6939616799354553, "test_mcc": 0.030981790993979436, "test_macro_f1": 0.5145817754513407, "test_runtime": 4.2122, "test_samples_per_second": 486.207, "test_steps_per_second": 15.194}, {"test_loss": 0.691857099533081, "test_mcc": 0.011457810998099996, "test_macro_f1": 0.4460281907576803, "test_runtime": 4.3919, "test_samples_per_second": 466.308, "test_steps_per_second": 14.572}, {"test_loss": 0.692922830581665, "test_mcc": 0.02597526164689717, "test_macro_f1": 0.47417358213745353, "test_runtime": 4.2892, "test_samples_per_second": 477.482, "test_steps_per_second": 14.921}, {"test_loss": 0.6909058094024658, "test_mcc": 0.013826587967766044, "test_macro_f1": 0.4880062059853819, "test_runtime": 4.5086, "test_samples_per_second": 454.244, "test_steps_per_second": 14.195}, {"test_loss": 0.6785345673561096, "test_mcc": 0.13667213708220755, "test_macro_f1": 0.567995044829527, "test_runtime": 4.251, "test_samples_per_second": 481.769, "test_steps_per_second": 15.055}, {"test_loss": 0.6927684545516968, "test_mcc": 0.010290737421541454, "test_macro_f1": 0.4485636412006296, "test_runtime": 4.3593, "test_samples_per_second": 469.795, "test_steps_per_second": 14.681}]}, "total": {"test_mcc": 3.3466629648919444, "test_mcc_se": 2.6071599080799346, "test_macro_f1": 47.518890641093215, "test_macro_f1_se": 3.204124593829029}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 34.08210689388071, "test_f1": 38.08138541086098}, {"test_em": 39.06976744186046, "test_f1": 43.268311791567605}, {"test_em": 31.375579598145286, "test_f1": 36.245151250947245}, {"test_em": 26.557632398753896, "test_f1": 31.979825834206505}, {"test_em": 32.818532818532816, "test_f1": 37.29401511754454}, {"test_em": 27.139552814186583, "test_f1": 33.20110808470468}, {"test_em": 31.814730447987852, "test_f1": 35.00017664890687}, {"test_em": 30.17843289371606, "test_f1": 34.98381195882321}, {"test_em": 37.333333333333336, "test_f1": 41.12521987816108}, {"test_em": 31.444099378881987, "test_f1": 35.67273260778925}]}, "total": {"test_em": 32.1813768019279, "test_em_se": 2.4480123251335666, "test_f1": 36.685173858351206, "test_f1_se": 2.1331441139796787}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 26.56855151045701, "test_f1": 32.06483787126031}, {"test_em": 39.06976744186046, "test_f1": 44.20381170750166}, {"test_em": 36.93972179289026, "test_f1": 41.627341387295665}, {"test_em": 23.753894080996886, "test_f1": 29.37480176821489}, {"test_em": 35.5984555984556, "test_f1": 40.86244048296238}, {"test_em": 40.47802621434079, "test_f1": 45.73328730849899}, {"test_em": 37.12984054669704, "test_f1": 42.688092925791906}, {"test_em": 36.53995345228859, "test_f1": 40.97686611235406}, {"test_em": 40.94117647058823, "test_f1": 46.34575811219409}, {"test_em": 38.12111801242236, "test_f1": 44.313861606235356}]}, "total": {"test_em": 35.51405051209973, "test_em_se": 3.563876883616923, "test_f1": 40.81910992823093, "test_f1_se": 3.519187404773948}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 37.41285824941905, "test_f1": 42.63673077925357}, {"test_em": 37.906976744186046, "test_f1": 42.68071624591174}, {"test_em": 33.61669242658424, "test_f1": 38.65410202838009}, {"test_em": 39.875389408099686, "test_f1": 45.08515867613535}, {"test_em": 36.67953667953668, "test_f1": 42.68898322853862}, {"test_em": 38.781804163454126, "test_f1": 43.48674880242237}, {"test_em": 42.67274107820805, "test_f1": 47.87290200729834}, {"test_em": 37.470907680372385, "test_f1": 42.14417425254885}, {"test_em": 34.745098039215684, "test_f1": 39.30264242256595}, {"test_em": 36.18012422360248, "test_f1": 41.36433475549232}]}, "total": {"test_em": 37.53421286926785, "test_em_se": 1.5908352282538245, "test_f1": 42.59164931985472, "test_f1_se": 1.6393100819583402}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.3992093801498413, "test_mcc": 0.7271667380324492, "test_macro_f1": 0.5955359582117606, "test_runtime": 14.6554, "test_samples_per_second": 139.744, "test_steps_per_second": 17.468}, {"test_loss": 0.4661298096179962, "test_mcc": 0.6911878209892228, "test_macro_f1": 0.6491174781250625, "test_runtime": 13.8493, "test_samples_per_second": 147.878, "test_steps_per_second": 18.485}, {"test_loss": 0.4467913508415222, "test_mcc": 0.7305786915653155, "test_macro_f1": 0.6890406176848404, "test_runtime": 14.1466, "test_samples_per_second": 144.77, "test_steps_per_second": 18.096}, {"test_loss": 0.4009768068790436, "test_mcc": 0.7387795169400553, "test_macro_f1": 0.7347159409696317, "test_runtime": 13.732, "test_samples_per_second": 149.141, "test_steps_per_second": 18.643}, {"test_loss": 0.41939613223075867, "test_mcc": 0.7473842638937696, "test_macro_f1": 0.6985676665719053, "test_runtime": 13.5852, "test_samples_per_second": 150.752, "test_steps_per_second": 18.844}, {"test_loss": 0.43778640031814575, "test_mcc": 0.7177421221369708, "test_macro_f1": 0.6729860813055568, "test_runtime": 13.7979, "test_samples_per_second": 148.428, "test_steps_per_second": 18.554}, {"test_loss": 0.4066251218318939, "test_mcc": 0.7377552141927078, "test_macro_f1": 0.7385988759019405, "test_runtime": 13.3749, "test_samples_per_second": 153.122, "test_steps_per_second": 19.14}, {"test_loss": 0.4144097566604614, "test_mcc": 0.7301970090401164, "test_macro_f1": 0.7032740507051657, "test_runtime": 14.5071, "test_samples_per_second": 141.172, "test_steps_per_second": 17.647}, {"test_loss": 0.4599790573120117, "test_mcc": 0.7147020906803057, "test_macro_f1": 0.6037243484259012, "test_runtime": 14.4316, "test_samples_per_second": 141.911, "test_steps_per_second": 17.739}, {"test_loss": 0.4489957094192505, "test_mcc": 0.7178063103403364, "test_macro_f1": 0.6888904759654279, "test_runtime": 13.9048, "test_samples_per_second": 147.287, "test_steps_per_second": 18.411}]}, "total": {"test_mcc": 72.5329977781125, "test_mcc_se": 0.984150504434476, "test_macro_f1": 67.74451493867193, "test_macro_f1_se": 3.019833417799886}}, "num_model_parameters": 124448259, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.7684797048568726, "test_mcc": 0.49157049938558217, "test_macro_f1": 0.662807701944465, "test_runtime": 4.4259, "test_samples_per_second": 462.733, "test_steps_per_second": 14.46}, {"test_loss": 0.8558840751647949, "test_mcc": 0.47277284417939347, "test_macro_f1": 0.6437898749833649, "test_runtime": 4.369, "test_samples_per_second": 468.762, "test_steps_per_second": 14.649}, {"test_loss": 0.8824273347854614, "test_mcc": 0.4353426146810378, "test_macro_f1": 0.6110208043934265, "test_runtime": 4.4166, "test_samples_per_second": 463.706, "test_steps_per_second": 14.491}, {"test_loss": 0.8393421173095703, "test_mcc": 0.5202389227383851, "test_macro_f1": 0.6739157347457606, "test_runtime": 4.2987, "test_samples_per_second": 476.418, "test_steps_per_second": 14.888}, {"test_loss": 0.8184480667114258, "test_mcc": 0.486857972384627, "test_macro_f1": 0.6553269611082746, "test_runtime": 4.3003, "test_samples_per_second": 476.242, "test_steps_per_second": 14.883}, {"test_loss": 0.799789309501648, "test_mcc": 0.48563956396400265, "test_macro_f1": 0.6617296938527483, "test_runtime": 4.3889, "test_samples_per_second": 466.635, "test_steps_per_second": 14.582}, {"test_loss": 0.8224369287490845, "test_mcc": 0.44681297233540374, "test_macro_f1": 0.6275757242463343, "test_runtime": 4.3094, "test_samples_per_second": 475.236, "test_steps_per_second": 14.851}, {"test_loss": 0.8398343324661255, "test_mcc": 0.4750336950342091, "test_macro_f1": 0.6457183263514437, "test_runtime": 4.3838, "test_samples_per_second": 467.17, "test_steps_per_second": 14.599}, {"test_loss": 0.803257942199707, "test_mcc": 0.4824211729926796, "test_macro_f1": 0.6539826140537685, "test_runtime": 4.4181, "test_samples_per_second": 463.548, "test_steps_per_second": 14.486}, {"test_loss": 0.8214430212974548, "test_mcc": 0.47651199477520784, "test_macro_f1": 0.6491119386266327, "test_runtime": 4.2658, "test_samples_per_second": 480.095, "test_steps_per_second": 15.003}]}, "total": {"test_mcc": 47.732022524705286, "test_mcc_se": 1.4536713637526404, "test_macro_f1": 64.84979374306221, "test_macro_f1_se": 1.1269145887321574}}, "num_model_parameters": 124448259, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.8276816606521606, "test_mcc": 0.43331857232799514, "test_macro_f1": 0.47681636558133406, "test_runtime": 3.5912, "test_samples_per_second": 570.28, "test_steps_per_second": 17.821}, {"test_loss": 0.7938814759254456, "test_mcc": 0.5396666871163165, "test_macro_f1": 0.6760015810586039, "test_runtime": 3.3183, "test_samples_per_second": 617.179, "test_steps_per_second": 19.287}, {"test_loss": 0.7885881662368774, "test_mcc": 0.476026281487401, "test_macro_f1": 0.5773333408103365, "test_runtime": 3.3679, "test_samples_per_second": 608.098, "test_steps_per_second": 19.003}, {"test_loss": 0.7849661111831665, "test_mcc": 0.5741020001292844, "test_macro_f1": 0.7034751457329552, "test_runtime": 3.392, "test_samples_per_second": 603.775, "test_steps_per_second": 18.868}, {"test_loss": 0.799677312374115, "test_mcc": 0.525608240938373, "test_macro_f1": 0.663763720384508, "test_runtime": 3.4132, "test_samples_per_second": 600.015, "test_steps_per_second": 18.75}, {"test_loss": 0.7537678480148315, "test_mcc": 0.5619349571517986, "test_macro_f1": 0.6898133568079291, "test_runtime": 3.521, "test_samples_per_second": 581.65, "test_steps_per_second": 18.177}, {"test_loss": 0.7171666622161865, "test_mcc": 0.47229091255698286, "test_macro_f1": 0.5142009964949782, "test_runtime": 3.417, "test_samples_per_second": 599.352, "test_steps_per_second": 18.73}, {"test_loss": 0.7731949687004089, "test_mcc": 0.5393649131578953, "test_macro_f1": 0.6598178207900158, "test_runtime": 3.4245, "test_samples_per_second": 598.043, "test_steps_per_second": 18.689}, {"test_loss": 0.7995756268501282, "test_mcc": 0.520011317673581, "test_macro_f1": 0.644489869312299, "test_runtime": 3.53, "test_samples_per_second": 580.163, "test_steps_per_second": 18.13}, {"test_loss": 0.7651185989379883, "test_mcc": 0.44783144734969316, "test_macro_f1": 0.4898163309204813, "test_runtime": 3.546, "test_samples_per_second": 577.553, "test_steps_per_second": 18.049}]}, "total": {"test_mcc": 50.90155329889321, "test_mcc_se": 3.0084583114177987, "test_macro_f1": 60.95528527893441, "test_macro_f1_se": 5.4053391314692245}}, "num_model_parameters": 124448259, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.05389464646577835, "test_micro_f1": 0.7299118714359771, "test_micro_f1_no_misc": 0.8109756097560975, "test_runtime": 6.863, "test_samples_per_second": 298.413, "test_steps_per_second": 9.325}, {"test_loss": 0.04873857647180557, "test_micro_f1": 0.7692307692307693, "test_micro_f1_no_misc": 0.8238805970149254, "test_runtime": 6.2683, "test_samples_per_second": 326.721, "test_steps_per_second": 10.21}, {"test_loss": 0.04848256707191467, "test_micro_f1": 0.7011385199240987, "test_micro_f1_no_misc": 0.7723532638507954, "test_runtime": 6.372, "test_samples_per_second": 321.407, "test_steps_per_second": 10.044}, {"test_loss": 0.057226281613111496, "test_micro_f1": 0.6605326876513318, "test_micro_f1_no_misc": 0.7036069001568217, "test_runtime": 6.8374, "test_samples_per_second": 299.529, "test_steps_per_second": 9.36}, {"test_loss": 0.06053805351257324, "test_micro_f1": 0.72, "test_micro_f1_no_misc": 0.7738158594997339, "test_runtime": 6.8479, "test_samples_per_second": 299.071, "test_steps_per_second": 9.346}, {"test_loss": 0.05593976005911827, "test_micro_f1": 0.7364928909952606, "test_micro_f1_no_misc": 0.7910685805422648, "test_runtime": 5.8145, "test_samples_per_second": 352.222, "test_steps_per_second": 11.007}, {"test_loss": 0.054003991186618805, "test_micro_f1": 0.7447535383113715, "test_micro_f1_no_misc": 0.8109313998884551, "test_runtime": 5.9524, "test_samples_per_second": 344.061, "test_steps_per_second": 10.752}, {"test_loss": 0.04802896827459335, "test_micro_f1": 0.7719112988384371, "test_micro_f1_no_misc": 0.8277571251548946, "test_runtime": 6.8507, "test_samples_per_second": 298.947, "test_steps_per_second": 9.342}, {"test_loss": 0.04787178710103035, "test_micro_f1": 0.72936660268714, "test_micro_f1_no_misc": 0.7737459978655283, "test_runtime": 6.726, "test_samples_per_second": 304.492, "test_steps_per_second": 9.515}, {"test_loss": 0.047215670347213745, "test_micro_f1": 0.7428298279158699, "test_micro_f1_no_misc": 0.8198970840480274, "test_runtime": 6.8965, "test_samples_per_second": 296.961, "test_steps_per_second": 9.28}]}, "total": {"test_micro_f1": 73.06168006990255, "test_micro_f1_se": 2.0110928995056963, "test_micro_f1_no_misc": 79.08032417777544, "test_micro_f1_no_misc_se": 2.3229114446895713}}, "num_model_parameters": 123862281, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.05232885107398033, "test_micro_f1": 0.84593837535014, "test_micro_f1_no_misc": 0.8587257617728531, "test_runtime": 7.7608, "test_samples_per_second": 263.89, "test_steps_per_second": 8.247}, {"test_loss": 0.05415869504213333, "test_micro_f1": 0.8141397404032035, "test_micro_f1_no_misc": 0.8309808179515019, "test_runtime": 6.2911, "test_samples_per_second": 325.537, "test_steps_per_second": 10.173}, {"test_loss": 0.05456845834851265, "test_micro_f1": 0.8488150367747207, "test_micro_f1_no_misc": 0.8646888567293778, "test_runtime": 7.2094, "test_samples_per_second": 284.072, "test_steps_per_second": 8.877}, {"test_loss": 0.06312195211648941, "test_micro_f1": 0.8142172926644821, "test_micro_f1_no_misc": 0.8306122448979592, "test_runtime": 7.1077, "test_samples_per_second": 288.138, "test_steps_per_second": 9.004}, {"test_loss": 0.062395285815000534, "test_micro_f1": 0.7905027932960893, "test_micro_f1_no_misc": 0.808682855040471, "test_runtime": 7.4348, "test_samples_per_second": 275.462, "test_steps_per_second": 8.608}, {"test_loss": 0.05683014541864395, "test_micro_f1": 0.8307860262008734, "test_micro_f1_no_misc": 0.8479880774962741, "test_runtime": 7.1671, "test_samples_per_second": 285.75, "test_steps_per_second": 8.93}, {"test_loss": 0.0543486550450325, "test_micro_f1": 0.8328507501974204, "test_micro_f1_no_misc": 0.8438162544169612, "test_runtime": 7.4775, "test_samples_per_second": 273.888, "test_steps_per_second": 8.559}, {"test_loss": 0.0525081604719162, "test_micro_f1": 0.8547625659539017, "test_micro_f1_no_misc": 0.8704393149664928, "test_runtime": 7.4429, "test_samples_per_second": 275.16, "test_steps_per_second": 8.599}, {"test_loss": 0.05847206711769104, "test_micro_f1": 0.7977970102281667, "test_micro_f1_no_misc": 0.8160707703649097, "test_runtime": 7.1592, "test_samples_per_second": 286.064, "test_steps_per_second": 8.939}, {"test_loss": 0.05757080018520355, "test_micro_f1": 0.8320209973753282, "test_micro_f1_no_misc": 0.8608507570295602, "test_runtime": 6.7938, "test_samples_per_second": 301.453, "test_steps_per_second": 9.42}]}, "total": {"test_micro_f1": 82.61830588444326, "test_micro_f1_se": 1.336711747034487, "test_micro_f1_no_misc": 84.32855710666361, "test_micro_f1_no_misc_se": 1.3090769362173176}}, "num_model_parameters": 123862281, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.04016191512346268, "test_micro_f1": 0.8787656135194709, "test_micro_f1_no_misc": 0.9057071960297767, "test_runtime": 5.7621, "test_samples_per_second": 355.424, "test_steps_per_second": 11.107}, {"test_loss": 0.02927268110215664, "test_micro_f1": 0.8855869242199108, "test_micro_f1_no_misc": 0.9097713097713097, "test_runtime": 5.6938, "test_samples_per_second": 359.688, "test_steps_per_second": 11.24}, {"test_loss": 0.03336022421717644, "test_micro_f1": 0.9026548672566371, "test_micro_f1_no_misc": 0.9278597050617776, "test_runtime": 5.4163, "test_samples_per_second": 378.12, "test_steps_per_second": 11.816}, {"test_loss": 0.03595955669879913, "test_micro_f1": 0.8724077328646749, "test_micro_f1_no_misc": 0.900078678206137, "test_runtime": 5.3262, "test_samples_per_second": 384.511, "test_steps_per_second": 12.016}, {"test_loss": 0.027514971792697906, "test_micro_f1": 0.9015405224380442, "test_micro_f1_no_misc": 0.9235359940320774, "test_runtime": 5.8329, "test_samples_per_second": 351.114, "test_steps_per_second": 10.972}, {"test_loss": 0.027707859873771667, "test_micro_f1": 0.8900273224043715, "test_micro_f1_no_misc": 0.920550038197097, "test_runtime": 5.8054, "test_samples_per_second": 352.775, "test_steps_per_second": 11.024}, {"test_loss": 0.03330603986978531, "test_micro_f1": 0.87829962290024, "test_micro_f1_no_misc": 0.9025133282559026, "test_runtime": 5.3424, "test_samples_per_second": 383.352, "test_steps_per_second": 11.98}, {"test_loss": 0.029347529634833336, "test_micro_f1": 0.8836401528308441, "test_micro_f1_no_misc": 0.9110026286143447, "test_runtime": 5.2487, "test_samples_per_second": 390.193, "test_steps_per_second": 12.194}, {"test_loss": 0.032761670649051666, "test_micro_f1": 0.8681279195113187, "test_micro_f1_no_misc": 0.8955465587044534, "test_runtime": 5.3416, "test_samples_per_second": 383.408, "test_steps_per_second": 11.982}, {"test_loss": 0.04040854424238205, "test_micro_f1": 0.8836727649292371, "test_micro_f1_no_misc": 0.912280701754386, "test_runtime": 5.7144, "test_samples_per_second": 358.393, "test_steps_per_second": 11.2}]}, "total": {"test_micro_f1": 88.44723442874749, "test_micro_f1_se": 0.6971783405704862, "test_micro_f1_no_misc": 91.0884613862726, "test_micro_f1_no_misc_se": 0.6512859313356469}}, "num_model_parameters": 123862281, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.040815554559230804, "test_micro_f1": 0.8617383235385091, "test_micro_f1_no_misc": 0.8965991068361389, "test_runtime": 5.7226, "test_samples_per_second": 357.879, "test_steps_per_second": 11.184}, {"test_loss": 0.046358369290828705, "test_micro_f1": 0.8347082187595479, "test_micro_f1_no_misc": 0.8751269035532995, "test_runtime": 5.7871, "test_samples_per_second": 353.888, "test_steps_per_second": 11.059}, {"test_loss": 0.04716844484210014, "test_micro_f1": 0.8107780805328489, "test_micro_f1_no_misc": 0.8460499662390276, "test_runtime": 5.4617, "test_samples_per_second": 374.972, "test_steps_per_second": 11.718}, {"test_loss": 0.05129602551460266, "test_micro_f1": 0.8455726805681475, "test_micro_f1_no_misc": 0.8782338737495688, "test_runtime": 5.5471, "test_samples_per_second": 369.199, "test_steps_per_second": 11.537}, {"test_loss": 0.05672714114189148, "test_micro_f1": 0.7531837477258945, "test_micro_f1_no_misc": 0.8052917232021709, "test_runtime": 5.4053, "test_samples_per_second": 378.891, "test_steps_per_second": 11.84}, {"test_loss": 0.04314461350440979, "test_micro_f1": 0.8642493257416842, "test_micro_f1_no_misc": 0.9023728813559322, "test_runtime": 5.4631, "test_samples_per_second": 374.875, "test_steps_per_second": 11.715}, {"test_loss": 0.040327899158000946, "test_micro_f1": 0.8248447204968945, "test_micro_f1_no_misc": 0.8592999313658202, "test_runtime": 5.7544, "test_samples_per_second": 355.901, "test_steps_per_second": 11.122}, {"test_loss": 0.046048641204833984, "test_micro_f1": 0.7864077669902912, "test_micro_f1_no_misc": 0.8267017428477473, "test_runtime": 5.6545, "test_samples_per_second": 362.188, "test_steps_per_second": 11.318}, {"test_loss": 0.04754102602601051, "test_micro_f1": 0.8102345415778253, "test_micro_f1_no_misc": 0.8439811701412239, "test_runtime": 5.0749, "test_samples_per_second": 403.556, "test_steps_per_second": 12.611}, {"test_loss": 0.04381873831152916, "test_micro_f1": 0.7958561852528946, "test_micro_f1_no_misc": 0.8379265091863518, "test_runtime": 5.408, "test_samples_per_second": 378.695, "test_steps_per_second": 11.834}]}, "total": {"test_micro_f1": 81.87573591184538, "test_micro_f1_se": 2.160409981767536, "test_micro_f1_no_misc": 85.7158380847728, "test_micro_f1_no_misc_se": 1.922200599237103}}, "num_model_parameters": 123862281, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.343519926071167, "test_mcc": 0.739991571294792, "test_macro_f1": 0.8660360368102964, "test_runtime": 3.2084, "test_samples_per_second": 638.323, "test_steps_per_second": 19.948}, {"test_loss": 0.3622126579284668, "test_mcc": 0.7395025122387429, "test_macro_f1": 0.8674580857163667, "test_runtime": 3.3098, "test_samples_per_second": 618.777, "test_steps_per_second": 19.337}, {"test_loss": 0.3468799591064453, "test_mcc": 0.7521528214382743, "test_macro_f1": 0.8748257173900069, "test_runtime": 3.2712, "test_samples_per_second": 626.073, "test_steps_per_second": 19.565}, {"test_loss": 0.4060012102127075, "test_mcc": 0.6990637892558623, "test_macro_f1": 0.8383514568647807, "test_runtime": 3.2521, "test_samples_per_second": 629.749, "test_steps_per_second": 19.68}, {"test_loss": 0.37084436416625977, "test_mcc": 0.7508170126642382, "test_macro_f1": 0.8742295804315281, "test_runtime": 3.3947, "test_samples_per_second": 603.287, "test_steps_per_second": 18.853}, {"test_loss": 0.3843744993209839, "test_mcc": 0.721433938093052, "test_macro_f1": 0.8533594239559587, "test_runtime": 3.2805, "test_samples_per_second": 624.303, "test_steps_per_second": 19.509}, {"test_loss": 0.36088836193084717, "test_mcc": 0.7494890888646324, "test_macro_f1": 0.865908705766357, "test_runtime": 3.261, "test_samples_per_second": 628.027, "test_steps_per_second": 19.626}, {"test_loss": 0.4340095818042755, "test_mcc": 0.7152607775052544, "test_macro_f1": 0.8518064159970558, "test_runtime": 3.341, "test_samples_per_second": 612.99, "test_steps_per_second": 19.156}, {"test_loss": 0.3829939365386963, "test_mcc": 0.7457753743640675, "test_macro_f1": 0.8656935207616461, "test_runtime": 3.2717, "test_samples_per_second": 625.97, "test_steps_per_second": 19.562}, {"test_loss": 0.4015166759490967, "test_mcc": 0.6873454495503694, "test_macro_f1": 0.8403597720245115, "test_runtime": 3.2503, "test_samples_per_second": 630.089, "test_steps_per_second": 19.69}]}, "total": {"test_mcc": 73.00832335269286, "test_mcc_se": 1.4328606029841817, "test_macro_f1": 85.98028715718507, "test_macro_f1_se": 0.8125822843104641}}, "num_model_parameters": 124447490, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.42722973227500916, "test_mcc": 0.6539057488034006, "test_macro_f1": 0.8193900829935106, "test_runtime": 3.6625, "test_samples_per_second": 559.179, "test_steps_per_second": 17.474}, {"test_loss": 0.43496471643447876, "test_mcc": 0.71839566851968, "test_macro_f1": 0.8540557086011631, "test_runtime": 3.755, "test_samples_per_second": 545.402, "test_steps_per_second": 17.044}, {"test_loss": 0.41500192880630493, "test_mcc": 0.7227606103126945, "test_macro_f1": 0.8593826673235058, "test_runtime": 3.6572, "test_samples_per_second": 559.984, "test_steps_per_second": 17.499}, {"test_loss": 0.4220075011253357, "test_mcc": 0.7034459318710091, "test_macro_f1": 0.8496399049631296, "test_runtime": 3.8016, "test_samples_per_second": 538.715, "test_steps_per_second": 16.835}, {"test_loss": 0.4433995485305786, "test_mcc": 0.6514060975796512, "test_macro_f1": 0.8251286043565202, "test_runtime": 3.6037, "test_samples_per_second": 568.311, "test_steps_per_second": 17.76}, {"test_loss": 0.41533979773521423, "test_mcc": 0.6478223674377697, "test_macro_f1": 0.8104981694322506, "test_runtime": 3.67, "test_samples_per_second": 558.044, "test_steps_per_second": 17.439}, {"test_loss": 0.4152356684207916, "test_mcc": 0.6672146825128172, "test_macro_f1": 0.8278874160055452, "test_runtime": 3.5617, "test_samples_per_second": 575.003, "test_steps_per_second": 17.969}, {"test_loss": 0.42260196805000305, "test_mcc": 0.7014343451691563, "test_macro_f1": 0.8465740794099004, "test_runtime": 3.6155, "test_samples_per_second": 566.457, "test_steps_per_second": 17.702}, {"test_loss": 0.4996110200881958, "test_mcc": 0.6660671891171221, "test_macro_f1": 0.8230681535211721, "test_runtime": 3.6766, "test_samples_per_second": 557.029, "test_steps_per_second": 17.407}, {"test_loss": 0.4747515320777893, "test_mcc": 0.695573793695676, "test_macro_f1": 0.8363686176536259, "test_runtime": 3.7405, "test_samples_per_second": 547.515, "test_steps_per_second": 17.11}]}, "total": {"test_mcc": 68.28026435018977, "test_mcc_se": 1.7733329524976396, "test_macro_f1": 83.51993404260323, "test_macro_f1_se": 1.0209172909260895}}, "num_model_parameters": 124447490, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.39914175868034363, "test_mcc": 0.6831176847021985, "test_macro_f1": 0.8199062340985777, "test_runtime": 3.0736, "test_samples_per_second": 666.315, "test_steps_per_second": 20.822}, {"test_loss": 0.36861652135849, "test_mcc": 0.7460699408368874, "test_macro_f1": 0.8665276329509906, "test_runtime": 3.1428, "test_samples_per_second": 651.657, "test_steps_per_second": 20.364}, {"test_loss": 0.48622679710388184, "test_mcc": 0.6513360182045896, "test_macro_f1": 0.803619943687182, "test_runtime": 3.1406, "test_samples_per_second": 652.102, "test_steps_per_second": 20.378}, {"test_loss": 0.34923288226127625, "test_mcc": 0.7531954804592546, "test_macro_f1": 0.871029273770517, "test_runtime": 3.1688, "test_samples_per_second": 646.297, "test_steps_per_second": 20.197}, {"test_loss": 0.39496973156929016, "test_mcc": 0.6999670984565248, "test_macro_f1": 0.8410377899717199, "test_runtime": 3.1721, "test_samples_per_second": 645.624, "test_steps_per_second": 20.176}, {"test_loss": 0.3586885929107666, "test_mcc": 0.7492448716284124, "test_macro_f1": 0.8696755215368452, "test_runtime": 3.0929, "test_samples_per_second": 662.167, "test_steps_per_second": 20.693}, {"test_loss": 0.4207962155342102, "test_mcc": 0.6578153579409849, "test_macro_f1": 0.807511152215062, "test_runtime": 3.0035, "test_samples_per_second": 681.879, "test_steps_per_second": 21.309}, {"test_loss": 0.5134848952293396, "test_mcc": 0.598138264635144, "test_macro_f1": 0.765032408806895, "test_runtime": 3.0926, "test_samples_per_second": 662.224, "test_steps_per_second": 20.695}, {"test_loss": 0.4650208652019501, "test_mcc": 0.6730551471118429, "test_macro_f1": 0.8135093496355144, "test_runtime": 3.1214, "test_samples_per_second": 656.118, "test_steps_per_second": 20.504}, {"test_loss": 0.48217543959617615, "test_mcc": 0.7216133101808707, "test_macro_f1": 0.8532478410236071, "test_runtime": 3.3212, "test_samples_per_second": 616.652, "test_steps_per_second": 19.27}]}, "total": {"test_mcc": 69.33553174156711, "test_mcc_se": 3.1290132636626327, "test_macro_f1": 83.11097147696911, "test_macro_f1_se": 2.1706075281198984}}, "num_model_parameters": 124447490, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_loss": 0.43611806631088257, "test_mcc": 0.6699263544367124, "test_macro_f1": 0.8331403823529765, "test_runtime": 3.324, "test_samples_per_second": 616.12, "test_steps_per_second": 19.254}, {"test_loss": 0.4567068815231323, "test_mcc": 0.6636825951927373, "test_macro_f1": 0.8309766699869858, "test_runtime": 3.3921, "test_samples_per_second": 603.763, "test_steps_per_second": 18.868}, {"test_loss": 0.4634445309638977, "test_mcc": 0.6400937624853767, "test_macro_f1": 0.8033743982752481, "test_runtime": 3.3599, "test_samples_per_second": 609.545, "test_steps_per_second": 19.048}, {"test_loss": 0.48253780603408813, "test_mcc": 0.5716954288584413, "test_macro_f1": 0.7697181577138368, "test_runtime": 3.1913, "test_samples_per_second": 641.747, "test_steps_per_second": 20.055}, {"test_loss": 0.41297245025634766, "test_mcc": 0.6898884393799168, "test_macro_f1": 0.8393347454302973, "test_runtime": 3.267, "test_samples_per_second": 626.873, "test_steps_per_second": 19.59}, {"test_loss": 0.44111424684524536, "test_mcc": 0.6630978556160817, "test_macro_f1": 0.8117747315563846, "test_runtime": 3.4175, "test_samples_per_second": 599.262, "test_steps_per_second": 18.727}, {"test_loss": 0.41348549723625183, "test_mcc": 0.6604991944514719, "test_macro_f1": 0.8236971675036611, "test_runtime": 3.4225, "test_samples_per_second": 598.395, "test_steps_per_second": 18.7}, {"test_loss": 0.4461684823036194, "test_mcc": 0.6683524392712525, "test_macro_f1": 0.8334356917589105, "test_runtime": 3.3102, "test_samples_per_second": 618.692, "test_steps_per_second": 19.334}, {"test_loss": 0.42012378573417664, "test_mcc": 0.6711322923255548, "test_macro_f1": 0.8324865637610611, "test_runtime": 3.2365, "test_samples_per_second": 632.775, "test_steps_per_second": 19.774}, {"test_loss": 0.40893980860710144, "test_mcc": 0.7257146723911162, "test_macro_f1": 0.858154145395464, "test_runtime": 3.3431, "test_samples_per_second": 612.612, "test_steps_per_second": 19.144}]}, "total": {"test_mcc": 66.2408303440866, "test_mcc_se": 2.4149770415536067, "test_macro_f1": 82.36092653734826, "test_macro_f1_se": 1.4919608219845915}}, "num_model_parameters": 124447490, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_em": 38.96204492641363, "test_f1": 44.060971350668055}, {"test_em": 39.689922480620154, "test_f1": 45.06910415006391}, {"test_em": 39.02627511591963, "test_f1": 43.23654054777341}, {"test_em": 43.53582554517134, "test_f1": 48.479565416911704}, {"test_em": 40.84942084942085, "test_f1": 46.13132029960866}, {"test_em": 36.08326908249807, "test_f1": 40.22249707793033}, {"test_em": 30.979498861047837, "test_f1": 35.6931035404099}, {"test_em": 30.333591931730023, "test_f1": 34.10412187864519}, {"test_em": 43.76470588235294, "test_f1": 48.34970786826397}, {"test_em": 46.73913043478261, "test_f1": 50.878213394167986}]}, "total": {"test_em": 38.99636851099571, "test_em_se": 3.299242845934877, "test_f1": 43.622514552444315, "test_f1_se": 3.409535602932061}}, "num_model_parameters": 123856898, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_em": 34.23702556158017, "test_f1": 38.747798723715285}, {"test_em": 37.98449612403101, "test_f1": 42.96773449748467}, {"test_em": 36.321483771251934, "test_f1": 41.23324717675957}, {"test_em": 40.49844236760124, "test_f1": 45.433563345041996}, {"test_em": 47.25868725868726, "test_f1": 52.12266857268103}, {"test_em": 39.86121819583654, "test_f1": 43.94880596968044}, {"test_em": 38.041002277904326, "test_f1": 43.328508665448076}, {"test_em": 37.16058960434445, "test_f1": 41.74766275758358}, {"test_em": 44.3921568627451, "test_f1": 49.724941352928646}, {"test_em": 45.807453416149066, "test_f1": 51.4548454129171}]}, "total": {"test_em": 40.156255544013106, "test_em_se": 2.6813358798502147, "test_f1": 45.07097764742404, "test_f1_se": 2.823316688107049}}, "num_model_parameters": 123856898, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_em": 44.46165762974439, "test_f1": 49.78651640026648}, {"test_em": 49.14728682170543, "test_f1": 53.94541619221924}, {"test_em": 42.272024729520865, "test_f1": 47.61069655121029}, {"test_em": 42.36760124610592, "test_f1": 47.043792343975205}, {"test_em": 42.16216216216216, "test_f1": 47.902219972071705}, {"test_em": 43.94757131842714, "test_f1": 48.54242046347771}, {"test_em": 45.78587699316629, "test_f1": 50.77414490016659}, {"test_em": 39.410395655546935, "test_f1": 44.073550546260805}, {"test_em": 43.92156862745098, "test_f1": 48.852759098659504}, {"test_em": 45.88509316770186, "test_f1": 50.50515653249721}]}, "total": {"test_em": 43.936123835153204, "test_em_se": 1.646496714656282, "test_f1": 48.90366730008047, "test_f1_se": 1.6249364390295367}}, "num_model_parameters": 123856898, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.5574853420257568, "test_mcc": 0.6807869820829051, "test_macro_f1": 0.5766987280297549, "test_runtime": 17.4027, "test_samples_per_second": 117.683, "test_steps_per_second": 58.841}, {"test_loss": 0.4027841091156006, "test_mcc": 0.7238936730751232, "test_macro_f1": 0.6887022293058439, "test_runtime": 17.7432, "test_samples_per_second": 115.424, "test_steps_per_second": 57.712}, {"test_loss": 0.560633659362793, "test_mcc": 0.616894397997616, "test_macro_f1": 0.5515401026710361, "test_runtime": 17.3352, "test_samples_per_second": 118.141, "test_steps_per_second": 59.071}, {"test_loss": 0.49494293332099915, "test_mcc": 0.7063859707190601, "test_macro_f1": 0.585344606463042, "test_runtime": 17.0786, "test_samples_per_second": 119.916, "test_steps_per_second": 59.958}, {"test_loss": 0.3991946876049042, "test_mcc": 0.7428752472118255, "test_macro_f1": 0.7136183804403308, "test_runtime": 17.0919, "test_samples_per_second": 119.823, "test_steps_per_second": 59.911}, {"test_loss": 0.3819820284843445, "test_mcc": 0.734939117488076, "test_macro_f1": 0.745093932607937, "test_runtime": 17.4565, "test_samples_per_second": 117.32, "test_steps_per_second": 58.66}, {"test_loss": 0.3717637360095978, "test_mcc": 0.7709303889469762, "test_macro_f1": 0.7660775612692329, "test_runtime": 17.2187, "test_samples_per_second": 118.94, "test_steps_per_second": 59.47}, {"test_loss": 0.4532559812068939, "test_mcc": 0.7244978474880323, "test_macro_f1": 0.631714265986454, "test_runtime": 17.3737, "test_samples_per_second": 117.88, "test_steps_per_second": 58.94}, {"test_loss": 0.4188390076160431, "test_mcc": 0.7423153216561785, "test_macro_f1": 0.7128290727998422, "test_runtime": 17.1941, "test_samples_per_second": 119.11, "test_steps_per_second": 59.555}, {"test_loss": 0.4594559967517853, "test_mcc": 0.7043296995025894, "test_macro_f1": 0.6000747066013749, "test_runtime": 17.4091, "test_samples_per_second": 117.64, "test_steps_per_second": 58.82}]}, "total": {"test_mcc": 71.47848646168381, "test_mcc_se": 2.629703047424513, "test_macro_f1": 65.71693586174848, "test_macro_f1_se": 4.781853884277048}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.7698988914489746, "test_mcc": 0.49260774906976695, "test_macro_f1": 0.6654488290054632, "test_runtime": 4.365, "test_samples_per_second": 469.183, "test_steps_per_second": 14.662}, {"test_loss": 0.7822731733322144, "test_mcc": 0.5069166893589484, "test_macro_f1": 0.668629490057456, "test_runtime": 4.3512, "test_samples_per_second": 470.67, "test_steps_per_second": 14.708}, {"test_loss": 0.8492672443389893, "test_mcc": 0.44536676031337263, "test_macro_f1": 0.6340247783648735, "test_runtime": 4.3446, "test_samples_per_second": 471.393, "test_steps_per_second": 14.731}, {"test_loss": 0.7920914888381958, "test_mcc": 0.4942259971787193, "test_macro_f1": 0.6628026498956688, "test_runtime": 4.3258, "test_samples_per_second": 473.435, "test_steps_per_second": 14.795}, {"test_loss": 0.8098464012145996, "test_mcc": 0.4643677128375377, "test_macro_f1": 0.6484984142562754, "test_runtime": 4.2837, "test_samples_per_second": 478.093, "test_steps_per_second": 14.94}, {"test_loss": 0.8796467185020447, "test_mcc": 0.4516653242530142, "test_macro_f1": 0.627717184733905, "test_runtime": 4.2797, "test_samples_per_second": 478.542, "test_steps_per_second": 14.954}, {"test_loss": 0.7750725150108337, "test_mcc": 0.46619984516859836, "test_macro_f1": 0.6501360440325131, "test_runtime": 4.2719, "test_samples_per_second": 479.41, "test_steps_per_second": 14.982}, {"test_loss": 0.8371888995170593, "test_mcc": 0.42390504355508685, "test_macro_f1": 0.6093562773590984, "test_runtime": 4.3406, "test_samples_per_second": 471.823, "test_steps_per_second": 14.744}, {"test_loss": 0.8112896680831909, "test_mcc": 0.4770505913105984, "test_macro_f1": 0.6485254582276933, "test_runtime": 4.3398, "test_samples_per_second": 471.909, "test_steps_per_second": 14.747}, {"test_loss": 0.8378975987434387, "test_mcc": 0.4557239727276641, "test_macro_f1": 0.6313265691975993, "test_runtime": 4.2568, "test_samples_per_second": 481.107, "test_steps_per_second": 15.035}]}, "total": {"test_mcc": 46.78029685773307, "test_mcc_se": 1.570714864357365, "test_macro_f1": 64.46465695130546, "test_macro_f1_se": 1.1723334749722516}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 1.0292503833770752, "test_mcc": 0.0, "test_macro_f1": 0.2127659574468085, "test_runtime": 3.6985, "test_samples_per_second": 553.735, "test_steps_per_second": 17.304}, {"test_loss": 0.7421048879623413, "test_mcc": 0.4897570837888454, "test_macro_f1": 0.6086758075086341, "test_runtime": 3.4365, "test_samples_per_second": 595.949, "test_steps_per_second": 18.623}, {"test_loss": 0.770923376083374, "test_mcc": 0.5481480348247973, "test_macro_f1": 0.6858874773560122, "test_runtime": 3.5484, "test_samples_per_second": 577.154, "test_steps_per_second": 18.036}, {"test_loss": 0.7568863034248352, "test_mcc": 0.5571139273402773, "test_macro_f1": 0.6933111623967415, "test_runtime": 3.5609, "test_samples_per_second": 575.13, "test_steps_per_second": 17.973}, {"test_loss": 0.7043734192848206, "test_mcc": 0.5688065127735173, "test_macro_f1": 0.6969177596488486, "test_runtime": 3.5885, "test_samples_per_second": 570.713, "test_steps_per_second": 17.835}, {"test_loss": 0.7493934631347656, "test_mcc": 0.5474333274518587, "test_macro_f1": 0.6689681769732984, "test_runtime": 3.6589, "test_samples_per_second": 559.727, "test_steps_per_second": 17.491}, {"test_loss": 0.7473951578140259, "test_mcc": 0.47566791438588746, "test_macro_f1": 0.539245920301905, "test_runtime": 3.4905, "test_samples_per_second": 586.741, "test_steps_per_second": 18.336}, {"test_loss": 0.9919052124023438, "test_mcc": 0.10416535385447273, "test_macro_f1": 0.24627549712913419, "test_runtime": 3.5932, "test_samples_per_second": 569.961, "test_steps_per_second": 17.811}, {"test_loss": 0.7252905368804932, "test_mcc": 0.5443563026523571, "test_macro_f1": 0.686948236640399, "test_runtime": 3.6725, "test_samples_per_second": 557.653, "test_steps_per_second": 17.427}, {"test_loss": 0.6797993779182434, "test_mcc": 0.606304714550333, "test_macro_f1": 0.7337277563834395, "test_runtime": 3.6697, "test_samples_per_second": 558.077, "test_steps_per_second": 17.44}]}, "total": {"test_mcc": 44.417531716223465, "test_mcc_se": 13.100119383800058, "test_macro_f1": 57.7272375178522, "test_macro_f1_se": 11.856668209168987}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.05255155265331268, "test_micro_f1": 0.7246231155778894, "test_micro_f1_no_misc": 0.7837681159420291, "test_runtime": 7.3241, "test_samples_per_second": 279.624, "test_steps_per_second": 8.738}, {"test_loss": 0.05145256966352463, "test_micro_f1": 0.7226277372262774, "test_micro_f1_no_misc": 0.8009738283627511, "test_runtime": 7.0599, "test_samples_per_second": 290.089, "test_steps_per_second": 9.065}, {"test_loss": 0.05127900838851929, "test_micro_f1": 0.743132530120482, "test_micro_f1_no_misc": 0.7827004219409284, "test_runtime": 6.5296, "test_samples_per_second": 313.647, "test_steps_per_second": 9.801}, {"test_loss": 0.055732667446136475, "test_micro_f1": 0.7225490196078431, "test_micro_f1_no_misc": 0.7710049423393739, "test_runtime": 7.1974, "test_samples_per_second": 284.545, "test_steps_per_second": 8.892}, {"test_loss": 0.057653043419122696, "test_micro_f1": 0.7518072289156627, "test_micro_f1_no_misc": 0.7987288135593221, "test_runtime": 7.3171, "test_samples_per_second": 279.891, "test_steps_per_second": 8.747}, {"test_loss": 0.04747140780091286, "test_micro_f1": 0.7741330834114338, "test_micro_f1_no_misc": 0.8223684210526316, "test_runtime": 5.9351, "test_samples_per_second": 345.069, "test_steps_per_second": 10.783}, {"test_loss": 0.05699869245290756, "test_micro_f1": 0.7271853986551393, "test_micro_f1_no_misc": 0.7883995703544575, "test_runtime": 6.02, "test_samples_per_second": 340.199, "test_steps_per_second": 10.631}, {"test_loss": 0.048349883407354355, "test_micro_f1": 0.7384284176533907, "test_micro_f1_no_misc": 0.7746987951807229, "test_runtime": 7.0553, "test_samples_per_second": 290.278, "test_steps_per_second": 9.071}, {"test_loss": 0.04705435037612915, "test_micro_f1": 0.7549540840985983, "test_micro_f1_no_misc": 0.8037280701754388, "test_runtime": 6.5557, "test_samples_per_second": 312.398, "test_steps_per_second": 9.762}, {"test_loss": 0.053443796932697296, "test_micro_f1": 0.7575462512171374, "test_micro_f1_no_misc": 0.8170594837261502, "test_runtime": 7.2716, "test_samples_per_second": 281.643, "test_steps_per_second": 8.801}]}, "total": {"test_micro_f1": 74.16986866483853, "test_micro_f1_se": 1.09837666032436, "test_micro_f1_no_misc": 79.43430462633805, "test_micro_f1_no_misc_se": 1.0667570001198554}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.04890301823616028, "test_micro_f1": 0.854573484069887, "test_micro_f1_no_misc": 0.8628005657708628, "test_runtime": 8.1748, "test_samples_per_second": 250.524, "test_steps_per_second": 7.829}, {"test_loss": 0.05386117845773697, "test_micro_f1": 0.8441486411536328, "test_micro_f1_no_misc": 0.8621722846441948, "test_runtime": 6.7686, "test_samples_per_second": 302.575, "test_steps_per_second": 9.455}, {"test_loss": 0.057869523763656616, "test_micro_f1": 0.8348843392714703, "test_micro_f1_no_misc": 0.8524473026080743, "test_runtime": 8.2011, "test_samples_per_second": 249.722, "test_steps_per_second": 7.804}, {"test_loss": 0.05883762985467911, "test_micro_f1": 0.8251393816523062, "test_micro_f1_no_misc": 0.8582322357019064, "test_runtime": 7.9106, "test_samples_per_second": 258.893, "test_steps_per_second": 8.09}, {"test_loss": 0.05983075499534607, "test_micro_f1": 0.8238557558945909, "test_micro_f1_no_misc": 0.8467650397275822, "test_runtime": 8.1137, "test_samples_per_second": 252.412, "test_steps_per_second": 7.888}, {"test_loss": 0.05766317993402481, "test_micro_f1": 0.8415300546448088, "test_micro_f1_no_misc": 0.8554171385428464, "test_runtime": 8.1596, "test_samples_per_second": 250.992, "test_steps_per_second": 7.844}, {"test_loss": 0.0567665733397007, "test_micro_f1": 0.8260528380852733, "test_micro_f1_no_misc": 0.8441649196366178, "test_runtime": 8.2337, "test_samples_per_second": 248.734, "test_steps_per_second": 7.773}, {"test_loss": 0.047406528145074844, "test_micro_f1": 0.8497523390203632, "test_micro_f1_no_misc": 0.8670909771621116, "test_runtime": 8.0847, "test_samples_per_second": 253.318, "test_steps_per_second": 7.916}, {"test_loss": 0.05655984580516815, "test_micro_f1": 0.8379383634431457, "test_micro_f1_no_misc": 0.8475319926873857, "test_runtime": 7.9081, "test_samples_per_second": 258.973, "test_steps_per_second": 8.093}, {"test_loss": 0.059384480118751526, "test_micro_f1": 0.8363055629491616, "test_micro_f1_no_misc": 0.8620443173695497, "test_runtime": 6.9784, "test_samples_per_second": 293.478, "test_steps_per_second": 9.171}]}, "total": {"test_micro_f1": 83.7418076018464, "test_micro_f1_se": 0.6469156911814261, "test_micro_f1_no_misc": 85.58666773851131, "test_micro_f1_no_misc_se": 0.48834891008275566}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.03733369708061218, "test_micro_f1": 0.866861741038771, "test_micro_f1_no_misc": 0.8948875255623722, "test_runtime": 6.4128, "test_samples_per_second": 319.363, "test_steps_per_second": 9.98}, {"test_loss": 0.031807683408260345, "test_micro_f1": 0.8523985239852399, "test_micro_f1_no_misc": 0.8865306122448979, "test_runtime": 6.3753, "test_samples_per_second": 321.24, "test_steps_per_second": 10.039}, {"test_loss": 0.03775227069854736, "test_micro_f1": 0.8446159242371098, "test_micro_f1_no_misc": 0.8778386844166014, "test_runtime": 5.9571, "test_samples_per_second": 343.79, "test_steps_per_second": 10.743}, {"test_loss": 0.03163769096136093, "test_micro_f1": 0.8881834215167549, "test_micro_f1_no_misc": 0.9081592432006307, "test_runtime": 5.8298, "test_samples_per_second": 351.301, "test_steps_per_second": 10.978}, {"test_loss": 0.02636861428618431, "test_micro_f1": 0.8985024958402662, "test_micro_f1_no_misc": 0.9215321680922276, "test_runtime": 6.3653, "test_samples_per_second": 321.744, "test_steps_per_second": 10.055}, {"test_loss": 0.025834649801254272, "test_micro_f1": 0.8984615384615384, "test_micro_f1_no_misc": 0.9215762777994538, "test_runtime": 6.3219, "test_samples_per_second": 323.953, "test_steps_per_second": 10.124}, {"test_loss": 0.028644852340221405, "test_micro_f1": 0.9016506189821184, "test_micro_f1_no_misc": 0.9204284621270084, "test_runtime": 5.7952, "test_samples_per_second": 353.397, "test_steps_per_second": 11.044}, {"test_loss": 0.030493678525090218, "test_micro_f1": 0.8829201101928374, "test_micro_f1_no_misc": 0.8965259618976467, "test_runtime": 5.7046, "test_samples_per_second": 359.006, "test_steps_per_second": 11.219}, {"test_loss": 0.035529252141714096, "test_micro_f1": 0.8655761024182077, "test_micro_f1_no_misc": 0.8955105284068335, "test_runtime": 5.8386, "test_samples_per_second": 350.77, "test_steps_per_second": 10.962}, {"test_loss": 0.04171273112297058, "test_micro_f1": 0.8720217835262083, "test_micro_f1_no_misc": 0.8906605922551252, "test_runtime": 6.3654, "test_samples_per_second": 321.738, "test_steps_per_second": 10.054}]}, "total": {"test_micro_f1": 87.71192260199052, "test_micro_f1_se": 1.2400631200797083, "test_micro_f1_no_misc": 90.13650056002798, "test_micro_f1_no_misc_se": 0.971813838710325}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.047590725123882294, "test_micro_f1": 0.8359469240048252, "test_micro_f1_no_misc": 0.8727519511367493, "test_runtime": 5.8048, "test_samples_per_second": 352.811, "test_steps_per_second": 11.025}, {"test_loss": 0.051030755043029785, "test_micro_f1": 0.7935464595159846, "test_micro_f1_no_misc": 0.828394659719961, "test_runtime": 5.9806, "test_samples_per_second": 342.443, "test_steps_per_second": 10.701}, {"test_loss": 0.05338737368583679, "test_micro_f1": 0.7776783049835869, "test_micro_f1_no_misc": 0.8266405484818805, "test_runtime": 5.8413, "test_samples_per_second": 350.607, "test_steps_per_second": 10.956}, {"test_loss": 0.05860495567321777, "test_micro_f1": 0.7493325422723227, "test_micro_f1_no_misc": 0.7951109681569637, "test_runtime": 6.0584, "test_samples_per_second": 338.043, "test_steps_per_second": 10.564}, {"test_loss": 0.061254099011421204, "test_micro_f1": 0.7617059349835968, "test_micro_f1_no_misc": 0.806268756252084, "test_runtime": 5.9032, "test_samples_per_second": 346.931, "test_steps_per_second": 10.842}, {"test_loss": 0.049946196377277374, "test_micro_f1": 0.8076349537727409, "test_micro_f1_no_misc": 0.8467394902350215, "test_runtime": 5.9772, "test_samples_per_second": 342.633, "test_steps_per_second": 10.707}, {"test_loss": 0.039070889353752136, "test_micro_f1": 0.8375229920294298, "test_micro_f1_no_misc": 0.8727147292169715, "test_runtime": 6.1758, "test_samples_per_second": 331.619, "test_steps_per_second": 10.363}, {"test_loss": 0.0432501882314682, "test_micro_f1": 0.836697247706422, "test_micro_f1_no_misc": 0.8689748811948406, "test_runtime": 6.0263, "test_samples_per_second": 339.845, "test_steps_per_second": 10.62}, {"test_loss": 0.05559355765581131, "test_micro_f1": 0.7757985257985258, "test_micro_f1_no_misc": 0.8205128205128204, "test_runtime": 5.6362, "test_samples_per_second": 363.367, "test_steps_per_second": 11.355}, {"test_loss": 0.042392559349536896, "test_micro_f1": 0.8451395277522233, "test_micro_f1_no_misc": 0.8737018425460636, "test_runtime": 5.7516, "test_samples_per_second": 356.076, "test_steps_per_second": 11.127}]}, "total": {"test_micro_f1": 80.21003412819658, "test_micro_f1_se": 2.192110408729133, "test_micro_f1_no_misc": 84.11810647453358, "test_micro_f1_no_misc_se": 1.8473864272649168}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.6903318762779236, "test_mcc": 0.07263787337054024, "test_macro_f1": 0.47503596606265336, "test_runtime": 3.2288, "test_samples_per_second": 634.29, "test_steps_per_second": 19.822}, {"test_loss": 0.6923625469207764, "test_mcc": 0.05104893119788475, "test_macro_f1": 0.3747696914747876, "test_runtime": 3.4159, "test_samples_per_second": 599.548, "test_steps_per_second": 18.736}, {"test_loss": 0.6890202760696411, "test_mcc": 0.09125690676108028, "test_macro_f1": 0.5265768163860013, "test_runtime": 3.338, "test_samples_per_second": 613.536, "test_steps_per_second": 19.173}, {"test_loss": 0.6915823221206665, "test_mcc": 0.05795592151471661, "test_macro_f1": 0.52337248221784, "test_runtime": 3.2361, "test_samples_per_second": 632.855, "test_steps_per_second": 19.777}, {"test_loss": 0.6894415616989136, "test_mcc": 0.11375844539473833, "test_macro_f1": 0.555870843288687, "test_runtime": 3.3169, "test_samples_per_second": 617.446, "test_steps_per_second": 19.295}, {"test_loss": 0.6925168037414551, "test_mcc": 0.031387639404470126, "test_macro_f1": 0.336374643974398, "test_runtime": 3.2752, "test_samples_per_second": 625.296, "test_steps_per_second": 19.541}, {"test_loss": 0.6872010231018066, "test_mcc": 0.12055661320377094, "test_macro_f1": 0.4295319418697352, "test_runtime": 3.2656, "test_samples_per_second": 627.149, "test_steps_per_second": 19.598}, {"test_loss": 0.6928732991218567, "test_mcc": 0.027357403531654084, "test_macro_f1": 0.38699514142006086, "test_runtime": 3.3498, "test_samples_per_second": 611.387, "test_steps_per_second": 19.106}, {"test_loss": 0.6905656456947327, "test_mcc": 0.11356051769773601, "test_macro_f1": 0.49547343623191964, "test_runtime": 3.2996, "test_samples_per_second": 620.675, "test_steps_per_second": 19.396}, {"test_loss": 0.6926385164260864, "test_mcc": 0.046075978822583456, "test_macro_f1": 0.43784631282626896, "test_runtime": 3.3077, "test_samples_per_second": 619.153, "test_steps_per_second": 19.349}]}, "total": {"test_mcc": 7.255962308991748, "test_mcc_se": 2.1813366875709206, "test_macro_f1": 45.41847275752352, "test_macro_f1_se": 4.530303292354798}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.688920259475708, "test_mcc": 0.07355230516701339, "test_macro_f1": 0.5292073769667813, "test_runtime": 3.7154, "test_samples_per_second": 551.22, "test_steps_per_second": 17.226}, {"test_loss": 0.6893293857574463, "test_mcc": 0.15332406836157159, "test_macro_f1": 0.4592415922495239, "test_runtime": 3.7778, "test_samples_per_second": 542.118, "test_steps_per_second": 16.941}, {"test_loss": 0.6892095804214478, "test_mcc": 0.10316742364673308, "test_macro_f1": 0.5507151342817309, "test_runtime": 3.7447, "test_samples_per_second": 546.907, "test_steps_per_second": 17.091}, {"test_loss": 0.68946373462677, "test_mcc": 0.1503471760494758, "test_macro_f1": 0.4766155326313539, "test_runtime": 3.8613, "test_samples_per_second": 530.393, "test_steps_per_second": 16.575}, {"test_loss": 0.6905962228775024, "test_mcc": 0.10248546886001117, "test_macro_f1": 0.5167719642238057, "test_runtime": 3.7039, "test_samples_per_second": 552.926, "test_steps_per_second": 17.279}, {"test_loss": 0.6880683898925781, "test_mcc": 0.16707237111515522, "test_macro_f1": 0.5072061028873832, "test_runtime": 3.7379, "test_samples_per_second": 547.898, "test_steps_per_second": 17.122}, {"test_loss": 0.6916671991348267, "test_mcc": 0.06144783334913673, "test_macro_f1": 0.5307025293440875, "test_runtime": 3.6084, "test_samples_per_second": 567.568, "test_steps_per_second": 17.736}, {"test_loss": 0.6908531188964844, "test_mcc": 0.08839395563753973, "test_macro_f1": 0.5441282883553482, "test_runtime": 3.6513, "test_samples_per_second": 560.895, "test_steps_per_second": 17.528}, {"test_loss": 0.6899513006210327, "test_mcc": 0.129340705036535, "test_macro_f1": 0.5542068911723231, "test_runtime": 3.6863, "test_samples_per_second": 555.569, "test_steps_per_second": 17.362}, {"test_loss": 0.6909065842628479, "test_mcc": 0.09764787256412671, "test_macro_f1": 0.4785824109853174, "test_runtime": 3.7576, "test_samples_per_second": 545.03, "test_steps_per_second": 17.032}]}, "total": {"test_mcc": 11.267791797872984, "test_mcc_se": 2.212936668052077, "test_macro_f1": 51.47377823097655, "test_macro_f1_se": 2.0744164203060103}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.6898041367530823, "test_mcc": 0.08535760586983178, "test_macro_f1": 0.38424610793608016, "test_runtime": 3.3096, "test_samples_per_second": 618.814, "test_steps_per_second": 19.338}, {"test_loss": 0.6923574805259705, "test_mcc": 0.10251699712752324, "test_macro_f1": 0.4899488940130181, "test_runtime": 3.3515, "test_samples_per_second": 611.062, "test_steps_per_second": 19.096}, {"test_loss": 0.6930222511291504, "test_mcc": 0.008779281880009733, "test_macro_f1": 0.3319382554961964, "test_runtime": 3.3502, "test_samples_per_second": 611.313, "test_steps_per_second": 19.104}, {"test_loss": 0.686158299446106, "test_mcc": 0.16901024688478725, "test_macro_f1": 0.43081947133207177, "test_runtime": 3.439, "test_samples_per_second": 595.518, "test_steps_per_second": 18.61}, {"test_loss": 0.689982533454895, "test_mcc": 0.08886117193022126, "test_macro_f1": 0.5330829375228352, "test_runtime": 3.385, "test_samples_per_second": 605.023, "test_steps_per_second": 18.907}, {"test_loss": 0.6900948286056519, "test_mcc": 0.10609762797220942, "test_macro_f1": 0.550908944938463, "test_runtime": 3.2459, "test_samples_per_second": 630.956, "test_steps_per_second": 19.717}, {"test_loss": 0.688757598400116, "test_mcc": 0.16828796123573486, "test_macro_f1": 0.5776196655314548, "test_runtime": 3.2797, "test_samples_per_second": 624.446, "test_steps_per_second": 19.514}, {"test_loss": 0.6907976865768433, "test_mcc": 0.10980107064861856, "test_macro_f1": 0.5398171621463039, "test_runtime": 3.2956, "test_samples_per_second": 621.44, "test_steps_per_second": 19.42}, {"test_loss": 0.6881415843963623, "test_mcc": 0.11959948003248752, "test_macro_f1": 0.4906379649861078, "test_runtime": 3.2325, "test_samples_per_second": 633.559, "test_steps_per_second": 19.799}, {"test_loss": 0.6873030662536621, "test_mcc": 0.16182590944832556, "test_macro_f1": 0.5479166666666667, "test_runtime": 3.3841, "test_samples_per_second": 605.176, "test_steps_per_second": 18.912}]}, "total": {"test_mcc": 11.201373530297493, "test_mcc_se": 2.9931091840393758, "test_macro_f1": 48.76936070569197, "test_macro_f1_se": 5.005415411330701}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_loss": 0.6918429732322693, "test_mcc": 0.07821239274144226, "test_macro_f1": 0.5254905741108106, "test_runtime": 3.5274, "test_samples_per_second": 580.591, "test_steps_per_second": 18.143}, {"test_loss": 0.6917135715484619, "test_mcc": 0.08534323435013705, "test_macro_f1": 0.5424323589015664, "test_runtime": 3.6129, "test_samples_per_second": 566.861, "test_steps_per_second": 17.714}, {"test_loss": 0.690933883190155, "test_mcc": 0.04605534377066643, "test_macro_f1": 0.5088873228408112, "test_runtime": 3.6399, "test_samples_per_second": 562.657, "test_steps_per_second": 17.583}, {"test_loss": 0.6927987337112427, "test_mcc": 0.005415227490430519, "test_macro_f1": 0.40136011255050336, "test_runtime": 3.5141, "test_samples_per_second": 582.794, "test_steps_per_second": 18.212}, {"test_loss": 0.6915160417556763, "test_mcc": 0.11607614000146295, "test_macro_f1": 0.5562934267970239, "test_runtime": 3.4946, "test_samples_per_second": 586.045, "test_steps_per_second": 18.314}, {"test_loss": 0.6900439858436584, "test_mcc": 0.0987131394478756, "test_macro_f1": 0.45159883636868375, "test_runtime": 3.6568, "test_samples_per_second": 560.05, "test_steps_per_second": 17.502}, {"test_loss": 0.6915982961654663, "test_mcc": 0.03171163944025124, "test_macro_f1": 0.5136330140014738, "test_runtime": 3.5504, "test_samples_per_second": 576.836, "test_steps_per_second": 18.026}, {"test_loss": 0.6923007965087891, "test_mcc": 0.08139502766297853, "test_macro_f1": 0.49725410088355715, "test_runtime": 3.5103, "test_samples_per_second": 583.423, "test_steps_per_second": 18.232}, {"test_loss": 0.6906085014343262, "test_mcc": 0.04309757179404567, "test_macro_f1": 0.36294575697414705, "test_runtime": 3.5241, "test_samples_per_second": 581.139, "test_steps_per_second": 18.161}, {"test_loss": 0.6909322738647461, "test_mcc": 0.1257980075345794, "test_macro_f1": 0.5628881300671087, "test_runtime": 3.5916, "test_samples_per_second": 570.22, "test_steps_per_second": 17.819}]}, "total": {"test_mcc": 7.118177242338697, "test_mcc_se": 2.3928319132757974, "test_macro_f1": 49.227836334956855, "test_macro_f1_se": 4.137547859568973}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_em": 33.07513555383424, "test_f1": 37.00221696523794}, {"test_em": 32.86821705426357, "test_f1": 37.95522738026033}, {"test_em": 35.47140649149923, "test_f1": 39.11467119108838}, {"test_em": 36.29283489096573, "test_f1": 40.50206960184971}, {"test_em": 26.872586872586872, "test_f1": 31.501713693664176}, {"test_em": 34.926754047802625, "test_f1": 39.221407931983194}, {"test_em": 29.992406985573272, "test_f1": 33.89051319943723}, {"test_em": 40.65166795965865, "test_f1": 45.43253559088908}, {"test_em": 36.627450980392155, "test_f1": 40.464719650463614}, {"test_em": 35.63664596273292, "test_f1": 39.46938118636383}]}, "total": {"test_em": 34.241510679930926, "test_em_se": 2.360348301949571, "test_f1": 38.455445639123745, "test_f1_se": 2.360243557839027}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_em": 37.955073586367156, "test_f1": 42.72024704963027}, {"test_em": 24.108527131782946, "test_f1": 29.976815588072718}, {"test_em": 46.05873261205564, "test_f1": 50.6325979575581}, {"test_em": 36.52647975077882, "test_f1": 40.87112011023719}, {"test_em": 33.513513513513516, "test_f1": 38.392301095750916}, {"test_em": 28.681572860447186, "test_f1": 33.683613786393096}, {"test_em": 34.47228549734245, "test_f1": 38.937017532584804}, {"test_em": 36.22963537626067, "test_f1": 40.30281220163698}, {"test_em": 40.78431372549019, "test_f1": 45.52364899176044}, {"test_em": 43.7888198757764, "test_f1": 49.18472813373108}]}, "total": {"test_em": 36.2118953929815, "test_em_se": 4.0900948758433495, "test_f1": 41.022490244735565, "test_f1_se": 3.9729601438087654}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_em": 38.729666924864446, "test_f1": 43.26745834587095}, {"test_em": 37.674418604651166, "test_f1": 41.99483713751107}, {"test_em": 38.48531684698609, "test_f1": 43.15843338128962}, {"test_em": 42.13395638629284, "test_f1": 47.02536889612624}, {"test_em": 24.092664092664094, "test_f1": 30.991182250080808}, {"test_em": 35.08095605242868, "test_f1": 39.70770510027675}, {"test_em": 44.039483675018985, "test_f1": 48.84818067692868}, {"test_em": 31.885182311869666, "test_f1": 36.709237934272494}, {"test_em": 40.86274509803921, "test_f1": 45.9263991995917}, {"test_em": 43.32298136645963, "test_f1": 49.05608303420688}]}, "total": {"test_em": 37.63073713592748, "test_em_se": 3.7470281591857715, "test_f1": 42.66848859561552, "test_f1_se": 3.5199897034102308}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.8626302480697632, "test_mcc": 0.4527918369364083, "test_macro_f1": 0.6342051691266648, "test_runtime": 4.8212, "test_samples_per_second": 424.793, "test_steps_per_second": 26.55}, {"test_loss": 0.8095752000808716, "test_mcc": 0.4980327792131438, "test_macro_f1": 0.6641654091628463, "test_runtime": 4.7864, "test_samples_per_second": 427.881, "test_steps_per_second": 26.743}, {"test_loss": 0.8835209608078003, "test_mcc": 0.4540669407278681, "test_macro_f1": 0.6322262964280781, "test_runtime": 4.8097, "test_samples_per_second": 425.808, "test_steps_per_second": 26.613}, {"test_loss": 0.8598515391349792, "test_mcc": 0.4450776418517896, "test_macro_f1": 0.6198397510856813, "test_runtime": 4.821, "test_samples_per_second": 424.81, "test_steps_per_second": 26.551}, {"test_loss": 0.8283499479293823, "test_mcc": 0.48781612591082474, "test_macro_f1": 0.66167501401667, "test_runtime": 4.7708, "test_samples_per_second": 429.278, "test_steps_per_second": 26.83}, {"test_loss": 0.846826434135437, "test_mcc": 0.4853629434023099, "test_macro_f1": 0.6590566592379526, "test_runtime": 4.779, "test_samples_per_second": 428.542, "test_steps_per_second": 26.784}, {"test_loss": 0.9231295585632324, "test_mcc": 0.46987385870465065, "test_macro_f1": 0.6479523629099753, "test_runtime": 4.8087, "test_samples_per_second": 425.899, "test_steps_per_second": 26.619}, {"test_loss": 0.862688422203064, "test_mcc": 0.45682570789109256, "test_macro_f1": 0.6315523069264525, "test_runtime": 4.7964, "test_samples_per_second": 426.985, "test_steps_per_second": 26.687}, {"test_loss": 0.8590692281723022, "test_mcc": 0.4403075844903439, "test_macro_f1": 0.6162439964413992, "test_runtime": 4.854, "test_samples_per_second": 421.921, "test_steps_per_second": 26.37}, {"test_loss": 0.890696108341217, "test_mcc": 0.44839081235151595, "test_macro_f1": 0.6297715326696869, "test_runtime": 4.7467, "test_samples_per_second": 431.456, "test_steps_per_second": 26.966}]}, "total": {"test_mcc": 46.38546231479947, "test_mcc_se": 1.2490284639190803, "test_macro_f1": 63.966884980054076, "test_macro_f1_se": 1.0774756023231267}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.7701488733291626, "test_mcc": 0.47437937580509665, "test_macro_f1": 0.5908990859243205, "test_runtime": 3.6697, "test_samples_per_second": 558.082, "test_steps_per_second": 17.44}, {"test_loss": 0.832795262336731, "test_mcc": 0.5186156911593226, "test_macro_f1": 0.6700671275483635, "test_runtime": 3.4492, "test_samples_per_second": 593.759, "test_steps_per_second": 18.555}, {"test_loss": 0.7444908022880554, "test_mcc": 0.5025474073948566, "test_macro_f1": 0.6402418951377823, "test_runtime": 3.5917, "test_samples_per_second": 570.199, "test_steps_per_second": 17.819}, {"test_loss": 0.8535891175270081, "test_mcc": 0.4659270255192846, "test_macro_f1": 0.5813096690114402, "test_runtime": 3.6152, "test_samples_per_second": 566.496, "test_steps_per_second": 17.703}, {"test_loss": 0.7644596099853516, "test_mcc": 0.48834393821304695, "test_macro_f1": 0.6313391300575254, "test_runtime": 3.5815, "test_samples_per_second": 571.821, "test_steps_per_second": 17.869}, {"test_loss": 0.7759668827056885, "test_mcc": 0.49901979943857516, "test_macro_f1": 0.6335335087565274, "test_runtime": 3.6566, "test_samples_per_second": 560.08, "test_steps_per_second": 17.503}, {"test_loss": 0.7537384033203125, "test_mcc": 0.49938155418120983, "test_macro_f1": 0.597462262794343, "test_runtime": 3.5109, "test_samples_per_second": 583.325, "test_steps_per_second": 18.229}, {"test_loss": 0.7693030834197998, "test_mcc": 0.4809751546476171, "test_macro_f1": 0.5669846676435613, "test_runtime": 3.5921, "test_samples_per_second": 570.134, "test_steps_per_second": 17.817}, {"test_loss": 0.7237076759338379, "test_mcc": 0.5430864425867757, "test_macro_f1": 0.6772395916394149, "test_runtime": 3.6782, "test_samples_per_second": 556.797, "test_steps_per_second": 17.4}, {"test_loss": 0.7362141013145447, "test_mcc": 0.5209852225093891, "test_macro_f1": 0.648047123845466, "test_runtime": 3.714, "test_samples_per_second": 551.428, "test_steps_per_second": 17.232}]}, "total": {"test_mcc": 49.93261611455174, "test_mcc_se": 1.4553136769438084, "test_macro_f1": 62.37124062358744, "test_macro_f1_se": 2.338874540911201}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.07795777916908264, "test_micro_f1": 0.5919456574478409, "test_micro_f1_no_misc": 0.6588103254769921, "test_runtime": 7.3579, "test_samples_per_second": 278.339, "test_steps_per_second": 8.698}, {"test_loss": 0.06907494366168976, "test_micro_f1": 0.6333503314635389, "test_micro_f1_no_misc": 0.7054631828978623, "test_runtime": 7.0995, "test_samples_per_second": 288.473, "test_steps_per_second": 9.015}, {"test_loss": 0.06371791660785675, "test_micro_f1": 0.6514719848053182, "test_micro_f1_no_misc": 0.713119216113228, "test_runtime": 6.5887, "test_samples_per_second": 310.836, "test_steps_per_second": 9.714}, {"test_loss": 0.0685562863945961, "test_micro_f1": 0.6248839368616528, "test_micro_f1_no_misc": 0.6816961889425657, "test_runtime": 7.2358, "test_samples_per_second": 283.039, "test_steps_per_second": 8.845}, {"test_loss": 0.07453414797782898, "test_micro_f1": 0.6293260473588342, "test_micro_f1_no_misc": 0.6818181818181818, "test_runtime": 7.2545, "test_samples_per_second": 282.308, "test_steps_per_second": 8.822}, {"test_loss": 0.07079949975013733, "test_micro_f1": 0.6328545780969479, "test_micro_f1_no_misc": 0.7006020799124247, "test_runtime": 5.8837, "test_samples_per_second": 348.08, "test_steps_per_second": 10.878}, {"test_loss": 0.07654871046543121, "test_micro_f1": 0.6441805225653207, "test_micro_f1_no_misc": 0.694906166219839, "test_runtime": 6.0675, "test_samples_per_second": 337.536, "test_steps_per_second": 10.548}, {"test_loss": 0.05812443792819977, "test_micro_f1": 0.6829527349973447, "test_micro_f1_no_misc": 0.7391037446286066, "test_runtime": 7.0142, "test_samples_per_second": 291.981, "test_steps_per_second": 9.124}, {"test_loss": 0.0641118511557579, "test_micro_f1": 0.6596457635232168, "test_micro_f1_no_misc": 0.7288231949971574, "test_runtime": 6.657, "test_samples_per_second": 307.646, "test_steps_per_second": 9.614}, {"test_loss": 0.07134942710399628, "test_micro_f1": 0.6461684011352886, "test_micro_f1_no_misc": 0.7173553719008264, "test_runtime": 7.2562, "test_samples_per_second": 282.242, "test_steps_per_second": 8.82}]}, "total": {"test_micro_f1": 63.96779958255303, "test_micro_f1_se": 1.4846505991085641, "test_micro_f1_no_misc": 70.21697652907683, "test_micro_f1_no_misc_se": 1.490470380296069}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.07404610514640808, "test_micro_f1": 0.7671443193449334, "test_micro_f1_no_misc": 0.7868403015764222, "test_runtime": 8.1218, "test_samples_per_second": 252.161, "test_steps_per_second": 7.88}, {"test_loss": 0.06745655834674835, "test_micro_f1": 0.7616707616707616, "test_micro_f1_no_misc": 0.7800072966070778, "test_runtime": 6.7122, "test_samples_per_second": 305.114, "test_steps_per_second": 9.535}, {"test_loss": 0.07110241055488586, "test_micro_f1": 0.7311162670791441, "test_micro_f1_no_misc": 0.7542110690959092, "test_runtime": 8.2051, "test_samples_per_second": 249.6, "test_steps_per_second": 7.8}, {"test_loss": 0.07446866482496262, "test_micro_f1": 0.7450396825396826, "test_micro_f1_no_misc": 0.7579231287929871, "test_runtime": 7.9276, "test_samples_per_second": 258.337, "test_steps_per_second": 8.073}, {"test_loss": 0.0806846022605896, "test_micro_f1": 0.711413043478261, "test_micro_f1_no_misc": 0.748349229640499, "test_runtime": 8.2155, "test_samples_per_second": 249.286, "test_steps_per_second": 7.79}, {"test_loss": 0.07239294797182083, "test_micro_f1": 0.7707659115426105, "test_micro_f1_no_misc": 0.7741700109449107, "test_runtime": 8.1583, "test_samples_per_second": 251.032, "test_steps_per_second": 7.845}, {"test_loss": 0.06832823902368546, "test_micro_f1": 0.761313679855185, "test_micro_f1_no_misc": 0.7590893645939517, "test_runtime": 8.1969, "test_samples_per_second": 249.851, "test_steps_per_second": 7.808}, {"test_loss": 0.06835369765758514, "test_micro_f1": 0.7635869565217391, "test_micro_f1_no_misc": 0.7747353048557868, "test_runtime": 8.1225, "test_samples_per_second": 252.139, "test_steps_per_second": 7.879}, {"test_loss": 0.07497449964284897, "test_micro_f1": 0.7420365535248041, "test_micro_f1_no_misc": 0.7576521425999281, "test_runtime": 7.8303, "test_samples_per_second": 261.547, "test_steps_per_second": 8.173}, {"test_loss": 0.07304580509662628, "test_micro_f1": 0.7590361445783133, "test_micro_f1_no_misc": 0.7730916695712792, "test_runtime": 6.9693, "test_samples_per_second": 293.86, "test_steps_per_second": 9.183}]}, "total": {"test_micro_f1": 75.13123320135435, "test_micro_f1_se": 1.1635868047381224, "test_micro_f1_no_misc": 76.66069518278752, "test_micro_f1_no_misc_se": 0.7876374529414272}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.058071717619895935, "test_micro_f1": 0.7609087630724847, "test_micro_f1_no_misc": 0.8083067092651757, "test_runtime": 6.4111, "test_samples_per_second": 319.447, "test_steps_per_second": 9.983}, {"test_loss": 0.05287904292345047, "test_micro_f1": 0.7449962935507782, "test_micro_f1_no_misc": 0.7863247863247862, "test_runtime": 6.2732, "test_samples_per_second": 326.469, "test_steps_per_second": 10.202}, {"test_loss": 0.05595758557319641, "test_micro_f1": 0.76423886779427, "test_micro_f1_no_misc": 0.806774441878368, "test_runtime": 5.8844, "test_samples_per_second": 348.039, "test_steps_per_second": 10.876}, {"test_loss": 0.05599689483642578, "test_micro_f1": 0.7490662139219015, "test_micro_f1_no_misc": 0.7785285285285284, "test_runtime": 5.8471, "test_samples_per_second": 350.259, "test_steps_per_second": 10.946}, {"test_loss": 0.05049853399395943, "test_micro_f1": 0.7827518104015799, "test_micro_f1_no_misc": 0.8157606712878511, "test_runtime": 6.428, "test_samples_per_second": 318.608, "test_steps_per_second": 9.957}, {"test_loss": 0.043729521334171295, "test_micro_f1": 0.8004059539918809, "test_micro_f1_no_misc": 0.8310991957104557, "test_runtime": 6.4536, "test_samples_per_second": 317.342, "test_steps_per_second": 9.917}, {"test_loss": 0.05506476014852524, "test_micro_f1": 0.7899328859060403, "test_micro_f1_no_misc": 0.8268945022288262, "test_runtime": 5.8947, "test_samples_per_second": 347.429, "test_steps_per_second": 10.857}, {"test_loss": 0.0506783127784729, "test_micro_f1": 0.7922971114167813, "test_micro_f1_no_misc": 0.8146194423511681, "test_runtime": 5.7418, "test_samples_per_second": 356.68, "test_steps_per_second": 11.146}, {"test_loss": 0.05045328289270401, "test_micro_f1": 0.782274947662247, "test_micro_f1_no_misc": 0.8105181747873165, "test_runtime": 5.8694, "test_samples_per_second": 348.93, "test_steps_per_second": 10.904}, {"test_loss": 0.05627947300672531, "test_micro_f1": 0.8024439918533605, "test_micro_f1_no_misc": 0.8469965999244427, "test_runtime": 6.2722, "test_samples_per_second": 326.522, "test_steps_per_second": 10.204}]}, "total": {"test_micro_f1": 77.69316839571324, "test_micro_f1_se": 1.2875252973091786, "test_micro_f1_no_misc": 81.25823052286918, "test_micro_f1_no_misc_se": 1.2484821314776586}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.06444866210222244, "test_micro_f1": 0.7292176039119805, "test_micro_f1_no_misc": 0.773469387755102, "test_runtime": 5.8149, "test_samples_per_second": 352.201, "test_steps_per_second": 11.006}, {"test_loss": 0.07490076124668121, "test_micro_f1": 0.7015329125338143, "test_micro_f1_no_misc": 0.7436065573770492, "test_runtime": 6.0123, "test_samples_per_second": 340.635, "test_steps_per_second": 10.645}, {"test_loss": 0.07954998314380646, "test_micro_f1": 0.6911208151382824, "test_micro_f1_no_misc": 0.7394796016704144, "test_runtime": 5.8278, "test_samples_per_second": 351.42, "test_steps_per_second": 10.982}, {"test_loss": 0.08101488649845123, "test_micro_f1": 0.7020648967551623, "test_micro_f1_no_misc": 0.7456966547580385, "test_runtime": 6.1318, "test_samples_per_second": 333.998, "test_steps_per_second": 10.437}, {"test_loss": 0.09067216515541077, "test_micro_f1": 0.6401188707280833, "test_micro_f1_no_misc": 0.6933333333333332, "test_runtime": 5.827, "test_samples_per_second": 351.469, "test_steps_per_second": 10.983}, {"test_loss": 0.07574984431266785, "test_micro_f1": 0.7197211733952947, "test_micro_f1_no_misc": 0.7596848325673013, "test_runtime": 6.0246, "test_samples_per_second": 339.94, "test_steps_per_second": 10.623}, {"test_loss": 0.07021017372608185, "test_micro_f1": 0.6968053044002411, "test_micro_f1_no_misc": 0.737360472751149, "test_runtime": 6.0611, "test_samples_per_second": 337.891, "test_steps_per_second": 10.559}, {"test_loss": 0.06885118782520294, "test_micro_f1": 0.7416487894575544, "test_micro_f1_no_misc": 0.7723244717109746, "test_runtime": 6.0333, "test_samples_per_second": 339.447, "test_steps_per_second": 10.608}, {"test_loss": 0.08137956261634827, "test_micro_f1": 0.656964656964657, "test_micro_f1_no_misc": 0.6940491591203105, "test_runtime": 5.5894, "test_samples_per_second": 366.405, "test_steps_per_second": 11.45}, {"test_loss": 0.07552914321422577, "test_micro_f1": 0.7047220561864913, "test_micro_f1_no_misc": 0.7461912479740681, "test_runtime": 5.7614, "test_samples_per_second": 355.47, "test_steps_per_second": 11.108}]}, "total": {"test_micro_f1": 69.83917079471561, "test_micro_f1_se": 1.9055725878699172, "test_micro_f1_no_misc": 74.0519571901774, "test_micro_f1_no_misc_se": 1.7199117113859224}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.5835114121437073, "test_mcc": 0.43293005288560243, "test_macro_f1": 0.6707615775342067, "test_runtime": 3.2058, "test_samples_per_second": 638.84, "test_steps_per_second": 19.964}, {"test_loss": 0.6215600371360779, "test_mcc": 0.42807966415904414, "test_macro_f1": 0.7080890567950151, "test_runtime": 3.3245, "test_samples_per_second": 616.033, "test_steps_per_second": 19.251}, {"test_loss": 0.586188793182373, "test_mcc": 0.45666010137305624, "test_macro_f1": 0.712497549471129, "test_runtime": 3.3326, "test_samples_per_second": 614.537, "test_steps_per_second": 19.204}, {"test_loss": 0.5969928503036499, "test_mcc": 0.3739296808725276, "test_macro_f1": 0.6513467618699982, "test_runtime": 3.2623, "test_samples_per_second": 627.786, "test_steps_per_second": 19.618}, {"test_loss": 0.6905452609062195, "test_mcc": 0.13546704920941938, "test_macro_f1": 0.5448781008142416, "test_runtime": 3.3046, "test_samples_per_second": 619.745, "test_steps_per_second": 19.367}, {"test_loss": 0.5745352506637573, "test_mcc": 0.435929463282494, "test_macro_f1": 0.6795589930642045, "test_runtime": 3.2559, "test_samples_per_second": 629.018, "test_steps_per_second": 19.657}, {"test_loss": 0.5835480093955994, "test_mcc": 0.4412003969597742, "test_macro_f1": 0.7081136109131629, "test_runtime": 3.2674, "test_samples_per_second": 626.805, "test_steps_per_second": 19.588}, {"test_loss": 0.6026626825332642, "test_mcc": 0.4422593743282813, "test_macro_f1": 0.6987692064464008, "test_runtime": 3.3017, "test_samples_per_second": 620.279, "test_steps_per_second": 19.384}, {"test_loss": 0.6016584038734436, "test_mcc": 0.4204043223422335, "test_macro_f1": 0.6637715350784806, "test_runtime": 3.2873, "test_samples_per_second": 623.005, "test_steps_per_second": 19.469}, {"test_loss": 0.6248722076416016, "test_mcc": 0.39342159522436926, "test_macro_f1": 0.621778872438503, "test_runtime": 3.2936, "test_samples_per_second": 621.814, "test_steps_per_second": 19.432}]}, "total": {"test_mcc": 39.60281700636802, "test_mcc_se": 5.873342314453115, "test_macro_f1": 66.59565264425342, "test_macro_f1_se": 3.189517793279517}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.6242748498916626, "test_mcc": 0.3632035598943925, "test_macro_f1": 0.6535359415660343, "test_runtime": 3.6993, "test_samples_per_second": 553.622, "test_steps_per_second": 17.301}, {"test_loss": 0.6224602460861206, "test_mcc": 0.38562453783032274, "test_macro_f1": 0.6785045227958733, "test_runtime": 3.7816, "test_samples_per_second": 541.57, "test_steps_per_second": 16.924}, {"test_loss": 0.6069148778915405, "test_mcc": 0.41002179391271687, "test_macro_f1": 0.6776562440773135, "test_runtime": 3.7313, "test_samples_per_second": 548.874, "test_steps_per_second": 17.152}, {"test_loss": 0.6118245720863342, "test_mcc": 0.4221422154159029, "test_macro_f1": 0.6923534608348741, "test_runtime": 3.8331, "test_samples_per_second": 534.29, "test_steps_per_second": 16.697}, {"test_loss": 0.6261289119720459, "test_mcc": 0.34029117115862595, "test_macro_f1": 0.6682369127878109, "test_runtime": 3.6694, "test_samples_per_second": 558.127, "test_steps_per_second": 17.441}, {"test_loss": 0.624476432800293, "test_mcc": 0.4117307603912786, "test_macro_f1": 0.6739850204281657, "test_runtime": 3.6583, "test_samples_per_second": 559.822, "test_steps_per_second": 17.494}, {"test_loss": 0.584652304649353, "test_mcc": 0.39948310269468446, "test_macro_f1": 0.6920093594899366, "test_runtime": 3.595, "test_samples_per_second": 569.679, "test_steps_per_second": 17.802}, {"test_loss": 0.6222035884857178, "test_mcc": 0.4138975116908294, "test_macro_f1": 0.679319940961842, "test_runtime": 3.6813, "test_samples_per_second": 556.326, "test_steps_per_second": 17.385}, {"test_loss": 0.6242825984954834, "test_mcc": 0.3444295603857105, "test_macro_f1": 0.6381701936173618, "test_runtime": 3.6802, "test_samples_per_second": 556.493, "test_steps_per_second": 17.39}, {"test_loss": 0.6136748790740967, "test_mcc": 0.3699129401367796, "test_macro_f1": 0.654684862738554, "test_runtime": 3.737, "test_samples_per_second": 548.036, "test_steps_per_second": 17.126}]}, "total": {"test_mcc": 38.60737153511244, "test_mcc_se": 1.8595799314583592, "test_macro_f1": 67.08456459297767, "test_macro_f1_se": 1.079975674174641}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.5737873315811157, "test_mcc": 0.4668276078605106, "test_macro_f1": 0.7173902937037548, "test_runtime": 3.3028, "test_samples_per_second": 620.083, "test_steps_per_second": 19.378}, {"test_loss": 0.6121782064437866, "test_mcc": 0.41064856895196533, "test_macro_f1": 0.65, "test_runtime": 3.355, "test_samples_per_second": 610.432, "test_steps_per_second": 19.076}, {"test_loss": 0.6153719425201416, "test_mcc": 0.4173642614649533, "test_macro_f1": 0.6901703893420552, "test_runtime": 3.3518, "test_samples_per_second": 611.02, "test_steps_per_second": 19.094}, {"test_loss": 0.6098477840423584, "test_mcc": 0.4519291318640236, "test_macro_f1": 0.7061635220125786, "test_runtime": 3.4196, "test_samples_per_second": 598.899, "test_steps_per_second": 18.716}, {"test_loss": 0.6918014287948608, "test_mcc": 0.0579532737391815, "test_macro_f1": 0.5283037556550827, "test_runtime": 3.3664, "test_samples_per_second": 608.37, "test_steps_per_second": 19.012}, {"test_loss": 0.5651121139526367, "test_mcc": 0.457632864966195, "test_macro_f1": 0.7070020061170935, "test_runtime": 3.302, "test_samples_per_second": 620.235, "test_steps_per_second": 19.382}, {"test_loss": 0.6058021783828735, "test_mcc": 0.3866850601360799, "test_macro_f1": 0.6490675072235356, "test_runtime": 3.2886, "test_samples_per_second": 622.76, "test_steps_per_second": 19.461}, {"test_loss": 0.5628088712692261, "test_mcc": 0.46329813937991127, "test_macro_f1": 0.7115478068244582, "test_runtime": 3.3399, "test_samples_per_second": 613.188, "test_steps_per_second": 19.162}, {"test_loss": 0.6462314128875732, "test_mcc": 0.3799560939285874, "test_macro_f1": 0.6219005330278443, "test_runtime": 3.2145, "test_samples_per_second": 637.121, "test_steps_per_second": 19.91}, {"test_loss": 0.6606992483139038, "test_mcc": 0.3339613831244152, "test_macro_f1": 0.6191275019600333, "test_runtime": 3.3995, "test_samples_per_second": 602.44, "test_steps_per_second": 18.826}]}, "total": {"test_mcc": 38.26256385415823, "test_mcc_se": 7.557886350055615, "test_macro_f1": 66.00673315866436, "test_macro_f1_se": 3.6892709559291803}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.6628706455230713, "test_mcc": 0.30052586319616503, "test_macro_f1": 0.6399196375302444, "test_runtime": 3.5255, "test_samples_per_second": 580.916, "test_steps_per_second": 18.154}, {"test_loss": 0.6281311511993408, "test_mcc": 0.32094468104475476, "test_macro_f1": 0.6476413137457884, "test_runtime": 3.6124, "test_samples_per_second": 566.932, "test_steps_per_second": 17.717}, {"test_loss": 0.6296401023864746, "test_mcc": 0.31451574420872824, "test_macro_f1": 0.6212788753103472, "test_runtime": 3.7475, "test_samples_per_second": 546.503, "test_steps_per_second": 17.078}, {"test_loss": 0.6551462411880493, "test_mcc": 0.2654805582146402, "test_macro_f1": 0.6150756299899042, "test_runtime": 3.4855, "test_samples_per_second": 587.585, "test_steps_per_second": 18.362}, {"test_loss": 0.6318864822387695, "test_mcc": 0.2970825540345823, "test_macro_f1": 0.6455112216149487, "test_runtime": 3.5195, "test_samples_per_second": 581.898, "test_steps_per_second": 18.184}, {"test_loss": 0.6574975848197937, "test_mcc": 0.25380420766038064, "test_macro_f1": 0.622470811174277, "test_runtime": 3.6214, "test_samples_per_second": 565.523, "test_steps_per_second": 17.673}, {"test_loss": 0.6476472616195679, "test_mcc": 0.26731223582293034, "test_macro_f1": 0.6333358796119472, "test_runtime": 3.5589, "test_samples_per_second": 575.466, "test_steps_per_second": 17.983}, {"test_loss": 0.6570836305618286, "test_mcc": 0.26508111296155484, "test_macro_f1": 0.630332225921543, "test_runtime": 3.5428, "test_samples_per_second": 578.067, "test_steps_per_second": 18.065}, {"test_loss": 0.6928620934486389, "test_mcc": 0.027326623696171823, "test_macro_f1": 0.4836091590553797, "test_runtime": 3.5587, "test_samples_per_second": 575.495, "test_steps_per_second": 17.984}, {"test_loss": 0.6697712540626526, "test_mcc": 0.2048162512034175, "test_macro_f1": 0.5881373199725084, "test_runtime": 3.603, "test_samples_per_second": 568.418, "test_steps_per_second": 17.763}]}, "total": {"test_mcc": 25.168898320433257, "test_mcc_se": 5.321471547283889, "test_macro_f1": 61.27312073926888, "test_macro_f1_se": 3.0094199565985904}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_em": 32.06816421378776, "test_f1": 37.8393668460596}, {"test_em": 31.24031007751938, "test_f1": 36.88372194292192}, {"test_em": 35.85780525502319, "test_f1": 40.38391873251863}, {"test_em": 37.92834890965732, "test_f1": 42.428514114437604}, {"test_em": 29.18918918918919, "test_f1": 35.15810944952534}, {"test_em": 38.16499614494988, "test_f1": 42.94071793809921}, {"test_em": 33.333333333333336, "test_f1": 37.65868720892299}, {"test_em": 33.0488750969744, "test_f1": 38.785652133144445}, {"test_em": 31.294117647058822, "test_f1": 36.83058956032043}, {"test_em": 30.97826086956522, "test_f1": 36.683128747206226}]}, "total": {"test_em": 33.310340073705845, "test_em_se": 1.8909211510605568, "test_f1": 38.55924066731565, "test_f1_se": 1.5971512633058504}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_em": 26.02633617350891, "test_f1": 31.932015412035266}, {"test_em": 21.782945736434108, "test_f1": 28.027641689894608}, {"test_em": 25.038639876352395, "test_f1": 30.663105360767965}, {"test_em": 23.364485981308412, "test_f1": 28.529854248556738}, {"test_em": 17.83783783783784, "test_f1": 25.002167630410234}, {"test_em": 22.51349267540478, "test_f1": 28.988055256177976}, {"test_em": 23.766135155656794, "test_f1": 29.688362477325803}, {"test_em": 23.584173778122576, "test_f1": 29.711793168342485}, {"test_em": 25.96078431372549, "test_f1": 32.57191691481718}, {"test_em": 22.437888198757765, "test_f1": 29.50758422722626}]}, "total": {"test_em": 23.231271972710907, "test_em_se": 1.4796090371314565, "test_f1": 29.462249638555456, "test_f1_se": 1.3127275515332029}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_em": 31.44848954298993, "test_f1": 36.25557478367958}, {"test_em": 30.852713178294575, "test_f1": 36.416726294966665}, {"test_em": 29.443585780525503, "test_f1": 34.3480476014425}, {"test_em": 31.152647975077883, "test_f1": 36.15637222613281}, {"test_em": 26.872586872586872, "test_f1": 32.47245771275155}, {"test_em": 25.983037779491134, "test_f1": 31.39081471432965}, {"test_em": 30.372057706909644, "test_f1": 35.15492346951267}, {"test_em": 26.997672614429792, "test_f1": 32.73856038880272}, {"test_em": 22.352941176470587, "test_f1": 28.838581968157644}, {"test_em": 26.630434782608695, "test_f1": 32.05732127531556}]}, "total": {"test_em": 28.210616740938462, "test_em_se": 1.8169843079499228, "test_f1": 33.58293804350914, "test_f1_se": 1.5521363529577525}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.5036730766296387, "test_mcc": 0.6830222384424192, "test_macro_f1": 0.5801809836618961, "test_runtime": 8.6703, "test_samples_per_second": 236.209, "test_steps_per_second": 29.526}, {"test_loss": 0.48438024520874023, "test_mcc": 0.6932470001153738, "test_macro_f1": 0.6190077112992153, "test_runtime": 8.2278, "test_samples_per_second": 248.914, "test_steps_per_second": 31.114}, {"test_loss": 0.5130420923233032, "test_mcc": 0.6930421244102805, "test_macro_f1": 0.6678339623660694, "test_runtime": 8.3841, "test_samples_per_second": 244.272, "test_steps_per_second": 30.534}, {"test_loss": 0.48815518617630005, "test_mcc": 0.6730307812475688, "test_macro_f1": 0.5842774238181784, "test_runtime": 8.2045, "test_samples_per_second": 249.618, "test_steps_per_second": 31.202}, {"test_loss": 0.5047904849052429, "test_mcc": 0.6739045199214478, "test_macro_f1": 0.6702146620782051, "test_runtime": 8.2543, "test_samples_per_second": 248.114, "test_steps_per_second": 31.014}, {"test_loss": 0.504636287689209, "test_mcc": 0.6748419640697874, "test_macro_f1": 0.6428315310567501, "test_runtime": 8.4965, "test_samples_per_second": 241.039, "test_steps_per_second": 30.13}, {"test_loss": 0.49269264936447144, "test_mcc": 0.6972213603721374, "test_macro_f1": 0.6203901460128415, "test_runtime": 8.0259, "test_samples_per_second": 255.173, "test_steps_per_second": 31.897}, {"test_loss": 0.4939131736755371, "test_mcc": 0.6968345604969816, "test_macro_f1": 0.6477819766518509, "test_runtime": 8.6294, "test_samples_per_second": 237.329, "test_steps_per_second": 29.666}, {"test_loss": 0.5304137468338013, "test_mcc": 0.6412600586196394, "test_macro_f1": 0.6505555407823382, "test_runtime": 8.6851, "test_samples_per_second": 235.806, "test_steps_per_second": 29.476}, {"test_loss": 0.4945298731327057, "test_mcc": 0.7094620707112201, "test_macro_f1": 0.7105272716127494, "test_runtime": 8.3263, "test_samples_per_second": 245.967, "test_steps_per_second": 30.746}]}, "total": {"test_mcc": 68.35866678406856, "test_mcc_se": 1.184530748130455, "test_macro_f1": 63.93601209340094, "test_macro_f1_se": 2.4745896576747293}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.9200639724731445, "test_mcc": 0.36830899803848516, "test_macro_f1": 0.5780916075576494, "test_runtime": 2.6149, "test_samples_per_second": 783.203, "test_steps_per_second": 24.475}, {"test_loss": 0.9505406618118286, "test_mcc": 0.356611366926384, "test_macro_f1": 0.561179005828018, "test_runtime": 2.6197, "test_samples_per_second": 781.762, "test_steps_per_second": 24.43}, {"test_loss": 0.919263482093811, "test_mcc": 0.3572770923323712, "test_macro_f1": 0.5714739938279427, "test_runtime": 2.5719, "test_samples_per_second": 796.295, "test_steps_per_second": 24.884}, {"test_loss": 0.9016720652580261, "test_mcc": 0.39377446279428485, "test_macro_f1": 0.5894093635062507, "test_runtime": 2.5713, "test_samples_per_second": 796.498, "test_steps_per_second": 24.891}, {"test_loss": 0.9178590774536133, "test_mcc": 0.36182735101264746, "test_macro_f1": 0.5676629260644667, "test_runtime": 2.6125, "test_samples_per_second": 783.929, "test_steps_per_second": 24.498}, {"test_loss": 0.9033106565475464, "test_mcc": 0.4059786915853751, "test_macro_f1": 0.6014199822899577, "test_runtime": 2.596, "test_samples_per_second": 788.898, "test_steps_per_second": 24.653}, {"test_loss": 0.9254603385925293, "test_mcc": 0.3881122789528883, "test_macro_f1": 0.5883182951011948, "test_runtime": 2.5933, "test_samples_per_second": 789.738, "test_steps_per_second": 24.679}, {"test_loss": 0.9644569158554077, "test_mcc": 0.3161229060860373, "test_macro_f1": 0.5225983462497669, "test_runtime": 2.6168, "test_samples_per_second": 782.63, "test_steps_per_second": 24.457}, {"test_loss": 0.9147257804870605, "test_mcc": 0.366644592053742, "test_macro_f1": 0.574856553869287, "test_runtime": 2.5758, "test_samples_per_second": 795.081, "test_steps_per_second": 24.846}, {"test_loss": 0.9299646615982056, "test_mcc": 0.34484886755502747, "test_macro_f1": 0.5384814978623028, "test_runtime": 2.6028, "test_samples_per_second": 786.832, "test_steps_per_second": 24.588}]}, "total": {"test_mcc": 36.59506607337243, "test_mcc_se": 1.5978152631901648, "test_macro_f1": 56.934915721568366, "test_macro_f1_se": 1.4768946670284449}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.841215968132019, "test_mcc": 0.46609474672983403, "test_macro_f1": 0.6207051971797514, "test_runtime": 2.0773, "test_samples_per_second": 985.879, "test_steps_per_second": 30.809}, {"test_loss": 0.781441330909729, "test_mcc": 0.4641201743459563, "test_macro_f1": 0.6171009635593888, "test_runtime": 1.9484, "test_samples_per_second": 1051.121, "test_steps_per_second": 32.848}, {"test_loss": 0.834067702293396, "test_mcc": 0.4665965024300974, "test_macro_f1": 0.6358435965345411, "test_runtime": 2.016, "test_samples_per_second": 1015.893, "test_steps_per_second": 31.747}, {"test_loss": 0.8298976421356201, "test_mcc": 0.44662903501235623, "test_macro_f1": 0.5863632172161878, "test_runtime": 1.9994, "test_samples_per_second": 1024.323, "test_steps_per_second": 32.01}, {"test_loss": 0.7950265407562256, "test_mcc": 0.4496583730109515, "test_macro_f1": 0.5951091357451298, "test_runtime": 2.0121, "test_samples_per_second": 1017.856, "test_steps_per_second": 31.808}, {"test_loss": 0.8296329379081726, "test_mcc": 0.43492504347308086, "test_macro_f1": 0.5934120213760774, "test_runtime": 2.1226, "test_samples_per_second": 964.857, "test_steps_per_second": 30.152}, {"test_loss": 0.7823520302772522, "test_mcc": 0.4757440386100898, "test_macro_f1": 0.6142600807378545, "test_runtime": 1.9807, "test_samples_per_second": 1034.001, "test_steps_per_second": 32.313}, {"test_loss": 0.8517112731933594, "test_mcc": 0.367939650776332, "test_macro_f1": 0.5257824887700876, "test_runtime": 2.0602, "test_samples_per_second": 994.06, "test_steps_per_second": 31.064}, {"test_loss": 0.877302885055542, "test_mcc": 0.43862540025123753, "test_macro_f1": 0.5973746701701862, "test_runtime": 2.0711, "test_samples_per_second": 988.831, "test_steps_per_second": 30.901}, {"test_loss": 0.7917823195457458, "test_mcc": 0.4489392819598084, "test_macro_f1": 0.6014838735861048, "test_runtime": 2.0935, "test_samples_per_second": 978.277, "test_steps_per_second": 30.571}]}, "total": {"test_mcc": 44.59272246599745, "test_mcc_se": 1.8860734872559972, "test_macro_f1": 59.8743524487531, "test_macro_f1_se": 1.8437538051356779}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.08247218281030655, "test_micro_f1": 0.562624254473161, "test_micro_f1_no_misc": 0.6446578631452582, "test_runtime": 4.8854, "test_samples_per_second": 419.212, "test_steps_per_second": 13.1}, {"test_loss": 0.08079734444618225, "test_micro_f1": 0.5929919137466307, "test_micro_f1_no_misc": 0.6486153846153846, "test_runtime": 4.4819, "test_samples_per_second": 456.949, "test_steps_per_second": 14.28}, {"test_loss": 0.07555236667394638, "test_micro_f1": 0.5950720595072059, "test_micro_f1_no_misc": 0.6463157894736842, "test_runtime": 4.4146, "test_samples_per_second": 463.911, "test_steps_per_second": 14.497}, {"test_loss": 0.08247263729572296, "test_micro_f1": 0.587511825922422, "test_micro_f1_no_misc": 0.6342494714587738, "test_runtime": 4.5953, "test_samples_per_second": 445.672, "test_steps_per_second": 13.927}, {"test_loss": 0.08427456766366959, "test_micro_f1": 0.609367894497499, "test_micro_f1_no_misc": 0.657421674370827, "test_runtime": 4.7646, "test_samples_per_second": 429.834, "test_steps_per_second": 13.432}, {"test_loss": 0.08220237493515015, "test_micro_f1": 0.5766257389722602, "test_micro_f1_no_misc": 0.6235985050720768, "test_runtime": 3.7713, "test_samples_per_second": 543.054, "test_steps_per_second": 16.97}, {"test_loss": 0.08281752467155457, "test_micro_f1": 0.6038647342995169, "test_micro_f1_no_misc": 0.6703601108033241, "test_runtime": 4.1306, "test_samples_per_second": 495.815, "test_steps_per_second": 15.494}, {"test_loss": 0.07289391756057739, "test_micro_f1": 0.618970189701897, "test_micro_f1_no_misc": 0.6744759556103576, "test_runtime": 4.7427, "test_samples_per_second": 431.818, "test_steps_per_second": 13.494}, {"test_loss": 0.07908554375171661, "test_micro_f1": 0.5954337899543379, "test_micro_f1_no_misc": 0.6630843632455669, "test_runtime": 4.58, "test_samples_per_second": 447.163, "test_steps_per_second": 13.974}, {"test_loss": 0.07614244520664215, "test_micro_f1": 0.629683698296837, "test_micro_f1_no_misc": 0.6873270614277809, "test_runtime": 4.5994, "test_samples_per_second": 445.278, "test_steps_per_second": 13.915}]}, "total": {"test_micro_f1": 59.72146099371768, "test_micro_f1_se": 1.215200834421084, "test_micro_f1_no_misc": 65.50106179223033, "test_micro_f1_no_misc_se": 1.1995886761547134}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.08595666289329529, "test_micro_f1": 0.7258432665483135, "test_micro_f1_no_misc": 0.7544338335607095, "test_runtime": 5.5943, "test_samples_per_second": 366.087, "test_steps_per_second": 11.44}, {"test_loss": 0.09023719280958176, "test_micro_f1": 0.6744628773456623, "test_micro_f1_no_misc": 0.6920634920634919, "test_runtime": 4.2467, "test_samples_per_second": 482.261, "test_steps_per_second": 15.071}, {"test_loss": 0.08915939927101135, "test_micro_f1": 0.711528429838289, "test_micro_f1_no_misc": 0.7278525868178596, "test_runtime": 5.4855, "test_samples_per_second": 373.349, "test_steps_per_second": 11.667}, {"test_loss": 0.08486582338809967, "test_micro_f1": 0.7426945952935092, "test_micro_f1_no_misc": 0.7549668874172186, "test_runtime": 5.2521, "test_samples_per_second": 389.938, "test_steps_per_second": 12.186}, {"test_loss": 0.09540289640426636, "test_micro_f1": 0.6962838781782621, "test_micro_f1_no_misc": 0.7228096676737159, "test_runtime": 5.5198, "test_samples_per_second": 371.03, "test_steps_per_second": 11.595}, {"test_loss": 0.08770714700222015, "test_micro_f1": 0.7346269472533479, "test_micro_f1_no_misc": 0.7359882005899705, "test_runtime": 5.3817, "test_samples_per_second": 380.548, "test_steps_per_second": 11.892}, {"test_loss": 0.08557257801294327, "test_micro_f1": 0.711533386117709, "test_micro_f1_no_misc": 0.7233743409490334, "test_runtime": 5.5701, "test_samples_per_second": 367.677, "test_steps_per_second": 11.49}, {"test_loss": 0.08416277170181274, "test_micro_f1": 0.7065901011758271, "test_micro_f1_no_misc": 0.7193169690501602, "test_runtime": 5.4251, "test_samples_per_second": 377.506, "test_steps_per_second": 11.797}, {"test_loss": 0.08816919475793839, "test_micro_f1": 0.7139830508474575, "test_micro_f1_no_misc": 0.7133262636974195, "test_runtime": 5.2345, "test_samples_per_second": 391.248, "test_steps_per_second": 12.226}, {"test_loss": 0.09191013872623444, "test_micro_f1": 0.7054161162483487, "test_micro_f1_no_misc": 0.7221629313411597, "test_runtime": 4.5192, "test_samples_per_second": 453.178, "test_steps_per_second": 14.162}]}, "total": {"test_micro_f1": 71.22962648846726, "test_micro_f1_se": 1.2007680878561489, "test_micro_f1_no_misc": 72.66295173160738, "test_micro_f1_no_misc_se": 1.1568917840415633}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.05998680368065834, "test_micro_f1": 0.7401855817273376, "test_micro_f1_no_misc": 0.7794294897549217, "test_runtime": 4.2952, "test_samples_per_second": 476.815, "test_steps_per_second": 14.9}, {"test_loss": 0.05675952136516571, "test_micro_f1": 0.760655737704918, "test_micro_f1_no_misc": 0.7816185441236275, "test_runtime": 4.1361, "test_samples_per_second": 495.153, "test_steps_per_second": 15.474}, {"test_loss": 0.05657687783241272, "test_micro_f1": 0.7540869565217391, "test_micro_f1_no_misc": 0.7809377401998463, "test_runtime": 3.9972, "test_samples_per_second": 512.364, "test_steps_per_second": 16.011}, {"test_loss": 0.05547136813402176, "test_micro_f1": 0.7459938629389703, "test_micro_f1_no_misc": 0.7704485488126649, "test_runtime": 3.8282, "test_samples_per_second": 534.974, "test_steps_per_second": 16.718}, {"test_loss": 0.061840638518333435, "test_micro_f1": 0.7384116693679091, "test_micro_f1_no_misc": 0.7737068965517241, "test_runtime": 4.2098, "test_samples_per_second": 486.487, "test_steps_per_second": 15.203}, {"test_loss": 0.058588262647390366, "test_micro_f1": 0.7417840375586853, "test_micro_f1_no_misc": 0.7722772277227723, "test_runtime": 4.2137, "test_samples_per_second": 486.034, "test_steps_per_second": 15.189}, {"test_loss": 0.05206356197595596, "test_micro_f1": 0.7736486486486486, "test_micro_f1_no_misc": 0.8058361391694726, "test_runtime": 3.7778, "test_samples_per_second": 542.118, "test_steps_per_second": 16.941}, {"test_loss": 0.061585597693920135, "test_micro_f1": 0.756811301715439, "test_micro_f1_no_misc": 0.7871396895787139, "test_runtime": 3.9323, "test_samples_per_second": 520.809, "test_steps_per_second": 16.275}, {"test_loss": 0.053768228739500046, "test_micro_f1": 0.7394957983193279, "test_micro_f1_no_misc": 0.7625340069957249, "test_runtime": 3.8866, "test_samples_per_second": 526.937, "test_steps_per_second": 16.467}, {"test_loss": 0.06915701925754547, "test_micro_f1": 0.7317073170731708, "test_micro_f1_no_misc": 0.7674333698430085, "test_runtime": 4.0873, "test_samples_per_second": 501.068, "test_steps_per_second": 15.658}]}, "total": {"test_micro_f1": 74.82780911576144, "test_micro_f1_se": 0.7908773546922541, "test_micro_f1_no_misc": 77.81361652752477, "test_micro_f1_no_misc_se": 0.7565765494981195}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.08074561506509781, "test_micro_f1": 0.6964231121981046, "test_micro_f1_no_misc": 0.7298831385642738, "test_runtime": 3.9288, "test_samples_per_second": 521.277, "test_steps_per_second": 16.29}, {"test_loss": 0.0826406180858612, "test_micro_f1": 0.6666666666666666, "test_micro_f1_no_misc": 0.7070249271608935, "test_runtime": 3.9732, "test_samples_per_second": 515.455, "test_steps_per_second": 16.108}, {"test_loss": 0.0836346298456192, "test_micro_f1": 0.689655172413793, "test_micro_f1_no_misc": 0.7314172447968286, "test_runtime": 3.8531, "test_samples_per_second": 531.523, "test_steps_per_second": 16.61}, {"test_loss": 0.09302131831645966, "test_micro_f1": 0.6573218013719058, "test_micro_f1_no_misc": 0.6966731898238747, "test_runtime": 3.9805, "test_samples_per_second": 514.507, "test_steps_per_second": 16.078}, {"test_loss": 0.09864125400781631, "test_micro_f1": 0.6593341260404281, "test_micro_f1_no_misc": 0.7085201793721974, "test_runtime": 3.8307, "test_samples_per_second": 534.633, "test_steps_per_second": 16.707}, {"test_loss": 0.08415068686008453, "test_micro_f1": 0.6946745562130178, "test_micro_f1_no_misc": 0.7320261437908496, "test_runtime": 3.9617, "test_samples_per_second": 516.953, "test_steps_per_second": 16.155}, {"test_loss": 0.07828570902347565, "test_micro_f1": 0.6771507863089731, "test_micro_f1_no_misc": 0.7163978494623657, "test_runtime": 4.0606, "test_samples_per_second": 504.36, "test_steps_per_second": 15.761}, {"test_loss": 0.08001711964607239, "test_micro_f1": 0.6884650317892825, "test_micro_f1_no_misc": 0.7262344642257306, "test_runtime": 4.0183, "test_samples_per_second": 509.674, "test_steps_per_second": 15.927}, {"test_loss": 0.0881529450416565, "test_micro_f1": 0.6873083997547517, "test_micro_f1_no_misc": 0.7243022464261403, "test_runtime": 3.7213, "test_samples_per_second": 550.338, "test_steps_per_second": 17.198}, {"test_loss": 0.07478778809309006, "test_micro_f1": 0.7153153153153152, "test_micro_f1_no_misc": 0.7496688741721854, "test_runtime": 3.8945, "test_samples_per_second": 525.867, "test_steps_per_second": 16.433}]}, "total": {"test_micro_f1": 68.3231496807224, "test_micro_f1_se": 1.1265735775636052, "test_micro_f1_no_misc": 72.2214825779534, "test_micro_f1_no_misc_se": 0.95092612358204}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.6920970678329468, "test_mcc": 0.019571885872874655, "test_macro_f1": 0.46608393313501767, "test_runtime": 2.0217, "test_samples_per_second": 1013.012, "test_steps_per_second": 31.657}, {"test_loss": 0.666379451751709, "test_mcc": 0.24311226007656103, "test_macro_f1": 0.6115850893399232, "test_runtime": 2.0882, "test_samples_per_second": 980.753, "test_steps_per_second": 30.649}, {"test_loss": 0.6925046443939209, "test_mcc": 0.03586558930550331, "test_macro_f1": 0.5146050606910378, "test_runtime": 2.0916, "test_samples_per_second": 979.135, "test_steps_per_second": 30.598}, {"test_loss": 0.6928786039352417, "test_mcc": 0.03515531201604414, "test_macro_f1": 0.502725582335528, "test_runtime": 2.0361, "test_samples_per_second": 1005.831, "test_steps_per_second": 31.432}, {"test_loss": 0.6709704399108887, "test_mcc": 0.21166417563393763, "test_macro_f1": 0.6054557499149553, "test_runtime": 2.0713, "test_samples_per_second": 988.729, "test_steps_per_second": 30.898}, {"test_loss": 0.6608574986457825, "test_mcc": 0.21336732052297233, "test_macro_f1": 0.5979650972102506, "test_runtime": 2.0176, "test_samples_per_second": 1015.07, "test_steps_per_second": 31.721}, {"test_loss": 0.6538949012756348, "test_mcc": 0.24337994499703872, "test_macro_f1": 0.6118454637677266, "test_runtime": 2.1306, "test_samples_per_second": 961.224, "test_steps_per_second": 30.038}, {"test_loss": 0.6674292087554932, "test_mcc": 0.2042526403697712, "test_macro_f1": 0.5993004290038767, "test_runtime": 2.0623, "test_samples_per_second": 993.062, "test_steps_per_second": 31.033}, {"test_loss": 0.6597943305969238, "test_mcc": 0.26285690778145787, "test_macro_f1": 0.607843137254902, "test_runtime": 2.1155, "test_samples_per_second": 968.101, "test_steps_per_second": 30.253}, {"test_loss": 0.6928848028182983, "test_mcc": 0.011983311968100123, "test_macro_f1": 0.43218643033414034, "test_runtime": 2.0982, "test_samples_per_second": 976.062, "test_steps_per_second": 30.502}]}, "total": {"test_mcc": 14.812093485442606, "test_mcc_se": 6.634740152407461, "test_macro_f1": 55.49595972987359, "test_macro_f1_se": 4.280882894612987}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.6936782598495483, "test_mcc": -0.024649730464208798, "test_macro_f1": 0.46851580995637987, "test_runtime": 2.2025, "test_samples_per_second": 929.86, "test_steps_per_second": 29.058}, {"test_loss": 0.6932549476623535, "test_mcc": 0.04071852465034033, "test_macro_f1": 0.45922836900877295, "test_runtime": 2.2902, "test_samples_per_second": 894.226, "test_steps_per_second": 27.945}, {"test_loss": 0.6750810146331787, "test_mcc": 0.15238312997038964, "test_macro_f1": 0.5694929010822821, "test_runtime": 2.2849, "test_samples_per_second": 896.323, "test_steps_per_second": 28.01}, {"test_loss": 0.6707598567008972, "test_mcc": 0.1745696333055986, "test_macro_f1": 0.5791274568822475, "test_runtime": 2.3881, "test_samples_per_second": 857.573, "test_steps_per_second": 26.799}, {"test_loss": 0.6940641403198242, "test_mcc": -0.01969676413357279, "test_macro_f1": 0.48703088106885184, "test_runtime": 2.2324, "test_samples_per_second": 917.389, "test_steps_per_second": 28.668}, {"test_loss": 0.6924997568130493, "test_mcc": 0.034603643080159785, "test_macro_f1": 0.46242325743691626, "test_runtime": 2.2167, "test_samples_per_second": 923.911, "test_steps_per_second": 28.872}, {"test_loss": 0.6932553052902222, "test_mcc": 0.026988693282890584, "test_macro_f1": 0.4319369787647733, "test_runtime": 2.166, "test_samples_per_second": 945.515, "test_steps_per_second": 29.547}, {"test_loss": 0.6643307209014893, "test_mcc": 0.21253897323347448, "test_macro_f1": 0.5968484341811713, "test_runtime": 2.1967, "test_samples_per_second": 932.316, "test_steps_per_second": 29.135}, {"test_loss": 0.6772351861000061, "test_mcc": 0.15060303059688668, "test_macro_f1": 0.570594019318642, "test_runtime": 2.1926, "test_samples_per_second": 934.052, "test_steps_per_second": 29.189}, {"test_loss": 0.6765670776367188, "test_mcc": 0.13628982260143743, "test_macro_f1": 0.5509542986358753, "test_runtime": 2.3491, "test_samples_per_second": 871.838, "test_steps_per_second": 27.245}]}, "total": {"test_mcc": 8.843489561233959, "test_mcc_se": 5.327621595836661, "test_macro_f1": 51.76152406335912, "test_macro_f1_se": 3.7990808431498255}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.6920773983001709, "test_mcc": 0.04692861287851037, "test_macro_f1": 0.5028605869581535, "test_runtime": 2.0029, "test_samples_per_second": 1022.492, "test_steps_per_second": 31.953}, {"test_loss": 0.682287335395813, "test_mcc": 0.1322725616671501, "test_macro_f1": 0.5510412860796493, "test_runtime": 1.9847, "test_samples_per_second": 1031.895, "test_steps_per_second": 32.247}, {"test_loss": 0.692322313785553, "test_mcc": 0.0869280732837881, "test_macro_f1": 0.5208715950867193, "test_runtime": 2.0771, "test_samples_per_second": 986.011, "test_steps_per_second": 30.813}, {"test_loss": 0.6729775667190552, "test_mcc": 0.18466397777320165, "test_macro_f1": 0.5655163856010055, "test_runtime": 2.0536, "test_samples_per_second": 997.261, "test_steps_per_second": 31.164}, {"test_loss": 0.6930071711540222, "test_mcc": 0.028850644840072392, "test_macro_f1": 0.5004480870974647, "test_runtime": 2.0224, "test_samples_per_second": 1012.661, "test_steps_per_second": 31.646}, {"test_loss": 0.6862271428108215, "test_mcc": 0.10321961357008305, "test_macro_f1": 0.4726728040060353, "test_runtime": 1.9612, "test_samples_per_second": 1044.249, "test_steps_per_second": 32.633}, {"test_loss": 0.6871302127838135, "test_mcc": 0.09177692701934329, "test_macro_f1": 0.5347245120668269, "test_runtime": 1.9667, "test_samples_per_second": 1041.334, "test_steps_per_second": 32.542}, {"test_loss": 0.6926810145378113, "test_mcc": 0.007170360217988978, "test_macro_f1": 0.4942965043090927, "test_runtime": 1.9906, "test_samples_per_second": 1028.81, "test_steps_per_second": 32.15}, {"test_loss": 0.6757801175117493, "test_mcc": 0.1603955656454944, "test_macro_f1": 0.5790971664461944, "test_runtime": 1.9567, "test_samples_per_second": 1046.657, "test_steps_per_second": 32.708}, {"test_loss": 0.6889365315437317, "test_mcc": 0.0559542367175593, "test_macro_f1": 0.527822912610989, "test_runtime": 2.0661, "test_samples_per_second": 991.26, "test_steps_per_second": 30.977}]}, "total": {"test_mcc": 8.981605736131916, "test_mcc_se": 3.548811353929451, "test_macro_f1": 52.493518402621305, "test_macro_f1_se": 2.0803877717826005}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_loss": 0.6798707246780396, "test_mcc": 0.12316746923488496, "test_macro_f1": 0.560546875, "test_runtime": 2.0683, "test_samples_per_second": 990.188, "test_steps_per_second": 30.943}, {"test_loss": 0.6925420761108398, "test_mcc": 0.047917296864202354, "test_macro_f1": 0.5225490196078431, "test_runtime": 2.1191, "test_samples_per_second": 966.44, "test_steps_per_second": 30.201}, {"test_loss": 0.6928820610046387, "test_mcc": 0.0048175772748147525, "test_macro_f1": 0.4389392574382666, "test_runtime": 2.1158, "test_samples_per_second": 967.974, "test_steps_per_second": 30.249}, {"test_loss": 0.6936331987380981, "test_mcc": 0.06215354756404121, "test_macro_f1": 0.4083921724209867, "test_runtime": 2.0053, "test_samples_per_second": 1021.289, "test_steps_per_second": 31.915}, {"test_loss": 0.6863626837730408, "test_mcc": 0.12118747471988757, "test_macro_f1": 0.5605925329808817, "test_runtime": 2.0404, "test_samples_per_second": 1003.72, "test_steps_per_second": 31.366}, {"test_loss": 0.6831422448158264, "test_mcc": 0.13649182326367232, "test_macro_f1": 0.5567575437882125, "test_runtime": 2.1058, "test_samples_per_second": 972.573, "test_steps_per_second": 30.393}, {"test_loss": 0.6926929354667664, "test_mcc": 0.01999503174140761, "test_macro_f1": 0.4896331738437002, "test_runtime": 2.0333, "test_samples_per_second": 1007.245, "test_steps_per_second": 31.476}, {"test_loss": 0.6921914219856262, "test_mcc": 0.05477440924397195, "test_macro_f1": 0.5265343003667229, "test_runtime": 2.0714, "test_samples_per_second": 988.712, "test_steps_per_second": 30.897}, {"test_loss": 0.6938158273696899, "test_mcc": 0.0010376903880685068, "test_macro_f1": 0.4913607575478079, "test_runtime": 2.0813, "test_samples_per_second": 983.987, "test_steps_per_second": 30.75}, {"test_loss": 0.6934152245521545, "test_mcc": 0.0006224622163890603, "test_macro_f1": 0.4846451902921445, "test_runtime": 2.0821, "test_samples_per_second": 983.625, "test_steps_per_second": 30.738}]}, "total": {"test_mcc": 5.721647825113404, "test_mcc_se": 3.2883659378988135, "test_macro_f1": 50.399508232865664, "test_macro_f1_se": 3.2106534056640603}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_em": 27.652982184353213, "test_f1": 33.395403257932095}, {"test_em": 28.06201550387597, "test_f1": 33.87515463466326}, {"test_em": 27.820710973724886, "test_f1": 33.35325668300317}, {"test_em": 25.0, "test_f1": 30.744054755346397}, {"test_em": 20.694980694980696, "test_f1": 26.963881523993457}, {"test_em": 20.277563608326908, "test_f1": 26.644468895506563}, {"test_em": 17.995444191343964, "test_f1": 23.96837180076479}, {"test_em": 28.006206361520558, "test_f1": 33.677154669448065}, {"test_em": 25.647058823529413, "test_f1": 31.455168795202695}, {"test_em": 30.124223602484474, "test_f1": 35.44503564509023}]}, "total": {"test_em": 25.12811859441401, "test_em_se": 2.528818201520225, "test_f1": 30.952195066095072, "test_f1_se": 2.3684781358503684}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_em": 29.43454686289698, "test_f1": 36.021556815409284}, {"test_em": 27.441860465116278, "test_f1": 35.21449701083337}, {"test_em": 27.125193199381762, "test_f1": 33.911956670974206}, {"test_em": 28.193146417445483, "test_f1": 34.25692445158031}, {"test_em": 27.876447876447877, "test_f1": 33.53572943221617}, {"test_em": 27.370855821125673, "test_f1": 33.4819990242363}, {"test_em": 27.33485193621868, "test_f1": 33.6394008112871}, {"test_em": 26.60977501939488, "test_f1": 31.95867445691628}, {"test_em": 29.41176470588235, "test_f1": 36.93091453761643}, {"test_em": 33.850931677018636, "test_f1": 40.06176041905937}]}, "total": {"test_em": 28.46493739809286, "test_em_se": 1.3070436692428573, "test_f1": 34.90134136301289, "test_f1_se": 1.4258153567057272}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_em": 30.673896204492642, "test_f1": 37.328963116926005}, {"test_em": 24.8062015503876, "test_f1": 31.542794573961896}, {"test_em": 28.516228748068006, "test_f1": 34.73296953552545}, {"test_em": 22.66355140186916, "test_f1": 29.371283389023617}, {"test_em": 22.16216216216216, "test_f1": 28.786541887662985}, {"test_em": 25.751734772552044, "test_f1": 33.36553615559226}, {"test_em": 29.23310554290053, "test_f1": 35.552214284951795}, {"test_em": 26.377036462373933, "test_f1": 33.6703600928417}, {"test_em": 31.058823529411764, "test_f1": 37.530443909819674}, {"test_em": 22.593167701863354, "test_f1": 30.062816494960842}]}, "total": {"test_em": 26.38359080760812, "test_em_se": 2.0850066754482803, "test_f1": 33.19439234412662, "test_f1_se": 1.967154536321641}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.38142064213752747, "test_mcc": 0.7564177892783056, "test_macro_f1": 0.7361098133648385, "test_runtime": 14.0231, "test_samples_per_second": 146.045, "test_steps_per_second": 18.256}, {"test_loss": 0.44411540031433105, "test_mcc": 0.742177256282863, "test_macro_f1": 0.7203722571547285, "test_runtime": 13.1474, "test_samples_per_second": 155.772, "test_steps_per_second": 19.472}, {"test_loss": 0.4199405908584595, "test_mcc": 0.7532817180113759, "test_macro_f1": 0.7218077942229391, "test_runtime": 13.6496, "test_samples_per_second": 150.041, "test_steps_per_second": 18.755}, {"test_loss": 0.3596622943878174, "test_mcc": 0.7670032084711793, "test_macro_f1": 0.7263101217562454, "test_runtime": 12.9285, "test_samples_per_second": 158.41, "test_steps_per_second": 19.801}, {"test_loss": 0.363484263420105, "test_mcc": 0.7680358182170806, "test_macro_f1": 0.7615217481088318, "test_runtime": 12.7717, "test_samples_per_second": 160.354, "test_steps_per_second": 20.044}, {"test_loss": 0.4128563404083252, "test_mcc": 0.7461574648059864, "test_macro_f1": 0.6973527315605743, "test_runtime": 13.1735, "test_samples_per_second": 155.464, "test_steps_per_second": 19.433}, {"test_loss": 0.39028632640838623, "test_mcc": 0.7725380369422339, "test_macro_f1": 0.7661411195043568, "test_runtime": 12.6749, "test_samples_per_second": 161.579, "test_steps_per_second": 20.197}, {"test_loss": 0.38174960017204285, "test_mcc": 0.7718053444875209, "test_macro_f1": 0.7714391375274309, "test_runtime": 13.63, "test_samples_per_second": 150.257, "test_steps_per_second": 18.782}, {"test_loss": 0.4024972915649414, "test_mcc": 0.7494423063711997, "test_macro_f1": 0.7225146825249062, "test_runtime": 13.5748, "test_samples_per_second": 150.868, "test_steps_per_second": 18.858}, {"test_loss": 0.3931802213191986, "test_mcc": 0.7461571784821192, "test_macro_f1": 0.7377695016507345, "test_runtime": 13.215, "test_samples_per_second": 154.975, "test_steps_per_second": 19.372}]}, "total": {"test_mcc": 75.73016121349865, "test_mcc_se": 0.717982415113771, "test_macro_f1": 73.61338907375585, "test_macro_f1_se": 1.4658195526141804}}, "num_model_parameters": 124693251, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.9603534936904907, "test_mcc": 0.2854215439145174, "test_macro_f1": 0.4965683944084878, "test_runtime": 5.2626, "test_samples_per_second": 389.16, "test_steps_per_second": 12.161}, {"test_loss": 0.9050782918930054, "test_mcc": 0.372437297953479, "test_macro_f1": 0.5643658769748225, "test_runtime": 5.1529, "test_samples_per_second": 397.448, "test_steps_per_second": 12.42}, {"test_loss": 1.0550495386123657, "test_mcc": 0.3228942031816684, "test_macro_f1": 0.5426240930983545, "test_runtime": 5.1411, "test_samples_per_second": 398.361, "test_steps_per_second": 12.449}, {"test_loss": 0.9521706104278564, "test_mcc": 0.34880862900528165, "test_macro_f1": 0.5562215558470903, "test_runtime": 5.1945, "test_samples_per_second": 394.26, "test_steps_per_second": 12.321}, {"test_loss": 0.9799266457557678, "test_mcc": 0.3291216367109194, "test_macro_f1": 0.534922182882958, "test_runtime": 5.2213, "test_samples_per_second": 392.238, "test_steps_per_second": 12.257}, {"test_loss": 0.973024308681488, "test_mcc": 0.3375180449260147, "test_macro_f1": 0.5490731247420325, "test_runtime": 5.1623, "test_samples_per_second": 396.726, "test_steps_per_second": 12.398}, {"test_loss": 0.9169017672538757, "test_mcc": 0.3399455284916528, "test_macro_f1": 0.5491434662958151, "test_runtime": 5.1973, "test_samples_per_second": 394.052, "test_steps_per_second": 12.314}, {"test_loss": 0.9974560737609863, "test_mcc": 0.3096082450619953, "test_macro_f1": 0.4997441578463586, "test_runtime": 5.1443, "test_samples_per_second": 398.11, "test_steps_per_second": 12.441}, {"test_loss": 0.9690852165222168, "test_mcc": 0.3335194833425786, "test_macro_f1": 0.5552517047161486, "test_runtime": 5.1376, "test_samples_per_second": 398.627, "test_steps_per_second": 12.457}, {"test_loss": 0.9657802581787109, "test_mcc": 0.35213487668736393, "test_macro_f1": 0.5611066791810698, "test_runtime": 5.1613, "test_samples_per_second": 396.796, "test_steps_per_second": 12.4}]}, "total": {"test_mcc": 33.31409489275472, "test_mcc_se": 1.485257246021639, "test_macro_f1": 54.09021235993138, "test_macro_f1_se": 1.4944398163312913}}, "num_model_parameters": 124693251, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.8457089066505432, "test_mcc": 0.366469757013856, "test_macro_f1": 0.4766680303193603, "test_runtime": 4.2284, "test_samples_per_second": 484.341, "test_steps_per_second": 15.136}, {"test_loss": 0.8794926404953003, "test_mcc": 0.3833500544595698, "test_macro_f1": 0.541077387063655, "test_runtime": 3.9461, "test_samples_per_second": 518.996, "test_steps_per_second": 16.219}, {"test_loss": 0.8233185410499573, "test_mcc": 0.42541507804762174, "test_macro_f1": 0.5399344574661535, "test_runtime": 3.9327, "test_samples_per_second": 520.759, "test_steps_per_second": 16.274}, {"test_loss": 0.8838033676147461, "test_mcc": 0.3009236706158335, "test_macro_f1": 0.4208243576969896, "test_runtime": 4.128, "test_samples_per_second": 496.125, "test_steps_per_second": 15.504}, {"test_loss": 0.86622154712677, "test_mcc": 0.38285213345082797, "test_macro_f1": 0.522537548406817, "test_runtime": 4.2421, "test_samples_per_second": 482.779, "test_steps_per_second": 15.087}, {"test_loss": 0.8268816471099854, "test_mcc": 0.37630449635519264, "test_macro_f1": 0.47373677335529757, "test_runtime": 4.1784, "test_samples_per_second": 490.136, "test_steps_per_second": 15.317}, {"test_loss": 0.8716349005699158, "test_mcc": 0.4158033850166839, "test_macro_f1": 0.579083332365775, "test_runtime": 4.0257, "test_samples_per_second": 508.727, "test_steps_per_second": 15.898}, {"test_loss": 0.8937285542488098, "test_mcc": 0.41762062912830383, "test_macro_f1": 0.5541993817423955, "test_runtime": 4.1182, "test_samples_per_second": 497.306, "test_steps_per_second": 15.541}, {"test_loss": 0.8328832983970642, "test_mcc": 0.36618228990779583, "test_macro_f1": 0.4797160120506459, "test_runtime": 4.2676, "test_samples_per_second": 479.893, "test_steps_per_second": 14.997}, {"test_loss": 0.8537735939025879, "test_mcc": 0.382400474213827, "test_macro_f1": 0.45622574536397126, "test_runtime": 4.1994, "test_samples_per_second": 487.686, "test_steps_per_second": 15.24}]}, "total": {"test_mcc": 38.17321968209512, "test_mcc_se": 2.2054773540510673, "test_macro_f1": 50.44003025831061, "test_macro_f1_se": 3.107197235830186}}, "num_model_parameters": 124693251, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.05129780247807503, "test_micro_f1": 0.770392749244713, "test_micro_f1_no_misc": 0.8290094339622641, "test_runtime": 6.6934, "test_samples_per_second": 305.972, "test_steps_per_second": 9.562}, {"test_loss": 0.050716549158096313, "test_micro_f1": 0.7870967741935484, "test_micro_f1_no_misc": 0.8353808353808353, "test_runtime": 6.1306, "test_samples_per_second": 334.064, "test_steps_per_second": 10.439}, {"test_loss": 0.047813378274440765, "test_micro_f1": 0.7465618860510804, "test_micro_f1_no_misc": 0.795417348608838, "test_runtime": 5.9946, "test_samples_per_second": 341.643, "test_steps_per_second": 10.676}, {"test_loss": 0.05271301418542862, "test_micro_f1": 0.7242044358727097, "test_micro_f1_no_misc": 0.7824199674443841, "test_runtime": 6.5838, "test_samples_per_second": 311.066, "test_steps_per_second": 9.721}, {"test_loss": 0.056103818118572235, "test_micro_f1": 0.7444120505344995, "test_micro_f1_no_misc": 0.7942430703624733, "test_runtime": 6.5313, "test_samples_per_second": 313.569, "test_steps_per_second": 9.799}, {"test_loss": 0.04310181364417076, "test_micro_f1": 0.7836961556276053, "test_micro_f1_no_misc": 0.8236536430834214, "test_runtime": 5.1967, "test_samples_per_second": 394.095, "test_steps_per_second": 12.315}, {"test_loss": 0.04934025555849075, "test_micro_f1": 0.7355883754168653, "test_micro_f1_no_misc": 0.8064159292035399, "test_runtime": 5.4817, "test_samples_per_second": 373.605, "test_steps_per_second": 11.675}, {"test_loss": 0.0501643568277359, "test_micro_f1": 0.7234273318872018, "test_micro_f1_no_misc": 0.7726190476190476, "test_runtime": 6.5248, "test_samples_per_second": 313.881, "test_steps_per_second": 9.809}, {"test_loss": 0.03546930104494095, "test_micro_f1": 0.7965200579990334, "test_micro_f1_no_misc": 0.8454396504642273, "test_runtime": 6.0322, "test_samples_per_second": 339.51, "test_steps_per_second": 10.61}, {"test_loss": 0.046282488852739334, "test_micro_f1": 0.7830326669917114, "test_micro_f1_no_misc": 0.8387451843698404, "test_runtime": 6.5999, "test_samples_per_second": 310.31, "test_steps_per_second": 9.697}]}, "total": {"test_micro_f1": 75.94932483818967, "test_micro_f1_se": 1.7166362322383384, "test_micro_f1_no_misc": 81.23344110498871, "test_micro_f1_no_misc_se": 1.5804052263312895}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06916838884353638, "test_micro_f1": 0.7925963488843812, "test_micro_f1_no_misc": 0.8249400479616307, "test_runtime": 9.3076, "test_samples_per_second": 220.036, "test_steps_per_second": 6.876}, {"test_loss": 0.06726449728012085, "test_micro_f1": 0.777120315581854, "test_micro_f1_no_misc": 0.8061034611090435, "test_runtime": 7.7786, "test_samples_per_second": 263.285, "test_steps_per_second": 8.228}, {"test_loss": 0.0662379264831543, "test_micro_f1": 0.7947830715996805, "test_micro_f1_no_misc": 0.8267831149927221, "test_runtime": 9.6478, "test_samples_per_second": 212.276, "test_steps_per_second": 6.634}, {"test_loss": 0.0705932080745697, "test_micro_f1": 0.7958549222797928, "test_micro_f1_no_misc": 0.820184790334044, "test_runtime": 9.0391, "test_samples_per_second": 226.571, "test_steps_per_second": 7.08}, {"test_loss": 0.07424737513065338, "test_micro_f1": 0.7596422582448296, "test_micro_f1_no_misc": 0.787201233616037, "test_runtime": 9.7834, "test_samples_per_second": 209.334, "test_steps_per_second": 6.542}, {"test_loss": 0.07005732506513596, "test_micro_f1": 0.7938311688311689, "test_micro_f1_no_misc": 0.8208955223880599, "test_runtime": 9.2435, "test_samples_per_second": 221.56, "test_steps_per_second": 6.924}, {"test_loss": 0.07131612300872803, "test_micro_f1": 0.7852598091198304, "test_micro_f1_no_misc": 0.8149763722282807, "test_runtime": 9.9187, "test_samples_per_second": 206.479, "test_steps_per_second": 6.452}, {"test_loss": 0.06427460163831711, "test_micro_f1": 0.8029395753946652, "test_micro_f1_no_misc": 0.8306451612903225, "test_runtime": 9.2388, "test_samples_per_second": 221.675, "test_steps_per_second": 6.927}, {"test_loss": 0.0702490508556366, "test_micro_f1": 0.8007518796992482, "test_micro_f1_no_misc": 0.8154069767441859, "test_runtime": 9.0393, "test_samples_per_second": 226.565, "test_steps_per_second": 7.08}, {"test_loss": 0.07461833953857422, "test_micro_f1": 0.8185473063521844, "test_micro_f1_no_misc": 0.842453176643408, "test_runtime": 7.6343, "test_samples_per_second": 268.264, "test_steps_per_second": 8.383}]}, "total": {"test_micro_f1": 79.21326655987635, "test_micro_f1_se": 0.978043827164807, "test_micro_f1_no_misc": 81.89589857307735, "test_micro_f1_no_misc_se": 0.9223539378077459}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.05530884861946106, "test_micro_f1": 0.7793633369923161, "test_micro_f1_no_misc": 0.8297264189465087, "test_runtime": 7.2104, "test_samples_per_second": 284.035, "test_steps_per_second": 8.876}, {"test_loss": 0.040746547281742096, "test_micro_f1": 0.8228273032450578, "test_micro_f1_no_misc": 0.8598516075845011, "test_runtime": 7.1906, "test_samples_per_second": 284.817, "test_steps_per_second": 8.901}, {"test_loss": 0.05160532519221306, "test_micro_f1": 0.8240549828178694, "test_micro_f1_no_misc": 0.8553702985653353, "test_runtime": 6.941, "test_samples_per_second": 295.057, "test_steps_per_second": 9.221}, {"test_loss": 0.048034220933914185, "test_micro_f1": 0.8149429263230715, "test_micro_f1_no_misc": 0.8467773060594366, "test_runtime": 6.9712, "test_samples_per_second": 293.78, "test_steps_per_second": 9.181}, {"test_loss": 0.05061451345682144, "test_micro_f1": 0.8051181102362204, "test_micro_f1_no_misc": 0.8318264014466547, "test_runtime": 7.2863, "test_samples_per_second": 281.076, "test_steps_per_second": 8.784}, {"test_loss": 0.039712365716695786, "test_micro_f1": 0.8571428571428572, "test_micro_f1_no_misc": 0.8855606758832566, "test_runtime": 7.2694, "test_samples_per_second": 281.727, "test_steps_per_second": 8.804}, {"test_loss": 0.04495169222354889, "test_micro_f1": 0.8385093167701863, "test_micro_f1_no_misc": 0.8653696498054474, "test_runtime": 6.6113, "test_samples_per_second": 309.775, "test_steps_per_second": 9.68}, {"test_loss": 0.05224192142486572, "test_micro_f1": 0.8227631127871101, "test_micro_f1_no_misc": 0.8487332339791357, "test_runtime": 6.8461, "test_samples_per_second": 299.148, "test_steps_per_second": 9.348}, {"test_loss": 0.04548745974898338, "test_micro_f1": 0.8154929577464789, "test_micro_f1_no_misc": 0.8479225494150867, "test_runtime": 6.8644, "test_samples_per_second": 298.35, "test_steps_per_second": 9.323}, {"test_loss": 0.04809809476137161, "test_micro_f1": 0.8330464716006883, "test_micro_f1_no_misc": 0.8615266589950134, "test_runtime": 6.9177, "test_samples_per_second": 296.053, "test_steps_per_second": 9.252}]}, "total": {"test_micro_f1": 82.13261375661857, "test_micro_f1_se": 1.2778602810277124, "test_micro_f1_no_misc": 85.32664800680377, "test_micro_f1_no_misc_se": 1.0143409891081694}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06272469460964203, "test_micro_f1": 0.7684275184275183, "test_micro_f1_no_misc": 0.8047457627118645, "test_runtime": 6.8053, "test_samples_per_second": 300.943, "test_steps_per_second": 9.404}, {"test_loss": 0.061231546103954315, "test_micro_f1": 0.7883565797453002, "test_micro_f1_no_misc": 0.8193094200469326, "test_runtime": 6.8647, "test_samples_per_second": 298.337, "test_steps_per_second": 9.323}, {"test_loss": 0.06796841323375702, "test_micro_f1": 0.7407862407862409, "test_micro_f1_no_misc": 0.7816013628620103, "test_runtime": 6.5365, "test_samples_per_second": 313.318, "test_steps_per_second": 9.791}, {"test_loss": 0.07756125926971436, "test_micro_f1": 0.6947743467933492, "test_micro_f1_no_misc": 0.7382849856550844, "test_runtime": 6.8861, "test_samples_per_second": 297.41, "test_steps_per_second": 9.294}, {"test_loss": 0.06758991628885269, "test_micro_f1": 0.7618486900206064, "test_micro_f1_no_misc": 0.8054607508532423, "test_runtime": 6.5749, "test_samples_per_second": 311.488, "test_steps_per_second": 9.734}, {"test_loss": 0.06243672966957092, "test_micro_f1": 0.7898203592814371, "test_micro_f1_no_misc": 0.8218992903007772, "test_runtime": 6.384, "test_samples_per_second": 320.8, "test_steps_per_second": 10.025}, {"test_loss": 0.06548295170068741, "test_micro_f1": 0.7154422788605697, "test_micro_f1_no_misc": 0.7616897774911319, "test_runtime": 6.9243, "test_samples_per_second": 295.768, "test_steps_per_second": 9.243}, {"test_loss": 0.06299382448196411, "test_micro_f1": 0.7803196490128487, "test_micro_f1_no_misc": 0.812650395324854, "test_runtime": 6.9317, "test_samples_per_second": 295.455, "test_steps_per_second": 9.233}, {"test_loss": 0.07326378673315048, "test_micro_f1": 0.7569745815251085, "test_micro_f1_no_misc": 0.7918395573997233, "test_runtime": 6.8851, "test_samples_per_second": 297.456, "test_steps_per_second": 9.295}, {"test_loss": 0.06275780498981476, "test_micro_f1": 0.776793893129771, "test_micro_f1_no_misc": 0.8063978673775408, "test_runtime": 6.6825, "test_samples_per_second": 306.47, "test_steps_per_second": 9.577}]}, "total": {"test_micro_f1": 75.73544137582749, "test_micro_f1_se": 1.9611778163134406, "test_micro_f1_no_misc": 79.43879170023162, "test_micro_f1_no_misc_se": 1.6621272467299417}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.3419691324234009, "test_mcc": 0.7708071376543328, "test_macro_f1": 0.8790519275549125, "test_runtime": 2.8573, "test_samples_per_second": 716.764, "test_steps_per_second": 22.399}, {"test_loss": 0.3046613931655884, "test_mcc": 0.8063779951811548, "test_macro_f1": 0.9017739475038674, "test_runtime": 2.9583, "test_samples_per_second": 692.294, "test_steps_per_second": 21.634}, {"test_loss": 0.3030266761779785, "test_mcc": 0.8039081709411763, "test_macro_f1": 0.9008907224003029, "test_runtime": 2.9369, "test_samples_per_second": 697.341, "test_steps_per_second": 21.792}, {"test_loss": 0.27171438932418823, "test_mcc": 0.7993508925272098, "test_macro_f1": 0.898000837094993, "test_runtime": 2.8758, "test_samples_per_second": 712.144, "test_steps_per_second": 22.254}, {"test_loss": 0.31969770789146423, "test_mcc": 0.7952033997980813, "test_macro_f1": 0.8939470655926353, "test_runtime": 2.9493, "test_samples_per_second": 694.391, "test_steps_per_second": 21.7}, {"test_loss": 0.3292139172554016, "test_mcc": 0.7701449621473209, "test_macro_f1": 0.8830799761990242, "test_runtime": 2.9119, "test_samples_per_second": 703.325, "test_steps_per_second": 21.979}, {"test_loss": 0.3271830677986145, "test_mcc": 0.7929041764804108, "test_macro_f1": 0.8915310129304921, "test_runtime": 2.8683, "test_samples_per_second": 714.021, "test_steps_per_second": 22.313}, {"test_loss": 0.30591967701911926, "test_mcc": 0.7686420712820706, "test_macro_f1": 0.8805146759938061, "test_runtime": 3.011, "test_samples_per_second": 680.179, "test_steps_per_second": 21.256}, {"test_loss": 0.3294796347618103, "test_mcc": 0.7659905426337915, "test_macro_f1": 0.8773056380478788, "test_runtime": 2.8898, "test_samples_per_second": 708.7, "test_steps_per_second": 22.147}, {"test_loss": 0.2969246804714203, "test_mcc": 0.7864850473994027, "test_macro_f1": 0.8887322814386663, "test_runtime": 2.9602, "test_samples_per_second": 691.844, "test_steps_per_second": 21.62}]}, "total": {"test_mcc": 78.59814396044952, "test_mcc_se": 0.9757867468523004, "test_macro_f1": 88.94828084756578, "test_macro_f1_se": 0.5684254764236989}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6045286059379578, "test_mcc": 0.356299389018584, "test_macro_f1": 0.6676917255940131, "test_runtime": 4.4052, "test_samples_per_second": 464.903, "test_steps_per_second": 14.528}, {"test_loss": 0.6122965216636658, "test_mcc": 0.3798067437042478, "test_macro_f1": 0.6754550546234905, "test_runtime": 4.6841, "test_samples_per_second": 437.227, "test_steps_per_second": 13.663}, {"test_loss": 0.6913429498672485, "test_mcc": 0.040632426405793114, "test_macro_f1": 0.4636591763184459, "test_runtime": 4.5898, "test_samples_per_second": 446.203, "test_steps_per_second": 13.944}, {"test_loss": 0.6242371797561646, "test_mcc": 0.3647430552291722, "test_macro_f1": 0.6669762590497175, "test_runtime": 4.7672, "test_samples_per_second": 429.604, "test_steps_per_second": 13.425}, {"test_loss": 0.646012544631958, "test_mcc": 0.279612211758853, "test_macro_f1": 0.6048073018428932, "test_runtime": 4.6234, "test_samples_per_second": 442.968, "test_steps_per_second": 13.843}, {"test_loss": 0.5781254768371582, "test_mcc": 0.4081777010580053, "test_macro_f1": 0.6980573543015727, "test_runtime": 4.5602, "test_samples_per_second": 449.1, "test_steps_per_second": 14.034}, {"test_loss": 0.6460044980049133, "test_mcc": 0.2618235083342694, "test_macro_f1": 0.6057085908541221, "test_runtime": 4.3952, "test_samples_per_second": 465.96, "test_steps_per_second": 14.561}, {"test_loss": 0.5943305492401123, "test_mcc": 0.4480977207284046, "test_macro_f1": 0.7154869882501687, "test_runtime": 4.5144, "test_samples_per_second": 453.661, "test_steps_per_second": 14.177}, {"test_loss": 0.6172597408294678, "test_mcc": 0.3738976886646081, "test_macro_f1": 0.6689308176100629, "test_runtime": 4.4409, "test_samples_per_second": 461.168, "test_steps_per_second": 14.411}, {"test_loss": 0.6295372247695923, "test_mcc": 0.42195085591390724, "test_macro_f1": 0.69398524556398, "test_runtime": 4.5706, "test_samples_per_second": 448.077, "test_steps_per_second": 14.002}]}, "total": {"test_mcc": 33.35041300815845, "test_mcc_se": 7.322523381542078, "test_macro_f1": 64.60758514008467, "test_macro_f1_se": 4.559934605203645}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.5733411312103271, "test_mcc": 0.40641648055662527, "test_macro_f1": 0.6915949171519231, "test_runtime": 4.0331, "test_samples_per_second": 507.797, "test_steps_per_second": 15.869}, {"test_loss": 0.5955899357795715, "test_mcc": 0.3742757969233018, "test_macro_f1": 0.6812321403089704, "test_runtime": 4.0667, "test_samples_per_second": 503.602, "test_steps_per_second": 15.738}, {"test_loss": 0.5917116403579712, "test_mcc": 0.4030005457686168, "test_macro_f1": 0.6817636271297787, "test_runtime": 4.0398, "test_samples_per_second": 506.961, "test_steps_per_second": 15.843}, {"test_loss": 0.6081455945968628, "test_mcc": 0.4545833234972709, "test_macro_f1": 0.7238581018507411, "test_runtime": 4.1149, "test_samples_per_second": 497.702, "test_steps_per_second": 15.553}, {"test_loss": 0.620057225227356, "test_mcc": 0.3237653169766048, "test_macro_f1": 0.6308848741920764, "test_runtime": 4.1752, "test_samples_per_second": 490.521, "test_steps_per_second": 15.329}, {"test_loss": 0.5987253189086914, "test_mcc": 0.35571433544931463, "test_macro_f1": 0.6565138164988995, "test_runtime": 3.9009, "test_samples_per_second": 525.0, "test_steps_per_second": 16.406}, {"test_loss": 0.6077391505241394, "test_mcc": 0.3213856287586799, "test_macro_f1": 0.6438198485869255, "test_runtime": 3.9349, "test_samples_per_second": 520.476, "test_steps_per_second": 16.265}, {"test_loss": 0.5308883190155029, "test_mcc": 0.49390261307779726, "test_macro_f1": 0.745159524165049, "test_runtime": 3.9753, "test_samples_per_second": 515.183, "test_steps_per_second": 16.099}, {"test_loss": 0.6257201433181763, "test_mcc": 0.3988432926006292, "test_macro_f1": 0.6758060740283821, "test_runtime": 3.9176, "test_samples_per_second": 522.773, "test_steps_per_second": 16.337}, {"test_loss": 0.5942760705947876, "test_mcc": 0.4170802889194044, "test_macro_f1": 0.682765449527703, "test_runtime": 4.0433, "test_samples_per_second": 506.515, "test_steps_per_second": 15.829}]}, "total": {"test_mcc": 39.48967622528245, "test_mcc_se": 3.362906602111308, "test_macro_f1": 68.1339837344045, "test_macro_f1_se": 2.1259502988905754}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6982429623603821, "test_mcc": -0.05575649422688902, "test_macro_f1": 0.4624397498680373, "test_runtime": 4.0255, "test_samples_per_second": 508.751, "test_steps_per_second": 15.898}, {"test_loss": 0.6371678113937378, "test_mcc": 0.29678617628312187, "test_macro_f1": 0.6470246734397678, "test_runtime": 4.1461, "test_samples_per_second": 493.957, "test_steps_per_second": 15.436}, {"test_loss": 0.6844277381896973, "test_mcc": 0.11260449971658555, "test_macro_f1": 0.555808263074572, "test_runtime": 4.129, "test_samples_per_second": 496.0, "test_steps_per_second": 15.5}, {"test_loss": 0.6141542196273804, "test_mcc": 0.30736480631638763, "test_macro_f1": 0.6366396761133604, "test_runtime": 3.957, "test_samples_per_second": 517.567, "test_steps_per_second": 16.174}, {"test_loss": 0.6012274026870728, "test_mcc": 0.3410819695191074, "test_macro_f1": 0.6705352198735941, "test_runtime": 4.0723, "test_samples_per_second": 502.904, "test_steps_per_second": 15.716}, {"test_loss": 0.6363339424133301, "test_mcc": 0.2778017834604523, "test_macro_f1": 0.6385198471570933, "test_runtime": 4.2711, "test_samples_per_second": 479.499, "test_steps_per_second": 14.984}, {"test_loss": 0.6516596078872681, "test_mcc": 0.2631864245049198, "test_macro_f1": 0.6259306862134473, "test_runtime": 4.0147, "test_samples_per_second": 510.12, "test_steps_per_second": 15.941}, {"test_loss": 0.6586822271347046, "test_mcc": 0.20047544507366863, "test_macro_f1": 0.5556970336868536, "test_runtime": 4.0592, "test_samples_per_second": 504.535, "test_steps_per_second": 15.767}, {"test_loss": 0.6592682600021362, "test_mcc": 0.22750049867372948, "test_macro_f1": 0.6135800943791082, "test_runtime": 4.0565, "test_samples_per_second": 504.871, "test_steps_per_second": 15.777}, {"test_loss": 0.6452854871749878, "test_mcc": 0.24639597673728583, "test_macro_f1": 0.6094802527413812, "test_runtime": 4.1211, "test_samples_per_second": 496.952, "test_steps_per_second": 15.53}]}, "total": {"test_mcc": 22.17441086058369, "test_mcc_se": 7.218517796624065, "test_macro_f1": 60.15655496547214, "test_macro_f1_se": 3.796842138023581}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_em": 34.3144848954299, "test_f1": 38.87409615398091}, {"test_em": 31.782945736434108, "test_f1": 35.54998358214933}, {"test_em": 30.91190108191654, "test_f1": 34.91386753019389}, {"test_em": 32.86604361370716, "test_f1": 37.385977913277316}, {"test_em": 42.625482625482626, "test_f1": 46.78577661107515}, {"test_em": 37.548188126445645, "test_f1": 41.96599082531968}, {"test_em": 41.00227790432802, "test_f1": 44.64655255733347}, {"test_em": 34.13498836307215, "test_f1": 38.276036778216366}, {"test_em": 36.627450980392155, "test_f1": 40.11143290112988}, {"test_em": 34.08385093167702, "test_f1": 37.225601905908825}]}, "total": {"test_em": 35.58976142588853, "test_em_se": 2.3872362411271166, "test_f1": 39.57353167585848, "test_f1_se": 2.39281934633717}}, "num_model_parameters": 124101890, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_em": 38.49728892331526, "test_f1": 43.13899399078887}, {"test_em": 37.286821705426355, "test_f1": 41.435543862968444}, {"test_em": 36.553323029366304, "test_f1": 40.31138984616293}, {"test_em": 34.65732087227414, "test_f1": 38.540977702098644}, {"test_em": 41.93050193050193, "test_f1": 46.492370955421165}, {"test_em": 40.555127216653815, "test_f1": 45.34754444135107}, {"test_em": 42.44495064540622, "test_f1": 46.66519263541766}, {"test_em": 40.65166795965865, "test_f1": 44.9511725635668}, {"test_em": 41.333333333333336, "test_f1": 45.664451546114805}, {"test_em": 41.149068322981364, "test_f1": 44.96137354810171}]}, "total": {"test_em": 39.505940393891734, "test_em_se": 1.615437514496864, "test_f1": 43.750901109199205, "test_f1_se": 1.7265121882775345}}, "num_model_parameters": 124101890, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_em": 43.99690162664601, "test_f1": 48.938325780305135}, {"test_em": 49.689922480620154, "test_f1": 54.849589853934845}, {"test_em": 43.97217928902627, "test_f1": 49.12908770658996}, {"test_em": 46.26168224299065, "test_f1": 51.38617033690711}, {"test_em": 48.49420849420849, "test_f1": 53.80830912828102}, {"test_em": 48.03392444101773, "test_f1": 51.87110722642826}, {"test_em": 49.430523917995444, "test_f1": 54.42861373116112}, {"test_em": 45.228859581070594, "test_f1": 50.26554934049031}, {"test_em": 44.23529411764706, "test_f1": 50.13503922590887}, {"test_em": 41.30434782608695, "test_f1": 46.57344683004501}]}, "total": {"test_em": 46.06478440173093, "test_em_se": 1.724241952947565, "test_f1": 51.13852391600516, "test_f1_se": 1.6503639969027362}}, "num_model_parameters": 124101890, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.7222992181777954, "test_mcc": 0.5242124909190082, "test_macro_f1": 0.5161391560762203, "test_runtime": 9.717, "test_samples_per_second": 210.764, "test_steps_per_second": 26.345}, {"test_loss": 0.6688365340232849, "test_mcc": 0.5591777523609983, "test_macro_f1": 0.5287275515427826, "test_runtime": 9.5166, "test_samples_per_second": 215.203, "test_steps_per_second": 26.9}, {"test_loss": 0.6952484846115112, "test_mcc": 0.5507895831445688, "test_macro_f1": 0.5242955052067738, "test_runtime": 9.644, "test_samples_per_second": 212.36, "test_steps_per_second": 26.545}, {"test_loss": 0.6274929642677307, "test_mcc": 0.5922711028736798, "test_macro_f1": 0.5418632532747483, "test_runtime": 9.5349, "test_samples_per_second": 214.791, "test_steps_per_second": 26.849}, {"test_loss": 0.636055588722229, "test_mcc": 0.5690972555183972, "test_macro_f1": 0.5326278659611993, "test_runtime": 9.4789, "test_samples_per_second": 216.058, "test_steps_per_second": 27.007}, {"test_loss": 0.6661450266838074, "test_mcc": 0.5786697477795558, "test_macro_f1": 0.5374382233178414, "test_runtime": 9.6565, "test_samples_per_second": 212.085, "test_steps_per_second": 26.511}, {"test_loss": 0.6522140502929688, "test_mcc": 0.5903478400478598, "test_macro_f1": 0.540827688432406, "test_runtime": 9.4014, "test_samples_per_second": 217.84, "test_steps_per_second": 27.23}, {"test_loss": 0.6194302439689636, "test_mcc": 0.6044790938596213, "test_macro_f1": 0.5522467580977785, "test_runtime": 9.8137, "test_samples_per_second": 208.688, "test_steps_per_second": 26.086}, {"test_loss": 0.6351544260978699, "test_mcc": 0.5941904470557886, "test_macro_f1": 0.5433655298757937, "test_runtime": 9.6803, "test_samples_per_second": 211.563, "test_steps_per_second": 26.445}, {"test_loss": 0.6341959238052368, "test_mcc": 0.6040199015030838, "test_macro_f1": 0.5469047332069586, "test_runtime": 9.5994, "test_samples_per_second": 213.346, "test_steps_per_second": 26.668}]}, "total": {"test_mcc": 57.67255215062561, "test_mcc_se": 1.6066801952044998, "test_macro_f1": 53.64436264992503, "test_macro_f1_se": 0.682292192624043}}, "num_model_parameters": 24486471, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.89979088306427, "test_mcc": 0.36694393835260186, "test_macro_f1": 0.5757053214800208, "test_runtime": 2.9572, "test_samples_per_second": 692.546, "test_steps_per_second": 21.642}, {"test_loss": 0.9212710857391357, "test_mcc": 0.4077905514468898, "test_macro_f1": 0.6004715440138743, "test_runtime": 2.9185, "test_samples_per_second": 701.721, "test_steps_per_second": 21.929}, {"test_loss": 0.9283897876739502, "test_mcc": 0.40446577171221154, "test_macro_f1": 0.6013578099850744, "test_runtime": 2.9342, "test_samples_per_second": 697.97, "test_steps_per_second": 21.812}, {"test_loss": 0.9138457775115967, "test_mcc": 0.3929570360226282, "test_macro_f1": 0.5863242600542892, "test_runtime": 2.9604, "test_samples_per_second": 691.791, "test_steps_per_second": 21.618}, {"test_loss": 0.9475891590118408, "test_mcc": 0.3738577908256167, "test_macro_f1": 0.5774369081637453, "test_runtime": 2.919, "test_samples_per_second": 701.604, "test_steps_per_second": 21.925}, {"test_loss": 0.9939492344856262, "test_mcc": 0.37169321228899715, "test_macro_f1": 0.5804732581772967, "test_runtime": 2.9658, "test_samples_per_second": 690.527, "test_steps_per_second": 21.579}, {"test_loss": 0.913551926612854, "test_mcc": 0.3582244419128277, "test_macro_f1": 0.5520026149761196, "test_runtime": 2.9179, "test_samples_per_second": 701.876, "test_steps_per_second": 21.934}, {"test_loss": 0.9125022292137146, "test_mcc": 0.3908130479928331, "test_macro_f1": 0.5903930627303705, "test_runtime": 2.925, "test_samples_per_second": 700.162, "test_steps_per_second": 21.88}, {"test_loss": 0.9005899429321289, "test_mcc": 0.39288272324921936, "test_macro_f1": 0.5782010260037839, "test_runtime": 2.9474, "test_samples_per_second": 694.845, "test_steps_per_second": 21.714}, {"test_loss": 1.0038955211639404, "test_mcc": 0.2249920409400799, "test_macro_f1": 0.38437266655867774, "test_runtime": 2.8948, "test_samples_per_second": 707.475, "test_steps_per_second": 22.109}]}, "total": {"test_mcc": 36.846205547439055, "test_mcc_se": 3.284210617816953, "test_macro_f1": 56.26738472143252, "test_macro_f1_se": 3.9796354933171694}}, "num_model_parameters": 24486471, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.8987012505531311, "test_mcc": 0.33985899058011565, "test_macro_f1": 0.4708322674422774, "test_runtime": 2.812, "test_samples_per_second": 728.302, "test_steps_per_second": 22.759}, {"test_loss": 0.8756693005561829, "test_mcc": 0.32325904437403147, "test_macro_f1": 0.4326292269458711, "test_runtime": 2.7227, "test_samples_per_second": 752.203, "test_steps_per_second": 23.506}, {"test_loss": 0.8899211883544922, "test_mcc": 0.32742346462713756, "test_macro_f1": 0.4307127848792276, "test_runtime": 2.7068, "test_samples_per_second": 756.603, "test_steps_per_second": 23.644}, {"test_loss": 0.9120551347732544, "test_mcc": 0.30772937664492483, "test_macro_f1": 0.4240117091426299, "test_runtime": 2.7505, "test_samples_per_second": 744.585, "test_steps_per_second": 23.268}, {"test_loss": 0.8866569995880127, "test_mcc": 0.3514399059658011, "test_macro_f1": 0.4859690908744647, "test_runtime": 2.7435, "test_samples_per_second": 746.494, "test_steps_per_second": 23.328}, {"test_loss": 0.8860082030296326, "test_mcc": 0.2884027499449457, "test_macro_f1": 0.42372947925126897, "test_runtime": 2.8173, "test_samples_per_second": 726.941, "test_steps_per_second": 22.717}, {"test_loss": 0.9096080660820007, "test_mcc": 0.32010890818296633, "test_macro_f1": 0.43647127473865344, "test_runtime": 2.7465, "test_samples_per_second": 745.677, "test_steps_per_second": 23.302}, {"test_loss": 0.8795769214630127, "test_mcc": 0.32286303437577, "test_macro_f1": 0.43148450814405054, "test_runtime": 2.7662, "test_samples_per_second": 740.37, "test_steps_per_second": 23.137}, {"test_loss": 0.9127947092056274, "test_mcc": 0.29402970754427016, "test_macro_f1": 0.4295239789963003, "test_runtime": 2.7677, "test_samples_per_second": 739.97, "test_steps_per_second": 23.124}, {"test_loss": 0.8785833120346069, "test_mcc": 0.36520478478841734, "test_macro_f1": 0.49346433036071985, "test_runtime": 2.794, "test_samples_per_second": 732.991, "test_steps_per_second": 22.906}]}, "total": {"test_mcc": 32.4031996702838, "test_mcc_se": 1.4842459840279547, "test_macro_f1": 44.58828650775463, "test_macro_f1_se": 1.6569167212785734}}, "num_model_parameters": 24486471, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.09886106848716736, "test_micro_f1": 0.4898828541001065, "test_micro_f1_no_misc": 0.5294117647058825, "test_runtime": 5.016, "test_samples_per_second": 408.295, "test_steps_per_second": 12.759}, {"test_loss": 0.09006889164447784, "test_micro_f1": 0.5404183154324477, "test_micro_f1_no_misc": 0.5815085158150851, "test_runtime": 4.9481, "test_samples_per_second": 413.894, "test_steps_per_second": 12.934}, {"test_loss": 0.08456376194953918, "test_micro_f1": 0.5501002004008015, "test_micro_f1_no_misc": 0.5927528393726338, "test_runtime": 4.9603, "test_samples_per_second": 412.882, "test_steps_per_second": 12.903}, {"test_loss": 0.09247119724750519, "test_micro_f1": 0.5219164118246689, "test_micro_f1_no_misc": 0.5778288340034463, "test_runtime": 4.769, "test_samples_per_second": 429.444, "test_steps_per_second": 13.42}, {"test_loss": 0.09626563638448715, "test_micro_f1": 0.5430861723446894, "test_micro_f1_no_misc": 0.582016348773842, "test_runtime": 5.078, "test_samples_per_second": 403.31, "test_steps_per_second": 12.603}, {"test_loss": 0.08766207098960876, "test_micro_f1": 0.5449275362318841, "test_micro_f1_no_misc": 0.5887309110057926, "test_runtime": 4.474, "test_samples_per_second": 457.753, "test_steps_per_second": 14.305}, {"test_loss": 0.09663613140583038, "test_micro_f1": 0.5495403472931563, "test_micro_f1_no_misc": 0.5905817174515235, "test_runtime": 4.5628, "test_samples_per_second": 448.848, "test_steps_per_second": 14.026}, {"test_loss": 0.07899518311023712, "test_micro_f1": 0.559953434225844, "test_micro_f1_no_misc": 0.5990037359900373, "test_runtime": 5.0425, "test_samples_per_second": 406.149, "test_steps_per_second": 12.692}, {"test_loss": 0.08941654860973358, "test_micro_f1": 0.5532994923857868, "test_micro_f1_no_misc": 0.5916258836324089, "test_runtime": 4.9051, "test_samples_per_second": 417.529, "test_steps_per_second": 13.048}, {"test_loss": 0.09528243541717529, "test_micro_f1": 0.5337972166998012, "test_micro_f1_no_misc": 0.5676532769556025, "test_runtime": 4.7855, "test_samples_per_second": 427.955, "test_steps_per_second": 13.374}]}, "total": {"test_micro_f1": 53.869219809391865, "test_micro_f1_se": 1.2502662842981345, "test_micro_f1_no_misc": 58.011138277062535, "test_micro_f1_no_misc_se": 1.234381989166895}}, "num_model_parameters": 24340941, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.06738512217998505, "test_micro_f1": 0.7705470572984184, "test_micro_f1_no_misc": 0.7892376681614349, "test_runtime": 5.4304, "test_samples_per_second": 377.136, "test_steps_per_second": 11.786}, {"test_loss": 0.06279421597719193, "test_micro_f1": 0.783068783068783, "test_micro_f1_no_misc": 0.812204867417363, "test_runtime": 4.4911, "test_samples_per_second": 456.015, "test_steps_per_second": 14.25}, {"test_loss": 0.064922995865345, "test_micro_f1": 0.7872111767866737, "test_micro_f1_no_misc": 0.8164146868250539, "test_runtime": 5.4016, "test_samples_per_second": 379.146, "test_steps_per_second": 11.848}, {"test_loss": 0.0644427016377449, "test_micro_f1": 0.7663503462426263, "test_micro_f1_no_misc": 0.7888391319324836, "test_runtime": 5.2932, "test_samples_per_second": 386.912, "test_steps_per_second": 12.091}, {"test_loss": 0.07028911262750626, "test_micro_f1": 0.7338008415147264, "test_micro_f1_no_misc": 0.7662141779788838, "test_runtime": 5.3513, "test_samples_per_second": 382.713, "test_steps_per_second": 11.96}, {"test_loss": 0.06889564543962479, "test_micro_f1": 0.79041248606466, "test_micro_f1_no_misc": 0.8113905325443787, "test_runtime": 5.3385, "test_samples_per_second": 383.63, "test_steps_per_second": 11.988}, {"test_loss": 0.07067123055458069, "test_micro_f1": 0.7357293868921776, "test_micro_f1_no_misc": 0.7610307094952349, "test_runtime": 5.4478, "test_samples_per_second": 375.93, "test_steps_per_second": 11.748}, {"test_loss": 0.06130499392747879, "test_micro_f1": 0.7774415405777166, "test_micro_f1_no_misc": 0.8082638637187387, "test_runtime": 5.3775, "test_samples_per_second": 380.844, "test_steps_per_second": 11.901}, {"test_loss": 0.06670860946178436, "test_micro_f1": 0.7391774891774892, "test_micro_f1_no_misc": 0.7535055350553506, "test_runtime": 5.2733, "test_samples_per_second": 388.369, "test_steps_per_second": 12.137}, {"test_loss": 0.06386905908584595, "test_micro_f1": 0.7735191637630662, "test_micro_f1_no_misc": 0.8121212121212122, "test_runtime": 4.7333, "test_samples_per_second": 432.682, "test_steps_per_second": 13.521}]}, "total": {"test_micro_f1": 76.57258271386338, "test_micro_f1_se": 1.3416837813415738, "test_micro_f1_no_misc": 79.19222385250134, "test_micro_f1_no_misc_se": 1.4859668889872446}}, "num_model_parameters": 24340941, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.055403079837560654, "test_micro_f1": 0.7404718693284936, "test_micro_f1_no_misc": 0.7711829717560378, "test_runtime": 4.5686, "test_samples_per_second": 448.273, "test_steps_per_second": 14.009}, {"test_loss": 0.05169715732336044, "test_micro_f1": 0.7639956092206368, "test_micro_f1_no_misc": 0.7964022894521668, "test_runtime": 4.5887, "test_samples_per_second": 446.316, "test_steps_per_second": 13.947}, {"test_loss": 0.05565682798624039, "test_micro_f1": 0.7514084507042255, "test_micro_f1_no_misc": 0.7859649122807018, "test_runtime": 4.5179, "test_samples_per_second": 453.309, "test_steps_per_second": 14.166}, {"test_loss": 0.049680598080158234, "test_micro_f1": 0.7755102040816326, "test_micro_f1_no_misc": 0.8065650644783118, "test_runtime": 4.3977, "test_samples_per_second": 465.7, "test_steps_per_second": 14.553}, {"test_loss": 0.05507457256317139, "test_micro_f1": 0.7634770889487872, "test_micro_f1_no_misc": 0.8069908814589666, "test_runtime": 4.694, "test_samples_per_second": 436.301, "test_steps_per_second": 13.634}, {"test_loss": 0.0520426481962204, "test_micro_f1": 0.7621621621621621, "test_micro_f1_no_misc": 0.7989614243323443, "test_runtime": 4.5919, "test_samples_per_second": 446.008, "test_steps_per_second": 13.938}, {"test_loss": 0.05427539348602295, "test_micro_f1": 0.7577937649880095, "test_micro_f1_no_misc": 0.7925247902364607, "test_runtime": 4.4106, "test_samples_per_second": 464.334, "test_steps_per_second": 14.51}, {"test_loss": 0.059080660343170166, "test_micro_f1": 0.773407587887226, "test_micro_f1_no_misc": 0.7998514667656887, "test_runtime": 4.4592, "test_samples_per_second": 459.271, "test_steps_per_second": 14.352}, {"test_loss": 0.05184298753738403, "test_micro_f1": 0.7490909090909091, "test_micro_f1_no_misc": 0.7863247863247863, "test_runtime": 4.4473, "test_samples_per_second": 460.501, "test_steps_per_second": 14.391}, {"test_loss": 0.05849357694387436, "test_micro_f1": 0.7713310580204777, "test_micro_f1_no_misc": 0.8055660022564874, "test_runtime": 4.5343, "test_samples_per_second": 451.666, "test_steps_per_second": 14.115}]}, "total": {"test_micro_f1": 76.08648704432561, "test_micro_f1_se": 0.7015385642231949, "test_micro_f1_no_misc": 79.50334589341952, "test_micro_f1_no_misc_se": 0.7038516286454286}}, "num_model_parameters": 24340941, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.07265177369117737, "test_micro_f1": 0.6562595653504745, "test_micro_f1_no_misc": 0.6977049180327869, "test_runtime": 4.8435, "test_samples_per_second": 422.831, "test_steps_per_second": 13.213}, {"test_loss": 0.07737250626087189, "test_micro_f1": 0.7141126589945488, "test_micro_f1_no_misc": 0.7511768661735038, "test_runtime": 4.8312, "test_samples_per_second": 423.91, "test_steps_per_second": 13.247}, {"test_loss": 0.06951943039894104, "test_micro_f1": 0.7117718446601943, "test_micro_f1_no_misc": 0.7495798319327731, "test_runtime": 4.6845, "test_samples_per_second": 437.183, "test_steps_per_second": 13.662}, {"test_loss": 0.08045883476734161, "test_micro_f1": 0.6760226933412959, "test_micro_f1_no_misc": 0.7184339314845024, "test_runtime": 4.7329, "test_samples_per_second": 432.711, "test_steps_per_second": 13.522}, {"test_loss": 0.08307584375143051, "test_micro_f1": 0.6686585001493875, "test_micro_f1_no_misc": 0.7141905396402398, "test_runtime": 4.6018, "test_samples_per_second": 445.039, "test_steps_per_second": 13.907}, {"test_loss": 0.07573135942220688, "test_micro_f1": 0.6688505062537224, "test_micro_f1_no_misc": 0.7166560306317804, "test_runtime": 4.6226, "test_samples_per_second": 443.039, "test_steps_per_second": 13.845}, {"test_loss": 0.06906117498874664, "test_micro_f1": 0.698501872659176, "test_micro_f1_no_misc": 0.7480287967089476, "test_runtime": 4.8792, "test_samples_per_second": 419.741, "test_steps_per_second": 13.117}, {"test_loss": 0.06852643191814423, "test_micro_f1": 0.6962645437844458, "test_micro_f1_no_misc": 0.7393458870168484, "test_runtime": 4.9136, "test_samples_per_second": 416.807, "test_steps_per_second": 13.025}, {"test_loss": 0.07590587437152863, "test_micro_f1": 0.673677698731828, "test_micro_f1_no_misc": 0.7115384615384616, "test_runtime": 4.5389, "test_samples_per_second": 451.211, "test_steps_per_second": 14.1}, {"test_loss": 0.07242798805236816, "test_micro_f1": 0.7198275862068965, "test_micro_f1_no_misc": 0.7559583752937228, "test_runtime": 4.7037, "test_samples_per_second": 435.401, "test_steps_per_second": 13.606}]}, "total": {"test_micro_f1": 68.8394747013197, "test_micro_f1_se": 1.3911301142988366, "test_micro_f1_no_misc": 73.02613638453566, "test_micro_f1_no_misc_se": 1.284085398397402}}, "num_model_parameters": 24340941, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6627457737922668, "test_mcc": 0.20942660319967327, "test_macro_f1": 0.5949986864478952, "test_runtime": 2.7679, "test_samples_per_second": 739.923, "test_steps_per_second": 23.123}, {"test_loss": 0.6705306768417358, "test_mcc": 0.17426845858479748, "test_macro_f1": 0.5726767039687346, "test_runtime": 2.7181, "test_samples_per_second": 753.476, "test_steps_per_second": 23.546}, {"test_loss": 0.6769312024116516, "test_mcc": 0.15681754274288442, "test_macro_f1": 0.5766609749719261, "test_runtime": 2.7213, "test_samples_per_second": 752.581, "test_steps_per_second": 23.518}, {"test_loss": 0.6927201747894287, "test_mcc": 0.000947375868909691, "test_macro_f1": 0.4930415448142915, "test_runtime": 2.6954, "test_samples_per_second": 759.812, "test_steps_per_second": 23.744}, {"test_loss": 0.6921499967575073, "test_mcc": 0.03747011736479831, "test_macro_f1": 0.4745207733443028, "test_runtime": 2.699, "test_samples_per_second": 758.787, "test_steps_per_second": 23.712}, {"test_loss": 0.6854451298713684, "test_mcc": 0.09146089818154358, "test_macro_f1": 0.5446979434984429, "test_runtime": 2.6899, "test_samples_per_second": 761.365, "test_steps_per_second": 23.793}, {"test_loss": 0.6628360152244568, "test_mcc": 0.19003153000694045, "test_macro_f1": 0.5942792766989364, "test_runtime": 2.6805, "test_samples_per_second": 764.031, "test_steps_per_second": 23.876}, {"test_loss": 0.6778742671012878, "test_mcc": 0.14482639072711928, "test_macro_f1": 0.5722554267746633, "test_runtime": 2.8053, "test_samples_per_second": 730.049, "test_steps_per_second": 22.814}, {"test_loss": 0.6712276935577393, "test_mcc": 0.19442491833674622, "test_macro_f1": 0.5833786758037871, "test_runtime": 2.7176, "test_samples_per_second": 753.617, "test_steps_per_second": 23.551}, {"test_loss": 0.6791081428527832, "test_mcc": 0.13989427355222267, "test_macro_f1": 0.53085371107113, "test_runtime": 2.6866, "test_samples_per_second": 762.297, "test_steps_per_second": 23.822}]}, "total": {"test_mcc": 13.395681085656353, "test_mcc_se": 4.314206581112906, "test_macro_f1": 55.37363717394109, "test_macro_f1_se": 2.614679127429192}}, "num_model_parameters": 24486086, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.4489287734031677, "test_mcc": 0.6129090632023007, "test_macro_f1": 0.8045595407309931, "test_runtime": 2.6433, "test_samples_per_second": 774.795, "test_steps_per_second": 24.212}, {"test_loss": 0.4381493031978607, "test_mcc": 0.6362929556926895, "test_macro_f1": 0.8134363740826789, "test_runtime": 2.6463, "test_samples_per_second": 773.907, "test_steps_per_second": 24.185}, {"test_loss": 0.4266570210456848, "test_mcc": 0.6484939532911739, "test_macro_f1": 0.82183515252885, "test_runtime": 2.6992, "test_samples_per_second": 758.732, "test_steps_per_second": 23.71}, {"test_loss": 0.42979076504707336, "test_mcc": 0.6390623575502358, "test_macro_f1": 0.8146558729139075, "test_runtime": 2.688, "test_samples_per_second": 761.918, "test_steps_per_second": 23.81}, {"test_loss": 0.42685389518737793, "test_mcc": 0.6383815024228273, "test_macro_f1": 0.8164119581792177, "test_runtime": 2.68, "test_samples_per_second": 764.188, "test_steps_per_second": 23.881}, {"test_loss": 0.41998445987701416, "test_mcc": 0.6702978341117914, "test_macro_f1": 0.8328533390774681, "test_runtime": 2.7795, "test_samples_per_second": 736.822, "test_steps_per_second": 23.026}, {"test_loss": 0.5192731022834778, "test_mcc": 0.6027278263051747, "test_macro_f1": 0.797867512581542, "test_runtime": 2.7448, "test_samples_per_second": 746.139, "test_steps_per_second": 23.317}, {"test_loss": 0.44148290157318115, "test_mcc": 0.6476590236934643, "test_macro_f1": 0.8235301559143802, "test_runtime": 2.8368, "test_samples_per_second": 721.942, "test_steps_per_second": 22.561}, {"test_loss": 0.4730839729309082, "test_mcc": 0.6376980784259293, "test_macro_f1": 0.8092369405038837, "test_runtime": 2.799, "test_samples_per_second": 731.678, "test_steps_per_second": 22.865}, {"test_loss": 0.4883044958114624, "test_mcc": 0.6212580146026839, "test_macro_f1": 0.8061839714125191, "test_runtime": 2.6614, "test_samples_per_second": 769.533, "test_steps_per_second": 24.048}]}, "total": {"test_mcc": 63.547806092982704, "test_mcc_se": 1.194228792070272, "test_macro_f1": 81.4057081792544, "test_macro_f1_se": 0.6359021722592169}}, "num_model_parameters": 24486086, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.5830731391906738, "test_mcc": 0.41267891487092656, "test_macro_f1": 0.704672202047395, "test_runtime": 2.8279, "test_samples_per_second": 724.202, "test_steps_per_second": 22.631}, {"test_loss": 0.5708813667297363, "test_mcc": 0.4296077444821799, "test_macro_f1": 0.7012204548671217, "test_runtime": 2.6936, "test_samples_per_second": 760.324, "test_steps_per_second": 23.76}, {"test_loss": 0.6055171489715576, "test_mcc": 0.3515968146137567, "test_macro_f1": 0.6742821594315314, "test_runtime": 2.6883, "test_samples_per_second": 761.808, "test_steps_per_second": 23.806}, {"test_loss": 0.5726261734962463, "test_mcc": 0.4420150015316384, "test_macro_f1": 0.7182552008436391, "test_runtime": 2.6967, "test_samples_per_second": 759.45, "test_steps_per_second": 23.733}, {"test_loss": 0.5677392482757568, "test_mcc": 0.412047022259149, "test_macro_f1": 0.7033762071348767, "test_runtime": 2.7192, "test_samples_per_second": 753.161, "test_steps_per_second": 23.536}, {"test_loss": 0.5497928857803345, "test_mcc": 0.44430753544855783, "test_macro_f1": 0.7220088346509926, "test_runtime": 2.7358, "test_samples_per_second": 748.594, "test_steps_per_second": 23.394}, {"test_loss": 0.5690586566925049, "test_mcc": 0.4197656687728814, "test_macro_f1": 0.7084383088869715, "test_runtime": 2.6573, "test_samples_per_second": 770.71, "test_steps_per_second": 24.085}, {"test_loss": 0.5645139217376709, "test_mcc": 0.44721212965001145, "test_macro_f1": 0.7152958145631896, "test_runtime": 2.6551, "test_samples_per_second": 771.355, "test_steps_per_second": 24.105}, {"test_loss": 0.5836761593818665, "test_mcc": 0.432144335119698, "test_macro_f1": 0.7082956190126124, "test_runtime": 2.7457, "test_samples_per_second": 745.894, "test_steps_per_second": 23.309}, {"test_loss": 0.596195638179779, "test_mcc": 0.3731258462763414, "test_macro_f1": 0.678913860366578, "test_runtime": 2.8931, "test_samples_per_second": 707.895, "test_steps_per_second": 22.122}]}, "total": {"test_mcc": 41.6450101302514, "test_mcc_se": 1.9515841493082335, "test_macro_f1": 70.34758661804908, "test_macro_f1_se": 0.9715924185131734}}, "num_model_parameters": 24486086, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6422231793403625, "test_mcc": 0.27504737132330404, "test_macro_f1": 0.6294166730361002, "test_runtime": 2.869, "test_samples_per_second": 713.845, "test_steps_per_second": 22.308}, {"test_loss": 0.6450122594833374, "test_mcc": 0.2556490077834685, "test_macro_f1": 0.6276896650443744, "test_runtime": 3.0284, "test_samples_per_second": 676.268, "test_steps_per_second": 21.133}, {"test_loss": 0.6411113739013672, "test_mcc": 0.2719614511874994, "test_macro_f1": 0.6311263997264187, "test_runtime": 3.1325, "test_samples_per_second": 653.797, "test_steps_per_second": 20.431}, {"test_loss": 0.6576670408248901, "test_mcc": 0.20740573230152629, "test_macro_f1": 0.5953794766892178, "test_runtime": 3.2587, "test_samples_per_second": 628.475, "test_steps_per_second": 19.64}, {"test_loss": 0.6353769898414612, "test_mcc": 0.3182120444715897, "test_macro_f1": 0.6575516213361392, "test_runtime": 2.9703, "test_samples_per_second": 689.491, "test_steps_per_second": 21.547}, {"test_loss": 0.6445820331573486, "test_mcc": 0.26311636551333867, "test_macro_f1": 0.621840288786993, "test_runtime": 3.0816, "test_samples_per_second": 664.592, "test_steps_per_second": 20.768}, {"test_loss": 0.6809624433517456, "test_mcc": 0.20415906794136984, "test_macro_f1": 0.5961042283463149, "test_runtime": 2.9048, "test_samples_per_second": 705.049, "test_steps_per_second": 22.033}, {"test_loss": 0.6390661001205444, "test_mcc": 0.29604798955016387, "test_macro_f1": 0.6304969961334003, "test_runtime": 2.8833, "test_samples_per_second": 710.299, "test_steps_per_second": 22.197}, {"test_loss": 0.6566861867904663, "test_mcc": 0.23351135387826255, "test_macro_f1": 0.6125050940210747, "test_runtime": 2.8737, "test_samples_per_second": 712.68, "test_steps_per_second": 22.271}, {"test_loss": 0.6461095809936523, "test_mcc": 0.22780167170970753, "test_macro_f1": 0.6022878415365618, "test_runtime": 2.9567, "test_samples_per_second": 692.654, "test_steps_per_second": 21.645}]}, "total": {"test_mcc": 25.5291205566023, "test_mcc_se": 2.3087049386178333, "test_macro_f1": 62.04398284656596, "test_macro_f1_se": 1.194088355524631}}, "num_model_parameters": 24486086, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_em": 36.018590240123935, "test_f1": 40.4734527881799}, {"test_em": 35.1937984496124, "test_f1": 39.360367038342424}, {"test_em": 39.258114374034, "test_f1": 43.02237053134863}, {"test_em": 32.47663551401869, "test_f1": 36.81337798173972}, {"test_em": 37.52895752895753, "test_f1": 41.31378241064221}, {"test_em": 28.450269853508097, "test_f1": 32.907834684637926}, {"test_em": 33.333333333333336, "test_f1": 38.231713036912204}, {"test_em": 35.68657874321179, "test_f1": 39.995227636011656}, {"test_em": 33.1764705882353, "test_f1": 37.68366672348319}, {"test_em": 32.453416149068325, "test_f1": 36.76683124802947}]}, "total": {"test_em": 34.35761647741034, "test_em_se": 1.891301630896121, "test_f1": 38.656862407932735, "test_f1_se": 1.7634295736725654}}, "num_model_parameters": 24338246, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_em": 30.364058869093725, "test_f1": 36.473534329916625}, {"test_em": 30.07751937984496, "test_f1": 34.44466284806196}, {"test_em": 32.45749613601237, "test_f1": 37.40713170197192}, {"test_em": 27.80373831775701, "test_f1": 32.24148521544164}, {"test_em": 37.915057915057915, "test_f1": 41.891033865823786}, {"test_em": 28.604471858134154, "test_f1": 33.04594899157013}, {"test_em": 33.10554290053151, "test_f1": 37.08627677040269}, {"test_em": 32.893716058960436, "test_f1": 37.16684249840128}, {"test_em": 29.333333333333332, "test_f1": 35.20124387574763}, {"test_em": 30.20186335403727, "test_f1": 35.17940789663435}]}, "total": {"test_em": 31.275679812276262, "test_em_se": 1.8226317893926167, "test_f1": 36.0137567993972, "test_f1_se": 1.6788438027713026}}, "num_model_parameters": 24338246, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_em": 28.272656855151045, "test_f1": 33.822121230602924}, {"test_em": 33.41085271317829, "test_f1": 38.334256941662076}, {"test_em": 31.60741885625966, "test_f1": 36.4916548307084}, {"test_em": 34.96884735202492, "test_f1": 38.81608650654686}, {"test_em": 37.2972972972973, "test_f1": 41.87937824249191}, {"test_em": 32.53662297609869, "test_f1": 37.12415232608401}, {"test_em": 33.333333333333336, "test_f1": 38.20490196194548}, {"test_em": 32.27307990690458, "test_f1": 35.71844328825886}, {"test_em": 33.01960784313726, "test_f1": 38.102984434005975}, {"test_em": 29.580745341614907, "test_f1": 35.15700561521117}]}, "total": {"test_em": 32.6300462475, "test_em_se": 1.5731128536136452, "test_f1": 37.36509853775176, "test_f1_se": 1.3956566517368205}}, "num_model_parameters": 24338246, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.7647472023963928, "test_mcc": 0.5842863523598187, "test_macro_f1": 0.5384178634195956, "test_runtime": 1.8853, "test_samples_per_second": 1086.28, "test_steps_per_second": 33.946}, {"test_loss": 0.7987620234489441, "test_mcc": 0.5304727566863584, "test_macro_f1": 0.5182298315232241, "test_runtime": 1.797, "test_samples_per_second": 1139.658, "test_steps_per_second": 35.614}, {"test_loss": 0.7559666633605957, "test_mcc": 0.5651853659180678, "test_macro_f1": 0.5320733966574801, "test_runtime": 1.8481, "test_samples_per_second": 1108.195, "test_steps_per_second": 34.631}, {"test_loss": 0.7361704111099243, "test_mcc": 0.5839890511392919, "test_macro_f1": 0.5390006039350989, "test_runtime": 1.8059, "test_samples_per_second": 1134.04, "test_steps_per_second": 35.439}, {"test_loss": 0.7531930208206177, "test_mcc": 0.5712200755586834, "test_macro_f1": 0.5341823683617254, "test_runtime": 1.7822, "test_samples_per_second": 1149.166, "test_steps_per_second": 35.911}, {"test_loss": 0.7921978235244751, "test_mcc": 0.5597126890034531, "test_macro_f1": 0.5299927419595544, "test_runtime": 1.8391, "test_samples_per_second": 1113.608, "test_steps_per_second": 34.8}, {"test_loss": 0.8238322138786316, "test_mcc": 0.5497948751294611, "test_macro_f1": 0.5255916472250215, "test_runtime": 1.7674, "test_samples_per_second": 1158.737, "test_steps_per_second": 36.211}, {"test_loss": 0.8122212886810303, "test_mcc": 0.5801857410707424, "test_macro_f1": 0.5369135732563249, "test_runtime": 1.87, "test_samples_per_second": 1095.187, "test_steps_per_second": 34.225}, {"test_loss": 0.7963465452194214, "test_mcc": 0.5629900588852478, "test_macro_f1": 0.5310085152161625, "test_runtime": 1.8367, "test_samples_per_second": 1115.033, "test_steps_per_second": 34.845}, {"test_loss": 0.828104555606842, "test_mcc": 0.5497083811265757, "test_macro_f1": 0.5258242311615171, "test_runtime": 1.842, "test_samples_per_second": 1111.834, "test_steps_per_second": 34.745}]}, "total": {"test_mcc": 56.375453468777, "test_mcc_se": 1.0686587385407156, "test_macro_f1": 53.11234772715704, "test_macro_f1_se": 0.4055208996842784}}, "num_model_parameters": 4389827, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 1.0374596118927002, "test_mcc": 0.19816027322867877, "test_macro_f1": 0.37289510904107664, "test_runtime": 0.9551, "test_samples_per_second": 2144.291, "test_steps_per_second": 67.009}, {"test_loss": 1.0253654718399048, "test_mcc": 0.24510136450855413, "test_macro_f1": 0.43858051487337524, "test_runtime": 0.9522, "test_samples_per_second": 2150.791, "test_steps_per_second": 67.212}, {"test_loss": 1.0522739887237549, "test_mcc": 0.22736806309439914, "test_macro_f1": 0.47373925960897645, "test_runtime": 0.9611, "test_samples_per_second": 2130.847, "test_steps_per_second": 66.589}, {"test_loss": 1.0459208488464355, "test_mcc": 0.17894238210887276, "test_macro_f1": 0.43230554737848087, "test_runtime": 0.9608, "test_samples_per_second": 2131.566, "test_steps_per_second": 66.611}, {"test_loss": 1.0317797660827637, "test_mcc": 0.21393502938058223, "test_macro_f1": 0.3785596107983144, "test_runtime": 0.9406, "test_samples_per_second": 2177.442, "test_steps_per_second": 68.045}, {"test_loss": 1.042222499847412, "test_mcc": 0.19960987849195339, "test_macro_f1": 0.381406782330334, "test_runtime": 0.9644, "test_samples_per_second": 2123.507, "test_steps_per_second": 66.36}, {"test_loss": 0.9951415657997131, "test_mcc": 0.29645096554234807, "test_macro_f1": 0.5154477538346595, "test_runtime": 0.9653, "test_samples_per_second": 2121.611, "test_steps_per_second": 66.3}, {"test_loss": 1.0089423656463623, "test_mcc": 0.22807018151929445, "test_macro_f1": 0.3884171199473064, "test_runtime": 0.9494, "test_samples_per_second": 2157.142, "test_steps_per_second": 67.411}, {"test_loss": 1.0098071098327637, "test_mcc": 0.23170347172339795, "test_macro_f1": 0.38642089947498404, "test_runtime": 0.9541, "test_samples_per_second": 2146.574, "test_steps_per_second": 67.08}, {"test_loss": 1.0423376560211182, "test_mcc": 0.20001285413398406, "test_macro_f1": 0.38970234669757375, "test_runtime": 0.9497, "test_samples_per_second": 2156.375, "test_steps_per_second": 67.387}]}, "total": {"test_mcc": 22.193544637320652, "test_mcc_se": 2.0356848812201513, "test_macro_f1": 41.57474943985082, "test_macro_f1_se": 2.9784119475049686}}, "num_model_parameters": 4389827, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.9986686706542969, "test_mcc": 0.2453687392135309, "test_macro_f1": 0.39795276840217886, "test_runtime": 0.9044, "test_samples_per_second": 2264.546, "test_steps_per_second": 70.767}, {"test_loss": 1.0037834644317627, "test_mcc": 0.18082760017411945, "test_macro_f1": 0.4064291422503233, "test_runtime": 0.8972, "test_samples_per_second": 2282.768, "test_steps_per_second": 71.337}, {"test_loss": 1.0001716613769531, "test_mcc": 0.24956321680292368, "test_macro_f1": 0.4024897846496887, "test_runtime": 0.8925, "test_samples_per_second": 2294.575, "test_steps_per_second": 71.705}, {"test_loss": 1.0143829584121704, "test_mcc": 0.2348120465141326, "test_macro_f1": 0.3961964222039199, "test_runtime": 0.89, "test_samples_per_second": 2301.242, "test_steps_per_second": 71.914}, {"test_loss": 1.011164665222168, "test_mcc": 0.195362487636662, "test_macro_f1": 0.41139240090545814, "test_runtime": 0.8921, "test_samples_per_second": 2295.602, "test_steps_per_second": 71.738}, {"test_loss": 1.0147501230239868, "test_mcc": 0.2114220236516319, "test_macro_f1": 0.38506154607187665, "test_runtime": 0.9059, "test_samples_per_second": 2260.811, "test_steps_per_second": 70.65}, {"test_loss": 1.0077106952667236, "test_mcc": 0.14154528903304528, "test_macro_f1": 0.3409236788639416, "test_runtime": 0.8962, "test_samples_per_second": 2285.097, "test_steps_per_second": 71.409}, {"test_loss": 0.983777642250061, "test_mcc": 0.26451785402848477, "test_macro_f1": 0.409144624156522, "test_runtime": 0.9019, "test_samples_per_second": 2270.87, "test_steps_per_second": 70.965}, {"test_loss": 0.9836522340774536, "test_mcc": 0.20529714180470546, "test_macro_f1": 0.3940277765561644, "test_runtime": 0.9038, "test_samples_per_second": 2266.034, "test_steps_per_second": 70.814}, {"test_loss": 1.0124727487564087, "test_mcc": 0.16409137197256318, "test_macro_f1": 0.36892026126764105, "test_runtime": 0.9072, "test_samples_per_second": 2257.453, "test_steps_per_second": 70.545}]}, "total": {"test_mcc": 20.92807770831799, "test_mcc_se": 2.4690409191868854, "test_macro_f1": 39.125384053277145, "test_macro_f1_se": 1.3436187008734641}}, "num_model_parameters": 4389827, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.1671697348356247, "test_micro_f1": 0.29598749348619074, "test_micro_f1_no_misc": 0.31431767337807603, "test_runtime": 2.4152, "test_samples_per_second": 847.966, "test_steps_per_second": 26.499}, {"test_loss": 0.15778909623622894, "test_micro_f1": 0.2625698324022346, "test_micro_f1_no_misc": 0.2855384615384616, "test_runtime": 2.3629, "test_samples_per_second": 866.731, "test_steps_per_second": 27.085}, {"test_loss": 0.15459172427654266, "test_micro_f1": 0.2684630738522954, "test_micro_f1_no_misc": 0.2833698030634573, "test_runtime": 2.3405, "test_samples_per_second": 875.034, "test_steps_per_second": 27.345}, {"test_loss": 0.1646130532026291, "test_micro_f1": 0.25483391175012393, "test_micro_f1_no_misc": 0.2673213311511184, "test_runtime": 2.3278, "test_samples_per_second": 879.814, "test_steps_per_second": 27.494}, {"test_loss": 0.18583014607429504, "test_micro_f1": 0.2647201946472019, "test_micro_f1_no_misc": 0.27969151670951153, "test_runtime": 2.3894, "test_samples_per_second": 857.108, "test_steps_per_second": 26.785}, {"test_loss": 0.17740947008132935, "test_micro_f1": 0.27366356056890634, "test_micro_f1_no_misc": 0.2908514013749339, "test_runtime": 2.1894, "test_samples_per_second": 935.405, "test_steps_per_second": 29.231}, {"test_loss": 0.187275692820549, "test_micro_f1": 0.22930542340627974, "test_micro_f1_no_misc": 0.24190283400809717, "test_runtime": 2.212, "test_samples_per_second": 925.871, "test_steps_per_second": 28.933}, {"test_loss": 0.16265708208084106, "test_micro_f1": 0.2714285714285714, "test_micro_f1_no_misc": 0.2896305125148987, "test_runtime": 2.4267, "test_samples_per_second": 843.953, "test_steps_per_second": 26.374}, {"test_loss": 0.17053493857383728, "test_micro_f1": 0.2784415584415584, "test_micro_f1_no_misc": 0.29695290858725765, "test_runtime": 2.3575, "test_samples_per_second": 868.734, "test_steps_per_second": 27.148}, {"test_loss": 0.16901946067810059, "test_micro_f1": 0.3070787637088734, "test_micro_f1_no_misc": 0.33151581243184297, "test_runtime": 2.3094, "test_samples_per_second": 886.808, "test_steps_per_second": 27.713}]}, "total": {"test_micro_f1": 27.06492383692235, "test_micro_f1_se": 1.3235760188763974, "test_micro_f1_no_misc": 28.81092254757655, "test_micro_f1_no_misc_se": 1.5077929864768063}}, "num_model_parameters": 4386057, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.21291010081768036, "test_micro_f1": 0.44870240116420085, "test_micro_f1_no_misc": 0.44409937888198764, "test_runtime": 2.5396, "test_samples_per_second": 806.422, "test_steps_per_second": 25.201}, {"test_loss": 0.18584921956062317, "test_micro_f1": 0.40773195876288665, "test_micro_f1_no_misc": 0.39564787339268054, "test_runtime": 2.2248, "test_samples_per_second": 920.524, "test_steps_per_second": 28.766}, {"test_loss": 0.20171809196472168, "test_micro_f1": 0.4527277215502345, "test_micro_f1_no_misc": 0.46625766871165647, "test_runtime": 2.5683, "test_samples_per_second": 797.402, "test_steps_per_second": 24.919}, {"test_loss": 0.192531555891037, "test_micro_f1": 0.4535679374389052, "test_micro_f1_no_misc": 0.458679057417856, "test_runtime": 2.5559, "test_samples_per_second": 801.279, "test_steps_per_second": 25.04}, {"test_loss": 0.20642587542533875, "test_micro_f1": 0.39609053497942387, "test_micro_f1_no_misc": 0.3877966101694916, "test_runtime": 2.5505, "test_samples_per_second": 802.984, "test_steps_per_second": 25.093}, {"test_loss": 0.20784427225589752, "test_micro_f1": 0.4481372286250335, "test_micro_f1_no_misc": 0.44299674267100975, "test_runtime": 2.5895, "test_samples_per_second": 790.873, "test_steps_per_second": 24.715}, {"test_loss": 0.2110995054244995, "test_micro_f1": 0.3826309067688378, "test_micro_f1_no_misc": 0.3748653500897666, "test_runtime": 2.5711, "test_samples_per_second": 796.534, "test_steps_per_second": 24.892}, {"test_loss": 0.20304515957832336, "test_micro_f1": 0.3987761346251912, "test_micro_f1_no_misc": 0.4022229940951719, "test_runtime": 2.5291, "test_samples_per_second": 809.789, "test_steps_per_second": 25.306}, {"test_loss": 0.19905194640159607, "test_micro_f1": 0.4504326328800989, "test_micro_f1_no_misc": 0.44042132982225146, "test_runtime": 2.5337, "test_samples_per_second": 808.3, "test_steps_per_second": 25.259}, {"test_loss": 0.20614399015903473, "test_micro_f1": 0.4389371486969852, "test_micro_f1_no_misc": 0.43982270712580973, "test_runtime": 2.3312, "test_samples_per_second": 878.521, "test_steps_per_second": 27.454}]}, "total": {"test_micro_f1": 42.77734605491798, "test_micro_f1_se": 1.7363191555475634, "test_micro_f1_no_misc": 42.52809712377682, "test_micro_f1_no_misc_se": 1.988087905596953}}, "num_model_parameters": 4386057, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.1608561873435974, "test_micro_f1": 0.4328156650911546, "test_micro_f1_no_misc": 0.457492795389049, "test_runtime": 2.3451, "test_samples_per_second": 873.32, "test_steps_per_second": 27.291}, {"test_loss": 0.1736970692873001, "test_micro_f1": 0.3613559322033898, "test_micro_f1_no_misc": 0.37905236907730677, "test_runtime": 2.1779, "test_samples_per_second": 940.372, "test_steps_per_second": 29.387}, {"test_loss": 0.18002259731292725, "test_micro_f1": 0.3921694480102696, "test_micro_f1_no_misc": 0.4141448486909215, "test_runtime": 2.2861, "test_samples_per_second": 895.867, "test_steps_per_second": 27.996}, {"test_loss": 0.17657828330993652, "test_micro_f1": 0.37927663734115347, "test_micro_f1_no_misc": 0.4019437695244707, "test_runtime": 2.236, "test_samples_per_second": 915.939, "test_steps_per_second": 28.623}, {"test_loss": 0.1663295179605484, "test_micro_f1": 0.4020681265206812, "test_micro_f1_no_misc": 0.42833929151771205, "test_runtime": 2.1903, "test_samples_per_second": 935.038, "test_steps_per_second": 29.22}, {"test_loss": 0.17987708747386932, "test_micro_f1": 0.36293683873036225, "test_micro_f1_no_misc": 0.3832539142273656, "test_runtime": 2.2304, "test_samples_per_second": 918.202, "test_steps_per_second": 28.694}, {"test_loss": 0.1687910109758377, "test_micro_f1": 0.34606741573033706, "test_micro_f1_no_misc": 0.37071100106119564, "test_runtime": 2.1832, "test_samples_per_second": 938.052, "test_steps_per_second": 29.314}, {"test_loss": 0.17158569395542145, "test_micro_f1": 0.3915079612862941, "test_micro_f1_no_misc": 0.4060880829015544, "test_runtime": 2.1921, "test_samples_per_second": 934.244, "test_steps_per_second": 29.195}, {"test_loss": 0.17953987419605255, "test_micro_f1": 0.40760507004669777, "test_micro_f1_no_misc": 0.4305408271474019, "test_runtime": 2.146, "test_samples_per_second": 954.315, "test_steps_per_second": 29.822}, {"test_loss": 0.17754028737545013, "test_micro_f1": 0.3885390428211587, "test_micro_f1_no_misc": 0.41307277628032346, "test_runtime": 2.2847, "test_samples_per_second": 896.392, "test_steps_per_second": 28.012}]}, "total": {"test_micro_f1": 38.64342137781499, "test_micro_f1_se": 1.5691817702331567, "test_micro_f1_no_misc": 40.84639675817301, "test_micro_f1_no_misc_se": 1.641647259582096}}, "num_model_parameters": 4386057, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.19509267807006836, "test_micro_f1": 0.3417756749234623, "test_micro_f1_no_misc": 0.35885447106954993, "test_runtime": 2.3429, "test_samples_per_second": 874.115, "test_steps_per_second": 27.316}, {"test_loss": 0.1806207001209259, "test_micro_f1": 0.3594153052450559, "test_micro_f1_no_misc": 0.38005472788081485, "test_runtime": 2.366, "test_samples_per_second": 865.586, "test_steps_per_second": 27.05}, {"test_loss": 0.18617305159568787, "test_micro_f1": 0.3562600752283718, "test_micro_f1_no_misc": 0.3772079772079772, "test_runtime": 2.3099, "test_samples_per_second": 886.603, "test_steps_per_second": 27.706}, {"test_loss": 0.21472029387950897, "test_micro_f1": 0.27921176797113517, "test_micro_f1_no_misc": 0.2953138815207781, "test_runtime": 2.4125, "test_samples_per_second": 848.902, "test_steps_per_second": 26.528}, {"test_loss": 0.21590231359004974, "test_micro_f1": 0.2992976769313884, "test_micro_f1_no_misc": 0.32060185185185186, "test_runtime": 2.2955, "test_samples_per_second": 892.193, "test_steps_per_second": 27.881}, {"test_loss": 0.19530312716960907, "test_micro_f1": 0.36388811963445034, "test_micro_f1_no_misc": 0.3861298853952395, "test_runtime": 2.2499, "test_samples_per_second": 910.278, "test_steps_per_second": 28.446}, {"test_loss": 0.19132250547409058, "test_micro_f1": 0.26293469041560646, "test_micro_f1_no_misc": 0.2781100478468899, "test_runtime": 2.41, "test_samples_per_second": 849.805, "test_steps_per_second": 26.556}, {"test_loss": 0.2056397646665573, "test_micro_f1": 0.30972719757508954, "test_micro_f1_no_misc": 0.3259860788863109, "test_runtime": 2.3798, "test_samples_per_second": 860.572, "test_steps_per_second": 26.893}, {"test_loss": 0.20353606343269348, "test_micro_f1": 0.3479966377136453, "test_micro_f1_no_misc": 0.3686553873552983, "test_runtime": 2.2806, "test_samples_per_second": 898.004, "test_steps_per_second": 28.063}, {"test_loss": 0.22037845849990845, "test_micro_f1": 0.3062122045079713, "test_micro_f1_no_misc": 0.32039114178889844, "test_runtime": 2.3018, "test_samples_per_second": 889.727, "test_steps_per_second": 27.804}]}, "total": {"test_micro_f1": 32.26719350146176, "test_micro_f1_se": 2.2276152003028233, "test_micro_f1_no_misc": 34.113054508036086, "test_micro_f1_no_misc_se": 2.3615106289147207}}, "num_model_parameters": 4386057, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.689111053943634, "test_mcc": 0.09898022722410446, "test_macro_f1": 0.5309643407222586, "test_runtime": 0.8742, "test_samples_per_second": 2342.634, "test_steps_per_second": 73.207}, {"test_loss": 0.6922297477722168, "test_mcc": 0.08298897956554195, "test_macro_f1": 0.5331747397742408, "test_runtime": 0.8984, "test_samples_per_second": 2279.696, "test_steps_per_second": 71.241}, {"test_loss": 0.6927573680877686, "test_mcc": 0.020481999339102473, "test_macro_f1": 0.5101765019727478, "test_runtime": 0.8985, "test_samples_per_second": 2279.48, "test_steps_per_second": 71.234}, {"test_loss": 0.6929787397384644, "test_mcc": 0.011917498694104042, "test_macro_f1": 0.4831487871077056, "test_runtime": 0.8833, "test_samples_per_second": 2318.474, "test_steps_per_second": 72.452}, {"test_loss": 0.6923558712005615, "test_mcc": 0.03738493510556502, "test_macro_f1": 0.5185321884891851, "test_runtime": 0.8897, "test_samples_per_second": 2301.984, "test_steps_per_second": 71.937}, {"test_loss": 0.6931378841400146, "test_mcc": -0.021555851947686454, "test_macro_f1": 0.47206567148095724, "test_runtime": 0.8686, "test_samples_per_second": 2357.868, "test_steps_per_second": 73.683}, {"test_loss": 0.6930814981460571, "test_mcc": 0.031204264511086093, "test_macro_f1": 0.3350615617976958, "test_runtime": 0.893, "test_samples_per_second": 2293.496, "test_steps_per_second": 71.672}, {"test_loss": 0.6927927136421204, "test_mcc": 0.050919486681618616, "test_macro_f1": 0.514950177388134, "test_runtime": 0.8754, "test_samples_per_second": 2339.579, "test_steps_per_second": 73.112}, {"test_loss": 0.6912710666656494, "test_mcc": 0.0656346076490859, "test_macro_f1": 0.5325928875570923, "test_runtime": 0.8841, "test_samples_per_second": 2316.356, "test_steps_per_second": 72.386}, {"test_loss": 0.6940317153930664, "test_mcc": 0.005984141131042801, "test_macro_f1": 0.4809789967019615, "test_runtime": 0.8705, "test_samples_per_second": 2352.603, "test_steps_per_second": 73.519}]}, "total": {"test_mcc": 3.8394028795356485, "test_mcc_se": 2.2892114540979143, "test_macro_f1": 49.11645852991978, "test_macro_f1_se": 3.6750968430950928}}, "num_model_parameters": 4389762, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.6939409971237183, "test_mcc": 0.009391664991041883, "test_macro_f1": 0.5001656377849782, "test_runtime": 0.8883, "test_samples_per_second": 2305.416, "test_steps_per_second": 72.044}, {"test_loss": 0.6928983926773071, "test_mcc": 0.03761449671243243, "test_macro_f1": 0.5002195320830458, "test_runtime": 0.8886, "test_samples_per_second": 2304.835, "test_steps_per_second": 72.026}, {"test_loss": 0.6926289796829224, "test_mcc": 0.016166538657257448, "test_macro_f1": 0.508019150252284, "test_runtime": 0.8656, "test_samples_per_second": 2366.011, "test_steps_per_second": 73.938}, {"test_loss": 0.6907276511192322, "test_mcc": 0.06420374469966213, "test_macro_f1": 0.5305606998100214, "test_runtime": 0.8766, "test_samples_per_second": 2336.167, "test_steps_per_second": 73.005}, {"test_loss": 0.6922107934951782, "test_mcc": 0.03330017766032506, "test_macro_f1": 0.5145288432443551, "test_runtime": 0.876, "test_samples_per_second": 2337.9, "test_steps_per_second": 73.059}, {"test_loss": 0.6948254108428955, "test_mcc": 0.012885867362874536, "test_macro_f1": 0.5013049997357422, "test_runtime": 0.8815, "test_samples_per_second": 2323.226, "test_steps_per_second": 72.601}, {"test_loss": 0.6931997537612915, "test_mcc": -0.0318197711807684, "test_macro_f1": 0.32896461336828303, "test_runtime": 0.877, "test_samples_per_second": 2335.324, "test_steps_per_second": 72.979}, {"test_loss": 0.6917991638183594, "test_mcc": 0.04604329906491414, "test_macro_f1": 0.4989781593318705, "test_runtime": 0.8797, "test_samples_per_second": 2328.176, "test_steps_per_second": 72.756}, {"test_loss": 0.6968829035758972, "test_mcc": -0.003469624479838407, "test_macro_f1": 0.4971199695196376, "test_runtime": 0.874, "test_samples_per_second": 2343.133, "test_steps_per_second": 73.223}, {"test_loss": 0.6916112899780273, "test_mcc": 0.058403677777306255, "test_macro_f1": 0.5208626531617027, "test_runtime": 0.892, "test_samples_per_second": 2296.068, "test_steps_per_second": 71.752}]}, "total": {"test_mcc": 2.4272007126520707, "test_mcc_se": 1.8276626911888436, "test_macro_f1": 49.00724258291921, "test_macro_f1_se": 3.5738739289846015}}, "num_model_parameters": 4389762, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.6916646361351013, "test_mcc": 0.04155173183407325, "test_macro_f1": 0.5117369053342092, "test_runtime": 0.8906, "test_samples_per_second": 2299.496, "test_steps_per_second": 71.859}, {"test_loss": 0.6929712295532227, "test_mcc": 0.02430346199776628, "test_macro_f1": 0.5081737129709519, "test_runtime": 0.9038, "test_samples_per_second": 2266.012, "test_steps_per_second": 70.813}, {"test_loss": 0.6904683113098145, "test_mcc": 0.07084041644874245, "test_macro_f1": 0.5334243182630896, "test_runtime": 0.8838, "test_samples_per_second": 2317.149, "test_steps_per_second": 72.411}, {"test_loss": 0.6930136680603027, "test_mcc": 0.051942127091886545, "test_macro_f1": 0.5249968676802949, "test_runtime": 0.8851, "test_samples_per_second": 2313.782, "test_steps_per_second": 72.306}, {"test_loss": 0.6924388408660889, "test_mcc": 0.01838206778978116, "test_macro_f1": 0.5084700226750871, "test_runtime": 0.897, "test_samples_per_second": 2283.055, "test_steps_per_second": 71.345}, {"test_loss": 0.6895158886909485, "test_mcc": 0.10148157242099087, "test_macro_f1": 0.5466287830663386, "test_runtime": 0.8887, "test_samples_per_second": 2304.581, "test_steps_per_second": 72.018}, {"test_loss": 0.6896286606788635, "test_mcc": 0.08065019483381061, "test_macro_f1": 0.5327865479798183, "test_runtime": 0.8834, "test_samples_per_second": 2318.267, "test_steps_per_second": 72.446}, {"test_loss": 0.6920114755630493, "test_mcc": 0.045332946104879826, "test_macro_f1": 0.4977195382193546, "test_runtime": 0.8824, "test_samples_per_second": 2320.941, "test_steps_per_second": 72.529}, {"test_loss": 0.6940979957580566, "test_mcc": 0.01961151926414453, "test_macro_f1": 0.4988646151436849, "test_runtime": 0.8928, "test_samples_per_second": 2293.892, "test_steps_per_second": 71.684}, {"test_loss": 0.6923578977584839, "test_mcc": 0.030156186918589407, "test_macro_f1": 0.5068729686051963, "test_runtime": 0.8986, "test_samples_per_second": 2279.006, "test_steps_per_second": 71.219}]}, "total": {"test_mcc": 4.84252224704665, "test_mcc_se": 1.7376062132141399, "test_macro_f1": 51.69674279938026, "test_macro_f1_se": 1.0210257241568206}}, "num_model_parameters": 4389762, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.6939292550086975, "test_mcc": 0.026657024745192794, "test_macro_f1": 0.46031680051646284, "test_runtime": 0.9216, "test_samples_per_second": 2222.226, "test_steps_per_second": 69.445}, {"test_loss": 0.6935063600540161, "test_mcc": 0.009953425233212774, "test_macro_f1": 0.5044352129272452, "test_runtime": 0.93, "test_samples_per_second": 2202.22, "test_steps_per_second": 68.819}, {"test_loss": 0.6923261880874634, "test_mcc": 0.06461582895218519, "test_macro_f1": 0.5319904546265577, "test_runtime": 0.9325, "test_samples_per_second": 2196.255, "test_steps_per_second": 68.633}, {"test_loss": 0.6930965781211853, "test_mcc": -0.005358945117765444, "test_macro_f1": 0.49729383518264736, "test_runtime": 0.9156, "test_samples_per_second": 2236.704, "test_steps_per_second": 69.897}, {"test_loss": 0.6925221085548401, "test_mcc": 0.03788114136500122, "test_macro_f1": 0.5060324692525644, "test_runtime": 0.9198, "test_samples_per_second": 2226.535, "test_steps_per_second": 69.579}, {"test_loss": 0.6932597160339355, "test_mcc": 0.004232513895051343, "test_macro_f1": 0.49796581887616864, "test_runtime": 0.9286, "test_samples_per_second": 2205.369, "test_steps_per_second": 68.918}, {"test_loss": 0.6929720044136047, "test_mcc": 0.04585394390049851, "test_macro_f1": 0.4573363755114407, "test_runtime": 0.9199, "test_samples_per_second": 2226.372, "test_steps_per_second": 69.574}, {"test_loss": 0.6926432847976685, "test_mcc": -0.007300487645553169, "test_macro_f1": 0.47257733909772226, "test_runtime": 0.9268, "test_samples_per_second": 2209.832, "test_steps_per_second": 69.057}, {"test_loss": 0.6930882334709167, "test_mcc": 0.02194211457777053, "test_macro_f1": 0.48757885877154383, "test_runtime": 0.9241, "test_samples_per_second": 2216.109, "test_steps_per_second": 69.253}, {"test_loss": 0.6923182606697083, "test_mcc": 0.05843635206796259, "test_macro_f1": 0.527388847948907, "test_runtime": 0.9275, "test_samples_per_second": 2207.985, "test_steps_per_second": 69.0}]}, "total": {"test_mcc": 2.569129119735564, "test_mcc_se": 1.5893878392841947, "test_macro_f1": 49.429160127112596, "test_macro_f1_se": 1.5756622051160722}}, "num_model_parameters": 4389762, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_em": 3.9504260263361735, "test_f1": 9.337667734806944}, {"test_em": 3.953488372093023, "test_f1": 10.13033892518738}, {"test_em": 5.023183925811438, "test_f1": 11.469329915893104}, {"test_em": 3.426791277258567, "test_f1": 8.971740504234994}, {"test_em": 5.173745173745174, "test_f1": 11.671355911422848}, {"test_em": 3.0069390902081725, "test_f1": 7.97518187975552}, {"test_em": 5.087319665907366, "test_f1": 11.414845934216265}, {"test_em": 6.051202482544608, "test_f1": 13.122644160798648}, {"test_em": 3.6862745098039214, "test_f1": 9.294012874081826}, {"test_em": 3.1055900621118013, "test_f1": 8.315648914942368}]}, "total": {"test_em": 4.246496058582024, "test_em_se": 0.6342526764978529, "test_f1": 10.17027667553399, "test_f1_se": 1.0404925576979558}}, "num_model_parameters": 4385602, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_em": 5.189775367931836, "test_f1": 13.494198547427276}, {"test_em": 3.643410852713178, "test_f1": 9.765569691168784}, {"test_em": 3.0139103554868623, "test_f1": 9.971707742515868}, {"test_em": 3.8161993769470404, "test_f1": 10.441511289239207}, {"test_em": 3.474903474903475, "test_f1": 10.906810999430675}, {"test_em": 4.009252120277564, "test_f1": 10.457472479626345}, {"test_em": 4.176157934700076, "test_f1": 11.052885954143616}, {"test_em": 4.887509697439876, "test_f1": 12.349003232415344}, {"test_em": 4.0, "test_f1": 10.26707284120349}, {"test_em": 3.7267080745341614, "test_f1": 9.319791630464666}]}, "total": {"test_em": 3.993782725493407, "test_em_se": 0.39835634121819924, "test_f1": 10.802602440763527, "test_f1_se": 0.7788213056739485}}, "num_model_parameters": 4385602, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_em": 5.654531371030209, "test_f1": 13.368341843845991}, {"test_em": 4.0310077519379846, "test_f1": 11.552373614282182}, {"test_em": 5.255023183925811, "test_f1": 12.282443149002598}, {"test_em": 5.685358255451713, "test_f1": 12.921139467490564}, {"test_em": 3.9382239382239383, "test_f1": 11.821512987811102}, {"test_em": 5.474171164225135, "test_f1": 11.233514366848935}, {"test_em": 3.7205770690964313, "test_f1": 11.293197985244126}, {"test_em": 4.1117145073700545, "test_f1": 12.50278327527099}, {"test_em": 4.0, "test_f1": 10.312853190908204}, {"test_em": 4.037267080745342, "test_f1": 10.399760471220874}]}, "total": {"test_em": 4.5907874322006625, "test_em_se": 0.5032192148321417, "test_f1": 11.768792035192558, "test_f1_se": 0.6281988882211557}}, "num_model_parameters": 4385602, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.5197759866714478, "test_mcc": 0.681392746394575, "test_macro_f1": 0.5816424802424938, "test_runtime": 8.2634, "test_samples_per_second": 247.841, "test_steps_per_second": 61.96}, {"test_loss": 0.4939712584018707, "test_mcc": 0.6819172800083341, "test_macro_f1": 0.7080493704301091, "test_runtime": 8.0536, "test_samples_per_second": 254.295, "test_steps_per_second": 63.574}, {"test_loss": 0.505869448184967, "test_mcc": 0.6923211410406961, "test_macro_f1": 0.6935444842906316, "test_runtime": 8.1169, "test_samples_per_second": 252.313, "test_steps_per_second": 63.078}, {"test_loss": 0.4817454516887665, "test_mcc": 0.6961094932490532, "test_macro_f1": 0.6102007877952237, "test_runtime": 7.8213, "test_samples_per_second": 261.849, "test_steps_per_second": 65.462}, {"test_loss": 0.4986327290534973, "test_mcc": 0.6853447820961971, "test_macro_f1": 0.651853366802167, "test_runtime": 7.9169, "test_samples_per_second": 258.687, "test_steps_per_second": 64.672}, {"test_loss": 0.5226515531539917, "test_mcc": 0.6767079080878674, "test_macro_f1": 0.6011562140156036, "test_runtime": 8.2937, "test_samples_per_second": 246.933, "test_steps_per_second": 61.733}, {"test_loss": 0.484434574842453, "test_mcc": 0.7031393068696671, "test_macro_f1": 0.6495792179681117, "test_runtime": 7.9772, "test_samples_per_second": 256.731, "test_steps_per_second": 64.183}, {"test_loss": 0.490010529756546, "test_mcc": 0.6900394677133335, "test_macro_f1": 0.643401958123567, "test_runtime": 8.1587, "test_samples_per_second": 251.02, "test_steps_per_second": 62.755}, {"test_loss": 0.5303842425346375, "test_mcc": 0.6417214691582463, "test_macro_f1": 0.6486760770151014, "test_runtime": 8.2273, "test_samples_per_second": 248.928, "test_steps_per_second": 62.232}, {"test_loss": 0.5019996762275696, "test_mcc": 0.6847613771891005, "test_macro_f1": 0.6150848637134908, "test_runtime": 8.0028, "test_samples_per_second": 255.909, "test_steps_per_second": 63.977}]}, "total": {"test_mcc": 68.3345497180707, "test_mcc_se": 1.0264941877877125, "test_macro_f1": 64.03188820396501, "test_macro_f1_se": 2.4653288988100908}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.9200639724731445, "test_mcc": 0.36830899803848516, "test_macro_f1": 0.5780916075576494, "test_runtime": 2.6003, "test_samples_per_second": 787.601, "test_steps_per_second": 24.613}, {"test_loss": 0.9505406618118286, "test_mcc": 0.356611366926384, "test_macro_f1": 0.561179005828018, "test_runtime": 2.596, "test_samples_per_second": 788.893, "test_steps_per_second": 24.653}, {"test_loss": 0.919263482093811, "test_mcc": 0.3572770923323712, "test_macro_f1": 0.5714739938279427, "test_runtime": 2.583, "test_samples_per_second": 792.888, "test_steps_per_second": 24.778}, {"test_loss": 0.9016720652580261, "test_mcc": 0.39377446279428485, "test_macro_f1": 0.5894093635062507, "test_runtime": 2.591, "test_samples_per_second": 790.424, "test_steps_per_second": 24.701}, {"test_loss": 0.9178590774536133, "test_mcc": 0.36182735101264746, "test_macro_f1": 0.5676629260644667, "test_runtime": 2.5601, "test_samples_per_second": 799.974, "test_steps_per_second": 24.999}, {"test_loss": 0.9033106565475464, "test_mcc": 0.4059786915853751, "test_macro_f1": 0.6014199822899577, "test_runtime": 2.6091, "test_samples_per_second": 784.95, "test_steps_per_second": 24.53}, {"test_loss": 0.9254603385925293, "test_mcc": 0.3881122789528883, "test_macro_f1": 0.5883182951011948, "test_runtime": 2.5962, "test_samples_per_second": 788.843, "test_steps_per_second": 24.651}, {"test_loss": 0.9644569158554077, "test_mcc": 0.3161229060860373, "test_macro_f1": 0.5225983462497669, "test_runtime": 2.596, "test_samples_per_second": 788.909, "test_steps_per_second": 24.653}, {"test_loss": 0.9147257804870605, "test_mcc": 0.366644592053742, "test_macro_f1": 0.574856553869287, "test_runtime": 2.5744, "test_samples_per_second": 795.521, "test_steps_per_second": 24.86}, {"test_loss": 0.9299646615982056, "test_mcc": 0.34484886755502747, "test_macro_f1": 0.5384814978623028, "test_runtime": 2.5466, "test_samples_per_second": 804.219, "test_steps_per_second": 25.132}]}, "total": {"test_mcc": 36.59506607337243, "test_mcc_se": 1.5978152631901648, "test_macro_f1": 56.934915721568366, "test_macro_f1_se": 1.4768946670284449}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.841215968132019, "test_mcc": 0.46609474672983403, "test_macro_f1": 0.6207051971797514, "test_runtime": 2.0884, "test_samples_per_second": 980.655, "test_steps_per_second": 30.645}, {"test_loss": 0.781441330909729, "test_mcc": 0.4641201743459563, "test_macro_f1": 0.6171009635593888, "test_runtime": 1.9547, "test_samples_per_second": 1047.714, "test_steps_per_second": 32.741}, {"test_loss": 0.834067702293396, "test_mcc": 0.4665965024300974, "test_macro_f1": 0.6358435965345411, "test_runtime": 1.9803, "test_samples_per_second": 1034.206, "test_steps_per_second": 32.319}, {"test_loss": 0.8298976421356201, "test_mcc": 0.44662903501235623, "test_macro_f1": 0.5863632172161878, "test_runtime": 2.0079, "test_samples_per_second": 1019.988, "test_steps_per_second": 31.875}, {"test_loss": 0.7950265407562256, "test_mcc": 0.4496583730109515, "test_macro_f1": 0.5951091357451298, "test_runtime": 2.0497, "test_samples_per_second": 999.174, "test_steps_per_second": 31.224}, {"test_loss": 0.8296329379081726, "test_mcc": 0.43492504347308086, "test_macro_f1": 0.5934120213760774, "test_runtime": 2.0862, "test_samples_per_second": 981.708, "test_steps_per_second": 30.678}, {"test_loss": 0.7823520302772522, "test_mcc": 0.4757440386100898, "test_macro_f1": 0.6142600807378545, "test_runtime": 2.0032, "test_samples_per_second": 1022.378, "test_steps_per_second": 31.949}, {"test_loss": 0.8517112731933594, "test_mcc": 0.367939650776332, "test_macro_f1": 0.5257824887700876, "test_runtime": 2.0238, "test_samples_per_second": 1011.958, "test_steps_per_second": 31.624}, {"test_loss": 0.877302885055542, "test_mcc": 0.43862540025123753, "test_macro_f1": 0.5973746701701862, "test_runtime": 2.0838, "test_samples_per_second": 982.81, "test_steps_per_second": 30.713}, {"test_loss": 0.7917823195457458, "test_mcc": 0.4489392819598084, "test_macro_f1": 0.6014838735861048, "test_runtime": 2.0784, "test_samples_per_second": 985.381, "test_steps_per_second": 30.793}]}, "total": {"test_mcc": 44.59272246599745, "test_mcc_se": 1.8860734872559972, "test_macro_f1": 59.8743524487531, "test_macro_f1_se": 1.8437538051356779}}, "num_model_parameters": 135326979, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.08247218281030655, "test_micro_f1": 0.562624254473161, "test_micro_f1_no_misc": 0.6446578631452582, "test_runtime": 4.7256, "test_samples_per_second": 433.384, "test_steps_per_second": 13.543}, {"test_loss": 0.08079734444618225, "test_micro_f1": 0.5929919137466307, "test_micro_f1_no_misc": 0.6486153846153846, "test_runtime": 4.4326, "test_samples_per_second": 462.034, "test_steps_per_second": 14.439}, {"test_loss": 0.07555236667394638, "test_micro_f1": 0.5950720595072059, "test_micro_f1_no_misc": 0.6463157894736842, "test_runtime": 4.4506, "test_samples_per_second": 460.166, "test_steps_per_second": 14.38}, {"test_loss": 0.08247263729572296, "test_micro_f1": 0.587511825922422, "test_micro_f1_no_misc": 0.6342494714587738, "test_runtime": 4.6027, "test_samples_per_second": 444.955, "test_steps_per_second": 13.905}, {"test_loss": 0.08427456766366959, "test_micro_f1": 0.609367894497499, "test_micro_f1_no_misc": 0.657421674370827, "test_runtime": 4.7156, "test_samples_per_second": 434.303, "test_steps_per_second": 13.572}, {"test_loss": 0.08220237493515015, "test_micro_f1": 0.5766257389722602, "test_micro_f1_no_misc": 0.6235985050720768, "test_runtime": 3.7467, "test_samples_per_second": 546.619, "test_steps_per_second": 17.082}, {"test_loss": 0.08281752467155457, "test_micro_f1": 0.6038647342995169, "test_micro_f1_no_misc": 0.6703601108033241, "test_runtime": 4.1063, "test_samples_per_second": 498.747, "test_steps_per_second": 15.586}, {"test_loss": 0.07289391756057739, "test_micro_f1": 0.618970189701897, "test_micro_f1_no_misc": 0.6744759556103576, "test_runtime": 4.708, "test_samples_per_second": 435.006, "test_steps_per_second": 13.594}, {"test_loss": 0.07908554375171661, "test_micro_f1": 0.5954337899543379, "test_micro_f1_no_misc": 0.6630843632455669, "test_runtime": 4.5119, "test_samples_per_second": 453.913, "test_steps_per_second": 14.185}, {"test_loss": 0.07614244520664215, "test_micro_f1": 0.629683698296837, "test_micro_f1_no_misc": 0.6873270614277809, "test_runtime": 4.6076, "test_samples_per_second": 444.481, "test_steps_per_second": 13.89}]}, "total": {"test_micro_f1": 59.72146099371768, "test_micro_f1_se": 1.215200834421084, "test_micro_f1_no_misc": 65.50106179223033, "test_micro_f1_no_misc_se": 1.1995886761547134}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.08595666289329529, "test_micro_f1": 0.7258432665483135, "test_micro_f1_no_misc": 0.7544338335607095, "test_runtime": 5.5833, "test_samples_per_second": 366.808, "test_steps_per_second": 11.463}, {"test_loss": 0.09023719280958176, "test_micro_f1": 0.6744628773456623, "test_micro_f1_no_misc": 0.6920634920634919, "test_runtime": 4.2612, "test_samples_per_second": 480.617, "test_steps_per_second": 15.019}, {"test_loss": 0.08915939927101135, "test_micro_f1": 0.711528429838289, "test_micro_f1_no_misc": 0.7278525868178596, "test_runtime": 5.5244, "test_samples_per_second": 370.719, "test_steps_per_second": 11.585}, {"test_loss": 0.08486582338809967, "test_micro_f1": 0.7426945952935092, "test_micro_f1_no_misc": 0.7549668874172186, "test_runtime": 5.2562, "test_samples_per_second": 389.637, "test_steps_per_second": 12.176}, {"test_loss": 0.09540289640426636, "test_micro_f1": 0.6962838781782621, "test_micro_f1_no_misc": 0.7228096676737159, "test_runtime": 5.4865, "test_samples_per_second": 373.281, "test_steps_per_second": 11.665}, {"test_loss": 0.08770714700222015, "test_micro_f1": 0.7346269472533479, "test_micro_f1_no_misc": 0.7359882005899705, "test_runtime": 5.3792, "test_samples_per_second": 380.729, "test_steps_per_second": 11.898}, {"test_loss": 0.08557257801294327, "test_micro_f1": 0.711533386117709, "test_micro_f1_no_misc": 0.7233743409490334, "test_runtime": 5.5327, "test_samples_per_second": 370.16, "test_steps_per_second": 11.567}, {"test_loss": 0.08416277170181274, "test_micro_f1": 0.7065901011758271, "test_micro_f1_no_misc": 0.7193169690501602, "test_runtime": 5.4014, "test_samples_per_second": 379.162, "test_steps_per_second": 11.849}, {"test_loss": 0.08816919475793839, "test_micro_f1": 0.7139830508474575, "test_micro_f1_no_misc": 0.7133262636974195, "test_runtime": 5.2188, "test_samples_per_second": 392.428, "test_steps_per_second": 12.263}, {"test_loss": 0.09191013872623444, "test_micro_f1": 0.7054161162483487, "test_micro_f1_no_misc": 0.7221629313411597, "test_runtime": 4.5029, "test_samples_per_second": 454.821, "test_steps_per_second": 14.213}]}, "total": {"test_micro_f1": 71.22962648846726, "test_micro_f1_se": 1.2007680878561489, "test_micro_f1_no_misc": 72.66295173160738, "test_micro_f1_no_misc_se": 1.1568917840415633}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.05998680368065834, "test_micro_f1": 0.7401855817273376, "test_micro_f1_no_misc": 0.7794294897549217, "test_runtime": 4.2908, "test_samples_per_second": 477.302, "test_steps_per_second": 14.916}, {"test_loss": 0.05675952136516571, "test_micro_f1": 0.760655737704918, "test_micro_f1_no_misc": 0.7816185441236275, "test_runtime": 4.1703, "test_samples_per_second": 491.089, "test_steps_per_second": 15.347}, {"test_loss": 0.05657687783241272, "test_micro_f1": 0.7540869565217391, "test_micro_f1_no_misc": 0.7809377401998463, "test_runtime": 3.9297, "test_samples_per_second": 521.159, "test_steps_per_second": 16.286}, {"test_loss": 0.05547136813402176, "test_micro_f1": 0.7459938629389703, "test_micro_f1_no_misc": 0.7704485488126649, "test_runtime": 3.8991, "test_samples_per_second": 525.254, "test_steps_per_second": 16.414}, {"test_loss": 0.061840638518333435, "test_micro_f1": 0.7384116693679091, "test_micro_f1_no_misc": 0.7737068965517241, "test_runtime": 4.2217, "test_samples_per_second": 485.117, "test_steps_per_second": 15.16}, {"test_loss": 0.058588262647390366, "test_micro_f1": 0.7417840375586853, "test_micro_f1_no_misc": 0.7722772277227723, "test_runtime": 4.2141, "test_samples_per_second": 485.986, "test_steps_per_second": 15.187}, {"test_loss": 0.05206356197595596, "test_micro_f1": 0.7736486486486486, "test_micro_f1_no_misc": 0.8058361391694726, "test_runtime": 3.7584, "test_samples_per_second": 544.909, "test_steps_per_second": 17.028}, {"test_loss": 0.061585597693920135, "test_micro_f1": 0.756811301715439, "test_micro_f1_no_misc": 0.7871396895787139, "test_runtime": 3.8823, "test_samples_per_second": 527.522, "test_steps_per_second": 16.485}, {"test_loss": 0.053768228739500046, "test_micro_f1": 0.7394957983193279, "test_micro_f1_no_misc": 0.7625340069957249, "test_runtime": 3.8801, "test_samples_per_second": 527.82, "test_steps_per_second": 16.494}, {"test_loss": 0.06915701925754547, "test_micro_f1": 0.7317073170731708, "test_micro_f1_no_misc": 0.7674333698430085, "test_runtime": 4.179, "test_samples_per_second": 490.065, "test_steps_per_second": 15.315}]}, "total": {"test_micro_f1": 74.82780911576144, "test_micro_f1_se": 0.7908773546922541, "test_micro_f1_no_misc": 77.81361652752477, "test_micro_f1_no_misc_se": 0.7565765494981195}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.08074561506509781, "test_micro_f1": 0.6964231121981046, "test_micro_f1_no_misc": 0.7298831385642738, "test_runtime": 3.9204, "test_samples_per_second": 522.401, "test_steps_per_second": 16.325}, {"test_loss": 0.0826406180858612, "test_micro_f1": 0.6666666666666666, "test_micro_f1_no_misc": 0.7070249271608935, "test_runtime": 4.1364, "test_samples_per_second": 495.121, "test_steps_per_second": 15.473}, {"test_loss": 0.0836346298456192, "test_micro_f1": 0.689655172413793, "test_micro_f1_no_misc": 0.7314172447968286, "test_runtime": 3.8569, "test_samples_per_second": 530.994, "test_steps_per_second": 16.594}, {"test_loss": 0.09302131831645966, "test_micro_f1": 0.6573218013719058, "test_micro_f1_no_misc": 0.6966731898238747, "test_runtime": 4.0539, "test_samples_per_second": 505.194, "test_steps_per_second": 15.787}, {"test_loss": 0.09864125400781631, "test_micro_f1": 0.6593341260404281, "test_micro_f1_no_misc": 0.7085201793721974, "test_runtime": 3.767, "test_samples_per_second": 543.671, "test_steps_per_second": 16.99}, {"test_loss": 0.08415068686008453, "test_micro_f1": 0.6946745562130178, "test_micro_f1_no_misc": 0.7320261437908496, "test_runtime": 3.883, "test_samples_per_second": 527.422, "test_steps_per_second": 16.482}, {"test_loss": 0.07828570902347565, "test_micro_f1": 0.6771507863089731, "test_micro_f1_no_misc": 0.7163978494623657, "test_runtime": 4.0271, "test_samples_per_second": 508.553, "test_steps_per_second": 15.892}, {"test_loss": 0.08001711964607239, "test_micro_f1": 0.6884650317892825, "test_micro_f1_no_misc": 0.7262344642257306, "test_runtime": 4.0225, "test_samples_per_second": 509.133, "test_steps_per_second": 15.91}, {"test_loss": 0.0881529450416565, "test_micro_f1": 0.6873083997547517, "test_micro_f1_no_misc": 0.7243022464261403, "test_runtime": 3.7318, "test_samples_per_second": 548.798, "test_steps_per_second": 17.15}, {"test_loss": 0.07478778809309006, "test_micro_f1": 0.7153153153153152, "test_micro_f1_no_misc": 0.7496688741721854, "test_runtime": 3.8271, "test_samples_per_second": 535.129, "test_steps_per_second": 16.723}]}, "total": {"test_micro_f1": 68.3231496807224, "test_micro_f1_se": 1.1265735775636052, "test_micro_f1_no_misc": 72.2214825779534, "test_micro_f1_no_misc_se": 0.95092612358204}}, "num_model_parameters": 134741001, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.6920970678329468, "test_mcc": 0.019571885872874655, "test_macro_f1": 0.46608393313501767, "test_runtime": 2.0385, "test_samples_per_second": 1004.653, "test_steps_per_second": 31.395}, {"test_loss": 0.666379451751709, "test_mcc": 0.24311226007656103, "test_macro_f1": 0.6115850893399232, "test_runtime": 2.1171, "test_samples_per_second": 967.341, "test_steps_per_second": 30.229}, {"test_loss": 0.6925046443939209, "test_mcc": 0.03586558930550331, "test_macro_f1": 0.5146050606910378, "test_runtime": 2.1803, "test_samples_per_second": 939.338, "test_steps_per_second": 29.354}, {"test_loss": 0.6928786039352417, "test_mcc": 0.03515531201604414, "test_macro_f1": 0.502725582335528, "test_runtime": 2.0571, "test_samples_per_second": 995.585, "test_steps_per_second": 31.112}, {"test_loss": 0.6709704399108887, "test_mcc": 0.21166417563393763, "test_macro_f1": 0.6054557499149553, "test_runtime": 2.0698, "test_samples_per_second": 989.479, "test_steps_per_second": 30.921}, {"test_loss": 0.6608574986457825, "test_mcc": 0.21336732052297233, "test_macro_f1": 0.5979650972102506, "test_runtime": 2.0385, "test_samples_per_second": 1004.676, "test_steps_per_second": 31.396}, {"test_loss": 0.6538949012756348, "test_mcc": 0.24337994499703872, "test_macro_f1": 0.6118454637677266, "test_runtime": 2.0663, "test_samples_per_second": 991.141, "test_steps_per_second": 30.973}, {"test_loss": 0.6674292087554932, "test_mcc": 0.2042526403697712, "test_macro_f1": 0.5993004290038767, "test_runtime": 2.0627, "test_samples_per_second": 992.859, "test_steps_per_second": 31.027}, {"test_loss": 0.6597943305969238, "test_mcc": 0.26285690778145787, "test_macro_f1": 0.607843137254902, "test_runtime": 2.0762, "test_samples_per_second": 986.433, "test_steps_per_second": 30.826}, {"test_loss": 0.6928848028182983, "test_mcc": 0.011983311968100123, "test_macro_f1": 0.43218643033414034, "test_runtime": 2.099, "test_samples_per_second": 975.706, "test_steps_per_second": 30.491}]}, "total": {"test_mcc": 14.812093485442606, "test_mcc_se": 6.634740152407461, "test_macro_f1": 55.49595972987359, "test_macro_f1_se": 4.280882894612987}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.6936782598495483, "test_mcc": -0.024649730464208798, "test_macro_f1": 0.46851580995637987, "test_runtime": 2.1805, "test_samples_per_second": 939.246, "test_steps_per_second": 29.351}, {"test_loss": 0.6932549476623535, "test_mcc": 0.04071852465034033, "test_macro_f1": 0.45922836900877295, "test_runtime": 2.2765, "test_samples_per_second": 899.646, "test_steps_per_second": 28.114}, {"test_loss": 0.6750810146331787, "test_mcc": 0.15238312997038964, "test_macro_f1": 0.5694929010822821, "test_runtime": 2.2441, "test_samples_per_second": 912.617, "test_steps_per_second": 28.519}, {"test_loss": 0.6707598567008972, "test_mcc": 0.1745696333055986, "test_macro_f1": 0.5791274568822475, "test_runtime": 2.3395, "test_samples_per_second": 875.389, "test_steps_per_second": 27.356}, {"test_loss": 0.6940641403198242, "test_mcc": -0.01969676413357279, "test_macro_f1": 0.48703088106885184, "test_runtime": 2.2278, "test_samples_per_second": 919.282, "test_steps_per_second": 28.728}, {"test_loss": 0.6924997568130493, "test_mcc": 0.034603643080159785, "test_macro_f1": 0.46242325743691626, "test_runtime": 2.1923, "test_samples_per_second": 934.164, "test_steps_per_second": 29.193}, {"test_loss": 0.6932553052902222, "test_mcc": 0.026988693282890584, "test_macro_f1": 0.4319369787647733, "test_runtime": 2.1511, "test_samples_per_second": 952.067, "test_steps_per_second": 29.752}, {"test_loss": 0.6643307209014893, "test_mcc": 0.21253897323347448, "test_macro_f1": 0.5968484341811713, "test_runtime": 2.2021, "test_samples_per_second": 930.002, "test_steps_per_second": 29.063}, {"test_loss": 0.6772351861000061, "test_mcc": 0.15060303059688668, "test_macro_f1": 0.570594019318642, "test_runtime": 2.1866, "test_samples_per_second": 936.607, "test_steps_per_second": 29.269}, {"test_loss": 0.6765670776367188, "test_mcc": 0.13628982260143743, "test_macro_f1": 0.5509542986358753, "test_runtime": 2.2429, "test_samples_per_second": 913.104, "test_steps_per_second": 28.534}]}, "total": {"test_mcc": 8.843489561233959, "test_mcc_se": 5.327621595836661, "test_macro_f1": 51.76152406335912, "test_macro_f1_se": 3.7990808431498255}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.6920773983001709, "test_mcc": 0.04692861287851037, "test_macro_f1": 0.5028605869581535, "test_runtime": 2.0132, "test_samples_per_second": 1017.307, "test_steps_per_second": 31.791}, {"test_loss": 0.682287335395813, "test_mcc": 0.1322725616671501, "test_macro_f1": 0.5510412860796493, "test_runtime": 1.9874, "test_samples_per_second": 1030.501, "test_steps_per_second": 32.203}, {"test_loss": 0.692322313785553, "test_mcc": 0.0869280732837881, "test_macro_f1": 0.5208715950867193, "test_runtime": 2.0136, "test_samples_per_second": 1017.104, "test_steps_per_second": 31.785}, {"test_loss": 0.6729775667190552, "test_mcc": 0.18466397777320165, "test_macro_f1": 0.5655163856010055, "test_runtime": 2.051, "test_samples_per_second": 998.552, "test_steps_per_second": 31.205}, {"test_loss": 0.6930071711540222, "test_mcc": 0.028850644840072392, "test_macro_f1": 0.5004480870974647, "test_runtime": 2.0368, "test_samples_per_second": 1005.493, "test_steps_per_second": 31.422}, {"test_loss": 0.6862271428108215, "test_mcc": 0.10321961357008305, "test_macro_f1": 0.4726728040060353, "test_runtime": 1.9607, "test_samples_per_second": 1044.532, "test_steps_per_second": 32.642}, {"test_loss": 0.6871302127838135, "test_mcc": 0.09177692701934329, "test_macro_f1": 0.5347245120668269, "test_runtime": 1.9458, "test_samples_per_second": 1052.527, "test_steps_per_second": 32.891}, {"test_loss": 0.6926810145378113, "test_mcc": 0.007170360217988978, "test_macro_f1": 0.4942965043090927, "test_runtime": 1.997, "test_samples_per_second": 1025.542, "test_steps_per_second": 32.048}, {"test_loss": 0.6757801175117493, "test_mcc": 0.1603955656454944, "test_macro_f1": 0.5790971664461944, "test_runtime": 1.9448, "test_samples_per_second": 1053.055, "test_steps_per_second": 32.908}, {"test_loss": 0.6889365315437317, "test_mcc": 0.0559542367175593, "test_macro_f1": 0.527822912610989, "test_runtime": 2.0163, "test_samples_per_second": 1015.7, "test_steps_per_second": 31.741}]}, "total": {"test_mcc": 8.981605736131916, "test_mcc_se": 3.548811353929451, "test_macro_f1": 52.493518402621305, "test_macro_f1_se": 2.0803877717826005}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_loss": 0.6798707246780396, "test_mcc": 0.12316746923488496, "test_macro_f1": 0.560546875, "test_runtime": 2.0576, "test_samples_per_second": 995.329, "test_steps_per_second": 31.104}, {"test_loss": 0.6925420761108398, "test_mcc": 0.047917296864202354, "test_macro_f1": 0.5225490196078431, "test_runtime": 2.1821, "test_samples_per_second": 938.556, "test_steps_per_second": 29.33}, {"test_loss": 0.6928820610046387, "test_mcc": 0.0048175772748147525, "test_macro_f1": 0.4389392574382666, "test_runtime": 2.1219, "test_samples_per_second": 965.154, "test_steps_per_second": 30.161}, {"test_loss": 0.6936331987380981, "test_mcc": 0.06215354756404121, "test_macro_f1": 0.4083921724209867, "test_runtime": 2.0143, "test_samples_per_second": 1016.738, "test_steps_per_second": 31.773}, {"test_loss": 0.6863626837730408, "test_mcc": 0.12118747471988757, "test_macro_f1": 0.5605925329808817, "test_runtime": 2.0526, "test_samples_per_second": 997.756, "test_steps_per_second": 31.18}, {"test_loss": 0.6831422448158264, "test_mcc": 0.13649182326367232, "test_macro_f1": 0.5567575437882125, "test_runtime": 2.2295, "test_samples_per_second": 918.592, "test_steps_per_second": 28.706}, {"test_loss": 0.6926929354667664, "test_mcc": 0.01999503174140761, "test_macro_f1": 0.4896331738437002, "test_runtime": 2.0391, "test_samples_per_second": 1004.379, "test_steps_per_second": 31.387}, {"test_loss": 0.6921914219856262, "test_mcc": 0.05477440924397195, "test_macro_f1": 0.5265343003667229, "test_runtime": 2.0684, "test_samples_per_second": 990.137, "test_steps_per_second": 30.942}, {"test_loss": 0.6938158273696899, "test_mcc": 0.0010376903880685068, "test_macro_f1": 0.4913607575478079, "test_runtime": 2.0397, "test_samples_per_second": 1004.062, "test_steps_per_second": 31.377}, {"test_loss": 0.6934152245521545, "test_mcc": 0.0006224622163890603, "test_macro_f1": 0.4846451902921445, "test_runtime": 2.0693, "test_samples_per_second": 989.726, "test_steps_per_second": 30.929}]}, "total": {"test_mcc": 5.721647825113404, "test_mcc_se": 3.2883659378988135, "test_macro_f1": 50.399508232865664, "test_macro_f1_se": 3.2106534056640603}}, "num_model_parameters": 135326210, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_em": 27.652982184353213, "test_f1": 33.395403257932095}, {"test_em": 28.06201550387597, "test_f1": 33.87515463466326}, {"test_em": 27.820710973724886, "test_f1": 33.35325668300317}, {"test_em": 25.0, "test_f1": 30.744054755346397}, {"test_em": 20.694980694980696, "test_f1": 26.963881523993457}, {"test_em": 20.277563608326908, "test_f1": 26.644468895506563}, {"test_em": 17.995444191343964, "test_f1": 23.96837180076479}, {"test_em": 28.006206361520558, "test_f1": 33.677154669448065}, {"test_em": 25.647058823529413, "test_f1": 31.455168795202695}, {"test_em": 30.124223602484474, "test_f1": 35.44503564509023}]}, "total": {"test_em": 25.12811859441401, "test_em_se": 2.528818201520225, "test_f1": 30.952195066095072, "test_f1_se": 2.3684781358503684}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_em": 29.43454686289698, "test_f1": 36.021556815409284}, {"test_em": 27.441860465116278, "test_f1": 35.21449701083337}, {"test_em": 27.125193199381762, "test_f1": 33.911956670974206}, {"test_em": 28.193146417445483, "test_f1": 34.25692445158031}, {"test_em": 27.876447876447877, "test_f1": 33.53572943221617}, {"test_em": 27.370855821125673, "test_f1": 33.4819990242363}, {"test_em": 27.33485193621868, "test_f1": 33.6394008112871}, {"test_em": 26.60977501939488, "test_f1": 31.95867445691628}, {"test_em": 29.41176470588235, "test_f1": 36.93091453761643}, {"test_em": 33.850931677018636, "test_f1": 40.06176041905937}]}, "total": {"test_em": 28.46493739809286, "test_em_se": 1.3070436692428573, "test_f1": 34.90134136301289, "test_f1_se": 1.4258153567057272}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_em": 30.673896204492642, "test_f1": 37.328963116926005}, {"test_em": 24.8062015503876, "test_f1": 31.542794573961896}, {"test_em": 28.516228748068006, "test_f1": 34.73296953552545}, {"test_em": 22.66355140186916, "test_f1": 29.371283389023617}, {"test_em": 22.16216216216216, "test_f1": 28.786541887662985}, {"test_em": 25.751734772552044, "test_f1": 33.36553615559226}, {"test_em": 29.23310554290053, "test_f1": 35.552214284951795}, {"test_em": 26.377036462373933, "test_f1": 33.6703600928417}, {"test_em": 31.058823529411764, "test_f1": 37.530443909819674}, {"test_em": 22.593167701863354, "test_f1": 30.062816494960842}]}, "total": {"test_em": 26.38359080760812, "test_em_se": 2.0850066754482803, "test_f1": 33.19439234412662, "test_f1_se": 1.967154536321641}}, "num_model_parameters": 134735618, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.7602863907814026, "test_mcc": 0.484576267432985, "test_macro_f1": 0.49384798328391755, "test_runtime": 29.3249, "test_samples_per_second": 69.838, "test_steps_per_second": 34.919}, {"test_loss": 0.7010371088981628, "test_mcc": 0.5179805510674385, "test_macro_f1": 0.5130668934240363, "test_runtime": 28.6626, "test_samples_per_second": 71.452, "test_steps_per_second": 35.726}, {"test_loss": 0.7661088109016418, "test_mcc": 0.4691726903501473, "test_macro_f1": 0.49406556874762025, "test_runtime": 28.8415, "test_samples_per_second": 71.009, "test_steps_per_second": 35.504}, {"test_loss": 0.7004254460334778, "test_mcc": 0.5285977684484112, "test_macro_f1": 0.5166536425216552, "test_runtime": 28.419, "test_samples_per_second": 72.064, "test_steps_per_second": 36.032}, {"test_loss": 0.7118685245513916, "test_mcc": 0.5439038894373328, "test_macro_f1": 0.5234148456909146, "test_runtime": 28.5539, "test_samples_per_second": 71.724, "test_steps_per_second": 35.862}, {"test_loss": 0.7014220952987671, "test_mcc": 0.5339120813722936, "test_macro_f1": 0.5189770928641081, "test_runtime": 28.8345, "test_samples_per_second": 71.026, "test_steps_per_second": 35.513}, {"test_loss": 0.7376218438148499, "test_mcc": 0.4995524874671961, "test_macro_f1": 0.5055545596631915, "test_runtime": 28.741, "test_samples_per_second": 71.257, "test_steps_per_second": 35.629}, {"test_loss": 0.7407304644584656, "test_mcc": 0.48050464773937174, "test_macro_f1": 0.49810852303194575, "test_runtime": 29.2582, "test_samples_per_second": 69.997, "test_steps_per_second": 34.999}, {"test_loss": 0.7072020173072815, "test_mcc": 0.5328292985698195, "test_macro_f1": 0.5192121360736582, "test_runtime": 29.031, "test_samples_per_second": 70.545, "test_steps_per_second": 35.273}, {"test_loss": 0.6431993246078491, "test_mcc": 0.5840928549946722, "test_macro_f1": 0.5485395233944316, "test_runtime": 29.0244, "test_samples_per_second": 70.561, "test_steps_per_second": 35.281}]}, "total": {"test_mcc": 51.75122536879668, "test_mcc_se": 2.1539972698371512, "test_macro_f1": 51.31440768695479, "test_macro_f1_se": 1.0250240141293574}}, "num_model_parameters": 132085251, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 1.0428112745285034, "test_mcc": 0.1594273457878059, "test_macro_f1": 0.379486209320864, "test_runtime": 7.3895, "test_samples_per_second": 277.149, "test_steps_per_second": 8.661}, {"test_loss": 1.010837435722351, "test_mcc": 0.23383454777181947, "test_macro_f1": 0.3841214999525679, "test_runtime": 7.4495, "test_samples_per_second": 274.919, "test_steps_per_second": 8.591}, {"test_loss": 1.0622724294662476, "test_mcc": 0.17090510846943546, "test_macro_f1": 0.37533036188199453, "test_runtime": 7.4043, "test_samples_per_second": 276.595, "test_steps_per_second": 8.644}, {"test_loss": 1.0457243919372559, "test_mcc": 0.16198133811092952, "test_macro_f1": 0.35306322208946317, "test_runtime": 7.4661, "test_samples_per_second": 274.305, "test_steps_per_second": 8.572}, {"test_loss": 1.0507322549819946, "test_mcc": 0.17998580091962318, "test_macro_f1": 0.36285094702352655, "test_runtime": 7.3184, "test_samples_per_second": 279.841, "test_steps_per_second": 8.745}, {"test_loss": 1.0486409664154053, "test_mcc": 0.18828174210605364, "test_macro_f1": 0.36211748149861805, "test_runtime": 7.2514, "test_samples_per_second": 282.427, "test_steps_per_second": 8.826}, {"test_loss": 1.0318055152893066, "test_mcc": 0.23354172393499903, "test_macro_f1": 0.3844846297676487, "test_runtime": 7.3302, "test_samples_per_second": 279.393, "test_steps_per_second": 8.731}, {"test_loss": 1.0712339878082275, "test_mcc": 0.14059766033417725, "test_macro_f1": 0.34220783564251617, "test_runtime": 7.3347, "test_samples_per_second": 279.219, "test_steps_per_second": 8.726}, {"test_loss": 1.0354641675949097, "test_mcc": 0.20544289372689398, "test_macro_f1": 0.38295584832673546, "test_runtime": 7.3583, "test_samples_per_second": 278.324, "test_steps_per_second": 8.698}, {"test_loss": 1.037922739982605, "test_mcc": 0.19185832518455817, "test_macro_f1": 0.37881031385141717, "test_runtime": 7.4006, "test_samples_per_second": 276.735, "test_steps_per_second": 8.648}]}, "total": {"test_mcc": 18.658564863462956, "test_mcc_se": 1.9127032602963938, "test_macro_f1": 37.05428349355351, "test_macro_f1_se": 0.9106100436437521}}, "num_model_parameters": 132085251, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.9962972402572632, "test_mcc": 0.16135570387524859, "test_macro_f1": 0.36301926158399905, "test_runtime": 6.5995, "test_samples_per_second": 310.329, "test_steps_per_second": 9.698}, {"test_loss": 0.969057023525238, "test_mcc": 0.21620325172535937, "test_macro_f1": 0.4076838876969024, "test_runtime": 6.1751, "test_samples_per_second": 331.654, "test_steps_per_second": 10.364}, {"test_loss": 0.9679567813873291, "test_mcc": 0.2156992981256765, "test_macro_f1": 0.35157618402082935, "test_runtime": 6.109, "test_samples_per_second": 335.244, "test_steps_per_second": 10.476}, {"test_loss": 0.9930045008659363, "test_mcc": 0.1339303915699602, "test_macro_f1": 0.34949836115500504, "test_runtime": 6.2301, "test_samples_per_second": 328.724, "test_steps_per_second": 10.273}, {"test_loss": 0.9807533025741577, "test_mcc": 0.1814819117083646, "test_macro_f1": 0.37572758639418447, "test_runtime": 6.3876, "test_samples_per_second": 320.622, "test_steps_per_second": 10.019}, {"test_loss": 1.0407600402832031, "test_mcc": 0.11780523691324775, "test_macro_f1": 0.33165542707391144, "test_runtime": 6.4904, "test_samples_per_second": 315.544, "test_steps_per_second": 9.861}, {"test_loss": 0.9643416404724121, "test_mcc": 0.18514686127332167, "test_macro_f1": 0.35794241600693216, "test_runtime": 6.1396, "test_samples_per_second": 333.573, "test_steps_per_second": 10.424}, {"test_loss": 0.9675336480140686, "test_mcc": 0.17869875055946335, "test_macro_f1": 0.3678816851051745, "test_runtime": 6.304, "test_samples_per_second": 324.872, "test_steps_per_second": 10.152}, {"test_loss": 0.9898120164871216, "test_mcc": 0.11588518284165271, "test_macro_f1": 0.3243332123217504, "test_runtime": 6.5056, "test_samples_per_second": 314.804, "test_steps_per_second": 9.838}, {"test_loss": 1.0024044513702393, "test_mcc": 0.026274851147410273, "test_macro_f1": 0.263304688677823, "test_runtime": 6.4489, "test_samples_per_second": 317.573, "test_steps_per_second": 9.924}]}, "total": {"test_mcc": 15.324814397397052, "test_mcc_se": 3.550866073465632, "test_macro_f1": 34.92622710036512, "test_macro_f1_se": 2.3601846674557114}}, "num_model_parameters": 132085251, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.1207769364118576, "test_micro_f1": 0.2236266407389402, "test_micro_f1_no_misc": 0.23821853961677888, "test_runtime": 11.2233, "test_samples_per_second": 182.477, "test_steps_per_second": 5.702}, {"test_loss": 0.11789143830537796, "test_micro_f1": 0.206, "test_micro_f1_no_misc": 0.21787414066631414, "test_runtime": 10.6293, "test_samples_per_second": 192.674, "test_steps_per_second": 6.021}, {"test_loss": 0.11468742787837982, "test_micro_f1": 0.1813975011568718, "test_micro_f1_no_misc": 0.18983050847457628, "test_runtime": 10.7027, "test_samples_per_second": 191.354, "test_steps_per_second": 5.98}, {"test_loss": 0.12131817638874054, "test_micro_f1": 0.19509939898289416, "test_micro_f1_no_misc": 0.2046556741028128, "test_runtime": 11.0942, "test_samples_per_second": 184.601, "test_steps_per_second": 5.769}, {"test_loss": 0.12521323561668396, "test_micro_f1": 0.18450515002239137, "test_micro_f1_no_misc": 0.19370004701457452, "test_runtime": 10.9383, "test_samples_per_second": 187.232, "test_steps_per_second": 5.851}, {"test_loss": 0.12348521500825882, "test_micro_f1": 0.2030501089324619, "test_micro_f1_no_misc": 0.2160407974038016, "test_runtime": 9.2758, "test_samples_per_second": 220.789, "test_steps_per_second": 6.9}, {"test_loss": 0.12968853116035461, "test_micro_f1": 0.1846989588048891, "test_micro_f1_no_misc": 0.19484240687679083, "test_runtime": 10.2399, "test_samples_per_second": 200.002, "test_steps_per_second": 6.25}, {"test_loss": 0.11165647208690643, "test_micro_f1": 0.19826264690853343, "test_micro_f1_no_misc": 0.2086021505376344, "test_runtime": 10.9994, "test_samples_per_second": 186.193, "test_steps_per_second": 5.819}, {"test_loss": 0.11892926692962646, "test_micro_f1": 0.1821412705464238, "test_micro_f1_no_misc": 0.19123134328358207, "test_runtime": 10.6219, "test_samples_per_second": 192.81, "test_steps_per_second": 6.025}, {"test_loss": 0.12278792262077332, "test_micro_f1": 0.20940959409594093, "test_micro_f1_no_misc": 0.2207097715119105, "test_runtime": 11.0103, "test_samples_per_second": 186.008, "test_steps_per_second": 5.813}]}, "total": {"test_micro_f1": 19.681912701893467, "test_micro_f1_se": 0.8660341696276516, "test_micro_f1_no_misc": 20.75705379488776, "test_micro_f1_no_misc_se": 0.9768334940813996}}, "num_model_parameters": 132089865, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.1664884388446808, "test_micro_f1": 0.466864490603363, "test_micro_f1_no_misc": 0.49582689335394126, "test_runtime": 12.4683, "test_samples_per_second": 164.256, "test_steps_per_second": 5.133}, {"test_loss": 0.1983679234981537, "test_micro_f1": 0.2673267326732673, "test_micro_f1_no_misc": 0.3061020340113371, "test_runtime": 10.4415, "test_samples_per_second": 196.141, "test_steps_per_second": 6.129}, {"test_loss": 0.21481965482234955, "test_micro_f1": 0.07116692830978545, "test_micro_f1_no_misc": 0.08126680609501047, "test_runtime": 12.5515, "test_samples_per_second": 163.168, "test_steps_per_second": 5.099}, {"test_loss": 0.16790805757045746, "test_micro_f1": 0.42712392829306306, "test_micro_f1_no_misc": 0.46511627906976744, "test_runtime": 12.1355, "test_samples_per_second": 168.761, "test_steps_per_second": 5.274}, {"test_loss": 0.1590775102376938, "test_micro_f1": 0.429573348918761, "test_micro_f1_no_misc": 0.46375766318067074, "test_runtime": 12.7231, "test_samples_per_second": 160.967, "test_steps_per_second": 5.03}, {"test_loss": 0.210414320230484, "test_micro_f1": 0.21217197096594081, "test_micro_f1_no_misc": 0.2437459910198845, "test_runtime": 12.7203, "test_samples_per_second": 161.003, "test_steps_per_second": 5.031}, {"test_loss": 0.1494593769311905, "test_micro_f1": 0.5089960886571057, "test_micro_f1_no_misc": 0.5359171399933176, "test_runtime": 12.7576, "test_samples_per_second": 160.532, "test_steps_per_second": 5.017}, {"test_loss": 0.19424986839294434, "test_micro_f1": 0.2076595744680851, "test_micro_f1_no_misc": 0.23735408560311286, "test_runtime": 12.1732, "test_samples_per_second": 168.238, "test_steps_per_second": 5.257}, {"test_loss": 0.20136982202529907, "test_micro_f1": 0.22064832470716425, "test_micro_f1_no_misc": 0.2541575149042987, "test_runtime": 12.0829, "test_samples_per_second": 169.496, "test_steps_per_second": 5.297}, {"test_loss": 0.1963237076997757, "test_micro_f1": 0.2410738255033557, "test_micro_f1_no_misc": 0.2762227007074746, "test_runtime": 10.1529, "test_samples_per_second": 201.715, "test_steps_per_second": 6.304}]}, "total": {"test_micro_f1": 30.526052130998917, "test_micro_f1_se": 8.853516555387003, "test_micro_f1_no_misc": 33.59467107938815, "test_micro_f1_no_misc_se": 9.071709881052453}}, "num_model_parameters": 132089865, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.11249189078807831, "test_micro_f1": 0.48145454545454547, "test_micro_f1_no_misc": 0.5178643115214774, "test_runtime": 10.0598, "test_samples_per_second": 203.582, "test_steps_per_second": 6.362}, {"test_loss": 0.12646865844726562, "test_micro_f1": 0.31223922114047287, "test_micro_f1_no_misc": 0.33026848105921297, "test_runtime": 9.999, "test_samples_per_second": 204.82, "test_steps_per_second": 6.401}, {"test_loss": 0.11969311535358429, "test_micro_f1": 0.4363390746369469, "test_micro_f1_no_misc": 0.46015146051208083, "test_runtime": 10.0698, "test_samples_per_second": 203.38, "test_steps_per_second": 6.356}, {"test_loss": 0.12831012904644012, "test_micro_f1": 0.3724696356275304, "test_micro_f1_no_misc": 0.3954072479368496, "test_runtime": 9.9734, "test_samples_per_second": 205.347, "test_steps_per_second": 6.417}, {"test_loss": 0.1334315538406372, "test_micro_f1": 0.38609034774130646, "test_micro_f1_no_misc": 0.4065821049022969, "test_runtime": 10.1287, "test_samples_per_second": 202.197, "test_steps_per_second": 6.319}, {"test_loss": 0.12034928798675537, "test_micro_f1": 0.4659738518270198, "test_micro_f1_no_misc": 0.4879105016239625, "test_runtime": 10.2084, "test_samples_per_second": 200.62, "test_steps_per_second": 6.269}, {"test_loss": 0.1280001997947693, "test_micro_f1": 0.4282881692002644, "test_micro_f1_no_misc": 0.45204513399153734, "test_runtime": 9.6593, "test_samples_per_second": 212.023, "test_steps_per_second": 6.626}, {"test_loss": 0.13361670076847076, "test_micro_f1": 0.34077636551013396, "test_micro_f1_no_misc": 0.35479256080114446, "test_runtime": 9.9053, "test_samples_per_second": 206.757, "test_steps_per_second": 6.461}, {"test_loss": 0.13776636123657227, "test_micro_f1": 0.25016329196603526, "test_micro_f1_no_misc": 0.26404688038607377, "test_runtime": 9.8416, "test_samples_per_second": 208.096, "test_steps_per_second": 6.503}, {"test_loss": 0.12438688427209854, "test_micro_f1": 0.4676165803108808, "test_micro_f1_no_misc": 0.4980842911877395, "test_runtime": 9.2211, "test_samples_per_second": 222.099, "test_steps_per_second": 6.941}]}, "total": {"test_micro_f1": 39.41411083415136, "test_micro_f1_se": 4.708929558840403, "test_micro_f1_no_misc": 41.67152973922376, "test_micro_f1_no_misc_se": 5.070284598003565}}, "num_model_parameters": 132089865, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.12997616827487946, "test_micro_f1": 0.43600734843845684, "test_micro_f1_no_misc": 0.46009693053311795, "test_runtime": 9.4322, "test_samples_per_second": 217.129, "test_steps_per_second": 6.785}, {"test_loss": 0.13999131321907043, "test_micro_f1": 0.4609991235758107, "test_micro_f1_no_misc": 0.4964766175528507, "test_runtime": 9.7381, "test_samples_per_second": 210.308, "test_steps_per_second": 6.572}, {"test_loss": 0.12620604038238525, "test_micro_f1": 0.4913194444444445, "test_micro_f1_no_misc": 0.5359477124183005, "test_runtime": 9.5293, "test_samples_per_second": 214.916, "test_steps_per_second": 6.716}, {"test_loss": 0.1756567656993866, "test_micro_f1": 0.22273916836289617, "test_micro_f1_no_misc": 0.23693164243736467, "test_runtime": 9.5211, "test_samples_per_second": 215.101, "test_steps_per_second": 6.722}, {"test_loss": 0.13293057680130005, "test_micro_f1": 0.4818560380725759, "test_micro_f1_no_misc": 0.5186161449752884, "test_runtime": 9.2391, "test_samples_per_second": 221.666, "test_steps_per_second": 6.927}, {"test_loss": 0.1332283318042755, "test_micro_f1": 0.5065088757396451, "test_micro_f1_no_misc": 0.5365697860108591, "test_runtime": 8.9258, "test_samples_per_second": 229.447, "test_steps_per_second": 7.17}, {"test_loss": 0.11920838057994843, "test_micro_f1": 0.48713235294117646, "test_micro_f1_no_misc": 0.5226364846870839, "test_runtime": 9.9548, "test_samples_per_second": 205.73, "test_steps_per_second": 6.429}, {"test_loss": 0.13089558482170105, "test_micro_f1": 0.44010647737355807, "test_micro_f1_no_misc": 0.4790652385589094, "test_runtime": 9.7478, "test_samples_per_second": 210.099, "test_steps_per_second": 6.566}, {"test_loss": 0.1270444691181183, "test_micro_f1": 0.5063291139240506, "test_micro_f1_no_misc": 0.5346869712351946, "test_runtime": 8.9632, "test_samples_per_second": 228.491, "test_steps_per_second": 7.14}, {"test_loss": 0.131157785654068, "test_micro_f1": 0.472197442759441, "test_micro_f1_no_misc": 0.5030517185994218, "test_runtime": 9.4242, "test_samples_per_second": 217.313, "test_steps_per_second": 6.791}]}, "total": {"test_micro_f1": 45.05195385632056, "test_micro_f1_se": 5.1864671128834, "test_micro_f1_no_misc": 48.24079247008391, "test_micro_f1_no_misc_se": 5.576502950142886}}, "num_model_parameters": 132089865, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.6945394277572632, "test_mcc": -0.004153486780686185, "test_macro_f1": 0.47654797703999124, "test_runtime": 6.2365, "test_samples_per_second": 328.387, "test_steps_per_second": 10.262}, {"test_loss": 0.6926968097686768, "test_mcc": 0.053910229383033345, "test_macro_f1": 0.4474061977357301, "test_runtime": 6.4894, "test_samples_per_second": 315.592, "test_steps_per_second": 9.862}, {"test_loss": 0.6934112310409546, "test_mcc": -0.0014831303507810306, "test_macro_f1": 0.45847111456915, "test_runtime": 6.4918, "test_samples_per_second": 315.475, "test_steps_per_second": 9.859}, {"test_loss": 0.6947414875030518, "test_mcc": 0.008777512582052355, "test_macro_f1": 0.4950406223896344, "test_runtime": 6.3482, "test_samples_per_second": 322.609, "test_steps_per_second": 10.082}, {"test_loss": 0.6939824819564819, "test_mcc": -0.011355169788944117, "test_macro_f1": 0.48586619612031434, "test_runtime": 6.4362, "test_samples_per_second": 318.198, "test_steps_per_second": 9.944}, {"test_loss": 0.6937477588653564, "test_mcc": -0.02363752746639291, "test_macro_f1": 0.4838966828675841, "test_runtime": 6.2836, "test_samples_per_second": 325.928, "test_steps_per_second": 10.185}, {"test_loss": 0.6930944919586182, "test_mcc": 0.00661986895841048, "test_macro_f1": 0.39474515201813687, "test_runtime": 6.5329, "test_samples_per_second": 313.491, "test_steps_per_second": 9.797}, {"test_loss": 0.6939771175384521, "test_mcc": -0.026821183076957245, "test_macro_f1": 0.45672354309315977, "test_runtime": 6.346, "test_samples_per_second": 322.721, "test_steps_per_second": 10.085}, {"test_loss": 0.6929506659507751, "test_mcc": 0.022666450385804306, "test_macro_f1": 0.4833689943590741, "test_runtime": 6.3376, "test_samples_per_second": 323.15, "test_steps_per_second": 10.098}, {"test_loss": 0.6933566331863403, "test_mcc": 0.0028309587322287444, "test_macro_f1": 0.46672730521220784, "test_runtime": 6.4173, "test_samples_per_second": 319.138, "test_steps_per_second": 9.973}]}, "total": {"test_mcc": 0.2735452257776774, "test_mcc_se": 1.446308705209376, "test_macro_f1": 46.48793785404983, "test_macro_f1_se": 1.7922002976789684}}, "num_model_parameters": 132084482, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.6928999423980713, "test_mcc": 0.027841286151115634, "test_macro_f1": 0.455806767394823, "test_runtime": 6.6023, "test_samples_per_second": 310.194, "test_steps_per_second": 9.694}, {"test_loss": 0.6935621500015259, "test_mcc": -0.010316599074952977, "test_macro_f1": 0.4845791260642997, "test_runtime": 7.019, "test_samples_per_second": 291.778, "test_steps_per_second": 9.118}, {"test_loss": 0.6925616264343262, "test_mcc": -0.012000567041897519, "test_macro_f1": 0.39356036917012527, "test_runtime": 6.8426, "test_samples_per_second": 299.301, "test_steps_per_second": 9.353}, {"test_loss": 0.6946784257888794, "test_mcc": -0.030706825988219007, "test_macro_f1": 0.4812085482682388, "test_runtime": 7.0822, "test_samples_per_second": 289.177, "test_steps_per_second": 9.037}, {"test_loss": 0.6926620602607727, "test_mcc": 0.02693223486670931, "test_macro_f1": 0.5126620149099662, "test_runtime": 6.8419, "test_samples_per_second": 299.334, "test_steps_per_second": 9.354}, {"test_loss": 0.6926599740982056, "test_mcc": 0.01095244569294412, "test_macro_f1": 0.43448622758292854, "test_runtime": 6.784, "test_samples_per_second": 301.886, "test_steps_per_second": 9.434}, {"test_loss": 0.6928625702857971, "test_mcc": 0.03286810711118521, "test_macro_f1": 0.5159124906819933, "test_runtime": 6.5051, "test_samples_per_second": 314.832, "test_steps_per_second": 9.838}, {"test_loss": 0.6937781572341919, "test_mcc": -0.022324074362693944, "test_macro_f1": 0.3992705428019738, "test_runtime": 6.7236, "test_samples_per_second": 304.599, "test_steps_per_second": 9.519}, {"test_loss": 0.6931413412094116, "test_mcc": 0.023491392900053355, "test_macro_f1": 0.4998618584161758, "test_runtime": 6.6827, "test_samples_per_second": 306.462, "test_steps_per_second": 9.577}, {"test_loss": 0.6942875385284424, "test_mcc": -0.03845124822239834, "test_macro_f1": 0.33181076672104404, "test_runtime": 6.8184, "test_samples_per_second": 300.365, "test_steps_per_second": 9.386}]}, "total": {"test_mcc": 0.08286152031845836, "test_mcc_se": 1.654875188481766, "test_macro_f1": 45.09158712011568, "test_macro_f1_se": 3.7485902278103675}}, "num_model_parameters": 132084482, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.6936946511268616, "test_mcc": -0.057028032782437295, "test_macro_f1": 0.45686663780793013, "test_runtime": 6.3443, "test_samples_per_second": 322.809, "test_steps_per_second": 10.088}, {"test_loss": 0.6957772970199585, "test_mcc": -0.03518338365074001, "test_macro_f1": 0.44354981145569294, "test_runtime": 6.2712, "test_samples_per_second": 326.573, "test_steps_per_second": 10.205}, {"test_loss": 0.6928354501724243, "test_mcc": 0.02700558150727893, "test_macro_f1": 0.5131324032282409, "test_runtime": 6.2911, "test_samples_per_second": 325.54, "test_steps_per_second": 10.173}, {"test_loss": 0.6933253407478333, "test_mcc": 0.005973832100857313, "test_macro_f1": 0.4933620015201505, "test_runtime": 6.4196, "test_samples_per_second": 319.021, "test_steps_per_second": 9.969}, {"test_loss": 0.6944742202758789, "test_mcc": -0.0371573374336877, "test_macro_f1": 0.4605919653328563, "test_runtime": 6.3658, "test_samples_per_second": 321.719, "test_steps_per_second": 10.054}, {"test_loss": 0.6920162439346313, "test_mcc": 0.04649997649869125, "test_macro_f1": 0.47182045937809214, "test_runtime": 6.1024, "test_samples_per_second": 335.605, "test_steps_per_second": 10.488}, {"test_loss": 0.6939404606819153, "test_mcc": 0.03194266226804445, "test_macro_f1": 0.4310461620428512, "test_runtime": 6.1535, "test_samples_per_second": 332.816, "test_steps_per_second": 10.401}, {"test_loss": 0.6937112212181091, "test_mcc": -0.0007805266897754876, "test_macro_f1": 0.4805194805194805, "test_runtime": 6.1693, "test_samples_per_second": 331.968, "test_steps_per_second": 10.374}, {"test_loss": 0.6950644254684448, "test_mcc": 0.008928529469511502, "test_macro_f1": 0.47596919001864657, "test_runtime": 6.0902, "test_samples_per_second": 336.278, "test_steps_per_second": 10.509}, {"test_loss": 0.6940818428993225, "test_mcc": -0.03251030188398961, "test_macro_f1": 0.48305880163065784, "test_runtime": 6.3901, "test_samples_per_second": 320.494, "test_steps_per_second": 10.015}]}, "total": {"test_mcc": -0.42309000596246654, "test_mcc_se": 2.144739871009534, "test_macro_f1": 47.09916912934599, "test_macro_f1_se": 1.4890411466914564}}, "num_model_parameters": 132084482, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_loss": 0.6927496194839478, "test_mcc": 0.01002556250098703, "test_macro_f1": 0.5047786864836912, "test_runtime": 6.3262, "test_samples_per_second": 323.732, "test_steps_per_second": 10.117}, {"test_loss": 0.6925306916236877, "test_mcc": 0.03944114394293188, "test_macro_f1": 0.5179616214982694, "test_runtime": 6.5875, "test_samples_per_second": 310.892, "test_steps_per_second": 9.715}, {"test_loss": 0.6930465698242188, "test_mcc": 0.02747576734928908, "test_macro_f1": 0.49703210772450096, "test_runtime": 6.5717, "test_samples_per_second": 311.637, "test_steps_per_second": 9.739}, {"test_loss": 0.6951622366905212, "test_mcc": -0.00871391090418254, "test_macro_f1": 0.48419650666115044, "test_runtime": 6.2225, "test_samples_per_second": 329.127, "test_steps_per_second": 10.285}, {"test_loss": 0.6884704232215881, "test_mcc": 0.12650507058725044, "test_macro_f1": 0.5543998052296427, "test_runtime": 6.5169, "test_samples_per_second": 314.262, "test_steps_per_second": 9.821}, {"test_loss": 0.692710280418396, "test_mcc": -0.003334636465020889, "test_macro_f1": 0.49666088703109534, "test_runtime": 6.4955, "test_samples_per_second": 315.294, "test_steps_per_second": 9.853}, {"test_loss": 0.693914532661438, "test_mcc": 0.026487186080408304, "test_macro_f1": 0.5127722999312084, "test_runtime": 6.3324, "test_samples_per_second": 323.416, "test_steps_per_second": 10.107}, {"test_loss": 0.692091703414917, "test_mcc": -0.0131406471088291, "test_macro_f1": 0.4932317590124899, "test_runtime": 6.5401, "test_samples_per_second": 313.143, "test_steps_per_second": 9.786}, {"test_loss": 0.6941704750061035, "test_mcc": -0.007985699342620877, "test_macro_f1": 0.49382362598056234, "test_runtime": 6.3974, "test_samples_per_second": 320.131, "test_steps_per_second": 10.004}, {"test_loss": 0.6929523944854736, "test_mcc": 0.004426071380682333, "test_macro_f1": 0.3775091064093622, "test_runtime": 6.5171, "test_samples_per_second": 314.252, "test_steps_per_second": 9.82}]}, "total": {"test_mcc": 2.011859080208956, "test_mcc_se": 2.5648347808445338, "test_macro_f1": 49.32366405961972, "test_macro_f1_se": 2.8000634969112532}}, "num_model_parameters": 132084482, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.6004585027694702, "test_mcc": 0.6055323025223548, "test_macro_f1": 0.6142997283222021, "test_runtime": 14.474, "test_samples_per_second": 141.496, "test_steps_per_second": 17.687}, {"test_loss": 0.5928646326065063, "test_mcc": 0.6111598879613688, "test_macro_f1": 0.5494847997373515, "test_runtime": 13.722, "test_samples_per_second": 149.25, "test_steps_per_second": 18.656}, {"test_loss": 0.6258002519607544, "test_mcc": 0.6098383593224799, "test_macro_f1": 0.6165171263179673, "test_runtime": 14.1928, "test_samples_per_second": 144.298, "test_steps_per_second": 18.037}, {"test_loss": 0.5642857551574707, "test_mcc": 0.6453710286523325, "test_macro_f1": 0.6554275306555502, "test_runtime": 13.4601, "test_samples_per_second": 152.153, "test_steps_per_second": 19.019}, {"test_loss": 0.5796818733215332, "test_mcc": 0.6233656783179744, "test_macro_f1": 0.5567893952620931, "test_runtime": 13.3828, "test_samples_per_second": 153.032, "test_steps_per_second": 19.129}, {"test_loss": 0.6213676929473877, "test_mcc": 0.6305686452134084, "test_macro_f1": 0.6224618241105188, "test_runtime": 13.8177, "test_samples_per_second": 148.216, "test_steps_per_second": 18.527}, {"test_loss": 0.5798491835594177, "test_mcc": 0.6377234705122596, "test_macro_f1": 0.5597872422749103, "test_runtime": 13.2913, "test_samples_per_second": 154.086, "test_steps_per_second": 19.261}, {"test_loss": 0.5844169855117798, "test_mcc": 0.595772619731775, "test_macro_f1": 0.6169912472792874, "test_runtime": 14.2966, "test_samples_per_second": 143.25, "test_steps_per_second": 17.906}, {"test_loss": 0.651258111000061, "test_mcc": 0.57129598606367, "test_macro_f1": 0.5361765110835742, "test_runtime": 14.1979, "test_samples_per_second": 144.247, "test_steps_per_second": 18.031}, {"test_loss": 0.5837907195091248, "test_mcc": 0.6364466629169652, "test_macro_f1": 0.5839936502059145, "test_runtime": 13.865, "test_samples_per_second": 147.71, "test_steps_per_second": 18.464}]}, "total": {"test_mcc": 61.67074641214588, "test_mcc_se": 1.4001296229906766, "test_macro_f1": 59.11929055249369, "test_macro_f1_se": 2.438670652226301}}, "num_model_parameters": 124443651, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.9924870729446411, "test_mcc": 0.27512303120304876, "test_macro_f1": 0.510616937233353, "test_runtime": 4.5509, "test_samples_per_second": 450.016, "test_steps_per_second": 14.063}, {"test_loss": 1.0257976055145264, "test_mcc": 0.24879750357292144, "test_macro_f1": 0.42656880156880156, "test_runtime": 4.5287, "test_samples_per_second": 452.232, "test_steps_per_second": 14.132}, {"test_loss": 1.0292551517486572, "test_mcc": 0.2389864319268633, "test_macro_f1": 0.43342968413169025, "test_runtime": 4.4902, "test_samples_per_second": 456.102, "test_steps_per_second": 14.253}, {"test_loss": 1.0070526599884033, "test_mcc": 0.2720816694903194, "test_macro_f1": 0.469823813991666, "test_runtime": 4.5526, "test_samples_per_second": 449.851, "test_steps_per_second": 14.058}, {"test_loss": 1.0494221448898315, "test_mcc": 0.1963505365044899, "test_macro_f1": 0.36741402462462763, "test_runtime": 4.5634, "test_samples_per_second": 448.788, "test_steps_per_second": 14.025}, {"test_loss": 1.0447888374328613, "test_mcc": 0.19281119898498014, "test_macro_f1": 0.38974129004373764, "test_runtime": 4.5266, "test_samples_per_second": 452.438, "test_steps_per_second": 14.139}, {"test_loss": 0.9948545694351196, "test_mcc": 0.2610374308723886, "test_macro_f1": 0.4704301055112365, "test_runtime": 4.5784, "test_samples_per_second": 447.319, "test_steps_per_second": 13.979}, {"test_loss": 1.0223426818847656, "test_mcc": 0.23463751922660492, "test_macro_f1": 0.44416588205744273, "test_runtime": 4.5672, "test_samples_per_second": 448.414, "test_steps_per_second": 14.013}, {"test_loss": 1.0296826362609863, "test_mcc": 0.2372989354409639, "test_macro_f1": 0.4752415101977938, "test_runtime": 4.5455, "test_samples_per_second": 450.554, "test_steps_per_second": 14.08}, {"test_loss": 1.012134313583374, "test_mcc": 0.25347989799388815, "test_macro_f1": 0.49099457799007556, "test_runtime": 4.5257, "test_samples_per_second": 452.523, "test_steps_per_second": 14.141}]}, "total": {"test_mcc": 24.106041552164687, "test_mcc_se": 1.7436083717462119, "test_macro_f1": 44.784266273504244, "test_macro_f1_se": 2.7768682647322835}}, "num_model_parameters": 124443651, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.9954994320869446, "test_mcc": 0.27169174200857066, "test_macro_f1": 0.4975883194488883, "test_runtime": 4.0066, "test_samples_per_second": 511.15, "test_steps_per_second": 15.973}, {"test_loss": 0.9361206889152527, "test_mcc": 0.2038811776026754, "test_macro_f1": 0.4211547211496572, "test_runtime": 3.7451, "test_samples_per_second": 546.845, "test_steps_per_second": 17.089}, {"test_loss": 0.9681470990180969, "test_mcc": 0.21189724159450946, "test_macro_f1": 0.42966705068261773, "test_runtime": 3.7393, "test_samples_per_second": 547.694, "test_steps_per_second": 17.115}, {"test_loss": 0.9764333963394165, "test_mcc": 0.23442928477442174, "test_macro_f1": 0.39102824113978607, "test_runtime": 3.8573, "test_samples_per_second": 530.941, "test_steps_per_second": 16.592}, {"test_loss": 0.9931416511535645, "test_mcc": 0.26047145776472647, "test_macro_f1": 0.48121139789240974, "test_runtime": 3.8253, "test_samples_per_second": 535.387, "test_steps_per_second": 16.731}, {"test_loss": 0.9730346202850342, "test_mcc": 0.17787498107996047, "test_macro_f1": 0.38012594537869493, "test_runtime": 3.9462, "test_samples_per_second": 518.979, "test_steps_per_second": 16.218}, {"test_loss": 0.9731416702270508, "test_mcc": 0.20310078217259098, "test_macro_f1": 0.43370224296986776, "test_runtime": 3.7483, "test_samples_per_second": 546.376, "test_steps_per_second": 17.074}, {"test_loss": 0.9616117477416992, "test_mcc": 0.22427740982627367, "test_macro_f1": 0.397844887075622, "test_runtime": 3.8656, "test_samples_per_second": 529.804, "test_steps_per_second": 16.556}, {"test_loss": 0.9916977286338806, "test_mcc": 0.22942205905552804, "test_macro_f1": 0.4771265018449455, "test_runtime": 3.9219, "test_samples_per_second": 522.196, "test_steps_per_second": 16.319}, {"test_loss": 0.9282536506652832, "test_mcc": 0.30432995840900784, "test_macro_f1": 0.5164441973455559, "test_runtime": 3.9317, "test_samples_per_second": 520.898, "test_steps_per_second": 16.278}]}, "total": {"test_mcc": 23.213760942882647, "test_mcc_se": 2.3236219474694937, "test_macro_f1": 44.258935049280446, "test_macro_f1_se": 2.9531536937910854}}, "num_model_parameters": 124443651, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.12761475145816803, "test_micro_f1": 0.4070066975785677, "test_micro_f1_no_misc": 0.4383714445064138, "test_runtime": 6.6493, "test_samples_per_second": 308.004, "test_steps_per_second": 9.625}, {"test_loss": 0.12013993412256241, "test_micro_f1": 0.47202983484283434, "test_micro_f1_no_misc": 0.5370716510903427, "test_runtime": 6.3356, "test_samples_per_second": 323.255, "test_steps_per_second": 10.102}, {"test_loss": 0.11258505284786224, "test_micro_f1": 0.4683673469387755, "test_micro_f1_no_misc": 0.5135440180586907, "test_runtime": 6.4088, "test_samples_per_second": 319.562, "test_steps_per_second": 9.986}, {"test_loss": 0.11564445495605469, "test_micro_f1": 0.4240809802876931, "test_micro_f1_no_misc": 0.4703791469194313, "test_runtime": 6.6432, "test_samples_per_second": 308.284, "test_steps_per_second": 9.634}, {"test_loss": 0.12000350654125214, "test_micro_f1": 0.48133198789101916, "test_micro_f1_no_misc": 0.5149375339489408, "test_runtime": 6.5483, "test_samples_per_second": 312.752, "test_steps_per_second": 9.774}, {"test_loss": 0.12400416284799576, "test_micro_f1": 0.4658981748318924, "test_micro_f1_no_misc": 0.5248618784530387, "test_runtime": 5.548, "test_samples_per_second": 369.141, "test_steps_per_second": 11.536}, {"test_loss": 0.12288478016853333, "test_micro_f1": 0.503177966101695, "test_micro_f1_no_misc": 0.5468208092485549, "test_runtime": 5.954, "test_samples_per_second": 343.97, "test_steps_per_second": 10.749}, {"test_loss": 0.09660910069942474, "test_micro_f1": 0.4973419964559953, "test_micro_f1_no_misc": 0.5370843989769821, "test_runtime": 6.5717, "test_samples_per_second": 311.641, "test_steps_per_second": 9.739}, {"test_loss": 0.10668189823627472, "test_micro_f1": 0.4495774647887324, "test_micro_f1_no_misc": 0.49440993788819876, "test_runtime": 6.1461, "test_samples_per_second": 333.22, "test_steps_per_second": 10.413}, {"test_loss": 0.10632991790771484, "test_micro_f1": 0.4986087924318309, "test_micro_f1_no_misc": 0.5350929814037193, "test_runtime": 6.5402, "test_samples_per_second": 313.138, "test_steps_per_second": 9.786}]}, "total": {"test_micro_f1": 46.67421242149036, "test_micro_f1_se": 1.9823585550850948, "test_micro_f1_no_misc": 51.12573800494313, "test_micro_f1_no_misc_se": 2.1308469780080865}}, "num_model_parameters": 123857673, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.20773737132549286, "test_micro_f1": 0.4614953794455335, "test_micro_f1_no_misc": 0.4461479494059027, "test_runtime": 8.8988, "test_samples_per_second": 230.144, "test_steps_per_second": 7.192}, {"test_loss": 0.1903776377439499, "test_micro_f1": 0.4194641207268247, "test_micro_f1_no_misc": 0.41376518218623487, "test_runtime": 7.0764, "test_samples_per_second": 289.411, "test_steps_per_second": 9.044}, {"test_loss": 0.19540289044380188, "test_micro_f1": 0.46953508518625464, "test_micro_f1_no_misc": 0.47147385103011097, "test_runtime": 8.2289, "test_samples_per_second": 248.878, "test_steps_per_second": 7.777}, {"test_loss": 0.19205915927886963, "test_micro_f1": 0.4346606842400449, "test_micro_f1_no_misc": 0.42023633677991135, "test_runtime": 8.1194, "test_samples_per_second": 252.237, "test_steps_per_second": 7.882}, {"test_loss": 0.20311814546585083, "test_micro_f1": 0.44288, "test_micro_f1_no_misc": 0.44696016771488467, "test_runtime": 8.5466, "test_samples_per_second": 239.629, "test_steps_per_second": 7.488}, {"test_loss": 0.2028675228357315, "test_micro_f1": 0.45735707591377694, "test_micro_f1_no_misc": 0.4401019541206457, "test_runtime": 8.1482, "test_samples_per_second": 251.343, "test_steps_per_second": 7.854}, {"test_loss": 0.1909908950328827, "test_micro_f1": 0.4663088849135361, "test_micro_f1_no_misc": 0.4551560647965231, "test_runtime": 8.5805, "test_samples_per_second": 238.682, "test_steps_per_second": 7.459}, {"test_loss": 0.19009748101234436, "test_micro_f1": 0.461869618696187, "test_micro_f1_no_misc": 0.45420944558521564, "test_runtime": 8.6248, "test_samples_per_second": 237.455, "test_steps_per_second": 7.42}, {"test_loss": 0.19308577477931976, "test_micro_f1": 0.4232437120555074, "test_micro_f1_no_misc": 0.40528977051730847, "test_runtime": 8.0714, "test_samples_per_second": 253.736, "test_steps_per_second": 7.929}, {"test_loss": 0.18077439069747925, "test_micro_f1": 0.47593261131167264, "test_micro_f1_no_misc": 0.45644461962948363, "test_runtime": 7.7729, "test_samples_per_second": 263.48, "test_steps_per_second": 8.234}]}, "total": {"test_micro_f1": 45.127471724893375, "test_micro_f1_se": 1.2336304646823255, "test_micro_f1_no_misc": 44.09785341766221, "test_micro_f1_no_misc_se": 1.3152928762780396}}, "num_model_parameters": 123857673, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.17453759908676147, "test_micro_f1": 0.4606109324758843, "test_micro_f1_no_misc": 0.4901185770750988, "test_runtime": 6.9958, "test_samples_per_second": 292.745, "test_steps_per_second": 9.148}, {"test_loss": 0.17642900347709656, "test_micro_f1": 0.4523527085804666, "test_micro_f1_no_misc": 0.49153278332609646, "test_runtime": 6.9273, "test_samples_per_second": 295.642, "test_steps_per_second": 9.239}, {"test_loss": 0.16912628710269928, "test_micro_f1": 0.44998194293968946, "test_micro_f1_no_misc": 0.48398576512455516, "test_runtime": 6.5747, "test_samples_per_second": 311.498, "test_steps_per_second": 9.734}, {"test_loss": 0.16005803644657135, "test_micro_f1": 0.4530929946743138, "test_micro_f1_no_misc": 0.4853333333333333, "test_runtime": 6.8297, "test_samples_per_second": 299.866, "test_steps_per_second": 9.371}, {"test_loss": 0.1720820665359497, "test_micro_f1": 0.4775697633345108, "test_micro_f1_no_misc": 0.5108527131782945, "test_runtime": 6.9157, "test_samples_per_second": 296.14, "test_steps_per_second": 9.254}, {"test_loss": 0.1653822660446167, "test_micro_f1": 0.447141738449491, "test_micro_f1_no_misc": 0.4741744284504657, "test_runtime": 6.8834, "test_samples_per_second": 297.529, "test_steps_per_second": 9.298}, {"test_loss": 0.16564390063285828, "test_micro_f1": 0.4677966101694915, "test_micro_f1_no_misc": 0.50020601565719, "test_runtime": 6.4736, "test_samples_per_second": 316.362, "test_steps_per_second": 9.886}, {"test_loss": 0.16627156734466553, "test_micro_f1": 0.4704974932510606, "test_micro_f1_no_misc": 0.49691484985602624, "test_runtime": 6.76, "test_samples_per_second": 302.959, "test_steps_per_second": 9.467}, {"test_loss": 0.15292075276374817, "test_micro_f1": 0.4372344534569332, "test_micro_f1_no_misc": 0.47341337907375647, "test_runtime": 6.6708, "test_samples_per_second": 307.01, "test_steps_per_second": 9.594}, {"test_loss": 0.17697715759277344, "test_micro_f1": 0.49447809048806557, "test_micro_f1_no_misc": 0.5238461538461539, "test_runtime": 6.8035, "test_samples_per_second": 301.02, "test_steps_per_second": 9.407}]}, "total": {"test_micro_f1": 46.10756727819907, "test_micro_f1_se": 1.0427528660314087, "test_micro_f1_no_misc": 49.30377998920971, "test_micro_f1_no_misc_se": 0.9747528380989998}}, "num_model_parameters": 123857673, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.18768340349197388, "test_micro_f1": 0.41302887844190733, "test_micro_f1_no_misc": 0.4380610412926391, "test_runtime": 6.2923, "test_samples_per_second": 325.477, "test_steps_per_second": 10.171}, {"test_loss": 0.18448123335838318, "test_micro_f1": 0.4666879183933695, "test_micro_f1_no_misc": 0.49826989619377166, "test_runtime": 6.315, "test_samples_per_second": 324.305, "test_steps_per_second": 10.135}, {"test_loss": 0.18830114603042603, "test_micro_f1": 0.43546441495778043, "test_micro_f1_no_misc": 0.4652061855670103, "test_runtime": 6.2205, "test_samples_per_second": 329.233, "test_steps_per_second": 10.289}, {"test_loss": 0.19209030270576477, "test_micro_f1": 0.398406374501992, "test_micro_f1_no_misc": 0.4288777698355969, "test_runtime": 6.278, "test_samples_per_second": 326.218, "test_steps_per_second": 10.194}, {"test_loss": 0.18874382972717285, "test_micro_f1": 0.42347879532882604, "test_micro_f1_no_misc": 0.46071547977265126, "test_runtime": 6.1882, "test_samples_per_second": 330.954, "test_steps_per_second": 10.342}, {"test_loss": 0.1901756376028061, "test_micro_f1": 0.4076897580377859, "test_micro_f1_no_misc": 0.4389721627408994, "test_runtime": 6.3247, "test_samples_per_second": 323.808, "test_steps_per_second": 10.119}, {"test_loss": 0.18507227301597595, "test_micro_f1": 0.4563011456628478, "test_micro_f1_no_misc": 0.4875131902919452, "test_runtime": 6.3575, "test_samples_per_second": 322.137, "test_steps_per_second": 10.067}, {"test_loss": 0.1871500015258789, "test_micro_f1": 0.3706865884027037, "test_micro_f1_no_misc": 0.3981658387466565, "test_runtime": 6.332, "test_samples_per_second": 323.439, "test_steps_per_second": 10.107}, {"test_loss": 0.18656307458877563, "test_micro_f1": 0.46778042959427213, "test_micro_f1_no_misc": 0.4990689013035381, "test_runtime": 6.0163, "test_samples_per_second": 340.409, "test_steps_per_second": 10.638}, {"test_loss": 0.18753103911876678, "test_micro_f1": 0.4618763727643552, "test_micro_f1_no_misc": 0.4960548885077187, "test_runtime": 6.0869, "test_samples_per_second": 336.461, "test_steps_per_second": 10.514}]}, "total": {"test_micro_f1": 43.0140067608584, "test_micro_f1_se": 2.0510308431661226, "test_micro_f1_no_misc": 46.10905354252427, "test_micro_f1_no_misc_se": 2.1450001755168473}}, "num_model_parameters": 123857673, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.6911829113960266, "test_mcc": 0.0473548180648024, "test_macro_f1": 0.5196603268097124, "test_runtime": 3.2096, "test_samples_per_second": 638.086, "test_steps_per_second": 19.94}, {"test_loss": 0.6913381814956665, "test_mcc": 0.06339132789479114, "test_macro_f1": 0.511278905707016, "test_runtime": 3.281, "test_samples_per_second": 624.2, "test_steps_per_second": 19.506}, {"test_loss": 0.6953182220458984, "test_mcc": -0.004218070160003394, "test_macro_f1": 0.3904294611329332, "test_runtime": 3.3096, "test_samples_per_second": 618.797, "test_steps_per_second": 19.337}, {"test_loss": 0.6924421191215515, "test_mcc": 0.016295344602314136, "test_macro_f1": 0.4972936641112617, "test_runtime": 3.17, "test_samples_per_second": 646.051, "test_steps_per_second": 20.189}, {"test_loss": 0.6924725770950317, "test_mcc": 0.03765376065153881, "test_macro_f1": 0.513713862120089, "test_runtime": 3.2685, "test_samples_per_second": 626.593, "test_steps_per_second": 19.581}, {"test_loss": 0.6942280530929565, "test_mcc": 0.007716707394338825, "test_macro_f1": 0.4723601916776038, "test_runtime": 3.2164, "test_samples_per_second": 636.746, "test_steps_per_second": 19.898}, {"test_loss": 0.6910924911499023, "test_mcc": 0.0617953315809289, "test_macro_f1": 0.49192395674787215, "test_runtime": 3.2594, "test_samples_per_second": 628.33, "test_steps_per_second": 19.635}, {"test_loss": 0.6934509873390198, "test_mcc": 0.033255947111353906, "test_macro_f1": 0.5085221835210905, "test_runtime": 3.3103, "test_samples_per_second": 618.673, "test_steps_per_second": 19.334}, {"test_loss": 0.6938877105712891, "test_mcc": -0.0032210989133633744, "test_macro_f1": 0.47524906678456413, "test_runtime": 3.2734, "test_samples_per_second": 625.653, "test_steps_per_second": 19.552}, {"test_loss": 0.6925101280212402, "test_mcc": 0.026500516713859057, "test_macro_f1": 0.5114835440617606, "test_runtime": 3.2086, "test_samples_per_second": 638.285, "test_steps_per_second": 19.946}]}, "total": {"test_mcc": 2.8652458494056043, "test_mcc_se": 1.52511889194303, "test_macro_f1": 48.91915162673903, "test_macro_f1_se": 2.3730390370836685}}, "num_model_parameters": 124442882, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.6918919086456299, "test_mcc": 0.045285308231930624, "test_macro_f1": 0.5168018492406199, "test_runtime": 3.9487, "test_samples_per_second": 518.658, "test_steps_per_second": 16.208}, {"test_loss": 0.6938289403915405, "test_mcc": 0.0, "test_macro_f1": 0.32830436208592984, "test_runtime": 4.1224, "test_samples_per_second": 496.802, "test_steps_per_second": 15.525}, {"test_loss": 0.6922813653945923, "test_mcc": 0.060629538344910326, "test_macro_f1": 0.5299306515404453, "test_runtime": 4.0168, "test_samples_per_second": 509.861, "test_steps_per_second": 15.933}, {"test_loss": 0.6933000087738037, "test_mcc": 0.012697880171693147, "test_macro_f1": 0.5005365330211686, "test_runtime": 4.2167, "test_samples_per_second": 485.686, "test_steps_per_second": 15.178}, {"test_loss": 0.6926710605621338, "test_mcc": 0.016472966832543276, "test_macro_f1": 0.5022915545368721, "test_runtime": 4.009, "test_samples_per_second": 510.854, "test_steps_per_second": 15.964}, {"test_loss": 0.6927990317344666, "test_mcc": 0.02732301045212663, "test_macro_f1": 0.5024179378333411, "test_runtime": 3.9884, "test_samples_per_second": 513.488, "test_steps_per_second": 16.046}, {"test_loss": 0.6922494173049927, "test_mcc": 0.03803501468021212, "test_macro_f1": 0.415182690313078, "test_runtime": 3.9363, "test_samples_per_second": 520.289, "test_steps_per_second": 16.259}, {"test_loss": 0.6933969855308533, "test_mcc": 0.02842295980789222, "test_macro_f1": 0.45834377569487467, "test_runtime": 3.9546, "test_samples_per_second": 517.872, "test_steps_per_second": 16.184}, {"test_loss": 0.6931805610656738, "test_mcc": 0.03593559201704557, "test_macro_f1": 0.49822202424528056, "test_runtime": 3.9557, "test_samples_per_second": 517.737, "test_steps_per_second": 16.179}, {"test_loss": 0.6938469409942627, "test_mcc": 0.025723918187386924, "test_macro_f1": 0.4456042145076321, "test_runtime": 4.1008, "test_samples_per_second": 499.418, "test_steps_per_second": 15.607}]}, "total": {"test_mcc": 2.9052618872574087, "test_mcc_se": 1.0681368329480343, "test_macro_f1": 46.976355930192426, "test_macro_f1_se": 3.7767967503243285}}, "num_model_parameters": 124442882, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.6930170655250549, "test_mcc": 0.024876220940675695, "test_macro_f1": 0.5121066348262362, "test_runtime": 3.6971, "test_samples_per_second": 553.942, "test_steps_per_second": 17.311}, {"test_loss": 0.6929351091384888, "test_mcc": 0.008458933068027913, "test_macro_f1": 0.41057295743443967, "test_runtime": 3.718, "test_samples_per_second": 550.828, "test_steps_per_second": 17.213}, {"test_loss": 0.6913250684738159, "test_mcc": 0.03074539196712023, "test_macro_f1": 0.513358144861151, "test_runtime": 3.7547, "test_samples_per_second": 545.456, "test_steps_per_second": 17.046}, {"test_loss": 0.6915866136550903, "test_mcc": 0.06567405738456503, "test_macro_f1": 0.45558557048498816, "test_runtime": 3.8464, "test_samples_per_second": 532.44, "test_steps_per_second": 16.639}, {"test_loss": 0.6940659880638123, "test_mcc": -0.00030529154853365086, "test_macro_f1": 0.34195975788277894, "test_runtime": 3.7845, "test_samples_per_second": 541.154, "test_steps_per_second": 16.911}, {"test_loss": 0.6933176517486572, "test_mcc": 0.032909149969264154, "test_macro_f1": 0.35869431133463014, "test_runtime": 3.6179, "test_samples_per_second": 566.067, "test_steps_per_second": 17.69}, {"test_loss": 0.6929705739021301, "test_mcc": 0.028648927852465454, "test_macro_f1": 0.4749455552729449, "test_runtime": 3.7482, "test_samples_per_second": 546.401, "test_steps_per_second": 17.075}, {"test_loss": 0.692081093788147, "test_mcc": 0.041097623988576235, "test_macro_f1": 0.5194740810632568, "test_runtime": 3.706, "test_samples_per_second": 552.618, "test_steps_per_second": 17.269}, {"test_loss": 0.6937522888183594, "test_mcc": -0.020203753028958285, "test_macro_f1": 0.4207938873069178, "test_runtime": 3.6394, "test_samples_per_second": 562.736, "test_steps_per_second": 17.585}, {"test_loss": 0.6929563283920288, "test_mcc": 0.014307385267423032, "test_macro_f1": 0.4993064971091059, "test_runtime": 3.7667, "test_samples_per_second": 543.709, "test_steps_per_second": 16.991}]}, "total": {"test_mcc": 2.262086458606258, "test_mcc_se": 1.4663629295275074, "test_macro_f1": 45.06797397576449, "test_macro_f1_se": 4.037739411002488}}, "num_model_parameters": 124442882, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_loss": 0.6938496232032776, "test_mcc": -0.022068971010806397, "test_macro_f1": 0.4106143714112748, "test_runtime": 3.7872, "test_samples_per_second": 540.771, "test_steps_per_second": 16.899}, {"test_loss": 0.6931479573249817, "test_mcc": 0.009948358147595643, "test_macro_f1": 0.39058628467156664, "test_runtime": 3.9644, "test_samples_per_second": 516.601, "test_steps_per_second": 16.144}, {"test_loss": 0.6933301687240601, "test_mcc": -0.022145694838175328, "test_macro_f1": 0.3326816552623004, "test_runtime": 3.9397, "test_samples_per_second": 519.834, "test_steps_per_second": 16.245}, {"test_loss": 0.6932610273361206, "test_mcc": -0.020493366496084683, "test_macro_f1": 0.4338174710080346, "test_runtime": 3.707, "test_samples_per_second": 552.469, "test_steps_per_second": 17.265}, {"test_loss": 0.6925844550132751, "test_mcc": 0.010980722669630443, "test_macro_f1": 0.49326426685487423, "test_runtime": 3.7992, "test_samples_per_second": 539.055, "test_steps_per_second": 16.845}, {"test_loss": 0.6916428208351135, "test_mcc": 0.04021616822591025, "test_macro_f1": 0.4681874992416061, "test_runtime": 3.8716, "test_samples_per_second": 528.975, "test_steps_per_second": 16.53}, {"test_loss": 0.6922136545181274, "test_mcc": 0.038397909625605464, "test_macro_f1": 0.5189366740508745, "test_runtime": 3.8236, "test_samples_per_second": 535.618, "test_steps_per_second": 16.738}, {"test_loss": 0.6947958469390869, "test_mcc": -0.03563560313505474, "test_macro_f1": 0.4811358910217529, "test_runtime": 3.8571, "test_samples_per_second": 530.964, "test_steps_per_second": 16.593}, {"test_loss": 0.6969650387763977, "test_mcc": -0.031196749126322292, "test_macro_f1": 0.43912363067292637, "test_runtime": 3.8305, "test_samples_per_second": 534.657, "test_steps_per_second": 16.708}, {"test_loss": 0.6936902403831482, "test_mcc": -0.03396422440154395, "test_macro_f1": 0.4816681046879494, "test_runtime": 3.8888, "test_samples_per_second": 526.646, "test_steps_per_second": 16.458}]}, "total": {"test_mcc": -0.659614503392456, "test_mcc_se": 1.8094320809328526, "test_macro_f1": 44.5001584888316, "test_macro_f1_se": 3.4510782797245287}}, "num_model_parameters": 124442882, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_em": 29.27962819519752, "test_f1": 35.05578866865385}, {"test_em": 28.837209302325583, "test_f1": 35.66268461660501}, {"test_em": 21.715610510046368, "test_f1": 28.15427450955323}, {"test_em": 24.221183800623052, "test_f1": 29.779917374395104}, {"test_em": 28.8030888030888, "test_f1": 34.79362114852377}, {"test_em": 22.8218966846569, "test_f1": 29.399916426146135}, {"test_em": 20.88078967350038, "test_f1": 26.931820740628414}, {"test_em": 24.980605120248253, "test_f1": 31.34037040210258}, {"test_em": 30.666666666666668, "test_f1": 37.537231037577065}, {"test_em": 22.127329192546583, "test_f1": 28.550876701061565}]}, "total": {"test_em": 25.43340079489001, "test_em_se": 2.254653582038221, "test_f1": 31.72065016252467, "test_f1_se": 2.309279620014086}}, "num_model_parameters": 123852290, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_em": 22.773044151820294, "test_f1": 30.772518318877164}, {"test_em": 23.565891472868216, "test_f1": 29.897692643966685}, {"test_em": 19.55177743431221, "test_f1": 26.193789244370297}, {"test_em": 19.470404984423677, "test_f1": 25.681708963406564}, {"test_em": 25.637065637065636, "test_f1": 32.11383283431053}, {"test_em": 23.20740169622205, "test_f1": 30.94375082629714}, {"test_em": 24.297646165527716, "test_f1": 31.195757162689862}, {"test_em": 26.997672614429792, "test_f1": 33.55086404707275}, {"test_em": 19.686274509803923, "test_f1": 27.28528176485311}, {"test_em": 21.506211180124225, "test_f1": 30.02358478853462}]}, "total": {"test_em": 22.669338984659777, "test_em_se": 1.6202302993746367, "test_f1": 29.76587805943787, "test_f1_se": 1.599822113136033}}, "num_model_parameters": 123852290, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_em": 31.913245546088305, "test_f1": 39.5332282396454}, {"test_em": 24.573643410852714, "test_f1": 32.149588365834894}, {"test_em": 24.497681607418855, "test_f1": 32.036165585679555}, {"test_em": 27.180685358255452, "test_f1": 33.97429424176085}, {"test_em": 25.01930501930502, "test_f1": 32.56691828067327}, {"test_em": 28.835774865073247, "test_f1": 35.47837842480144}, {"test_em": 29.23310554290053, "test_f1": 35.70303748737357}, {"test_em": 30.488750969743986, "test_f1": 37.90872049210649}, {"test_em": 28.235294117647058, "test_f1": 36.315734238174635}, {"test_em": 21.428571428571427, "test_f1": 28.79343960120908}]}, "total": {"test_em": 27.14060578658566, "test_em_se": 1.9939179565513347, "test_f1": 34.44595049572592, "test_f1_se": 1.9686688637108753}}, "num_model_parameters": 123852290, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.7364985942840576, "test_mcc": 0.5104410332725609, "test_macro_f1": 0.5101306609949593, "test_runtime": 14.5513, "test_samples_per_second": 140.743, "test_steps_per_second": 17.593}, {"test_loss": 0.8288907408714294, "test_mcc": 0.40707674885335443, "test_macro_f1": 0.460696723473528, "test_runtime": 13.8114, "test_samples_per_second": 148.284, "test_steps_per_second": 18.535}, {"test_loss": 0.7218541502952576, "test_mcc": 0.5095286685672836, "test_macro_f1": 0.5085251071429906, "test_runtime": 17.5257, "test_samples_per_second": 116.857, "test_steps_per_second": 58.428}, {"test_loss": 0.7750221490859985, "test_mcc": 0.4488122802761564, "test_macro_f1": 0.4836569808122291, "test_runtime": 17.1492, "test_samples_per_second": 119.422, "test_steps_per_second": 59.711}, {"test_loss": 0.803397536277771, "test_mcc": 0.434137407369637, "test_macro_f1": 0.4654839315216872, "test_runtime": 17.2423, "test_samples_per_second": 118.777, "test_steps_per_second": 59.389}, {"test_loss": 0.8065894246101379, "test_mcc": 0.40981224593341115, "test_macro_f1": 0.47014748855295546, "test_runtime": 17.3027, "test_samples_per_second": 118.363, "test_steps_per_second": 59.182}, {"test_loss": 0.7802754640579224, "test_mcc": 0.45317293163920086, "test_macro_f1": 0.48272353123006434, "test_runtime": 17.1914, "test_samples_per_second": 119.129, "test_steps_per_second": 59.565}, {"test_loss": 0.7584764361381531, "test_mcc": 0.46729917780978864, "test_macro_f1": 0.4909239230114344, "test_runtime": 17.5242, "test_samples_per_second": 116.867, "test_steps_per_second": 58.433}, {"test_loss": 0.8100336790084839, "test_mcc": 0.4173601585553885, "test_macro_f1": 0.4702802303563631, "test_runtime": 17.4818, "test_samples_per_second": 117.15, "test_steps_per_second": 58.575}, {"test_loss": 0.7909336090087891, "test_mcc": 0.43743477651076507, "test_macro_f1": 0.4749103653941506, "test_runtime": 17.4211, "test_samples_per_second": 117.559, "test_steps_per_second": 58.779}]}, "total": {"test_mcc": 44.95075428787546, "test_mcc_se": 2.3040930288263746, "test_macro_f1": 48.17478942490362, "test_macro_f1_se": 1.0599099305746003}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 1.0033890008926392, "test_mcc": 0.23909516396210492, "test_macro_f1": 0.47657120671145775, "test_runtime": 4.4002, "test_samples_per_second": 465.437, "test_steps_per_second": 14.545}, {"test_loss": 1.0590693950653076, "test_mcc": 0.17888185718805166, "test_macro_f1": 0.3379102663034881, "test_runtime": 4.3338, "test_samples_per_second": 472.56, "test_steps_per_second": 14.768}, {"test_loss": 1.0027422904968262, "test_mcc": 0.24865863211134254, "test_macro_f1": 0.49743297107450885, "test_runtime": 4.3435, "test_samples_per_second": 471.51, "test_steps_per_second": 14.735}, {"test_loss": 1.0042271614074707, "test_mcc": 0.26342834640121254, "test_macro_f1": 0.5049548272296498, "test_runtime": 4.327, "test_samples_per_second": 473.309, "test_steps_per_second": 14.791}, {"test_loss": 1.0337367057800293, "test_mcc": 0.24203949715608725, "test_macro_f1": 0.49265031880814775, "test_runtime": 4.2574, "test_samples_per_second": 481.049, "test_steps_per_second": 15.033}, {"test_loss": 1.0291037559509277, "test_mcc": 0.20569820997979307, "test_macro_f1": 0.4356831123916898, "test_runtime": 4.3511, "test_samples_per_second": 470.689, "test_steps_per_second": 14.709}, {"test_loss": 1.0321223735809326, "test_mcc": 0.19788336819511543, "test_macro_f1": 0.38093702110494276, "test_runtime": 4.3072, "test_samples_per_second": 475.486, "test_steps_per_second": 14.859}, {"test_loss": 1.0508646965026855, "test_mcc": 0.1641471105894933, "test_macro_f1": 0.3834403916367355, "test_runtime": 4.3636, "test_samples_per_second": 469.339, "test_steps_per_second": 14.667}, {"test_loss": 1.0315561294555664, "test_mcc": 0.19931667263902025, "test_macro_f1": 0.4579944106690223, "test_runtime": 4.3199, "test_samples_per_second": 474.087, "test_steps_per_second": 14.815}, {"test_loss": 0.9972329139709473, "test_mcc": 0.2673822591172788, "test_macro_f1": 0.5023344089897429, "test_runtime": 4.2884, "test_samples_per_second": 477.569, "test_steps_per_second": 14.924}]}, "total": {"test_mcc": 22.065311173395, "test_mcc_se": 2.2376308686407396, "test_macro_f1": 44.699089349193855, "test_macro_f1_se": 3.7232096371421477}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.9916173815727234, "test_mcc": 0.17534435114327443, "test_macro_f1": 0.3697886245229332, "test_runtime": 3.7078, "test_samples_per_second": 552.343, "test_steps_per_second": 17.261}, {"test_loss": 0.9758310317993164, "test_mcc": 0.08123632850522854, "test_macro_f1": 0.33268619826896945, "test_runtime": 3.4121, "test_samples_per_second": 600.222, "test_steps_per_second": 18.757}, {"test_loss": 0.9670118093490601, "test_mcc": 0.21534411808126053, "test_macro_f1": 0.3690181479171785, "test_runtime": 3.5647, "test_samples_per_second": 574.518, "test_steps_per_second": 17.954}, {"test_loss": 1.0000395774841309, "test_mcc": 0.18339869518574312, "test_macro_f1": 0.34168361518038237, "test_runtime": 3.5671, "test_samples_per_second": 574.142, "test_steps_per_second": 17.942}, {"test_loss": 0.9865160584449768, "test_mcc": 0.10770360901434019, "test_macro_f1": 0.3239625141258163, "test_runtime": 3.5631, "test_samples_per_second": 574.787, "test_steps_per_second": 17.962}, {"test_loss": 0.967533528804779, "test_mcc": 0.16621059156658818, "test_macro_f1": 0.36759797615984907, "test_runtime": 3.6671, "test_samples_per_second": 558.487, "test_steps_per_second": 17.453}, {"test_loss": 0.958582878112793, "test_mcc": 0.20399897654386198, "test_macro_f1": 0.37788765529468077, "test_runtime": 3.4957, "test_samples_per_second": 585.86, "test_steps_per_second": 18.308}, {"test_loss": 0.9631351232528687, "test_mcc": 0.09196947696990265, "test_macro_f1": 0.2759244337004208, "test_runtime": 3.5845, "test_samples_per_second": 571.351, "test_steps_per_second": 17.855}, {"test_loss": 0.9845606088638306, "test_mcc": 0.043532546109399835, "test_macro_f1": 0.25098784184981787, "test_runtime": 3.649, "test_samples_per_second": 561.243, "test_steps_per_second": 17.539}, {"test_loss": 1.031245231628418, "test_mcc": 0.0, "test_macro_f1": 0.2132181999335769, "test_runtime": 3.6837, "test_samples_per_second": 555.958, "test_steps_per_second": 17.374}]}, "total": {"test_mcc": 12.687386931195993, "test_mcc_se": 4.506505788879123, "test_macro_f1": 32.22755206953625, "test_macro_f1_se": 3.530476996174356}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.10800385475158691, "test_micro_f1": 0.40939597315436244, "test_micro_f1_no_misc": 0.4361593462717059, "test_runtime": 7.2841, "test_samples_per_second": 281.162, "test_steps_per_second": 8.786}, {"test_loss": 0.10102671384811401, "test_micro_f1": 0.44537815126050423, "test_micro_f1_no_misc": 0.4724233983286908, "test_runtime": 7.04, "test_samples_per_second": 290.908, "test_steps_per_second": 9.091}, {"test_loss": 0.10629279166460037, "test_micro_f1": 0.29067041725269577, "test_micro_f1_no_misc": 0.3043691703485518, "test_runtime": 6.5319, "test_samples_per_second": 313.536, "test_steps_per_second": 9.798}, {"test_loss": 0.11112204194068909, "test_micro_f1": 0.40266539742979535, "test_micro_f1_no_misc": 0.4246987951807229, "test_runtime": 7.2621, "test_samples_per_second": 282.014, "test_steps_per_second": 8.813}, {"test_loss": 0.10837435722351074, "test_micro_f1": 0.4066797642436149, "test_micro_f1_no_misc": 0.42901554404145076, "test_runtime": 7.2411, "test_samples_per_second": 282.828, "test_steps_per_second": 8.838}, {"test_loss": 0.10920967161655426, "test_micro_f1": 0.37342908438061045, "test_micro_f1_no_misc": 0.3980861244019139, "test_runtime": 5.9172, "test_samples_per_second": 346.111, "test_steps_per_second": 10.816}, {"test_loss": 0.11052651703357697, "test_micro_f1": 0.39078252520403267, "test_micro_f1_no_misc": 0.4120040691759919, "test_runtime": 6.0278, "test_samples_per_second": 339.762, "test_steps_per_second": 10.618}, {"test_loss": 0.09217598289251328, "test_micro_f1": 0.47371107708014293, "test_micro_f1_no_misc": 0.5024416711882799, "test_runtime": 6.9888, "test_samples_per_second": 293.04, "test_steps_per_second": 9.158}, {"test_loss": 0.10571525990962982, "test_micro_f1": 0.4242973708068903, "test_micro_f1_no_misc": 0.4459266317293949, "test_runtime": 6.5671, "test_samples_per_second": 311.857, "test_steps_per_second": 9.746}, {"test_loss": 0.10433854907751083, "test_micro_f1": 0.4293047130191321, "test_micro_f1_no_misc": 0.452755905511811, "test_runtime": 7.2659, "test_samples_per_second": 281.867, "test_steps_per_second": 8.808}]}, "total": {"test_micro_f1": 40.46314473831781, "test_micro_f1_se": 3.037196634373938, "test_micro_f1_no_misc": 42.77880656178514, "test_micro_f1_no_misc_se": 3.264220099107963}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.13301990926265717, "test_micro_f1": 0.5128991060025542, "test_micro_f1_no_misc": 0.5177763413057531, "test_runtime": 8.1296, "test_samples_per_second": 251.918, "test_steps_per_second": 7.872}, {"test_loss": 0.12248434126377106, "test_micro_f1": 0.5534766824909243, "test_micro_f1_no_misc": 0.573919360697421, "test_runtime": 6.7089, "test_samples_per_second": 305.265, "test_steps_per_second": 9.54}, {"test_loss": 0.12692824006080627, "test_micro_f1": 0.5271317829457365, "test_micro_f1_no_misc": 0.5449477351916376, "test_runtime": 8.173, "test_samples_per_second": 250.582, "test_steps_per_second": 7.831}, {"test_loss": 0.1242557093501091, "test_micro_f1": 0.5384414907479802, "test_micro_f1_no_misc": 0.55286800276434, "test_runtime": 7.8391, "test_samples_per_second": 261.254, "test_steps_per_second": 8.164}, {"test_loss": 0.13335129618644714, "test_micro_f1": 0.46336633663366344, "test_micro_f1_no_misc": 0.48705388383484954, "test_runtime": 8.15, "test_samples_per_second": 251.29, "test_steps_per_second": 7.853}, {"test_loss": 0.143828883767128, "test_micro_f1": 0.3966244725738397, "test_micro_f1_no_misc": 0.4198210598761184, "test_runtime": 8.1514, "test_samples_per_second": 251.244, "test_steps_per_second": 7.851}, {"test_loss": 0.1542607545852661, "test_micro_f1": 0.3299136069114471, "test_micro_f1_no_misc": 0.3697949036668739, "test_runtime": 8.2794, "test_samples_per_second": 247.36, "test_steps_per_second": 7.73}, {"test_loss": 0.12339993566274643, "test_micro_f1": 0.47816222348269993, "test_micro_f1_no_misc": 0.49356223175965663, "test_runtime": 8.157, "test_samples_per_second": 251.074, "test_steps_per_second": 7.846}, {"test_loss": 0.1517399251461029, "test_micro_f1": 0.40183883180097346, "test_micro_f1_no_misc": 0.4110326269761184, "test_runtime": 7.8729, "test_samples_per_second": 260.134, "test_steps_per_second": 8.129}, {"test_loss": 0.2887517511844635, "test_micro_f1": 0.0, "test_micro_f1_no_misc": 0.0, "test_runtime": 7.0295, "test_samples_per_second": 291.344, "test_steps_per_second": 9.104}]}, "total": {"test_micro_f1": 42.01854533589818, "test_micro_f1_se": 10.176215961694535, "test_micro_f1_no_misc": 43.70776146072769, "test_micro_f1_no_misc_se": 10.381822288804559}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.09539352357387543, "test_micro_f1": 0.5246347264695889, "test_micro_f1_no_misc": 0.556118754525706, "test_runtime": 6.3289, "test_samples_per_second": 323.593, "test_steps_per_second": 10.112}, {"test_loss": 0.08534904569387436, "test_micro_f1": 0.5454545454545454, "test_micro_f1_no_misc": 0.5732874091083047, "test_runtime": 6.3053, "test_samples_per_second": 324.804, "test_steps_per_second": 10.15}, {"test_loss": 0.1188659518957138, "test_micro_f1": 0.4036568213783403, "test_micro_f1_no_misc": 0.42692450725176645, "test_runtime": 5.8524, "test_samples_per_second": 349.94, "test_steps_per_second": 10.936}, {"test_loss": 0.08281463384628296, "test_micro_f1": 0.5697948200470906, "test_micro_f1_no_misc": 0.6035242290748899, "test_runtime": 5.8968, "test_samples_per_second": 347.308, "test_steps_per_second": 10.853}, {"test_loss": 0.1027020588517189, "test_micro_f1": 0.5161290322580645, "test_micro_f1_no_misc": 0.560741004631279, "test_runtime": 6.3916, "test_samples_per_second": 320.422, "test_steps_per_second": 10.013}, {"test_loss": 0.0917508602142334, "test_micro_f1": 0.5502998001332444, "test_micro_f1_no_misc": 0.5811051693404634, "test_runtime": 6.4017, "test_samples_per_second": 319.913, "test_steps_per_second": 9.997}, {"test_loss": 0.10103502869606018, "test_micro_f1": 0.5030181086519115, "test_micro_f1_no_misc": 0.5286944045911046, "test_runtime": 5.786, "test_samples_per_second": 353.961, "test_steps_per_second": 11.061}, {"test_loss": 0.10129137337207794, "test_micro_f1": 0.46914399469143997, "test_micro_f1_no_misc": 0.49131341209173035, "test_runtime": 5.7607, "test_samples_per_second": 355.514, "test_steps_per_second": 11.11}, {"test_loss": 0.08289659768342972, "test_micro_f1": 0.5778251599147121, "test_micro_f1_no_misc": 0.6089278901182755, "test_runtime": 5.8691, "test_samples_per_second": 348.945, "test_steps_per_second": 10.905}, {"test_loss": 0.08874916285276413, "test_micro_f1": 0.5924217462932455, "test_micro_f1_no_misc": 0.6239822353811992, "test_runtime": 6.3358, "test_samples_per_second": 323.245, "test_steps_per_second": 10.101}]}, "total": {"test_micro_f1": 52.52378755292184, "test_micro_f1_se": 3.5065659979975448, "test_micro_f1_no_misc": 55.546190161147194, "test_micro_f1_no_misc_se": 3.7085314998783905}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.10346385836601257, "test_micro_f1": 0.5312314098750743, "test_micro_f1_no_misc": 0.5644753476611882, "test_runtime": 5.8685, "test_samples_per_second": 348.983, "test_steps_per_second": 10.906}, {"test_loss": 0.11276376992464066, "test_micro_f1": 0.5227470298464213, "test_micro_f1_no_misc": 0.55456501690747, "test_runtime": 6.0788, "test_samples_per_second": 336.91, "test_steps_per_second": 10.528}, {"test_loss": 0.11433069407939911, "test_micro_f1": 0.48383303938859495, "test_micro_f1_no_misc": 0.515825759949859, "test_runtime": 5.9402, "test_samples_per_second": 344.771, "test_steps_per_second": 10.774}, {"test_loss": 0.12956136465072632, "test_micro_f1": 0.415921012033323, "test_micro_f1_no_misc": 0.4451783355350067, "test_runtime": 6.1396, "test_samples_per_second": 333.573, "test_steps_per_second": 10.424}, {"test_loss": 0.12159975618124008, "test_micro_f1": 0.5224635525141327, "test_micro_f1_no_misc": 0.5649497894395854, "test_runtime": 5.953, "test_samples_per_second": 344.027, "test_steps_per_second": 10.751}, {"test_loss": 0.11879170686006546, "test_micro_f1": 0.4774566473988439, "test_micro_f1_no_misc": 0.5119453924914675, "test_runtime": 6.0441, "test_samples_per_second": 338.845, "test_steps_per_second": 10.589}, {"test_loss": 0.1082836240530014, "test_micro_f1": 0.4620193810565802, "test_micro_f1_no_misc": 0.49250249916694433, "test_runtime": 6.06, "test_samples_per_second": 337.956, "test_steps_per_second": 10.561}, {"test_loss": 0.10685577988624573, "test_micro_f1": 0.5136004679730916, "test_micro_f1_no_misc": 0.5462555066079297, "test_runtime": 5.9739, "test_samples_per_second": 342.824, "test_steps_per_second": 10.713}, {"test_loss": 0.11259771138429642, "test_micro_f1": 0.4951456310679611, "test_micro_f1_no_misc": 0.5303867403314918, "test_runtime": 5.5551, "test_samples_per_second": 368.672, "test_steps_per_second": 11.521}, {"test_loss": 0.10131584107875824, "test_micro_f1": 0.5983112183353437, "test_micro_f1_no_misc": 0.6267787839586029, "test_runtime": 5.7946, "test_samples_per_second": 353.434, "test_steps_per_second": 11.045}]}, "total": {"test_micro_f1": 50.22729389489366, "test_micro_f1_se": 3.001125426118624, "test_micro_f1_no_misc": 53.528631720495454, "test_micro_f1_no_misc_se": 3.028832848972249}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.6930256485939026, "test_mcc": 0.03268502557866725, "test_macro_f1": 0.5153615710776704, "test_runtime": 3.2185, "test_samples_per_second": 636.328, "test_steps_per_second": 19.885}, {"test_loss": 0.6922380924224854, "test_mcc": 0.020841169418828385, "test_macro_f1": 0.48624913705909745, "test_runtime": 3.3959, "test_samples_per_second": 603.083, "test_steps_per_second": 18.846}, {"test_loss": 0.6967631578445435, "test_mcc": 0.030427660722006422, "test_macro_f1": 0.5090141925584963, "test_runtime": 3.3112, "test_samples_per_second": 618.506, "test_steps_per_second": 19.328}, {"test_loss": 0.6943167448043823, "test_mcc": 0.025574004759809976, "test_macro_f1": 0.512315666660291, "test_runtime": 3.2489, "test_samples_per_second": 630.361, "test_steps_per_second": 19.699}, {"test_loss": 0.6956491470336914, "test_mcc": 0.00391981908283613, "test_macro_f1": 0.4858288319034674, "test_runtime": 3.2805, "test_samples_per_second": 624.298, "test_steps_per_second": 19.509}, {"test_loss": 0.6925686597824097, "test_mcc": 0.025343390022669464, "test_macro_f1": 0.5034679659254891, "test_runtime": 3.2828, "test_samples_per_second": 623.855, "test_steps_per_second": 19.495}, {"test_loss": 0.6935451030731201, "test_mcc": -0.008278048563002662, "test_macro_f1": 0.492170891015266, "test_runtime": 3.2933, "test_samples_per_second": 621.865, "test_steps_per_second": 19.433}, {"test_loss": 0.6918695569038391, "test_mcc": 0.012501688087407616, "test_macro_f1": 0.4935230109755523, "test_runtime": 3.3349, "test_samples_per_second": 614.12, "test_steps_per_second": 19.191}, {"test_loss": 0.6929876804351807, "test_mcc": 0.03346346102620578, "test_macro_f1": 0.4896367349908842, "test_runtime": 3.3424, "test_samples_per_second": 612.735, "test_steps_per_second": 19.148}, {"test_loss": 0.6933650374412537, "test_mcc": -0.03374535331957946, "test_macro_f1": 0.3782204265714555, "test_runtime": 3.3495, "test_samples_per_second": 611.437, "test_steps_per_second": 19.107}]}, "total": {"test_mcc": 1.4273281681584893, "test_mcc_se": 1.33674851257355, "test_macro_f1": 48.657884287376696, "test_macro_f1_se": 2.454175833595741}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.6926542520523071, "test_mcc": 0.028454801983168437, "test_macro_f1": 0.51415077357594, "test_runtime": 3.6604, "test_samples_per_second": 559.5, "test_steps_per_second": 17.484}, {"test_loss": 0.6952788233757019, "test_mcc": 0.007818815896799641, "test_macro_f1": 0.4841873899641128, "test_runtime": 3.7594, "test_samples_per_second": 544.765, "test_steps_per_second": 17.024}, {"test_loss": 0.6925914287567139, "test_mcc": 0.005345513594477348, "test_macro_f1": 0.5005187974589902, "test_runtime": 3.693, "test_samples_per_second": 554.569, "test_steps_per_second": 17.33}, {"test_loss": 0.6947546005249023, "test_mcc": 0.014361247764577858, "test_macro_f1": 0.4456720625889429, "test_runtime": 3.8502, "test_samples_per_second": 531.924, "test_steps_per_second": 16.623}, {"test_loss": 0.6933563947677612, "test_mcc": 0.013133608970947454, "test_macro_f1": 0.5059913692216624, "test_runtime": 3.6868, "test_samples_per_second": 555.495, "test_steps_per_second": 17.359}, {"test_loss": 0.6908541917800903, "test_mcc": 0.0628680904190697, "test_macro_f1": 0.4672563991260319, "test_runtime": 3.6694, "test_samples_per_second": 558.129, "test_steps_per_second": 17.442}, {"test_loss": 0.6945969462394714, "test_mcc": 0.01094465302803986, "test_macro_f1": 0.39329795071612667, "test_runtime": 3.6537, "test_samples_per_second": 560.521, "test_steps_per_second": 17.516}, {"test_loss": 0.6955013871192932, "test_mcc": 0.03698395484004235, "test_macro_f1": 0.4148551163813554, "test_runtime": 3.6578, "test_samples_per_second": 559.896, "test_steps_per_second": 17.497}, {"test_loss": 0.6935733556747437, "test_mcc": 0.013951341060961069, "test_macro_f1": 0.4401903610652814, "test_runtime": 3.6779, "test_samples_per_second": 556.838, "test_steps_per_second": 17.401}, {"test_loss": 0.6968120336532593, "test_mcc": -0.030596539955484916, "test_macro_f1": 0.3699647156700055, "test_runtime": 3.7484, "test_samples_per_second": 546.359, "test_steps_per_second": 17.074}]}, "total": {"test_mcc": 1.6326548760259882, "test_mcc_se": 1.4874410951024108, "test_macro_f1": 45.360849357684494, "test_macro_f1_se": 3.072038693235033}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.6920127272605896, "test_mcc": 0.02345683150494123, "test_macro_f1": 0.49247776756287986, "test_runtime": 3.2896, "test_samples_per_second": 622.57, "test_steps_per_second": 19.455}, {"test_loss": 0.6944743394851685, "test_mcc": 0.03828614532651053, "test_macro_f1": 0.5148348386366624, "test_runtime": 3.2943, "test_samples_per_second": 621.673, "test_steps_per_second": 19.427}, {"test_loss": 0.6935190558433533, "test_mcc": 0.059774034755574953, "test_macro_f1": 0.4447900115216917, "test_runtime": 3.3511, "test_samples_per_second": 611.143, "test_steps_per_second": 19.098}, {"test_loss": 0.6922070384025574, "test_mcc": 0.028426290545315397, "test_macro_f1": 0.5052854894067627, "test_runtime": 3.4057, "test_samples_per_second": 601.339, "test_steps_per_second": 18.792}, {"test_loss": 0.694154679775238, "test_mcc": -0.006006816438588794, "test_macro_f1": 0.42095238095238097, "test_runtime": 3.4063, "test_samples_per_second": 601.246, "test_steps_per_second": 18.789}, {"test_loss": 0.6930780410766602, "test_mcc": 0.028284577537756685, "test_macro_f1": 0.4792440705749693, "test_runtime": 3.2965, "test_samples_per_second": 621.261, "test_steps_per_second": 19.414}, {"test_loss": 0.6916942000389099, "test_mcc": 0.0467659493078855, "test_macro_f1": 0.4347784607416897, "test_runtime": 3.2818, "test_samples_per_second": 624.039, "test_steps_per_second": 19.501}, {"test_loss": 0.6938815116882324, "test_mcc": 0.01492886978297969, "test_macro_f1": 0.48308584370368757, "test_runtime": 3.3329, "test_samples_per_second": 614.479, "test_steps_per_second": 19.202}, {"test_loss": 0.6935685873031616, "test_mcc": 0.01064839176557894, "test_macro_f1": 0.4941374347188483, "test_runtime": 3.2906, "test_samples_per_second": 622.372, "test_steps_per_second": 19.449}, {"test_loss": 0.6934041976928711, "test_mcc": 0.03463123606894293, "test_macro_f1": 0.5018625865196491, "test_runtime": 3.3428, "test_samples_per_second": 612.666, "test_steps_per_second": 19.146}]}, "total": {"test_mcc": 2.7919551015689708, "test_mcc_se": 1.1615309227291002, "test_macro_f1": 47.71448884339221, "test_macro_f1_se": 2.001620335603412}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_loss": 0.6907632350921631, "test_mcc": 0.05351176170617931, "test_macro_f1": 0.48751383650108326, "test_runtime": 3.5478, "test_samples_per_second": 577.255, "test_steps_per_second": 18.039}, {"test_loss": 0.6930848360061646, "test_mcc": 0.06361562905337764, "test_macro_f1": 0.3895460834515987, "test_runtime": 3.6075, "test_samples_per_second": 567.711, "test_steps_per_second": 17.741}, {"test_loss": 0.6951397657394409, "test_mcc": -0.04083469358933761, "test_macro_f1": 0.3928349967184918, "test_runtime": 3.652, "test_samples_per_second": 560.791, "test_steps_per_second": 17.525}, {"test_loss": 0.6927680373191833, "test_mcc": 0.013076224738319271, "test_macro_f1": 0.4545111556996107, "test_runtime": 3.4591, "test_samples_per_second": 592.058, "test_steps_per_second": 18.502}, {"test_loss": 0.6915856599807739, "test_mcc": -0.011911374574640945, "test_macro_f1": 0.4819572205050374, "test_runtime": 3.4825, "test_samples_per_second": 588.087, "test_steps_per_second": 18.378}, {"test_loss": 0.6948676705360413, "test_mcc": 0.018299066383893142, "test_macro_f1": 0.49600637151036014, "test_runtime": 3.63, "test_samples_per_second": 564.182, "test_steps_per_second": 17.631}, {"test_loss": 0.6932662725448608, "test_mcc": 0.029815821013016514, "test_macro_f1": 0.5048370294640651, "test_runtime": 3.5345, "test_samples_per_second": 579.424, "test_steps_per_second": 18.107}, {"test_loss": 0.6936507225036621, "test_mcc": 0.01611505821066099, "test_macro_f1": 0.48934302783678923, "test_runtime": 3.5524, "test_samples_per_second": 576.504, "test_steps_per_second": 18.016}, {"test_loss": 0.6941424608230591, "test_mcc": -0.02805297508428809, "test_macro_f1": 0.43810980262282095, "test_runtime": 3.507, "test_samples_per_second": 583.968, "test_steps_per_second": 18.249}, {"test_loss": 0.691790759563446, "test_mcc": 0.051909499298031805, "test_macro_f1": 0.5249116441548686, "test_runtime": 3.6158, "test_samples_per_second": 566.408, "test_steps_per_second": 17.7}]}, "total": {"test_mcc": 1.65544017155212, "test_mcc_se": 2.178199525906168, "test_macro_f1": 46.595711684647256, "test_macro_f1_se": 2.8664743189257447}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_em": 11.773818745158792, "test_f1": 19.75124662306283}, {"test_em": 12.48062015503876, "test_f1": 19.63002105614106}, {"test_em": 1.6228748068006182, "test_f1": 8.289486585927014}, {"test_em": 9.034267912772586, "test_f1": 17.406256445080228}, {"test_em": 11.505791505791505, "test_f1": 18.183555666268223}, {"test_em": 18.118735543562067, "test_f1": 23.865684992112584}, {"test_em": 3.1131359149582383, "test_f1": 10.705449815178504}, {"test_em": 1.2412723041117144, "test_f1": 9.983529290813392}, {"test_em": 9.647058823529411, "test_f1": 17.062368201159757}, {"test_em": 8.307453416149068, "test_f1": 16.517662872072012}]}, "total": {"test_em": 8.684502912787277, "test_em_se": 3.3212102965095776, "test_f1": 16.13952615478156, "test_f1_se": 3.0696065626247986}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_em": 28.195197521301317, "test_f1": 34.78511117269549}, {"test_em": 15.813953488372093, "test_f1": 23.711915743305006}, {"test_em": 17.465224111282843, "test_f1": 24.11320659404454}, {"test_em": 14.485981308411215, "test_f1": 21.27062811520225}, {"test_em": 17.99227799227799, "test_f1": 25.42402898859261}, {"test_em": 20.123361603700847, "test_f1": 26.337545766961256}, {"test_em": 4.6317388003037205, "test_f1": 14.323599126753763}, {"test_em": 5.3529868114817685, "test_f1": 13.811456557410754}, {"test_em": 8.392156862745098, "test_f1": 17.854785339010316}, {"test_em": 13.043478260869565, "test_f1": 21.153960593265648}]}, "total": {"test_em": 14.549635676074647, "test_em_se": 4.442420970563148, "test_f1": 22.278623799724162, "test_f1_se": 3.8376161319902145}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_em": 13.865220759101472, "test_f1": 22.10532140308776}, {"test_em": 15.03875968992248, "test_f1": 21.79271581721599}, {"test_em": 22.720247295208654, "test_f1": 29.31056491573207}, {"test_em": 13.473520249221183, "test_f1": 22.94446295864805}, {"test_em": 21.08108108108108, "test_f1": 27.38696209679615}, {"test_em": 14.417887432536624, "test_f1": 21.21942246658491}, {"test_em": 18.602885345482157, "test_f1": 25.627496888154752}, {"test_em": 7.757951900698216, "test_f1": 16.879462518950717}, {"test_em": 4.235294117647059, "test_f1": 11.841665997692077}, {"test_em": 10.248447204968944, "test_f1": 18.256044405942024}]}, "total": {"test_em": 14.144129507586788, "test_em_se": 3.561110392061523, "test_f1": 21.736411946880448, "test_f1_se": 3.2000790560175036}}, "num_model_parameters": 277454594, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 1.0508525371551514, "test_mcc": 0.1698036606977078, "test_macro_f1": 0.351893839023949, "test_runtime": 7.3851, "test_samples_per_second": 277.317, "test_steps_per_second": 8.666}, {"test_loss": 1.0315806865692139, "test_mcc": 0.2181886318629445, "test_macro_f1": 0.44511992281614504, "test_runtime": 7.2865, "test_samples_per_second": 281.069, "test_steps_per_second": 8.783}, {"test_loss": 1.0677130222320557, "test_mcc": 0.1583128006743993, "test_macro_f1": 0.3606358065054684, "test_runtime": 7.3511, "test_samples_per_second": 278.599, "test_steps_per_second": 8.706}, {"test_loss": 1.0572271347045898, "test_mcc": 0.18755944489580195, "test_macro_f1": 0.36332062793652414, "test_runtime": 7.3105, "test_samples_per_second": 280.146, "test_steps_per_second": 8.755}, {"test_loss": 1.039766550064087, "test_mcc": 0.18854612176507438, "test_macro_f1": 0.3802143134139088, "test_runtime": 7.3124, "test_samples_per_second": 280.072, "test_steps_per_second": 8.752}, {"test_loss": 1.0609768629074097, "test_mcc": 0.19848178130242666, "test_macro_f1": 0.42335591791854815, "test_runtime": 7.2856, "test_samples_per_second": 281.103, "test_steps_per_second": 8.784}, {"test_loss": 1.0325407981872559, "test_mcc": 0.20566263419813285, "test_macro_f1": 0.3738230858982908, "test_runtime": 7.3252, "test_samples_per_second": 279.581, "test_steps_per_second": 8.737}, {"test_loss": 1.0714327096939087, "test_mcc": 0.1359407986598775, "test_macro_f1": 0.33710483457950174, "test_runtime": 7.356, "test_samples_per_second": 278.411, "test_steps_per_second": 8.7}, {"test_loss": 1.0394229888916016, "test_mcc": 0.1852616161392127, "test_macro_f1": 0.36520428114865444, "test_runtime": 7.2858, "test_samples_per_second": 281.094, "test_steps_per_second": 8.784}, {"test_loss": 1.075648546218872, "test_mcc": 0.14799390524749073, "test_macro_f1": 0.34470751732024635, "test_runtime": 7.3216, "test_samples_per_second": 279.719, "test_steps_per_second": 8.741}]}, "total": {"test_mcc": 17.95751395443068, "test_mcc_se": 1.6208043730108084, "test_macro_f1": 37.45380146561237, "test_macro_f1_se": 2.127882183942416}}, "num_model_parameters": 132085251, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.9938336610794067, "test_mcc": 0.14749981718791313, "test_macro_f1": 0.3510245366579545, "test_runtime": 6.6194, "test_samples_per_second": 309.394, "test_steps_per_second": 9.669}, {"test_loss": 1.0035922527313232, "test_mcc": 0.2491337364742959, "test_macro_f1": 0.45133002346806234, "test_runtime": 6.0461, "test_samples_per_second": 338.729, "test_steps_per_second": 10.585}, {"test_loss": 0.9665629863739014, "test_mcc": 0.2193308748501156, "test_macro_f1": 0.3835901899282521, "test_runtime": 6.0706, "test_samples_per_second": 337.363, "test_steps_per_second": 10.543}, {"test_loss": 0.9940508008003235, "test_mcc": 0.1968822452769953, "test_macro_f1": 0.3783395318125679, "test_runtime": 6.2049, "test_samples_per_second": 330.061, "test_steps_per_second": 10.314}, {"test_loss": 0.9816946983337402, "test_mcc": 0.18031480776060424, "test_macro_f1": 0.3692534047539085, "test_runtime": 6.3246, "test_samples_per_second": 323.812, "test_steps_per_second": 10.119}, {"test_loss": 0.9808458089828491, "test_mcc": 0.0674082285962444, "test_macro_f1": 0.3162702602040783, "test_runtime": 6.478, "test_samples_per_second": 316.147, "test_steps_per_second": 9.88}, {"test_loss": 0.9775810837745667, "test_mcc": 0.013734406031896348, "test_macro_f1": 0.23087281729529754, "test_runtime": 6.1519, "test_samples_per_second": 332.906, "test_steps_per_second": 10.403}, {"test_loss": 0.9507485628128052, "test_mcc": 0.1993737665876054, "test_macro_f1": 0.38199383462541353, "test_runtime": 6.2984, "test_samples_per_second": 325.163, "test_steps_per_second": 10.161}, {"test_loss": 0.9980186223983765, "test_mcc": 0.258002521626337, "test_macro_f1": 0.4432265697475384, "test_runtime": 6.5614, "test_samples_per_second": 312.128, "test_steps_per_second": 9.754}, {"test_loss": 0.9766938090324402, "test_mcc": 0.20956495977773926, "test_macro_f1": 0.36972497731991405, "test_runtime": 6.4228, "test_samples_per_second": 318.863, "test_steps_per_second": 9.964}]}, "total": {"test_mcc": 17.412453641697464, "test_mcc_se": 4.844259802223286, "test_macro_f1": 36.75626145812988, "test_macro_f1_se": 3.8607161623428086}}, "num_model_parameters": 132085251, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.11480745673179626, "test_micro_f1": 0.38781725888324875, "test_micro_f1_no_misc": 0.4375366568914956, "test_runtime": 11.1012, "test_samples_per_second": 184.484, "test_steps_per_second": 5.765}, {"test_loss": 0.11320485174655914, "test_micro_f1": 0.26883468834688345, "test_micro_f1_no_misc": 0.2880371660859466, "test_runtime": 10.6285, "test_samples_per_second": 192.69, "test_steps_per_second": 6.022}, {"test_loss": 0.10500096529722214, "test_micro_f1": 0.3480368395540475, "test_micro_f1_no_misc": 0.3771186440677966, "test_runtime": 10.698, "test_samples_per_second": 191.438, "test_steps_per_second": 5.982}, {"test_loss": 0.11350992321968079, "test_micro_f1": 0.3530534351145039, "test_micro_f1_no_misc": 0.3739262253663467, "test_runtime": 11.0642, "test_samples_per_second": 185.102, "test_steps_per_second": 5.784}, {"test_loss": 0.12290702015161514, "test_micro_f1": 0.3135593220338983, "test_micro_f1_no_misc": 0.3324987481221833, "test_runtime": 10.9485, "test_samples_per_second": 187.057, "test_steps_per_second": 5.846}, {"test_loss": 0.12366479635238647, "test_micro_f1": 0.35571687840290384, "test_micro_f1_no_misc": 0.3702609551944855, "test_runtime": 9.2742, "test_samples_per_second": 220.827, "test_steps_per_second": 6.901}, {"test_loss": 0.1232815682888031, "test_micro_f1": 0.36967294350842417, "test_micro_f1_no_misc": 0.39366754617414246, "test_runtime": 10.205, "test_samples_per_second": 200.686, "test_steps_per_second": 6.271}, {"test_loss": 0.10413214564323425, "test_micro_f1": 0.3802660753880266, "test_micro_f1_no_misc": 0.4054696789536267, "test_runtime": 11.023, "test_samples_per_second": 185.794, "test_steps_per_second": 5.806}, {"test_loss": 0.11070819944143295, "test_micro_f1": 0.38472834067547723, "test_micro_f1_no_misc": 0.4083333333333333, "test_runtime": 10.5648, "test_samples_per_second": 193.852, "test_steps_per_second": 6.058}, {"test_loss": 0.1157451644539833, "test_micro_f1": 0.3178368121442125, "test_micro_f1_no_misc": 0.3375959079283888, "test_runtime": 11.0317, "test_samples_per_second": 185.647, "test_steps_per_second": 5.801}]}, "total": {"test_micro_f1": 34.79522594051626, "test_micro_f1_se": 2.3459481520106116, "test_micro_f1_no_misc": 37.24444862117745, "test_micro_f1_no_misc_se": 2.696104410884172}}, "num_model_parameters": 132089865, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.14736708998680115, "test_micro_f1": 0.5047476261869065, "test_micro_f1_no_misc": 0.5301820504631107, "test_runtime": 12.3758, "test_samples_per_second": 165.484, "test_steps_per_second": 5.171}, {"test_loss": 0.14700275659561157, "test_micro_f1": 0.5433592624603861, "test_micro_f1_no_misc": 0.5734112490869248, "test_runtime": 10.43, "test_samples_per_second": 196.357, "test_steps_per_second": 6.136}, {"test_loss": 0.15256281197071075, "test_micro_f1": 0.494629578628477, "test_micro_f1_no_misc": 0.5480013665869491, "test_runtime": 12.6831, "test_samples_per_second": 161.475, "test_steps_per_second": 5.046}, {"test_loss": 0.15626853704452515, "test_micro_f1": 0.5424754222334258, "test_micro_f1_no_misc": 0.5527768756089639, "test_runtime": 12.0577, "test_samples_per_second": 169.85, "test_steps_per_second": 5.308}, {"test_loss": 0.1698247641324997, "test_micro_f1": 0.459528543027549, "test_micro_f1_no_misc": 0.5032727272727273, "test_runtime": 12.7181, "test_samples_per_second": 161.03, "test_steps_per_second": 5.032}, {"test_loss": 0.16563844680786133, "test_micro_f1": 0.4927048260381594, "test_micro_f1_no_misc": 0.5290464011691635, "test_runtime": 12.666, "test_samples_per_second": 161.692, "test_steps_per_second": 5.053}, {"test_loss": 0.1643647402524948, "test_micro_f1": 0.45444444444444443, "test_micro_f1_no_misc": 0.4955872369314324, "test_runtime": 12.709, "test_samples_per_second": 161.146, "test_steps_per_second": 5.036}, {"test_loss": 0.1486312448978424, "test_micro_f1": 0.3913294797687861, "test_micro_f1_no_misc": 0.4234550561797753, "test_runtime": 12.2653, "test_samples_per_second": 166.975, "test_steps_per_second": 5.218}, {"test_loss": 0.17292752861976624, "test_micro_f1": 0.4040184632093402, "test_micro_f1_no_misc": 0.421832884097035, "test_runtime": 12.1732, "test_samples_per_second": 168.238, "test_steps_per_second": 5.257}, {"test_loss": 0.15773199498653412, "test_micro_f1": 0.4847161572052402, "test_micro_f1_no_misc": 0.518005540166205, "test_runtime": 10.157, "test_samples_per_second": 201.635, "test_steps_per_second": 6.301}]}, "total": {"test_micro_f1": 47.719538032027145, "test_micro_f1_se": 3.170980237531653, "test_micro_f1_no_misc": 50.95571387562286, "test_micro_f1_no_misc_se": 3.1768134978797824}}, "num_model_parameters": 132089865, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.10415787249803543, "test_micro_f1": 0.5103900838497993, "test_micro_f1_no_misc": 0.5538461538461538, "test_runtime": 10.0831, "test_samples_per_second": 203.111, "test_steps_per_second": 6.347}, {"test_loss": 0.10363170504570007, "test_micro_f1": 0.5222745382107933, "test_micro_f1_no_misc": 0.5642458100558658, "test_runtime": 10.1786, "test_samples_per_second": 201.207, "test_steps_per_second": 6.288}, {"test_loss": 0.12071812152862549, "test_micro_f1": 0.47817189631650747, "test_micro_f1_no_misc": 0.5227272727272728, "test_runtime": 9.9509, "test_samples_per_second": 205.81, "test_steps_per_second": 6.432}, {"test_loss": 0.11709179729223251, "test_micro_f1": 0.39205298013245027, "test_micro_f1_no_misc": 0.4169312169312169, "test_runtime": 9.9688, "test_samples_per_second": 205.441, "test_steps_per_second": 6.42}, {"test_loss": 0.1268337070941925, "test_micro_f1": 0.39987425337944044, "test_micro_f1_no_misc": 0.42731575388776194, "test_runtime": 10.1599, "test_samples_per_second": 201.577, "test_steps_per_second": 6.299}, {"test_loss": 0.11727544665336609, "test_micro_f1": 0.45514511873350927, "test_micro_f1_no_misc": 0.48573466476462196, "test_runtime": 10.1181, "test_samples_per_second": 202.41, "test_steps_per_second": 6.325}, {"test_loss": 0.11984191834926605, "test_micro_f1": 0.4641434262948207, "test_micro_f1_no_misc": 0.4936845904005774, "test_runtime": 9.504, "test_samples_per_second": 215.488, "test_steps_per_second": 6.734}, {"test_loss": 0.11441553384065628, "test_micro_f1": 0.4725848563968668, "test_micro_f1_no_misc": 0.507410021171489, "test_runtime": 9.9337, "test_samples_per_second": 206.166, "test_steps_per_second": 6.443}, {"test_loss": 0.10697363317012787, "test_micro_f1": 0.49965541006202624, "test_micro_f1_no_misc": 0.5372682557699583, "test_runtime": 9.7811, "test_samples_per_second": 209.383, "test_steps_per_second": 6.543}, {"test_loss": 0.12369506061077118, "test_micro_f1": 0.4496815286624204, "test_micro_f1_no_misc": 0.4826862539349423, "test_runtime": 9.1744, "test_samples_per_second": 223.23, "test_steps_per_second": 6.976}]}, "total": {"test_micro_f1": 46.439740920386335, "test_micro_f1_se": 2.667022075937234, "test_micro_f1_no_misc": 49.91849993489861, "test_micro_f1_no_misc_se": 3.0439460270862675}}, "num_model_parameters": 132089865, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.12497146427631378, "test_micro_f1": 0.4963724304715841, "test_micro_f1_no_misc": 0.5251683231805067, "test_runtime": 9.5345, "test_samples_per_second": 214.8, "test_steps_per_second": 6.712}, {"test_loss": 0.13416683673858643, "test_micro_f1": 0.4944226710883328, "test_micro_f1_no_misc": 0.5349065880039332, "test_runtime": 9.7247, "test_samples_per_second": 210.597, "test_steps_per_second": 6.581}, {"test_loss": 0.12932974100112915, "test_micro_f1": 0.5043116265239369, "test_micro_f1_no_misc": 0.543739837398374, "test_runtime": 9.3897, "test_samples_per_second": 218.112, "test_steps_per_second": 6.816}, {"test_loss": 0.14078933000564575, "test_micro_f1": 0.44560791157649793, "test_micro_f1_no_misc": 0.4756824599937245, "test_runtime": 9.4857, "test_samples_per_second": 215.904, "test_steps_per_second": 6.747}, {"test_loss": 0.14430652558803558, "test_micro_f1": 0.46921697549312613, "test_micro_f1_no_misc": 0.507079354626276, "test_runtime": 9.1259, "test_samples_per_second": 224.417, "test_steps_per_second": 7.013}, {"test_loss": 0.13234224915504456, "test_micro_f1": 0.5489162272993555, "test_micro_f1_no_misc": 0.589710610932476, "test_runtime": 8.8226, "test_samples_per_second": 232.132, "test_steps_per_second": 7.254}, {"test_loss": 0.1246548593044281, "test_micro_f1": 0.5186511489107728, "test_micro_f1_no_misc": 0.5607973421926911, "test_runtime": 9.7616, "test_samples_per_second": 209.801, "test_steps_per_second": 6.556}, {"test_loss": 0.1293228566646576, "test_micro_f1": 0.48514251061249236, "test_micro_f1_no_misc": 0.5184700882641387, "test_runtime": 9.7488, "test_samples_per_second": 210.077, "test_steps_per_second": 6.565}, {"test_loss": 0.14086058735847473, "test_micro_f1": 0.515507377295995, "test_micro_f1_no_misc": 0.5502504173622704, "test_runtime": 8.9231, "test_samples_per_second": 229.518, "test_steps_per_second": 7.172}, {"test_loss": 0.13582296669483185, "test_micro_f1": 0.4361259655377302, "test_micro_f1_no_misc": 0.4586066854108091, "test_runtime": 9.1867, "test_samples_per_second": 222.932, "test_steps_per_second": 6.967}]}, "total": {"test_micro_f1": 49.14274844809824, "test_micro_f1_se": 2.118639051136541, "test_micro_f1_no_misc": 52.644117073652, "test_micro_f1_no_misc_se": 2.421669546165368}}, "num_model_parameters": 132089865, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.6925080418586731, "test_mcc": 0.005788402043585756, "test_macro_f1": 0.5016873797813893, "test_runtime": 6.0154, "test_samples_per_second": 340.461, "test_steps_per_second": 10.639}, {"test_loss": 0.692140519618988, "test_mcc": 0.04184045106713255, "test_macro_f1": 0.5023722744421, "test_runtime": 6.4308, "test_samples_per_second": 318.465, "test_steps_per_second": 9.952}, {"test_loss": 0.6930379867553711, "test_mcc": -0.006119254344480219, "test_macro_f1": 0.49684726539945473, "test_runtime": 6.4662, "test_samples_per_second": 316.724, "test_steps_per_second": 9.898}, {"test_loss": 0.6942304968833923, "test_mcc": 0.010169007025826494, "test_macro_f1": 0.4944490380040315, "test_runtime": 6.3227, "test_samples_per_second": 323.911, "test_steps_per_second": 10.122}, {"test_loss": 0.6927927136421204, "test_mcc": 0.015544272747329495, "test_macro_f1": 0.49040247814904214, "test_runtime": 6.505, "test_samples_per_second": 314.835, "test_steps_per_second": 9.839}, {"test_loss": 0.6931739449501038, "test_mcc": 0.0, "test_macro_f1": 0.3342002600780234, "test_runtime": 6.2511, "test_samples_per_second": 327.623, "test_steps_per_second": 10.238}, {"test_loss": 0.6933478713035583, "test_mcc": 0.019655366286799435, "test_macro_f1": 0.48157490085038535, "test_runtime": 6.4817, "test_samples_per_second": 315.968, "test_steps_per_second": 9.874}, {"test_loss": 0.6922086477279663, "test_mcc": 0.02770298942337898, "test_macro_f1": 0.5067712066235961, "test_runtime": 6.3013, "test_samples_per_second": 325.014, "test_steps_per_second": 10.157}, {"test_loss": 0.692965030670166, "test_mcc": -0.0004693943410382325, "test_macro_f1": 0.49271312928231964, "test_runtime": 6.3522, "test_samples_per_second": 322.407, "test_steps_per_second": 10.075}, {"test_loss": 0.6930657625198364, "test_mcc": 0.015673222560815967, "test_macro_f1": 0.44295485636114906, "test_runtime": 6.4169, "test_samples_per_second": 319.156, "test_steps_per_second": 9.974}]}, "total": {"test_mcc": 1.2978506246935024, "test_mcc_se": 0.8962462709747046, "test_macro_f1": 47.43972788971491, "test_macro_f1_se": 3.2515055874891403}}, "num_model_parameters": 132084482, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.6948094964027405, "test_mcc": 0.032724886237382775, "test_macro_f1": 0.4860880208631914, "test_runtime": 6.5997, "test_samples_per_second": 310.316, "test_steps_per_second": 9.697}, {"test_loss": 0.6940352916717529, "test_mcc": -0.01458808081465283, "test_macro_f1": 0.4894581310958338, "test_runtime": 6.9844, "test_samples_per_second": 293.225, "test_steps_per_second": 9.163}, {"test_loss": 0.6924463510513306, "test_mcc": 0.04592858823361987, "test_macro_f1": 0.4863209615471088, "test_runtime": 6.8427, "test_samples_per_second": 299.295, "test_steps_per_second": 9.353}, {"test_loss": 0.695132315158844, "test_mcc": -0.03867184167331003, "test_macro_f1": 0.47932468803523365, "test_runtime": 7.0452, "test_samples_per_second": 290.694, "test_steps_per_second": 9.084}, {"test_loss": 0.6920579671859741, "test_mcc": 0.06413975894302092, "test_macro_f1": 0.531236582044792, "test_runtime": 6.816, "test_samples_per_second": 300.471, "test_steps_per_second": 9.39}, {"test_loss": 0.6932802200317383, "test_mcc": 0.049272478321107475, "test_macro_f1": 0.5242979242979243, "test_runtime": 6.7787, "test_samples_per_second": 302.124, "test_steps_per_second": 9.441}, {"test_loss": 0.6947271823883057, "test_mcc": 0.030561786090487167, "test_macro_f1": 0.5143039223639816, "test_runtime": 6.5122, "test_samples_per_second": 314.488, "test_steps_per_second": 9.828}, {"test_loss": 0.6932474374771118, "test_mcc": 0.009603012077783756, "test_macro_f1": 0.4989409053498739, "test_runtime": 6.6988, "test_samples_per_second": 305.727, "test_steps_per_second": 9.554}, {"test_loss": 0.6927245855331421, "test_mcc": 0.04117409833844092, "test_macro_f1": 0.5168769545993745, "test_runtime": 6.6137, "test_samples_per_second": 309.662, "test_steps_per_second": 9.677}, {"test_loss": 0.695563554763794, "test_mcc": -0.028635740242249828, "test_macro_f1": 0.41175389643015897, "test_runtime": 6.8168, "test_samples_per_second": 300.435, "test_steps_per_second": 9.389}]}, "total": {"test_mcc": 1.915089455116302, "test_mcc_se": 2.1966333280565453, "test_macro_f1": 49.38601986627472, "test_macro_f1_se": 2.1055515967885374}}, "num_model_parameters": 132084482, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.6936914324760437, "test_mcc": 0.02146198581839234, "test_macro_f1": 0.5018937131804749, "test_runtime": 6.1913, "test_samples_per_second": 330.785, "test_steps_per_second": 10.337}, {"test_loss": 0.693446695804596, "test_mcc": -0.006061749892635712, "test_macro_f1": 0.3769205208110793, "test_runtime": 6.2395, "test_samples_per_second": 328.229, "test_steps_per_second": 10.257}, {"test_loss": 0.6916232109069824, "test_mcc": 0.055686026675855996, "test_macro_f1": 0.5273275220783183, "test_runtime": 6.2559, "test_samples_per_second": 327.372, "test_steps_per_second": 10.23}, {"test_loss": 0.6911324858665466, "test_mcc": 0.074825992657854, "test_macro_f1": 0.523509125339789, "test_runtime": 6.4806, "test_samples_per_second": 316.018, "test_steps_per_second": 9.876}, {"test_loss": 0.692356288433075, "test_mcc": 0.0163895399978723, "test_macro_f1": 0.5041505257332596, "test_runtime": 6.3912, "test_samples_per_second": 320.442, "test_steps_per_second": 10.014}, {"test_loss": 0.6929898858070374, "test_mcc": 0.024911489590999748, "test_macro_f1": 0.512218963831867, "test_runtime": 6.0406, "test_samples_per_second": 339.041, "test_steps_per_second": 10.595}, {"test_loss": 0.6923791766166687, "test_mcc": 0.020760433034534776, "test_macro_f1": 0.3618222438137822, "test_runtime": 6.1592, "test_samples_per_second": 332.511, "test_steps_per_second": 10.391}, {"test_loss": 0.6920207738876343, "test_mcc": 0.060095742683195466, "test_macro_f1": 0.45500420521446594, "test_runtime": 6.2722, "test_samples_per_second": 326.52, "test_steps_per_second": 10.204}, {"test_loss": 0.6941574215888977, "test_mcc": 0.03646231788888448, "test_macro_f1": 0.4919167510836099, "test_runtime": 6.1808, "test_samples_per_second": 331.349, "test_steps_per_second": 10.355}, {"test_loss": 0.6948984861373901, "test_mcc": -0.02372588091147203, "test_macro_f1": 0.45437162380862106, "test_runtime": 6.3007, "test_samples_per_second": 325.044, "test_steps_per_second": 10.158}]}, "total": {"test_mcc": 2.8080589754348138, "test_mcc_se": 1.8635628093269032, "test_macro_f1": 47.09135194895268, "test_macro_f1_se": 3.662334853150816}}, "num_model_parameters": 132084482, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.6942744255065918, "test_mcc": -0.02829576879579508, "test_macro_f1": 0.3522881050048733, "test_runtime": 6.3616, "test_samples_per_second": 321.931, "test_steps_per_second": 10.06}, {"test_loss": 0.6945644021034241, "test_mcc": -0.01556743806469934, "test_macro_f1": 0.4653748229463993, "test_runtime": 6.6116, "test_samples_per_second": 309.759, "test_steps_per_second": 9.68}, {"test_loss": 0.6988117098808289, "test_mcc": -0.06756521239344268, "test_macro_f1": 0.44829760231647126, "test_runtime": 6.5329, "test_samples_per_second": 313.49, "test_steps_per_second": 9.797}, {"test_loss": 0.6941268444061279, "test_mcc": 0.019211702931927945, "test_macro_f1": 0.4767612571594726, "test_runtime": 6.1845, "test_samples_per_second": 331.149, "test_steps_per_second": 10.348}, {"test_loss": 0.694661021232605, "test_mcc": 0.035329347742577205, "test_macro_f1": 0.47019290039940337, "test_runtime": 6.3579, "test_samples_per_second": 322.119, "test_steps_per_second": 10.066}, {"test_loss": 0.6916782855987549, "test_mcc": 0.04090109720499334, "test_macro_f1": 0.43140466864531707, "test_runtime": 6.4972, "test_samples_per_second": 315.214, "test_steps_per_second": 9.85}, {"test_loss": 0.6930406093597412, "test_mcc": 0.025299293835301714, "test_macro_f1": 0.5005824104034957, "test_runtime": 6.3255, "test_samples_per_second": 323.771, "test_steps_per_second": 10.118}, {"test_loss": 0.6926078796386719, "test_mcc": 0.05118753160716436, "test_macro_f1": 0.4911374075316848, "test_runtime": 6.4164, "test_samples_per_second": 319.183, "test_steps_per_second": 9.974}, {"test_loss": 0.6931651830673218, "test_mcc": 0.03362385904421531, "test_macro_f1": 0.49081761006289304, "test_runtime": 6.3507, "test_samples_per_second": 322.482, "test_steps_per_second": 10.078}, {"test_loss": 0.6938230991363525, "test_mcc": -0.049108054395699936, "test_macro_f1": 0.46956746956746953, "test_runtime": 6.6279, "test_samples_per_second": 308.995, "test_steps_per_second": 9.656}]}, "total": {"test_mcc": 0.45016358716542854, "test_mcc_se": 2.5720050566092434, "test_macro_f1": 45.964242540374805, "test_macro_f1_se": 2.6640197012662767}}, "num_model_parameters": 132084482, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_loss": 0.47707515954971313, "test_mcc": 0.7029318683853409, "test_macro_f1": 0.5859302784291976, "test_runtime": 14.4195, "test_samples_per_second": 142.03, "test_steps_per_second": 17.754}, {"test_loss": 0.4863039255142212, "test_mcc": 0.7008848808848084, "test_macro_f1": 0.6855581095856721, "test_runtime": 13.828, "test_samples_per_second": 148.106, "test_steps_per_second": 18.513}, {"test_loss": 0.5132668614387512, "test_mcc": 0.7079825048751744, "test_macro_f1": 0.6833782130724556, "test_runtime": 17.2744, "test_samples_per_second": 118.557, "test_steps_per_second": 59.279}, {"test_loss": 0.4200369715690613, "test_mcc": 0.7373263194445606, "test_macro_f1": 0.6757731314070395, "test_runtime": 16.981, "test_samples_per_second": 120.605, "test_steps_per_second": 60.303}, {"test_loss": 0.4328124523162842, "test_mcc": 0.7371276655167937, "test_macro_f1": 0.7073669629878517, "test_runtime": 17.1608, "test_samples_per_second": 119.342, "test_steps_per_second": 59.671}, {"test_loss": 0.44398051500320435, "test_mcc": 0.7371984642313945, "test_macro_f1": 0.7531729221005788, "test_runtime": 17.2039, "test_samples_per_second": 119.043, "test_steps_per_second": 59.521}, {"test_loss": 0.502758800983429, "test_mcc": 0.6874619707839499, "test_macro_f1": 0.5843917954459737, "test_runtime": 17.1369, "test_samples_per_second": 119.508, "test_steps_per_second": 59.754}, {"test_loss": 0.44207850098609924, "test_mcc": 0.7268043332118154, "test_macro_f1": 0.6676007206775673, "test_runtime": 17.2662, "test_samples_per_second": 118.613, "test_steps_per_second": 59.307}, {"test_loss": 0.4953046441078186, "test_mcc": 0.701990280668249, "test_macro_f1": 0.6191903772517887, "test_runtime": 17.2465, "test_samples_per_second": 118.748, "test_steps_per_second": 59.374}, {"test_loss": 0.47515445947647095, "test_mcc": 0.693591088832777, "test_macro_f1": 0.5817498675607226, "test_runtime": 17.2078, "test_samples_per_second": 119.016, "test_steps_per_second": 59.508}]}, "total": {"test_mcc": 71.33299376834864, "test_mcc_se": 1.1997840247644618, "test_macro_f1": 65.44112378518847, "test_macro_f1_se": 3.6440678103002866}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_loss": 0.6847759485244751, "test_mcc": 0.5746995785421359, "test_macro_f1": 0.5338270454390778, "test_runtime": 29.4101, "test_samples_per_second": 69.636, "test_steps_per_second": 34.818}, {"test_loss": 0.6563371419906616, "test_mcc": 0.5573373142497468, "test_macro_f1": 0.5285283848366741, "test_runtime": 28.5441, "test_samples_per_second": 71.749, "test_steps_per_second": 35.874}, {"test_loss": 0.7184163928031921, "test_mcc": 0.5355396597618681, "test_macro_f1": 0.5140711880751004, "test_runtime": 29.0222, "test_samples_per_second": 70.567, "test_steps_per_second": 35.283}, {"test_loss": 0.6228752732276917, "test_mcc": 0.5896831088683404, "test_macro_f1": 0.5404599265030388, "test_runtime": 28.1506, "test_samples_per_second": 72.752, "test_steps_per_second": 36.376}, {"test_loss": 0.6493799090385437, "test_mcc": 0.5811689838744473, "test_macro_f1": 0.5308882326491426, "test_runtime": 28.7317, "test_samples_per_second": 71.28, "test_steps_per_second": 35.64}, {"test_loss": 0.7091606855392456, "test_mcc": 0.5337639533165209, "test_macro_f1": 0.5189953069918394, "test_runtime": 29.1057, "test_samples_per_second": 70.364, "test_steps_per_second": 35.182}, {"test_loss": 0.6399739980697632, "test_mcc": 0.5730279511218018, "test_macro_f1": 0.5334754198285329, "test_runtime": 28.673, "test_samples_per_second": 71.426, "test_steps_per_second": 35.713}, {"test_loss": 0.6412788033485413, "test_mcc": 0.5790001012717616, "test_macro_f1": 0.5365273444504215, "test_runtime": 29.3436, "test_samples_per_second": 69.794, "test_steps_per_second": 34.897}, {"test_loss": 0.6265842914581299, "test_mcc": 0.5916320152094946, "test_macro_f1": 0.5766962207845702, "test_runtime": 29.341, "test_samples_per_second": 69.8, "test_steps_per_second": 34.9}, {"test_loss": 0.6429657936096191, "test_mcc": 0.5899166292670003, "test_macro_f1": 0.5415691597921596, "test_runtime": 29.1194, "test_samples_per_second": 70.331, "test_steps_per_second": 35.166}]}, "total": {"test_mcc": 57.057692954831175, "test_mcc_se": 1.330399847751779, "test_macro_f1": 53.55038229350557, "test_macro_f1_se": 1.0469629176120618}}, "num_model_parameters": 132085251, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.5914421081542969, "test_mcc": 0.617126081238237, "test_macro_f1": 0.5525238552453421, "test_runtime": 7.9313, "test_samples_per_second": 258.218, "test_steps_per_second": 8.069}, {"test_loss": 0.6381902098655701, "test_mcc": 0.5708546435203463, "test_macro_f1": 0.5336432039351754, "test_runtime": 7.6518, "test_samples_per_second": 267.648, "test_steps_per_second": 8.364}, {"test_loss": 0.6185575723648071, "test_mcc": 0.5981073955302565, "test_macro_f1": 0.555729193231919, "test_runtime": 6.4715, "test_samples_per_second": 316.464, "test_steps_per_second": 39.558}, {"test_loss": 0.6843203902244568, "test_mcc": 0.5320756963921895, "test_macro_f1": 0.5180528459272016, "test_runtime": 6.2562, "test_samples_per_second": 327.357, "test_steps_per_second": 40.92}, {"test_loss": 0.5808607339859009, "test_mcc": 0.6104353913546671, "test_macro_f1": 0.562318554142785, "test_runtime": 6.2561, "test_samples_per_second": 327.36, "test_steps_per_second": 40.92}, {"test_loss": 0.6007595062255859, "test_mcc": 0.6267439005326446, "test_macro_f1": 0.554777208555099, "test_runtime": 6.3918, "test_samples_per_second": 320.41, "test_steps_per_second": 40.051}, {"test_loss": 0.6411068439483643, "test_mcc": 0.5734397842394668, "test_macro_f1": 0.5321624127015131, "test_runtime": 6.1443, "test_samples_per_second": 333.316, "test_steps_per_second": 41.664}, {"test_loss": 0.6027268171310425, "test_mcc": 0.6076895475072434, "test_macro_f1": 0.5475390024761485, "test_runtime": 6.4763, "test_samples_per_second": 316.231, "test_steps_per_second": 39.529}, {"test_loss": 0.6028574705123901, "test_mcc": 0.6038488207231119, "test_macro_f1": 0.5886480257417198, "test_runtime": 6.4449, "test_samples_per_second": 317.771, "test_steps_per_second": 39.721}, {"test_loss": 0.5877875685691833, "test_mcc": 0.6256525367538498, "test_macro_f1": 0.5783921888759251, "test_runtime": 6.3015, "test_samples_per_second": 325.002, "test_steps_per_second": 40.625}]}, "total": {"test_mcc": 59.65973797792012, "test_mcc_se": 1.8369989632311094, "test_macro_f1": 55.237864908328284, "test_macro_f1_se": 1.3179484012262428}}, "num_model_parameters": 42131459, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.9808837175369263, "test_mcc": 0.2825091094580311, "test_macro_f1": 0.5052125520259315, "test_runtime": 2.2202, "test_samples_per_second": 922.428, "test_steps_per_second": 28.826}, {"test_loss": 0.9757198095321655, "test_mcc": 0.29175584747232597, "test_macro_f1": 0.5022007842042556, "test_runtime": 2.243, "test_samples_per_second": 913.049, "test_steps_per_second": 28.533}, {"test_loss": 1.0210837125778198, "test_mcc": 0.2741194544884668, "test_macro_f1": 0.5001736470024353, "test_runtime": 2.2189, "test_samples_per_second": 923.0, "test_steps_per_second": 28.844}, {"test_loss": 1.0619603395462036, "test_mcc": 0.28123974591143275, "test_macro_f1": 0.50640287225375, "test_runtime": 2.2266, "test_samples_per_second": 919.776, "test_steps_per_second": 28.743}, {"test_loss": 1.0339574813842773, "test_mcc": 0.27429348120762953, "test_macro_f1": 0.5087026607493819, "test_runtime": 2.1914, "test_samples_per_second": 934.544, "test_steps_per_second": 29.205}, {"test_loss": 1.0239179134368896, "test_mcc": 0.2561707465972598, "test_macro_f1": 0.5010028788084336, "test_runtime": 2.2065, "test_samples_per_second": 928.149, "test_steps_per_second": 29.005}, {"test_loss": 0.980637788772583, "test_mcc": 0.28577285775561906, "test_macro_f1": 0.5111247129520459, "test_runtime": 2.2207, "test_samples_per_second": 922.234, "test_steps_per_second": 28.82}, {"test_loss": 0.9920654892921448, "test_mcc": 0.2790724140875142, "test_macro_f1": 0.5165286398426084, "test_runtime": 2.2483, "test_samples_per_second": 910.913, "test_steps_per_second": 28.466}, {"test_loss": 0.969876229763031, "test_mcc": 0.29387265204088964, "test_macro_f1": 0.5187555195090637, "test_runtime": 2.272, "test_samples_per_second": 901.423, "test_steps_per_second": 28.169}, {"test_loss": 1.0392158031463623, "test_mcc": 0.27467458814848517, "test_macro_f1": 0.5154599801734637, "test_runtime": 2.2198, "test_samples_per_second": 922.622, "test_steps_per_second": 28.832}]}, "total": {"test_mcc": 27.93480897167654, "test_mcc_se": 0.663626515770232, "test_macro_f1": 50.8556424752137, "test_macro_f1_se": 0.4159813778237448}}, "num_model_parameters": 42131459, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.9553834199905396, "test_mcc": 0.2674405992026133, "test_macro_f1": 0.407870419543282, "test_runtime": 1.8583, "test_samples_per_second": 1102.07, "test_steps_per_second": 34.44}, {"test_loss": 0.9211719036102295, "test_mcc": 0.24211655265375834, "test_macro_f1": 0.40003238476151853, "test_runtime": 1.806, "test_samples_per_second": 1133.97, "test_steps_per_second": 35.437}, {"test_loss": 0.923447847366333, "test_mcc": 0.30515688295671534, "test_macro_f1": 0.42033167443009106, "test_runtime": 1.7313, "test_samples_per_second": 1182.955, "test_steps_per_second": 36.967}, {"test_loss": 0.9514694213867188, "test_mcc": 0.2674153936581536, "test_macro_f1": 0.40938899554515995, "test_runtime": 1.7655, "test_samples_per_second": 1160.007, "test_steps_per_second": 36.25}, {"test_loss": 0.9821100831031799, "test_mcc": 0.20279698569123342, "test_macro_f1": 0.38303741138420033, "test_runtime": 1.8058, "test_samples_per_second": 1134.152, "test_steps_per_second": 35.442}, {"test_loss": 0.9516760110855103, "test_mcc": 0.27676587570041233, "test_macro_f1": 0.41242291238402135, "test_runtime": 1.8138, "test_samples_per_second": 1129.125, "test_steps_per_second": 35.285}, {"test_loss": 0.9255647659301758, "test_mcc": 0.26310833788515847, "test_macro_f1": 0.4086074296503166, "test_runtime": 1.769, "test_samples_per_second": 1157.689, "test_steps_per_second": 36.178}, {"test_loss": 0.9369980096817017, "test_mcc": 0.24373618073295883, "test_macro_f1": 0.3999649892025647, "test_runtime": 1.8327, "test_samples_per_second": 1117.47, "test_steps_per_second": 34.921}, {"test_loss": 0.9644644260406494, "test_mcc": 0.2629519110440514, "test_macro_f1": 0.4016971972541434, "test_runtime": 1.8187, "test_samples_per_second": 1126.049, "test_steps_per_second": 35.189}, {"test_loss": 0.9277832508087158, "test_mcc": 0.3017422387275536, "test_macro_f1": 0.4235365629113655, "test_runtime": 1.8319, "test_samples_per_second": 1117.988, "test_steps_per_second": 34.937}]}, "total": {"test_mcc": 26.332309582526086, "test_mcc_se": 1.840669009198834, "test_macro_f1": 40.66889977066664, "test_macro_f1_se": 0.7124166017774124}}, "num_model_parameters": 42131459, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.086130790412426, "test_micro_f1": 0.6139630390143737, "test_micro_f1_no_misc": 0.6838015540944411, "test_runtime": 3.8272, "test_samples_per_second": 535.114, "test_steps_per_second": 16.722}, {"test_loss": 0.0760120078921318, "test_micro_f1": 0.615141955835962, "test_micro_f1_no_misc": 0.6602162777461582, "test_runtime": 3.5752, "test_samples_per_second": 572.841, "test_steps_per_second": 17.901}, {"test_loss": 0.07549063116312027, "test_micro_f1": 0.6348747591522158, "test_micro_f1_no_misc": 0.6836127636560304, "test_runtime": 3.4939, "test_samples_per_second": 586.162, "test_steps_per_second": 18.318}, {"test_loss": 0.07729664444923401, "test_micro_f1": 0.6333333333333333, "test_micro_f1_no_misc": 0.6832229580573952, "test_runtime": 3.6943, "test_samples_per_second": 554.369, "test_steps_per_second": 17.324}, {"test_loss": 0.08478152751922607, "test_micro_f1": 0.5855984740104911, "test_micro_f1_no_misc": 0.6341724692019283, "test_runtime": 3.7148, "test_samples_per_second": 551.302, "test_steps_per_second": 17.228}, {"test_loss": 0.07331037521362305, "test_micro_f1": 0.6030150753768844, "test_micro_f1_no_misc": 0.6604264170566821, "test_runtime": 3.1142, "test_samples_per_second": 657.624, "test_steps_per_second": 20.551}, {"test_loss": 0.0840483158826828, "test_micro_f1": 0.5852731591448931, "test_micro_f1_no_misc": 0.6400000000000001, "test_runtime": 3.3592, "test_samples_per_second": 609.662, "test_steps_per_second": 19.052}, {"test_loss": 0.06600549817085266, "test_micro_f1": 0.6237251744498121, "test_micro_f1_no_misc": 0.6768107121119904, "test_runtime": 3.6373, "test_samples_per_second": 563.06, "test_steps_per_second": 17.596}, {"test_loss": 0.07486698031425476, "test_micro_f1": 0.6014251781472684, "test_micro_f1_no_misc": 0.6360387953037264, "test_runtime": 3.4392, "test_samples_per_second": 595.483, "test_steps_per_second": 18.609}, {"test_loss": 0.08169656246900558, "test_micro_f1": 0.6066441983630236, "test_micro_f1_no_misc": 0.6528662420382164, "test_runtime": 3.6335, "test_samples_per_second": 563.636, "test_steps_per_second": 17.614}]}, "total": {"test_micro_f1": 61.029943468282575, "test_micro_f1_se": 1.0801274809443102, "test_micro_f1_no_misc": 66.11168189266569, "test_micro_f1_no_misc_se": 1.2440518938565788}}, "num_model_parameters": 41871881, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.10853497684001923, "test_micro_f1": 0.6671759612936083, "test_micro_f1_no_misc": 0.6895133653187114, "test_runtime": 5.1537, "test_samples_per_second": 397.386, "test_steps_per_second": 12.418}, {"test_loss": 0.10169342160224915, "test_micro_f1": 0.6369213608477412, "test_micro_f1_no_misc": 0.6563763322307975, "test_runtime": 4.1882, "test_samples_per_second": 488.99, "test_steps_per_second": 15.281}, {"test_loss": 0.10345624387264252, "test_micro_f1": 0.6241171854564479, "test_micro_f1_no_misc": 0.6425307557117751, "test_runtime": 5.0937, "test_samples_per_second": 402.063, "test_steps_per_second": 12.564}, {"test_loss": 0.1057838648557663, "test_micro_f1": 0.6529968454258676, "test_micro_f1_no_misc": 0.6571328915242414, "test_runtime": 4.8833, "test_samples_per_second": 419.389, "test_steps_per_second": 13.106}, {"test_loss": 0.10845189541578293, "test_micro_f1": 0.6198764738910724, "test_micro_f1_no_misc": 0.6485093853514907, "test_runtime": 5.127, "test_samples_per_second": 399.455, "test_steps_per_second": 12.483}, {"test_loss": 0.1025635302066803, "test_micro_f1": 0.635204773528614, "test_micro_f1_no_misc": 0.6442857142857144, "test_runtime": 4.9725, "test_samples_per_second": 411.868, "test_steps_per_second": 12.871}, {"test_loss": 0.09950515627861023, "test_micro_f1": 0.6309181271252943, "test_micro_f1_no_misc": 0.6379952590585846, "test_runtime": 5.1683, "test_samples_per_second": 396.263, "test_steps_per_second": 12.383}, {"test_loss": 0.0960736870765686, "test_micro_f1": 0.6666666666666667, "test_micro_f1_no_misc": 0.6812068338785896, "test_runtime": 5.0439, "test_samples_per_second": 406.035, "test_steps_per_second": 12.689}, {"test_loss": 0.10834468901157379, "test_micro_f1": 0.6197330541742999, "test_micro_f1_no_misc": 0.624244578741557, "test_runtime": 4.9769, "test_samples_per_second": 411.503, "test_steps_per_second": 12.859}, {"test_loss": 0.10384902358055115, "test_micro_f1": 0.6409638554216868, "test_micro_f1_no_misc": 0.6548488008342023, "test_runtime": 4.1722, "test_samples_per_second": 490.869, "test_steps_per_second": 15.34}]}, "total": {"test_micro_f1": 63.945743038313, "test_micro_f1_se": 1.0931321006361148, "test_micro_f1_no_misc": 65.36643916935662, "test_micro_f1_no_misc_se": 1.2071757252915463}}, "num_model_parameters": 41871881, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.08174936473369598, "test_micro_f1": 0.6201940352137979, "test_micro_f1_no_misc": 0.6650887573964497, "test_runtime": 3.9006, "test_samples_per_second": 525.051, "test_steps_per_second": 16.408}, {"test_loss": 0.07107679545879364, "test_micro_f1": 0.6419040750090154, "test_micro_f1_no_misc": 0.6816923685251087, "test_runtime": 3.9898, "test_samples_per_second": 513.309, "test_steps_per_second": 16.041}, {"test_loss": 0.08040759712457657, "test_micro_f1": 0.6590594744121715, "test_micro_f1_no_misc": 0.6945386064030131, "test_runtime": 3.7535, "test_samples_per_second": 545.625, "test_steps_per_second": 17.051}, {"test_loss": 0.07889995723962784, "test_micro_f1": 0.6263966480446927, "test_micro_f1_no_misc": 0.6604127579737336, "test_runtime": 3.7622, "test_samples_per_second": 544.368, "test_steps_per_second": 17.012}, {"test_loss": 0.07715977728366852, "test_micro_f1": 0.6535947712418301, "test_micro_f1_no_misc": 0.6893439777854912, "test_runtime": 3.908, "test_samples_per_second": 524.049, "test_steps_per_second": 16.377}, {"test_loss": 0.07359062135219574, "test_micro_f1": 0.6957109084768659, "test_micro_f1_no_misc": 0.725770097670924, "test_runtime": 3.9336, "test_samples_per_second": 520.643, "test_steps_per_second": 16.27}, {"test_loss": 0.07365607470273972, "test_micro_f1": 0.6987461877329717, "test_micro_f1_no_misc": 0.7330798479087451, "test_runtime": 3.6006, "test_samples_per_second": 568.787, "test_steps_per_second": 17.775}, {"test_loss": 0.07284089177846909, "test_micro_f1": 0.6696306429548563, "test_micro_f1_no_misc": 0.7020202020202021, "test_runtime": 3.629, "test_samples_per_second": 564.339, "test_steps_per_second": 17.636}, {"test_loss": 0.07173068821430206, "test_micro_f1": 0.6683081252198382, "test_micro_f1_no_misc": 0.6985350809560524, "test_runtime": 3.7563, "test_samples_per_second": 545.222, "test_steps_per_second": 17.038}, {"test_loss": 0.0792509913444519, "test_micro_f1": 0.6816632583503749, "test_micro_f1_no_misc": 0.7140762463343108, "test_runtime": 3.7284, "test_samples_per_second": 549.302, "test_steps_per_second": 17.166}]}, "total": {"test_micro_f1": 66.15208126656415, "test_micro_f1_se": 1.6615170296749688, "test_micro_f1_no_misc": 69.64557942974031, "test_micro_f1_no_misc_se": 1.4756686908184027}}, "num_model_parameters": 41871881, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.08834464848041534, "test_micro_f1": 0.6290819470117067, "test_micro_f1_no_misc": 0.6688589279842158, "test_runtime": 3.704, "test_samples_per_second": 552.912, "test_steps_per_second": 17.279}, {"test_loss": 0.09451358020305634, "test_micro_f1": 0.6271545207136378, "test_micro_f1_no_misc": 0.6647135416666667, "test_runtime": 3.9528, "test_samples_per_second": 518.112, "test_steps_per_second": 16.191}, {"test_loss": 0.0914546549320221, "test_micro_f1": 0.6060606060606061, "test_micro_f1_no_misc": 0.6465177398160314, "test_runtime": 3.8015, "test_samples_per_second": 538.732, "test_steps_per_second": 16.835}, {"test_loss": 0.10064560174942017, "test_micro_f1": 0.6388296251142944, "test_micro_f1_no_misc": 0.6835359842260927, "test_runtime": 3.7416, "test_samples_per_second": 547.359, "test_steps_per_second": 17.105}, {"test_loss": 0.10386307537555695, "test_micro_f1": 0.6024901305800182, "test_micro_f1_no_misc": 0.6513460275771504, "test_runtime": 3.5376, "test_samples_per_second": 578.93, "test_steps_per_second": 18.092}, {"test_loss": 0.10421361029148102, "test_micro_f1": 0.5972685887708651, "test_micro_f1_no_misc": 0.6365718024206739, "test_runtime": 3.5129, "test_samples_per_second": 582.995, "test_steps_per_second": 18.219}, {"test_loss": 0.08933520317077637, "test_micro_f1": 0.6223885251013409, "test_micro_f1_no_misc": 0.6655495978552279, "test_runtime": 3.8672, "test_samples_per_second": 529.586, "test_steps_per_second": 16.55}, {"test_loss": 0.08128118515014648, "test_micro_f1": 0.6700906344410875, "test_micro_f1_no_misc": 0.7048054919908467, "test_runtime": 4.02, "test_samples_per_second": 509.451, "test_steps_per_second": 15.92}, {"test_loss": 0.0955641120672226, "test_micro_f1": 0.6294670846394984, "test_micro_f1_no_misc": 0.6662092624356775, "test_runtime": 3.5324, "test_samples_per_second": 579.778, "test_steps_per_second": 18.118}, {"test_loss": 0.08929144591093063, "test_micro_f1": 0.6524953789279113, "test_micro_f1_no_misc": 0.6899022801302932, "test_runtime": 3.625, "test_samples_per_second": 564.973, "test_steps_per_second": 17.655}]}, "total": {"test_micro_f1": 62.75327041360966, "test_micro_f1_se": 1.4010578697317033, "test_micro_f1_no_misc": 66.78010656102876, "test_micro_f1_no_misc_se": 1.2773709038462333}}, "num_model_parameters": 41871881, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.5823851823806763, "test_mcc": 0.40921901467417077, "test_macro_f1": 0.6972126713790283, "test_runtime": 1.4838, "test_samples_per_second": 1380.278, "test_steps_per_second": 43.134}, {"test_loss": 0.6897255182266235, "test_mcc": 0.09078254675197812, "test_macro_f1": 0.486730905962627, "test_runtime": 1.5402, "test_samples_per_second": 1329.689, "test_steps_per_second": 41.553}, {"test_loss": 0.6867628693580627, "test_mcc": 0.08999812182468148, "test_macro_f1": 0.53936390884669, "test_runtime": 1.5393, "test_samples_per_second": 1330.502, "test_steps_per_second": 41.578}, {"test_loss": 0.69005286693573, "test_mcc": 0.06900254832360309, "test_macro_f1": 0.4395470351557522, "test_runtime": 1.5272, "test_samples_per_second": 1341.054, "test_steps_per_second": 41.908}, {"test_loss": 0.6259868144989014, "test_mcc": 0.3305373831853354, "test_macro_f1": 0.6420243481912165, "test_runtime": 1.5358, "test_samples_per_second": 1333.511, "test_steps_per_second": 41.672}, {"test_loss": 0.6303728818893433, "test_mcc": 0.3557297714026268, "test_macro_f1": 0.6632627646326277, "test_runtime": 1.4895, "test_samples_per_second": 1374.925, "test_steps_per_second": 42.966}, {"test_loss": 0.6196601986885071, "test_mcc": 0.3785897278950662, "test_macro_f1": 0.6728239011427897, "test_runtime": 1.5329, "test_samples_per_second": 1336.061, "test_steps_per_second": 41.752}, {"test_loss": 0.5847775340080261, "test_mcc": 0.4083157787286276, "test_macro_f1": 0.6990908421963695, "test_runtime": 1.5387, "test_samples_per_second": 1330.969, "test_steps_per_second": 41.593}, {"test_loss": 0.6621620655059814, "test_mcc": 0.24444034321965977, "test_macro_f1": 0.5738035392112688, "test_runtime": 1.5428, "test_samples_per_second": 1327.441, "test_steps_per_second": 41.483}, {"test_loss": 0.6595237255096436, "test_mcc": 0.2511477477271782, "test_macro_f1": 0.5501724232262689, "test_runtime": 1.5324, "test_samples_per_second": 1336.492, "test_steps_per_second": 41.765}]}, "total": {"test_mcc": 26.277629837329275, "test_mcc_se": 8.435991144177475, "test_macro_f1": 59.64032339944638, "test_macro_f1_se": 5.681832853464024}}, "num_model_parameters": 42130946, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6927029490470886, "test_mcc": 0.0, "test_macro_f1": 0.33159268929503916, "test_runtime": 1.9439, "test_samples_per_second": 1053.527, "test_steps_per_second": 32.923}, {"test_loss": 0.690438985824585, "test_mcc": 0.11107021979182356, "test_macro_f1": 0.43794907708299846, "test_runtime": 2.0459, "test_samples_per_second": 1001.019, "test_steps_per_second": 31.282}, {"test_loss": 0.6927008628845215, "test_mcc": -0.0038805025430834177, "test_macro_f1": 0.49379456340944256, "test_runtime": 1.9717, "test_samples_per_second": 1038.721, "test_steps_per_second": 32.46}, {"test_loss": 0.6924116611480713, "test_mcc": 0.06784860932192358, "test_macro_f1": 0.5025403315588123, "test_runtime": 2.0641, "test_samples_per_second": 992.216, "test_steps_per_second": 31.007}, {"test_loss": 0.6910362243652344, "test_mcc": 0.07133062291320805, "test_macro_f1": 0.48982320935292517, "test_runtime": 1.9966, "test_samples_per_second": 1025.726, "test_steps_per_second": 32.054}, {"test_loss": 0.6862585544586182, "test_mcc": 0.0868589145882172, "test_macro_f1": 0.5323927170540367, "test_runtime": 1.9985, "test_samples_per_second": 1024.769, "test_steps_per_second": 32.024}, {"test_loss": 0.6814597249031067, "test_mcc": 0.1247643626246996, "test_macro_f1": 0.5604048776217696, "test_runtime": 1.9527, "test_samples_per_second": 1048.8, "test_steps_per_second": 32.775}, {"test_loss": 0.6929647326469421, "test_mcc": 0.005798421744088781, "test_macro_f1": 0.5004051363831605, "test_runtime": 1.9425, "test_samples_per_second": 1054.305, "test_steps_per_second": 32.947}, {"test_loss": 0.6897517442703247, "test_mcc": 0.0318053697005336, "test_macro_f1": 0.45905103412947434, "test_runtime": 1.9561, "test_samples_per_second": 1047.004, "test_steps_per_second": 32.719}, {"test_loss": 0.6925022602081299, "test_mcc": 0.04677563598320179, "test_macro_f1": 0.5211353715975027, "test_runtime": 2.0157, "test_samples_per_second": 1016.028, "test_steps_per_second": 31.751}]}, "total": {"test_mcc": 5.423716541246128, "test_mcc_se": 2.845581542381736, "test_macro_f1": 48.2908900748516, "test_macro_f1_se": 3.9341590372902595}}, "num_model_parameters": 42130946, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6838467121124268, "test_mcc": 0.10051021900153444, "test_macro_f1": 0.5226165410784639, "test_runtime": 1.8309, "test_samples_per_second": 1118.604, "test_steps_per_second": 34.956}, {"test_loss": 0.6920047998428345, "test_mcc": 0.04391811810696158, "test_macro_f1": 0.5161563299497814, "test_runtime": 1.7922, "test_samples_per_second": 1142.724, "test_steps_per_second": 35.71}, {"test_loss": 0.6957728862762451, "test_mcc": -0.002976631733038407, "test_macro_f1": 0.4960099466696009, "test_runtime": 1.8347, "test_samples_per_second": 1116.262, "test_steps_per_second": 34.883}, {"test_loss": 0.6911629438400269, "test_mcc": 0.06533590719662524, "test_macro_f1": 0.44758786653825444, "test_runtime": 1.8328, "test_samples_per_second": 1117.386, "test_steps_per_second": 34.918}, {"test_loss": 0.6913529634475708, "test_mcc": 0.042873464205525375, "test_macro_f1": 0.5211002782192061, "test_runtime": 1.8059, "test_samples_per_second": 1134.057, "test_steps_per_second": 35.439}, {"test_loss": 0.6929711103439331, "test_mcc": 0.040559128784808246, "test_macro_f1": 0.40362126628993195, "test_runtime": 1.743, "test_samples_per_second": 1174.965, "test_steps_per_second": 36.718}, {"test_loss": 0.6753835678100586, "test_mcc": 0.17319076519921955, "test_macro_f1": 0.576839661903143, "test_runtime": 1.7484, "test_samples_per_second": 1171.336, "test_steps_per_second": 36.604}, {"test_loss": 0.6909622550010681, "test_mcc": 0.04338129510282551, "test_macro_f1": 0.4132972585843313, "test_runtime": 1.7759, "test_samples_per_second": 1153.228, "test_steps_per_second": 36.038}, {"test_loss": 0.6827705502510071, "test_mcc": 0.13720357918561402, "test_macro_f1": 0.5472786711107231, "test_runtime": 1.7503, "test_samples_per_second": 1170.079, "test_steps_per_second": 36.565}, {"test_loss": 0.6930617690086365, "test_mcc": 0.017613262421111504, "test_macro_f1": 0.3920544770461081, "test_runtime": 1.8068, "test_samples_per_second": 1133.483, "test_steps_per_second": 35.421}]}, "total": {"test_mcc": 6.616091074711869, "test_mcc_se": 3.396786069121984, "test_macro_f1": 48.36562297389545, "test_macro_f1_se": 4.022517075102894}}, "num_model_parameters": 42130946, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6928169131278992, "test_mcc": 0.018570819642919133, "test_macro_f1": 0.43098098802079565, "test_runtime": 1.7698, "test_samples_per_second": 1157.173, "test_steps_per_second": 36.162}, {"test_loss": 0.6931718587875366, "test_mcc": -0.01855694888751606, "test_macro_f1": 0.3614507685312172, "test_runtime": 1.8203, "test_samples_per_second": 1125.115, "test_steps_per_second": 35.16}, {"test_loss": 0.6913994550704956, "test_mcc": 0.07041031602578797, "test_macro_f1": 0.5255053260076619, "test_runtime": 1.8359, "test_samples_per_second": 1115.524, "test_steps_per_second": 34.86}, {"test_loss": 0.6949431896209717, "test_mcc": -0.003580967508040334, "test_macro_f1": 0.38595955220137257, "test_runtime": 1.751, "test_samples_per_second": 1169.614, "test_steps_per_second": 36.55}, {"test_loss": 0.6904412508010864, "test_mcc": 0.06671072500569176, "test_macro_f1": 0.4621153151866443, "test_runtime": 1.7804, "test_samples_per_second": 1150.325, "test_steps_per_second": 35.948}, {"test_loss": 0.6805702447891235, "test_mcc": 0.14878584522868965, "test_macro_f1": 0.5658821266266983, "test_runtime": 1.8168, "test_samples_per_second": 1127.233, "test_steps_per_second": 35.226}, {"test_loss": 0.6925045251846313, "test_mcc": 0.04287463366727488, "test_macro_f1": 0.486720422989974, "test_runtime": 1.7851, "test_samples_per_second": 1147.272, "test_steps_per_second": 35.852}, {"test_loss": 0.6905306577682495, "test_mcc": 0.06634627687081585, "test_macro_f1": 0.4982487526586757, "test_runtime": 1.8064, "test_samples_per_second": 1133.763, "test_steps_per_second": 35.43}, {"test_loss": 0.6954716444015503, "test_mcc": 0.0274190672172514, "test_macro_f1": 0.3447740011065406, "test_runtime": 1.7658, "test_samples_per_second": 1159.838, "test_steps_per_second": 36.245}, {"test_loss": 0.7041631937026978, "test_mcc": 0.09726928147227655, "test_macro_f1": 0.5375261628795988, "test_runtime": 1.8197, "test_samples_per_second": 1125.433, "test_steps_per_second": 35.17}]}, "total": {"test_mcc": 5.162490487351508, "test_mcc_se": 3.0678221812812234, "test_macro_f1": 45.991634162091785, "test_macro_f1_se": 4.756639261693499}}, "num_model_parameters": 42130946, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 32.30054221533695, "test_f1": 37.299209564097715}, {"test_em": 26.666666666666668, "test_f1": 31.7785115907551}, {"test_em": 26.197836166924265, "test_f1": 31.7606125198861}, {"test_em": 24.68847352024922, "test_f1": 29.803543025093333}, {"test_em": 32.432432432432435, "test_f1": 36.56032146633652}, {"test_em": 34.541249036237474, "test_f1": 39.203693263514594}, {"test_em": 30.44798785117692, "test_f1": 35.163527130405846}, {"test_em": 25.368502715283164, "test_f1": 30.11234382987993}, {"test_em": 25.176470588235293, "test_f1": 30.32119533676629}, {"test_em": 28.41614906832298, "test_f1": 33.36396173428884}]}, "total": {"test_em": 28.623631026086535, "test_em_se": 2.206822325252954, "test_f1": 33.53669194610242, "test_f1_se": 2.069508409079885}}, "num_model_parameters": 41868290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 30.286599535243997, "test_f1": 35.97793177009344}, {"test_em": 28.449612403100776, "test_f1": 34.21350377448731}, {"test_em": 29.21174652241113, "test_f1": 34.13555413987273}, {"test_em": 28.037383177570092, "test_f1": 32.88060038586283}, {"test_em": 31.274131274131275, "test_f1": 36.78004728867181}, {"test_em": 28.758673862760215, "test_f1": 34.250708171294164}, {"test_em": 27.790432801822323, "test_f1": 32.58525175323488}, {"test_em": 28.08378588052754, "test_f1": 33.25947927576378}, {"test_em": 32.627450980392155, "test_f1": 38.27742953472331}, {"test_em": 31.599378881987576, "test_f1": 37.36106425295631}]}, "total": {"test_em": 29.611919531994705, "test_em_se": 1.0662123998026691, "test_f1": 34.97215703469605, "test_f1_se": 1.234659866997633}}, "num_model_parameters": 41868290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 31.913245546088305, "test_f1": 37.747977444405215}, {"test_em": 28.527131782945737, "test_f1": 34.934770677678735}, {"test_em": 32.61205564142195, "test_f1": 37.6969820258455}, {"test_em": 33.8006230529595, "test_f1": 39.3454295850964}, {"test_em": 31.73745173745174, "test_f1": 37.05915532557266}, {"test_em": 34.07864302235929, "test_f1": 39.04186765295262}, {"test_em": 29.08124525436598, "test_f1": 34.522563121260255}, {"test_em": 31.186966640806826, "test_f1": 36.97445332006769}, {"test_em": 32.627450980392155, "test_f1": 38.956745291037784}, {"test_em": 30.667701863354036, "test_f1": 35.95607869093774}]}, "total": {"test_em": 31.623251552214548, "test_em_se": 1.1316886701520654, "test_f1": 37.22360231348546, "test_f1_se": 1.0441317173687954}}, "num_model_parameters": 41868290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6741358041763306, "test_mcc": 0.5598852181522417, "test_macro_f1": 0.5299272060005089, "test_runtime": 0.9908, "test_samples_per_second": 2067.021, "test_steps_per_second": 64.594}, {"test_loss": 0.6695041060447693, "test_mcc": 0.5621574372176332, "test_macro_f1": 0.5305309098855568, "test_runtime": 0.9276, "test_samples_per_second": 2207.816, "test_steps_per_second": 68.994}, {"test_loss": 0.6965596675872803, "test_mcc": 0.5299197914928887, "test_macro_f1": 0.517533932085487, "test_runtime": 0.9545, "test_samples_per_second": 2145.537, "test_steps_per_second": 67.048}, {"test_loss": 0.6795926094055176, "test_mcc": 0.546093777121311, "test_macro_f1": 0.522837508883223, "test_runtime": 0.9225, "test_samples_per_second": 2220.108, "test_steps_per_second": 69.378}, {"test_loss": 0.6345189213752747, "test_mcc": 0.6165027841266177, "test_macro_f1": 0.5518389294036087, "test_runtime": 0.8994, "test_samples_per_second": 2277.031, "test_steps_per_second": 71.157}, {"test_loss": 0.6938681602478027, "test_mcc": 0.5412523109681397, "test_macro_f1": 0.5224065029700404, "test_runtime": 0.9557, "test_samples_per_second": 2142.996, "test_steps_per_second": 66.969}, {"test_loss": 0.6380332708358765, "test_mcc": 0.5963910921185297, "test_macro_f1": 0.5435203012797917, "test_runtime": 0.9039, "test_samples_per_second": 2265.614, "test_steps_per_second": 70.8}, {"test_loss": 0.6522385478019714, "test_mcc": 0.5787885461462453, "test_macro_f1": 0.5363955892178889, "test_runtime": 0.9846, "test_samples_per_second": 2079.989, "test_steps_per_second": 65.0}, {"test_loss": 0.647669792175293, "test_mcc": 0.6039702196122446, "test_macro_f1": 0.5473031164328775, "test_runtime": 0.9564, "test_samples_per_second": 2141.354, "test_steps_per_second": 66.917}, {"test_loss": 0.6402275562286377, "test_mcc": 0.6061368268128063, "test_macro_f1": 0.5477907754844652, "test_runtime": 0.9689, "test_samples_per_second": 2113.637, "test_steps_per_second": 66.051}]}, "total": {"test_mcc": 57.41098003768658, "test_mcc_se": 1.8930161158214467, "test_macro_f1": 53.500847716434485, "test_macro_f1_se": 0.7535611724629672}}, "num_model_parameters": 4575491, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 1.0465072393417358, "test_mcc": 0.17312126386718937, "test_macro_f1": 0.34719692515094586, "test_runtime": 0.5607, "test_samples_per_second": 3652.72, "test_steps_per_second": 114.148}, {"test_loss": 1.0017638206481934, "test_mcc": 0.2580384056549915, "test_macro_f1": 0.46950226354123287, "test_runtime": 0.5591, "test_samples_per_second": 3662.952, "test_steps_per_second": 114.467}, {"test_loss": 1.0232006311416626, "test_mcc": 0.20088429020542822, "test_macro_f1": 0.3754404073841315, "test_runtime": 0.5626, "test_samples_per_second": 3640.184, "test_steps_per_second": 113.756}, {"test_loss": 1.0185165405273438, "test_mcc": 0.22234153927318767, "test_macro_f1": 0.4493704977356758, "test_runtime": 0.5685, "test_samples_per_second": 3602.239, "test_steps_per_second": 112.57}, {"test_loss": 1.0329160690307617, "test_mcc": 0.21488201230073378, "test_macro_f1": 0.3879252777774089, "test_runtime": 0.5537, "test_samples_per_second": 3699.057, "test_steps_per_second": 115.596}, {"test_loss": 1.058039903640747, "test_mcc": 0.1658994101790163, "test_macro_f1": 0.3510775835315465, "test_runtime": 0.5596, "test_samples_per_second": 3659.44, "test_steps_per_second": 114.357}, {"test_loss": 1.017730951309204, "test_mcc": 0.22741143634932068, "test_macro_f1": 0.45018965626266577, "test_runtime": 0.5681, "test_samples_per_second": 3604.697, "test_steps_per_second": 112.647}, {"test_loss": 1.0299708843231201, "test_mcc": 0.18804508287872987, "test_macro_f1": 0.3878987527191779, "test_runtime": 0.573, "test_samples_per_second": 3573.944, "test_steps_per_second": 111.686}, {"test_loss": 1.0360850095748901, "test_mcc": 0.21331235990817, "test_macro_f1": 0.37720017391590344, "test_runtime": 0.5549, "test_samples_per_second": 3690.938, "test_steps_per_second": 115.342}, {"test_loss": 1.0349774360656738, "test_mcc": 0.20716054961060146, "test_macro_f1": 0.41103565024251515, "test_runtime": 0.5577, "test_samples_per_second": 3672.249, "test_steps_per_second": 114.758}]}, "total": {"test_mcc": 20.710963502273692, "test_mcc_se": 1.6774903042013118, "test_macro_f1": 40.06837188261203, "test_macro_f1_se": 2.6539277731086335}}, "num_model_parameters": 4575491, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 1.0030518770217896, "test_mcc": 0.07906989298330369, "test_macro_f1": 0.2954787426727563, "test_runtime": 0.4826, "test_samples_per_second": 4243.655, "test_steps_per_second": 132.614}, {"test_loss": 0.9530434608459473, "test_mcc": 0.20976831594664272, "test_macro_f1": 0.38761450629877725, "test_runtime": 0.4711, "test_samples_per_second": 4347.683, "test_steps_per_second": 135.865}, {"test_loss": 0.9542444944381714, "test_mcc": 0.20916071120226631, "test_macro_f1": 0.38483586017752985, "test_runtime": 0.4882, "test_samples_per_second": 4195.427, "test_steps_per_second": 131.107}, {"test_loss": 0.9828073382377625, "test_mcc": 0.20130626178961605, "test_macro_f1": 0.3814509296039639, "test_runtime": 0.4785, "test_samples_per_second": 4280.162, "test_steps_per_second": 133.755}, {"test_loss": 0.9673551321029663, "test_mcc": 0.23930731874963407, "test_macro_f1": 0.39984494790815406, "test_runtime": 0.4785, "test_samples_per_second": 4280.339, "test_steps_per_second": 133.761}, {"test_loss": 0.9622809886932373, "test_mcc": 0.20837466770467836, "test_macro_f1": 0.38606672930914665, "test_runtime": 0.4799, "test_samples_per_second": 4267.241, "test_steps_per_second": 133.351}, {"test_loss": 0.9703016877174377, "test_mcc": 0.1533662365876451, "test_macro_f1": 0.3422967539738268, "test_runtime": 0.476, "test_samples_per_second": 4302.12, "test_steps_per_second": 134.441}, {"test_loss": 0.9707434177398682, "test_mcc": 0.2149795199591764, "test_macro_f1": 0.3892664353190669, "test_runtime": 0.4786, "test_samples_per_second": 4279.128, "test_steps_per_second": 133.723}, {"test_loss": 0.9759098291397095, "test_mcc": 0.1786108539227518, "test_macro_f1": 0.3719817538783055, "test_runtime": 0.4753, "test_samples_per_second": 4308.509, "test_steps_per_second": 134.641}, {"test_loss": 0.974541962146759, "test_mcc": 0.22525625592561835, "test_macro_f1": 0.3973995256097235, "test_runtime": 0.4815, "test_samples_per_second": 4252.971, "test_steps_per_second": 132.905}]}, "total": {"test_mcc": 19.19200034771333, "test_mcc_se": 2.8673772569861873, "test_macro_f1": 37.3623618475125, "test_macro_f1_se": 1.973650305766067}}, "num_model_parameters": 4575491, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.12638089060783386, "test_micro_f1": 0.23062015503875968, "test_micro_f1_no_misc": 0.24561403508771928, "test_runtime": 1.9671, "test_samples_per_second": 1041.126, "test_steps_per_second": 32.535}, {"test_loss": 0.12076684832572937, "test_micro_f1": 0.24465440079562406, "test_micro_f1_no_misc": 0.25867507886435326, "test_runtime": 1.7854, "test_samples_per_second": 1147.077, "test_steps_per_second": 35.846}, {"test_loss": 0.12249825894832611, "test_micro_f1": 0.2389687654933069, "test_micro_f1_no_misc": 0.25091098386257155, "test_runtime": 1.7772, "test_samples_per_second": 1152.38, "test_steps_per_second": 36.012}, {"test_loss": 0.1315329670906067, "test_micro_f1": 0.228992628992629, "test_micro_f1_no_misc": 0.24157594608605495, "test_runtime": 1.8796, "test_samples_per_second": 1089.589, "test_steps_per_second": 34.05}, {"test_loss": 0.127485454082489, "test_micro_f1": 0.27190605239385723, "test_micro_f1_no_misc": 0.2858499525166192, "test_runtime": 1.8719, "test_samples_per_second": 1094.05, "test_steps_per_second": 34.189}, {"test_loss": 0.1317954957485199, "test_micro_f1": 0.23237597911227154, "test_micro_f1_no_misc": 0.24722222222222223, "test_runtime": 1.7425, "test_samples_per_second": 1175.324, "test_steps_per_second": 36.729}, {"test_loss": 0.13971246778964996, "test_micro_f1": 0.2086491306286224, "test_micro_f1_no_misc": 0.21992481203007516, "test_runtime": 1.8177, "test_samples_per_second": 1126.693, "test_steps_per_second": 35.209}, {"test_loss": 0.1123233288526535, "test_micro_f1": 0.32412714955706096, "test_micro_f1_no_misc": 0.34288864388092616, "test_runtime": 1.7991, "test_samples_per_second": 1138.343, "test_steps_per_second": 35.573}, {"test_loss": 0.1212923526763916, "test_micro_f1": 0.2753824756606398, "test_micro_f1_no_misc": 0.29146221786064774, "test_runtime": 1.792, "test_samples_per_second": 1142.877, "test_steps_per_second": 35.715}, {"test_loss": 0.1206621378660202, "test_micro_f1": 0.28638497652582157, "test_micro_f1_no_misc": 0.3029397110114599, "test_runtime": 1.8395, "test_samples_per_second": 1113.33, "test_steps_per_second": 34.792}]}, "total": {"test_micro_f1": 25.420617141985925, "test_micro_f1_se": 2.1424531734790846, "test_micro_f1_no_misc": 26.870636034226493, "test_micro_f1_no_misc_se": 2.2645790423271817}}, "num_model_parameters": 4559753, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.1674518585205078, "test_micro_f1": 0.3938805245264691, "test_micro_f1_no_misc": 0.38885370487650406, "test_runtime": 2.2976, "test_samples_per_second": 891.353, "test_steps_per_second": 27.855}, {"test_loss": 0.14533600211143494, "test_micro_f1": 0.4555466022025249, "test_micro_f1_no_misc": 0.4641638225255973, "test_runtime": 2.02, "test_samples_per_second": 1013.849, "test_steps_per_second": 31.683}, {"test_loss": 0.16424304246902466, "test_micro_f1": 0.3989690721649485, "test_micro_f1_no_misc": 0.4077669902912621, "test_runtime": 2.3198, "test_samples_per_second": 882.843, "test_steps_per_second": 27.589}, {"test_loss": 0.15869353711605072, "test_micro_f1": 0.4219823356231599, "test_micro_f1_no_misc": 0.4206092028515878, "test_runtime": 2.267, "test_samples_per_second": 903.406, "test_steps_per_second": 28.231}, {"test_loss": 0.17085814476013184, "test_micro_f1": 0.327141382868937, "test_micro_f1_no_misc": 0.30369889682024653, "test_runtime": 2.3493, "test_samples_per_second": 871.762, "test_steps_per_second": 27.243}, {"test_loss": 0.1743445247411728, "test_micro_f1": 0.3384077863738457, "test_micro_f1_no_misc": 0.3103789126853377, "test_runtime": 2.2197, "test_samples_per_second": 922.644, "test_steps_per_second": 28.833}, {"test_loss": 0.16289091110229492, "test_micro_f1": 0.36032093362509116, "test_micro_f1_no_misc": 0.34946574481458204, "test_runtime": 2.2969, "test_samples_per_second": 891.635, "test_steps_per_second": 27.864}, {"test_loss": 0.13654160499572754, "test_micro_f1": 0.4884154460719041, "test_micro_f1_no_misc": 0.502283105022831, "test_runtime": 2.2331, "test_samples_per_second": 917.12, "test_steps_per_second": 28.66}, {"test_loss": 0.15014755725860596, "test_micro_f1": 0.46070038910505834, "test_micro_f1_no_misc": 0.46789309267615414, "test_runtime": 2.3188, "test_samples_per_second": 883.199, "test_steps_per_second": 27.6}, {"test_loss": 0.14254139363765717, "test_micro_f1": 0.49764767381076846, "test_micro_f1_no_misc": 0.5075342465753424, "test_runtime": 2.0141, "test_samples_per_second": 1016.831, "test_steps_per_second": 31.776}]}, "total": {"test_micro_f1": 41.430121463727076, "test_micro_f1_se": 3.7687319815678118, "test_micro_f1_no_misc": 41.226477191394444, "test_micro_f1_no_misc_se": 4.606649932794794}}, "num_model_parameters": 4559753, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.11973471939563751, "test_micro_f1": 0.4376502919958777, "test_micro_f1_no_misc": 0.46317332356174423, "test_runtime": 1.8662, "test_samples_per_second": 1097.411, "test_steps_per_second": 34.294}, {"test_loss": 0.1061861589550972, "test_micro_f1": 0.4815844336344684, "test_micro_f1_no_misc": 0.5125515174222556, "test_runtime": 1.9049, "test_samples_per_second": 1075.095, "test_steps_per_second": 33.597}, {"test_loss": 0.12258756160736084, "test_micro_f1": 0.454395785314455, "test_micro_f1_no_misc": 0.4806474313863476, "test_runtime": 1.8034, "test_samples_per_second": 1135.624, "test_steps_per_second": 35.488}, {"test_loss": 0.12044381350278854, "test_micro_f1": 0.43608521970705727, "test_micro_f1_no_misc": 0.4563901744393022, "test_runtime": 1.8371, "test_samples_per_second": 1114.798, "test_steps_per_second": 34.837}, {"test_loss": 0.13380077481269836, "test_micro_f1": 0.37383177570093457, "test_micro_f1_no_misc": 0.39473684210526316, "test_runtime": 1.8694, "test_samples_per_second": 1095.55, "test_steps_per_second": 34.236}, {"test_loss": 0.13029739260673523, "test_micro_f1": 0.3762917933130699, "test_micro_f1_no_misc": 0.4007794738551478, "test_runtime": 1.8689, "test_samples_per_second": 1095.826, "test_steps_per_second": 34.245}, {"test_loss": 0.13949190080165863, "test_micro_f1": 0.3737280296022202, "test_micro_f1_no_misc": 0.393485342019544, "test_runtime": 1.7633, "test_samples_per_second": 1161.463, "test_steps_per_second": 36.296}, {"test_loss": 0.11272084712982178, "test_micro_f1": 0.5194976867151355, "test_micro_f1_no_misc": 0.5421940928270043, "test_runtime": 1.8165, "test_samples_per_second": 1127.448, "test_steps_per_second": 35.233}, {"test_loss": 0.11710165441036224, "test_micro_f1": 0.39277504105090305, "test_micro_f1_no_misc": 0.4184744576627012, "test_runtime": 1.8239, "test_samples_per_second": 1122.88, "test_steps_per_second": 35.09}, {"test_loss": 0.11103315651416779, "test_micro_f1": 0.5082765335929893, "test_micro_f1_no_misc": 0.5490196078431373, "test_runtime": 1.8694, "test_samples_per_second": 1095.523, "test_steps_per_second": 34.235}]}, "total": {"test_micro_f1": 43.54116590627111, "test_micro_f1_se": 3.443973354687796, "test_micro_f1_no_misc": 46.114522631224474, "test_micro_f1_no_misc_se": 3.683852554146805}}, "num_model_parameters": 4559753, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.14655496180057526, "test_micro_f1": 0.32249018508132365, "test_micro_f1_no_misc": 0.3387334315169367, "test_runtime": 2.0656, "test_samples_per_second": 991.473, "test_steps_per_second": 30.984}, {"test_loss": 0.13856953382492065, "test_micro_f1": 0.4053137365743358, "test_micro_f1_no_misc": 0.4288277511961723, "test_runtime": 1.987, "test_samples_per_second": 1030.705, "test_steps_per_second": 32.21}, {"test_loss": 0.15314875543117523, "test_micro_f1": 0.32559409997268507, "test_micro_f1_no_misc": 0.3452070663191428, "test_runtime": 1.9188, "test_samples_per_second": 1067.34, "test_steps_per_second": 33.354}, {"test_loss": 0.17989963293075562, "test_micro_f1": 0.22435897435897437, "test_micro_f1_no_misc": 0.23742227247032222, "test_runtime": 1.938, "test_samples_per_second": 1056.77, "test_steps_per_second": 33.024}, {"test_loss": 0.1592213660478592, "test_micro_f1": 0.33023510114816845, "test_micro_f1_no_misc": 0.3551896501029109, "test_runtime": 1.846, "test_samples_per_second": 1109.413, "test_steps_per_second": 34.669}, {"test_loss": 0.16623735427856445, "test_micro_f1": 0.29101667563206024, "test_micro_f1_no_misc": 0.30834995725277853, "test_runtime": 1.8647, "test_samples_per_second": 1098.325, "test_steps_per_second": 34.323}, {"test_loss": 0.1555459350347519, "test_micro_f1": 0.29042166992460205, "test_micro_f1_no_misc": 0.3067846607669616, "test_runtime": 1.9583, "test_samples_per_second": 1045.779, "test_steps_per_second": 32.681}, {"test_loss": 0.13832245767116547, "test_micro_f1": 0.428780345130155, "test_micro_f1_no_misc": 0.4547146401985111, "test_runtime": 2.0122, "test_samples_per_second": 1017.787, "test_steps_per_second": 31.806}, {"test_loss": 0.1720108985900879, "test_micro_f1": 0.25216178521617855, "test_micro_f1_no_misc": 0.26706056129985223, "test_runtime": 1.8272, "test_samples_per_second": 1120.866, "test_steps_per_second": 35.027}, {"test_loss": 0.13083750009536743, "test_micro_f1": 0.45153733528550516, "test_micro_f1_no_misc": 0.4754856614246068, "test_runtime": 1.9069, "test_samples_per_second": 1074.006, "test_steps_per_second": 33.563}]}, "total": {"test_micro_f1": 33.21909908323988, "test_micro_f1_se": 4.644361768371486, "test_micro_f1_no_misc": 35.17775652548195, "test_micro_f1_no_misc_se": 4.898948070583577}}, "num_model_parameters": 4559753, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6939345598220825, "test_mcc": -0.028011128743483604, "test_macro_f1": 0.4782768089428694, "test_runtime": 0.4524, "test_samples_per_second": 4527.113, "test_steps_per_second": 141.472}, {"test_loss": 0.6924828290939331, "test_mcc": 0.039801086056700144, "test_macro_f1": 0.5192212997423418, "test_runtime": 0.4687, "test_samples_per_second": 4369.849, "test_steps_per_second": 136.558}, {"test_loss": 0.6941193342208862, "test_mcc": -0.03858069405979564, "test_macro_f1": 0.47144031386701424, "test_runtime": 0.4493, "test_samples_per_second": 4558.303, "test_steps_per_second": 142.447}, {"test_loss": 0.6933532953262329, "test_mcc": -0.0074800707917016766, "test_macro_f1": 0.48746608991671414, "test_runtime": 0.4598, "test_samples_per_second": 4454.041, "test_steps_per_second": 139.189}, {"test_loss": 0.6939953565597534, "test_mcc": -0.008396694342277227, "test_macro_f1": 0.4955177861371265, "test_runtime": 0.4555, "test_samples_per_second": 4495.832, "test_steps_per_second": 140.495}, {"test_loss": 0.6936007738113403, "test_mcc": -0.005350896865651109, "test_macro_f1": 0.48580516836457566, "test_runtime": 0.4466, "test_samples_per_second": 4585.365, "test_steps_per_second": 143.293}, {"test_loss": 0.6944708824157715, "test_mcc": -0.0038506897739981013, "test_macro_f1": 0.49795303229744936, "test_runtime": 0.4511, "test_samples_per_second": 4539.564, "test_steps_per_second": 141.861}, {"test_loss": 0.694059431552887, "test_mcc": -0.028762409383855412, "test_macro_f1": 0.4825944411151808, "test_runtime": 0.4503, "test_samples_per_second": 4547.745, "test_steps_per_second": 142.117}, {"test_loss": 0.6933598518371582, "test_mcc": -0.006541261344650336, "test_macro_f1": 0.47874213836477986, "test_runtime": 0.4518, "test_samples_per_second": 4533.079, "test_steps_per_second": 141.659}, {"test_loss": 0.6934128999710083, "test_mcc": -0.018617992999143677, "test_macro_f1": 0.47484331747593234, "test_runtime": 0.447, "test_samples_per_second": 4581.335, "test_steps_per_second": 143.167}]}, "total": {"test_mcc": -1.0579075224785663, "test_mcc_se": 1.3268717813842903, "test_macro_f1": 48.71860396223984, "test_macro_f1_se": 0.8730295008626509}}, "num_model_parameters": 4575362, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6929346323013306, "test_mcc": 0.019005964978108775, "test_macro_f1": 0.4966240150365068, "test_runtime": 0.508, "test_samples_per_second": 4031.251, "test_steps_per_second": 125.977}, {"test_loss": 0.6931390762329102, "test_mcc": 0.004869506606242473, "test_macro_f1": 0.4872746533857616, "test_runtime": 0.5059, "test_samples_per_second": 4048.398, "test_steps_per_second": 126.512}, {"test_loss": 0.6926574110984802, "test_mcc": 0.032949840409517046, "test_macro_f1": 0.5163783331997572, "test_runtime": 0.5068, "test_samples_per_second": 4040.668, "test_steps_per_second": 126.271}, {"test_loss": 0.6931467056274414, "test_mcc": -0.01607903891372396, "test_macro_f1": 0.4484023288864438, "test_runtime": 0.5129, "test_samples_per_second": 3993.227, "test_steps_per_second": 124.788}, {"test_loss": 0.6936532855033875, "test_mcc": -0.0154882674522729, "test_macro_f1": 0.4860348609561197, "test_runtime": 0.5042, "test_samples_per_second": 4061.838, "test_steps_per_second": 126.932}, {"test_loss": 0.6928905844688416, "test_mcc": 0.02131064651201857, "test_macro_f1": 0.4867167919799499, "test_runtime": 0.5098, "test_samples_per_second": 4016.943, "test_steps_per_second": 125.529}, {"test_loss": 0.6936279535293579, "test_mcc": 0.010615255872077166, "test_macro_f1": 0.4728426811676798, "test_runtime": 0.4964, "test_samples_per_second": 4125.439, "test_steps_per_second": 128.92}, {"test_loss": 0.6928913593292236, "test_mcc": 0.0068934479696546504, "test_macro_f1": 0.4663650660645662, "test_runtime": 0.5066, "test_samples_per_second": 4042.95, "test_steps_per_second": 126.342}, {"test_loss": 0.6928698420524597, "test_mcc": 0.03338227869205952, "test_macro_f1": 0.5163702169714257, "test_runtime": 0.5172, "test_samples_per_second": 3960.088, "test_steps_per_second": 123.753}, {"test_loss": 0.6931891441345215, "test_mcc": 0.02121483902993098, "test_macro_f1": 0.46865000432413734, "test_runtime": 0.5275, "test_samples_per_second": 3882.514, "test_steps_per_second": 121.329}]}, "total": {"test_mcc": 1.186744737036123, "test_mcc_se": 1.0813569640576473, "test_macro_f1": 48.45658951972348, "test_macro_f1_se": 1.3409877906421401}}, "num_model_parameters": 4575362, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.692602276802063, "test_mcc": 0.059889390231727305, "test_macro_f1": 0.5292896925307089, "test_runtime": 0.4856, "test_samples_per_second": 4217.846, "test_steps_per_second": 131.808}, {"test_loss": 0.6932992339134216, "test_mcc": 0.0385474206665164, "test_macro_f1": 0.49314685175535355, "test_runtime": 0.4957, "test_samples_per_second": 4131.228, "test_steps_per_second": 129.101}, {"test_loss": 0.6929283738136292, "test_mcc": -0.010423612894974212, "test_macro_f1": 0.4945275539571948, "test_runtime": 0.4823, "test_samples_per_second": 4246.277, "test_steps_per_second": 132.696}, {"test_loss": 0.6938053369522095, "test_mcc": 0.015399723977935155, "test_macro_f1": 0.5045865407184223, "test_runtime": 0.481, "test_samples_per_second": 4258.227, "test_steps_per_second": 133.07}, {"test_loss": 0.6926530599594116, "test_mcc": 0.031114324873251244, "test_macro_f1": 0.5147290376824887, "test_runtime": 0.4848, "test_samples_per_second": 4224.428, "test_steps_per_second": 132.013}, {"test_loss": 0.6928164958953857, "test_mcc": 0.0362162175953879, "test_macro_f1": 0.516606964516719, "test_runtime": 0.4811, "test_samples_per_second": 4256.529, "test_steps_per_second": 133.017}, {"test_loss": 0.6909826993942261, "test_mcc": 0.04788232181095429, "test_macro_f1": 0.5228308904253411, "test_runtime": 0.4784, "test_samples_per_second": 4280.742, "test_steps_per_second": 133.773}, {"test_loss": 0.6930628418922424, "test_mcc": 0.027389138986183562, "test_macro_f1": 0.5129281651745645, "test_runtime": 0.4849, "test_samples_per_second": 4223.333, "test_steps_per_second": 131.979}, {"test_loss": 0.6934892535209656, "test_mcc": -0.00922665581715024, "test_macro_f1": 0.49098097356066217, "test_runtime": 0.4838, "test_samples_per_second": 4232.738, "test_steps_per_second": 132.273}, {"test_loss": 0.6924657225608826, "test_mcc": 0.03954233025345103, "test_macro_f1": 0.5195312499999999, "test_runtime": 0.4815, "test_samples_per_second": 4252.967, "test_steps_per_second": 132.905}]}, "total": {"test_mcc": 2.7633059968328246, "test_mcc_se": 1.4244929537228879, "test_macro_f1": 50.99157920321454, "test_macro_f1_se": 0.8306695495958536}}, "num_model_parameters": 4575362, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6921939849853516, "test_mcc": 0.02975486195595937, "test_macro_f1": 0.5083894596416821, "test_runtime": 0.4882, "test_samples_per_second": 4195.246, "test_steps_per_second": 131.101}, {"test_loss": 0.6928762197494507, "test_mcc": 0.01583021214776777, "test_macro_f1": 0.5073704436502824, "test_runtime": 0.4893, "test_samples_per_second": 4185.859, "test_steps_per_second": 130.808}, {"test_loss": 0.6935912370681763, "test_mcc": -0.00996204180556061, "test_macro_f1": 0.46804660299533274, "test_runtime": 0.4916, "test_samples_per_second": 4166.273, "test_steps_per_second": 130.196}, {"test_loss": 0.6932070851325989, "test_mcc": -0.010806288923983462, "test_macro_f1": 0.49449765871771423, "test_runtime": 0.4861, "test_samples_per_second": 4213.262, "test_steps_per_second": 131.664}, {"test_loss": 0.6923189163208008, "test_mcc": 0.023765124527030747, "test_macro_f1": 0.4856840163855255, "test_runtime": 0.475, "test_samples_per_second": 4311.567, "test_steps_per_second": 134.736}, {"test_loss": 0.6934800148010254, "test_mcc": 0.0017234890758849916, "test_macro_f1": 0.49855845988461883, "test_runtime": 0.4954, "test_samples_per_second": 4134.32, "test_steps_per_second": 129.198}, {"test_loss": 0.6929651498794556, "test_mcc": 0.011113404219707383, "test_macro_f1": 0.4976805268545163, "test_runtime": 0.4765, "test_samples_per_second": 4297.879, "test_steps_per_second": 134.309}, {"test_loss": 0.6940029859542847, "test_mcc": -0.0023374541012726054, "test_macro_f1": 0.49862131168663837, "test_runtime": 0.4866, "test_samples_per_second": 4208.497, "test_steps_per_second": 131.516}, {"test_loss": 0.6937633156776428, "test_mcc": -0.024593502384955366, "test_macro_f1": 0.47811721399675167, "test_runtime": 0.4915, "test_samples_per_second": 4166.55, "test_steps_per_second": 130.205}, {"test_loss": 0.6930103898048401, "test_mcc": 0.00787805665180489, "test_macro_f1": 0.5017329626035052, "test_runtime": 0.4853, "test_samples_per_second": 4219.829, "test_steps_per_second": 131.87}]}, "total": {"test_mcc": 0.4236586136238311, "test_mcc_se": 1.0404435594537866, "test_macro_f1": 49.38698656416567, "test_macro_f1_se": 0.7992010615748488}}, "num_model_parameters": 4575362, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 6.893880712625871, "test_f1": 11.59967369367168}, {"test_em": 9.30232558139535, "test_f1": 16.176634380464755}, {"test_em": 0.9273570324574961, "test_f1": 1.1868185052110864}, {"test_em": 2.4922118380062304, "test_f1": 3.575537172293631}, {"test_em": 12.972972972972974, "test_f1": 20.298975067882647}, {"test_em": 7.632999228989977, "test_f1": 12.71081347082527}, {"test_em": 1.8223234624145785, "test_f1": 2.8071780577475334}, {"test_em": 13.498836307214896, "test_f1": 20.394478921951226}, {"test_em": 18.823529411764707, "test_f1": 25.47846356480487}, {"test_em": 0.6211180124223602, "test_f1": 0.7968661773009599}]}, "total": {"test_em": 7.498755456026444, "test_em_se": 3.8409545349929, "test_f1": 11.502543901215365, "test_f1_se": 5.599486172864927}}, "num_model_parameters": 4558850, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 3.3307513555383426, "test_f1": 7.249513833779035}, {"test_em": 8.992248062015504, "test_f1": 17.207939061762268}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 4.595015576323988, "test_f1": 7.882504930677001}, {"test_em": 8.957528957528957, "test_f1": 14.91207179951099}, {"test_em": 0.2313030069390902, "test_f1": 0.4324930364660057}, {"test_em": 1.5186028853454823, "test_f1": 3.3214299608511055}, {"test_em": 1.3964313421256789, "test_f1": 2.28219398547274}, {"test_em": 7.686274509803922, "test_f1": 14.305013773198075}, {"test_em": 0.2329192546583851, "test_f1": 0.4441297143160498}]}, "total": {"test_em": 3.6941074950279345, "test_em_se": 2.2658930425063613, "test_f1": 6.803729009603326, "test_f1_se": 4.088024861214703}}, "num_model_parameters": 4558850, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 8.675445391169635, "test_f1": 14.854438674958466}, {"test_em": 12.713178294573643, "test_f1": 22.228150110834125}, {"test_em": 0.0, "test_f1": 0.028101728256287758}, {"test_em": 11.7601246105919, "test_f1": 19.04072209345228}, {"test_em": 12.123552123552123, "test_f1": 19.157018720015113}, {"test_em": 2.158828064764842, "test_f1": 3.8925152583368363}, {"test_em": 4.6317388003037205, "test_f1": 10.064297708824595}, {"test_em": 7.21489526764934, "test_f1": 13.801304214072895}, {"test_em": 10.27450980392157, "test_f1": 16.677868641809656}, {"test_em": 3.3385093167701863, "test_f1": 6.561068470663832}]}, "total": {"test_em": 7.289078167329696, "test_em_se": 2.8157237904043138, "test_f1": 12.630548562122408, "test_f1_se": 4.512709933506943}}, "num_model_parameters": 4558850, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.5807465314865112, "test_mcc": 0.6167236031636545, "test_macro_f1": 0.5485736699937197, "test_runtime": 17.4076, "test_samples_per_second": 117.65, "test_steps_per_second": 14.706}, {"test_loss": 0.6219038963317871, "test_mcc": 0.5834788929831448, "test_macro_f1": 0.538652775618776, "test_runtime": 16.8666, "test_samples_per_second": 121.424, "test_steps_per_second": 15.178}, {"test_loss": 0.678077757358551, "test_mcc": 0.5866578164112001, "test_macro_f1": 0.6448612526078739, "test_runtime": 17.0722, "test_samples_per_second": 119.961, "test_steps_per_second": 14.995}, {"test_loss": 0.5725217461585999, "test_mcc": 0.6393600839340525, "test_macro_f1": 0.6743281539315142, "test_runtime": 16.7058, "test_samples_per_second": 122.592, "test_steps_per_second": 15.324}, {"test_loss": 0.6647512912750244, "test_mcc": 0.5696254417759355, "test_macro_f1": 0.5278647548597389, "test_runtime": 16.6707, "test_samples_per_second": 122.85, "test_steps_per_second": 15.356}, {"test_loss": 0.5535286664962769, "test_mcc": 0.6418958519130471, "test_macro_f1": 0.5695440092811485, "test_runtime": 17.0408, "test_samples_per_second": 120.182, "test_steps_per_second": 15.023}, {"test_loss": 0.5637654066085815, "test_mcc": 0.6489277371017786, "test_macro_f1": 0.5744686449334125, "test_runtime": 16.5054, "test_samples_per_second": 124.08, "test_steps_per_second": 15.51}, {"test_loss": 0.6307693123817444, "test_mcc": 0.6433108668522642, "test_macro_f1": 0.6632924742681676, "test_runtime": 17.6765, "test_samples_per_second": 115.86, "test_steps_per_second": 14.483}, {"test_loss": 0.6079012155532837, "test_mcc": 0.6226461785991325, "test_macro_f1": 0.5615129374399415, "test_runtime": 17.3806, "test_samples_per_second": 117.832, "test_steps_per_second": 14.729}, {"test_loss": 0.5577095150947571, "test_mcc": 0.6269463291239831, "test_macro_f1": 0.5900952971720684, "test_runtime": 16.9867, "test_samples_per_second": 120.565, "test_steps_per_second": 15.071}]}, "total": {"test_mcc": 61.79572801858193, "test_mcc_se": 1.7581589339570578, "test_macro_f1": 58.9319397010636, "test_macro_f1_se": 3.2779373776661838}}, "num_model_parameters": 111442179, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.9609929919242859, "test_mcc": 0.34885854674431394, "test_macro_f1": 0.5637886691960267, "test_runtime": 5.0242, "test_samples_per_second": 407.63, "test_steps_per_second": 12.738}, {"test_loss": 0.9992303848266602, "test_mcc": 0.3754982907978399, "test_macro_f1": 0.5742337752652132, "test_runtime": 4.9997, "test_samples_per_second": 409.625, "test_steps_per_second": 12.801}, {"test_loss": 0.9617420434951782, "test_mcc": 0.33377943855990083, "test_macro_f1": 0.5547501258844011, "test_runtime": 4.9932, "test_samples_per_second": 410.161, "test_steps_per_second": 12.818}, {"test_loss": 0.9783861041069031, "test_mcc": 0.3522055124911711, "test_macro_f1": 0.5651036902942872, "test_runtime": 5.0409, "test_samples_per_second": 406.275, "test_steps_per_second": 12.696}, {"test_loss": 1.0584194660186768, "test_mcc": 0.28470808039645223, "test_macro_f1": 0.4935067220840718, "test_runtime": 4.9497, "test_samples_per_second": 413.765, "test_steps_per_second": 12.93}, {"test_loss": 1.0241501331329346, "test_mcc": 0.3334491092681493, "test_macro_f1": 0.543436020371379, "test_runtime": 5.0766, "test_samples_per_second": 403.421, "test_steps_per_second": 12.607}, {"test_loss": 0.9355447292327881, "test_mcc": 0.3415146453283336, "test_macro_f1": 0.5367777215631265, "test_runtime": 5.1231, "test_samples_per_second": 399.76, "test_steps_per_second": 12.492}, {"test_loss": 1.0278069972991943, "test_mcc": 0.336314180536376, "test_macro_f1": 0.5481065248830533, "test_runtime": 5.0813, "test_samples_per_second": 403.044, "test_steps_per_second": 12.595}, {"test_loss": 0.9472579956054688, "test_mcc": 0.33418779045728686, "test_macro_f1": 0.5498238346581169, "test_runtime": 4.9595, "test_samples_per_second": 412.944, "test_steps_per_second": 12.904}, {"test_loss": 0.9954782128334045, "test_mcc": 0.350403158010478, "test_macro_f1": 0.5570431708753926, "test_runtime": 4.9418, "test_samples_per_second": 414.427, "test_steps_per_second": 12.951}]}, "total": {"test_mcc": 33.909187525903015, "test_mcc_se": 1.427802108966262, "test_macro_f1": 54.86570255075067, "test_macro_f1_se": 1.381715832795602}}, "num_model_parameters": 111442179, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.8774535059928894, "test_mcc": 0.32086749936012365, "test_macro_f1": 0.4457893369839865, "test_runtime": 3.9305, "test_samples_per_second": 521.049, "test_steps_per_second": 16.283}, {"test_loss": 0.8529908061027527, "test_mcc": 0.36189855757998135, "test_macro_f1": 0.5248232663338898, "test_runtime": 3.7143, "test_samples_per_second": 551.376, "test_steps_per_second": 17.23}, {"test_loss": 0.8275007009506226, "test_mcc": 0.36345628447132045, "test_macro_f1": 0.4483908264070145, "test_runtime": 3.7511, "test_samples_per_second": 545.973, "test_steps_per_second": 17.062}, {"test_loss": 0.9477381706237793, "test_mcc": 0.3604050781891217, "test_macro_f1": 0.5065517898983695, "test_runtime": 3.7863, "test_samples_per_second": 540.902, "test_steps_per_second": 16.903}, {"test_loss": 0.8776232004165649, "test_mcc": 0.3670503830439288, "test_macro_f1": 0.4738577730259396, "test_runtime": 3.8316, "test_samples_per_second": 534.501, "test_steps_per_second": 16.703}, {"test_loss": 0.9686177968978882, "test_mcc": 0.3364356367732378, "test_macro_f1": 0.5073478333575032, "test_runtime": 3.9823, "test_samples_per_second": 514.273, "test_steps_per_second": 16.071}, {"test_loss": 0.8550126552581787, "test_mcc": 0.3754153818230638, "test_macro_f1": 0.448191046526417, "test_runtime": 3.7705, "test_samples_per_second": 543.161, "test_steps_per_second": 16.974}, {"test_loss": 0.93178790807724, "test_mcc": 0.28526867651524046, "test_macro_f1": 0.4468941216987821, "test_runtime": 3.8277, "test_samples_per_second": 535.052, "test_steps_per_second": 16.72}, {"test_loss": 0.8923897743225098, "test_mcc": 0.372650009788856, "test_macro_f1": 0.5178361681170393, "test_runtime": 3.9282, "test_samples_per_second": 521.363, "test_steps_per_second": 16.293}, {"test_loss": 0.8996005058288574, "test_mcc": 0.3530904381642994, "test_macro_f1": 0.5008834236026504, "test_runtime": 3.9374, "test_samples_per_second": 520.135, "test_steps_per_second": 16.254}]}, "total": {"test_mcc": 34.965379457091736, "test_mcc_se": 1.7423046570493408, "test_macro_f1": 48.20565585951592, "test_macro_f1_se": 2.024539733834901}}, "num_model_parameters": 111442179, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.062278080731630325, "test_micro_f1": 0.7136246786632391, "test_micro_f1_no_misc": 0.7861901877649909, "test_runtime": 8.7626, "test_samples_per_second": 233.72, "test_steps_per_second": 7.304}, {"test_loss": 0.05879649519920349, "test_micro_f1": 0.6922268907563025, "test_micro_f1_no_misc": 0.7541371158392436, "test_runtime": 7.8855, "test_samples_per_second": 259.717, "test_steps_per_second": 8.116}, {"test_loss": 0.060363560914993286, "test_micro_f1": 0.6944045911047345, "test_micro_f1_no_misc": 0.7562744004461796, "test_runtime": 7.9693, "test_samples_per_second": 256.985, "test_steps_per_second": 8.031}, {"test_loss": 0.05804881080985069, "test_micro_f1": 0.6938775510204082, "test_micro_f1_no_misc": 0.735357917570499, "test_runtime": 8.537, "test_samples_per_second": 239.898, "test_steps_per_second": 7.497}, {"test_loss": 0.06798404455184937, "test_micro_f1": 0.6979553903345724, "test_micro_f1_no_misc": 0.7519582245430809, "test_runtime": 8.6808, "test_samples_per_second": 235.923, "test_steps_per_second": 7.373}, {"test_loss": 0.054592013359069824, "test_micro_f1": 0.7073394495412845, "test_micro_f1_no_misc": 0.7673293927995702, "test_runtime": 6.8109, "test_samples_per_second": 300.696, "test_steps_per_second": 9.397}, {"test_loss": 0.06076022982597351, "test_micro_f1": 0.7033073929961089, "test_micro_f1_no_misc": 0.7622222222222222, "test_runtime": 7.6251, "test_samples_per_second": 268.588, "test_steps_per_second": 8.393}, {"test_loss": 0.055425792932510376, "test_micro_f1": 0.6927613941018768, "test_micro_f1_no_misc": 0.7386231038506419, "test_runtime": 8.6157, "test_samples_per_second": 237.706, "test_steps_per_second": 7.428}, {"test_loss": 0.05911720544099808, "test_micro_f1": 0.7061680427391938, "test_micro_f1_no_misc": 0.7450561197220738, "test_runtime": 8.0308, "test_samples_per_second": 255.018, "test_steps_per_second": 7.969}, {"test_loss": 0.05761805176734924, "test_micro_f1": 0.686848635235732, "test_micro_f1_no_misc": 0.735930735930736, "test_runtime": 8.4461, "test_samples_per_second": 242.479, "test_steps_per_second": 7.577}]}, "total": {"test_micro_f1": 69.88514016493453, "test_micro_f1_se": 0.5202275762630653, "test_micro_f1_no_misc": 75.33079420689238, "test_micro_f1_no_misc_se": 0.9857595033592854}}, "num_model_parameters": 110856201, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.06402187794446945, "test_micro_f1": 0.8134796238244515, "test_micro_f1_no_misc": 0.8320557491289199, "test_runtime": 9.5277, "test_samples_per_second": 214.952, "test_steps_per_second": 6.717}, {"test_loss": 0.057121641933918, "test_micro_f1": 0.7994366197183098, "test_micro_f1_no_misc": 0.8158386253268585, "test_runtime": 7.1332, "test_samples_per_second": 287.107, "test_steps_per_second": 8.972}, {"test_loss": 0.06344777345657349, "test_micro_f1": 0.7584767866458008, "test_micro_f1_no_misc": 0.775395430579965, "test_runtime": 9.5488, "test_samples_per_second": 214.477, "test_steps_per_second": 6.702}, {"test_loss": 0.06452471017837524, "test_micro_f1": 0.8247096092925026, "test_micro_f1_no_misc": 0.8547866618859806, "test_runtime": 8.8473, "test_samples_per_second": 231.483, "test_steps_per_second": 7.234}, {"test_loss": 0.06633436679840088, "test_micro_f1": 0.7879977565900167, "test_micro_f1_no_misc": 0.8206106870229009, "test_runtime": 9.6443, "test_samples_per_second": 212.352, "test_steps_per_second": 6.636}, {"test_loss": 0.06352756172418594, "test_micro_f1": 0.7957766046123922, "test_micro_f1_no_misc": 0.82777138473341, "test_runtime": 9.1659, "test_samples_per_second": 223.437, "test_steps_per_second": 6.982}, {"test_loss": 0.06709132343530655, "test_micro_f1": 0.805921938088829, "test_micro_f1_no_misc": 0.8247499073731013, "test_runtime": 9.7116, "test_samples_per_second": 210.881, "test_steps_per_second": 6.59}, {"test_loss": 0.052272550761699677, "test_micro_f1": 0.8270344827586206, "test_micro_f1_no_misc": 0.851221317542561, "test_runtime": 9.6291, "test_samples_per_second": 212.689, "test_steps_per_second": 6.647}, {"test_loss": 0.0600169412791729, "test_micro_f1": 0.8077858880778589, "test_micro_f1_no_misc": 0.8234426833763362, "test_runtime": 8.9148, "test_samples_per_second": 229.729, "test_steps_per_second": 7.179}, {"test_loss": 0.05881204828619957, "test_micro_f1": 0.8270110304008609, "test_micro_f1_no_misc": 0.855457227138643, "test_runtime": 7.8792, "test_samples_per_second": 259.926, "test_steps_per_second": 8.123}]}, "total": {"test_micro_f1": 80.47630340009644, "test_micro_f1_se": 1.3079619287004358, "test_micro_f1_no_misc": 82.81329674108676, "test_micro_f1_no_misc_se": 1.4649902211942072}}, "num_model_parameters": 110856201, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.036577366292476654, "test_micro_f1": 0.8527696793002916, "test_micro_f1_no_misc": 0.8851379168382051, "test_runtime": 6.9937, "test_samples_per_second": 292.836, "test_steps_per_second": 9.151}, {"test_loss": 0.03453686088323593, "test_micro_f1": 0.8592927012791574, "test_micro_f1_no_misc": 0.889358108108108, "test_runtime": 7.0649, "test_samples_per_second": 289.883, "test_steps_per_second": 9.059}, {"test_loss": 0.04799966514110565, "test_micro_f1": 0.8346289752650177, "test_micro_f1_no_misc": 0.8669833729216151, "test_runtime": 6.5346, "test_samples_per_second": 313.411, "test_steps_per_second": 9.794}, {"test_loss": 0.03538968041539192, "test_micro_f1": 0.8718672785033534, "test_micro_f1_no_misc": 0.8973954222573007, "test_runtime": 6.421, "test_samples_per_second": 318.953, "test_steps_per_second": 9.967}, {"test_loss": 0.03446778655052185, "test_micro_f1": 0.871986417657046, "test_micro_f1_no_misc": 0.9021820917983446, "test_runtime": 7.0041, "test_samples_per_second": 292.402, "test_steps_per_second": 9.138}, {"test_loss": 0.03102659061551094, "test_micro_f1": 0.8889652801650052, "test_micro_f1_no_misc": 0.9238578680203046, "test_runtime": 7.0397, "test_samples_per_second": 290.921, "test_steps_per_second": 9.091}, {"test_loss": 0.039959218353033066, "test_micro_f1": 0.8354344122657581, "test_micro_f1_no_misc": 0.8625982777985773, "test_runtime": 6.2811, "test_samples_per_second": 326.058, "test_steps_per_second": 10.189}, {"test_loss": 0.03598593547940254, "test_micro_f1": 0.8663434903047093, "test_micro_f1_no_misc": 0.8968405024743052, "test_runtime": 6.4545, "test_samples_per_second": 317.3, "test_steps_per_second": 9.916}, {"test_loss": 0.03376453369855881, "test_micro_f1": 0.8570397111913358, "test_micro_f1_no_misc": 0.8879803761242846, "test_runtime": 6.3934, "test_samples_per_second": 320.33, "test_steps_per_second": 10.01}, {"test_loss": 0.04435211420059204, "test_micro_f1": 0.8508741858073363, "test_micro_f1_no_misc": 0.8941717791411044, "test_runtime": 6.8551, "test_samples_per_second": 298.757, "test_steps_per_second": 9.336}]}, "total": {"test_micro_f1": 85.89202131739012, "test_micro_f1_se": 1.0420724086015136, "test_micro_f1_no_misc": 89.06505715482149, "test_micro_f1_no_misc_se": 1.0771413958237837}}, "num_model_parameters": 110856201, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.05437785014510155, "test_micro_f1": 0.7848729076255425, "test_micro_f1_no_misc": 0.8259109311740892, "test_runtime": 6.3204, "test_samples_per_second": 324.03, "test_steps_per_second": 10.126}, {"test_loss": 0.05395447835326195, "test_micro_f1": 0.8010849909584087, "test_micro_f1_no_misc": 0.8300000000000001, "test_runtime": 6.5472, "test_samples_per_second": 312.807, "test_steps_per_second": 9.775}, {"test_loss": 0.05829280614852905, "test_micro_f1": 0.7769138755980861, "test_micro_f1_no_misc": 0.8202396804260985, "test_runtime": 6.2603, "test_samples_per_second": 327.14, "test_steps_per_second": 10.223}, {"test_loss": 0.06041664257645607, "test_micro_f1": 0.7792833483890395, "test_micro_f1_no_misc": 0.8114285714285714, "test_runtime": 6.5407, "test_samples_per_second": 313.117, "test_steps_per_second": 9.785}, {"test_loss": 0.06266925483942032, "test_micro_f1": 0.7912417516496701, "test_micro_f1_no_misc": 0.8170068027210884, "test_runtime": 6.2749, "test_samples_per_second": 326.382, "test_steps_per_second": 10.199}, {"test_loss": 0.057754527777433395, "test_micro_f1": 0.7687705653604547, "test_micro_f1_no_misc": 0.8038952316991269, "test_runtime": 6.4587, "test_samples_per_second": 317.094, "test_steps_per_second": 9.909}, {"test_loss": 0.05423824489116669, "test_micro_f1": 0.8138016785825303, "test_micro_f1_no_misc": 0.8528381219341274, "test_runtime": 6.587, "test_samples_per_second": 310.914, "test_steps_per_second": 9.716}, {"test_loss": 0.05441669747233391, "test_micro_f1": 0.7965791081246182, "test_micro_f1_no_misc": 0.8293998651382334, "test_runtime": 6.6107, "test_samples_per_second": 309.802, "test_steps_per_second": 9.681}, {"test_loss": 0.0639430582523346, "test_micro_f1": 0.7964274715121651, "test_micro_f1_no_misc": 0.8366921473245309, "test_runtime": 5.9923, "test_samples_per_second": 341.771, "test_steps_per_second": 10.68}, {"test_loss": 0.052396755665540695, "test_micro_f1": 0.812938663411657, "test_micro_f1_no_misc": 0.8415481309956996, "test_runtime": 6.3419, "test_samples_per_second": 322.93, "test_steps_per_second": 10.092}]}, "total": {"test_micro_f1": 79.21914361212171, "test_micro_f1_se": 0.9278169585619223, "test_micro_f1_no_misc": 82.68959482841565, "test_micro_f1_no_misc_se": 0.9031366643376812}}, "num_model_parameters": 110856201, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.6512274742126465, "test_mcc": 0.4262066170189035, "test_macro_f1": 0.696265570204885, "test_runtime": 4.0028, "test_samples_per_second": 511.636, "test_steps_per_second": 15.989}, {"test_loss": 0.6286028623580933, "test_mcc": 0.4195575147445699, "test_macro_f1": 0.7004334925464777, "test_runtime": 4.2356, "test_samples_per_second": 483.525, "test_steps_per_second": 15.11}, {"test_loss": 0.6206399202346802, "test_mcc": 0.4114590620153425, "test_macro_f1": 0.6901923683380637, "test_runtime": 4.2465, "test_samples_per_second": 482.274, "test_steps_per_second": 15.071}, {"test_loss": 0.6892635822296143, "test_mcc": 0.10511837886743454, "test_macro_f1": 0.5043275212626341, "test_runtime": 4.1219, "test_samples_per_second": 496.862, "test_steps_per_second": 15.527}, {"test_loss": 0.5901646614074707, "test_mcc": 0.4084698254787905, "test_macro_f1": 0.6941362670101013, "test_runtime": 4.2354, "test_samples_per_second": 483.541, "test_steps_per_second": 15.111}, {"test_loss": 0.5900508165359497, "test_mcc": 0.40525795049883595, "test_macro_f1": 0.702620766084759, "test_runtime": 4.114, "test_samples_per_second": 497.812, "test_steps_per_second": 15.557}, {"test_loss": 0.5918276906013489, "test_mcc": 0.3766514716389378, "test_macro_f1": 0.6708752925913334, "test_runtime": 4.1984, "test_samples_per_second": 487.806, "test_steps_per_second": 15.244}, {"test_loss": 0.6091099977493286, "test_mcc": 0.33368806006937746, "test_macro_f1": 0.6649501955898134, "test_runtime": 4.1436, "test_samples_per_second": 494.252, "test_steps_per_second": 15.445}, {"test_loss": 0.6051754951477051, "test_mcc": 0.41615338609180674, "test_macro_f1": 0.6975521129360558, "test_runtime": 4.1782, "test_samples_per_second": 490.161, "test_steps_per_second": 15.318}, {"test_loss": 0.6125631332397461, "test_mcc": 0.35965433781765554, "test_macro_f1": 0.6696617861961789, "test_runtime": 4.2237, "test_samples_per_second": 484.884, "test_steps_per_second": 15.153}]}, "total": {"test_mcc": 36.62216604241655, "test_mcc_se": 5.976358122004723, "test_macro_f1": 66.91015372760303, "test_macro_f1_se": 3.6897592730730304}}, "num_model_parameters": 111441410, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.6905149221420288, "test_mcc": 0.42940262514163385, "test_macro_f1": 0.7033009833134467, "test_runtime": 4.2172, "test_samples_per_second": 485.631, "test_steps_per_second": 15.176}, {"test_loss": 0.6634613275527954, "test_mcc": 0.2564066898353087, "test_macro_f1": 0.6243036785480495, "test_runtime": 4.3981, "test_samples_per_second": 465.656, "test_steps_per_second": 14.552}, {"test_loss": 0.5538666844367981, "test_mcc": 0.4664563170611466, "test_macro_f1": 0.7303643605812498, "test_runtime": 4.3729, "test_samples_per_second": 468.343, "test_steps_per_second": 14.636}, {"test_loss": 0.593864917755127, "test_mcc": 0.46094278523611065, "test_macro_f1": 0.7283946192198371, "test_runtime": 4.535, "test_samples_per_second": 451.603, "test_steps_per_second": 14.113}, {"test_loss": 0.6105107069015503, "test_mcc": 0.44582513259237616, "test_macro_f1": 0.7057677622453911, "test_runtime": 4.3526, "test_samples_per_second": 470.525, "test_steps_per_second": 14.704}, {"test_loss": 0.6554532051086426, "test_mcc": 0.47187293253091656, "test_macro_f1": 0.7338836658258809, "test_runtime": 4.2477, "test_samples_per_second": 482.143, "test_steps_per_second": 15.067}, {"test_loss": 0.6025714874267578, "test_mcc": 0.38024200221906773, "test_macro_f1": 0.6795740871858997, "test_runtime": 4.1906, "test_samples_per_second": 488.712, "test_steps_per_second": 15.272}, {"test_loss": 0.5957890152931213, "test_mcc": 0.39434544789879145, "test_macro_f1": 0.6961079287104073, "test_runtime": 4.2297, "test_samples_per_second": 484.195, "test_steps_per_second": 15.131}, {"test_loss": 0.6221891641616821, "test_mcc": 0.3630048847383677, "test_macro_f1": 0.6611223929916712, "test_runtime": 4.2535, "test_samples_per_second": 481.49, "test_steps_per_second": 15.047}, {"test_loss": 0.617576003074646, "test_mcc": 0.4279232492125182, "test_macro_f1": 0.7051862514964862, "test_runtime": 4.3571, "test_samples_per_second": 470.038, "test_steps_per_second": 14.689}]}, "total": {"test_mcc": 40.96422066466238, "test_mcc_se": 4.054914098725502, "test_macro_f1": 69.6800573011832, "test_macro_f1_se": 2.118938041609466}}, "num_model_parameters": 111441410, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.6281307935714722, "test_mcc": 0.38445877372130266, "test_macro_f1": 0.6434782946087338, "test_runtime": 3.7752, "test_samples_per_second": 542.493, "test_steps_per_second": 16.953}, {"test_loss": 0.6798598766326904, "test_mcc": 0.18573553567825174, "test_macro_f1": 0.5869302137958854, "test_runtime": 3.7667, "test_samples_per_second": 543.716, "test_steps_per_second": 16.991}, {"test_loss": 0.5746609568595886, "test_mcc": 0.39256102173554425, "test_macro_f1": 0.6820755799434399, "test_runtime": 3.7575, "test_samples_per_second": 545.043, "test_steps_per_second": 17.033}, {"test_loss": 0.5543665885925293, "test_mcc": 0.447726954034417, "test_macro_f1": 0.72039681025785, "test_runtime": 3.8527, "test_samples_per_second": 531.572, "test_steps_per_second": 16.612}, {"test_loss": 0.5949757099151611, "test_mcc": 0.38789250487262744, "test_macro_f1": 0.6505675057996065, "test_runtime": 3.8378, "test_samples_per_second": 533.634, "test_steps_per_second": 16.676}, {"test_loss": 0.5125955939292908, "test_mcc": 0.5278475698347135, "test_macro_f1": 0.7587089079962297, "test_runtime": 3.6756, "test_samples_per_second": 557.182, "test_steps_per_second": 17.412}, {"test_loss": 0.6037245988845825, "test_mcc": 0.3551086114502062, "test_macro_f1": 0.664248719899724, "test_runtime": 3.6665, "test_samples_per_second": 558.575, "test_steps_per_second": 17.455}, {"test_loss": 0.5877817869186401, "test_mcc": 0.4413119625645853, "test_macro_f1": 0.6793219102489285, "test_runtime": 3.7622, "test_samples_per_second": 544.363, "test_steps_per_second": 17.011}, {"test_loss": 0.6120868921279907, "test_mcc": 0.35829220648327426, "test_macro_f1": 0.6786738582008764, "test_runtime": 3.6909, "test_samples_per_second": 554.871, "test_steps_per_second": 17.34}, {"test_loss": 0.5981801748275757, "test_mcc": 0.477151698304688, "test_macro_f1": 0.7264493033159998, "test_runtime": 3.8341, "test_samples_per_second": 534.152, "test_steps_per_second": 16.692}]}, "total": {"test_mcc": 39.580868386796105, "test_mcc_se": 5.703631872334794, "test_macro_f1": 67.90851104067274, "test_macro_f1_se": 3.0005632769285935}}, "num_model_parameters": 111441410, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.5915744304656982, "test_mcc": 0.39648927693130354, "test_macro_f1": 0.6683602210392081, "test_runtime": 3.8988, "test_samples_per_second": 525.293, "test_steps_per_second": 16.415}, {"test_loss": 0.5780559778213501, "test_mcc": 0.4202338488339087, "test_macro_f1": 0.6978597106294718, "test_runtime": 4.0371, "test_samples_per_second": 507.296, "test_steps_per_second": 15.853}, {"test_loss": 0.6036330461502075, "test_mcc": 0.433734821968243, "test_macro_f1": 0.7152203767894056, "test_runtime": 4.0297, "test_samples_per_second": 508.232, "test_steps_per_second": 15.882}, {"test_loss": 0.5858156681060791, "test_mcc": 0.39978131269967787, "test_macro_f1": 0.6934523809523809, "test_runtime": 3.8395, "test_samples_per_second": 533.407, "test_steps_per_second": 16.669}, {"test_loss": 0.5902583003044128, "test_mcc": 0.4058904116791825, "test_macro_f1": 0.692072170585019, "test_runtime": 3.8912, "test_samples_per_second": 526.313, "test_steps_per_second": 16.447}, {"test_loss": 0.6901572942733765, "test_mcc": -0.007679624769730885, "test_macro_f1": 0.3447907717415139, "test_runtime": 4.0363, "test_samples_per_second": 507.393, "test_steps_per_second": 15.856}, {"test_loss": 0.6241912245750427, "test_mcc": 0.29795789248364807, "test_macro_f1": 0.6354518002458078, "test_runtime": 3.9107, "test_samples_per_second": 523.698, "test_steps_per_second": 16.366}, {"test_loss": 0.6417115926742554, "test_mcc": 0.31409762835838856, "test_macro_f1": 0.633779602245339, "test_runtime": 3.8951, "test_samples_per_second": 525.791, "test_steps_per_second": 16.431}, {"test_loss": 0.690213680267334, "test_mcc": 0.07575113702287324, "test_macro_f1": 0.5101016686053137, "test_runtime": 3.9159, "test_samples_per_second": 522.992, "test_steps_per_second": 16.344}, {"test_loss": 0.575350284576416, "test_mcc": 0.39085326421526617, "test_macro_f1": 0.6895792362862965, "test_runtime": 4.0223, "test_samples_per_second": 509.167, "test_steps_per_second": 15.911}]}, "total": {"test_mcc": 31.271099694227605, "test_mcc_se": 9.571194856525365, "test_macro_f1": 62.80667939119758, "test_macro_f1_se": 7.171634742365109}}, "num_model_parameters": 111441410, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_em": 48.489542989930285, "test_f1": 51.94240660591414}, {"test_em": 50.07751937984496, "test_f1": 53.740808895808}, {"test_em": 48.068006182380216, "test_f1": 51.77179592740096}, {"test_em": 49.84423676012461, "test_f1": 53.16889417975178}, {"test_em": 50.73359073359073, "test_f1": 54.87447190473935}, {"test_em": 49.190439475713184, "test_f1": 52.708691674177636}, {"test_em": 52.391799544419136, "test_f1": 56.66742268109009}, {"test_em": 46.625290923196275, "test_f1": 51.320994272666766}, {"test_em": 43.68627450980392, "test_f1": 47.38239213992264}, {"test_em": 46.11801242236025, "test_f1": 49.27674499160158}]}, "total": {"test_em": 48.52247129213636, "test_em_se": 1.5659475745269382, "test_f1": 52.2854623273073, "test_f1_se": 1.644874485606426}}, "num_model_parameters": 110850818, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_em": 45.54608830364059, "test_f1": 50.536271573854904}, {"test_em": 45.50387596899225, "test_f1": 50.17672279867183}, {"test_em": 46.05873261205564, "test_f1": 50.82929561234046}, {"test_em": 46.02803738317757, "test_f1": 50.08649726111245}, {"test_em": 47.1042471042471, "test_f1": 53.01881642814857}, {"test_em": 44.33307632999229, "test_f1": 49.723426404156676}, {"test_em": 47.911921032649964, "test_f1": 52.76951297798001}, {"test_em": 46.004654771140416, "test_f1": 51.267947912012616}, {"test_em": 44.31372549019608, "test_f1": 48.634165217206544}, {"test_em": 45.2639751552795, "test_f1": 50.353361675064264}]}, "total": {"test_em": 45.80683341513715, "test_em_se": 0.689010902288224, "test_f1": 50.739601786054834, "test_f1_se": 0.8264584513804587}}, "num_model_parameters": 110850818, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_em": 49.65143299767622, "test_f1": 54.68296768565596}, {"test_em": 46.89922480620155, "test_f1": 51.93409376268115}, {"test_em": 46.59969088098918, "test_f1": 50.68095244099878}, {"test_em": 47.429906542056074, "test_f1": 51.64685717538629}, {"test_em": 47.41312741312741, "test_f1": 51.80750186057572}, {"test_em": 46.02929838087895, "test_f1": 51.13159059065425}, {"test_em": 43.735763097949885, "test_f1": 49.17322835043239}, {"test_em": 46.39255236617533, "test_f1": 51.652425325791505}, {"test_em": 50.509803921568626, "test_f1": 55.12847034320353}, {"test_em": 46.27329192546584, "test_f1": 50.98276074390432}]}, "total": {"test_em": 47.09340923320891, "test_em_se": 1.173857765570596, "test_f1": 51.882084827928395, "test_f1_se": 1.10590933147316}}, "num_model_parameters": 110850818, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.6805734634399414, "test_mcc": 0.5359985899435221, "test_macro_f1": 0.5197879077721258, "test_runtime": 8.9066, "test_samples_per_second": 229.941, "test_steps_per_second": 28.743}, {"test_loss": 0.6695351600646973, "test_mcc": 0.538853632890032, "test_macro_f1": 0.5203823027612596, "test_runtime": 8.756, "test_samples_per_second": 233.896, "test_steps_per_second": 29.237}, {"test_loss": 0.6726656556129456, "test_mcc": 0.5596736375118647, "test_macro_f1": 0.5321000136823127, "test_runtime": 8.9545, "test_samples_per_second": 228.713, "test_steps_per_second": 28.589}, {"test_loss": 0.6615459322929382, "test_mcc": 0.5347960340595522, "test_macro_f1": 0.5193152359990219, "test_runtime": 8.6628, "test_samples_per_second": 236.412, "test_steps_per_second": 29.552}, {"test_loss": 0.7614258527755737, "test_mcc": 0.47095663439359886, "test_macro_f1": 0.49517492702911287, "test_runtime": 8.6581, "test_samples_per_second": 236.542, "test_steps_per_second": 29.568}, {"test_loss": 0.6676854491233826, "test_mcc": 0.5530830151552738, "test_macro_f1": 0.5340272037818478, "test_runtime": 8.8563, "test_samples_per_second": 231.248, "test_steps_per_second": 28.906}, {"test_loss": 0.6669520139694214, "test_mcc": 0.5457815343821667, "test_macro_f1": 0.5222008398246789, "test_runtime": 8.6654, "test_samples_per_second": 236.343, "test_steps_per_second": 29.543}, {"test_loss": 0.7001983523368835, "test_mcc": 0.5211870137083319, "test_macro_f1": 0.5099183390088274, "test_runtime": 9.1169, "test_samples_per_second": 224.638, "test_steps_per_second": 28.08}, {"test_loss": 0.7104532718658447, "test_mcc": 0.530856287843067, "test_macro_f1": 0.5178934482019305, "test_runtime": 9.0048, "test_samples_per_second": 227.434, "test_steps_per_second": 28.429}, {"test_loss": 0.6146117448806763, "test_mcc": 0.5970245599350688, "test_macro_f1": 0.5593745477428708, "test_runtime": 8.8, "test_samples_per_second": 232.728, "test_steps_per_second": 29.091}]}, "total": {"test_mcc": 53.88210939822476, "test_mcc_se": 1.9685264703784369, "test_macro_f1": 52.30174765803988, "test_macro_f1_se": 1.0392604303445043}}, "num_model_parameters": 83453187, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.9860340356826782, "test_mcc": 0.2868853597605856, "test_macro_f1": 0.49735432699731574, "test_runtime": 2.2882, "test_samples_per_second": 895.03, "test_steps_per_second": 27.97}, {"test_loss": 0.9763898849487305, "test_mcc": 0.3274380194980674, "test_macro_f1": 0.5380077850821573, "test_runtime": 2.2801, "test_samples_per_second": 898.193, "test_steps_per_second": 28.069}, {"test_loss": 1.0103631019592285, "test_mcc": 0.3206872102155672, "test_macro_f1": 0.5333203913745542, "test_runtime": 2.2819, "test_samples_per_second": 897.495, "test_steps_per_second": 28.047}, {"test_loss": 0.9690114259719849, "test_mcc": 0.32346973838380544, "test_macro_f1": 0.544955383468792, "test_runtime": 2.2799, "test_samples_per_second": 898.29, "test_steps_per_second": 28.072}, {"test_loss": 0.9830803275108337, "test_mcc": 0.30720564561397, "test_macro_f1": 0.5237476457527954, "test_runtime": 2.2153, "test_samples_per_second": 924.464, "test_steps_per_second": 28.889}, {"test_loss": 1.017232894897461, "test_mcc": 0.26616902976124546, "test_macro_f1": 0.4789965714141416, "test_runtime": 2.2718, "test_samples_per_second": 901.503, "test_steps_per_second": 28.172}, {"test_loss": 0.979744553565979, "test_mcc": 0.31515824768804646, "test_macro_f1": 0.529184237154487, "test_runtime": 2.2545, "test_samples_per_second": 908.419, "test_steps_per_second": 28.388}, {"test_loss": 0.9811211228370667, "test_mcc": 0.29182732650216364, "test_macro_f1": 0.4994469115102081, "test_runtime": 2.2751, "test_samples_per_second": 900.192, "test_steps_per_second": 28.131}, {"test_loss": 0.9776369333267212, "test_mcc": 0.3300981072128211, "test_macro_f1": 0.5196269269166711, "test_runtime": 2.3376, "test_samples_per_second": 876.124, "test_steps_per_second": 27.379}, {"test_loss": 0.9977555274963379, "test_mcc": 0.2979246620560623, "test_macro_f1": 0.5110852749872318, "test_runtime": 2.2452, "test_samples_per_second": 912.18, "test_steps_per_second": 28.506}]}, "total": {"test_mcc": 30.66863346692335, "test_mcc_se": 1.2835599735273464, "test_macro_f1": 51.75725454658354, "test_macro_f1_se": 1.2836134012953926}}, "num_model_parameters": 83453187, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.9432348012924194, "test_mcc": 0.2632643744586109, "test_macro_f1": 0.40606388844506686, "test_runtime": 2.1557, "test_samples_per_second": 950.023, "test_steps_per_second": 29.688}, {"test_loss": 0.9295293092727661, "test_mcc": 0.23367138285380737, "test_macro_f1": 0.383004584803591, "test_runtime": 1.9882, "test_samples_per_second": 1030.057, "test_steps_per_second": 32.189}, {"test_loss": 0.977871298789978, "test_mcc": 0.2781006416463908, "test_macro_f1": 0.4702241691145547, "test_runtime": 2.0142, "test_samples_per_second": 1016.768, "test_steps_per_second": 31.774}, {"test_loss": 0.9510149955749512, "test_mcc": 0.2564041472202929, "test_macro_f1": 0.40126408278049125, "test_runtime": 2.0405, "test_samples_per_second": 1003.688, "test_steps_per_second": 31.365}, {"test_loss": 1.005367636680603, "test_mcc": 0.20949864804622229, "test_macro_f1": 0.3661299018828001, "test_runtime": 2.0467, "test_samples_per_second": 1000.613, "test_steps_per_second": 31.269}, {"test_loss": 0.9394747018814087, "test_mcc": 0.24575473189773708, "test_macro_f1": 0.399071185300848, "test_runtime": 2.1329, "test_samples_per_second": 960.208, "test_steps_per_second": 30.007}, {"test_loss": 0.9361628890037537, "test_mcc": 0.19613170692296536, "test_macro_f1": 0.3799399033321141, "test_runtime": 2.0395, "test_samples_per_second": 1004.18, "test_steps_per_second": 31.381}, {"test_loss": 0.9019118547439575, "test_mcc": 0.2534441249945484, "test_macro_f1": 0.4031153119064077, "test_runtime": 2.0635, "test_samples_per_second": 992.51, "test_steps_per_second": 31.016}, {"test_loss": 0.9665848612785339, "test_mcc": 0.2349168829884561, "test_macro_f1": 0.42617360034620394, "test_runtime": 2.0928, "test_samples_per_second": 978.576, "test_steps_per_second": 30.581}, {"test_loss": 0.9291023015975952, "test_mcc": 0.2679761706670892, "test_macro_f1": 0.40874740444584834, "test_runtime": 2.0964, "test_samples_per_second": 976.904, "test_steps_per_second": 30.528}]}, "total": {"test_mcc": 24.391628116961208, "test_mcc_se": 1.6037690096081814, "test_macro_f1": 40.43734032357926, "test_macro_f1_se": 1.775951024185999}}, "num_model_parameters": 83453187, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.17139248549938202, "test_micro_f1": 0.1939304219096965, "test_micro_f1_no_misc": 0.21546052631578946, "test_runtime": 5.1066, "test_samples_per_second": 401.049, "test_steps_per_second": 12.533}, {"test_loss": 0.17290788888931274, "test_micro_f1": 0.22892498066511985, "test_micro_f1_no_misc": 0.24978614200171084, "test_runtime": 4.8445, "test_samples_per_second": 422.744, "test_steps_per_second": 13.211}, {"test_loss": 0.1719960719347, "test_micro_f1": 0.2, "test_micro_f1_no_misc": 0.2135523613963039, "test_runtime": 4.8678, "test_samples_per_second": 420.722, "test_steps_per_second": 13.148}, {"test_loss": 0.17333707213401794, "test_micro_f1": 0.17757009345794392, "test_micro_f1_no_misc": 0.19273034657650046, "test_runtime": 5.1007, "test_samples_per_second": 401.512, "test_steps_per_second": 12.547}, {"test_loss": 0.19270172715187073, "test_micro_f1": 0.1806367771280052, "test_micro_f1_no_misc": 0.1930937279774489, "test_runtime": 5.0991, "test_samples_per_second": 401.636, "test_steps_per_second": 12.551}, {"test_loss": 0.18997392058372498, "test_micro_f1": 0.20790273556231004, "test_micro_f1_no_misc": 0.22503328894806923, "test_runtime": 4.1327, "test_samples_per_second": 495.557, "test_steps_per_second": 15.486}, {"test_loss": 0.18879510462284088, "test_micro_f1": 0.1894039735099338, "test_micro_f1_no_misc": 0.20516499282639883, "test_runtime": 4.5089, "test_samples_per_second": 454.208, "test_steps_per_second": 14.194}, {"test_loss": 0.15737205743789673, "test_micro_f1": 0.2418456642800318, "test_micro_f1_no_misc": 0.2620689655172414, "test_runtime": 5.144, "test_samples_per_second": 398.136, "test_steps_per_second": 12.442}, {"test_loss": 0.17007532715797424, "test_micro_f1": 0.21860149355057706, "test_micro_f1_no_misc": 0.2357247437774524, "test_runtime": 4.8316, "test_samples_per_second": 423.872, "test_steps_per_second": 13.246}, {"test_loss": 0.17846159636974335, "test_micro_f1": 0.23508137432188064, "test_micro_f1_no_misc": 0.25423728813559326, "test_runtime": 5.0725, "test_samples_per_second": 403.742, "test_steps_per_second": 12.617}]}, "total": {"test_micro_f1": 20.738975143854987, "test_micro_f1_se": 1.4175906377486165, "test_micro_f1_no_misc": 22.46852383472509, "test_micro_f1_no_misc_se": 1.5504976219360875}}, "num_model_parameters": 82867209, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.17745345830917358, "test_micro_f1": 0.4441585177560474, "test_micro_f1_no_misc": 0.45576923076923076, "test_runtime": 4.9204, "test_samples_per_second": 416.228, "test_steps_per_second": 13.007}, {"test_loss": 0.1583285927772522, "test_micro_f1": 0.46385193753614806, "test_micro_f1_no_misc": 0.5010893246187363, "test_runtime": 3.8834, "test_samples_per_second": 527.368, "test_steps_per_second": 16.48}, {"test_loss": 0.16568583250045776, "test_micro_f1": 0.4752915047196002, "test_micro_f1_no_misc": 0.498921639108555, "test_runtime": 4.7521, "test_samples_per_second": 430.969, "test_steps_per_second": 13.468}, {"test_loss": 0.16640403866767883, "test_micro_f1": 0.45035105315947843, "test_micro_f1_no_misc": 0.4640605296343001, "test_runtime": 4.6215, "test_samples_per_second": 443.141, "test_steps_per_second": 13.848}, {"test_loss": 0.16380882263183594, "test_micro_f1": 0.4221961244862008, "test_micro_f1_no_misc": 0.4423288172830465, "test_runtime": 4.6807, "test_samples_per_second": 437.545, "test_steps_per_second": 13.673}, {"test_loss": 0.1771971732378006, "test_micro_f1": 0.42700929469655546, "test_micro_f1_no_misc": 0.45077026121902214, "test_runtime": 4.8565, "test_samples_per_second": 421.706, "test_steps_per_second": 13.178}, {"test_loss": 0.15998485684394836, "test_micro_f1": 0.4769528015456804, "test_micro_f1_no_misc": 0.499486125385406, "test_runtime": 4.9657, "test_samples_per_second": 412.429, "test_steps_per_second": 12.888}, {"test_loss": 0.15742143988609314, "test_micro_f1": 0.43641703377386204, "test_micro_f1_no_misc": 0.4619948090470894, "test_runtime": 4.7856, "test_samples_per_second": 427.949, "test_steps_per_second": 13.373}, {"test_loss": 0.16752752661705017, "test_micro_f1": 0.42357850808555036, "test_micro_f1_no_misc": 0.42999336429993357, "test_runtime": 4.6402, "test_samples_per_second": 441.357, "test_steps_per_second": 13.792}, {"test_loss": 0.16083863377571106, "test_micro_f1": 0.4693434617471514, "test_micro_f1_no_misc": 0.4941775836972344, "test_runtime": 4.128, "test_samples_per_second": 496.127, "test_steps_per_second": 15.504}]}, "total": {"test_micro_f1": 44.89150237506275, "test_micro_f1_se": 1.3291526851994173, "test_micro_f1_no_misc": 46.985916850625536, "test_micro_f1_no_misc_se": 1.6391610466225102}}, "num_model_parameters": 82867209, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.18715770542621613, "test_micro_f1": 0.4097094520044134, "test_micro_f1_no_misc": 0.4429752066115703, "test_runtime": 3.9809, "test_samples_per_second": 514.461, "test_steps_per_second": 16.077}, {"test_loss": 0.17313973605632782, "test_micro_f1": 0.41044776119402987, "test_micro_f1_no_misc": 0.43354943273906, "test_runtime": 3.9316, "test_samples_per_second": 520.906, "test_steps_per_second": 16.278}, {"test_loss": 0.18838728964328766, "test_micro_f1": 0.3798922800718133, "test_micro_f1_no_misc": 0.4078740157480315, "test_runtime": 3.8789, "test_samples_per_second": 527.98, "test_steps_per_second": 16.499}, {"test_loss": 0.17754006385803223, "test_micro_f1": 0.37037037037037035, "test_micro_f1_no_misc": 0.3980384143849612, "test_runtime": 3.8534, "test_samples_per_second": 531.476, "test_steps_per_second": 16.609}, {"test_loss": 0.2007606029510498, "test_micro_f1": 0.37743589743589745, "test_micro_f1_no_misc": 0.40253920836445106, "test_runtime": 4.1624, "test_samples_per_second": 492.02, "test_steps_per_second": 15.376}, {"test_loss": 0.18486812710762024, "test_micro_f1": 0.3798319327731092, "test_micro_f1_no_misc": 0.4073126142595978, "test_runtime": 4.067, "test_samples_per_second": 503.56, "test_steps_per_second": 15.736}, {"test_loss": 0.18469929695129395, "test_micro_f1": 0.4072651065316102, "test_micro_f1_no_misc": 0.42976461655277143, "test_runtime": 3.7812, "test_samples_per_second": 541.623, "test_steps_per_second": 16.926}, {"test_loss": 0.17368218302726746, "test_micro_f1": 0.400909435392194, "test_micro_f1_no_misc": 0.42387332521315463, "test_runtime": 3.8102, "test_samples_per_second": 537.511, "test_steps_per_second": 16.797}, {"test_loss": 0.18559467792510986, "test_micro_f1": 0.39970555760029447, "test_micro_f1_no_misc": 0.42857142857142855, "test_runtime": 3.8076, "test_samples_per_second": 537.868, "test_steps_per_second": 16.808}, {"test_loss": 0.20053450763225555, "test_micro_f1": 0.41785714285714287, "test_micro_f1_no_misc": 0.44322631166797183, "test_runtime": 3.9408, "test_samples_per_second": 519.696, "test_steps_per_second": 16.24}]}, "total": {"test_micro_f1": 39.53424936230875, "test_micro_f1_se": 1.0447622500743667, "test_micro_f1_no_misc": 42.17724574112999, "test_micro_f1_no_misc_se": 1.032703285897533}}, "num_model_parameters": 82867209, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.20028617978096008, "test_micro_f1": 0.3338821205136648, "test_micro_f1_no_misc": 0.3567909922589726, "test_runtime": 4.0954, "test_samples_per_second": 500.069, "test_steps_per_second": 15.627}, {"test_loss": 0.20678189396858215, "test_micro_f1": 0.37447065940713853, "test_micro_f1_no_misc": 0.39802306425041184, "test_runtime": 4.0693, "test_samples_per_second": 503.281, "test_steps_per_second": 15.728}, {"test_loss": 0.20540009438991547, "test_micro_f1": 0.34840265220012057, "test_micro_f1_no_misc": 0.3729362253156362, "test_runtime": 3.94, "test_samples_per_second": 519.792, "test_steps_per_second": 16.244}, {"test_loss": 0.2192007303237915, "test_micro_f1": 0.29723266142808336, "test_micro_f1_no_misc": 0.32222222222222224, "test_runtime": 4.1199, "test_samples_per_second": 497.104, "test_steps_per_second": 15.535}, {"test_loss": 0.21224980056285858, "test_micro_f1": 0.3375499334221039, "test_micro_f1_no_misc": 0.3653136531365314, "test_runtime": 4.0193, "test_samples_per_second": 509.536, "test_steps_per_second": 15.923}, {"test_loss": 0.22591891884803772, "test_micro_f1": 0.38146811070998793, "test_micro_f1_no_misc": 0.4107965766951942, "test_runtime": 4.0831, "test_samples_per_second": 501.579, "test_steps_per_second": 15.674}, {"test_loss": 0.2014135718345642, "test_micro_f1": 0.3733509234828496, "test_micro_f1_no_misc": 0.3975731620271235, "test_runtime": 4.1807, "test_samples_per_second": 489.873, "test_steps_per_second": 15.309}, {"test_loss": 0.20557811856269836, "test_micro_f1": 0.32543978349120434, "test_micro_f1_no_misc": 0.3477001086562839, "test_runtime": 4.182, "test_samples_per_second": 489.721, "test_steps_per_second": 15.304}, {"test_loss": 0.2152772843837738, "test_micro_f1": 0.33407999999999993, "test_micro_f1_no_misc": 0.358797096439682, "test_runtime": 3.9731, "test_samples_per_second": 515.465, "test_steps_per_second": 16.108}, {"test_loss": 0.2041516900062561, "test_micro_f1": 0.3823529411764706, "test_micro_f1_no_misc": 0.40888262248854423, "test_runtime": 3.89, "test_samples_per_second": 526.481, "test_steps_per_second": 16.453}]}, "total": {"test_micro_f1": 34.882297858316235, "test_micro_f1_se": 1.7561867567414433, "test_micro_f1_no_misc": 37.39035723490602, "test_micro_f1_no_misc_se": 1.8105679720863608}}, "num_model_parameters": 82867209, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.6922817230224609, "test_mcc": -0.012644596273971293, "test_macro_f1": 0.4357297264920964, "test_runtime": 2.0751, "test_samples_per_second": 986.945, "test_steps_per_second": 30.842}, {"test_loss": 0.6937610507011414, "test_mcc": 0.0356102075228376, "test_macro_f1": 0.4514012507737295, "test_runtime": 2.213, "test_samples_per_second": 925.454, "test_steps_per_second": 28.92}, {"test_loss": 0.6927611827850342, "test_mcc": 0.04027166522354276, "test_macro_f1": 0.3649318432013149, "test_runtime": 2.2682, "test_samples_per_second": 902.921, "test_steps_per_second": 28.216}, {"test_loss": 0.692327618598938, "test_mcc": 0.030499076530735903, "test_macro_f1": 0.3833576642335766, "test_runtime": 2.2584, "test_samples_per_second": 906.832, "test_steps_per_second": 28.338}, {"test_loss": 0.6946120858192444, "test_mcc": -0.029825087255999395, "test_macro_f1": 0.44480079056335176, "test_runtime": 2.2157, "test_samples_per_second": 924.308, "test_steps_per_second": 28.885}, {"test_loss": 0.6929503679275513, "test_mcc": 0.022667619506912536, "test_macro_f1": 0.34801516170868757, "test_runtime": 2.1609, "test_samples_per_second": 947.738, "test_steps_per_second": 29.617}, {"test_loss": 0.6939844489097595, "test_mcc": -0.001641867742674276, "test_macro_f1": 0.49538091482574087, "test_runtime": 2.2066, "test_samples_per_second": 928.134, "test_steps_per_second": 29.004}, {"test_loss": 0.6934919357299805, "test_mcc": -0.0018078445302340035, "test_macro_f1": 0.49439725189167794, "test_runtime": 2.1751, "test_samples_per_second": 941.557, "test_steps_per_second": 29.424}, {"test_loss": 0.6927359104156494, "test_mcc": 0.0529146914118806, "test_macro_f1": 0.4791926629684996, "test_runtime": 2.1795, "test_samples_per_second": 939.675, "test_steps_per_second": 29.365}, {"test_loss": 0.692530632019043, "test_mcc": 0.018797651047956776, "test_macro_f1": 0.5084981718604189, "test_runtime": 2.2878, "test_samples_per_second": 895.193, "test_steps_per_second": 27.975}]}, "total": {"test_mcc": 1.5484151544098723, "test_mcc_se": 1.6195579849937918, "test_macro_f1": 44.05705438519094, "test_macro_f1_se": 3.5621336733863767}}, "num_model_parameters": 83452418, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.6715264320373535, "test_mcc": 0.16217867330897812, "test_macro_f1": 0.5760412754188973, "test_runtime": 1.9435, "test_samples_per_second": 1053.753, "test_steps_per_second": 32.93}, {"test_loss": 0.689010500907898, "test_mcc": 0.05096237421571012, "test_macro_f1": 0.5078164938794428, "test_runtime": 1.9815, "test_samples_per_second": 1033.536, "test_steps_per_second": 32.298}, {"test_loss": 0.694108247756958, "test_mcc": 0.026476007993947892, "test_macro_f1": 0.513225755644965, "test_runtime": 1.877, "test_samples_per_second": 1091.128, "test_steps_per_second": 34.098}, {"test_loss": 0.6600531339645386, "test_mcc": 0.2316843343035438, "test_macro_f1": 0.6156822480848803, "test_runtime": 2.0063, "test_samples_per_second": 1020.773, "test_steps_per_second": 31.899}, {"test_loss": 0.6832898855209351, "test_mcc": 0.12139777307096972, "test_macro_f1": 0.5034547681644832, "test_runtime": 1.9031, "test_samples_per_second": 1076.159, "test_steps_per_second": 33.63}, {"test_loss": 0.6636394262313843, "test_mcc": 0.2249553352491749, "test_macro_f1": 0.6041666666666666, "test_runtime": 1.9213, "test_samples_per_second": 1065.948, "test_steps_per_second": 33.311}, {"test_loss": 0.658982515335083, "test_mcc": 0.22300477712501646, "test_macro_f1": 0.6105885585993471, "test_runtime": 1.8587, "test_samples_per_second": 1101.871, "test_steps_per_second": 34.433}, {"test_loss": 0.6746490001678467, "test_mcc": 0.15167954861505814, "test_macro_f1": 0.5744038612552911, "test_runtime": 1.9097, "test_samples_per_second": 1072.418, "test_steps_per_second": 33.513}, {"test_loss": 0.6839108467102051, "test_mcc": 0.10856317544974184, "test_macro_f1": 0.5532542680336621, "test_runtime": 1.9361, "test_samples_per_second": 1057.775, "test_steps_per_second": 33.055}, {"test_loss": 0.6964176893234253, "test_mcc": 0.00042441366779120894, "test_macro_f1": 0.452329345531316, "test_runtime": 1.9487, "test_samples_per_second": 1050.972, "test_steps_per_second": 32.843}]}, "total": {"test_mcc": 13.01326412999932, "test_mcc_se": 5.218449994662003, "test_macro_f1": 55.10963241278952, "test_macro_f1_se": 3.396657001683343}}, "num_model_parameters": 83452418, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.6768620610237122, "test_mcc": 0.14549593453062024, "test_macro_f1": 0.57274304411797, "test_runtime": 1.9485, "test_samples_per_second": 1051.083, "test_steps_per_second": 32.846}, {"test_loss": 0.6865109801292419, "test_mcc": 0.12075605488324063, "test_macro_f1": 0.5103249691484986, "test_runtime": 2.0966, "test_samples_per_second": 976.84, "test_steps_per_second": 30.526}, {"test_loss": 0.6925203800201416, "test_mcc": 0.04510736744324024, "test_macro_f1": 0.5225256247161791, "test_runtime": 1.9729, "test_samples_per_second": 1038.083, "test_steps_per_second": 32.44}, {"test_loss": 0.6897225379943848, "test_mcc": 0.08674372208832873, "test_macro_f1": 0.4808976237846425, "test_runtime": 1.9868, "test_samples_per_second": 1030.786, "test_steps_per_second": 32.212}, {"test_loss": 0.6893553137779236, "test_mcc": 0.08292312188264028, "test_macro_f1": 0.5155196126973648, "test_runtime": 2.0027, "test_samples_per_second": 1022.621, "test_steps_per_second": 31.957}, {"test_loss": 0.6913691759109497, "test_mcc": 0.05183402320993649, "test_macro_f1": 0.4850854993407242, "test_runtime": 1.8952, "test_samples_per_second": 1080.606, "test_steps_per_second": 33.769}, {"test_loss": 0.692353367805481, "test_mcc": 0.024619483667797374, "test_macro_f1": 0.3490513321337209, "test_runtime": 1.946, "test_samples_per_second": 1052.419, "test_steps_per_second": 32.888}, {"test_loss": 0.6887702941894531, "test_mcc": 0.0918093889411406, "test_macro_f1": 0.4845529478386711, "test_runtime": 1.9671, "test_samples_per_second": 1041.137, "test_steps_per_second": 32.536}, {"test_loss": 0.6927934885025024, "test_mcc": 0.023015601464460723, "test_macro_f1": 0.49167818805092073, "test_runtime": 1.9472, "test_samples_per_second": 1051.787, "test_steps_per_second": 32.868}, {"test_loss": 0.6917635202407837, "test_mcc": 0.05667808949828495, "test_macro_f1": 0.5251194591021876, "test_runtime": 1.9898, "test_samples_per_second": 1029.238, "test_steps_per_second": 32.164}]}, "total": {"test_mcc": 7.289827876096902, "test_mcc_se": 2.4885796788057872, "test_macro_f1": 49.37498300930879, "test_macro_f1_se": 3.5824755158066086}}, "num_model_parameters": 83452418, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_loss": 0.6936804056167603, "test_mcc": -0.0043457080723602985, "test_macro_f1": 0.3719987684541204, "test_runtime": 2.1703, "test_samples_per_second": 943.627, "test_steps_per_second": 29.488}, {"test_loss": 0.6938621997833252, "test_mcc": 0.013524569635151439, "test_macro_f1": 0.4825566590272473, "test_runtime": 2.2085, "test_samples_per_second": 927.319, "test_steps_per_second": 28.979}, {"test_loss": 0.692660927772522, "test_mcc": 0.03813869591532641, "test_macro_f1": 0.4858267210827159, "test_runtime": 2.1951, "test_samples_per_second": 933.0, "test_steps_per_second": 29.156}, {"test_loss": 0.6924107074737549, "test_mcc": 0.05434702931258327, "test_macro_f1": 0.46988416788135634, "test_runtime": 2.0873, "test_samples_per_second": 981.151, "test_steps_per_second": 30.661}, {"test_loss": 0.6945061683654785, "test_mcc": -0.010871299166238699, "test_macro_f1": 0.47722112503862535, "test_runtime": 2.1756, "test_samples_per_second": 941.329, "test_steps_per_second": 29.417}, {"test_loss": 0.6908712387084961, "test_mcc": 0.0684971180460426, "test_macro_f1": 0.5134661191639012, "test_runtime": 2.207, "test_samples_per_second": 927.957, "test_steps_per_second": 28.999}, {"test_loss": 0.692657470703125, "test_mcc": 0.010777203338360684, "test_macro_f1": 0.40799648644885905, "test_runtime": 2.1441, "test_samples_per_second": 955.198, "test_steps_per_second": 29.85}, {"test_loss": 0.695401132106781, "test_mcc": 0.0034512807926659465, "test_macro_f1": 0.3786646725777161, "test_runtime": 2.1392, "test_samples_per_second": 957.346, "test_steps_per_second": 29.917}, {"test_loss": 0.6930347681045532, "test_mcc": 0.019776257231166584, "test_macro_f1": 0.5092042094781217, "test_runtime": 2.1546, "test_samples_per_second": 950.515, "test_steps_per_second": 29.704}, {"test_loss": 0.6905560493469238, "test_mcc": 0.06373506030688215, "test_macro_f1": 0.5029709865054752, "test_runtime": 2.1963, "test_samples_per_second": 932.49, "test_steps_per_second": 29.14}]}, "total": {"test_mcc": 2.570302073395801, "test_mcc_se": 1.7766419702283556, "test_macro_f1": 45.997899156581376, "test_macro_f1_se": 3.3159666308939304}}, "num_model_parameters": 83452418, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.4993517129332359, "epoch": 3.43}, {"test_em": 0.07751937984496124, "test_f1": 0.346191706656823, "epoch": 5.57}, {"test_em": 0.0, "test_f1": 0.23563805248503858, "epoch": 6.0}, {"test_em": 0.0778816199376947, "test_f1": 0.3162050825602227, "epoch": 5.57}, {"test_em": 0.0, "test_f1": 0.5051742488140389, "epoch": 3.43}, {"test_em": 0.15420200462606015, "test_f1": 0.6559380369984025, "epoch": 8.57}, {"test_em": 0.07593014426727411, "test_f1": 0.7599291988947624, "epoch": 5.14}, {"test_em": 0.07757951900698215, "test_f1": 0.4509329994201988, "epoch": 3.86}, {"test_em": 0.0, "test_f1": 0.8379519365678534, "epoch": 5.57}, {"test_em": 0.07763975155279502, "test_f1": 0.5601129805322353, "epoch": 4.71}]}, "total": {"test_em": 0.05407524192357673, "test_em_se": 0.03228791637350257, "test_f1": 0.5167425955862811, "test_f1_se": 0.11987578245001568}}, "num_model_parameters": 82862594, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_em": 0.07745933384972889, "test_f1": 1.1360235284437845}, {"test_em": 0.07751937984496124, "test_f1": 0.47823752474915265}, {"test_em": 0.0, "test_f1": 0.520997797441485}, {"test_em": 0.0, "test_f1": 0.7861077136778072}, {"test_em": 0.23166023166023167, "test_f1": 1.1685023993544654}, {"test_em": 0.0, "test_f1": 0.8540164739992395}, {"test_em": 0.0, "test_f1": 0.39459570211278644}, {"test_em": 0.0, "test_f1": 0.32946667159235044}, {"test_em": 0.0, "test_f1": 0.5236086353733412}, {"test_em": 0.07763975155279502, "test_f1": 1.0621930691806472}]}, "total": {"test_em": 0.046427869690771686, "test_em_se": 0.04626602304330623, "test_f1": 0.725374951592506, "test_f1_se": 0.19691173986208127}}, "num_model_parameters": 82862594, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.6252120575262691}, {"test_em": 0.0, "test_f1": 0.17430115104533708}, {"test_em": 0.0, "test_f1": 0.30935490750019345}, {"test_em": 0.0, "test_f1": 0.34447164120061313}, {"test_em": 0.15444015444015444, "test_f1": 0.5043875043875046}, {"test_em": 0.0, "test_f1": 1.7397594108317356}, {"test_em": 0.0, "test_f1": 0.3692982964053579}, {"test_em": 0.1551590380139643, "test_f1": 0.4402787515551629}, {"test_em": 0.0, "test_f1": 0.5607513593672763}, {"test_em": 0.3105590062111801, "test_f1": 1.2896502221036386}]}, "total": {"test_em": 0.06201581986652989, "test_em_se": 0.06723729001926866, "test_f1": 0.6357465301923089, "test_f1_se": 0.3052494451662276}}, "num_model_parameters": 82862594, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6812589168548584, "test_mcc": 0.556034637362922, "test_macro_f1": 0.5311933818393707, "test_runtime": 15.8528, "test_samples_per_second": 129.189, "test_steps_per_second": 16.149}, {"test_loss": 0.7240790724754333, "test_mcc": 0.5090404043044992, "test_macro_f1": 0.5161466685470318, "test_runtime": 15.3428, "test_samples_per_second": 133.483, "test_steps_per_second": 16.685}, {"test_loss": 0.6648303866386414, "test_mcc": 0.5649717616014509, "test_macro_f1": 0.537624082414221, "test_runtime": 15.655, "test_samples_per_second": 130.821, "test_steps_per_second": 16.353}, {"test_loss": 0.6596368551254272, "test_mcc": 0.5557509386960331, "test_macro_f1": 0.5553303286615211, "test_runtime": 15.2102, "test_samples_per_second": 134.647, "test_steps_per_second": 16.831}, {"test_loss": 0.7069655060768127, "test_mcc": 0.5161905614077452, "test_macro_f1": 0.5230494585986093, "test_runtime": 14.9828, "test_samples_per_second": 136.69, "test_steps_per_second": 17.086}, {"test_loss": 0.6725810766220093, "test_mcc": 0.5553979857672151, "test_macro_f1": 0.544792984430647, "test_runtime": 15.5421, "test_samples_per_second": 131.771, "test_steps_per_second": 16.471}, {"test_loss": 0.6445701122283936, "test_mcc": 0.5702291413923535, "test_macro_f1": 0.5618210558991962, "test_runtime": 14.8322, "test_samples_per_second": 138.078, "test_steps_per_second": 17.26}, {"test_loss": 0.6036467552185059, "test_mcc": 0.6032366560132724, "test_macro_f1": 0.6006816964618178, "test_runtime": 16.0222, "test_samples_per_second": 127.822, "test_steps_per_second": 15.978}, {"test_loss": 0.682559609413147, "test_mcc": 0.563821556514386, "test_macro_f1": 0.5769331471211024, "test_runtime": 15.8372, "test_samples_per_second": 129.316, "test_steps_per_second": 16.164}, {"test_loss": 0.6455087065696716, "test_mcc": 0.5795397982179465, "test_macro_f1": 0.5880743790658779, "test_runtime": 15.5057, "test_samples_per_second": 132.08, "test_steps_per_second": 16.51}]}, "total": {"test_mcc": 55.74213441277824, "test_mcc_se": 1.7161389080838334, "test_macro_f1": 55.35647183039395, "test_macro_f1_se": 1.7519946390852743}}, "num_model_parameters": 110426115, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.8610591292381287, "test_mcc": 0.4096860333448973, "test_macro_f1": 0.6028470331678103, "test_runtime": 4.17, "test_samples_per_second": 491.126, "test_steps_per_second": 15.348}, {"test_loss": 0.8724945783615112, "test_mcc": 0.4120679232639994, "test_macro_f1": 0.6046198122680103, "test_runtime": 4.1684, "test_samples_per_second": 491.312, "test_steps_per_second": 15.354}, {"test_loss": 0.9182673096656799, "test_mcc": 0.3791999034090152, "test_macro_f1": 0.5868066616055378, "test_runtime": 4.1351, "test_samples_per_second": 495.269, "test_steps_per_second": 15.477}, {"test_loss": 0.8890355825424194, "test_mcc": 0.40692007727042845, "test_macro_f1": 0.6035311880690287, "test_runtime": 4.1275, "test_samples_per_second": 496.188, "test_steps_per_second": 15.506}, {"test_loss": 0.9124554395675659, "test_mcc": 0.3846505956573024, "test_macro_f1": 0.587139879154875, "test_runtime": 4.0793, "test_samples_per_second": 502.043, "test_steps_per_second": 15.689}, {"test_loss": 0.8762156367301941, "test_mcc": 0.39183126946506425, "test_macro_f1": 0.592507222367745, "test_runtime": 4.1384, "test_samples_per_second": 494.882, "test_steps_per_second": 15.465}, {"test_loss": 0.87405925989151, "test_mcc": 0.39687905807079327, "test_macro_f1": 0.5875526346776364, "test_runtime": 4.0906, "test_samples_per_second": 500.661, "test_steps_per_second": 15.646}, {"test_loss": 0.8770965337753296, "test_mcc": 0.4076180031228022, "test_macro_f1": 0.6039284404129518, "test_runtime": 4.1066, "test_samples_per_second": 498.706, "test_steps_per_second": 15.585}, {"test_loss": 0.9141746163368225, "test_mcc": 0.363611576658401, "test_macro_f1": 0.563280092575141, "test_runtime": 4.1215, "test_samples_per_second": 496.905, "test_steps_per_second": 15.528}, {"test_loss": 0.9070521593093872, "test_mcc": 0.3659932824208049, "test_macro_f1": 0.5787637390207184, "test_runtime": 4.0883, "test_samples_per_second": 500.938, "test_steps_per_second": 15.654}]}, "total": {"test_mcc": 39.18457722683509, "test_mcc_se": 1.1136894118569067, "test_macro_f1": 59.10976703319456, "test_macro_f1_se": 0.8301939724658702}}, "num_model_parameters": 110426115, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.8588663339614868, "test_mcc": 0.34017023368216615, "test_macro_f1": 0.5056156310930509, "test_runtime": 3.8255, "test_samples_per_second": 535.359, "test_steps_per_second": 16.73}, {"test_loss": 0.8907963633537292, "test_mcc": 0.28091333480528696, "test_macro_f1": 0.42282262401603427, "test_runtime": 3.6044, "test_samples_per_second": 568.197, "test_steps_per_second": 17.756}, {"test_loss": 0.8411807417869568, "test_mcc": 0.3671578149788031, "test_macro_f1": 0.5405175182860876, "test_runtime": 3.6511, "test_samples_per_second": 560.926, "test_steps_per_second": 17.529}, {"test_loss": 0.8775327801704407, "test_mcc": 0.33597344733187207, "test_macro_f1": 0.46002846621603055, "test_runtime": 3.6972, "test_samples_per_second": 553.936, "test_steps_per_second": 17.31}, {"test_loss": 0.8712411522865295, "test_mcc": 0.32768911071423085, "test_macro_f1": 0.49932454284389466, "test_runtime": 3.7161, "test_samples_per_second": 551.12, "test_steps_per_second": 17.223}, {"test_loss": 0.8692887425422668, "test_mcc": 0.32035857175134763, "test_macro_f1": 0.44592026241209276, "test_runtime": 3.8183, "test_samples_per_second": 536.361, "test_steps_per_second": 16.761}, {"test_loss": 0.8527840971946716, "test_mcc": 0.32342985242244726, "test_macro_f1": 0.5013671945380936, "test_runtime": 3.629, "test_samples_per_second": 564.349, "test_steps_per_second": 17.636}, {"test_loss": 0.8582010865211487, "test_mcc": 0.31007779846826544, "test_macro_f1": 0.4917790641512074, "test_runtime": 3.7069, "test_samples_per_second": 552.489, "test_steps_per_second": 17.265}, {"test_loss": 0.8627243638038635, "test_mcc": 0.34784053573561285, "test_macro_f1": 0.5020680056540896, "test_runtime": 3.7939, "test_samples_per_second": 539.81, "test_steps_per_second": 16.869}, {"test_loss": 0.8931106328964233, "test_mcc": 0.2850722833813031, "test_macro_f1": 0.43100377711245647, "test_runtime": 3.831, "test_samples_per_second": 534.587, "test_steps_per_second": 16.706}]}, "total": {"test_mcc": 32.38682983271335, "test_mcc_se": 1.656491168164126, "test_macro_f1": 48.004470863230374, "test_macro_f1_se": 2.3560274033928845}}, "num_model_parameters": 110426115, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.14411216974258423, "test_micro_f1": 0.4083277367360645, "test_micro_f1_no_misc": 0.44903988183161003, "test_runtime": 7.623, "test_samples_per_second": 268.661, "test_steps_per_second": 8.396}, {"test_loss": 0.14203549921512604, "test_micro_f1": 0.3943661971830986, "test_micro_f1_no_misc": 0.42570836212854185, "test_runtime": 7.3575, "test_samples_per_second": 278.357, "test_steps_per_second": 8.699}, {"test_loss": 0.1429797261953354, "test_micro_f1": 0.38941176470588235, "test_micro_f1_no_misc": 0.41426783479349183, "test_runtime": 7.3217, "test_samples_per_second": 279.718, "test_steps_per_second": 8.741}, {"test_loss": 0.14827674627304077, "test_micro_f1": 0.4105392156862745, "test_micro_f1_no_misc": 0.4440026507620941, "test_runtime": 6.9995, "test_samples_per_second": 292.592, "test_steps_per_second": 9.144}, {"test_loss": 0.1635461449623108, "test_micro_f1": 0.3612078977932637, "test_micro_f1_no_misc": 0.3853779429987608, "test_runtime": 7.5352, "test_samples_per_second": 271.792, "test_steps_per_second": 8.494}, {"test_loss": 0.14934486150741577, "test_micro_f1": 0.4242761692650335, "test_micro_f1_no_misc": 0.459589867310012, "test_runtime": 6.0827, "test_samples_per_second": 336.69, "test_steps_per_second": 10.522}, {"test_loss": 0.15460732579231262, "test_micro_f1": 0.3928776565192418, "test_micro_f1_no_misc": 0.4214417744916821, "test_runtime": 6.4535, "test_samples_per_second": 317.347, "test_steps_per_second": 9.917}, {"test_loss": 0.12801170349121094, "test_micro_f1": 0.42131979695431465, "test_micro_f1_no_misc": 0.45200816882232814, "test_runtime": 7.4857, "test_samples_per_second": 273.588, "test_steps_per_second": 8.55}, {"test_loss": 0.1428026705980301, "test_micro_f1": 0.4239520958083832, "test_micro_f1_no_misc": 0.4555483452303698, "test_runtime": 7.0021, "test_samples_per_second": 292.485, "test_steps_per_second": 9.14}, {"test_loss": 0.14891737699508667, "test_micro_f1": 0.43907351460221555, "test_micro_f1_no_misc": 0.4669176976869284, "test_runtime": 6.9994, "test_samples_per_second": 292.595, "test_steps_per_second": 9.144}]}, "total": {"test_micro_f1": 40.65352045253772, "test_micro_f1_se": 1.4007947042762048, "test_micro_f1_no_misc": 43.73902526055819, "test_micro_f1_no_misc_se": 1.5623107767412925}}, "num_model_parameters": 109840137, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.09196322411298752, "test_micro_f1": 0.69558599695586, "test_micro_f1_no_misc": 0.7369141293191925, "test_runtime": 7.7976, "test_samples_per_second": 262.645, "test_steps_per_second": 8.208}, {"test_loss": 0.08102616667747498, "test_micro_f1": 0.6946308724832214, "test_micro_f1_no_misc": 0.721997796547925, "test_runtime": 6.0122, "test_samples_per_second": 340.643, "test_steps_per_second": 10.645}, {"test_loss": 0.09467894583940506, "test_micro_f1": 0.7210994341147937, "test_micro_f1_no_misc": 0.7583988563259472, "test_runtime": 7.5213, "test_samples_per_second": 272.293, "test_steps_per_second": 8.509}, {"test_loss": 0.0946759581565857, "test_micro_f1": 0.6876790830945558, "test_micro_f1_no_misc": 0.7291739281979784, "test_runtime": 7.4039, "test_samples_per_second": 276.609, "test_steps_per_second": 8.644}, {"test_loss": 0.10106910765171051, "test_micro_f1": 0.652014652014652, "test_micro_f1_no_misc": 0.696528555431131, "test_runtime": 7.465, "test_samples_per_second": 274.348, "test_steps_per_second": 8.573}, {"test_loss": 0.09111553430557251, "test_micro_f1": 0.7087565193521823, "test_micro_f1_no_misc": 0.7399545109931767, "test_runtime": 7.5498, "test_samples_per_second": 271.265, "test_steps_per_second": 8.477}, {"test_loss": 0.08357597887516022, "test_micro_f1": 0.7245751281359589, "test_micro_f1_no_misc": 0.7690662865288668, "test_runtime": 7.764, "test_samples_per_second": 263.782, "test_steps_per_second": 8.243}, {"test_loss": 0.08683119714260101, "test_micro_f1": 0.7074601844090528, "test_micro_f1_no_misc": 0.7456734386756961, "test_runtime": 7.7105, "test_samples_per_second": 265.612, "test_steps_per_second": 8.3}, {"test_loss": 0.09148310869932175, "test_micro_f1": 0.6958134605193429, "test_micro_f1_no_misc": 0.7287390029325513, "test_runtime": 7.3549, "test_samples_per_second": 278.454, "test_steps_per_second": 8.702}, {"test_loss": 0.09041189402341843, "test_micro_f1": 0.7001096491228069, "test_micro_f1_no_misc": 0.7357089829250185, "test_runtime": 6.4453, "test_samples_per_second": 317.752, "test_steps_per_second": 9.93}]}, "total": {"test_micro_f1": 69.87724980202425, "test_micro_f1_se": 1.2544400020649678, "test_micro_f1_no_misc": 73.62155487877483, "test_micro_f1_no_misc_se": 1.232383296275201}}, "num_model_parameters": 109840137, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.12434341758489609, "test_micro_f1": 0.5881916078722614, "test_micro_f1_no_misc": 0.6280857952246054, "test_runtime": 6.6859, "test_samples_per_second": 306.315, "test_steps_per_second": 9.572}, {"test_loss": 0.11085139214992523, "test_micro_f1": 0.6333333333333333, "test_micro_f1_no_misc": 0.6677699627637567, "test_runtime": 6.6316, "test_samples_per_second": 308.824, "test_steps_per_second": 9.651}, {"test_loss": 0.12774652242660522, "test_micro_f1": 0.5898752751283932, "test_micro_f1_no_misc": 0.6345768150822302, "test_runtime": 6.3959, "test_samples_per_second": 320.207, "test_steps_per_second": 10.006}, {"test_loss": 0.11435742676258087, "test_micro_f1": 0.6279646017699115, "test_micro_f1_no_misc": 0.6593749999999999, "test_runtime": 6.4303, "test_samples_per_second": 318.494, "test_steps_per_second": 9.953}, {"test_loss": 0.14746221899986267, "test_micro_f1": 0.5218978102189781, "test_micro_f1_no_misc": 0.5563792430745221, "test_runtime": 6.5995, "test_samples_per_second": 310.327, "test_steps_per_second": 9.698}, {"test_loss": 0.1182851642370224, "test_micro_f1": 0.647839401156856, "test_micro_f1_no_misc": 0.682503770739065, "test_runtime": 6.5868, "test_samples_per_second": 310.926, "test_steps_per_second": 9.716}, {"test_loss": 0.11943165957927704, "test_micro_f1": 0.6614060258249641, "test_micro_f1_no_misc": 0.6881382560879811, "test_runtime": 6.1513, "test_samples_per_second": 332.938, "test_steps_per_second": 10.404}, {"test_loss": 0.11722418665885925, "test_micro_f1": 0.6344976593446165, "test_micro_f1_no_misc": 0.6615561517822921, "test_runtime": 6.3583, "test_samples_per_second": 322.097, "test_steps_per_second": 10.066}, {"test_loss": 0.1132931113243103, "test_micro_f1": 0.6564663023679417, "test_micro_f1_no_misc": 0.6845906902086677, "test_runtime": 6.2042, "test_samples_per_second": 330.098, "test_steps_per_second": 10.316}, {"test_loss": 0.1291433423757553, "test_micro_f1": 0.6294520547945205, "test_micro_f1_no_misc": 0.6666666666666667, "test_runtime": 6.3413, "test_samples_per_second": 322.965, "test_steps_per_second": 10.093}]}, "total": {"test_micro_f1": 61.909240718117765, "test_micro_f1_se": 2.6047519055269133, "test_micro_f1_no_misc": 65.29642351629788, "test_micro_f1_no_misc_se": 2.4373456509636044}}, "num_model_parameters": 109840137, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.16218575835227966, "test_micro_f1": 0.5120160213618159, "test_micro_f1_no_misc": 0.5472103004291845, "test_runtime": 6.6114, "test_samples_per_second": 309.767, "test_steps_per_second": 9.68}, {"test_loss": 0.1553056836128235, "test_micro_f1": 0.5078611687926431, "test_micro_f1_no_misc": 0.5462667517549457, "test_runtime": 6.853, "test_samples_per_second": 298.846, "test_steps_per_second": 9.339}, {"test_loss": 0.15077468752861023, "test_micro_f1": 0.5382731169626455, "test_micro_f1_no_misc": 0.5818908122503329, "test_runtime": 6.3864, "test_samples_per_second": 320.681, "test_steps_per_second": 10.021}, {"test_loss": 0.17064765095710754, "test_micro_f1": 0.5270516717325228, "test_micro_f1_no_misc": 0.5704697986577182, "test_runtime": 6.7124, "test_samples_per_second": 305.109, "test_steps_per_second": 9.535}, {"test_loss": 0.16297337412834167, "test_micro_f1": 0.5004522158577027, "test_micro_f1_no_misc": 0.5446194225721784, "test_runtime": 6.354, "test_samples_per_second": 322.318, "test_steps_per_second": 10.072}, {"test_loss": 0.1600949466228485, "test_micro_f1": 0.5144124168514412, "test_micro_f1_no_misc": 0.5554789800137836, "test_runtime": 6.5092, "test_samples_per_second": 314.633, "test_steps_per_second": 9.832}, {"test_loss": 0.15445742011070251, "test_micro_f1": 0.5105966742745354, "test_micro_f1_no_misc": 0.5469786936779603, "test_runtime": 6.9255, "test_samples_per_second": 295.719, "test_steps_per_second": 9.241}, {"test_loss": 0.154676616191864, "test_micro_f1": 0.5135313531353135, "test_micro_f1_no_misc": 0.5475017593244195, "test_runtime": 6.8963, "test_samples_per_second": 296.971, "test_steps_per_second": 9.28}, {"test_loss": 0.15886864066123962, "test_micro_f1": 0.5194570135746607, "test_micro_f1_no_misc": 0.5585644371941272, "test_runtime": 6.0906, "test_samples_per_second": 336.258, "test_steps_per_second": 10.508}, {"test_loss": 0.15459033846855164, "test_micro_f1": 0.5418227215980025, "test_micro_f1_no_misc": 0.5743623716462405, "test_runtime": 6.3435, "test_samples_per_second": 322.849, "test_steps_per_second": 10.089}]}, "total": {"test_micro_f1": 51.854743741412825, "test_micro_f1_se": 0.8247948503384241, "test_micro_f1_no_misc": 55.73343327520891, "test_micro_f1_no_misc_se": 0.8420262375562991}}, "num_model_parameters": 109840137, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6837522387504578, "test_mcc": 0.08555348667743982, "test_macro_f1": 0.5260762361900349, "test_runtime": 3.3624, "test_samples_per_second": 609.082, "test_steps_per_second": 19.034}, {"test_loss": 0.6933411359786987, "test_mcc": 0.026319243283113965, "test_macro_f1": 0.5023881102171655, "test_runtime": 3.607, "test_samples_per_second": 567.779, "test_steps_per_second": 17.743}, {"test_loss": 0.6906317472457886, "test_mcc": 0.097189744794031, "test_macro_f1": 0.536890767841814, "test_runtime": 3.5776, "test_samples_per_second": 572.458, "test_steps_per_second": 17.889}, {"test_loss": 0.6911121606826782, "test_mcc": 0.03672824393174928, "test_macro_f1": 0.47523427041499333, "test_runtime": 3.4626, "test_samples_per_second": 591.467, "test_steps_per_second": 18.483}, {"test_loss": 0.6923633217811584, "test_mcc": 0.06540699655222582, "test_macro_f1": 0.4906622451047877, "test_runtime": 3.5572, "test_samples_per_second": 575.73, "test_steps_per_second": 17.992}, {"test_loss": 0.6973475813865662, "test_mcc": -0.02260783396017904, "test_macro_f1": 0.48858407411020316, "test_runtime": 3.5215, "test_samples_per_second": 581.572, "test_steps_per_second": 18.174}, {"test_loss": 0.6965349316596985, "test_mcc": 0.048274390245184894, "test_macro_f1": 0.513686425296652, "test_runtime": 3.5262, "test_samples_per_second": 580.796, "test_steps_per_second": 18.15}, {"test_loss": 0.6883378028869629, "test_mcc": 0.08157967923751551, "test_macro_f1": 0.5392265605071809, "test_runtime": 3.4732, "test_samples_per_second": 589.653, "test_steps_per_second": 18.427}, {"test_loss": 0.6918030381202698, "test_mcc": 0.02030786661498229, "test_macro_f1": 0.5077177247486118, "test_runtime": 3.548, "test_samples_per_second": 577.226, "test_steps_per_second": 18.038}, {"test_loss": 0.6962863206863403, "test_mcc": 0.015225835800809176, "test_macro_f1": 0.47658476109180337, "test_runtime": 3.5138, "test_samples_per_second": 582.84, "test_steps_per_second": 18.214}]}, "total": {"test_mcc": 4.539776531768727, "test_mcc_se": 2.320614504904543, "test_macro_f1": 50.57051175523246, "test_macro_f1_se": 1.4441259990733117}}, "num_model_parameters": 110425346, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.5961612462997437, "test_mcc": 0.40640930322191937, "test_macro_f1": 0.6881677925257015, "test_runtime": 3.434, "test_samples_per_second": 596.384, "test_steps_per_second": 18.637}, {"test_loss": 0.6195029616355896, "test_mcc": 0.4431657706457986, "test_macro_f1": 0.6750180178712215, "test_runtime": 3.5889, "test_samples_per_second": 570.655, "test_steps_per_second": 17.833}, {"test_loss": 0.5902281999588013, "test_mcc": 0.43198460336205463, "test_macro_f1": 0.6867682276468576, "test_runtime": 3.4249, "test_samples_per_second": 597.97, "test_steps_per_second": 18.687}, {"test_loss": 0.5792471170425415, "test_mcc": 0.44519867313853756, "test_macro_f1": 0.6940300803977101, "test_runtime": 3.5205, "test_samples_per_second": 581.733, "test_steps_per_second": 18.179}, {"test_loss": 0.595858097076416, "test_mcc": 0.45065808061837775, "test_macro_f1": 0.6891226889499561, "test_runtime": 3.4329, "test_samples_per_second": 596.581, "test_steps_per_second": 18.643}, {"test_loss": 0.6031173467636108, "test_mcc": 0.37968691618420325, "test_macro_f1": 0.6517695685869285, "test_runtime": 3.413, "test_samples_per_second": 600.055, "test_steps_per_second": 18.752}, {"test_loss": 0.6351962089538574, "test_mcc": 0.48166346402690596, "test_macro_f1": 0.7200265223872195, "test_runtime": 3.3867, "test_samples_per_second": 604.714, "test_steps_per_second": 18.897}, {"test_loss": 0.6298083662986755, "test_mcc": 0.306989905482716, "test_macro_f1": 0.6193119409170003, "test_runtime": 3.3736, "test_samples_per_second": 607.073, "test_steps_per_second": 18.971}, {"test_loss": 0.645311713218689, "test_mcc": 0.2927106344128216, "test_macro_f1": 0.5682661521569736, "test_runtime": 3.4345, "test_samples_per_second": 596.297, "test_steps_per_second": 18.634}, {"test_loss": 0.5990265607833862, "test_mcc": 0.39939416110009174, "test_macro_f1": 0.6610791667794998, "test_runtime": 3.4977, "test_samples_per_second": 585.522, "test_steps_per_second": 18.298}]}, "total": {"test_mcc": 40.37861512193426, "test_mcc_se": 3.84507537087773, "test_macro_f1": 66.53560158219068, "test_macro_f1_se": 2.709366064318832}}, "num_model_parameters": 110425346, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6584044694900513, "test_mcc": 0.2108723178849147, "test_macro_f1": 0.6016802569804793, "test_runtime": 3.6349, "test_samples_per_second": 563.42, "test_steps_per_second": 17.607}, {"test_loss": 0.6662963628768921, "test_mcc": 0.20376936003662335, "test_macro_f1": 0.5601939108281028, "test_runtime": 3.5919, "test_samples_per_second": 570.165, "test_steps_per_second": 17.818}, {"test_loss": 0.6593093276023865, "test_mcc": 0.21014402175920452, "test_macro_f1": 0.5835985770454971, "test_runtime": 3.6682, "test_samples_per_second": 558.318, "test_steps_per_second": 17.447}, {"test_loss": 0.6884306073188782, "test_mcc": 0.08740364672787723, "test_macro_f1": 0.5396423672113788, "test_runtime": 3.6298, "test_samples_per_second": 564.226, "test_steps_per_second": 17.632}, {"test_loss": 0.6573535799980164, "test_mcc": 0.22525215652403735, "test_macro_f1": 0.600158525054846, "test_runtime": 3.6501, "test_samples_per_second": 561.087, "test_steps_per_second": 17.534}, {"test_loss": 0.6528476476669312, "test_mcc": 0.2427270213637432, "test_macro_f1": 0.6195608564553488, "test_runtime": 3.4787, "test_samples_per_second": 588.731, "test_steps_per_second": 18.398}, {"test_loss": 0.6509618759155273, "test_mcc": 0.2424700132714725, "test_macro_f1": 0.6054231230445233, "test_runtime": 3.5695, "test_samples_per_second": 573.755, "test_steps_per_second": 17.93}, {"test_loss": 0.6672409176826477, "test_mcc": 0.19612655019580208, "test_macro_f1": 0.5778754166539856, "test_runtime": 3.5456, "test_samples_per_second": 577.619, "test_steps_per_second": 18.051}, {"test_loss": 0.6744173169136047, "test_mcc": 0.20920234971404075, "test_macro_f1": 0.5746719352703852, "test_runtime": 3.5185, "test_samples_per_second": 582.067, "test_steps_per_second": 18.19}, {"test_loss": 0.6770168542861938, "test_mcc": 0.14156459986708692, "test_macro_f1": 0.5603243029425906, "test_runtime": 3.7391, "test_samples_per_second": 547.729, "test_steps_per_second": 17.117}]}, "total": {"test_mcc": 19.695320373448023, "test_mcc_se": 2.96542669055954, "test_macro_f1": 58.231292714871365, "test_macro_f1_se": 1.5305725401589727}}, "num_model_parameters": 110425346, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6800382733345032, "test_mcc": 0.14105687436375064, "test_macro_f1": 0.554012046251988, "test_runtime": 3.9123, "test_samples_per_second": 523.476, "test_steps_per_second": 16.359}, {"test_loss": 0.6736105680465698, "test_mcc": 0.16086382779486502, "test_macro_f1": 0.5799335060078324, "test_runtime": 4.0544, "test_samples_per_second": 505.134, "test_steps_per_second": 15.785}, {"test_loss": 0.6798622012138367, "test_mcc": 0.1434547342287915, "test_macro_f1": 0.5612515848842123, "test_runtime": 4.0191, "test_samples_per_second": 509.57, "test_steps_per_second": 15.924}, {"test_loss": 0.6966012120246887, "test_mcc": 0.04576200844437926, "test_macro_f1": 0.5163537607745896, "test_runtime": 3.8633, "test_samples_per_second": 530.123, "test_steps_per_second": 16.566}, {"test_loss": 0.685123860836029, "test_mcc": 0.09191594178605701, "test_macro_f1": 0.5371093229808459, "test_runtime": 3.9204, "test_samples_per_second": 522.398, "test_steps_per_second": 16.325}, {"test_loss": 0.6812804341316223, "test_mcc": 0.12339261958076961, "test_macro_f1": 0.5564289177225903, "test_runtime": 4.0233, "test_samples_per_second": 509.029, "test_steps_per_second": 15.907}, {"test_loss": 0.6951451897621155, "test_mcc": -0.01618790778470263, "test_macro_f1": 0.48555115902481794, "test_runtime": 3.9478, "test_samples_per_second": 518.769, "test_steps_per_second": 16.212}, {"test_loss": 0.6816785335540771, "test_mcc": 0.13440968799536532, "test_macro_f1": 0.5671999594555958, "test_runtime": 3.9704, "test_samples_per_second": 515.817, "test_steps_per_second": 16.119}, {"test_loss": 0.6945035457611084, "test_mcc": 0.03125682577795687, "test_macro_f1": 0.513713862120089, "test_runtime": 3.9042, "test_samples_per_second": 524.564, "test_steps_per_second": 16.393}, {"test_loss": 0.691177248954773, "test_mcc": 0.03354117013477837, "test_macro_f1": 0.5144395534443518, "test_runtime": 4.0038, "test_samples_per_second": 511.512, "test_steps_per_second": 15.985}]}, "total": {"test_mcc": 8.894657823220111, "test_mcc_se": 3.777882024338596, "test_macro_f1": 53.85993672666913, "test_macro_f1_se": 1.8604813564763913}}, "num_model_parameters": 110425346, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_em": 32.687838884585595, "test_f1": 39.126087118324314}, {"test_em": 28.527131782945737, "test_f1": 33.71165043843298}, {"test_em": 16.228748068006183, "test_f1": 22.39013361587539}, {"test_em": 12.694704049844237, "test_f1": 18.991521848644837}, {"test_em": 14.826254826254827, "test_f1": 21.091787283276243}, {"test_em": 3.623747108712413, "test_f1": 11.028522546111901}, {"test_em": 6.83371298405467, "test_f1": 14.225788117961375}, {"test_em": 18.774243599689683, "test_f1": 24.736797651647446}, {"test_em": 21.725490196078432, "test_f1": 27.31937149029469}, {"test_em": 23.214285714285715, "test_f1": 29.016608993675042}]}, "total": {"test_em": 17.913615721445748, "test_em_se": 5.623468771972642, "test_f1": 24.163826910424426, "test_f1_se": 5.305703895819341}}, "num_model_parameters": 109834754, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_em": 31.835786212238574, "test_f1": 38.08707019084523}, {"test_em": 31.472868217054263, "test_f1": 37.59597056730621}, {"test_em": 28.74806800618238, "test_f1": 35.20519108716593}, {"test_em": 31.152647975077883, "test_f1": 36.66773925262543}, {"test_em": 32.972972972972975, "test_f1": 39.55808356825608}, {"test_em": 15.574402467232074, "test_f1": 22.947633866030955}, {"test_em": 16.856492027334852, "test_f1": 23.86613541629624}, {"test_em": 31.031807602792863, "test_f1": 37.259904785298275}, {"test_em": 0.1568627450980392, "test_f1": 2.1883023705824645}, {"test_em": 35.9472049689441, "test_f1": 42.12985959714385}]}, "total": {"test_em": 25.574911319492802, "test_em_se": 6.943050008925125, "test_f1": 31.55058907015506, "test_f1_se": 7.51377738850809}}, "num_model_parameters": 109834754, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_em": 21.53369481022463, "test_f1": 28.381032664498928}, {"test_em": 20.852713178294575, "test_f1": 27.80823815480742}, {"test_em": 21.25193199381762, "test_f1": 28.241444201728882}, {"test_em": 25.0, "test_f1": 31.23502005952603}, {"test_em": 23.706563706563706, "test_f1": 29.43383407092232}, {"test_em": 27.216653816499615, "test_f1": 32.51056068560027}, {"test_em": 27.107061503416855, "test_f1": 33.31237968100881}, {"test_em": 27.307990690457718, "test_f1": 33.41298069540249}, {"test_em": 27.45098039215686, "test_f1": 33.38969762304312}, {"test_em": 19.099378881987576, "test_f1": 25.80834723764084}]}, "total": {"test_em": 24.052696897341914, "test_em_se": 1.975910910898818, "test_f1": 30.353353507417904, "test_f1_se": 1.7173825674068008}}, "num_model_parameters": 109834754, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.39043349027633667, "test_mcc": 0.7501117513188302, "test_macro_f1": 0.6642938050321879, "test_runtime": 17.3861, "test_samples_per_second": 117.795, "test_steps_per_second": 58.898}, {"test_loss": 0.41031894087791443, "test_mcc": 0.7172624010126286, "test_macro_f1": 0.6465204452141117, "test_runtime": 17.6333, "test_samples_per_second": 116.144, "test_steps_per_second": 58.072}, {"test_loss": 0.4727446734905243, "test_mcc": 0.7207727380305914, "test_macro_f1": 0.7019460990408359, "test_runtime": 17.3797, "test_samples_per_second": 117.839, "test_steps_per_second": 58.919}, {"test_loss": 0.3935243487358093, "test_mcc": 0.785109625035111, "test_macro_f1": 0.772182267609035, "test_runtime": 17.1497, "test_samples_per_second": 119.419, "test_steps_per_second": 59.709}, {"test_loss": 0.39179638028144836, "test_mcc": 0.7381750780571414, "test_macro_f1": 0.735206753265226, "test_runtime": 17.1942, "test_samples_per_second": 119.11, "test_steps_per_second": 59.555}, {"test_loss": 0.38724029064178467, "test_mcc": 0.7279028506356044, "test_macro_f1": 0.6773305598835492, "test_runtime": 17.3322, "test_samples_per_second": 118.162, "test_steps_per_second": 59.081}, {"test_loss": 0.35366344451904297, "test_mcc": 0.7673960406278363, "test_macro_f1": 0.747157718424698, "test_runtime": 17.2023, "test_samples_per_second": 119.054, "test_steps_per_second": 59.527}, {"test_loss": 0.4064069986343384, "test_mcc": 0.7520458310481858, "test_macro_f1": 0.7322673715267815, "test_runtime": 17.4149, "test_samples_per_second": 117.6, "test_steps_per_second": 58.8}, {"test_loss": 0.41812843084335327, "test_mcc": 0.7497355433438481, "test_macro_f1": 0.7131429696559809, "test_runtime": 17.2636, "test_samples_per_second": 118.631, "test_steps_per_second": 59.316}, {"test_loss": 0.3932094871997833, "test_mcc": 0.7495272682653098, "test_macro_f1": 0.7070071259109101, "test_runtime": 17.3469, "test_samples_per_second": 118.061, "test_steps_per_second": 59.031}]}, "total": {"test_mcc": 74.58039127375088, "test_mcc_se": 1.2931749105589871, "test_macro_f1": 70.97055115563316, "test_macro_f1_se": 2.413567799098227}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.7593169808387756, "test_mcc": 0.5070944898072569, "test_macro_f1": 0.660300179491709, "test_runtime": 4.3694, "test_samples_per_second": 468.713, "test_steps_per_second": 14.647}, {"test_loss": 0.7948716282844543, "test_mcc": 0.5069042105460477, "test_macro_f1": 0.668388055092632, "test_runtime": 4.3538, "test_samples_per_second": 470.388, "test_steps_per_second": 14.7}, {"test_loss": 0.8052659630775452, "test_mcc": 0.491346546778657, "test_macro_f1": 0.6659702779718487, "test_runtime": 4.3419, "test_samples_per_second": 471.688, "test_steps_per_second": 14.74}, {"test_loss": 0.7875428199768066, "test_mcc": 0.5037668663421376, "test_macro_f1": 0.6678099428417582, "test_runtime": 4.3189, "test_samples_per_second": 474.192, "test_steps_per_second": 14.818}, {"test_loss": 0.7836235761642456, "test_mcc": 0.5015447952073129, "test_macro_f1": 0.6703753520663976, "test_runtime": 4.2607, "test_samples_per_second": 480.673, "test_steps_per_second": 15.021}, {"test_loss": 0.8187824487686157, "test_mcc": 0.47611562828724036, "test_macro_f1": 0.6507120508794616, "test_runtime": 4.3053, "test_samples_per_second": 475.689, "test_steps_per_second": 14.865}, {"test_loss": 0.8058636784553528, "test_mcc": 0.49299348665924886, "test_macro_f1": 0.6623968067367826, "test_runtime": 4.3438, "test_samples_per_second": 471.472, "test_steps_per_second": 14.734}, {"test_loss": 0.7712796926498413, "test_mcc": 0.5177680627763436, "test_macro_f1": 0.679489161306547, "test_runtime": 4.3721, "test_samples_per_second": 468.421, "test_steps_per_second": 14.638}, {"test_loss": 0.8004249930381775, "test_mcc": 0.5082166295370866, "test_macro_f1": 0.6637895037895037, "test_runtime": 4.3357, "test_samples_per_second": 472.362, "test_steps_per_second": 14.761}, {"test_loss": 0.839512288570404, "test_mcc": 0.47120345698158705, "test_macro_f1": 0.6492559028249879, "test_runtime": 4.2687, "test_samples_per_second": 479.774, "test_steps_per_second": 14.993}]}, "total": {"test_mcc": 49.76954172922919, "test_mcc_se": 0.9166150733356846, "test_macro_f1": 66.3848723300163, "test_macro_f1_se": 0.5575365665801812}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.693827211856842, "test_mcc": 0.5547076195895952, "test_macro_f1": 0.6543178773105948, "test_runtime": 3.7081, "test_samples_per_second": 552.304, "test_steps_per_second": 17.26}, {"test_loss": 0.7159743905067444, "test_mcc": 0.49494073500062996, "test_macro_f1": 0.609334172945664, "test_runtime": 3.4427, "test_samples_per_second": 594.885, "test_steps_per_second": 18.59}, {"test_loss": 0.6591811180114746, "test_mcc": 0.5745064295209124, "test_macro_f1": 0.6896103812639159, "test_runtime": 3.5409, "test_samples_per_second": 578.389, "test_steps_per_second": 18.075}, {"test_loss": 0.6709139347076416, "test_mcc": 0.5827320032933481, "test_macro_f1": 0.7024026460457478, "test_runtime": 3.5679, "test_samples_per_second": 573.999, "test_steps_per_second": 17.937}, {"test_loss": 0.7433512806892395, "test_mcc": 0.5586162346459694, "test_macro_f1": 0.6842277917167886, "test_runtime": 3.582, "test_samples_per_second": 571.747, "test_steps_per_second": 17.867}, {"test_loss": 0.7183029055595398, "test_mcc": 0.5741233131811627, "test_macro_f1": 0.7051018236435169, "test_runtime": 3.6799, "test_samples_per_second": 556.54, "test_steps_per_second": 17.392}, {"test_loss": 0.7268800735473633, "test_mcc": 0.5746125120157235, "test_macro_f1": 0.6870565624545365, "test_runtime": 3.5041, "test_samples_per_second": 584.451, "test_steps_per_second": 18.264}, {"test_loss": 0.7066196799278259, "test_mcc": 0.481639600808264, "test_macro_f1": 0.5785422763843566, "test_runtime": 3.6377, "test_samples_per_second": 562.992, "test_steps_per_second": 17.593}, {"test_loss": 0.699109673500061, "test_mcc": 0.5325704119589916, "test_macro_f1": 0.661892048253676, "test_runtime": 3.7503, "test_samples_per_second": 546.083, "test_steps_per_second": 17.065}, {"test_loss": 0.7308942079544067, "test_mcc": 0.5962865749269035, "test_macro_f1": 0.7220578186636196, "test_runtime": 3.7063, "test_samples_per_second": 552.58, "test_steps_per_second": 17.268}]}, "total": {"test_mcc": 55.24735434941499, "test_mcc_se": 2.3597709503374977, "test_macro_f1": 66.94543398682417, "test_macro_f1_se": 2.789018522324942}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.05862506106495857, "test_micro_f1": 0.670509125840538, "test_micro_f1_no_misc": 0.7649496743635287, "test_runtime": 7.4155, "test_samples_per_second": 276.179, "test_steps_per_second": 8.631}, {"test_loss": 0.06189028173685074, "test_micro_f1": 0.6676721970839617, "test_micro_f1_no_misc": 0.7367816091954023, "test_runtime": 7.131, "test_samples_per_second": 287.198, "test_steps_per_second": 8.975}, {"test_loss": 0.05636012554168701, "test_micro_f1": 0.654124457308249, "test_micro_f1_no_misc": 0.7149972329828445, "test_runtime": 6.6495, "test_samples_per_second": 307.992, "test_steps_per_second": 9.625}, {"test_loss": 0.0686604380607605, "test_micro_f1": 0.6108986615678776, "test_micro_f1_no_misc": 0.6606574761399787, "test_runtime": 7.2601, "test_samples_per_second": 282.09, "test_steps_per_second": 8.815}, {"test_loss": 0.0642341673374176, "test_micro_f1": 0.7000955109837632, "test_micro_f1_no_misc": 0.7619559376679205, "test_runtime": 7.2658, "test_samples_per_second": 281.867, "test_steps_per_second": 8.808}, {"test_loss": 0.058801352977752686, "test_micro_f1": 0.7132216014897579, "test_micro_f1_no_misc": 0.7779632721202003, "test_runtime": 5.853, "test_samples_per_second": 349.905, "test_steps_per_second": 10.935}, {"test_loss": 0.06668893992900848, "test_micro_f1": 0.6565320665083135, "test_micro_f1_no_misc": 0.7183939229517091, "test_runtime": 6.033, "test_samples_per_second": 339.464, "test_steps_per_second": 10.608}, {"test_loss": 0.05872843414545059, "test_micro_f1": 0.689880304678999, "test_micro_f1_no_misc": 0.7638190954773869, "test_runtime": 7.0983, "test_samples_per_second": 288.52, "test_steps_per_second": 9.016}, {"test_loss": 0.057474516332149506, "test_micro_f1": 0.6916588566073102, "test_micro_f1_no_misc": 0.7619571192963166, "test_runtime": 6.6262, "test_samples_per_second": 309.076, "test_steps_per_second": 9.659}, {"test_loss": 0.05950654670596123, "test_micro_f1": 0.7343599615014438, "test_micro_f1_no_misc": 0.7862219792236195, "test_runtime": 7.2916, "test_samples_per_second": 280.87, "test_steps_per_second": 8.777}]}, "total": {"test_micro_f1": 67.88952743570213, "test_micro_f1_se": 2.1590851840217393, "test_micro_f1_no_misc": 74.47697319418907, "test_micro_f1_no_misc_se": 2.3467081144186785}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.05249755084514618, "test_micro_f1": 0.843035343035343, "test_micro_f1_no_misc": 0.8698099929627023, "test_runtime": 8.1742, "test_samples_per_second": 250.545, "test_steps_per_second": 7.83}, {"test_loss": 0.059971362352371216, "test_micro_f1": 0.77663421418637, "test_micro_f1_no_misc": 0.804564907275321, "test_runtime": 6.7523, "test_samples_per_second": 303.305, "test_steps_per_second": 9.478}, {"test_loss": 0.06253042817115784, "test_micro_f1": 0.7978580990629183, "test_micro_f1_no_misc": 0.8206970894717931, "test_runtime": 8.1679, "test_samples_per_second": 250.738, "test_steps_per_second": 7.836}, {"test_loss": 0.0576460063457489, "test_micro_f1": 0.8192337361789663, "test_micro_f1_no_misc": 0.8515193370165746, "test_runtime": 7.8861, "test_samples_per_second": 259.699, "test_steps_per_second": 8.116}, {"test_loss": 0.06283552944660187, "test_micro_f1": 0.7955580865603646, "test_micro_f1_no_misc": 0.8211567732115678, "test_runtime": 8.217, "test_samples_per_second": 249.238, "test_steps_per_second": 7.789}, {"test_loss": 0.05847269669175148, "test_micro_f1": 0.8172101945738558, "test_micro_f1_no_misc": 0.8373676248108927, "test_runtime": 8.1352, "test_samples_per_second": 251.745, "test_steps_per_second": 7.867}, {"test_loss": 0.061438556760549545, "test_micro_f1": 0.7770534550195567, "test_micro_f1_no_misc": 0.8033012379642366, "test_runtime": 8.2668, "test_samples_per_second": 247.739, "test_steps_per_second": 7.742}, {"test_loss": 0.052489541471004486, "test_micro_f1": 0.8319467554076538, "test_micro_f1_no_misc": 0.8535871156661786, "test_runtime": 8.1686, "test_samples_per_second": 250.715, "test_steps_per_second": 7.835}, {"test_loss": 0.05621230974793434, "test_micro_f1": 0.8145011907912147, "test_micro_f1_no_misc": 0.8294998174516246, "test_runtime": 7.9208, "test_samples_per_second": 258.56, "test_steps_per_second": 8.08}, {"test_loss": 0.05538773536682129, "test_micro_f1": 0.8364998662028366, "test_micro_f1_no_misc": 0.8643578643578644, "test_runtime": 7.0297, "test_samples_per_second": 291.333, "test_steps_per_second": 9.104}]}, "total": {"test_micro_f1": 81.09530941019078, "test_micro_f1_se": 1.457739904506297, "test_micro_f1_no_misc": 83.55861760188755, "test_micro_f1_no_misc_se": 1.4684348497244522}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.036421213299036026, "test_micro_f1": 0.8835311572700297, "test_micro_f1_no_misc": 0.9099249374478732, "test_runtime": 6.4179, "test_samples_per_second": 319.106, "test_steps_per_second": 9.972}, {"test_loss": 0.03241877630352974, "test_micro_f1": 0.8800896525961898, "test_micro_f1_no_misc": 0.9059757626410364, "test_runtime": 6.425, "test_samples_per_second": 318.753, "test_steps_per_second": 9.961}, {"test_loss": 0.034259192645549774, "test_micro_f1": 0.8678181177299965, "test_micro_f1_no_misc": 0.8966876971608833, "test_runtime": 5.933, "test_samples_per_second": 345.19, "test_steps_per_second": 10.787}, {"test_loss": 0.03219674527645111, "test_micro_f1": 0.8989323843416369, "test_micro_f1_no_misc": 0.9191557148546396, "test_runtime": 5.8285, "test_samples_per_second": 351.376, "test_steps_per_second": 10.98}, {"test_loss": 0.029586102813482285, "test_micro_f1": 0.9002022926500337, "test_micro_f1_no_misc": 0.9212717638152914, "test_runtime": 6.3862, "test_samples_per_second": 320.691, "test_steps_per_second": 10.022}, {"test_loss": 0.029749803245067596, "test_micro_f1": 0.8765347885402456, "test_micro_f1_no_misc": 0.9042879019908115, "test_runtime": 6.475, "test_samples_per_second": 316.294, "test_steps_per_second": 9.884}, {"test_loss": 0.029161853715777397, "test_micro_f1": 0.9120840630472855, "test_micro_f1_no_misc": 0.930485436893204, "test_runtime": 5.8017, "test_samples_per_second": 353.001, "test_steps_per_second": 11.031}, {"test_loss": 0.03201460465788841, "test_micro_f1": 0.8749999999999999, "test_micro_f1_no_misc": 0.9013554216867469, "test_runtime": 5.8055, "test_samples_per_second": 352.771, "test_steps_per_second": 11.024}, {"test_loss": 0.03273230791091919, "test_micro_f1": 0.8734634851771511, "test_micro_f1_no_misc": 0.9018653690186537, "test_runtime": 5.9138, "test_samples_per_second": 346.307, "test_steps_per_second": 10.822}, {"test_loss": 0.03707104176282883, "test_micro_f1": 0.9032702237521514, "test_micro_f1_no_misc": 0.9247478665632273, "test_runtime": 6.3331, "test_samples_per_second": 323.382, "test_steps_per_second": 10.106}]}, "total": {"test_micro_f1": 88.7092616510472, "test_micro_f1_se": 0.9411209887071691, "test_micro_f1_no_misc": 91.15757872072366, "test_micro_f1_no_misc_se": 0.7127468308818109}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.0358794741332531, "test_micro_f1": 0.8307123034227567, "test_micro_f1_no_misc": 0.8696835658387206, "test_runtime": 5.8613, "test_samples_per_second": 349.412, "test_steps_per_second": 10.919}, {"test_loss": 0.049291327595710754, "test_micro_f1": 0.7903081064911756, "test_micro_f1_no_misc": 0.8301639344262295, "test_runtime": 6.032, "test_samples_per_second": 339.522, "test_steps_per_second": 10.61}, {"test_loss": 0.05048803612589836, "test_micro_f1": 0.7724550898203593, "test_micro_f1_no_misc": 0.8207979071288423, "test_runtime": 5.8747, "test_samples_per_second": 348.614, "test_steps_per_second": 10.894}, {"test_loss": 0.05690167099237442, "test_micro_f1": 0.8299607369374811, "test_micro_f1_no_misc": 0.8639175257731959, "test_runtime": 6.1449, "test_samples_per_second": 333.284, "test_steps_per_second": 10.415}, {"test_loss": 0.05303521081805229, "test_micro_f1": 0.830564784053156, "test_micro_f1_no_misc": 0.8680970805487161, "test_runtime": 5.9697, "test_samples_per_second": 343.065, "test_steps_per_second": 10.721}, {"test_loss": 0.04793946444988251, "test_micro_f1": 0.8268190018039686, "test_micro_f1_no_misc": 0.86493768945773, "test_runtime": 6.1012, "test_samples_per_second": 335.669, "test_steps_per_second": 10.49}, {"test_loss": 0.04538208246231079, "test_micro_f1": 0.7945628668520235, "test_micro_f1_no_misc": 0.835149863760218, "test_runtime": 6.0759, "test_samples_per_second": 337.069, "test_steps_per_second": 10.533}, {"test_loss": 0.04819624871015549, "test_micro_f1": 0.7657384987893462, "test_micro_f1_no_misc": 0.8223249669749009, "test_runtime": 6.0619, "test_samples_per_second": 337.85, "test_steps_per_second": 10.558}, {"test_loss": 0.05575089901685715, "test_micro_f1": 0.8237465395262997, "test_micro_f1_no_misc": 0.860456942003515, "test_runtime": 5.6353, "test_samples_per_second": 363.422, "test_steps_per_second": 11.357}, {"test_loss": 0.049964725971221924, "test_micro_f1": 0.7908116385911179, "test_micro_f1_no_misc": 0.8394495412844036, "test_runtime": 5.8503, "test_samples_per_second": 350.069, "test_steps_per_second": 10.94}]}, "total": {"test_micro_f1": 80.55679566287685, "test_micro_f1_se": 1.5854243200074676, "test_micro_f1_no_misc": 84.74979017196472, "test_micro_f1_no_misc_se": 1.2261971510680965}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.367215096950531, "test_mcc": 0.7269429556239148, "test_macro_f1": 0.8531185843781625, "test_runtime": 3.2315, "test_samples_per_second": 633.764, "test_steps_per_second": 19.805}, {"test_loss": 0.4217842221260071, "test_mcc": 0.7021324021349524, "test_macro_f1": 0.8353984700300184, "test_runtime": 3.3573, "test_samples_per_second": 610.009, "test_steps_per_second": 19.063}, {"test_loss": 0.35914236307144165, "test_mcc": 0.7239191414293598, "test_macro_f1": 0.8552651577858001, "test_runtime": 3.3468, "test_samples_per_second": 611.931, "test_steps_per_second": 19.123}, {"test_loss": 0.41785064339637756, "test_mcc": 0.7053345248867886, "test_macro_f1": 0.8419384902143523, "test_runtime": 3.2962, "test_samples_per_second": 621.317, "test_steps_per_second": 19.416}, {"test_loss": 0.41049402952194214, "test_mcc": 0.680869633102692, "test_macro_f1": 0.8230951899905421, "test_runtime": 3.2789, "test_samples_per_second": 624.597, "test_steps_per_second": 19.519}, {"test_loss": 0.41476041078567505, "test_mcc": 0.7080706125763362, "test_macro_f1": 0.846416539757257, "test_runtime": 3.2396, "test_samples_per_second": 632.179, "test_steps_per_second": 19.756}, {"test_loss": 0.4008137583732605, "test_mcc": 0.7162083192315495, "test_macro_f1": 0.8490885903299261, "test_runtime": 3.3244, "test_samples_per_second": 616.049, "test_steps_per_second": 19.252}, {"test_loss": 0.45905423164367676, "test_mcc": 0.6835502886297269, "test_macro_f1": 0.8301770178579865, "test_runtime": 3.3753, "test_samples_per_second": 606.763, "test_steps_per_second": 18.961}, {"test_loss": 0.46264684200286865, "test_mcc": 0.6421879885164233, "test_macro_f1": 0.8016955015010849, "test_runtime": 3.2867, "test_samples_per_second": 623.116, "test_steps_per_second": 19.472}, {"test_loss": 0.5080848336219788, "test_mcc": 0.6179641093044133, "test_macro_f1": 0.780476196095554, "test_runtime": 3.2974, "test_samples_per_second": 621.093, "test_steps_per_second": 19.409}]}, "total": {"test_mcc": 69.07179975436156, "test_mcc_se": 2.216141062565622, "test_macro_f1": 83.16669737940684, "test_macro_f1_se": 1.4972622234857746}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.45117491483688354, "test_mcc": 0.6341944978060721, "test_macro_f1": 0.8055555555555556, "test_runtime": 3.6801, "test_samples_per_second": 556.502, "test_steps_per_second": 17.391}, {"test_loss": 0.5421251058578491, "test_mcc": 0.6351903765456091, "test_macro_f1": 0.7965715257159858, "test_runtime": 3.7806, "test_samples_per_second": 541.72, "test_steps_per_second": 16.929}, {"test_loss": 0.4313410520553589, "test_mcc": 0.6775580523936509, "test_macro_f1": 0.8311791084146664, "test_runtime": 3.737, "test_samples_per_second": 548.035, "test_steps_per_second": 17.126}, {"test_loss": 0.43695366382598877, "test_mcc": 0.6958094820924469, "test_macro_f1": 0.8395732880847736, "test_runtime": 3.8563, "test_samples_per_second": 531.074, "test_steps_per_second": 16.596}, {"test_loss": 0.4640713334083557, "test_mcc": 0.6306665253577519, "test_macro_f1": 0.8030934778386432, "test_runtime": 3.6841, "test_samples_per_second": 555.897, "test_steps_per_second": 17.372}, {"test_loss": 0.48129189014434814, "test_mcc": 0.6293004404264905, "test_macro_f1": 0.7989370272574041, "test_runtime": 3.699, "test_samples_per_second": 553.669, "test_steps_per_second": 17.302}, {"test_loss": 0.532660722732544, "test_mcc": 0.5615887974703644, "test_macro_f1": 0.7494529893280919, "test_runtime": 3.5915, "test_samples_per_second": 570.234, "test_steps_per_second": 17.82}, {"test_loss": 0.436980664730072, "test_mcc": 0.6674598058794948, "test_macro_f1": 0.8247416300513646, "test_runtime": 3.6645, "test_samples_per_second": 558.88, "test_steps_per_second": 17.465}, {"test_loss": 0.4976559579372406, "test_mcc": 0.6498372941194088, "test_macro_f1": 0.8066236336933112, "test_runtime": 3.6541, "test_samples_per_second": 560.463, "test_steps_per_second": 17.514}, {"test_loss": 0.4982053339481354, "test_mcc": 0.6493996782969788, "test_macro_f1": 0.8142629448245787, "test_runtime": 3.7384, "test_samples_per_second": 547.835, "test_steps_per_second": 17.12}]}, "total": {"test_mcc": 64.31004950388267, "test_mcc_se": 2.2419035501994875, "test_macro_f1": 80.69991180764376, "test_macro_f1_se": 1.5344401206369978}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.43547844886779785, "test_mcc": 0.6646114209560781, "test_macro_f1": 0.8067062672432892, "test_runtime": 3.3281, "test_samples_per_second": 615.374, "test_steps_per_second": 19.23}, {"test_loss": 0.40820401906967163, "test_mcc": 0.7208793363959922, "test_macro_f1": 0.8514419233843693, "test_runtime": 3.3419, "test_samples_per_second": 612.824, "test_steps_per_second": 19.151}, {"test_loss": 0.36876147985458374, "test_mcc": 0.7253946427858776, "test_macro_f1": 0.8539035247728014, "test_runtime": 3.3425, "test_samples_per_second": 612.71, "test_steps_per_second": 19.147}, {"test_loss": 0.44825607538223267, "test_mcc": 0.6614037956173517, "test_macro_f1": 0.81812799715825, "test_runtime": 3.4576, "test_samples_per_second": 592.318, "test_steps_per_second": 18.51}, {"test_loss": 0.4554063677787781, "test_mcc": 0.7032709459647639, "test_macro_f1": 0.832715599206979, "test_runtime": 3.3926, "test_samples_per_second": 603.666, "test_steps_per_second": 18.865}, {"test_loss": 0.47309762239456177, "test_mcc": 0.6727208583156322, "test_macro_f1": 0.8120972897531205, "test_runtime": 3.2641, "test_samples_per_second": 627.425, "test_steps_per_second": 19.607}, {"test_loss": 0.4528062343597412, "test_mcc": 0.6376554630627634, "test_macro_f1": 0.7903737508949973, "test_runtime": 3.3264, "test_samples_per_second": 615.686, "test_steps_per_second": 19.24}, {"test_loss": 0.39295339584350586, "test_mcc": 0.7185838088063051, "test_macro_f1": 0.8458328638643577, "test_runtime": 3.2993, "test_samples_per_second": 620.739, "test_steps_per_second": 19.398}, {"test_loss": 0.49736618995666504, "test_mcc": 0.6101385210609804, "test_macro_f1": 0.770101827005845, "test_runtime": 3.2787, "test_samples_per_second": 624.63, "test_steps_per_second": 19.52}, {"test_loss": 0.43546921014785767, "test_mcc": 0.6884999511513136, "test_macro_f1": 0.8306881163479303, "test_runtime": 3.3699, "test_samples_per_second": 607.741, "test_steps_per_second": 18.992}]}, "total": {"test_mcc": 68.03158744117059, "test_mcc_se": 2.3685105380208777, "test_macro_f1": 82.11989159631938, "test_macro_f1_se": 1.6882254128309446}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_loss": 0.45471900701522827, "test_mcc": 0.6577375413017558, "test_macro_f1": 0.8115529127984729, "test_runtime": 3.5148, "test_samples_per_second": 582.685, "test_steps_per_second": 18.209}, {"test_loss": 0.3985432982444763, "test_mcc": 0.6883990719056985, "test_macro_f1": 0.8391343663310191, "test_runtime": 3.6192, "test_samples_per_second": 565.864, "test_steps_per_second": 17.683}, {"test_loss": 0.42869842052459717, "test_mcc": 0.6803272837603684, "test_macro_f1": 0.8307227148985863, "test_runtime": 3.6344, "test_samples_per_second": 563.509, "test_steps_per_second": 17.61}, {"test_loss": 0.3826386630535126, "test_mcc": 0.7184289201967907, "test_macro_f1": 0.8530787931927781, "test_runtime": 3.466, "test_samples_per_second": 590.875, "test_steps_per_second": 18.465}, {"test_loss": 0.4034659266471863, "test_mcc": 0.6918207698004212, "test_macro_f1": 0.8344320289245251, "test_runtime": 3.524, "test_samples_per_second": 581.159, "test_steps_per_second": 18.161}, {"test_loss": 0.3788910210132599, "test_mcc": 0.6958139181306318, "test_macro_f1": 0.8395109319938476, "test_runtime": 3.6147, "test_samples_per_second": 566.573, "test_steps_per_second": 17.705}, {"test_loss": 0.47697192430496216, "test_mcc": 0.6162347533808393, "test_macro_f1": 0.7837159159247253, "test_runtime": 3.5299, "test_samples_per_second": 580.188, "test_steps_per_second": 18.131}, {"test_loss": 0.4543919265270233, "test_mcc": 0.6155793485476305, "test_macro_f1": 0.793125197098707, "test_runtime": 3.5368, "test_samples_per_second": 579.05, "test_steps_per_second": 18.095}, {"test_loss": 0.41132116317749023, "test_mcc": 0.6633032230057774, "test_macro_f1": 0.8226222503386947, "test_runtime": 3.5133, "test_samples_per_second": 582.936, "test_steps_per_second": 18.217}, {"test_loss": 0.43263518810272217, "test_mcc": 0.6620539634711712, "test_macro_f1": 0.8246919920959006, "test_runtime": 3.6023, "test_samples_per_second": 568.525, "test_steps_per_second": 17.766}]}, "total": {"test_mcc": 66.89698793501086, "test_mcc_se": 2.069437338635442, "test_macro_f1": 82.32587103597255, "test_macro_f1_se": 1.3384740358657392}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.38465335965156555, "test_mcc": 0.742851214211726, "test_macro_f1": 0.7516436432470729, "test_runtime": 14.5069, "test_samples_per_second": 141.174, "test_steps_per_second": 17.647}, {"test_loss": 0.4252317547798157, "test_mcc": 0.7273373376733905, "test_macro_f1": 0.6704059210311369, "test_runtime": 13.9661, "test_samples_per_second": 146.641, "test_steps_per_second": 18.33}, {"test_loss": 0.39670222997665405, "test_mcc": 0.751869757552428, "test_macro_f1": 0.73952447739264, "test_runtime": 17.2226, "test_samples_per_second": 118.914, "test_steps_per_second": 59.457}, {"test_loss": 0.3632529675960541, "test_mcc": 0.7643345918618727, "test_macro_f1": 0.6724816116463092, "test_runtime": 16.9386, "test_samples_per_second": 120.907, "test_steps_per_second": 60.454}, {"test_loss": 0.40908083319664, "test_mcc": 0.7327918201223121, "test_macro_f1": 0.7351239862046816, "test_runtime": 17.1829, "test_samples_per_second": 119.188, "test_steps_per_second": 59.594}, {"test_loss": 0.3768458366394043, "test_mcc": 0.7578567850639449, "test_macro_f1": 0.7147430604159507, "test_runtime": 17.3338, "test_samples_per_second": 118.15, "test_steps_per_second": 59.075}, {"test_loss": 0.3451361656188965, "test_mcc": 0.7867686290610311, "test_macro_f1": 0.782447921885581, "test_runtime": 17.2099, "test_samples_per_second": 119.001, "test_steps_per_second": 59.501}, {"test_loss": 0.39966970682144165, "test_mcc": 0.7494232492973505, "test_macro_f1": 0.7085582739008757, "test_runtime": 17.6737, "test_samples_per_second": 115.878, "test_steps_per_second": 57.939}, {"test_loss": 0.41222184896469116, "test_mcc": 0.7351590568347688, "test_macro_f1": 0.6877859295654917, "test_runtime": 17.4218, "test_samples_per_second": 117.554, "test_steps_per_second": 58.777}, {"test_loss": 0.36979037523269653, "test_mcc": 0.7561002334845025, "test_macro_f1": 0.7727611950035097, "test_runtime": 17.4214, "test_samples_per_second": 117.557, "test_steps_per_second": 58.778}]}, "total": {"test_mcc": 75.04492675163328, "test_mcc_se": 1.081309339615553, "test_macro_f1": 72.35476020293248, "test_macro_f1_se": 2.451763968048316}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.8028892874717712, "test_mcc": 0.5152522871995934, "test_macro_f1": 0.6613333357396639, "test_runtime": 4.3594, "test_samples_per_second": 469.79, "test_steps_per_second": 14.681}, {"test_loss": 0.7660902738571167, "test_mcc": 0.5191569117014987, "test_macro_f1": 0.6733008964058396, "test_runtime": 4.3378, "test_samples_per_second": 472.123, "test_steps_per_second": 14.754}, {"test_loss": 0.8464475274085999, "test_mcc": 0.49604175495235797, "test_macro_f1": 0.6677742895269371, "test_runtime": 4.3642, "test_samples_per_second": 469.27, "test_steps_per_second": 14.665}, {"test_loss": 0.8103988766670227, "test_mcc": 0.520713279767734, "test_macro_f1": 0.6776733143824831, "test_runtime": 4.2885, "test_samples_per_second": 477.56, "test_steps_per_second": 14.924}, {"test_loss": 0.7924936413764954, "test_mcc": 0.5108317587748533, "test_macro_f1": 0.673732859966572, "test_runtime": 4.2763, "test_samples_per_second": 478.914, "test_steps_per_second": 14.966}, {"test_loss": 0.8107879161834717, "test_mcc": 0.4933966856594589, "test_macro_f1": 0.6646122115761129, "test_runtime": 4.3403, "test_samples_per_second": 471.855, "test_steps_per_second": 14.745}, {"test_loss": 0.8398717641830444, "test_mcc": 0.49511848243139966, "test_macro_f1": 0.6650901343881498, "test_runtime": 4.2837, "test_samples_per_second": 478.093, "test_steps_per_second": 14.94}, {"test_loss": 0.7954670190811157, "test_mcc": 0.5041970011597676, "test_macro_f1": 0.6697674051737815, "test_runtime": 4.3518, "test_samples_per_second": 470.612, "test_steps_per_second": 14.707}, {"test_loss": 0.8607965111732483, "test_mcc": 0.500886544204748, "test_macro_f1": 0.6598414516525785, "test_runtime": 4.3234, "test_samples_per_second": 473.699, "test_steps_per_second": 14.803}, {"test_loss": 0.8499808311462402, "test_mcc": 0.49205860250133787, "test_macro_f1": 0.6583195596414126, "test_runtime": 4.2611, "test_samples_per_second": 480.625, "test_steps_per_second": 15.02}]}, "total": {"test_mcc": 50.4765330835275, "test_mcc_se": 0.6800537720777708, "test_macro_f1": 66.7144545845353, "test_macro_f1_se": 0.40011347524909724}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.7573544979095459, "test_mcc": 0.4782383560750472, "test_macro_f1": 0.5501236474455898, "test_runtime": 3.6932, "test_samples_per_second": 554.529, "test_steps_per_second": 17.329}, {"test_loss": 0.7466832995414734, "test_mcc": 0.5426257760082376, "test_macro_f1": 0.673598175625775, "test_runtime": 3.4681, "test_samples_per_second": 590.526, "test_steps_per_second": 18.454}, {"test_loss": 0.6970210075378418, "test_mcc": 0.5441398420055441, "test_macro_f1": 0.6770937383192205, "test_runtime": 3.5436, "test_samples_per_second": 577.951, "test_steps_per_second": 18.061}, {"test_loss": 0.7148302793502808, "test_mcc": 0.5400985262610477, "test_macro_f1": 0.6617778395416555, "test_runtime": 3.594, "test_samples_per_second": 569.831, "test_steps_per_second": 17.807}, {"test_loss": 0.6861291527748108, "test_mcc": 0.5316874395891055, "test_macro_f1": 0.6452248191176971, "test_runtime": 3.5641, "test_samples_per_second": 574.625, "test_steps_per_second": 17.957}, {"test_loss": 0.6942429542541504, "test_mcc": 0.5628343064206781, "test_macro_f1": 0.6936614226478914, "test_runtime": 3.7076, "test_samples_per_second": 552.382, "test_steps_per_second": 17.262}, {"test_loss": 0.6798555850982666, "test_mcc": 0.5586332873686649, "test_macro_f1": 0.683806205666356, "test_runtime": 3.4783, "test_samples_per_second": 588.798, "test_steps_per_second": 18.4}, {"test_loss": 0.7328364849090576, "test_mcc": 0.49315311380277854, "test_macro_f1": 0.6142949611063535, "test_runtime": 3.5897, "test_samples_per_second": 570.527, "test_steps_per_second": 17.829}, {"test_loss": 0.7071875333786011, "test_mcc": 0.5423328011446882, "test_macro_f1": 0.6779360361047476, "test_runtime": 3.7059, "test_samples_per_second": 552.639, "test_steps_per_second": 17.27}, {"test_loss": 0.7438680529594421, "test_mcc": 0.5290729852548328, "test_macro_f1": 0.6451767700671528, "test_runtime": 3.6882, "test_samples_per_second": 555.278, "test_steps_per_second": 17.352}]}, "total": {"test_mcc": 53.22816433930625, "test_mcc_se": 1.6656783033940452, "test_macro_f1": 65.22693615642439, "test_macro_f1_se": 2.65417139221278}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.07390207052230835, "test_micro_f1": 0.604040404040404, "test_micro_f1_no_misc": 0.6629401900503075, "test_runtime": 7.3731, "test_samples_per_second": 277.766, "test_steps_per_second": 8.68}, {"test_loss": 0.07176891714334488, "test_micro_f1": 0.6645833333333333, "test_micro_f1_no_misc": 0.7366526694661067, "test_runtime": 7.1369, "test_samples_per_second": 286.958, "test_steps_per_second": 8.967}, {"test_loss": 0.05717780441045761, "test_micro_f1": 0.6801932367149759, "test_micro_f1_no_misc": 0.748898678414097, "test_runtime": 6.5339, "test_samples_per_second": 313.444, "test_steps_per_second": 9.795}, {"test_loss": 0.06926387548446655, "test_micro_f1": 0.6840148698884759, "test_micro_f1_no_misc": 0.749047359825803, "test_runtime": 7.3226, "test_samples_per_second": 279.68, "test_steps_per_second": 8.74}, {"test_loss": 0.0715848058462143, "test_micro_f1": 0.6511194029850745, "test_micro_f1_no_misc": 0.704521556256572, "test_runtime": 7.3, "test_samples_per_second": 280.547, "test_steps_per_second": 8.767}, {"test_loss": 0.0699608102440834, "test_micro_f1": 0.6493629070316188, "test_micro_f1_no_misc": 0.7099236641221374, "test_runtime": 5.8996, "test_samples_per_second": 347.14, "test_steps_per_second": 10.848}, {"test_loss": 0.07353248447179794, "test_micro_f1": 0.6734496124031008, "test_micro_f1_no_misc": 0.7301057317751809, "test_runtime": 6.0096, "test_samples_per_second": 340.79, "test_steps_per_second": 10.65}, {"test_loss": 0.060219939798116684, "test_micro_f1": 0.6521739130434784, "test_micro_f1_no_misc": 0.7201492537313433, "test_runtime": 7.1037, "test_samples_per_second": 288.299, "test_steps_per_second": 9.009}, {"test_loss": 0.06485132873058319, "test_micro_f1": 0.6169909824394875, "test_micro_f1_no_misc": 0.6809192944949225, "test_runtime": 6.6871, "test_samples_per_second": 306.26, "test_steps_per_second": 9.571}, {"test_loss": 0.05577438324689865, "test_micro_f1": 0.7176301958910655, "test_micro_f1_no_misc": 0.7818480043739748, "test_runtime": 7.2864, "test_samples_per_second": 281.071, "test_steps_per_second": 8.783}]}, "total": {"test_micro_f1": 65.93558857771016, "test_micro_f1_se": 2.0387750886373954, "test_micro_f1_no_misc": 72.25006402510445, "test_micro_f1_no_misc_se": 2.161459711884639}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.06359957158565521, "test_micro_f1": 0.7986697365055001, "test_micro_f1_no_misc": 0.825494205862304, "test_runtime": 8.1586, "test_samples_per_second": 251.023, "test_steps_per_second": 7.844}, {"test_loss": 0.06443913280963898, "test_micro_f1": 0.7633087633087633, "test_micro_f1_no_misc": 0.7912794853466762, "test_runtime": 6.7408, "test_samples_per_second": 303.821, "test_steps_per_second": 9.494}, {"test_loss": 0.06156415119767189, "test_micro_f1": 0.7782470960929251, "test_micro_f1_no_misc": 0.8050089445438282, "test_runtime": 8.2638, "test_samples_per_second": 247.828, "test_steps_per_second": 7.745}, {"test_loss": 0.06904252618551254, "test_micro_f1": 0.7931659332125292, "test_micro_f1_no_misc": 0.821160409556314, "test_runtime": 7.942, "test_samples_per_second": 257.868, "test_steps_per_second": 8.058}, {"test_loss": 0.07569220662117004, "test_micro_f1": 0.7501391207568169, "test_micro_f1_no_misc": 0.7920569501686024, "test_runtime": 8.1831, "test_samples_per_second": 250.271, "test_steps_per_second": 7.821}, {"test_loss": 0.07841356098651886, "test_micro_f1": 0.7101996762007555, "test_micro_f1_no_misc": 0.7228490832157969, "test_runtime": 8.1039, "test_samples_per_second": 252.719, "test_steps_per_second": 7.897}, {"test_loss": 0.06748752295970917, "test_micro_f1": 0.785524215007983, "test_micro_f1_no_misc": 0.8057103064066852, "test_runtime": 8.254, "test_samples_per_second": 248.121, "test_steps_per_second": 7.754}, {"test_loss": 0.06558774411678314, "test_micro_f1": 0.764944549634839, "test_micro_f1_no_misc": 0.8143582306018854, "test_runtime": 8.1436, "test_samples_per_second": 251.486, "test_steps_per_second": 7.859}, {"test_loss": 0.06743814796209335, "test_micro_f1": 0.7957689178193653, "test_micro_f1_no_misc": 0.8175235336712526, "test_runtime": 7.942, "test_samples_per_second": 257.87, "test_steps_per_second": 8.058}, {"test_loss": 0.060765840113162994, "test_micro_f1": 0.7997875730217737, "test_micro_f1_no_misc": 0.8293551834698967, "test_runtime": 7.0541, "test_samples_per_second": 290.328, "test_steps_per_second": 9.073}]}, "total": {"test_micro_f1": 77.3975558156125, "test_micro_f1_se": 1.7410787346146932, "test_micro_f1_no_misc": 80.24796332843242, "test_micro_f1_no_misc_se": 1.911521140358121}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.04560001939535141, "test_micro_f1": 0.8157894736842104, "test_micro_f1_no_misc": 0.8683788121990368, "test_runtime": 6.4368, "test_samples_per_second": 318.169, "test_steps_per_second": 9.943}, {"test_loss": 0.03651643544435501, "test_micro_f1": 0.8409260642270351, "test_micro_f1_no_misc": 0.8767123287671234, "test_runtime": 6.3083, "test_samples_per_second": 324.654, "test_steps_per_second": 10.145}, {"test_loss": 0.048867180943489075, "test_micro_f1": 0.8187780462547463, "test_micro_f1_no_misc": 0.8556942277691107, "test_runtime": 5.9167, "test_samples_per_second": 346.137, "test_steps_per_second": 10.817}, {"test_loss": 0.032758310437202454, "test_micro_f1": 0.8690140845070423, "test_micro_f1_no_misc": 0.8968222832483327, "test_runtime": 5.849, "test_samples_per_second": 350.146, "test_steps_per_second": 10.942}, {"test_loss": 0.031048834323883057, "test_micro_f1": 0.8779342723004696, "test_micro_f1_no_misc": 0.9103703703703705, "test_runtime": 6.3879, "test_samples_per_second": 320.604, "test_steps_per_second": 10.019}, {"test_loss": 0.031403131783008575, "test_micro_f1": 0.8752125127507651, "test_micro_f1_no_misc": 0.9066059225512528, "test_runtime": 6.3605, "test_samples_per_second": 321.99, "test_steps_per_second": 10.062}, {"test_loss": 0.035181403160095215, "test_micro_f1": 0.8525597269624574, "test_micro_f1_no_misc": 0.8803001876172607, "test_runtime": 5.7357, "test_samples_per_second": 357.063, "test_steps_per_second": 11.158}, {"test_loss": 0.03519726172089577, "test_micro_f1": 0.8851422550052688, "test_micro_f1_no_misc": 0.9106124001521492, "test_runtime": 5.7804, "test_samples_per_second": 354.3, "test_steps_per_second": 11.072}, {"test_loss": 0.03383327275514603, "test_micro_f1": 0.8801711840228246, "test_micro_f1_no_misc": 0.8981891348088531, "test_runtime": 5.8121, "test_samples_per_second": 352.369, "test_steps_per_second": 11.012}, {"test_loss": 0.042796459048986435, "test_micro_f1": 0.8657627118644069, "test_micro_f1_no_misc": 0.9034719572682182, "test_runtime": 6.3022, "test_samples_per_second": 324.966, "test_steps_per_second": 10.155}]}, "total": {"test_micro_f1": 85.81290331579228, "test_micro_f1_se": 1.5658913798526086, "test_micro_f1_no_misc": 89.07157624751709, "test_micro_f1_no_misc_se": 1.1905314533865794}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.0495305210351944, "test_micro_f1": 0.7465164541950786, "test_micro_f1_no_misc": 0.7987179487179488, "test_runtime": 5.8696, "test_samples_per_second": 348.914, "test_steps_per_second": 10.904}, {"test_loss": 0.05198520049452782, "test_micro_f1": 0.8127465857359636, "test_micro_f1_no_misc": 0.8520425677995194, "test_runtime": 6.0398, "test_samples_per_second": 339.085, "test_steps_per_second": 10.596}, {"test_loss": 0.05280247703194618, "test_micro_f1": 0.7962229667986598, "test_micro_f1_no_misc": 0.8415410385259631, "test_runtime": 5.8968, "test_samples_per_second": 347.31, "test_steps_per_second": 10.853}, {"test_loss": 0.05728168040513992, "test_micro_f1": 0.804921968787515, "test_micro_f1_no_misc": 0.8409846972721223, "test_runtime": 6.1145, "test_samples_per_second": 334.941, "test_steps_per_second": 10.467}, {"test_loss": 0.06720288097858429, "test_micro_f1": 0.7468167012140954, "test_micro_f1_no_misc": 0.8041863605671844, "test_runtime": 5.9687, "test_samples_per_second": 343.125, "test_steps_per_second": 10.723}, {"test_loss": 0.0636729747056961, "test_micro_f1": 0.7511019688510138, "test_micro_f1_no_misc": 0.8106565176022836, "test_runtime": 6.0974, "test_samples_per_second": 335.879, "test_steps_per_second": 10.496}, {"test_loss": 0.050756968557834625, "test_micro_f1": 0.7686635944700462, "test_micro_f1_no_misc": 0.8134907251264756, "test_runtime": 6.1137, "test_samples_per_second": 334.987, "test_steps_per_second": 10.468}, {"test_loss": 0.046984098851680756, "test_micro_f1": 0.8358118361153263, "test_micro_f1_no_misc": 0.8657741160315826, "test_runtime": 6.0342, "test_samples_per_second": 339.401, "test_steps_per_second": 10.606}, {"test_loss": 0.05460352450609207, "test_micro_f1": 0.7748243201955394, "test_micro_f1_no_misc": 0.8219645293315143, "test_runtime": 5.601, "test_samples_per_second": 365.648, "test_steps_per_second": 11.426}, {"test_loss": 0.04267117753624916, "test_micro_f1": 0.8422664624808576, "test_micro_f1_no_misc": 0.8777027027027027, "test_runtime": 5.8355, "test_samples_per_second": 350.953, "test_steps_per_second": 10.967}]}, "total": {"test_micro_f1": 78.79892858844096, "test_micro_f1_se": 2.217784405091553, "test_micro_f1_no_misc": 83.27061203677297, "test_micro_f1_no_misc_se": 1.675649619393017}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.38425585627555847, "test_mcc": 0.7081830885182268, "test_macro_f1": 0.8454588813831276, "test_runtime": 3.2024, "test_samples_per_second": 639.527, "test_steps_per_second": 19.985}, {"test_loss": 0.41543716192245483, "test_mcc": 0.7056158744218648, "test_macro_f1": 0.8456901748040988, "test_runtime": 3.3504, "test_samples_per_second": 611.272, "test_steps_per_second": 19.102}, {"test_loss": 0.39751899242401123, "test_mcc": 0.7197009577914754, "test_macro_f1": 0.8546116244635877, "test_runtime": 3.3514, "test_samples_per_second": 611.087, "test_steps_per_second": 19.096}, {"test_loss": 0.42661258578300476, "test_mcc": 0.7197057136700483, "test_macro_f1": 0.8582890690188106, "test_runtime": 3.2462, "test_samples_per_second": 630.896, "test_steps_per_second": 19.715}, {"test_loss": 0.4020676910877228, "test_mcc": 0.6573127282336877, "test_macro_f1": 0.8206656289056253, "test_runtime": 3.2823, "test_samples_per_second": 623.952, "test_steps_per_second": 19.498}, {"test_loss": 0.3726979196071625, "test_mcc": 0.7274506508245336, "test_macro_f1": 0.8568889689329131, "test_runtime": 3.2549, "test_samples_per_second": 629.206, "test_steps_per_second": 19.663}, {"test_loss": 0.443151593208313, "test_mcc": 0.687719648015342, "test_macro_f1": 0.825555360862878, "test_runtime": 3.3098, "test_samples_per_second": 618.763, "test_steps_per_second": 19.336}, {"test_loss": 0.4215664565563202, "test_mcc": 0.6853852926117172, "test_macro_f1": 0.8371075239450522, "test_runtime": 3.3238, "test_samples_per_second": 616.168, "test_steps_per_second": 19.255}, {"test_loss": 0.40644580125808716, "test_mcc": 0.6775349456533118, "test_macro_f1": 0.827072521888172, "test_runtime": 3.2942, "test_samples_per_second": 621.701, "test_steps_per_second": 19.428}, {"test_loss": 0.3830140233039856, "test_mcc": 0.7276334243146341, "test_macro_f1": 0.8581559399860282, "test_runtime": 3.266, "test_samples_per_second": 627.064, "test_steps_per_second": 19.596}]}, "total": {"test_mcc": 70.16242324054842, "test_mcc_se": 1.469199156393484, "test_macro_f1": 84.29495694190294, "test_macro_f1_se": 0.899608100111646}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.4666765630245209, "test_mcc": 0.6018058817178741, "test_macro_f1": 0.7876756115249575, "test_runtime": 3.675, "test_samples_per_second": 557.284, "test_steps_per_second": 17.415}, {"test_loss": 0.47624945640563965, "test_mcc": 0.6027069865986736, "test_macro_f1": 0.7761204664287087, "test_runtime": 3.8399, "test_samples_per_second": 533.348, "test_steps_per_second": 16.667}, {"test_loss": 0.4539833664894104, "test_mcc": 0.6735101818612653, "test_macro_f1": 0.8298821658696348, "test_runtime": 3.7339, "test_samples_per_second": 548.489, "test_steps_per_second": 17.14}, {"test_loss": 0.4966782331466675, "test_mcc": 0.6593610853473344, "test_macro_f1": 0.8180680526216546, "test_runtime": 3.8455, "test_samples_per_second": 532.576, "test_steps_per_second": 16.643}, {"test_loss": 0.44369181990623474, "test_mcc": 0.6387586582268839, "test_macro_f1": 0.8089293863496814, "test_runtime": 3.6618, "test_samples_per_second": 559.29, "test_steps_per_second": 17.478}, {"test_loss": 0.40863507986068726, "test_mcc": 0.6931120551873091, "test_macro_f1": 0.8434751566597307, "test_runtime": 3.6852, "test_samples_per_second": 555.731, "test_steps_per_second": 17.367}, {"test_loss": 0.4943811893463135, "test_mcc": 0.688584221838154, "test_macro_f1": 0.8363912337230048, "test_runtime": 3.6252, "test_samples_per_second": 564.935, "test_steps_per_second": 17.654}, {"test_loss": 0.42956459522247314, "test_mcc": 0.66076669153031, "test_macro_f1": 0.8225266880291592, "test_runtime": 3.6642, "test_samples_per_second": 558.925, "test_steps_per_second": 17.466}, {"test_loss": 0.5022686123847961, "test_mcc": 0.5764846777609125, "test_macro_f1": 0.7603908877466845, "test_runtime": 3.6984, "test_samples_per_second": 553.749, "test_steps_per_second": 17.305}, {"test_loss": 0.5201795697212219, "test_mcc": 0.6392063740829194, "test_macro_f1": 0.8080840868691552, "test_runtime": 3.7588, "test_samples_per_second": 544.851, "test_steps_per_second": 17.027}]}, "total": {"test_mcc": 64.34296814151637, "test_mcc_se": 2.433932432854917, "test_macro_f1": 80.91543735822371, "test_macro_f1_se": 1.670710978283042}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.362928569316864, "test_mcc": 0.7316787859245842, "test_macro_f1": 0.8581699593296315, "test_runtime": 3.304, "test_samples_per_second": 619.855, "test_steps_per_second": 19.37}, {"test_loss": 0.43557220697402954, "test_mcc": 0.6981764566915855, "test_macro_f1": 0.8354158225094173, "test_runtime": 3.3229, "test_samples_per_second": 616.32, "test_steps_per_second": 19.26}, {"test_loss": 0.3889164328575134, "test_mcc": 0.7203839864404432, "test_macro_f1": 0.8498015530629852, "test_runtime": 3.3407, "test_samples_per_second": 613.047, "test_steps_per_second": 19.158}, {"test_loss": 0.3603624403476715, "test_mcc": 0.7135943173509298, "test_macro_f1": 0.8507250926437105, "test_runtime": 3.4093, "test_samples_per_second": 600.718, "test_steps_per_second": 18.772}, {"test_loss": 0.3714733123779297, "test_mcc": 0.7401309455760109, "test_macro_f1": 0.8613490071249545, "test_runtime": 3.396, "test_samples_per_second": 603.056, "test_steps_per_second": 18.845}, {"test_loss": 0.4056454300880432, "test_mcc": 0.7382268104739365, "test_macro_f1": 0.8589184959911128, "test_runtime": 3.2455, "test_samples_per_second": 631.019, "test_steps_per_second": 19.719}, {"test_loss": 0.4252294898033142, "test_mcc": 0.6693947709643597, "test_macro_f1": 0.8137109244716654, "test_runtime": 3.2626, "test_samples_per_second": 627.713, "test_steps_per_second": 19.616}, {"test_loss": 0.41058555245399475, "test_mcc": 0.710139611793382, "test_macro_f1": 0.8418965883898633, "test_runtime": 3.2818, "test_samples_per_second": 624.046, "test_steps_per_second": 19.501}, {"test_loss": 0.4550555348396301, "test_mcc": 0.6562277263680513, "test_macro_f1": 0.8041545776560579, "test_runtime": 3.2469, "test_samples_per_second": 630.757, "test_steps_per_second": 19.711}, {"test_loss": 0.5082334280014038, "test_mcc": 0.6283355589387728, "test_macro_f1": 0.7866524768861779, "test_runtime": 3.3775, "test_samples_per_second": 606.359, "test_steps_per_second": 18.949}]}, "total": {"test_mcc": 70.06288970522057, "test_mcc_se": 2.3343578693314955, "test_macro_f1": 83.60794498065577, "test_macro_f1_se": 1.6066963342186713}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_loss": 0.4206453561782837, "test_mcc": 0.67197785778849, "test_macro_f1": 0.8227810431136278, "test_runtime": 3.5681, "test_samples_per_second": 573.973, "test_steps_per_second": 17.937}, {"test_loss": 0.428705632686615, "test_mcc": 0.6245840039875813, "test_macro_f1": 0.7990899355532102, "test_runtime": 3.612, "test_samples_per_second": 567.0, "test_steps_per_second": 17.719}, {"test_loss": 0.38800039887428284, "test_mcc": 0.6943977602984754, "test_macro_f1": 0.8400313400139157, "test_runtime": 3.6491, "test_samples_per_second": 561.239, "test_steps_per_second": 17.539}, {"test_loss": 0.4475857615470886, "test_mcc": 0.6385860401023031, "test_macro_f1": 0.794747224570637, "test_runtime": 3.4794, "test_samples_per_second": 588.611, "test_steps_per_second": 18.394}, {"test_loss": 0.370206743478775, "test_mcc": 0.7064698007182606, "test_macro_f1": 0.8471425828167289, "test_runtime": 3.5379, "test_samples_per_second": 578.876, "test_steps_per_second": 18.09}, {"test_loss": 0.403959721326828, "test_mcc": 0.7085500871752286, "test_macro_f1": 0.8480611975731998, "test_runtime": 3.6215, "test_samples_per_second": 565.516, "test_steps_per_second": 17.672}, {"test_loss": 0.4545028507709503, "test_mcc": 0.6488001306497018, "test_macro_f1": 0.8079638536614087, "test_runtime": 3.5806, "test_samples_per_second": 571.975, "test_steps_per_second": 17.874}, {"test_loss": 0.43107321858406067, "test_mcc": 0.6628942086961654, "test_macro_f1": 0.8163355408388521, "test_runtime": 3.5273, "test_samples_per_second": 580.615, "test_steps_per_second": 18.144}, {"test_loss": 0.38188445568084717, "test_mcc": 0.6827434298944219, "test_macro_f1": 0.8327651831385534, "test_runtime": 3.4974, "test_samples_per_second": 585.573, "test_steps_per_second": 18.299}, {"test_loss": 0.42333710193634033, "test_mcc": 0.6423003001957288, "test_macro_f1": 0.8100770338519743, "test_runtime": 3.6024, "test_samples_per_second": 568.507, "test_steps_per_second": 17.766}]}, "total": {"test_mcc": 66.81303619506357, "test_mcc_se": 1.8315961335210602, "test_macro_f1": 82.18994935132109, "test_macro_f1_se": 1.2032165864547892}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.4622061848640442, "test_mcc": 0.71580916716644, "test_macro_f1": 0.6064596494253124, "test_runtime": 14.501, "test_samples_per_second": 141.232, "test_steps_per_second": 17.654}, {"test_loss": 0.4405435025691986, "test_mcc": 0.7296787570064456, "test_macro_f1": 0.6999368385461059, "test_runtime": 13.8458, "test_samples_per_second": 147.915, "test_steps_per_second": 18.489}, {"test_loss": 0.4468706548213959, "test_mcc": 0.7233575848167408, "test_macro_f1": 0.6718446467132018, "test_runtime": 17.5387, "test_samples_per_second": 116.77, "test_steps_per_second": 58.385}, {"test_loss": 0.4311557114124298, "test_mcc": 0.7554544485428699, "test_macro_f1": 0.7305580935025802, "test_runtime": 17.1323, "test_samples_per_second": 119.54, "test_steps_per_second": 59.77}, {"test_loss": 0.42536771297454834, "test_mcc": 0.7469724493798197, "test_macro_f1": 0.698782250921638, "test_runtime": 17.2533, "test_samples_per_second": 118.702, "test_steps_per_second": 59.351}, {"test_loss": 0.44009721279144287, "test_mcc": 0.7532758790590565, "test_macro_f1": 0.7413950183401353, "test_runtime": 17.3505, "test_samples_per_second": 118.037, "test_steps_per_second": 59.019}, {"test_loss": 0.4219512343406677, "test_mcc": 0.7339842163627418, "test_macro_f1": 0.7139694634313821, "test_runtime": 17.2735, "test_samples_per_second": 118.563, "test_steps_per_second": 59.281}, {"test_loss": 0.45656833052635193, "test_mcc": 0.7305378218872274, "test_macro_f1": 0.7185809065854399, "test_runtime": 17.5466, "test_samples_per_second": 116.718, "test_steps_per_second": 58.359}, {"test_loss": 0.4541904330253601, "test_mcc": 0.7366065644832613, "test_macro_f1": 0.6954481013688992, "test_runtime": 17.5054, "test_samples_per_second": 116.992, "test_steps_per_second": 58.496}, {"test_loss": 0.44271916151046753, "test_mcc": 0.7212933002584743, "test_macro_f1": 0.742580293766252, "test_runtime": 17.2144, "test_samples_per_second": 118.97, "test_steps_per_second": 59.485}]}, "total": {"test_mcc": 73.46970188963077, "test_mcc_se": 0.8362566699758106, "test_macro_f1": 70.19555262600946, "test_macro_f1_se": 2.4901608657657586}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.8427096009254456, "test_mcc": 0.48429082473404506, "test_macro_f1": 0.6451303562826852, "test_runtime": 4.3715, "test_samples_per_second": 468.489, "test_steps_per_second": 14.64}, {"test_loss": 0.7979487180709839, "test_mcc": 0.4821598476125987, "test_macro_f1": 0.6431407205394644, "test_runtime": 4.3323, "test_samples_per_second": 472.733, "test_steps_per_second": 14.773}, {"test_loss": 0.8113290667533875, "test_mcc": 0.4913343650448725, "test_macro_f1": 0.6627110910995194, "test_runtime": 4.3386, "test_samples_per_second": 472.044, "test_steps_per_second": 14.751}, {"test_loss": 0.806322455406189, "test_mcc": 0.47702139681915584, "test_macro_f1": 0.6503880503802237, "test_runtime": 4.3142, "test_samples_per_second": 474.712, "test_steps_per_second": 14.835}, {"test_loss": 0.8194117546081543, "test_mcc": 0.5017705977719118, "test_macro_f1": 0.6678665260660955, "test_runtime": 4.2984, "test_samples_per_second": 476.455, "test_steps_per_second": 14.889}, {"test_loss": 0.8250232934951782, "test_mcc": 0.47747493499983934, "test_macro_f1": 0.6541800222918578, "test_runtime": 4.3168, "test_samples_per_second": 474.424, "test_steps_per_second": 14.826}, {"test_loss": 0.8211483955383301, "test_mcc": 0.5211753798528705, "test_macro_f1": 0.6772284877113867, "test_runtime": 4.2877, "test_samples_per_second": 477.647, "test_steps_per_second": 14.926}, {"test_loss": 0.8239747881889343, "test_mcc": 0.4958100743285517, "test_macro_f1": 0.6673651696075162, "test_runtime": 4.3609, "test_samples_per_second": 469.632, "test_steps_per_second": 14.676}, {"test_loss": 0.8299701809883118, "test_mcc": 0.48732417597824434, "test_macro_f1": 0.658437453520118, "test_runtime": 4.3252, "test_samples_per_second": 473.508, "test_steps_per_second": 14.797}, {"test_loss": 0.8522453904151917, "test_mcc": 0.494627379137598, "test_macro_f1": 0.657095814536674, "test_runtime": 4.2659, "test_samples_per_second": 480.083, "test_steps_per_second": 15.003}]}, "total": {"test_mcc": 49.12988976279687, "test_mcc_se": 0.8204665406455394, "test_macro_f1": 65.8354369203554, "test_macro_f1_se": 0.6648920791750657}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.6877707242965698, "test_mcc": 0.5746805623302604, "test_macro_f1": 0.7096206630070263, "test_runtime": 3.684, "test_samples_per_second": 555.917, "test_steps_per_second": 17.372}, {"test_loss": 0.7097420692443848, "test_mcc": 0.5416785531644058, "test_macro_f1": 0.6777815992243976, "test_runtime": 3.5033, "test_samples_per_second": 584.598, "test_steps_per_second": 18.269}, {"test_loss": 0.7494053244590759, "test_mcc": 0.5398628159094869, "test_macro_f1": 0.6733800901886875, "test_runtime": 3.5629, "test_samples_per_second": 574.819, "test_steps_per_second": 17.963}, {"test_loss": 0.6914193630218506, "test_mcc": 0.5661332012078955, "test_macro_f1": 0.7003059993649839, "test_runtime": 3.5723, "test_samples_per_second": 573.301, "test_steps_per_second": 17.916}, {"test_loss": 0.6979995965957642, "test_mcc": 0.5377570330572846, "test_macro_f1": 0.669887244485674, "test_runtime": 3.5962, "test_samples_per_second": 569.482, "test_steps_per_second": 17.796}, {"test_loss": 0.7041698694229126, "test_mcc": 0.5523800249734018, "test_macro_f1": 0.6875563235325405, "test_runtime": 3.7053, "test_samples_per_second": 552.724, "test_steps_per_second": 17.273}, {"test_loss": 0.6637430787086487, "test_mcc": 0.5435003104745116, "test_macro_f1": 0.6658215180534554, "test_runtime": 3.5101, "test_samples_per_second": 583.462, "test_steps_per_second": 18.233}, {"test_loss": 0.6939895153045654, "test_mcc": 0.5461170656868164, "test_macro_f1": 0.6793309808637868, "test_runtime": 3.6071, "test_samples_per_second": 567.775, "test_steps_per_second": 17.743}, {"test_loss": 0.6973481178283691, "test_mcc": 0.5631875428740978, "test_macro_f1": 0.706093521897249, "test_runtime": 3.6702, "test_samples_per_second": 558.005, "test_steps_per_second": 17.438}, {"test_loss": 0.6749386191368103, "test_mcc": 0.5880174144696501, "test_macro_f1": 0.7196037638730043, "test_runtime": 3.6756, "test_samples_per_second": 557.185, "test_steps_per_second": 17.412}]}, "total": {"test_mcc": 55.53314524147811, "test_mcc_se": 1.0512960544266146, "test_macro_f1": 68.89381704490806, "test_macro_f1_se": 1.1595011442779646}}, "num_model_parameters": 278045955, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.08974437415599823, "test_micro_f1": 0.5908863294942414, "test_micro_f1_no_misc": 0.6448979591836734, "test_runtime": 7.3219, "test_samples_per_second": 279.707, "test_steps_per_second": 8.741}, {"test_loss": 0.09496060013771057, "test_micro_f1": 0.5960334029227556, "test_micro_f1_no_misc": 0.6626722588376273, "test_runtime": 7.117, "test_samples_per_second": 287.762, "test_steps_per_second": 8.993}, {"test_loss": 0.08289483934640884, "test_micro_f1": 0.5938402309913378, "test_micro_f1_no_misc": 0.6430131004366813, "test_runtime": 6.5553, "test_samples_per_second": 312.417, "test_steps_per_second": 9.763}, {"test_loss": 0.08659963309764862, "test_micro_f1": 0.607976653696498, "test_micro_f1_no_misc": 0.6418400876232201, "test_runtime": 7.2912, "test_samples_per_second": 280.885, "test_steps_per_second": 8.778}, {"test_loss": 0.0966288149356842, "test_micro_f1": 0.5484739676840216, "test_micro_f1_no_misc": 0.6015584415584415, "test_runtime": 7.3342, "test_samples_per_second": 279.241, "test_steps_per_second": 8.726}, {"test_loss": 0.09117157757282257, "test_micro_f1": 0.5966460723742277, "test_micro_f1_no_misc": 0.6408668730650156, "test_runtime": 5.9242, "test_samples_per_second": 345.7, "test_steps_per_second": 10.803}, {"test_loss": 0.09857824444770813, "test_micro_f1": 0.5885687293339632, "test_micro_f1_no_misc": 0.6446011937059143, "test_runtime": 6.0663, "test_samples_per_second": 337.603, "test_steps_per_second": 10.55}, {"test_loss": 0.08738026767969131, "test_micro_f1": 0.6163522012578616, "test_micro_f1_no_misc": 0.6630824372759857, "test_runtime": 7.0201, "test_samples_per_second": 291.734, "test_steps_per_second": 9.117}, {"test_loss": 0.08647502958774567, "test_micro_f1": 0.6084949215143122, "test_micro_f1_no_misc": 0.6739846322722284, "test_runtime": 6.6101, "test_samples_per_second": 309.829, "test_steps_per_second": 9.682}, {"test_loss": 0.08392716199159622, "test_micro_f1": 0.6346615458473356, "test_micro_f1_no_misc": 0.6975964225824483, "test_runtime": 7.3331, "test_samples_per_second": 279.281, "test_steps_per_second": 8.728}]}, "total": {"test_micro_f1": 59.819340551165546, "test_micro_f1_se": 1.3867853044357072, "test_micro_f1_no_misc": 65.14113406541236, "test_micro_f1_no_misc_se": 1.567057415361375}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.0955355167388916, "test_micro_f1": 0.7263389581804842, "test_micro_f1_no_misc": 0.7482540738277352, "test_runtime": 8.2072, "test_samples_per_second": 249.536, "test_steps_per_second": 7.798}, {"test_loss": 0.09311694651842117, "test_micro_f1": 0.7439718233541046, "test_micro_f1_no_misc": 0.76, "test_runtime": 6.7441, "test_samples_per_second": 303.672, "test_steps_per_second": 9.49}, {"test_loss": 0.09343254566192627, "test_micro_f1": 0.7671379034409176, "test_micro_f1_no_misc": 0.7850861765740416, "test_runtime": 8.2538, "test_samples_per_second": 248.128, "test_steps_per_second": 7.754}, {"test_loss": 0.09577487409114838, "test_micro_f1": 0.7618304732189287, "test_micro_f1_no_misc": 0.7800565770862802, "test_runtime": 7.9138, "test_samples_per_second": 258.787, "test_steps_per_second": 8.087}, {"test_loss": 0.09264767169952393, "test_micro_f1": 0.7297883884970157, "test_micro_f1_no_misc": 0.7482282730324507, "test_runtime": 8.2682, "test_samples_per_second": 247.695, "test_steps_per_second": 7.74}, {"test_loss": 0.0925513356924057, "test_micro_f1": 0.7675054704595186, "test_micro_f1_no_misc": 0.7787345563459379, "test_runtime": 8.1319, "test_samples_per_second": 251.848, "test_steps_per_second": 7.87}, {"test_loss": 0.09213520586490631, "test_micro_f1": 0.7583821181479511, "test_micro_f1_no_misc": 0.7687943262411346, "test_runtime": 8.1585, "test_samples_per_second": 251.028, "test_steps_per_second": 7.845}, {"test_loss": 0.09084759652614594, "test_micro_f1": 0.7543616726668513, "test_micro_f1_no_misc": 0.775842904779548, "test_runtime": 8.1929, "test_samples_per_second": 249.973, "test_steps_per_second": 7.812}, {"test_loss": 0.09938891232013702, "test_micro_f1": 0.7375099127676447, "test_micro_f1_no_misc": 0.7516059957173448, "test_runtime": 7.9418, "test_samples_per_second": 257.877, "test_steps_per_second": 8.059}, {"test_loss": 0.10620645433664322, "test_micro_f1": 0.7513929424250465, "test_micro_f1_no_misc": 0.7661832331093031, "test_runtime": 7.1209, "test_samples_per_second": 287.604, "test_steps_per_second": 8.988}]}, "total": {"test_micro_f1": 74.98219663158463, "test_micro_f1_se": 0.9220364617002699, "test_micro_f1_no_misc": 76.62786116713775, "test_micro_f1_no_misc_se": 0.8523249345157018}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.07001244276762009, "test_micro_f1": 0.7575757575757576, "test_micro_f1_no_misc": 0.8064649813510153, "test_runtime": 6.4116, "test_samples_per_second": 319.419, "test_steps_per_second": 9.982}, {"test_loss": 0.06623846292495728, "test_micro_f1": 0.7878120411160059, "test_micro_f1_no_misc": 0.8250716919295371, "test_runtime": 6.3702, "test_samples_per_second": 321.497, "test_steps_per_second": 10.047}, {"test_loss": 0.06436828523874283, "test_micro_f1": 0.7806069061737007, "test_micro_f1_no_misc": 0.8169123351435221, "test_runtime": 5.911, "test_samples_per_second": 346.474, "test_steps_per_second": 10.827}, {"test_loss": 0.060441069304943085, "test_micro_f1": 0.794281729428173, "test_micro_f1_no_misc": 0.8246225319396051, "test_runtime": 5.8224, "test_samples_per_second": 351.747, "test_steps_per_second": 10.992}, {"test_loss": 0.06742073595523834, "test_micro_f1": 0.7791530944625408, "test_micro_f1_no_misc": 0.8197567268706228, "test_runtime": 6.4716, "test_samples_per_second": 316.462, "test_steps_per_second": 9.889}, {"test_loss": 0.06260441243648529, "test_micro_f1": 0.8051334008780818, "test_micro_f1_no_misc": 0.8398496240601504, "test_runtime": 6.4221, "test_samples_per_second": 318.898, "test_steps_per_second": 9.966}, {"test_loss": 0.06578502804040909, "test_micro_f1": 0.7656408522150829, "test_micro_f1_no_misc": 0.7977401129943501, "test_runtime": 5.8785, "test_samples_per_second": 348.391, "test_steps_per_second": 10.887}, {"test_loss": 0.06606629490852356, "test_micro_f1": 0.7921541637990366, "test_micro_f1_no_misc": 0.8147047901968065, "test_runtime": 5.8416, "test_samples_per_second": 350.59, "test_steps_per_second": 10.956}, {"test_loss": 0.061178021132946014, "test_micro_f1": 0.7885918003565061, "test_micro_f1_no_misc": 0.8186946011281224, "test_runtime": 5.8264, "test_samples_per_second": 351.504, "test_steps_per_second": 10.985}, {"test_loss": 0.07597991824150085, "test_micro_f1": 0.7877342419080068, "test_micro_f1_no_misc": 0.8297632468996619, "test_runtime": 6.3622, "test_samples_per_second": 321.9, "test_steps_per_second": 10.059}]}, "total": {"test_micro_f1": 78.38683987912891, "test_micro_f1_se": 0.8614385482944653, "test_micro_f1_no_misc": 81.93580642513393, "test_micro_f1_no_misc_se": 0.730546185141618}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.08690095692873001, "test_micro_f1": 0.7017330495591366, "test_micro_f1_no_misc": 0.74, "test_runtime": 5.8523, "test_samples_per_second": 349.95, "test_steps_per_second": 10.936}, {"test_loss": 0.08639175444841385, "test_micro_f1": 0.7314423657211828, "test_micro_f1_no_misc": 0.7737815126050419, "test_runtime": 6.0037, "test_samples_per_second": 341.122, "test_steps_per_second": 10.66}, {"test_loss": 0.08742403239011765, "test_micro_f1": 0.7240230233262648, "test_micro_f1_no_misc": 0.7708333333333334, "test_runtime": 5.8602, "test_samples_per_second": 349.477, "test_steps_per_second": 10.921}, {"test_loss": 0.09961637854576111, "test_micro_f1": 0.6941457586618878, "test_micro_f1_no_misc": 0.7423025435073629, "test_runtime": 6.1321, "test_samples_per_second": 333.979, "test_steps_per_second": 10.437}, {"test_loss": 0.09384658932685852, "test_micro_f1": 0.7246642246642246, "test_micro_f1_no_misc": 0.7705263157894737, "test_runtime": 5.8673, "test_samples_per_second": 349.054, "test_steps_per_second": 10.908}, {"test_loss": 0.08690541982650757, "test_micro_f1": 0.7339504329650642, "test_micro_f1_no_misc": 0.7654569892473119, "test_runtime": 6.1181, "test_samples_per_second": 334.746, "test_steps_per_second": 10.461}, {"test_loss": 0.09019513428211212, "test_micro_f1": 0.7014101778050276, "test_micro_f1_no_misc": 0.7513850415512465, "test_runtime": 6.0892, "test_samples_per_second": 336.331, "test_steps_per_second": 10.51}, {"test_loss": 0.08509360253810883, "test_micro_f1": 0.7244712990936556, "test_micro_f1_no_misc": 0.7597161203109158, "test_runtime": 6.0463, "test_samples_per_second": 338.72, "test_steps_per_second": 10.585}, {"test_loss": 0.09908205270767212, "test_micro_f1": 0.674909529553679, "test_micro_f1_no_misc": 0.7233477250083028, "test_runtime": 5.5465, "test_samples_per_second": 369.239, "test_steps_per_second": 11.539}, {"test_loss": 0.0967312902212143, "test_micro_f1": 0.7160940325497288, "test_micro_f1_no_misc": 0.7590999338186633, "test_runtime": 5.7204, "test_samples_per_second": 358.018, "test_steps_per_second": 11.188}]}, "total": {"test_micro_f1": 71.26843893899853, "test_micro_f1_se": 1.1767991218990665, "test_micro_f1_no_misc": 75.56449515171651, "test_micro_f1_no_misc_se": 1.0100090079451385}}, "num_model_parameters": 277459977, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.5935012698173523, "test_mcc": 0.393470665216292, "test_macro_f1": 0.6842429848905335, "test_runtime": 3.2043, "test_samples_per_second": 639.145, "test_steps_per_second": 19.973}, {"test_loss": 0.6339069604873657, "test_mcc": 0.37489212671167166, "test_macro_f1": 0.6872984063364824, "test_runtime": 3.353, "test_samples_per_second": 610.804, "test_steps_per_second": 19.088}, {"test_loss": 0.6906394958496094, "test_mcc": 0.08414117205262742, "test_macro_f1": 0.42447831134014014, "test_runtime": 3.3432, "test_samples_per_second": 612.582, "test_steps_per_second": 19.143}, {"test_loss": 0.6135510802268982, "test_mcc": 0.3530415471417594, "test_macro_f1": 0.6501600316467078, "test_runtime": 3.2684, "test_samples_per_second": 626.609, "test_steps_per_second": 19.582}, {"test_loss": 0.6379077434539795, "test_mcc": 0.341770105490591, "test_macro_f1": 0.6662256734733008, "test_runtime": 3.2636, "test_samples_per_second": 627.527, "test_steps_per_second": 19.61}, {"test_loss": 0.602368175983429, "test_mcc": 0.3892741399209707, "test_macro_f1": 0.6619858837165362, "test_runtime": 3.2555, "test_samples_per_second": 629.082, "test_steps_per_second": 19.659}, {"test_loss": 0.5754674077033997, "test_mcc": 0.4373599886338198, "test_macro_f1": 0.7164820488028112, "test_runtime": 3.2803, "test_samples_per_second": 624.342, "test_steps_per_second": 19.511}, {"test_loss": 0.625075101852417, "test_mcc": 0.40012145031981083, "test_macro_f1": 0.6920897125489078, "test_runtime": 3.3498, "test_samples_per_second": 611.384, "test_steps_per_second": 19.106}, {"test_loss": 0.5968285799026489, "test_mcc": 0.4274722760604989, "test_macro_f1": 0.7020332810731535, "test_runtime": 3.3204, "test_samples_per_second": 616.796, "test_steps_per_second": 19.275}, {"test_loss": 0.5915694236755371, "test_mcc": 0.4605298325841379, "test_macro_f1": 0.7242406241336977, "test_runtime": 3.307, "test_samples_per_second": 619.295, "test_steps_per_second": 19.353}]}, "total": {"test_mcc": 36.6207330413218, "test_mcc_se": 6.551132758455861, "test_macro_f1": 66.0923695796227, "test_macro_f1_se": 5.349679591996588}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.6212149858474731, "test_mcc": 0.3500746827978761, "test_macro_f1": 0.6647978857824983, "test_runtime": 3.7107, "test_samples_per_second": 551.916, "test_steps_per_second": 17.247}, {"test_loss": 0.618144154548645, "test_mcc": 0.37830686904901073, "test_macro_f1": 0.6710534213065594, "test_runtime": 3.8092, "test_samples_per_second": 537.649, "test_steps_per_second": 16.802}, {"test_loss": 0.6206352710723877, "test_mcc": 0.3263283088030912, "test_macro_f1": 0.6375560639146827, "test_runtime": 3.7111, "test_samples_per_second": 551.856, "test_steps_per_second": 17.246}, {"test_loss": 0.6129863262176514, "test_mcc": 0.4004879134738459, "test_macro_f1": 0.6772834711202351, "test_runtime": 3.9099, "test_samples_per_second": 523.8, "test_steps_per_second": 16.369}, {"test_loss": 0.6898900270462036, "test_mcc": 0.11234849105573821, "test_macro_f1": 0.55415725170547, "test_runtime": 3.6584, "test_samples_per_second": 559.812, "test_steps_per_second": 17.494}, {"test_loss": 0.6075165271759033, "test_mcc": 0.3581687871343424, "test_macro_f1": 0.6735184535895786, "test_runtime": 3.694, "test_samples_per_second": 554.408, "test_steps_per_second": 17.325}, {"test_loss": 0.6244789361953735, "test_mcc": 0.32253133934475786, "test_macro_f1": 0.6480762398216372, "test_runtime": 3.5784, "test_samples_per_second": 572.329, "test_steps_per_second": 17.885}, {"test_loss": 0.6211469173431396, "test_mcc": 0.37624107056014844, "test_macro_f1": 0.6695913077267385, "test_runtime": 3.6551, "test_samples_per_second": 560.311, "test_steps_per_second": 17.51}, {"test_loss": 0.692974328994751, "test_mcc": 0.027667540919405615, "test_macro_f1": 0.4591700133868809, "test_runtime": 3.6746, "test_samples_per_second": 557.334, "test_steps_per_second": 17.417}, {"test_loss": 0.6794240474700928, "test_mcc": 0.3141807471576739, "test_macro_f1": 0.6495790335110417, "test_runtime": 3.7431, "test_samples_per_second": 547.135, "test_steps_per_second": 17.098}]}, "total": {"test_mcc": 29.663357502958903, "test_mcc_se": 7.691601866758491, "test_macro_f1": 63.04783141865323, "test_macro_f1_se": 4.348139852402498}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.6128249168395996, "test_mcc": 0.3492897094640106, "test_macro_f1": 0.6066048297498287, "test_runtime": 3.3841, "test_samples_per_second": 605.181, "test_steps_per_second": 18.912}, {"test_loss": 0.6242426633834839, "test_mcc": 0.3864707539628151, "test_macro_f1": 0.6542517271830035, "test_runtime": 3.3096, "test_samples_per_second": 618.813, "test_steps_per_second": 19.338}, {"test_loss": 0.6321656703948975, "test_mcc": 0.3301863609431122, "test_macro_f1": 0.6232391675211466, "test_runtime": 3.3586, "test_samples_per_second": 609.783, "test_steps_per_second": 19.056}, {"test_loss": 0.6191656589508057, "test_mcc": 0.37093296339172316, "test_macro_f1": 0.6542318702469075, "test_runtime": 3.4005, "test_samples_per_second": 602.268, "test_steps_per_second": 18.821}, {"test_loss": 0.6117295026779175, "test_mcc": 0.37595250219320364, "test_macro_f1": 0.6683781619482784, "test_runtime": 3.3735, "test_samples_per_second": 607.083, "test_steps_per_second": 18.971}, {"test_loss": 0.5947043895721436, "test_mcc": 0.42572276722395364, "test_macro_f1": 0.6699369029217241, "test_runtime": 3.2441, "test_samples_per_second": 631.294, "test_steps_per_second": 19.728}, {"test_loss": 0.6232295036315918, "test_mcc": 0.3474502384660468, "test_macro_f1": 0.6450214275307347, "test_runtime": 3.2721, "test_samples_per_second": 625.905, "test_steps_per_second": 19.56}, {"test_loss": 0.6379233002662659, "test_mcc": 0.34309293699175125, "test_macro_f1": 0.6066161104107122, "test_runtime": 3.3166, "test_samples_per_second": 617.502, "test_steps_per_second": 19.297}, {"test_loss": 0.6658449172973633, "test_mcc": 0.3082515217404796, "test_macro_f1": 0.6441803271319062, "test_runtime": 3.2447, "test_samples_per_second": 631.183, "test_steps_per_second": 19.724}, {"test_loss": 0.6364894509315491, "test_mcc": 0.36356073375062314, "test_macro_f1": 0.6665836511020559, "test_runtime": 3.371, "test_samples_per_second": 607.541, "test_steps_per_second": 18.986}]}, "total": {"test_mcc": 36.00910488127719, "test_mcc_se": 2.017055393910094, "test_macro_f1": 64.39044175746298, "test_macro_f1_se": 1.4919448082497953}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_loss": 0.6924108862876892, "test_mcc": 0.0782689764898663, "test_macro_f1": 0.45311088563808155, "test_runtime": 3.5082, "test_samples_per_second": 583.772, "test_steps_per_second": 18.243}, {"test_loss": 0.692559003829956, "test_mcc": 0.0032972841565180894, "test_macro_f1": 0.3996295111566047, "test_runtime": 3.6097, "test_samples_per_second": 567.359, "test_steps_per_second": 17.73}, {"test_loss": 0.6705750226974487, "test_mcc": 0.22052165317565328, "test_macro_f1": 0.601506629027529, "test_runtime": 3.6371, "test_samples_per_second": 563.088, "test_steps_per_second": 17.596}, {"test_loss": 0.67684006690979, "test_mcc": 0.22168910474242565, "test_macro_f1": 0.6084923458483719, "test_runtime": 3.4864, "test_samples_per_second": 587.418, "test_steps_per_second": 18.357}, {"test_loss": 0.6924015283584595, "test_mcc": 0.005958131858366685, "test_macro_f1": 0.4288410838239017, "test_runtime": 3.5327, "test_samples_per_second": 579.732, "test_steps_per_second": 18.117}, {"test_loss": 0.6559826135635376, "test_mcc": 0.31220410680774496, "test_macro_f1": 0.6266216519546155, "test_runtime": 3.6316, "test_samples_per_second": 563.936, "test_steps_per_second": 17.623}, {"test_loss": 0.665972113609314, "test_mcc": 0.27088302307606776, "test_macro_f1": 0.6299803130477346, "test_runtime": 3.5583, "test_samples_per_second": 575.556, "test_steps_per_second": 17.986}, {"test_loss": 0.6923924684524536, "test_mcc": 0.04704790830844001, "test_macro_f1": 0.5067991715767335, "test_runtime": 3.5622, "test_samples_per_second": 574.928, "test_steps_per_second": 17.966}, {"test_loss": 0.6928070783615112, "test_mcc": 0.025984630588431496, "test_macro_f1": 0.5098190394988, "test_runtime": 3.5292, "test_samples_per_second": 580.307, "test_steps_per_second": 18.135}, {"test_loss": 0.6211071610450745, "test_mcc": 0.3129017820393017, "test_macro_f1": 0.6435317873574177, "test_runtime": 3.6167, "test_samples_per_second": 566.262, "test_steps_per_second": 17.696}]}, "total": {"test_mcc": 14.987566012428161, "test_mcc_se": 8.027400512128423, "test_macro_f1": 54.0833241892979, "test_macro_f1_se": 5.710933297176799}}, "num_model_parameters": 278045186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 1.0124610591900312, "test_f1": 5.518970973141168}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.3878975950349108, "test_f1": 4.680648624608308}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 0.1400358654224942, "test_em_se": 0.20446739712760204, "test_f1": 1.0199619597749474, "test_f1_se": 1.3383655429014634}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KBLab/bert-base-swedish-cased-new", "results": {"raw": {"test": [{"test_speed": 1.85}, {"test_speed": 1.92}, {"test_speed": 1.9}, {"test_speed": 1.87}, {"test_speed": 1.89}, {"test_speed": 1.89}, {"test_speed": 1.89}, {"test_speed": 1.84}, {"test_speed": 1.9}, {"test_speed": 1.89}]}, "total": {"test_speed": 1.884, "test_speed_se": 0.014955483572552494}}, "num_model_parameters": 135193344, "max_sequence_length": 512, "vocabulary_size": 64000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/distilbert-base-25lang-cased", "results": {"raw": {"test": [{"test_speed": 3.76}, {"test_speed": 3.65}, {"test_speed": 3.83}, {"test_speed": 3.83}, {"test_speed": 3.78}, {"test_speed": 3.77}, {"test_speed": 3.81}, {"test_speed": 3.7}, {"test_speed": 3.7}, {"test_speed": 3.62}]}, "total": {"test_speed": 3.7449999999999997, "test_speed_se": 0.045942853391771135}}, "num_model_parameters": 108781056, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "DDSC/roberta-base-danish", "results": {"raw": {"test": [{"test_speed": 1.9}, {"test_speed": 1.93}, {"test_speed": 1.88}, {"test_speed": 1.93}, {"test_speed": 1.88}, {"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.89}, {"test_speed": 1.9}, {"test_speed": 1.9}]}, "total": {"test_speed": 1.9009999999999998, "test_speed_se": 0.01071546338501307}}, "num_model_parameters": 124645632, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "AI-Nordics/bert-large-swedish-cased", "results": {"raw": {"test": [{"test_speed": 0.53}, {"test_speed": 0.52}, {"test_speed": 0.54}, {"test_speed": 0.52}, {"test_speed": 0.53}, {"test_speed": 0.52}, {"test_speed": 0.52}, {"test_speed": 0.53}, {"test_speed": 0.53}, {"test_speed": 0.53}]}, "total": {"test_speed": 0.5270000000000001, "test_speed_se": 0.004183374501789465}}, "num_model_parameters": 335215616, "max_sequence_length": 512, "vocabulary_size": 30592}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking", "results": {"raw": {"test": [{"test_speed": 3.68}, {"test_speed": 3.76}, {"test_speed": 3.69}, {"test_speed": 3.72}, {"test_speed": 3.76}, {"test_speed": 3.9}, {"test_speed": 3.89}, {"test_speed": 3.83}, {"test_speed": 3.63}, {"test_speed": 3.72}]}, "total": {"test_speed": 3.758, "test_speed_se": 0.05572898866638239}}, "num_model_parameters": 135324672, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v1", "results": {"raw": {"test": [{"test_speed": 3.78}, {"test_speed": 3.9}, {"test_speed": 3.72}, {"test_speed": 3.77}, {"test_speed": 3.82}, {"test_speed": 3.81}, {"test_speed": 3.51}, {"test_speed": 3.71}, {"test_speed": 3.77}, {"test_speed": 3.85}]}, "total": {"test_speed": 3.7640000000000002, "test_speed_se": 0.0656071595009095}}, "num_model_parameters": 135324672, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Maltehb/aelaectra-danish-electra-small-cased", "results": {"raw": {"test": [{"test_speed": 26.59}, {"test_speed": 26.88}, {"test_speed": 26.56}, {"test_speed": 27.58}, {"test_speed": 27.71}, {"test_speed": 28.26}, {"test_speed": 27.68}, {"test_speed": 28.36}, {"test_speed": 28.06}, {"test_speed": 28.04}]}, "total": {"test_speed": 27.572000000000003, "test_speed_se": 0.4157562012098492}}, "num_model_parameters": 13737984, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/distilbert-base-en-da-cased", "results": {"raw": {"test": [{"test_speed": 3.72}, {"test_speed": 3.76}, {"test_speed": 3.8}, {"test_speed": 3.78}, {"test_speed": 3.83}, {"test_speed": 3.87}, {"test_speed": 3.89}, {"test_speed": 3.79}, {"test_speed": 3.81}, {"test_speed": 3.79}]}, "total": {"test_speed": 3.804, "test_speed_se": 0.03094897305781461}}, "num_model_parameters": 68649984, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "vesteinn/ScandiBERT", "results": {"raw": {"test": [{"test_speed": 1.89}, {"test_speed": 1.95}, {"test_speed": 1.92}, {"test_speed": 1.89}, {"test_speed": 1.86}, {"test_speed": 1.88}, {"test_speed": 1.88}, {"test_speed": 1.88}, {"test_speed": 1.91}, {"test_speed": 1.89}]}, "total": {"test_speed": 1.895, "test_speed_se": 0.01580202518666515}}, "num_model_parameters": 124445952, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/bert-base-da-cased", "results": {"raw": {"test": [{"test_speed": 1.89}, {"test_speed": 1.89}, {"test_speed": 1.87}, {"test_speed": 1.91}, {"test_speed": 1.87}, {"test_speed": 1.85}, {"test_speed": 1.87}, {"test_speed": 1.92}, {"test_speed": 1.91}, {"test_speed": 1.9}]}, "total": {"test_speed": 1.888, "test_speed_se": 0.01395138224932086}}, "num_model_parameters": 103820544, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KBLab/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_speed": 1.88}, {"test_speed": 1.91}, {"test_speed": 1.9}, {"test_speed": 1.87}, {"test_speed": 1.88}, {"test_speed": 1.92}, {"test_speed": 1.87}, {"test_speed": 1.91}, {"test_speed": 1.92}, {"test_speed": 1.92}]}, "total": {"test_speed": 1.8980000000000004, "test_speed_se": 0.013001169178193139}}, "num_model_parameters": 124690944, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "xlm-roberta-large", "results": {"raw": {"test": [{"test_speed": 0.53}, {"test_speed": 0.53}, {"test_speed": 0.52}, {"test_speed": 0.52}, {"test_speed": 0.51}, {"test_speed": 0.52}, {"test_speed": 0.52}, {"test_speed": 0.53}, {"test_speed": 0.52}, {"test_speed": 0.52}]}, "total": {"test_speed": 0.5219999999999999, "test_speed_se": 0.003920000000000003}}, "num_model_parameters": 559890432, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "bert-base-multilingual-cased", "results": {"raw": {"test": [{"test_speed": 1.93}, {"test_speed": 1.95}, {"test_speed": 1.86}, {"test_speed": 1.9}, {"test_speed": 1.91}, {"test_speed": 1.94}, {"test_speed": 1.91}, {"test_speed": 1.92}, {"test_speed": 1.92}, {"test_speed": 1.89}]}, "total": {"test_speed": 1.9130000000000003, "test_speed_se": 0.016016663544918163}}, "num_model_parameters": 177853440, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/distilbert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_speed": 3.75}, {"test_speed": 3.82}, {"test_speed": 3.8}, {"test_speed": 3.83}, {"test_speed": 3.74}, {"test_speed": 3.65}, {"test_speed": 3.74}, {"test_speed": 3.81}, {"test_speed": 3.75}, {"test_speed": 3.75}]}, "total": {"test_speed": 3.7640000000000002, "test_speed_se": 0.0330821576617299}}, "num_model_parameters": 75545856, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "pere/roberta-base-exp-8", "results": {"raw": {"test": [{"test_speed": 1.88}, {"test_speed": 1.86}, {"test_speed": 1.87}, {"test_speed": 1.91}, {"test_speed": 1.84}, {"test_speed": 1.93}, {"test_speed": 1.94}, {"test_speed": 1.96}, {"test_speed": 1.96}, {"test_speed": 1.85}]}, "total": {"test_speed": 1.9000000000000004, "test_speed_se": 0.028327858294540258}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_speed": 1.95}, {"test_speed": 1.96}, {"test_speed": 1.95}, {"test_speed": 1.99}, {"test_speed": 1.98}, {"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.92}, {"test_speed": 1.91}, {"test_speed": 1.94}]}, "total": {"test_speed": 1.948, "test_speed_se": 0.015125760219645908}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "microsoft/infoxlm-base", "results": {"raw": {"test": [{"test_speed": 1.75}, {"test_speed": 1.91}, {"test_speed": 1.81}, {"test_speed": 1.82}, {"test_speed": 1.94}, {"test_speed": 1.83}, {"test_speed": 1.76}, {"test_speed": 1.75}, {"test_speed": 1.76}, {"test_speed": 1.74}]}, "total": {"test_speed": 1.807, "test_speed_se": 0.043538674506440556}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KBLab/megatron-bert-large-swedish-cased-110k", "results": {"raw": {"test": [{"test_speed": 0.52}, {"test_speed": 0.54}, {"test_speed": 0.53}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.53}, {"test_speed": 0.53}, {"test_speed": 0.53}, {"test_speed": 0.54}, {"test_speed": 0.54}]}, "total": {"test_speed": 0.534, "test_speed_se": 0.004333723059397727}}, "num_model_parameters": 369554432, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "jannesg/bertsson", "results": {"raw": {"test": [{"test_speed": 1.86}, {"test_speed": 1.94}, {"test_speed": 1.9}, {"test_speed": 1.93}, {"test_speed": 1.9}, {"test_speed": 1.92}, {"test_speed": 1.94}, {"test_speed": 1.9}, {"test_speed": 1.92}, {"test_speed": 1.92}]}, "total": {"test_speed": 1.9130000000000003, "test_speed_se": 0.014912610621737392}}, "num_model_parameters": 124441344, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/stsb-xlm-r-multilingual", "results": {"raw": {"test": [{"test_speed": 1.85}, {"test_speed": 1.91}, {"test_speed": 1.93}, {"test_speed": 1.93}, {"test_speed": 1.88}, {"test_speed": 1.91}, {"test_speed": 1.86}, {"test_speed": 1.84}, {"test_speed": 1.87}, {"test_speed": 1.89}]}, "total": {"test_speed": 1.887, "test_speed_se": 0.020041472556232502}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_speed": 5.6}, {"test_speed": 5.92}, {"test_speed": 6.08}, {"test_speed": 6.14}, {"test_speed": 5.96}, {"test_speed": 5.92}, {"test_speed": 6.25}, {"test_speed": 6.04}, {"test_speed": 6.17}, {"test_speed": 6.06}]}, "total": {"test_speed": 6.014, "test_speed_se": 0.11222129249339849}}, "num_model_parameters": 24485316, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sarnikowski/convbert-small-da-cased", "results": {"raw": {"test": [{"test_speed": 9.34}, {"test_speed": 9.93}, {"test_speed": 9.87}, {"test_speed": 10.07}, {"test_speed": 10.02}, {"test_speed": 9.9}, {"test_speed": 9.78}, {"test_speed": 10.16}, {"test_speed": 9.88}, {"test_speed": 10.1}]}, "total": {"test_speed": 9.904999999999998, "test_speed_se": 0.14326484255081956}}, "num_model_parameters": 13014104, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "fresh-xlmr-base", "results": {"raw": {"test": [{"test_speed": 0.84}, {"test_speed": 0.86}, {"test_speed": 0.89}, {"test_speed": 0.88}, {"test_speed": 0.86}, {"test_speed": 0.9}, {"test_speed": 0.85}, {"test_speed": 0.85}, {"test_speed": 0.87}, {"test_speed": 0.87}]}, "total": {"test_speed": 0.867, "test_speed_se": 0.011705428939883702}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "setu4993/LaBSE", "results": {"raw": {"test": [{"test_speed": 1.87}, {"test_speed": 1.94}, {"test_speed": 1.95}, {"test_speed": 1.89}, {"test_speed": 1.94}, {"test_speed": 1.92}, {"test_speed": 1.89}, {"test_speed": 1.96}, {"test_speed": 1.92}, {"test_speed": 1.9}]}, "total": {"test_speed": 1.918, "test_speed_se": 0.01843280168009675}}, "num_model_parameters": 470926848, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Maltehb/danish-bert-botxo", "results": {"raw": {"test": [{"test_speed": 1.87}, {"test_speed": 1.91}, {"test_speed": 1.93}, {"test_speed": 1.92}, {"test_speed": 1.87}, {"test_speed": 1.91}, {"test_speed": 1.95}, {"test_speed": 1.92}, {"test_speed": 1.82}, {"test_speed": 1.91}]}, "total": {"test_speed": 1.9010000000000002, "test_speed_se": 0.023273710490594277}}, "num_model_parameters": 110617344, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "3ebdola/Dialectal-Arabic-XLM-R-Base", "results": {"raw": {"test": [{"test_speed": 1.92}, {"test_speed": 1.9}, {"test_speed": 1.93}, {"test_speed": 1.97}, {"test_speed": 1.94}, {"test_speed": 1.92}, {"test_speed": 1.88}, {"test_speed": 1.9}, {"test_speed": 1.89}, {"test_speed": 1.95}]}, "total": {"test_speed": 1.92, "test_speed_se": 0.017530772943598366}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "dbmdz/bert-base-historic-multilingual-cased", "results": {"raw": {"test": [{"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.89}, {"test_speed": 1.89}, {"test_speed": 1.93}, {"test_speed": 1.9}, {"test_speed": 1.94}, {"test_speed": 1.92}]}, "total": {"test_speed": 1.907, "test_speed_se": 0.010554923021983638}}, "num_model_parameters": 110617344, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "dbmdz/bert-medium-historic-multilingual-cased", "results": {"raw": {"test": [{"test_speed": 5.57}, {"test_speed": 5.75}, {"test_speed": 5.79}, {"test_speed": 5.38}, {"test_speed": 6.0}, {"test_speed": 5.88}, {"test_speed": 5.7}, {"test_speed": 5.89}, {"test_speed": 5.84}, {"test_speed": 5.6}]}, "total": {"test_speed": 5.74, "test_speed_se": 0.11353722835362072}}, "num_model_parameters": 42129920, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.23273855702094648, "test_f1": 4.2434274054024534}, {"test_em": 0.0784313725490196, "test_f1": 3.705671909792485}, {"test_em": 0.07763975155279502, "test_f1": 7.600771447084252}]}, "total": {"test_em": 0.03888096811227611, "test_em_se": 0.046762125252852005, "test_f1": 1.5549870762279192, "test_f1_se": 1.6699097624499755}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.9345794392523364, "test_f1": 7.878981284306705}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.9870918754745635, "test_f1": 5.852733905834312}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.6274509803921569, "test_f1": 6.472225974359907}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 0.2549122295119057, "test_em_se": 0.26065309438976386, "test_f1": 2.0203941164500927, "test_f1_se": 2.0390137211483936}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2", "results": {"raw": {"test": [{"test_speed": 1.89}, {"test_speed": 1.94}, {"test_speed": 1.91}, {"test_speed": 1.95}, {"test_speed": 1.91}, {"test_speed": 1.93}, {"test_speed": 1.9}, {"test_speed": 1.91}, {"test_speed": 1.96}, {"test_speed": 1.92}]}, "total": {"test_speed": 1.922, "test_speed_se": 0.013951382249320925}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "dbmdz/bert-tiny-historic-multilingual-cased", "results": {"raw": {"test": [{"test_speed": 113.32}, {"test_speed": 111.27}, {"test_speed": 116.5}, {"test_speed": 118.61}, {"test_speed": 125.45}, {"test_speed": 122.44}, {"test_speed": 115.35}, {"test_speed": 115.09}, {"test_speed": 114.97}, {"test_speed": 119.52}]}, "total": {"test_speed": 117.252, "test_speed_se": 2.6652505718683277}}, "num_model_parameters": 4575104, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Maltehb/aelaectra-danish-electra-small-uncased", "results": {"raw": {"test": [{"test_speed": 27.37}, {"test_speed": 27.62}, {"test_speed": 28.24}, {"test_speed": 28.24}, {"test_speed": 28.18}, {"test_speed": 28.08}, {"test_speed": 27.96}, {"test_speed": 27.76}, {"test_speed": 28.04}, {"test_speed": 28.08}]}, "total": {"test_speed": 27.957, "test_speed_se": 0.17820677178802963}}, "num_model_parameters": 13737984, "max_sequence_length": 128, "vocabulary_size": 32000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/distilbert-base-da-cased", "results": {"raw": {"test": [{"test_speed": 3.81}, {"test_speed": 3.81}, {"test_speed": 3.7}, {"test_speed": 3.8}, {"test_speed": 3.88}, {"test_speed": 3.77}, {"test_speed": 3.82}, {"test_speed": 3.81}, {"test_speed": 3.87}, {"test_speed": 3.85}]}, "total": {"test_speed": 3.8120000000000003, "test_speed_se": 0.03197998262802666}}, "num_model_parameters": 61291776, "max_sequence_length": 512, "vocabulary_size": 23150}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sarnikowski/electra-small-generator-da-256-cased", "results": {"raw": {"test": [{"test_speed": 49.34}, {"test_speed": 48.58}, {"test_speed": 51.75}, {"test_speed": 48.39}, {"test_speed": 49.78}, {"test_speed": 50.65}, {"test_speed": 43.64}, {"test_speed": 52.01}, {"test_speed": 51.13}, {"test_speed": 52.01}]}, "total": {"test_speed": 49.727999999999994, "test_speed_se": 1.5686036726833053}}, "num_model_parameters": 4389632, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KBLab/megatron-bert-base-swedish-cased-125k", "results": {"raw": {"test": [{"test_speed": 1.96}, {"test_speed": 1.95}, {"test_speed": 1.93}, {"test_speed": 1.94}, {"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.93}, {"test_speed": 1.94}, {"test_speed": 1.9}, {"test_speed": 1.93}]}, "total": {"test_speed": 1.9279999999999997, "test_speed_se": 0.013325437662189153}}, "num_model_parameters": 135291648, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "distilbert-base-multilingual-cased", "results": {"raw": {"test": [{"test_speed": 3.83}, {"test_speed": 3.8}, {"test_speed": 3.71}, {"test_speed": 3.88}, {"test_speed": 3.65}, {"test_speed": 3.68}, {"test_speed": 3.87}, {"test_speed": 3.83}, {"test_speed": 3.67}, {"test_speed": 3.83}]}, "total": {"test_speed": 3.775, "test_speed_se": 0.05452496268275253}}, "num_model_parameters": 135324672, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Addedk/mbert-swedish-distilled-cased", "results": {"raw": {"test": [{"test_speed": 3.79}, {"test_speed": 3.8}, {"test_speed": 3.86}, {"test_speed": 3.75}, {"test_speed": 3.81}, {"test_speed": 3.91}, {"test_speed": 3.89}, {"test_speed": 3.79}, {"test_speed": 3.83}, {"test_speed": 3.64}]}, "total": {"test_speed": 3.807, "test_speed_se": 0.047388064132460835}}, "num_model_parameters": 135326208, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Twitter/twhin-bert-base", "results": {"raw": {"test": [{"test_speed": 1.41}, {"test_speed": 1.45}, {"test_speed": 1.46}, {"test_speed": 1.42}, {"test_speed": 1.42}, {"test_speed": 1.43}, {"test_speed": 1.45}, {"test_speed": 1.43}, {"test_speed": 1.45}, {"test_speed": 1.46}]}, "total": {"test_speed": 1.438, "test_speed_se": 0.01124037168226904}}, "num_model_parameters": 278828544, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "microsoft/mdeberta-v3-base", "results": {"raw": {"test": [{"test_speed": 1.2}, {"test_speed": 1.23}, {"test_speed": 1.21}, {"test_speed": 1.22}, {"test_speed": 1.22}, {"test_speed": 1.22}, {"test_speed": 1.2}, {"test_speed": 1.23}, {"test_speed": 1.24}, {"test_speed": 1.23}]}, "total": {"test_speed": 1.22, "test_speed_se": 0.008264085618573372}}, "num_model_parameters": 278809344, "max_sequence_length": 512, "vocabulary_size": 251000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "fresh-electra-small", "results": {"raw": {"test": [{"test_speed": 3.11}, {"test_speed": 3.24}, {"test_speed": 3.05}, {"test_speed": 3.26}, {"test_speed": 3.17}, {"test_speed": 3.11}, {"test_speed": 3.1}, {"test_speed": 3.1}, {"test_speed": 3.02}, {"test_speed": 3.18}]}, "total": {"test_speed": 3.134, "test_speed_se": 0.04802777714799821}}, "num_model_parameters": 13548800, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "pere/roberta-base-exp-32B", "results": {"raw": {"test": [{"test_speed": 1.87}, {"test_speed": 1.86}, {"test_speed": 1.85}, {"test_speed": 1.87}, {"test_speed": 1.89}, {"test_speed": 1.9}, {"test_speed": 1.85}, {"test_speed": 1.87}, {"test_speed": 1.8}, {"test_speed": 1.87}]}, "total": {"test_speed": 1.8630000000000002, "test_speed_se": 0.0167971479060517}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "vesteinn/ScandiBERT-no-faroese", "results": {"raw": {"test": [{"test_speed": 1.89}, {"test_speed": 1.98}, {"test_speed": 1.96}, {"test_speed": 1.91}, {"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.93}, {"test_speed": 1.89}, {"test_speed": 1.94}, {"test_speed": 1.91}]}, "total": {"test_speed": 1.921, "test_speed_se": 0.01903656831819574}}, "num_model_parameters": 124445952, "max_sequence_length": 512, "vocabulary_size": 50005}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_speed": 1.84}, {"test_speed": 1.92}, {"test_speed": 1.78}, {"test_speed": 1.78}, {"test_speed": 1.88}, {"test_speed": 1.89}, {"test_speed": 1.83}, {"test_speed": 1.87}, {"test_speed": 1.9}, {"test_speed": 1.88}]}, "total": {"test_speed": 1.8569999999999998, "test_speed_se": 0.029946622143036027}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "DDSC/roberta-base-scandinavian", "results": {"raw": {"test": [{"test_speed": 1.94}, {"test_speed": 1.88}, {"test_speed": 1.94}, {"test_speed": 1.97}, {"test_speed": 1.92}, {"test_speed": 1.91}, {"test_speed": 1.98}, {"test_speed": 1.93}, {"test_speed": 1.93}, {"test_speed": 1.95}]}, "total": {"test_speed": 1.935, "test_speed_se": 0.017832529576902758}}, "num_model_parameters": 124645632, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "microsoft/xlm-align-base", "results": {"raw": {"test": [{"test_speed": 1.89}, {"test_speed": 1.88}, {"test_speed": 1.85}, {"test_speed": 1.93}, {"test_speed": 1.92}, {"test_speed": 1.84}, {"test_speed": 1.87}, {"test_speed": 1.88}, {"test_speed": 1.9}, {"test_speed": 1.89}]}, "total": {"test_speed": 1.8849999999999998, "test_speed_se": 0.017347199581872922}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/bert-base-25lang-cased", "results": {"raw": {"test": [{"test_speed": 1.91}, {"test_speed": 1.94}, {"test_speed": 1.91}, {"test_speed": 1.93}, {"test_speed": 1.97}, {"test_speed": 1.9}, {"test_speed": 1.88}, {"test_speed": 1.91}, {"test_speed": 1.89}, {"test_speed": 1.93}]}, "total": {"test_speed": 1.9169999999999998, "test_speed_se": 0.01628098277131944}}, "num_model_parameters": 151309824, "max_sequence_length": 512, "vocabulary_size": 84985}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/bert-base-en-da-cased", "results": {"raw": {"test": [{"test_speed": 1.92}, {"test_speed": 1.93}, {"test_speed": 1.95}, {"test_speed": 1.9}, {"test_speed": 1.92}, {"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.94}]}, "total": {"test_speed": 1.9240000000000002, "test_speed_se": 0.01176000000000001}}, "num_model_parameters": 111178752, "max_sequence_length": 512, "vocabulary_size": 32731}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "jjzha/dajobbert-base-cased", "results": {"raw": {"test": [{"test_speed": 1.96}, {"test_speed": 1.94}, {"test_speed": 1.95}, {"test_speed": 1.95}, {"test_speed": 1.9}, {"test_speed": 1.92}, {"test_speed": 1.91}, {"test_speed": 1.94}, {"test_speed": 1.96}, {"test_speed": 1.92}]}, "total": {"test_speed": 1.935, "test_speed_se": 0.013148079707698775}}, "num_model_parameters": 110423808, "max_sequence_length": 512, "vocabulary_size": 31748}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/paraphrase-xlm-r-multilingual-v1", "results": {"raw": {"test": [{"test_speed": 1.93}, {"test_speed": 1.95}, {"test_speed": 1.91}, {"test_speed": 1.91}, {"test_speed": 1.91}, {"test_speed": 1.92}, {"test_speed": 1.95}, {"test_speed": 1.91}, {"test_speed": 1.83}, {"test_speed": 1.88}]}, "total": {"test_speed": 1.9099999999999997, "test_speed_se": 0.0216686152969886}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/quora-distilbert-multilingual", "results": {"raw": {"test": [{"test_speed": 3.76}, {"test_speed": 3.93}, {"test_speed": 3.85}, {"test_speed": 3.84}, {"test_speed": 3.79}, {"test_speed": 3.86}, {"test_speed": 3.75}, {"test_speed": 3.88}, {"test_speed": 3.8}, {"test_speed": 3.8}]}, "total": {"test_speed": 3.8259999999999996, "test_speed_se": 0.03484172211587714}}, "num_model_parameters": 135324672, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "alexanderfalk/danbert-small-cased", "results": {"raw": {"test": [{"test_speed": 3.72}, {"test_speed": 3.85}, {"test_speed": 3.78}, {"test_speed": 3.86}, {"test_speed": 3.81}, {"test_speed": 3.87}, {"test_speed": 3.77}, {"test_speed": 3.83}, {"test_speed": 3.79}, {"test_speed": 3.93}]}, "total": {"test_speed": 3.821, "test_speed_se": 0.03712520317939164}}, "num_model_parameters": 83450880, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "flax-community/nordic-roberta-wiki", "results": {"raw": {"test": [{"test_speed": 1.89}, {"test_speed": 1.98}, {"test_speed": 1.91}, {"test_speed": 1.88}, {"test_speed": 1.89}, {"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.92}, {"test_speed": 1.92}]}, "total": {"test_speed": 1.921, "test_speed_se": 0.01881100859721363}}, "num_model_parameters": 124645632, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "google/canine-c", "results": {"raw": {"test": [{"test_speed": 0.96}, {"test_speed": 0.95}, {"test_speed": 0.97}, {"test_speed": 0.95}, {"test_speed": 0.97}, {"test_speed": 0.95}, {"test_speed": 0.95}, {"test_speed": 0.96}, {"test_speed": 0.95}, {"test_speed": 0.95}]}, "total": {"test_speed": 0.9559999999999998, "test_speed_se": 0.00522666666666667}}, "num_model_parameters": 132082944, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "pere/roberta-base-exp-32", "results": {"raw": {"test": [{"test_speed": 1.93}, {"test_speed": 1.9}, {"test_speed": 1.91}, {"test_speed": 1.97}, {"test_speed": 1.9}, {"test_speed": 1.93}, {"test_speed": 1.97}, {"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.91}]}, "total": {"test_speed": 1.922, "test_speed_se": 0.01723611711880996}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", "results": {"raw": {"test": [{"test_speed": 5.02}, {"test_speed": 4.98}, {"test_speed": 5.03}, {"test_speed": 4.91}, {"test_speed": 4.92}, {"test_speed": 5.04}, {"test_speed": 5.09}, {"test_speed": 4.92}, {"test_speed": 4.94}, {"test_speed": 4.98}]}, "total": {"test_speed": 4.983, "test_speed_se": 0.03776357092342943}}, "num_model_parameters": 117653760, "max_sequence_length": 512, "vocabulary_size": 250037}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "flax-community/swe-roberta-wiki-oscar", "results": {"raw": {"test": [{"test_speed": 1.88}, {"test_speed": 1.89}, {"test_speed": 1.89}, {"test_speed": 1.89}, {"test_speed": 1.92}, {"test_speed": 1.95}, {"test_speed": 1.93}, {"test_speed": 1.95}, {"test_speed": 1.97}, {"test_speed": 1.94}]}, "total": {"test_speed": 1.921, "test_speed_se": 0.01969775621739696}}, "num_model_parameters": 124645632, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KBLab/megatron-bert-large-swedish-cased-165k", "results": {"raw": {"test": [{"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.55}, {"test_speed": 0.54}, {"test_speed": 0.55}, {"test_speed": 0.53}, {"test_speed": 0.53}, {"test_speed": 0.55}, {"test_speed": 0.54}, {"test_speed": 0.54}]}, "total": {"test_speed": 0.541, "test_speed_se": 0.004573333333333337}}, "num_model_parameters": 369554432, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "xlm-roberta-base", "results": {"raw": {"test": [{"test_speed": 1.93}, {"test_speed": 1.97}, {"test_speed": 1.93}, {"test_speed": 1.87}, {"test_speed": 1.9}, {"test_speed": 1.94}, {"test_speed": 1.91}, {"test_speed": 1.93}, {"test_speed": 1.93}, {"test_speed": 1.96}]}, "total": {"test_speed": 1.927, "test_speed_se": 0.01778459258271982}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KBLab/albert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_speed": 1.92}, {"test_speed": 1.95}, {"test_speed": 1.9}, {"test_speed": 1.9}, {"test_speed": 1.91}, {"test_speed": 1.92}, {"test_speed": 1.93}, {"test_speed": 1.88}, {"test_speed": 1.9}, {"test_speed": 1.91}]}, "total": {"test_speed": 1.9119999999999997, "test_speed_se": 0.011975797816151271}}, "num_model_parameters": 14243584, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "jonfd/electra-small-nordic", "results": {"raw": {"test": [{"test_speed": 25.89}, {"test_speed": 27.48}, {"test_speed": 28.18}, {"test_speed": 28.71}, {"test_speed": 27.25}, {"test_speed": 27.27}, {"test_speed": 27.19}, {"test_speed": 26.03}, {"test_speed": 26.97}, {"test_speed": 27.84}]}, "total": {"test_speed": 27.281, "test_speed_se": 0.5390807697058638}}, "num_model_parameters": 21943424, "max_sequence_length": 128, "vocabulary_size": 96105}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Addedk/kbbert-distilled-cased", "results": {"raw": {"test": [{"test_speed": 3.69}, {"test_speed": 3.86}, {"test_speed": 3.71}, {"test_speed": 3.78}, {"test_speed": 3.86}, {"test_speed": 3.73}, {"test_speed": 3.72}, {"test_speed": 3.95}, {"test_speed": 3.85}, {"test_speed": 3.81}]}, "total": {"test_speed": 3.7960000000000003, "test_speed_se": 0.05228299744871389}}, "num_model_parameters": 82163712, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_speed": 1.95}, {"test_speed": 1.94}, {"test_speed": 1.91}, {"test_speed": 1.94}, {"test_speed": 1.95}, {"test_speed": 1.98}, {"test_speed": 1.92}, {"test_speed": 1.96}, {"test_speed": 1.95}, {"test_speed": 1.97}]}, "total": {"test_speed": 1.9469999999999998, "test_speed_se": 0.01308298980440719}}, "num_model_parameters": 124690944, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "birgermoell/roberta-swedish-scandi", "results": {"raw": {"test": [{"test_speed": 1.94}, {"test_speed": 1.93}, {"test_speed": 1.96}, {"test_speed": 1.92}, {"test_speed": 1.92}, {"test_speed": 1.93}, {"test_speed": 1.98}, {"test_speed": 1.94}, {"test_speed": 1.91}, {"test_speed": 1.92}]}, "total": {"test_speed": 1.935, "test_speed_se": 0.013148079707698775}}, "num_model_parameters": 124645632, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/bert-base-en-no-cased", "results": {"raw": {"test": [{"test_speed": 1.94}, {"test_speed": 1.9}, {"test_speed": 1.92}, {"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.92}, {"test_speed": 1.93}, {"test_speed": 1.96}, {"test_speed": 1.9}, {"test_speed": 1.95}]}, "total": {"test_speed": 1.9299999999999997, "test_speed_se": 0.012396128427860057}}, "num_model_parameters": 111439872, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "NbAiLab/nb-bert-base", "results": {"raw": {"test": [{"test_speed": 1.92}, {"test_speed": 1.97}, {"test_speed": 1.95}, {"test_speed": 1.92}, {"test_speed": 1.85}, {"test_speed": 1.87}, {"test_speed": 1.96}, {"test_speed": 1.92}, {"test_speed": 1.9}, {"test_speed": 1.91}]}, "total": {"test_speed": 1.9169999999999998, "test_speed_se": 0.023383492753079722}}, "num_model_parameters": 177853440, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "NbAiLab/nb-bert-large", "results": {"raw": {"test": [{"test_speed": 0.51}, {"test_speed": 0.51}, {"test_speed": 0.5}, {"test_speed": 0.5}, {"test_speed": 0.5}, {"test_speed": 0.51}, {"test_speed": 0.51}, {"test_speed": 0.5}, {"test_speed": 0.5}, {"test_speed": 0.5}]}, "total": {"test_speed": 0.504, "test_speed_se": 0.0032006665972366885}}, "num_model_parameters": 355087360, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "google/canine-s", "results": {"raw": {"test": [{"test_speed": 0.98}, {"test_speed": 0.97}, {"test_speed": 0.97}, {"test_speed": 0.96}, {"test_speed": 0.97}, {"test_speed": 0.98}, {"test_speed": 0.98}, {"test_speed": 0.96}, {"test_speed": 0.97}, {"test_speed": 0.97}]}, "total": {"test_speed": 0.9710000000000001, "test_speed_se": 0.004573333333333337}}, "num_model_parameters": 132082944, "max_sequence_length": 2048, "vocabulary_size": 1114112}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "cardiffnlp/twitter-xlm-roberta-base", "results": {"raw": {"test": [{"test_speed": 1.9}, {"test_speed": 1.89}, {"test_speed": 1.9}, {"test_speed": 1.89}, {"test_speed": 1.94}, {"test_speed": 1.89}, {"test_speed": 1.93}, {"test_speed": 1.91}, {"test_speed": 1.94}, {"test_speed": 1.88}]}, "total": {"test_speed": 1.907, "test_speed_se": 0.013720000000000012}}, "num_model_parameters": 278043648, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/bert-base-en-fr-de-no-da-cased", "results": {"raw": {"test": [{"test_speed": 1.93}, {"test_speed": 1.92}, {"test_speed": 1.95}, {"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.91}, {"test_speed": 1.95}, {"test_speed": 1.9}, {"test_speed": 1.93}]}, "total": {"test_speed": 1.9309999999999998, "test_speed_se": 0.010309426107532214}}, "num_model_parameters": 118074624, "max_sequence_length": 512, "vocabulary_size": 41710}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "xlm-mlm-100-1280", "results": {"raw": {"test": [{"test_speed": 0.56}, {"test_speed": 0.55}, {"test_speed": 0.57}, {"test_speed": 0.56}, {"test_speed": 0.56}, {"test_speed": 0.57}, {"test_speed": 0.57}, {"test_speed": 0.57}, {"test_speed": 0.57}, {"test_speed": 0.57}]}, "total": {"test_speed": 0.5650000000000001, "test_speed_se": 0.004382693235899559}}, "num_model_parameters": 573136640, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "studio-ousia/mluke-large-lite", "results": {"raw": {"test": [{"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.55}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.54}]}, "total": {"test_speed": 0.541, "test_speed_se": 0.0019600000000000017}}, "num_model_parameters": 560685056, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_speed": 1.92}, {"test_speed": 1.91}, {"test_speed": 1.89}, {"test_speed": 1.94}, {"test_speed": 1.92}, {"test_speed": 1.89}, {"test_speed": 1.9}, {"test_speed": 1.84}, {"test_speed": 1.88}, {"test_speed": 1.89}]}, "total": {"test_speed": 1.8980000000000001, "test_speed_se": 0.01698666666666665}}, "num_model_parameters": 470926848, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_speed": 0.51}, {"test_speed": 0.53}, {"test_speed": 0.51}, {"test_speed": 0.52}, {"test_speed": 0.52}, {"test_speed": 0.53}, {"test_speed": 0.52}, {"test_speed": 0.52}, {"test_speed": 0.53}, {"test_speed": 0.53}]}, "total": {"test_speed": 0.522, "test_speed_se": 0.004889098985384622}}, "num_model_parameters": 559890432, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/distiluse-base-multilingual-cased", "results": {"raw": {"test": [{"test_speed": 3.68}, {"test_speed": 3.9}, {"test_speed": 3.87}, {"test_speed": 3.88}, {"test_speed": 3.94}, {"test_speed": 3.91}, {"test_speed": 3.77}, {"test_speed": 3.79}, {"test_speed": 3.86}, {"test_speed": 3.9}]}, "total": {"test_speed": 3.85, "test_speed_se": 0.049325584977102196}}, "num_model_parameters": 135324672, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "xlm-mlm-17-1280", "results": {"raw": {"test": [{"test_speed": 0.56}, {"test_speed": 0.55}, {"test_speed": 0.56}, {"test_speed": 0.57}, {"test_speed": 0.57}, {"test_speed": 0.56}, {"test_speed": 0.56}, {"test_speed": 0.56}, {"test_speed": 0.56}, {"test_speed": 0.56}]}, "total": {"test_speed": 0.5610000000000002, "test_speed_se": 0.0035183076739945217}}, "num_model_parameters": 573136640, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sentence-transformers/distiluse-base-multilingual-cased-v2", "results": {"raw": {"test": [{"test_speed": 3.77}, {"test_speed": 3.8}, {"test_speed": 3.72}, {"test_speed": 3.88}, {"test_speed": 3.65}, {"test_speed": 3.69}, {"test_speed": 3.74}, {"test_speed": 3.85}, {"test_speed": 3.77}, {"test_speed": 3.88}]}, "total": {"test_speed": 3.775000000000001, "test_speed_se": 0.04865030775282354}}, "num_model_parameters": 135324672, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.4381606876850128, "test_mcc": 0.745032855985755, "test_macro_f1": 0.7515604963423028, "test_runtime": 5.9858, "test_samples_per_second": 342.146, "test_steps_per_second": 10.692}, {"test_loss": 0.45493996143341064, "test_mcc": 0.7198971157632336, "test_macro_f1": 0.6840868752795904, "test_runtime": 5.9812, "test_samples_per_second": 342.404, "test_steps_per_second": 10.7}, {"test_loss": 0.478055477142334, "test_mcc": 0.7256256145011345, "test_macro_f1": 0.6148186713727098, "test_runtime": 5.9604, "test_samples_per_second": 343.6, "test_steps_per_second": 10.738}, {"test_loss": 0.4154213070869446, "test_mcc": 0.7345710358417145, "test_macro_f1": 0.7242226264853455, "test_runtime": 5.9904, "test_samples_per_second": 341.878, "test_steps_per_second": 10.684}, {"test_loss": 0.4231399893760681, "test_mcc": 0.7409953785959815, "test_macro_f1": 0.762275584370085, "test_runtime": 6.0026, "test_samples_per_second": 341.186, "test_steps_per_second": 10.662}, {"test_loss": 0.3925119638442993, "test_mcc": 0.7681438488207147, "test_macro_f1": 0.7525979410412736, "test_runtime": 6.0361, "test_samples_per_second": 339.291, "test_steps_per_second": 10.603}, {"test_loss": 0.4244686961174011, "test_mcc": 0.734679189685767, "test_macro_f1": 0.7262236476524587, "test_runtime": 6.038, "test_samples_per_second": 339.183, "test_steps_per_second": 10.599}, {"test_loss": 0.4403730630874634, "test_mcc": 0.7398217057171731, "test_macro_f1": 0.7309518070106981, "test_runtime": 6.0454, "test_samples_per_second": 338.768, "test_steps_per_second": 10.587}, {"test_loss": 0.5260993242263794, "test_mcc": 0.6977358804267766, "test_macro_f1": 0.5832987049862183, "test_runtime": 6.03, "test_samples_per_second": 339.634, "test_steps_per_second": 10.614}, {"test_loss": 0.45739561319351196, "test_mcc": 0.725943394551064, "test_macro_f1": 0.691433269317824, "test_runtime": 5.9965, "test_samples_per_second": 341.532, "test_steps_per_second": 10.673}]}, "total": {"test_mcc": 73.32446019889314, "test_mcc_se": 1.134328907856485, "test_macro_f1": 70.21469623858506, "test_macro_f1_se": 3.7355174900287538}}, "num_model_parameters": 278048259, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.809569239616394, "test_mcc": 0.46885439304875387, "test_macro_f1": 0.6483324025218055, "test_runtime": 4.4256, "test_samples_per_second": 462.764, "test_steps_per_second": 14.461}, {"test_loss": 0.8275814652442932, "test_mcc": 0.46930723314911854, "test_macro_f1": 0.6423304199983838, "test_runtime": 4.3952, "test_samples_per_second": 465.965, "test_steps_per_second": 14.561}, {"test_loss": 0.8558933734893799, "test_mcc": 0.46597297560062106, "test_macro_f1": 0.646355652430071, "test_runtime": 4.3549, "test_samples_per_second": 470.275, "test_steps_per_second": 14.696}, {"test_loss": 0.8648790121078491, "test_mcc": 0.4384266769892158, "test_macro_f1": 0.6216325958628556, "test_runtime": 4.3121, "test_samples_per_second": 474.943, "test_steps_per_second": 14.842}, {"test_loss": 0.8819198608398438, "test_mcc": 0.443251100953901, "test_macro_f1": 0.6314278646523473, "test_runtime": 4.2578, "test_samples_per_second": 480.996, "test_steps_per_second": 15.031}, {"test_loss": 0.8871002197265625, "test_mcc": 0.43156719906928953, "test_macro_f1": 0.6195686644264756, "test_runtime": 4.3727, "test_samples_per_second": 468.359, "test_steps_per_second": 14.636}, {"test_loss": 0.8897831439971924, "test_mcc": 0.48072493944191774, "test_macro_f1": 0.6547670759940811, "test_runtime": 4.317, "test_samples_per_second": 474.399, "test_steps_per_second": 14.825}, {"test_loss": 0.8351919651031494, "test_mcc": 0.48061821694126655, "test_macro_f1": 0.6549820202625196, "test_runtime": 4.3966, "test_samples_per_second": 465.819, "test_steps_per_second": 14.557}, {"test_loss": 0.81526780128479, "test_mcc": 0.4858228686764043, "test_macro_f1": 0.6546874893882282, "test_runtime": 4.308, "test_samples_per_second": 475.395, "test_steps_per_second": 14.856}, {"test_loss": 0.892379879951477, "test_mcc": 0.3958186317744526, "test_macro_f1": 0.5787500032691412, "test_runtime": 4.2554, "test_samples_per_second": 481.274, "test_steps_per_second": 15.04}]}, "total": {"test_mcc": 45.603642356449406, "test_mcc_se": 1.7577778265868724, "test_macro_f1": 63.52834188805909, "test_macro_f1_se": 1.4798954951425893}}, "num_model_parameters": 278048259, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.7550053596496582, "test_mcc": 0.559605405187465, "test_macro_f1": 0.6785689116413108, "test_runtime": 3.6747, "test_samples_per_second": 557.331, "test_steps_per_second": 17.417}, {"test_loss": 0.7223165035247803, "test_mcc": 0.48892451259646114, "test_macro_f1": 0.6117655375115949, "test_runtime": 3.4455, "test_samples_per_second": 594.401, "test_steps_per_second": 18.575}, {"test_loss": 0.7272219657897949, "test_mcc": 0.4906659340738825, "test_macro_f1": 0.5676039029260083, "test_runtime": 3.5452, "test_samples_per_second": 577.677, "test_steps_per_second": 18.052}, {"test_loss": 0.7876966595649719, "test_mcc": 0.5517428489052844, "test_macro_f1": 0.6915133221657008, "test_runtime": 3.5717, "test_samples_per_second": 573.399, "test_steps_per_second": 17.919}, {"test_loss": 0.7348586320877075, "test_mcc": 0.5197207726158877, "test_macro_f1": 0.6368905999645044, "test_runtime": 3.5949, "test_samples_per_second": 569.693, "test_steps_per_second": 17.803}, {"test_loss": 0.7297541499137878, "test_mcc": 0.5390437853051067, "test_macro_f1": 0.6749549354282917, "test_runtime": 3.6899, "test_samples_per_second": 555.033, "test_steps_per_second": 17.345}, {"test_loss": 0.7389017343521118, "test_mcc": 0.5667349858577886, "test_macro_f1": 0.6855482891474605, "test_runtime": 3.5293, "test_samples_per_second": 580.286, "test_steps_per_second": 18.134}, {"test_loss": 0.7362168431282043, "test_mcc": 0.46495889306556315, "test_macro_f1": 0.5495800219192228, "test_runtime": 3.5859, "test_samples_per_second": 571.125, "test_steps_per_second": 17.848}, {"test_loss": 0.7512382864952087, "test_mcc": 0.5353319270226069, "test_macro_f1": 0.6733858599616406, "test_runtime": 3.7097, "test_samples_per_second": 552.073, "test_steps_per_second": 17.252}, {"test_loss": 0.740546703338623, "test_mcc": 0.5741848994891181, "test_macro_f1": 0.6939321534431899, "test_runtime": 3.6873, "test_samples_per_second": 555.416, "test_steps_per_second": 17.357}]}, "total": {"test_mcc": 52.90913964119165, "test_mcc_se": 2.293500814385561, "test_macro_f1": 64.63743534108924, "test_macro_f1_se": 3.2848094632097764}}, "num_model_parameters": 278048259, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.06350045651197433, "test_micro_f1": 0.6723876829883897, "test_micro_f1_no_misc": 0.7406555491661875, "test_runtime": 7.1777, "test_samples_per_second": 285.327, "test_steps_per_second": 8.916}, {"test_loss": 0.059675462543964386, "test_micro_f1": 0.7019527235354573, "test_micro_f1_no_misc": 0.7547386559448591, "test_runtime": 7.0223, "test_samples_per_second": 291.644, "test_steps_per_second": 9.114}, {"test_loss": 0.056319959461688995, "test_micro_f1": 0.7416383906931654, "test_micro_f1_no_misc": 0.7911494873178628, "test_runtime": 6.6221, "test_samples_per_second": 309.267, "test_steps_per_second": 9.665}, {"test_loss": 0.052982769906520844, "test_micro_f1": 0.7296385542168675, "test_micro_f1_no_misc": 0.7773584905660377, "test_runtime": 7.1031, "test_samples_per_second": 288.325, "test_steps_per_second": 9.01}, {"test_loss": 0.06646710634231567, "test_micro_f1": 0.6957328385899815, "test_micro_f1_no_misc": 0.7466666666666666, "test_runtime": 7.0693, "test_samples_per_second": 289.705, "test_steps_per_second": 9.053}, {"test_loss": 0.05278386175632477, "test_micro_f1": 0.7266760431317393, "test_micro_f1_no_misc": 0.7946577629382304, "test_runtime": 5.955, "test_samples_per_second": 343.915, "test_steps_per_second": 10.747}, {"test_loss": 0.06145066022872925, "test_micro_f1": 0.7061657032755299, "test_micro_f1_no_misc": 0.7683060109289618, "test_runtime": 5.9446, "test_samples_per_second": 344.514, "test_steps_per_second": 10.766}, {"test_loss": 0.05430903285741806, "test_micro_f1": 0.6983122362869199, "test_micro_f1_no_misc": 0.7447947650208209, "test_runtime": 6.9617, "test_samples_per_second": 294.181, "test_steps_per_second": 9.193}, {"test_loss": 0.056092049926519394, "test_micro_f1": 0.6971109040074558, "test_micro_f1_no_misc": 0.7390396659707724, "test_runtime": 6.5906, "test_samples_per_second": 310.747, "test_steps_per_second": 9.711}, {"test_loss": 0.06005328893661499, "test_micro_f1": 0.7218190614417029, "test_micro_f1_no_misc": 0.7739176910742916, "test_runtime": 7.1176, "test_samples_per_second": 287.737, "test_steps_per_second": 8.992}]}, "total": {"test_micro_f1": 70.9143413816721, "test_micro_f1_se": 1.2731680179261038, "test_micro_f1_no_misc": 76.31284745594692, "test_micro_f1_no_misc_se": 1.2882084603082817}}, "num_model_parameters": 277462281, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.05912761017680168, "test_micro_f1": 0.8171266443126127, "test_micro_f1_no_misc": 0.8277528477735588, "test_runtime": 7.2817, "test_samples_per_second": 281.252, "test_steps_per_second": 8.789}, {"test_loss": 0.05532623454928398, "test_micro_f1": 0.803561491374513, "test_micro_f1_no_misc": 0.8237004725554343, "test_runtime": 6.6588, "test_samples_per_second": 307.561, "test_steps_per_second": 9.611}, {"test_loss": 0.0628117099404335, "test_micro_f1": 0.7719937532535139, "test_micro_f1_no_misc": 0.804717308359348, "test_runtime": 7.1396, "test_samples_per_second": 286.849, "test_steps_per_second": 8.964}, {"test_loss": 0.0642964094877243, "test_micro_f1": 0.8048217491664529, "test_micro_f1_no_misc": 0.8318830490776192, "test_runtime": 6.851, "test_samples_per_second": 298.935, "test_steps_per_second": 9.342}, {"test_loss": 0.06337445229291916, "test_micro_f1": 0.7899581589958159, "test_micro_f1_no_misc": 0.8186646433990895, "test_runtime": 7.1106, "test_samples_per_second": 288.021, "test_steps_per_second": 9.001}, {"test_loss": 0.0658947229385376, "test_micro_f1": 0.8135217511776116, "test_micro_f1_no_misc": 0.8313931656027037, "test_runtime": 7.0336, "test_samples_per_second": 291.175, "test_steps_per_second": 9.099}, {"test_loss": 0.06203316152095795, "test_micro_f1": 0.7623940405856666, "test_micro_f1_no_misc": 0.7839127471029311, "test_runtime": 7.2417, "test_samples_per_second": 282.808, "test_steps_per_second": 8.838}, {"test_loss": 0.05481027066707611, "test_micro_f1": 0.8035003977724741, "test_micro_f1_no_misc": 0.8382406397673573, "test_runtime": 7.069, "test_samples_per_second": 289.714, "test_steps_per_second": 9.054}, {"test_loss": 0.06666207313537598, "test_micro_f1": 0.809447128287708, "test_micro_f1_no_misc": 0.8223276176577891, "test_runtime": 6.7842, "test_samples_per_second": 301.88, "test_steps_per_second": 9.434}, {"test_loss": 0.060714878141880035, "test_micro_f1": 0.8196015078082929, "test_micro_f1_no_misc": 0.8359712230215829, "test_runtime": 7.0275, "test_samples_per_second": 291.429, "test_steps_per_second": 9.107}]}, "total": {"test_micro_f1": 79.95926622734662, "test_micro_f1_se": 1.1860385745538038, "test_micro_f1_no_misc": 82.18563714317413, "test_micro_f1_no_misc_se": 1.0207907236580047}}, "num_model_parameters": 277462281, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.03641350939869881, "test_micro_f1": 0.8820101966496722, "test_micro_f1_no_misc": 0.9129896907216495, "test_runtime": 6.3586, "test_samples_per_second": 322.082, "test_steps_per_second": 10.065}, {"test_loss": 0.04092557728290558, "test_micro_f1": 0.8390386016023307, "test_micro_f1_no_misc": 0.8782643631980716, "test_runtime": 6.2788, "test_samples_per_second": 326.179, "test_steps_per_second": 10.193}, {"test_loss": 0.04165628179907799, "test_micro_f1": 0.8708201337557199, "test_micro_f1_no_misc": 0.9024960998439937, "test_runtime": 5.9031, "test_samples_per_second": 346.936, "test_steps_per_second": 10.842}, {"test_loss": 0.03755088895559311, "test_micro_f1": 0.8265835929387332, "test_micro_f1_no_misc": 0.8648648648648648, "test_runtime": 5.8657, "test_samples_per_second": 349.15, "test_steps_per_second": 10.911}, {"test_loss": 0.031883880496025085, "test_micro_f1": 0.8985990660440293, "test_micro_f1_no_misc": 0.9211309523809524, "test_runtime": 6.3562, "test_samples_per_second": 322.203, "test_steps_per_second": 10.069}, {"test_loss": 0.031024938449263573, "test_micro_f1": 0.8842608398770911, "test_micro_f1_no_misc": 0.903103709311128, "test_runtime": 6.3819, "test_samples_per_second": 320.909, "test_steps_per_second": 10.028}, {"test_loss": 0.036307767033576965, "test_micro_f1": 0.8802456499488229, "test_micro_f1_no_misc": 0.9020501138952164, "test_runtime": 5.853, "test_samples_per_second": 349.905, "test_steps_per_second": 10.935}, {"test_loss": 0.035204797983169556, "test_micro_f1": 0.8726772195457674, "test_micro_f1_no_misc": 0.8964474678760394, "test_runtime": 5.7963, "test_samples_per_second": 353.33, "test_steps_per_second": 11.042}, {"test_loss": 0.037090130150318146, "test_micro_f1": 0.8315640481245576, "test_micro_f1_no_misc": 0.8650380456547858, "test_runtime": 5.8395, "test_samples_per_second": 350.713, "test_steps_per_second": 10.96}, {"test_loss": 0.04049917310476303, "test_micro_f1": 0.8759822343696618, "test_micro_f1_no_misc": 0.899394856278366, "test_runtime": 6.3182, "test_samples_per_second": 324.145, "test_steps_per_second": 10.13}]}, "total": {"test_micro_f1": 86.61781582856388, "test_micro_f1_se": 1.5306658590328732, "test_micro_f1_no_misc": 89.45780164025068, "test_micro_f1_no_misc_se": 1.1838820419673592}}, "num_model_parameters": 277462281, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.052351366728544235, "test_micro_f1": 0.752785305630834, "test_micro_f1_no_misc": 0.793361535958347, "test_runtime": 5.9026, "test_samples_per_second": 346.966, "test_steps_per_second": 10.843}, {"test_loss": 0.06120392680168152, "test_micro_f1": 0.7396622015142692, "test_micro_f1_no_misc": 0.780952380952381, "test_runtime": 6.0035, "test_samples_per_second": 341.134, "test_steps_per_second": 10.66}, {"test_loss": 0.06001483276486397, "test_micro_f1": 0.749477455957002, "test_micro_f1_no_misc": 0.7881548974943052, "test_runtime": 5.8766, "test_samples_per_second": 348.499, "test_steps_per_second": 10.891}, {"test_loss": 0.06564906239509583, "test_micro_f1": 0.747924080664294, "test_micro_f1_no_misc": 0.8018047051240734, "test_runtime": 6.1194, "test_samples_per_second": 334.672, "test_steps_per_second": 10.459}, {"test_loss": 0.0699157565832138, "test_micro_f1": 0.7300203429235688, "test_micro_f1_no_misc": 0.7763328998699609, "test_runtime": 5.931, "test_samples_per_second": 345.302, "test_steps_per_second": 10.791}, {"test_loss": 0.05495648458600044, "test_micro_f1": 0.7813789039481437, "test_micro_f1_no_misc": 0.8212654924983692, "test_runtime": 6.0418, "test_samples_per_second": 338.973, "test_steps_per_second": 10.593}, {"test_loss": 0.04918023198843002, "test_micro_f1": 0.7874692874692876, "test_micro_f1_no_misc": 0.8265582655826559, "test_runtime": 6.0853, "test_samples_per_second": 336.548, "test_steps_per_second": 10.517}, {"test_loss": 0.058601632714271545, "test_micro_f1": 0.7547612071491356, "test_micro_f1_no_misc": 0.790891597177678, "test_runtime": 6.0255, "test_samples_per_second": 339.891, "test_steps_per_second": 10.622}, {"test_loss": 0.059587523341178894, "test_micro_f1": 0.7754728492983526, "test_micro_f1_no_misc": 0.80339558573854, "test_runtime": 5.5815, "test_samples_per_second": 366.923, "test_steps_per_second": 11.466}, {"test_loss": 0.06178359314799309, "test_micro_f1": 0.7452718676122931, "test_micro_f1_no_misc": 0.787993680884676, "test_runtime": 5.7373, "test_samples_per_second": 356.963, "test_steps_per_second": 11.155}]}, "total": {"test_micro_f1": 75.6422350216718, "test_micro_f1_se": 1.1665988621378647, "test_micro_f1_no_misc": 79.70711041280987, "test_micro_f1_no_misc_se": 1.0165579199271988}}, "num_model_parameters": 277462281, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.6922330856323242, "test_mcc": 0.08420735227449644, "test_macro_f1": 0.5421004418463868, "test_runtime": 3.1956, "test_samples_per_second": 640.887, "test_steps_per_second": 20.028}, {"test_loss": 0.6716400384902954, "test_mcc": 0.2492936798590588, "test_macro_f1": 0.5361502428049446, "test_runtime": 3.3511, "test_samples_per_second": 611.139, "test_steps_per_second": 19.098}, {"test_loss": 0.6878753304481506, "test_mcc": 0.12604489266457158, "test_macro_f1": 0.5606453803683163, "test_runtime": 3.3392, "test_samples_per_second": 613.322, "test_steps_per_second": 19.166}, {"test_loss": 0.5410965085029602, "test_mcc": 0.5336159596130707, "test_macro_f1": 0.7310740375520719, "test_runtime": 3.2259, "test_samples_per_second": 634.867, "test_steps_per_second": 19.84}, {"test_loss": 0.6907668709754944, "test_mcc": 0.0870685938720234, "test_macro_f1": 0.5351979173619918, "test_runtime": 3.2986, "test_samples_per_second": 620.876, "test_steps_per_second": 19.402}, {"test_loss": 0.5490175485610962, "test_mcc": 0.5012865062058208, "test_macro_f1": 0.7072032583446715, "test_runtime": 3.2365, "test_samples_per_second": 632.781, "test_steps_per_second": 19.774}, {"test_loss": 0.567420244216919, "test_mcc": 0.49180971668626683, "test_macro_f1": 0.7020831508701355, "test_runtime": 3.2876, "test_samples_per_second": 622.944, "test_steps_per_second": 19.467}, {"test_loss": 0.6418148279190063, "test_mcc": 0.33112412922469897, "test_macro_f1": 0.5636202190551576, "test_runtime": 3.3266, "test_samples_per_second": 615.647, "test_steps_per_second": 19.239}, {"test_loss": 0.6280114054679871, "test_mcc": 0.3640617687965372, "test_macro_f1": 0.677999674059673, "test_runtime": 3.2915, "test_samples_per_second": 622.203, "test_steps_per_second": 19.444}, {"test_loss": 0.6047378778457642, "test_mcc": 0.46095811601980563, "test_macro_f1": 0.6653662796726638, "test_runtime": 3.2855, "test_samples_per_second": 623.346, "test_steps_per_second": 19.48}]}, "total": {"test_mcc": 32.294707152163504, "test_mcc_se": 10.977863751596137, "test_macro_f1": 62.21440601936011, "test_macro_f1_se": 5.020378961951807}}, "num_model_parameters": 278047490, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.6831721067428589, "test_mcc": 0.20447208355118224, "test_macro_f1": 0.473506745396432, "test_runtime": 3.6731, "test_samples_per_second": 557.568, "test_steps_per_second": 17.424}, {"test_loss": 0.6929775476455688, "test_mcc": 0.0710966714563184, "test_macro_f1": 0.37753234174012856, "test_runtime": 3.7808, "test_samples_per_second": 541.681, "test_steps_per_second": 16.928}, {"test_loss": 0.615266740322113, "test_mcc": 0.42642360570228366, "test_macro_f1": 0.6716788822134467, "test_runtime": 3.7301, "test_samples_per_second": 549.05, "test_steps_per_second": 17.158}, {"test_loss": 0.5816078782081604, "test_mcc": 0.4704649872538835, "test_macro_f1": 0.6856912268753059, "test_runtime": 3.8389, "test_samples_per_second": 533.49, "test_steps_per_second": 16.672}, {"test_loss": 0.5938942432403564, "test_mcc": 0.4416993892314187, "test_macro_f1": 0.6400778516307398, "test_runtime": 3.7052, "test_samples_per_second": 552.734, "test_steps_per_second": 17.273}, {"test_loss": 0.6483554840087891, "test_mcc": 0.36666639249829774, "test_macro_f1": 0.5804887961011678, "test_runtime": 3.6517, "test_samples_per_second": 560.838, "test_steps_per_second": 17.526}, {"test_loss": 0.6933227181434631, "test_mcc": 0.007442250007038869, "test_macro_f1": 0.5033837504157711, "test_runtime": 3.5433, "test_samples_per_second": 577.999, "test_steps_per_second": 18.062}, {"test_loss": 0.6617367267608643, "test_mcc": 0.2998581444795981, "test_macro_f1": 0.5365801330186655, "test_runtime": 3.664, "test_samples_per_second": 558.96, "test_steps_per_second": 17.467}, {"test_loss": 0.5556116104125977, "test_mcc": 0.5087992168534788, "test_macro_f1": 0.7112978028499806, "test_runtime": 3.6561, "test_samples_per_second": 560.165, "test_steps_per_second": 17.505}, {"test_loss": 0.6924866437911987, "test_mcc": 0.02882701941035839, "test_macro_f1": 0.3474239127565623, "test_runtime": 3.7225, "test_samples_per_second": 550.174, "test_steps_per_second": 17.193}]}, "total": {"test_mcc": 28.257497604438587, "test_mcc_se": 11.882269487590106, "test_macro_f1": 55.276614429982, "test_macro_f1_se": 7.926321772725248}}, "num_model_parameters": 278047490, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.6820859909057617, "test_mcc": 0.19412826400108285, "test_macro_f1": 0.45158300203926094, "test_runtime": 3.3191, "test_samples_per_second": 617.042, "test_steps_per_second": 19.283}, {"test_loss": 0.5968644022941589, "test_mcc": 0.47525519311448033, "test_macro_f1": 0.6701443627031035, "test_runtime": 3.29, "test_samples_per_second": 622.488, "test_steps_per_second": 19.453}, {"test_loss": 0.692946195602417, "test_mcc": 0.01268760928068199, "test_macro_f1": 0.37909335265779065, "test_runtime": 3.3503, "test_samples_per_second": 611.28, "test_steps_per_second": 19.102}, {"test_loss": 0.6938108801841736, "test_mcc": 0.0027505932220309396, "test_macro_f1": 0.38402320886763536, "test_runtime": 3.3916, "test_samples_per_second": 603.848, "test_steps_per_second": 18.87}, {"test_loss": 0.6898555755615234, "test_mcc": 0.09138698954367495, "test_macro_f1": 0.3794257229676671, "test_runtime": 3.3482, "test_samples_per_second": 611.667, "test_steps_per_second": 19.115}, {"test_loss": 0.5668048858642578, "test_mcc": 0.5083916131720891, "test_macro_f1": 0.7098151934093071, "test_runtime": 3.1958, "test_samples_per_second": 640.839, "test_steps_per_second": 20.026}, {"test_loss": 0.65980064868927, "test_mcc": 0.3198718365595281, "test_macro_f1": 0.531718203197258, "test_runtime": 3.2557, "test_samples_per_second": 629.057, "test_steps_per_second": 19.658}, {"test_loss": 0.681431233882904, "test_mcc": 0.24791796002882677, "test_macro_f1": 0.5136269610496415, "test_runtime": 3.3107, "test_samples_per_second": 618.596, "test_steps_per_second": 19.331}, {"test_loss": 0.5922461152076721, "test_mcc": 0.49546875324938716, "test_macro_f1": 0.70057106760605, "test_runtime": 3.2584, "test_samples_per_second": 628.534, "test_steps_per_second": 19.642}, {"test_loss": 0.6102288961410522, "test_mcc": 0.4068948301863355, "test_macro_f1": 0.6078327301331278, "test_runtime": 3.3709, "test_samples_per_second": 607.56, "test_steps_per_second": 18.986}]}, "total": {"test_mcc": 27.547536423581175, "test_mcc_se": 12.161527008884075, "test_macro_f1": 53.27833804630841, "test_macro_f1_se": 8.269863395859987}}, "num_model_parameters": 278047490, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_loss": 0.686516523361206, "test_mcc": 0.21967547260849202, "test_macro_f1": 0.6007081504907968, "test_runtime": 3.524, "test_samples_per_second": 581.15, "test_steps_per_second": 18.161}, {"test_loss": 0.6915633678436279, "test_mcc": 0.1342506909664107, "test_macro_f1": 0.4740678441267172, "test_runtime": 3.5818, "test_samples_per_second": 571.785, "test_steps_per_second": 17.868}, {"test_loss": 0.6840640306472778, "test_mcc": 0.2018169756292448, "test_macro_f1": 0.541720218323847, "test_runtime": 3.6336, "test_samples_per_second": 563.629, "test_steps_per_second": 17.613}, {"test_loss": 0.6911789178848267, "test_mcc": 0.02481781537648967, "test_macro_f1": 0.4160880374124233, "test_runtime": 3.4277, "test_samples_per_second": 597.479, "test_steps_per_second": 18.671}, {"test_loss": 0.6903066635131836, "test_mcc": 0.1048043198368094, "test_macro_f1": 0.5038737457543794, "test_runtime": 3.5607, "test_samples_per_second": 575.174, "test_steps_per_second": 17.974}, {"test_loss": 0.6925101280212402, "test_mcc": -0.011752030633035064, "test_macro_f1": 0.40717547292889755, "test_runtime": 3.6078, "test_samples_per_second": 567.662, "test_steps_per_second": 17.739}, {"test_loss": 0.656017541885376, "test_mcc": 0.3777285540756813, "test_macro_f1": 0.6246689399350394, "test_runtime": 3.509, "test_samples_per_second": 583.648, "test_steps_per_second": 18.239}, {"test_loss": 0.6910794973373413, "test_mcc": 0.08489953032848056, "test_macro_f1": 0.5039508782525542, "test_runtime": 3.4963, "test_samples_per_second": 585.77, "test_steps_per_second": 18.305}, {"test_loss": 0.6058750152587891, "test_mcc": 0.39340189195671704, "test_macro_f1": 0.6311901504787962, "test_runtime": 3.4952, "test_samples_per_second": 585.946, "test_steps_per_second": 18.311}, {"test_loss": 0.6934279799461365, "test_mcc": -0.009391307938616587, "test_macro_f1": 0.4873554902840276, "test_runtime": 3.6101, "test_samples_per_second": 567.304, "test_steps_per_second": 17.728}]}, "total": {"test_mcc": 15.202519122066738, "test_mcc_se": 9.061619835400322, "test_macro_f1": 51.907989279874776, "test_macro_f1_se": 4.954837583027336}}, "num_model_parameters": 278047490, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 5.0693802111354955}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.07593014426727411, "test_f1": 0.9549095767950893}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 0.007593014426727411, "test_em_se": 0.014882308276385725, "test_f1": 0.6024289787930585, "test_f1_se": 0.9904253482064547}}, "num_model_parameters": 277457666, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_em": 0.0, "test_f1": 0.06454944487477407}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.01112594570538496}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.15186028853454822, "test_f1": 3.6676347311445348}, {"test_em": 0.0, "test_f1": 0.019394879751745538}, {"test_em": 0.23529411764705882, "test_f1": 2.5743140536486155}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 0.0387154406181607, "test_em_se": 0.052035863441516846, "test_f1": 0.6337019055125055, "test_f1_se": 0.828150522807119}}, "num_model_parameters": 277457666, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_em": 0.07745933384972889, "test_f1": 3.2172697000762085}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.22779043280182232, "test_f1": 4.811866101837637}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}, {"test_em": 0.0, "test_f1": 0.0}]}, "total": {"test_em": 0.030524976665155124, "test_em_se": 0.045532546816328345, "test_f1": 0.8029135801913846, "test_f1_se": 1.0746921771620355}}, "num_model_parameters": 277457666, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "clips/mfaq", "results": {"raw": {"test": [{"test_speed": 7.76}, {"test_speed": 8.14}, {"test_speed": 8.1}, {"test_speed": 8.18}, {"test_speed": 8.33}, {"test_speed": 8.47}, {"test_speed": 8.25}, {"test_speed": 8.34}, {"test_speed": 8.04}, {"test_speed": 8.49}]}, "total": {"test_speed": 8.209999999999997, "test_speed_se": 0.13519422735868253}}, "num_model_parameters": 278045952, "max_sequence_length": 128, "vocabulary_size": 250005}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "google/rembert", "results": {"raw": {"test": [{"test_speed": 0.78}, {"test_speed": 0.8}, {"test_speed": 0.79}, {"test_speed": 0.79}, {"test_speed": 0.81}, {"test_speed": 0.79}, {"test_speed": 0.79}, {"test_speed": 0.79}, {"test_speed": 0.8}, {"test_speed": 0.81}]}, "total": {"test_speed": 0.7949999999999999, "test_speed_se": 0.006023435712098024}}, "num_model_parameters": 575920384, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "studio-ousia/mluke-base-lite", "results": {"raw": {"test": [{"test_loss": 0.4430450201034546, "test_mcc": 0.6991636963133951, "test_macro_f1": 0.6110187916766973, "test_runtime": 17.7152, "test_samples_per_second": 115.607, "test_steps_per_second": 57.804}, {"test_loss": 0.4685264825820923, "test_mcc": 0.6637150917576538, "test_macro_f1": 0.6176688001337084, "test_runtime": 17.3879, "test_samples_per_second": 117.783, "test_steps_per_second": 58.891}, {"test_loss": 0.4862357974052429, "test_mcc": 0.6829400019081084, "test_macro_f1": 0.5999647994058134, "test_runtime": 17.7564, "test_samples_per_second": 115.339, "test_steps_per_second": 57.669}, {"test_loss": 0.4401801526546478, "test_mcc": 0.7116000443160183, "test_macro_f1": 0.7373443542876927, "test_runtime": 17.6082, "test_samples_per_second": 116.309, "test_steps_per_second": 58.155}, {"test_loss": 0.3998374342918396, "test_mcc": 0.7387894235810125, "test_macro_f1": 0.6876952849392506, "test_runtime": 17.645, "test_samples_per_second": 116.067, "test_steps_per_second": 58.033}, {"test_loss": 0.42871713638305664, "test_mcc": 0.6931642333368271, "test_macro_f1": 0.6582011533585642, "test_runtime": 18.1081, "test_samples_per_second": 113.099, "test_steps_per_second": 56.549}, {"test_loss": 0.416065514087677, "test_mcc": 0.7517632548943143, "test_macro_f1": 0.7359917768350696, "test_runtime": 17.7136, "test_samples_per_second": 115.618, "test_steps_per_second": 57.809}, {"test_loss": 0.43881312012672424, "test_mcc": 0.7089150797530869, "test_macro_f1": 0.6712928293035275, "test_runtime": 17.8778, "test_samples_per_second": 114.556, "test_steps_per_second": 57.278}, {"test_loss": 0.48159533739089966, "test_mcc": 0.7186433648154037, "test_macro_f1": 0.6923807186965081, "test_runtime": 17.8373, "test_samples_per_second": 114.816, "test_steps_per_second": 57.408}, {"test_loss": 0.46923375129699707, "test_mcc": 0.7037336475082143, "test_macro_f1": 0.7262769761747699, "test_runtime": 17.8574, "test_samples_per_second": 114.686, "test_steps_per_second": 57.343}]}, "total": {"test_mcc": 70.72427838184035, "test_mcc_se": 1.5856084805761586, "test_macro_f1": 67.378354848116, "test_macro_f1_se": 3.200085952027745}}, "num_model_parameters": 278642179, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "studio-ousia/mluke-base-lite", "results": {"raw": {"test": [{"test_loss": 0.8782159090042114, "test_mcc": 0.4184919918546524, "test_macro_f1": 0.6159320101518094, "test_runtime": 4.3964, "test_samples_per_second": 465.834, "test_steps_per_second": 14.557}, {"test_loss": 0.9026755690574646, "test_mcc": 0.40729077874103736, "test_macro_f1": 0.6060678980612105, "test_runtime": 4.3832, "test_samples_per_second": 467.237, "test_steps_per_second": 14.601}, {"test_loss": 0.8954839706420898, "test_mcc": 0.3927543685186522, "test_macro_f1": 0.5980661155075594, "test_runtime": 4.3839, "test_samples_per_second": 467.166, "test_steps_per_second": 14.599}, {"test_loss": 0.8677986860275269, "test_mcc": 0.42897734168751983, "test_macro_f1": 0.6187561178151596, "test_runtime": 4.3493, "test_samples_per_second": 470.88, "test_steps_per_second": 14.715}, {"test_loss": 0.8763742446899414, "test_mcc": 0.3811086226083699, "test_macro_f1": 0.5836467242818051, "test_runtime": 4.305, "test_samples_per_second": 475.727, "test_steps_per_second": 14.866}, {"test_loss": 0.9122453927993774, "test_mcc": 0.42152451394450713, "test_macro_f1": 0.6140439961934745, "test_runtime": 4.3906, "test_samples_per_second": 466.453, "test_steps_per_second": 14.577}, {"test_loss": 0.8468042612075806, "test_mcc": 0.41763103866284484, "test_macro_f1": 0.616063420708183, "test_runtime": 4.3702, "test_samples_per_second": 468.632, "test_steps_per_second": 14.645}, {"test_loss": 0.9059122800827026, "test_mcc": 0.3728173015454851, "test_macro_f1": 0.5786052989798204, "test_runtime": 4.3764, "test_samples_per_second": 467.963, "test_steps_per_second": 14.624}, {"test_loss": 0.8813399076461792, "test_mcc": 0.40227343290408835, "test_macro_f1": 0.6004499398702325, "test_runtime": 4.3536, "test_samples_per_second": 470.42, "test_steps_per_second": 14.701}, {"test_loss": 0.8876291513442993, "test_mcc": 0.39685855059454994, "test_macro_f1": 0.6002959160897584, "test_runtime": 4.2878, "test_samples_per_second": 477.636, "test_steps_per_second": 14.926}]}, "total": {"test_mcc": 40.397279410617074, "test_mcc_se": 1.1343271200412464, "test_macro_f1": 60.31927437659014, "test_macro_f1_se": 0.8580742448068921}}, "num_model_parameters": 278642179, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "studio-ousia/mluke-base-lite", "results": {"raw": {"test": [{"test_loss": 0.8657321929931641, "test_mcc": 0.42544436856732437, "test_macro_f1": 0.48912501553350346, "test_runtime": 3.6909, "test_samples_per_second": 554.879, "test_steps_per_second": 17.34}, {"test_loss": 0.82334965467453, "test_mcc": 0.3736527087563863, "test_macro_f1": 0.45523124762212497, "test_runtime": 3.5032, "test_samples_per_second": 584.604, "test_steps_per_second": 18.269}, {"test_loss": 0.8302276134490967, "test_mcc": 0.4577076152289777, "test_macro_f1": 0.5782803522596648, "test_runtime": 3.5502, "test_samples_per_second": 576.866, "test_steps_per_second": 18.027}, {"test_loss": 0.8723023533821106, "test_mcc": 0.43807136329911217, "test_macro_f1": 0.5831083744182992, "test_runtime": 3.5922, "test_samples_per_second": 570.13, "test_steps_per_second": 17.817}, {"test_loss": 0.8184929490089417, "test_mcc": 0.4139297165963775, "test_macro_f1": 0.5425876621976197, "test_runtime": 3.5955, "test_samples_per_second": 569.601, "test_steps_per_second": 17.8}, {"test_loss": 0.8093564510345459, "test_mcc": 0.46858190523440746, "test_macro_f1": 0.6285721400905889, "test_runtime": 3.7164, "test_samples_per_second": 551.072, "test_steps_per_second": 17.221}, {"test_loss": 0.8128252029418945, "test_mcc": 0.4036843885649833, "test_macro_f1": 0.4779409086235064, "test_runtime": 3.5804, "test_samples_per_second": 572.004, "test_steps_per_second": 17.875}, {"test_loss": 0.8242929577827454, "test_mcc": 0.4150694971372678, "test_macro_f1": 0.47353530821907386, "test_runtime": 3.7095, "test_samples_per_second": 552.096, "test_steps_per_second": 17.253}, {"test_loss": 0.8338209390640259, "test_mcc": 0.3995538064557129, "test_macro_f1": 0.4640121080170845, "test_runtime": 3.7121, "test_samples_per_second": 551.705, "test_steps_per_second": 17.241}, {"test_loss": 0.8137120008468628, "test_mcc": 0.4013487766608255, "test_macro_f1": 0.47274892924713857, "test_runtime": 3.7303, "test_samples_per_second": 549.021, "test_steps_per_second": 17.157}]}, "total": {"test_mcc": 41.97044146501375, "test_mcc_se": 1.7747053057915974, "test_macro_f1": 51.651420462286055, "test_macro_f1_se": 3.8095198991689916}}, "num_model_parameters": 278642179, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "studio-ousia/mluke-base-lite", "results": {"raw": {"test": [{"test_loss": 0.45307502150535583, "test_mcc": 0.6429403396083739, "test_macro_f1": 0.8164996885512292, "test_runtime": 3.2289, "test_samples_per_second": 634.265, "test_steps_per_second": 19.821}, {"test_loss": 0.49451661109924316, "test_mcc": 0.6017394374900702, "test_macro_f1": 0.7921564213780758, "test_runtime": 3.3897, "test_samples_per_second": 604.184, "test_steps_per_second": 18.881}, {"test_loss": 0.4584520161151886, "test_mcc": 0.6563017587480618, "test_macro_f1": 0.8273860320069113, "test_runtime": 3.4219, "test_samples_per_second": 598.503, "test_steps_per_second": 18.703}, {"test_loss": 0.4857335090637207, "test_mcc": 0.6171354896268475, "test_macro_f1": 0.8044515122457113, "test_runtime": 3.2804, "test_samples_per_second": 624.313, "test_steps_per_second": 19.51}, {"test_loss": 0.48183590173721313, "test_mcc": 0.6211324319783325, "test_macro_f1": 0.8042669749389912, "test_runtime": 3.2961, "test_samples_per_second": 621.345, "test_steps_per_second": 19.417}, {"test_loss": 0.46050524711608887, "test_mcc": 0.5866404932736127, "test_macro_f1": 0.7844187158478172, "test_runtime": 3.2571, "test_samples_per_second": 628.78, "test_steps_per_second": 19.649}, {"test_loss": 0.449879914522171, "test_mcc": 0.6692232566891905, "test_macro_f1": 0.8246919920959005, "test_runtime": 3.3127, "test_samples_per_second": 618.223, "test_steps_per_second": 19.319}, {"test_loss": 0.47259455919265747, "test_mcc": 0.543267076344464, "test_macro_f1": 0.7696768171825495, "test_runtime": 3.3627, "test_samples_per_second": 609.032, "test_steps_per_second": 19.032}, {"test_loss": 0.4465045630931854, "test_mcc": 0.591406510092422, "test_macro_f1": 0.790581912330717, "test_runtime": 3.3705, "test_samples_per_second": 607.628, "test_steps_per_second": 18.988}, {"test_loss": 0.474057674407959, "test_mcc": 0.601935464419974, "test_macro_f1": 0.7855528569974259, "test_runtime": 3.2934, "test_samples_per_second": 621.859, "test_steps_per_second": 19.433}]}, "total": {"test_mcc": 61.317222582713484, "test_mcc_se": 2.290254404557712, "test_macro_f1": 79.99682923575328, "test_macro_f1_se": 1.167102020075204}}, "num_model_parameters": 278641410, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "studio-ousia/mluke-base-lite", "results": {"raw": {"test": [{"test_loss": 0.622603714466095, "test_mcc": 0.3542307668531266, "test_macro_f1": 0.6566951423187739, "test_runtime": 3.7339, "test_samples_per_second": 548.493, "test_steps_per_second": 17.14}, {"test_loss": 0.6052026748657227, "test_mcc": 0.39786905472019657, "test_macro_f1": 0.6852017807166368, "test_runtime": 3.8229, "test_samples_per_second": 535.715, "test_steps_per_second": 16.741}, {"test_loss": 0.5599743127822876, "test_mcc": 0.4710443035392938, "test_macro_f1": 0.7355219760611831, "test_runtime": 3.7579, "test_samples_per_second": 544.981, "test_steps_per_second": 17.031}, {"test_loss": 0.6118215918540955, "test_mcc": 0.3661835973352816, "test_macro_f1": 0.6546982429335371, "test_runtime": 3.895, "test_samples_per_second": 525.804, "test_steps_per_second": 16.431}, {"test_loss": 0.5948481559753418, "test_mcc": 0.42906317942028815, "test_macro_f1": 0.7027423757580213, "test_runtime": 3.7345, "test_samples_per_second": 548.398, "test_steps_per_second": 17.137}, {"test_loss": 0.5415294170379639, "test_mcc": 0.489700418555269, "test_macro_f1": 0.7425666478715419, "test_runtime": 3.7463, "test_samples_per_second": 546.666, "test_steps_per_second": 17.083}, {"test_loss": 0.5984379053115845, "test_mcc": 0.4429387175989026, "test_macro_f1": 0.7206261262421455, "test_runtime": 3.588, "test_samples_per_second": 570.797, "test_steps_per_second": 17.837}, {"test_loss": 0.5538690090179443, "test_mcc": 0.4560533083707298, "test_macro_f1": 0.7276423433909331, "test_runtime": 3.6695, "test_samples_per_second": 558.117, "test_steps_per_second": 17.441}, {"test_loss": 0.6020931601524353, "test_mcc": 0.39113104019311634, "test_macro_f1": 0.6853265044814341, "test_runtime": 3.6915, "test_samples_per_second": 554.789, "test_steps_per_second": 17.337}, {"test_loss": 0.6374481916427612, "test_mcc": 0.40126045429432, "test_macro_f1": 0.6762978456884225, "test_runtime": 3.7893, "test_samples_per_second": 540.475, "test_steps_per_second": 16.89}]}, "total": {"test_mcc": 41.99474840880525, "test_mcc_se": 2.7924151557052124, "test_macro_f1": 69.87318985462629, "test_macro_f1_se": 1.9793258304710686}}, "num_model_parameters": 278641410, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "studio-ousia/mluke-base-lite", "results": {"raw": {"test": [{"test_loss": 0.6239920258522034, "test_mcc": 0.35819648203831894, "test_macro_f1": 0.6433219608647753, "test_runtime": 3.3695, "test_samples_per_second": 607.8, "test_steps_per_second": 18.994}, {"test_loss": 0.5573636889457703, "test_mcc": 0.48831228731977944, "test_macro_f1": 0.7160288408208542, "test_runtime": 3.3159, "test_samples_per_second": 617.633, "test_steps_per_second": 19.301}, {"test_loss": 0.608483076095581, "test_mcc": 0.3727211820462892, "test_macro_f1": 0.6743540799917249, "test_runtime": 3.3439, "test_samples_per_second": 612.455, "test_steps_per_second": 19.139}, {"test_loss": 0.5852370262145996, "test_mcc": 0.41639059351669494, "test_macro_f1": 0.6882819771051586, "test_runtime": 3.4469, "test_samples_per_second": 594.156, "test_steps_per_second": 18.567}, {"test_loss": 0.5727931261062622, "test_mcc": 0.4937190030138937, "test_macro_f1": 0.7357128243866358, "test_runtime": 3.4354, "test_samples_per_second": 596.145, "test_steps_per_second": 18.63}, {"test_loss": 0.5783572196960449, "test_mcc": 0.5473064364663641, "test_macro_f1": 0.7679154840182769, "test_runtime": 3.2678, "test_samples_per_second": 626.717, "test_steps_per_second": 19.585}, {"test_loss": 0.6051201820373535, "test_mcc": 0.352013009615995, "test_macro_f1": 0.6525163073579128, "test_runtime": 3.2869, "test_samples_per_second": 623.081, "test_steps_per_second": 19.471}, {"test_loss": 0.5488711595535278, "test_mcc": 0.4770078742092741, "test_macro_f1": 0.733522085957002, "test_runtime": 3.3497, "test_samples_per_second": 611.395, "test_steps_per_second": 19.106}, {"test_loss": 0.6375119090080261, "test_mcc": 0.3825221809873158, "test_macro_f1": 0.6487750463854937, "test_runtime": 3.2648, "test_samples_per_second": 627.291, "test_steps_per_second": 19.603}, {"test_loss": 0.5726219415664673, "test_mcc": 0.4657527770946567, "test_macro_f1": 0.7253107503236171, "test_runtime": 3.415, "test_samples_per_second": 599.706, "test_steps_per_second": 18.741}]}, "total": {"test_mcc": 43.539418263085814, "test_mcc_se": 4.202523262516635, "test_macro_f1": 69.8573935721145, "test_macro_f1_se": 2.675876005703948}}, "num_model_parameters": 278641410, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "studio-ousia/mluke-base-lite", "results": {"raw": {"test": [{"test_loss": 0.6529251337051392, "test_mcc": 0.35554249882636474, "test_macro_f1": 0.6731555315104647, "test_runtime": 3.5792, "test_samples_per_second": 572.198, "test_steps_per_second": 17.881}, {"test_loss": 0.6394562721252441, "test_mcc": 0.2743765323012295, "test_macro_f1": 0.6204516807625134, "test_runtime": 3.6704, "test_samples_per_second": 557.978, "test_steps_per_second": 17.437}, {"test_loss": 0.6342524886131287, "test_mcc": 0.29106191489880223, "test_macro_f1": 0.6419922983570163, "test_runtime": 3.6641, "test_samples_per_second": 558.93, "test_steps_per_second": 17.467}, {"test_loss": 0.6381427645683289, "test_mcc": 0.24231288170242707, "test_macro_f1": 0.6206053782952734, "test_runtime": 3.5102, "test_samples_per_second": 583.442, "test_steps_per_second": 18.233}, {"test_loss": 0.6296615600585938, "test_mcc": 0.283426206464792, "test_macro_f1": 0.6279822499882628, "test_runtime": 3.5388, "test_samples_per_second": 578.731, "test_steps_per_second": 18.085}, {"test_loss": 0.6479054689407349, "test_mcc": 0.24078931402070197, "test_macro_f1": 0.6011343501949962, "test_runtime": 3.6482, "test_samples_per_second": 561.375, "test_steps_per_second": 17.543}, {"test_loss": 0.655005156993866, "test_mcc": 0.2658704821515256, "test_macro_f1": 0.6321304741424036, "test_runtime": 3.5651, "test_samples_per_second": 574.452, "test_steps_per_second": 17.952}, {"test_loss": 0.6340150833129883, "test_mcc": 0.3120638977018838, "test_macro_f1": 0.6461502365392525, "test_runtime": 3.5486, "test_samples_per_second": 577.137, "test_steps_per_second": 18.036}, {"test_loss": 0.6426330208778381, "test_mcc": 0.2802611075487848, "test_macro_f1": 0.639129096413566, "test_runtime": 3.5325, "test_samples_per_second": 579.753, "test_steps_per_second": 18.117}, {"test_loss": 0.6357316374778748, "test_mcc": 0.26934475162564847, "test_macro_f1": 0.6260203665354743, "test_runtime": 3.6783, "test_samples_per_second": 556.78, "test_steps_per_second": 17.399}]}, "total": {"test_mcc": 28.150495872421605, "test_mcc_se": 2.081344503938568, "test_macro_f1": 63.28751662739223, "test_macro_f1_se": 1.1877058461295373}}, "num_model_parameters": 278641410, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "studio-ousia/mluke-base-lite", "results": {"raw": {"test": [{"test_speed": 2.0}, {"test_speed": 1.91}, {"test_speed": 1.9}, {"test_speed": 1.87}, {"test_speed": 1.96}, {"test_speed": 1.9}, {"test_speed": 1.88}, {"test_speed": 1.93}, {"test_speed": 1.88}, {"test_speed": 1.91}]}, "total": {"test_speed": 1.9140000000000001, "test_speed_se": 0.024826666666666674}}, "num_model_parameters": 278639872, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "studio-ousia/mluke-large", "results": {"raw": {"test": [{"test_speed": 0.54}, {"test_speed": 0.55}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.55}, {"test_speed": 0.55}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.55}]}, "total": {"test_speed": 0.5439999999999999, "test_speed_se": 0.0032006665972366885}}, "num_model_parameters": 867884288, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_speed": 0.43}, {"test_speed": 0.42}, {"test_speed": 0.43}, {"test_speed": 0.43}, {"test_speed": 0.43}, {"test_speed": 0.43}, {"test_speed": 0.43}, {"test_speed": 0.43}, {"test_speed": 0.43}, {"test_speed": 0.43}]}, "total": {"test_speed": 0.429, "test_speed_se": 0.0019600000000000017}}, "num_model_parameters": 561460736, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.6561543941497803, "test_mcc": 0.6084342320550302, "test_macro_f1": 0.5488100371867657, "test_runtime": 5.1379, "test_samples_per_second": 398.61, "test_steps_per_second": 12.457}, {"test_loss": 0.690657377243042, "test_mcc": 0.5672897887795513, "test_macro_f1": 0.5325704547612008, "test_runtime": 5.0187, "test_samples_per_second": 408.071, "test_steps_per_second": 12.752}, {"test_loss": 0.7437028884887695, "test_mcc": 0.5352006278638844, "test_macro_f1": 0.5203422833437691, "test_runtime": 5.2387, "test_samples_per_second": 390.935, "test_steps_per_second": 12.217}, {"test_loss": 0.6670414209365845, "test_mcc": 0.5967354852231881, "test_macro_f1": 0.5436088793084677, "test_runtime": 5.017, "test_samples_per_second": 408.21, "test_steps_per_second": 12.757}, {"test_loss": 0.6791762709617615, "test_mcc": 0.6004846248301978, "test_macro_f1": 0.5451809843465177, "test_runtime": 4.859, "test_samples_per_second": 421.487, "test_steps_per_second": 13.171}, {"test_loss": 0.687852144241333, "test_mcc": 0.5837342509298007, "test_macro_f1": 0.5388753244652937, "test_runtime": 5.1522, "test_samples_per_second": 397.503, "test_steps_per_second": 12.422}, {"test_loss": 0.6572777032852173, "test_mcc": 0.6043806448927649, "test_macro_f1": 0.5467205876725375, "test_runtime": 4.8118, "test_samples_per_second": 425.625, "test_steps_per_second": 13.301}, {"test_loss": 0.7236127853393555, "test_mcc": 0.5596020106960743, "test_macro_f1": 0.5285073946126578, "test_runtime": 5.2002, "test_samples_per_second": 393.832, "test_steps_per_second": 12.307}, {"test_loss": 0.7518207430839539, "test_mcc": 0.5488899387768453, "test_macro_f1": 0.5252619709817884, "test_runtime": 5.1366, "test_samples_per_second": 398.708, "test_steps_per_second": 12.46}, {"test_loss": 0.6990023851394653, "test_mcc": 0.5880132199770743, "test_macro_f1": 0.5408011883668316, "test_runtime": 5.1088, "test_samples_per_second": 400.876, "test_steps_per_second": 12.527}]}, "total": {"test_mcc": 57.9276482402441, "test_mcc_se": 1.563636515824356, "test_macro_f1": 53.7067910504583, "test_macro_f1_se": 0.6092130733040415}}, "num_model_parameters": 13354115, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.9888791441917419, "test_mcc": 0.2672424184523941, "test_macro_f1": 0.48630085582395366, "test_runtime": 1.4766, "test_samples_per_second": 1386.935, "test_steps_per_second": 43.342}, {"test_loss": 0.9925166368484497, "test_mcc": 0.2252227721825824, "test_macro_f1": 0.3794498601979899, "test_runtime": 1.4878, "test_samples_per_second": 1376.553, "test_steps_per_second": 43.017}, {"test_loss": 1.0118366479873657, "test_mcc": 0.2366048345826716, "test_macro_f1": 0.3829586201903745, "test_runtime": 1.4932, "test_samples_per_second": 1371.584, "test_steps_per_second": 42.862}, {"test_loss": 0.9900237321853638, "test_mcc": 0.2403399761391438, "test_macro_f1": 0.38937881861908813, "test_runtime": 1.4831, "test_samples_per_second": 1380.91, "test_steps_per_second": 43.153}, {"test_loss": 0.9953924417495728, "test_mcc": 0.2360451162929994, "test_macro_f1": 0.389002719963574, "test_runtime": 1.478, "test_samples_per_second": 1385.617, "test_steps_per_second": 43.301}, {"test_loss": 1.0017846822738647, "test_mcc": 0.21502162588343118, "test_macro_f1": 0.37772549875307265, "test_runtime": 1.472, "test_samples_per_second": 1391.343, "test_steps_per_second": 43.479}, {"test_loss": 0.9647042751312256, "test_mcc": 0.31267363950452226, "test_macro_f1": 0.5158104327455041, "test_runtime": 1.4783, "test_samples_per_second": 1385.379, "test_steps_per_second": 43.293}, {"test_loss": 1.0139131546020508, "test_mcc": 0.2278156038668032, "test_macro_f1": 0.3786198250229417, "test_runtime": 1.4864, "test_samples_per_second": 1377.869, "test_steps_per_second": 43.058}, {"test_loss": 0.9981803894042969, "test_mcc": 0.24952243936045204, "test_macro_f1": 0.39168865988018936, "test_runtime": 1.4884, "test_samples_per_second": 1375.942, "test_steps_per_second": 42.998}, {"test_loss": 0.9829614758491516, "test_mcc": 0.2278969646240071, "test_macro_f1": 0.3943412352191344, "test_runtime": 1.4407, "test_samples_per_second": 1421.571, "test_steps_per_second": 44.424}]}, "total": {"test_mcc": 24.38385390889007, "test_mcc_se": 1.7447122894835572, "test_macro_f1": 40.85276526415822, "test_macro_f1_se": 3.0736897829579646}}, "num_model_parameters": 13354115, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.9765619039535522, "test_mcc": 0.26997470535176604, "test_macro_f1": 0.4094933899666829, "test_runtime": 1.4097, "test_samples_per_second": 1452.826, "test_steps_per_second": 45.401}, {"test_loss": 0.924144983291626, "test_mcc": 0.299007741422611, "test_macro_f1": 0.4223291530463385, "test_runtime": 1.3635, "test_samples_per_second": 1501.984, "test_steps_per_second": 46.937}, {"test_loss": 0.9260281324386597, "test_mcc": 0.2868056276833685, "test_macro_f1": 0.4099250782866098, "test_runtime": 1.3547, "test_samples_per_second": 1511.813, "test_steps_per_second": 47.244}, {"test_loss": 0.9403465986251831, "test_mcc": 0.2996033243673224, "test_macro_f1": 0.42213588138421904, "test_runtime": 1.4021, "test_samples_per_second": 1460.642, "test_steps_per_second": 45.645}, {"test_loss": 0.9216505289077759, "test_mcc": 0.3299696343522058, "test_macro_f1": 0.43528709438446467, "test_runtime": 1.3862, "test_samples_per_second": 1477.41, "test_steps_per_second": 46.169}, {"test_loss": 0.9275586605072021, "test_mcc": 0.28966679338592816, "test_macro_f1": 0.41861658172215765, "test_runtime": 1.4072, "test_samples_per_second": 1455.354, "test_steps_per_second": 45.48}, {"test_loss": 0.9166665077209473, "test_mcc": 0.310284642442167, "test_macro_f1": 0.42683858557215953, "test_runtime": 1.3376, "test_samples_per_second": 1531.082, "test_steps_per_second": 47.846}, {"test_loss": 0.9033573865890503, "test_mcc": 0.30190484600984807, "test_macro_f1": 0.422544883677433, "test_runtime": 1.3681, "test_samples_per_second": 1496.984, "test_steps_per_second": 46.781}, {"test_loss": 0.9129780530929565, "test_mcc": 0.31054505326967885, "test_macro_f1": 0.4232116798712993, "test_runtime": 1.3582, "test_samples_per_second": 1507.894, "test_steps_per_second": 47.122}, {"test_loss": 0.9401242136955261, "test_mcc": 0.29888190899889194, "test_macro_f1": 0.42153251924917506, "test_runtime": 1.3835, "test_samples_per_second": 1480.348, "test_steps_per_second": 46.261}]}, "total": {"test_mcc": 29.966442772837876, "test_mcc_se": 0.9913524108239588, "test_macro_f1": 42.11914847160539, "test_macro_f1_se": 0.4662066802323648}}, "num_model_parameters": 13354115, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.11163486540317535, "test_micro_f1": 0.47516641065028165, "test_micro_f1_no_misc": 0.5419432709716355, "test_runtime": 3.3428, "test_samples_per_second": 612.665, "test_steps_per_second": 19.146}, {"test_loss": 0.113180972635746, "test_micro_f1": 0.46881959910913135, "test_micro_f1_no_misc": 0.4991108476585655, "test_runtime": 3.1597, "test_samples_per_second": 648.158, "test_steps_per_second": 20.255}, {"test_loss": 0.10968004167079926, "test_micro_f1": 0.4992279979413279, "test_micro_f1_no_misc": 0.5298957761930884, "test_runtime": 3.1121, "test_samples_per_second": 658.078, "test_steps_per_second": 20.565}, {"test_loss": 0.11409708112478256, "test_micro_f1": 0.4840637450199203, "test_micro_f1_no_misc": 0.525330396475771, "test_runtime": 3.0114, "test_samples_per_second": 680.094, "test_steps_per_second": 21.253}, {"test_loss": 0.12194398045539856, "test_micro_f1": 0.46837944664031617, "test_micro_f1_no_misc": 0.4960753532182104, "test_runtime": 3.1431, "test_samples_per_second": 651.581, "test_steps_per_second": 20.362}, {"test_loss": 0.11094304919242859, "test_micro_f1": 0.49760765550239233, "test_micro_f1_no_misc": 0.5393844548774126, "test_runtime": 2.7076, "test_samples_per_second": 756.387, "test_steps_per_second": 23.637}, {"test_loss": 0.12129824608564377, "test_micro_f1": 0.48102564102564105, "test_micro_f1_no_misc": 0.5111716621253406, "test_runtime": 2.8581, "test_samples_per_second": 716.572, "test_steps_per_second": 22.393}, {"test_loss": 0.10093138366937637, "test_micro_f1": 0.4957841483979764, "test_micro_f1_no_misc": 0.5494791666666666, "test_runtime": 3.1617, "test_samples_per_second": 647.751, "test_steps_per_second": 20.242}, {"test_loss": 0.10331283509731293, "test_micro_f1": 0.4858585858585858, "test_micro_f1_no_misc": 0.5483119906868452, "test_runtime": 3.0971, "test_samples_per_second": 661.269, "test_steps_per_second": 20.665}, {"test_loss": 0.10926851630210876, "test_micro_f1": 0.4914341654429761, "test_micro_f1_no_misc": 0.5385450597176981, "test_runtime": 2.9414, "test_samples_per_second": 696.264, "test_steps_per_second": 21.758}]}, "total": {"test_micro_f1": 48.47367395588549, "test_micro_f1_se": 0.7068538613812712, "test_micro_f1_no_misc": 52.79247978591235, "test_micro_f1_no_misc_se": 1.2147035437905118}}, "num_model_parameters": 13289865, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.10181311517953873, "test_micro_f1": 0.6877051249684423, "test_micro_f1_no_misc": 0.7213445378151262, "test_runtime": 3.4232, "test_samples_per_second": 598.273, "test_steps_per_second": 18.696}, {"test_loss": 0.09655152261257172, "test_micro_f1": 0.6759562841530055, "test_micro_f1_no_misc": 0.7063463607027609, "test_runtime": 2.8326, "test_samples_per_second": 723.004, "test_steps_per_second": 22.594}, {"test_loss": 0.09378393739461899, "test_micro_f1": 0.7271280827366747, "test_micro_f1_no_misc": 0.7632950990615225, "test_runtime": 3.4113, "test_samples_per_second": 600.35, "test_steps_per_second": 18.761}, {"test_loss": 0.10939913243055344, "test_micro_f1": 0.6621451896508413, "test_micro_f1_no_misc": 0.7053941908713693, "test_runtime": 3.378, "test_samples_per_second": 606.285, "test_steps_per_second": 18.946}, {"test_loss": 0.09886101633310318, "test_micro_f1": 0.6764307024681313, "test_micro_f1_no_misc": 0.7173674588665448, "test_runtime": 3.3704, "test_samples_per_second": 607.65, "test_steps_per_second": 18.989}, {"test_loss": 0.09601429849863052, "test_micro_f1": 0.7122988819198254, "test_micro_f1_no_misc": 0.719044170890659, "test_runtime": 3.4303, "test_samples_per_second": 597.035, "test_steps_per_second": 18.657}, {"test_loss": 0.10269584506750107, "test_micro_f1": 0.6926701570680628, "test_micro_f1_no_misc": 0.720110573600553, "test_runtime": 3.4561, "test_samples_per_second": 592.573, "test_steps_per_second": 18.518}, {"test_loss": 0.0944693461060524, "test_micro_f1": 0.6880977683315622, "test_micro_f1_no_misc": 0.7064953108718306, "test_runtime": 3.3969, "test_samples_per_second": 602.895, "test_steps_per_second": 18.84}, {"test_loss": 0.09521827101707458, "test_micro_f1": 0.7070496083550915, "test_micro_f1_no_misc": 0.7380261248185775, "test_runtime": 3.3595, "test_samples_per_second": 609.613, "test_steps_per_second": 19.05}, {"test_loss": 0.09124454855918884, "test_micro_f1": 0.725443473656341, "test_micro_f1_no_misc": 0.7567567567567568, "test_runtime": 2.9887, "test_samples_per_second": 685.255, "test_steps_per_second": 21.414}]}, "total": {"test_micro_f1": 69.54925273307977, "test_micro_f1_se": 1.3538734570985411, "test_micro_f1_no_misc": 72.54180584255701, "test_micro_f1_no_misc_se": 1.281716856459091}}, "num_model_parameters": 13289865, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.07252679765224457, "test_micro_f1": 0.7186932849364791, "test_micro_f1_no_misc": 0.7540849673202615, "test_runtime": 2.8664, "test_samples_per_second": 714.494, "test_steps_per_second": 22.328}, {"test_loss": 0.0773293748497963, "test_micro_f1": 0.6864035087719299, "test_micro_f1_no_misc": 0.7126064045399271, "test_runtime": 2.9103, "test_samples_per_second": 703.718, "test_steps_per_second": 21.991}, {"test_loss": 0.07634671032428741, "test_micro_f1": 0.6726395589248795, "test_micro_f1_no_misc": 0.7191273860537593, "test_runtime": 2.8022, "test_samples_per_second": 730.859, "test_steps_per_second": 22.839}, {"test_loss": 0.07612940669059753, "test_micro_f1": 0.7112676056338029, "test_micro_f1_no_misc": 0.728780102645085, "test_runtime": 2.7879, "test_samples_per_second": 734.595, "test_steps_per_second": 22.956}, {"test_loss": 0.07421496510505676, "test_micro_f1": 0.7168053244592346, "test_micro_f1_no_misc": 0.7473919523099851, "test_runtime": 2.8838, "test_samples_per_second": 710.17, "test_steps_per_second": 22.193}, {"test_loss": 0.0752510130405426, "test_micro_f1": 0.7008431703204047, "test_micro_f1_no_misc": 0.7375415282392026, "test_runtime": 2.8468, "test_samples_per_second": 719.415, "test_steps_per_second": 22.482}, {"test_loss": 0.07725527882575989, "test_micro_f1": 0.6969283276450512, "test_micro_f1_no_misc": 0.7210884353741497, "test_runtime": 2.752, "test_samples_per_second": 744.197, "test_steps_per_second": 23.256}, {"test_loss": 0.08027932792901993, "test_micro_f1": 0.6921751120303343, "test_micro_f1_no_misc": 0.7174484052532831, "test_runtime": 2.8397, "test_samples_per_second": 721.193, "test_steps_per_second": 22.537}, {"test_loss": 0.0746607780456543, "test_micro_f1": 0.6789822237713489, "test_micro_f1_no_misc": 0.7093023255813954, "test_runtime": 2.7913, "test_samples_per_second": 733.714, "test_steps_per_second": 22.929}, {"test_loss": 0.0840674489736557, "test_micro_f1": 0.7305183659457604, "test_micro_f1_no_misc": 0.7675304878048781, "test_runtime": 2.8077, "test_samples_per_second": 729.412, "test_steps_per_second": 22.794}]}, "total": {"test_micro_f1": 70.05256482439226, "test_micro_f1_se": 1.1566038393778515, "test_micro_f1_no_misc": 73.14901995121927, "test_micro_f1_no_misc_se": 1.2070520598747525}}, "num_model_parameters": 13289865, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.08854988217353821, "test_micro_f1": 0.6422073984232868, "test_micro_f1_no_misc": 0.6826580226904375, "test_runtime": 2.9905, "test_samples_per_second": 684.841, "test_steps_per_second": 21.401}, {"test_loss": 0.09836101531982422, "test_micro_f1": 0.6026200873362446, "test_micro_f1_no_misc": 0.6446589847399564, "test_runtime": 3.0685, "test_samples_per_second": 667.434, "test_steps_per_second": 20.857}, {"test_loss": 0.09281732141971588, "test_micro_f1": 0.6361746361746361, "test_micro_f1_no_misc": 0.6824214956296536, "test_runtime": 3.0541, "test_samples_per_second": 670.576, "test_steps_per_second": 20.955}, {"test_loss": 0.10917866975069046, "test_micro_f1": 0.5925272138864373, "test_micro_f1_no_misc": 0.632537688442211, "test_runtime": 3.0271, "test_samples_per_second": 676.55, "test_steps_per_second": 21.142}, {"test_loss": 0.1113676130771637, "test_micro_f1": 0.6086956521739131, "test_micro_f1_no_misc": 0.6583493282149712, "test_runtime": 2.9497, "test_samples_per_second": 694.308, "test_steps_per_second": 21.697}, {"test_loss": 0.09920857846736908, "test_micro_f1": 0.61620029455081, "test_micro_f1_no_misc": 0.6628643852978453, "test_runtime": 2.9149, "test_samples_per_second": 702.597, "test_steps_per_second": 21.956}, {"test_loss": 0.09237214922904968, "test_micro_f1": 0.6378778531770513, "test_micro_f1_no_misc": 0.6800924397490922, "test_runtime": 3.1066, "test_samples_per_second": 659.25, "test_steps_per_second": 20.602}, {"test_loss": 0.09474712610244751, "test_micro_f1": 0.6255612092187969, "test_micro_f1_no_misc": 0.6624405705229794, "test_runtime": 3.0674, "test_samples_per_second": 667.669, "test_steps_per_second": 20.865}, {"test_loss": 0.104659304022789, "test_micro_f1": 0.5935207823960882, "test_micro_f1_no_misc": 0.6381860006572461, "test_runtime": 2.8717, "test_samples_per_second": 713.167, "test_steps_per_second": 22.286}, {"test_loss": 0.09504485130310059, "test_micro_f1": 0.6514753140520011, "test_micro_f1_no_misc": 0.6895697926338595, "test_runtime": 2.9291, "test_samples_per_second": 699.181, "test_steps_per_second": 21.849}]}, "total": {"test_micro_f1": 62.06860441389266, "test_micro_f1_se": 1.305279435857672, "test_micro_f1_no_misc": 66.33778708578252, "test_micro_f1_no_misc_se": 1.2503014286309269}}, "num_model_parameters": 13289865, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.6809793710708618, "test_mcc": 0.1731977663763385, "test_macro_f1": 0.5506890843455194, "test_runtime": 1.3424, "test_samples_per_second": 1525.642, "test_steps_per_second": 47.676}, {"test_loss": 0.6775180101394653, "test_mcc": 0.11549045721662628, "test_macro_f1": 0.5467241678151139, "test_runtime": 1.3615, "test_samples_per_second": 1504.246, "test_steps_per_second": 47.008}, {"test_loss": 0.690178632736206, "test_mcc": 0.07345147875994433, "test_macro_f1": 0.5295361633763084, "test_runtime": 1.3747, "test_samples_per_second": 1489.777, "test_steps_per_second": 46.556}, {"test_loss": 0.6797438859939575, "test_mcc": 0.14119967904260092, "test_macro_f1": 0.5441463218112964, "test_runtime": 1.3585, "test_samples_per_second": 1507.57, "test_steps_per_second": 47.112}, {"test_loss": 0.676283597946167, "test_mcc": 0.15867215101870052, "test_macro_f1": 0.5790437529567964, "test_runtime": 1.3338, "test_samples_per_second": 1535.454, "test_steps_per_second": 47.983}, {"test_loss": 0.6833702921867371, "test_mcc": 0.14886688248822044, "test_macro_f1": 0.555021760671735, "test_runtime": 1.3478, "test_samples_per_second": 1519.558, "test_steps_per_second": 47.486}, {"test_loss": 0.6700952053070068, "test_mcc": 0.17963666350643243, "test_macro_f1": 0.5870461477156039, "test_runtime": 1.3466, "test_samples_per_second": 1520.891, "test_steps_per_second": 47.528}, {"test_loss": 0.6788539290428162, "test_mcc": 0.1719240158665819, "test_macro_f1": 0.5765025553514538, "test_runtime": 1.3541, "test_samples_per_second": 1512.494, "test_steps_per_second": 47.265}, {"test_loss": 0.6732828617095947, "test_mcc": 0.1401203884734104, "test_macro_f1": 0.556255166824161, "test_runtime": 1.3234, "test_samples_per_second": 1547.529, "test_steps_per_second": 48.36}, {"test_loss": 0.6740522980690002, "test_mcc": 0.16964162428436724, "test_macro_f1": 0.5674506242316871, "test_runtime": 1.325, "test_samples_per_second": 1545.62, "test_steps_per_second": 48.301}]}, "total": {"test_mcc": 14.722011070332227, "test_mcc_se": 2.0145322668501757, "test_macro_f1": 55.924157450996745, "test_macro_f1_se": 1.1120847709964208}}, "num_model_parameters": 13353858, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.41426682472229004, "test_mcc": 0.6803579504079456, "test_macro_f1": 0.8396772465911272, "test_runtime": 1.35, "test_samples_per_second": 1517.082, "test_steps_per_second": 47.409}, {"test_loss": 0.43238455057144165, "test_mcc": 0.6705999039196527, "test_macro_f1": 0.834458408233016, "test_runtime": 1.3501, "test_samples_per_second": 1516.887, "test_steps_per_second": 47.403}, {"test_loss": 0.3928369879722595, "test_mcc": 0.7064531545195574, "test_macro_f1": 0.8516335052812578, "test_runtime": 1.3243, "test_samples_per_second": 1546.475, "test_steps_per_second": 48.327}, {"test_loss": 0.407867431640625, "test_mcc": 0.6810564045325864, "test_macro_f1": 0.8395989974937343, "test_runtime": 1.3673, "test_samples_per_second": 1497.866, "test_steps_per_second": 46.808}, {"test_loss": 0.42528191208839417, "test_mcc": 0.7180374745689794, "test_macro_f1": 0.8572039855736903, "test_runtime": 1.3686, "test_samples_per_second": 1496.39, "test_steps_per_second": 46.762}, {"test_loss": 0.432140588760376, "test_mcc": 0.6866583131534247, "test_macro_f1": 0.8418694999783662, "test_runtime": 1.3427, "test_samples_per_second": 1525.241, "test_steps_per_second": 47.664}, {"test_loss": 0.4302103817462921, "test_mcc": 0.6996996299427546, "test_macro_f1": 0.8480183963865808, "test_runtime": 1.3458, "test_samples_per_second": 1521.776, "test_steps_per_second": 47.555}, {"test_loss": 0.4061122536659241, "test_mcc": 0.6991994542075066, "test_macro_f1": 0.8481623453713527, "test_runtime": 1.3349, "test_samples_per_second": 1534.229, "test_steps_per_second": 47.945}, {"test_loss": 0.42905503511428833, "test_mcc": 0.6782009886532182, "test_macro_f1": 0.8340954582833643, "test_runtime": 1.3695, "test_samples_per_second": 1495.415, "test_steps_per_second": 46.732}, {"test_loss": 0.44632434844970703, "test_mcc": 0.638055337439419, "test_macro_f1": 0.8176132748380935, "test_runtime": 1.3784, "test_samples_per_second": 1485.812, "test_steps_per_second": 46.432}]}, "total": {"test_mcc": 68.58318611345044, "test_mcc_se": 1.379715250537289, "test_macro_f1": 84.12331118030582, "test_macro_f1_se": 0.6906591819143407}}, "num_model_parameters": 13353858, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.5874598026275635, "test_mcc": 0.44744271681700093, "test_macro_f1": 0.7236450518368533, "test_runtime": 1.3666, "test_samples_per_second": 1498.566, "test_steps_per_second": 46.83}, {"test_loss": 0.5947471261024475, "test_mcc": 0.43247495585063345, "test_macro_f1": 0.7095404238796529, "test_runtime": 1.3837, "test_samples_per_second": 1480.124, "test_steps_per_second": 46.254}, {"test_loss": 0.6401299238204956, "test_mcc": 0.368209808390146, "test_macro_f1": 0.6462184208442228, "test_runtime": 1.3636, "test_samples_per_second": 1501.955, "test_steps_per_second": 46.936}, {"test_loss": 0.6002769470214844, "test_mcc": 0.3910839634102971, "test_macro_f1": 0.6877124598400004, "test_runtime": 1.4035, "test_samples_per_second": 1459.248, "test_steps_per_second": 45.601}, {"test_loss": 0.6098349094390869, "test_mcc": 0.37384700935898285, "test_macro_f1": 0.6854411075145299, "test_runtime": 1.4406, "test_samples_per_second": 1421.624, "test_steps_per_second": 44.426}, {"test_loss": 0.5787724256515503, "test_mcc": 0.4373130500178035, "test_macro_f1": 0.7157807465443686, "test_runtime": 1.3591, "test_samples_per_second": 1506.824, "test_steps_per_second": 47.088}, {"test_loss": 0.5744956731796265, "test_mcc": 0.42900964886799625, "test_macro_f1": 0.7125345061526225, "test_runtime": 1.3606, "test_samples_per_second": 1505.193, "test_steps_per_second": 47.037}, {"test_loss": 0.5890545845031738, "test_mcc": 0.426317650443785, "test_macro_f1": 0.6986164770792929, "test_runtime": 1.3527, "test_samples_per_second": 1513.995, "test_steps_per_second": 47.312}, {"test_loss": 0.619070827960968, "test_mcc": 0.35340615720573987, "test_macro_f1": 0.6711466353943247, "test_runtime": 1.3536, "test_samples_per_second": 1513.052, "test_steps_per_second": 47.283}, {"test_loss": 0.6052915453910828, "test_mcc": 0.4201491521015982, "test_macro_f1": 0.6974880455528878, "test_runtime": 1.4164, "test_samples_per_second": 1445.892, "test_steps_per_second": 45.184}]}, "total": {"test_mcc": 40.79254112463984, "test_mcc_se": 2.0613490081598544, "test_macro_f1": 69.48123874638756, "test_macro_f1_se": 1.44374614704137}}, "num_model_parameters": 13353858, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_loss": 0.6465588808059692, "test_mcc": 0.24555376217426983, "test_macro_f1": 0.6207859439767209, "test_runtime": 1.4144, "test_samples_per_second": 1447.944, "test_steps_per_second": 45.248}, {"test_loss": 0.6604386568069458, "test_mcc": 0.2234767802253147, "test_macro_f1": 0.6037036153456699, "test_runtime": 1.4045, "test_samples_per_second": 1458.181, "test_steps_per_second": 45.568}, {"test_loss": 0.6471489071846008, "test_mcc": 0.29314132378392954, "test_macro_f1": 0.6228956760839409, "test_runtime": 1.4116, "test_samples_per_second": 1450.844, "test_steps_per_second": 45.339}, {"test_loss": 0.6559180617332458, "test_mcc": 0.2712751511808384, "test_macro_f1": 0.6352433835147393, "test_runtime": 1.3891, "test_samples_per_second": 1474.358, "test_steps_per_second": 46.074}, {"test_loss": 0.658836841583252, "test_mcc": 0.21188663592616824, "test_macro_f1": 0.6048419705841395, "test_runtime": 1.3948, "test_samples_per_second": 1468.296, "test_steps_per_second": 45.884}, {"test_loss": 0.6603502035140991, "test_mcc": 0.21571472288303048, "test_macro_f1": 0.5934557308698192, "test_runtime": 1.4192, "test_samples_per_second": 1443.04, "test_steps_per_second": 45.095}, {"test_loss": 0.6576358079910278, "test_mcc": 0.2703137121946474, "test_macro_f1": 0.6292815774892423, "test_runtime": 1.4052, "test_samples_per_second": 1457.471, "test_steps_per_second": 45.546}, {"test_loss": 0.6458206176757812, "test_mcc": 0.2922689392305483, "test_macro_f1": 0.6279782816991376, "test_runtime": 1.4189, "test_samples_per_second": 1443.347, "test_steps_per_second": 45.105}, {"test_loss": 0.6527500152587891, "test_mcc": 0.24862999428740729, "test_macro_f1": 0.6191934548875059, "test_runtime": 1.4455, "test_samples_per_second": 1416.836, "test_steps_per_second": 44.276}, {"test_loss": 0.6567009091377258, "test_mcc": 0.23565034645151275, "test_macro_f1": 0.6165712206240065, "test_runtime": 1.473, "test_samples_per_second": 1390.346, "test_steps_per_second": 43.448}]}, "total": {"test_mcc": 25.07911368337667, "test_mcc_se": 1.8555133042055385, "test_macro_f1": 61.739508550749214, "test_macro_f1_se": 0.8096198636252707}}, "num_model_parameters": 13353858, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_em": 26.49109217660728, "test_f1": 31.72957704478004}, {"test_em": 30.387596899224807, "test_f1": 36.20299873318921}, {"test_em": 27.125193199381762, "test_f1": 32.24472314113922}, {"test_em": 25.46728971962617, "test_f1": 31.11755860147835}, {"test_em": 27.413127413127413, "test_f1": 32.485023713683596}, {"test_em": 25.366229760986894, "test_f1": 31.100969339282795}, {"test_em": 33.181473044798786, "test_f1": 38.016216889703685}, {"test_em": 28.08378588052754, "test_f1": 33.665884444567865}, {"test_em": 26.431372549019606, "test_f1": 31.47827429408675}, {"test_em": 26.940993788819874, "test_f1": 32.39791011238444}]}, "total": {"test_em": 27.688815443212015, "test_em_se": 1.4884950287290684, "test_f1": 33.0439136314296, "test_f1_se": 1.4332208552711647}}, "num_model_parameters": 13288066, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_em": 28.81487219209915, "test_f1": 34.94991183311494}, {"test_em": 21.782945736434108, "test_f1": 28.703666900801338}, {"test_em": 21.483771251931994, "test_f1": 28.029691202748797}, {"test_em": 27.258566978193148, "test_f1": 32.47455683800122}, {"test_em": 25.55984555984556, "test_f1": 31.556813929436668}, {"test_em": 26.137239784117195, "test_f1": 32.65342214214463}, {"test_em": 25.74031890660592, "test_f1": 31.842632499994494}, {"test_em": 27.307990690457718, "test_f1": 32.85259149587463}, {"test_em": 26.03921568627451, "test_f1": 31.86013783595281}, {"test_em": 26.39751552795031, "test_f1": 33.51270084159293}]}, "total": {"test_em": 25.65222823139096, "test_em_se": 1.440719463252709, "test_f1": 31.84361255196625, "test_f1_se": 1.2901415196291548}}, "num_model_parameters": 13288066, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_em": 27.8853601859024, "test_f1": 33.72852910671292}, {"test_em": 26.666666666666668, "test_f1": 32.72207165199823}, {"test_em": 26.738794435857805, "test_f1": 32.44120377667909}, {"test_em": 28.50467289719626, "test_f1": 34.44129459010741}, {"test_em": 25.328185328185327, "test_f1": 31.4296882005572}, {"test_em": 24.05551272166538, "test_f1": 30.204726826473625}, {"test_em": 28.32194381169324, "test_f1": 33.81624225879379}, {"test_em": 27.851047323506595, "test_f1": 32.928766895987614}, {"test_em": 24.470588235294116, "test_f1": 30.576348647781757}, {"test_em": 29.114906832298136, "test_f1": 34.792773058451104}]}, "total": {"test_em": 26.893767843826595, "test_em_se": 1.091710642478094, "test_f1": 32.70816450135427, "test_f1_se": 0.9731110067532042}}, "num_model_parameters": 13288066, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sarnikowski/electra-small-discriminator-da-256-cased", "results": {"raw": {"test": [{"test_speed": 10.4}, {"test_speed": 10.59}, {"test_speed": 10.64}, {"test_speed": 10.35}, {"test_speed": 10.75}, {"test_speed": 10.64}, {"test_speed": 10.72}, {"test_speed": 10.84}, {"test_speed": 10.74}, {"test_speed": 11.18}]}, "total": {"test_speed": 10.684999999999999, "test_speed_se": 0.14374075738402564}}, "num_model_parameters": 13353344, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "sberbank-ai/mGPT", "results": {"raw": {"test": [{"test_speed": 0.08}, {"test_speed": 0.08}, {"test_speed": 0.08}, {"test_speed": 0.08}, {"test_speed": 0.08}, {"test_speed": 0.08}, {"test_speed": 0.08}, {"test_speed": 0.08}, {"test_speed": 0.08}, {"test_speed": 0.08}]}, "total": {"test_speed": 0.07999999999999999, "test_speed_se": 9.066821367772112e-18}}, "num_model_parameters": 1417596928, "max_sequence_length": 1024, "vocabulary_size": 100000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "studio-ousia/mluke-base", "results": {"raw": {"test": [{"test_loss": 0.42572712898254395, "test_mcc": 0.7380871139585019, "test_macro_f1": 0.685681790087636, "test_runtime": 17.7817, "test_samples_per_second": 115.174, "test_steps_per_second": 57.587}, {"test_loss": 0.4999239444732666, "test_mcc": 0.68667523317985, "test_macro_f1": 0.5790661720832154, "test_runtime": 17.2547, "test_samples_per_second": 118.692, "test_steps_per_second": 59.346}, {"test_loss": 0.4941534399986267, "test_mcc": 0.6855018556022512, "test_macro_f1": 0.5991612059956228, "test_runtime": 17.6804, "test_samples_per_second": 115.834, "test_steps_per_second": 57.917}, {"test_loss": 0.45276838541030884, "test_mcc": 0.6924709991954686, "test_macro_f1": 0.678273145070019, "test_runtime": 17.3395, "test_samples_per_second": 118.112, "test_steps_per_second": 59.056}, {"test_loss": 0.4463983178138733, "test_mcc": 0.7141466098548568, "test_macro_f1": 0.6478090361128854, "test_runtime": 17.5122, "test_samples_per_second": 116.947, "test_steps_per_second": 58.473}, {"test_loss": 0.42272642254829407, "test_mcc": 0.7225456911413565, "test_macro_f1": 0.6744035968227996, "test_runtime": 17.5912, "test_samples_per_second": 116.422, "test_steps_per_second": 58.211}, {"test_loss": 0.4582896828651428, "test_mcc": 0.7069756586878758, "test_macro_f1": 0.7327019647019647, "test_runtime": 17.4214, "test_samples_per_second": 117.556, "test_steps_per_second": 58.778}, {"test_loss": 0.4617808163166046, "test_mcc": 0.703992268925963, "test_macro_f1": 0.6811080336577534, "test_runtime": 17.8089, "test_samples_per_second": 114.999, "test_steps_per_second": 57.499}, {"test_loss": 0.43864139914512634, "test_mcc": 0.7038540384213035, "test_macro_f1": 0.6299096200256208, "test_runtime": 17.5938, "test_samples_per_second": 116.405, "test_steps_per_second": 58.202}, {"test_loss": 0.46615397930145264, "test_mcc": 0.6999137436984131, "test_macro_f1": 0.7163998358318892, "test_runtime": 17.4782, "test_samples_per_second": 117.174, "test_steps_per_second": 58.587}]}, "total": {"test_mcc": 70.5416321266584, "test_mcc_se": 1.0099418000904055, "test_macro_f1": 66.24514400389407, "test_macro_f1_se": 3.019403191696334}}, "num_model_parameters": 585841411, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "studio-ousia/mluke-base", "results": {"raw": {"test": [{"test_loss": 0.8353416919708252, "test_mcc": 0.4327632315456497, "test_macro_f1": 0.626570418840093, "test_runtime": 4.3315, "test_samples_per_second": 472.811, "test_steps_per_second": 14.775}, {"test_loss": 0.8814141750335693, "test_mcc": 0.4444973527433666, "test_macro_f1": 0.6306149558662181, "test_runtime": 4.3081, "test_samples_per_second": 475.382, "test_steps_per_second": 14.856}, {"test_loss": 0.8802743554115295, "test_mcc": 0.40122406249637005, "test_macro_f1": 0.6052984961306946, "test_runtime": 4.228, "test_samples_per_second": 484.389, "test_steps_per_second": 15.137}, {"test_loss": 0.8868106007575989, "test_mcc": 0.4135626397081641, "test_macro_f1": 0.6081725252629332, "test_runtime": 4.1752, "test_samples_per_second": 490.512, "test_steps_per_second": 15.328}, {"test_loss": 0.8924058675765991, "test_mcc": 0.3976649376964024, "test_macro_f1": 0.6054535636506454, "test_runtime": 4.1474, "test_samples_per_second": 493.801, "test_steps_per_second": 15.431}, {"test_loss": 0.888042151927948, "test_mcc": 0.43031769736091324, "test_macro_f1": 0.6194636589201015, "test_runtime": 4.1926, "test_samples_per_second": 488.476, "test_steps_per_second": 15.265}, {"test_loss": 0.8602022528648376, "test_mcc": 0.41233303548831846, "test_macro_f1": 0.5938058319373224, "test_runtime": 4.1717, "test_samples_per_second": 490.924, "test_steps_per_second": 15.341}, {"test_loss": 0.9251353740692139, "test_mcc": 0.4036089412695481, "test_macro_f1": 0.5900690452668932, "test_runtime": 4.2331, "test_samples_per_second": 483.811, "test_steps_per_second": 15.119}, {"test_loss": 0.9065503478050232, "test_mcc": 0.4610256326053216, "test_macro_f1": 0.6347078644868059, "test_runtime": 4.2038, "test_samples_per_second": 487.173, "test_steps_per_second": 15.224}, {"test_loss": 0.9073984622955322, "test_mcc": 0.38784749794160495, "test_macro_f1": 0.5948254177356879, "test_runtime": 4.1351, "test_samples_per_second": 495.271, "test_steps_per_second": 15.477}]}, "total": {"test_mcc": 41.84845028855659, "test_mcc_se": 1.4289452180279063, "test_macro_f1": 61.089817780973966, "test_macro_f1_se": 0.9967141706999102}}, "num_model_parameters": 585841411, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "studio-ousia/mluke-base", "results": {"raw": {"test": [{"test_loss": 0.8880839347839355, "test_mcc": 0.42065726667969394, "test_macro_f1": 0.4956649032315412, "test_runtime": 3.6795, "test_samples_per_second": 556.594, "test_steps_per_second": 17.394}, {"test_loss": 0.8181891441345215, "test_mcc": 0.4334242216582757, "test_macro_f1": 0.5909304275314456, "test_runtime": 3.342, "test_samples_per_second": 612.807, "test_steps_per_second": 19.15}, {"test_loss": 0.8088623285293579, "test_mcc": 0.4170651418507667, "test_macro_f1": 0.47608425410724725, "test_runtime": 3.4356, "test_samples_per_second": 596.104, "test_steps_per_second": 18.628}, {"test_loss": 0.8568017482757568, "test_mcc": 0.40296599967801355, "test_macro_f1": 0.49416624805631226, "test_runtime": 3.4648, "test_samples_per_second": 591.088, "test_steps_per_second": 18.472}, {"test_loss": 0.8095768690109253, "test_mcc": 0.417854792463383, "test_macro_f1": 0.5476480770122603, "test_runtime": 3.4641, "test_samples_per_second": 591.213, "test_steps_per_second": 18.475}, {"test_loss": 0.8320084810256958, "test_mcc": 0.40263479857940804, "test_macro_f1": 0.5027643609766547, "test_runtime": 3.5433, "test_samples_per_second": 577.986, "test_steps_per_second": 18.062}, {"test_loss": 0.8301968574523926, "test_mcc": 0.45727148397450107, "test_macro_f1": 0.5858443442989746, "test_runtime": 3.3843, "test_samples_per_second": 605.145, "test_steps_per_second": 18.911}, {"test_loss": 0.8043547868728638, "test_mcc": 0.40981909655010507, "test_macro_f1": 0.4686925618023265, "test_runtime": 3.5028, "test_samples_per_second": 584.669, "test_steps_per_second": 18.271}, {"test_loss": 0.8512269258499146, "test_mcc": 0.39131505024951196, "test_macro_f1": 0.46066227225884226, "test_runtime": 3.5933, "test_samples_per_second": 569.955, "test_steps_per_second": 17.811}, {"test_loss": 0.8230968117713928, "test_mcc": 0.40249357542447023, "test_macro_f1": 0.4635902400031348, "test_runtime": 3.583, "test_samples_per_second": 571.583, "test_steps_per_second": 17.862}]}, "total": {"test_mcc": 41.55501427108129, "test_mcc_se": 1.1704823011597716, "test_macro_f1": 50.860476892787396, "test_macro_f1_se": 3.0401577846114867}}, "num_model_parameters": 585841411, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "studio-ousia/mluke-base", "results": {"raw": {"test": [{"test_loss": 0.41545408964157104, "test_mcc": 0.6440352902629138, "test_macro_f1": 0.8169806704183997, "test_runtime": 3.1192, "test_samples_per_second": 656.589, "test_steps_per_second": 20.518}, {"test_loss": 0.4650890827178955, "test_mcc": 0.623591835389868, "test_macro_f1": 0.8085594647674854, "test_runtime": 3.2629, "test_samples_per_second": 627.663, "test_steps_per_second": 19.614}, {"test_loss": 0.5205029845237732, "test_mcc": 0.5312181674673565, "test_macro_f1": 0.7586854314397877, "test_runtime": 3.2286, "test_samples_per_second": 634.323, "test_steps_per_second": 19.823}, {"test_loss": 0.48334169387817383, "test_mcc": 0.6251693949104882, "test_macro_f1": 0.8076619288518665, "test_runtime": 3.1619, "test_samples_per_second": 647.714, "test_steps_per_second": 20.241}, {"test_loss": 0.46676602959632874, "test_mcc": 0.6008626342842074, "test_macro_f1": 0.7917379526402682, "test_runtime": 3.1877, "test_samples_per_second": 642.466, "test_steps_per_second": 20.077}, {"test_loss": 0.45722413063049316, "test_mcc": 0.6001742492719675, "test_macro_f1": 0.7946450503561777, "test_runtime": 3.1626, "test_samples_per_second": 647.566, "test_steps_per_second": 20.236}, {"test_loss": 0.42959168553352356, "test_mcc": 0.6317940715539436, "test_macro_f1": 0.8109287172393022, "test_runtime": 3.1863, "test_samples_per_second": 642.749, "test_steps_per_second": 20.086}, {"test_loss": 0.5346236824989319, "test_mcc": 0.5693447602816428, "test_macro_f1": 0.7618360296884086, "test_runtime": 3.2238, "test_samples_per_second": 635.266, "test_steps_per_second": 19.852}, {"test_loss": 0.45031577348709106, "test_mcc": 0.616191132654255, "test_macro_f1": 0.7994692259097249, "test_runtime": 3.1895, "test_samples_per_second": 642.107, "test_steps_per_second": 20.066}, {"test_loss": 0.4657999575138092, "test_mcc": 0.5926609556517269, "test_macro_f1": 0.7843900281160688, "test_runtime": 3.2255, "test_samples_per_second": 634.948, "test_steps_per_second": 19.842}]}, "total": {"test_mcc": 60.3504249172837, "test_mcc_se": 2.066508757469336, "test_macro_f1": 79.34894499427489, "test_macro_f1_se": 1.243077034678656}}, "num_model_parameters": 585840642, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "studio-ousia/mluke-base", "results": {"raw": {"test": [{"test_loss": 0.6272380352020264, "test_mcc": 0.3753982352099793, "test_macro_f1": 0.6492711097457844, "test_runtime": 3.6004, "test_samples_per_second": 568.827, "test_steps_per_second": 17.776}, {"test_loss": 0.6203895807266235, "test_mcc": 0.381070380681495, "test_macro_f1": 0.676675072886544, "test_runtime": 3.6821, "test_samples_per_second": 556.2, "test_steps_per_second": 17.381}, {"test_loss": 0.5485739707946777, "test_mcc": 0.5017704683618042, "test_macro_f1": 0.7417482742872945, "test_runtime": 3.6872, "test_samples_per_second": 555.433, "test_steps_per_second": 17.357}, {"test_loss": 0.6189786195755005, "test_mcc": 0.46392724058508783, "test_macro_f1": 0.715523266529715, "test_runtime": 3.7422, "test_samples_per_second": 547.269, "test_steps_per_second": 17.102}, {"test_loss": 0.5979312658309937, "test_mcc": 0.4673164859335281, "test_macro_f1": 0.7312538318400361, "test_runtime": 3.559, "test_samples_per_second": 575.44, "test_steps_per_second": 17.983}, {"test_loss": 0.5597540140151978, "test_mcc": 0.4622566194276632, "test_macro_f1": 0.7245878882526462, "test_runtime": 3.579, "test_samples_per_second": 572.224, "test_steps_per_second": 17.882}, {"test_loss": 0.6415606737136841, "test_mcc": 0.4193903301598663, "test_macro_f1": 0.6846684633157983, "test_runtime": 3.486, "test_samples_per_second": 587.491, "test_steps_per_second": 18.359}, {"test_loss": 0.6315377950668335, "test_mcc": 0.33003032578848046, "test_macro_f1": 0.6345423558897243, "test_runtime": 3.5598, "test_samples_per_second": 575.317, "test_steps_per_second": 17.979}, {"test_loss": 0.6370676755905151, "test_mcc": 0.3397471335995109, "test_macro_f1": 0.6330597768334918, "test_runtime": 3.5677, "test_samples_per_second": 574.046, "test_steps_per_second": 17.939}, {"test_loss": 0.6198350191116333, "test_mcc": 0.418019832777586, "test_macro_f1": 0.6826630031424196, "test_runtime": 3.6526, "test_samples_per_second": 560.702, "test_steps_per_second": 17.522}]}, "total": {"test_mcc": 41.589270525250015, "test_mcc_se": 3.6090960795874643, "test_macro_f1": 68.73993042723454, "test_macro_f1_se": 2.478905241590229}}, "num_model_parameters": 585840642, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "studio-ousia/mluke-base", "results": {"raw": {"test": [{"test_loss": 0.5823782682418823, "test_mcc": 0.3996478062180285, "test_macro_f1": 0.6836902021497113, "test_runtime": 3.2397, "test_samples_per_second": 632.152, "test_steps_per_second": 19.755}, {"test_loss": 0.5577560067176819, "test_mcc": 0.5302121732895101, "test_macro_f1": 0.7529033852236224, "test_runtime": 3.2335, "test_samples_per_second": 633.369, "test_steps_per_second": 19.793}, {"test_loss": 0.5948773622512817, "test_mcc": 0.3917432217672521, "test_macro_f1": 0.6778162758930482, "test_runtime": 3.2599, "test_samples_per_second": 628.242, "test_steps_per_second": 19.633}, {"test_loss": 0.5546085834503174, "test_mcc": 0.5011241840462887, "test_macro_f1": 0.7493536493949546, "test_runtime": 3.329, "test_samples_per_second": 615.208, "test_steps_per_second": 19.225}, {"test_loss": 0.5933535695075989, "test_mcc": 0.48471922314646326, "test_macro_f1": 0.7203480324691464, "test_runtime": 3.3314, "test_samples_per_second": 614.757, "test_steps_per_second": 19.211}, {"test_loss": 0.6215606331825256, "test_mcc": 0.36428139869908366, "test_macro_f1": 0.6345176003763475, "test_runtime": 3.1559, "test_samples_per_second": 648.942, "test_steps_per_second": 20.279}, {"test_loss": 0.5838317275047302, "test_mcc": 0.5209657250746694, "test_macro_f1": 0.7580988542768001, "test_runtime": 3.2001, "test_samples_per_second": 639.986, "test_steps_per_second": 20.0}, {"test_loss": 0.5738407373428345, "test_mcc": 0.44914310131701435, "test_macro_f1": 0.7245715506585072, "test_runtime": 3.2217, "test_samples_per_second": 635.69, "test_steps_per_second": 19.865}, {"test_loss": 0.610090434551239, "test_mcc": 0.42164182190826094, "test_macro_f1": 0.68255404916433, "test_runtime": 3.1498, "test_samples_per_second": 650.202, "test_steps_per_second": 20.319}, {"test_loss": 0.6221335530281067, "test_mcc": 0.35807079000767256, "test_macro_f1": 0.6370855596502769, "test_runtime": 3.2825, "test_samples_per_second": 623.913, "test_steps_per_second": 19.497}]}, "total": {"test_mcc": 44.215494454742434, "test_mcc_se": 3.9851490572901667, "test_macro_f1": 70.20939159256744, "test_macro_f1_se": 2.8397572219786236}}, "num_model_parameters": 585840642, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "studio-ousia/mluke-base", "results": {"raw": {"test": [{"test_loss": 0.6418638229370117, "test_mcc": 0.2460404942701434, "test_macro_f1": 0.6230022383382576, "test_runtime": 3.4427, "test_samples_per_second": 594.886, "test_steps_per_second": 18.59}, {"test_loss": 0.6197205781936646, "test_mcc": 0.38948896923677145, "test_macro_f1": 0.6942612942612942, "test_runtime": 3.5179, "test_samples_per_second": 582.172, "test_steps_per_second": 18.193}, {"test_loss": 0.6595435738563538, "test_mcc": 0.2546960849535429, "test_macro_f1": 0.5986836594267935, "test_runtime": 3.5777, "test_samples_per_second": 572.442, "test_steps_per_second": 17.889}, {"test_loss": 0.6425535678863525, "test_mcc": 0.25824676618149633, "test_macro_f1": 0.6130736800355039, "test_runtime": 3.3881, "test_samples_per_second": 604.477, "test_steps_per_second": 18.89}, {"test_loss": 0.6287298202514648, "test_mcc": 0.2879021080596101, "test_macro_f1": 0.6438124725264225, "test_runtime": 3.4098, "test_samples_per_second": 600.629, "test_steps_per_second": 18.77}, {"test_loss": 0.6268375515937805, "test_mcc": 0.30661194735683195, "test_macro_f1": 0.651882812997751, "test_runtime": 3.5336, "test_samples_per_second": 579.572, "test_steps_per_second": 18.112}, {"test_loss": 0.6569956541061401, "test_mcc": 0.27323192415422193, "test_macro_f1": 0.6345323472900173, "test_runtime": 3.4483, "test_samples_per_second": 593.923, "test_steps_per_second": 18.56}, {"test_loss": 0.6032006740570068, "test_mcc": 0.34968493335135303, "test_macro_f1": 0.6747842453560307, "test_runtime": 3.425, "test_samples_per_second": 597.952, "test_steps_per_second": 18.686}, {"test_loss": 0.6416085362434387, "test_mcc": 0.25554016217796915, "test_macro_f1": 0.6233361252621679, "test_runtime": 3.4179, "test_samples_per_second": 599.206, "test_steps_per_second": 18.725}, {"test_loss": 0.6465180516242981, "test_mcc": 0.32979752615364366, "test_macro_f1": 0.6648981285807649, "test_runtime": 3.5134, "test_samples_per_second": 582.914, "test_steps_per_second": 18.216}]}, "total": {"test_mcc": 29.512409158955844, "test_mcc_se": 2.9737581336037886, "test_macro_f1": 64.22267004075003, "test_macro_f1_se": 1.8373509916009036}}, "num_model_parameters": 585840642, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "studio-ousia/mluke-base", "results": {"raw": {"test": [{"test_speed": 1.89}, {"test_speed": 1.91}, {"test_speed": 1.95}, {"test_speed": 1.92}, {"test_speed": 1.93}, {"test_speed": 1.95}, {"test_speed": 1.96}, {"test_speed": 1.9}, {"test_speed": 1.96}, {"test_speed": 1.95}]}, "total": {"test_speed": 1.932, "test_speed_se": 0.01594989933789205}}, "num_model_parameters": 585839104, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.3973894715309143, "test_mcc": 0.7331322247671131, "test_macro_f1": 0.6777573258775919, "test_runtime": 11.3955, "test_samples_per_second": 179.72, "test_steps_per_second": 22.465}, {"test_loss": 0.39591479301452637, "test_mcc": 0.7578218985240565, "test_macro_f1": 0.7268968150205621, "test_runtime": 10.9221, "test_samples_per_second": 187.51, "test_steps_per_second": 23.439}, {"test_loss": 0.41678035259246826, "test_mcc": 0.7314403557725113, "test_macro_f1": 0.7066888895581384, "test_runtime": 11.2135, "test_samples_per_second": 182.637, "test_steps_per_second": 22.83}, {"test_loss": 0.356491357088089, "test_mcc": 0.7760933748404955, "test_macro_f1": 0.7722990968174493, "test_runtime": 10.9196, "test_samples_per_second": 187.553, "test_steps_per_second": 23.444}, {"test_loss": 0.40374496579170227, "test_mcc": 0.7281911298740653, "test_macro_f1": 0.7446915378309015, "test_runtime": 11.0573, "test_samples_per_second": 185.217, "test_steps_per_second": 23.152}, {"test_loss": 0.3551488518714905, "test_mcc": 0.7730642923168473, "test_macro_f1": 0.7563174696792728, "test_runtime": 11.154, "test_samples_per_second": 183.612, "test_steps_per_second": 22.951}, {"test_loss": 0.3812483251094818, "test_mcc": 0.7731771750908916, "test_macro_f1": 0.7674736757557135, "test_runtime": 10.9291, "test_samples_per_second": 187.389, "test_steps_per_second": 23.424}, {"test_loss": 0.3868224024772644, "test_mcc": 0.7520136840212456, "test_macro_f1": 0.7452091971891469, "test_runtime": 11.3672, "test_samples_per_second": 180.167, "test_steps_per_second": 22.521}, {"test_loss": 0.41304975748062134, "test_mcc": 0.7203581218525777, "test_macro_f1": 0.6559275240951368, "test_runtime": 11.3103, "test_samples_per_second": 181.074, "test_steps_per_second": 22.634}, {"test_loss": 0.3693065941333771, "test_mcc": 0.7635099509765823, "test_macro_f1": 0.7398231856448505, "test_runtime": 11.0541, "test_samples_per_second": 185.27, "test_steps_per_second": 23.159}]}, "total": {"test_mcc": 75.08802208036387, "test_mcc_se": 1.3022926512726258, "test_macro_f1": 72.93084717468764, "test_macro_f1_se": 2.3731418798023096}}, "num_model_parameters": 470929155, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.7893645167350769, "test_mcc": 0.48845926550421376, "test_macro_f1": 0.659677945192804, "test_runtime": 3.3626, "test_samples_per_second": 609.048, "test_steps_per_second": 19.033}, {"test_loss": 0.7935441136360168, "test_mcc": 0.49368143343518966, "test_macro_f1": 0.6592836876390357, "test_runtime": 3.2618, "test_samples_per_second": 627.879, "test_steps_per_second": 19.621}, {"test_loss": 0.8401949405670166, "test_mcc": 0.4689157582163409, "test_macro_f1": 0.6457006422415228, "test_runtime": 3.3628, "test_samples_per_second": 609.022, "test_steps_per_second": 19.032}, {"test_loss": 0.8175356388092041, "test_mcc": 0.485693789618124, "test_macro_f1": 0.6575849158636949, "test_runtime": 3.2207, "test_samples_per_second": 635.884, "test_steps_per_second": 19.871}, {"test_loss": 0.7896530628204346, "test_mcc": 0.45305382873908956, "test_macro_f1": 0.6391001524628953, "test_runtime": 3.3242, "test_samples_per_second": 616.081, "test_steps_per_second": 19.253}, {"test_loss": 0.8273547887802124, "test_mcc": 0.4775206169445198, "test_macro_f1": 0.651714653012767, "test_runtime": 3.2666, "test_samples_per_second": 626.95, "test_steps_per_second": 19.592}, {"test_loss": 0.7952802181243896, "test_mcc": 0.4831388135230303, "test_macro_f1": 0.6552140107335588, "test_runtime": 3.2308, "test_samples_per_second": 633.907, "test_steps_per_second": 19.81}, {"test_loss": 0.8052774667739868, "test_mcc": 0.4903134563219029, "test_macro_f1": 0.6537577069370826, "test_runtime": 3.2414, "test_samples_per_second": 631.824, "test_steps_per_second": 19.745}, {"test_loss": 0.7933229207992554, "test_mcc": 0.4798950634149697, "test_macro_f1": 0.6540587111628019, "test_runtime": 3.2209, "test_samples_per_second": 635.838, "test_steps_per_second": 19.87}, {"test_loss": 0.8049730062484741, "test_mcc": 0.48275210490413745, "test_macro_f1": 0.6577563491287207, "test_runtime": 3.2178, "test_samples_per_second": 636.45, "test_steps_per_second": 19.889}]}, "total": {"test_mcc": 48.03424130621517, "test_mcc_se": 0.7359492156929165, "test_macro_f1": 65.33848774374883, "test_macro_f1_se": 0.40325965804859565}}, "num_model_parameters": 470929155, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.744400143623352, "test_mcc": 0.5936579465992557, "test_macro_f1": 0.7250429987527518, "test_runtime": 2.8689, "test_samples_per_second": 713.871, "test_steps_per_second": 22.308}, {"test_loss": 0.7294998168945312, "test_mcc": 0.5238160842463031, "test_macro_f1": 0.6718459319874951, "test_runtime": 2.8124, "test_samples_per_second": 728.193, "test_steps_per_second": 22.756}, {"test_loss": 0.6959563493728638, "test_mcc": 0.547565009214781, "test_macro_f1": 0.6774592164090568, "test_runtime": 2.7758, "test_samples_per_second": 737.803, "test_steps_per_second": 23.056}, {"test_loss": 0.7303937077522278, "test_mcc": 0.5821593003219223, "test_macro_f1": 0.704898702765036, "test_runtime": 2.8144, "test_samples_per_second": 727.68, "test_steps_per_second": 22.74}, {"test_loss": 0.7397818565368652, "test_mcc": 0.5546470605067795, "test_macro_f1": 0.6953899620422216, "test_runtime": 2.8287, "test_samples_per_second": 724.008, "test_steps_per_second": 22.625}, {"test_loss": 0.7412004470825195, "test_mcc": 0.5572813388991611, "test_macro_f1": 0.6943140044327626, "test_runtime": 2.8545, "test_samples_per_second": 717.465, "test_steps_per_second": 22.421}, {"test_loss": 0.6761797666549683, "test_mcc": 0.563834878132519, "test_macro_f1": 0.6787158763256135, "test_runtime": 2.8382, "test_samples_per_second": 721.586, "test_steps_per_second": 22.55}, {"test_loss": 0.6955075860023499, "test_mcc": 0.5757237392497372, "test_macro_f1": 0.6940459132359731, "test_runtime": 2.8168, "test_samples_per_second": 727.069, "test_steps_per_second": 22.721}, {"test_loss": 0.6989791393280029, "test_mcc": 0.5567333215387312, "test_macro_f1": 0.6813476524497988, "test_runtime": 2.8786, "test_samples_per_second": 711.453, "test_steps_per_second": 22.233}, {"test_loss": 0.7111515998840332, "test_mcc": 0.5796085884872463, "test_macro_f1": 0.7075733536544085, "test_runtime": 2.8401, "test_samples_per_second": 721.112, "test_steps_per_second": 22.535}]}, "total": {"test_mcc": 56.350272671964355, "test_mcc_se": 1.2496032987001224, "test_macro_f1": 69.30633612055118, "test_macro_f1_se": 1.0159347593754307}}, "num_model_parameters": 470929155, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.055712781846523285, "test_micro_f1": 0.7401656314699793, "test_micro_f1_no_misc": 0.8224414303329224, "test_runtime": 6.0748, "test_samples_per_second": 337.13, "test_steps_per_second": 10.535}, {"test_loss": 0.053507037460803986, "test_micro_f1": 0.7186009538950715, "test_micro_f1_no_misc": 0.7798896382587369, "test_runtime": 5.7606, "test_samples_per_second": 355.519, "test_steps_per_second": 11.11}, {"test_loss": 0.05636623501777649, "test_micro_f1": 0.7223563495895703, "test_micro_f1_no_misc": 0.7758433079434168, "test_runtime": 5.5374, "test_samples_per_second": 369.846, "test_steps_per_second": 11.558}, {"test_loss": 0.05670858174562454, "test_micro_f1": 0.7121137812653261, "test_micro_f1_no_misc": 0.7731188971855255, "test_runtime": 6.0029, "test_samples_per_second": 341.168, "test_steps_per_second": 10.661}, {"test_loss": 0.053016915917396545, "test_micro_f1": 0.7676864244741873, "test_micro_f1_no_misc": 0.8166311300639659, "test_runtime": 5.9872, "test_samples_per_second": 342.065, "test_steps_per_second": 10.69}, {"test_loss": 0.04849742352962494, "test_micro_f1": 0.7755868544600939, "test_micro_f1_no_misc": 0.818082788671024, "test_runtime": 5.1976, "test_samples_per_second": 394.029, "test_steps_per_second": 12.313}, {"test_loss": 0.054829951375722885, "test_micro_f1": 0.7443946188340806, "test_micro_f1_no_misc": 0.8024971623155506, "test_runtime": 5.4541, "test_samples_per_second": 375.495, "test_steps_per_second": 11.734}, {"test_loss": 0.05066612362861633, "test_micro_f1": 0.7474310438074634, "test_micro_f1_no_misc": 0.7992565055762082, "test_runtime": 5.9745, "test_samples_per_second": 342.789, "test_steps_per_second": 10.712}, {"test_loss": 0.048087190836668015, "test_micro_f1": 0.7508369201339071, "test_micro_f1_no_misc": 0.8046230049532195, "test_runtime": 5.8114, "test_samples_per_second": 352.413, "test_steps_per_second": 11.013}, {"test_loss": 0.051864560693502426, "test_micro_f1": 0.7413280475718533, "test_micro_f1_no_misc": 0.8122827346465816, "test_runtime": 5.9988, "test_samples_per_second": 341.403, "test_steps_per_second": 10.669}]}, "total": {"test_micro_f1": 74.20500625501532, "test_micro_f1_se": 1.2620595061541109, "test_micro_f1_no_misc": 80.04666599947153, "test_micro_f1_no_misc_se": 1.1305903169706388}}, "num_model_parameters": 470343177, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.05480889230966568, "test_micro_f1": 0.8141414141414142, "test_micro_f1_no_misc": 0.8356164383561644, "test_runtime": 7.1293, "test_samples_per_second": 287.267, "test_steps_per_second": 8.977}, {"test_loss": 0.050805844366550446, "test_micro_f1": 0.8100621820237422, "test_micro_f1_no_misc": 0.8340110905730129, "test_runtime": 5.8663, "test_samples_per_second": 349.11, "test_steps_per_second": 10.91}, {"test_loss": 0.05518941581249237, "test_micro_f1": 0.836083022884513, "test_micro_f1_no_misc": 0.856936936936937, "test_runtime": 7.13, "test_samples_per_second": 287.237, "test_steps_per_second": 8.976}, {"test_loss": 0.06230958178639412, "test_micro_f1": 0.8220250521920669, "test_micro_f1_no_misc": 0.8390557939914162, "test_runtime": 6.9422, "test_samples_per_second": 295.007, "test_steps_per_second": 9.219}, {"test_loss": 0.05896417051553726, "test_micro_f1": 0.7905788876276957, "test_micro_f1_no_misc": 0.8130518234165066, "test_runtime": 7.0467, "test_samples_per_second": 290.632, "test_steps_per_second": 9.082}, {"test_loss": 0.05723704397678375, "test_micro_f1": 0.8224299065420559, "test_micro_f1_no_misc": 0.8390977443609021, "test_runtime": 7.173, "test_samples_per_second": 285.513, "test_steps_per_second": 8.922}, {"test_loss": 0.05264776945114136, "test_micro_f1": 0.8110381077529566, "test_micro_f1_no_misc": 0.8347398030942336, "test_runtime": 7.2552, "test_samples_per_second": 282.279, "test_steps_per_second": 8.821}, {"test_loss": 0.04680664837360382, "test_micro_f1": 0.8339320254213871, "test_micro_f1_no_misc": 0.8576779026217229, "test_runtime": 7.2016, "test_samples_per_second": 284.38, "test_steps_per_second": 8.887}, {"test_loss": 0.05603567138314247, "test_micro_f1": 0.8349720967313313, "test_micro_f1_no_misc": 0.8555555555555554, "test_runtime": 7.0557, "test_samples_per_second": 290.263, "test_steps_per_second": 9.071}, {"test_loss": 0.054655544459819794, "test_micro_f1": 0.8161263960773633, "test_micro_f1_no_misc": 0.8407460545193688, "test_runtime": 6.0651, "test_samples_per_second": 337.67, "test_steps_per_second": 10.552}]}, "total": {"test_micro_f1": 81.91389091394527, "test_micro_f1_se": 0.8700684519634372, "test_micro_f1_no_misc": 84.06489143425819, "test_micro_f1_no_misc_se": 0.8388024546420125}}, "num_model_parameters": 470343177, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.03419795632362366, "test_micro_f1": 0.8746784270488791, "test_micro_f1_no_misc": 0.8997920997920998, "test_runtime": 5.5679, "test_samples_per_second": 367.825, "test_steps_per_second": 11.495}, {"test_loss": 0.031027652323246002, "test_micro_f1": 0.879245283018868, "test_micro_f1_no_misc": 0.9039026437263954, "test_runtime": 5.5034, "test_samples_per_second": 372.134, "test_steps_per_second": 11.629}, {"test_loss": 0.03676536679267883, "test_micro_f1": 0.8574438202247192, "test_micro_f1_no_misc": 0.8920298390263055, "test_runtime": 5.3508, "test_samples_per_second": 382.744, "test_steps_per_second": 11.961}, {"test_loss": 0.030664922669529915, "test_micro_f1": 0.8632388947184331, "test_micro_f1_no_misc": 0.8990825688073395, "test_runtime": 5.2721, "test_samples_per_second": 388.457, "test_steps_per_second": 12.139}, {"test_loss": 0.0260564386844635, "test_micro_f1": 0.9100707308858201, "test_micro_f1_no_misc": 0.9258003766478342, "test_runtime": 5.5969, "test_samples_per_second": 365.915, "test_steps_per_second": 11.435}, {"test_loss": 0.0321882888674736, "test_micro_f1": 0.8548168249660788, "test_micro_f1_no_misc": 0.8947566955865711, "test_runtime": 5.635, "test_samples_per_second": 363.441, "test_steps_per_second": 11.358}, {"test_loss": 0.03432043641805649, "test_micro_f1": 0.8523466940733129, "test_micro_f1_no_misc": 0.8846008323874386, "test_runtime": 5.3947, "test_samples_per_second": 379.628, "test_steps_per_second": 11.863}, {"test_loss": 0.030464617535471916, "test_micro_f1": 0.8621761658031087, "test_micro_f1_no_misc": 0.889475669558657, "test_runtime": 5.3062, "test_samples_per_second": 385.961, "test_steps_per_second": 12.061}, {"test_loss": 0.032789409160614014, "test_micro_f1": 0.8740043446777698, "test_micro_f1_no_misc": 0.9031467102574582, "test_runtime": 5.3455, "test_samples_per_second": 383.124, "test_steps_per_second": 11.973}, {"test_loss": 0.03402210772037506, "test_micro_f1": 0.8836088154269973, "test_micro_f1_no_misc": 0.9156346749226006, "test_runtime": 5.5968, "test_samples_per_second": 365.922, "test_steps_per_second": 11.435}]}, "total": {"test_micro_f1": 87.11630000843988, "test_micro_f1_se": 1.0750234107464667, "test_micro_f1_no_misc": 90.082221107127, "test_micro_f1_no_misc_se": 0.7642243901162085}}, "num_model_parameters": 470343177, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.04132770746946335, "test_micro_f1": 0.8391478851497376, "test_micro_f1_no_misc": 0.8761969904240766, "test_runtime": 5.7671, "test_samples_per_second": 355.118, "test_steps_per_second": 11.097}, {"test_loss": 0.04839636757969856, "test_micro_f1": 0.8288996372430472, "test_micro_f1_no_misc": 0.8661850705194358, "test_runtime": 5.6058, "test_samples_per_second": 365.337, "test_steps_per_second": 11.417}, {"test_loss": 0.04731379449367523, "test_micro_f1": 0.8067327923053802, "test_micro_f1_no_misc": 0.8521855188521855, "test_runtime": 5.3827, "test_samples_per_second": 380.476, "test_steps_per_second": 11.89}, {"test_loss": 0.056845322251319885, "test_micro_f1": 0.8157099697885195, "test_micro_f1_no_misc": 0.8533694547917372, "test_runtime": 5.4476, "test_samples_per_second": 375.943, "test_steps_per_second": 11.748}, {"test_loss": 0.0576174221932888, "test_micro_f1": 0.8052884615384616, "test_micro_f1_no_misc": 0.85556704584626, "test_runtime": 5.3606, "test_samples_per_second": 382.047, "test_steps_per_second": 11.939}, {"test_loss": 0.05019032955169678, "test_micro_f1": 0.8183703703703703, "test_micro_f1_no_misc": 0.8651761517615175, "test_runtime": 5.4303, "test_samples_per_second": 377.141, "test_steps_per_second": 11.786}, {"test_loss": 0.04525058716535568, "test_micro_f1": 0.8195812807881773, "test_micro_f1_no_misc": 0.8635253054101222, "test_runtime": 5.6001, "test_samples_per_second": 365.71, "test_steps_per_second": 11.428}, {"test_loss": 0.04448501020669937, "test_micro_f1": 0.8374961455442491, "test_micro_f1_no_misc": 0.8759372869802318, "test_runtime": 5.8493, "test_samples_per_second": 350.13, "test_steps_per_second": 10.942}, {"test_loss": 0.054071418941020966, "test_micro_f1": 0.7880633373934226, "test_micro_f1_no_misc": 0.8336769759450172, "test_runtime": 5.1344, "test_samples_per_second": 398.875, "test_steps_per_second": 12.465}, {"test_loss": 0.048651911318302155, "test_micro_f1": 0.8297742525930445, "test_micro_f1_no_misc": 0.8626282687851704, "test_runtime": 5.2957, "test_samples_per_second": 386.728, "test_steps_per_second": 12.085}]}, "total": {"test_micro_f1": 81.89064132714408, "test_micro_f1_se": 0.9841661214832778, "test_micro_f1_no_misc": 86.04448069315754, "test_micro_f1_no_misc_se": 0.7775290398611033}}, "num_model_parameters": 470343177, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.4383699297904968, "test_mcc": 0.6385067256111544, "test_macro_f1": 0.8105606821778544, "test_runtime": 2.8343, "test_samples_per_second": 722.577, "test_steps_per_second": 22.581}, {"test_loss": 0.4878910481929779, "test_mcc": 0.6110612632436125, "test_macro_f1": 0.7849673914340971, "test_runtime": 2.8222, "test_samples_per_second": 725.672, "test_steps_per_second": 22.677}, {"test_loss": 0.4665869474411011, "test_mcc": 0.6166267756988361, "test_macro_f1": 0.7928469016989099, "test_runtime": 2.8544, "test_samples_per_second": 717.496, "test_steps_per_second": 22.422}, {"test_loss": 0.4700920581817627, "test_mcc": 0.6298518054002822, "test_macro_f1": 0.8060274861896854, "test_runtime": 2.7609, "test_samples_per_second": 741.78, "test_steps_per_second": 23.181}, {"test_loss": 0.4746446907520294, "test_mcc": 0.5714166570033161, "test_macro_f1": 0.7725116455994643, "test_runtime": 2.7957, "test_samples_per_second": 732.557, "test_steps_per_second": 22.892}, {"test_loss": 0.5447163581848145, "test_mcc": 0.5986635900586863, "test_macro_f1": 0.7993163584032914, "test_runtime": 2.8004, "test_samples_per_second": 731.319, "test_steps_per_second": 22.854}, {"test_loss": 0.45623382925987244, "test_mcc": 0.6331756228928911, "test_macro_f1": 0.8088314967661598, "test_runtime": 2.7663, "test_samples_per_second": 740.332, "test_steps_per_second": 23.135}, {"test_loss": 0.5010287761688232, "test_mcc": 0.6212665764854252, "test_macro_f1": 0.8045876486382815, "test_runtime": 2.7873, "test_samples_per_second": 734.774, "test_steps_per_second": 22.962}, {"test_loss": 0.432862788438797, "test_mcc": 0.6376777517657097, "test_macro_f1": 0.8172117702656625, "test_runtime": 2.7558, "test_samples_per_second": 743.162, "test_steps_per_second": 23.224}, {"test_loss": 0.4677025079727173, "test_mcc": 0.6246007660606842, "test_macro_f1": 0.7996075938632725, "test_runtime": 2.8875, "test_samples_per_second": 709.266, "test_steps_per_second": 22.165}]}, "total": {"test_mcc": 61.82847534220597, "test_mcc_se": 1.2779090989745616, "test_macro_f1": 79.96468975036679, "test_macro_f1_se": 0.8199986085208203}}, "num_model_parameters": 470928386, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.5375360250473022, "test_mcc": 0.5397618547348222, "test_macro_f1": 0.7486006088579004, "test_runtime": 3.0283, "test_samples_per_second": 676.296, "test_steps_per_second": 21.134}, {"test_loss": 0.5209235548973083, "test_mcc": 0.5478515008678452, "test_macro_f1": 0.7610134707670468, "test_runtime": 2.9965, "test_samples_per_second": 683.469, "test_steps_per_second": 21.358}, {"test_loss": 0.5110871195793152, "test_mcc": 0.5951782082772379, "test_macro_f1": 0.7961344900232021, "test_runtime": 3.0486, "test_samples_per_second": 671.793, "test_steps_per_second": 20.994}, {"test_loss": 0.5392769575119019, "test_mcc": 0.5939214292349295, "test_macro_f1": 0.783812274273617, "test_runtime": 3.0352, "test_samples_per_second": 674.746, "test_steps_per_second": 21.086}, {"test_loss": 0.5175138115882874, "test_mcc": 0.5910525673840054, "test_macro_f1": 0.7884409338349405, "test_runtime": 2.944, "test_samples_per_second": 695.649, "test_steps_per_second": 21.739}, {"test_loss": 0.5060052871704102, "test_mcc": 0.5792738644311511, "test_macro_f1": 0.7836426225997143, "test_runtime": 2.9506, "test_samples_per_second": 694.087, "test_steps_per_second": 21.69}, {"test_loss": 0.5470958948135376, "test_mcc": 0.4857749094845956, "test_macro_f1": 0.7220227682169007, "test_runtime": 2.8989, "test_samples_per_second": 706.474, "test_steps_per_second": 22.077}, {"test_loss": 0.5295854806900024, "test_mcc": 0.5434630386890367, "test_macro_f1": 0.7663262004899015, "test_runtime": 2.9543, "test_samples_per_second": 693.228, "test_steps_per_second": 21.663}, {"test_loss": 0.561638593673706, "test_mcc": 0.5100315448985591, "test_macro_f1": 0.7307692307692307, "test_runtime": 3.0102, "test_samples_per_second": 680.353, "test_steps_per_second": 21.261}, {"test_loss": 0.5256767272949219, "test_mcc": 0.5451087774568611, "test_macro_f1": 0.748140784188105, "test_runtime": 2.9854, "test_samples_per_second": 686.01, "test_steps_per_second": 21.438}]}, "total": {"test_mcc": 55.31417695459043, "test_mcc_se": 2.292460828806608, "test_macro_f1": 76.28903384020559, "test_macro_f1_se": 1.5687332758919896}}, "num_model_parameters": 470928386, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.4756329655647278, "test_mcc": 0.5813452832753976, "test_macro_f1": 0.777030490229059, "test_runtime": 2.7966, "test_samples_per_second": 732.321, "test_steps_per_second": 22.885}, {"test_loss": 0.5120596885681152, "test_mcc": 0.5979836494297608, "test_macro_f1": 0.7749147137782675, "test_runtime": 2.7701, "test_samples_per_second": 739.329, "test_steps_per_second": 23.104}, {"test_loss": 0.46858635544776917, "test_mcc": 0.6068710103529878, "test_macro_f1": 0.7902995062070238, "test_runtime": 2.7564, "test_samples_per_second": 743.0, "test_steps_per_second": 23.219}, {"test_loss": 0.4529000520706177, "test_mcc": 0.6213656757858904, "test_macro_f1": 0.8103730855323759, "test_runtime": 2.8059, "test_samples_per_second": 729.884, "test_steps_per_second": 22.809}, {"test_loss": 0.5251806974411011, "test_mcc": 0.612538331118334, "test_macro_f1": 0.7781260680992307, "test_runtime": 2.8539, "test_samples_per_second": 717.61, "test_steps_per_second": 22.425}, {"test_loss": 0.458207905292511, "test_mcc": 0.6231587331904108, "test_macro_f1": 0.7972886244553963, "test_runtime": 2.7485, "test_samples_per_second": 745.139, "test_steps_per_second": 23.286}, {"test_loss": 0.5322991609573364, "test_mcc": 0.5059875230284765, "test_macro_f1": 0.7329951524776884, "test_runtime": 2.7107, "test_samples_per_second": 755.535, "test_steps_per_second": 23.61}, {"test_loss": 0.46204984188079834, "test_mcc": 0.6116012903096764, "test_macro_f1": 0.8019370403104908, "test_runtime": 2.7431, "test_samples_per_second": 746.588, "test_steps_per_second": 23.331}, {"test_loss": 0.6010700464248657, "test_mcc": 0.5409173779750525, "test_macro_f1": 0.7336322257441175, "test_runtime": 2.7106, "test_samples_per_second": 755.557, "test_steps_per_second": 23.611}, {"test_loss": 0.48939356207847595, "test_mcc": 0.6359714863669421, "test_macro_f1": 0.8050596862534739, "test_runtime": 2.8459, "test_samples_per_second": 719.64, "test_steps_per_second": 22.489}]}, "total": {"test_mcc": 59.37740360832928, "test_mcc_se": 2.5235347582790633, "test_macro_f1": 78.01656593087122, "test_macro_f1_se": 1.7079467685935878}}, "num_model_parameters": 470928386, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_loss": 0.5438512563705444, "test_mcc": 0.48091891414375304, "test_macro_f1": 0.7261653860956656, "test_runtime": 2.9426, "test_samples_per_second": 695.991, "test_steps_per_second": 21.75}, {"test_loss": 0.6018388867378235, "test_mcc": 0.3826791154515812, "test_macro_f1": 0.6570310666793076, "test_runtime": 2.9132, "test_samples_per_second": 702.997, "test_steps_per_second": 21.969}, {"test_loss": 0.5587742924690247, "test_mcc": 0.4724617972724739, "test_macro_f1": 0.7204298301815033, "test_runtime": 2.9176, "test_samples_per_second": 701.946, "test_steps_per_second": 21.936}, {"test_loss": 0.5573972463607788, "test_mcc": 0.49583599336804646, "test_macro_f1": 0.7307524137034542, "test_runtime": 2.8772, "test_samples_per_second": 711.809, "test_steps_per_second": 22.244}, {"test_loss": 0.5706594586372375, "test_mcc": 0.4411469596176263, "test_macro_f1": 0.6965264763565047, "test_runtime": 2.8801, "test_samples_per_second": 711.081, "test_steps_per_second": 22.221}, {"test_loss": 0.5469015836715698, "test_mcc": 0.4903598713992934, "test_macro_f1": 0.7275553392069503, "test_runtime": 3.0213, "test_samples_per_second": 677.863, "test_steps_per_second": 21.183}, {"test_loss": 0.6211432218551636, "test_mcc": 0.3871464277419036, "test_macro_f1": 0.6808672086720866, "test_runtime": 2.8974, "test_samples_per_second": 706.831, "test_steps_per_second": 22.088}, {"test_loss": 0.5364446640014648, "test_mcc": 0.5223045151539991, "test_macro_f1": 0.757297144604002, "test_runtime": 2.8754, "test_samples_per_second": 712.253, "test_steps_per_second": 22.258}, {"test_loss": 0.5641471147537231, "test_mcc": 0.44501417731009313, "test_macro_f1": 0.7197620761646837, "test_runtime": 2.8592, "test_samples_per_second": 716.294, "test_steps_per_second": 22.384}, {"test_loss": 0.5164223313331604, "test_mcc": 0.5364348678996163, "test_macro_f1": 0.761747120843941, "test_runtime": 2.9185, "test_samples_per_second": 701.729, "test_steps_per_second": 21.929}]}, "total": {"test_mcc": 46.543026393583865, "test_mcc_se": 3.2069467943998986, "test_macro_f1": 71.78134062508099, "test_macro_f1_se": 1.9971606349284226}}, "num_model_parameters": 470928386, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_em": 52.98218435321456, "test_f1": 57.36021272701612}, {"test_em": 52.4031007751938, "test_f1": 56.726329975545}, {"test_em": 52.47295208655332, "test_f1": 56.34843564161901}, {"test_em": 48.67601246105919, "test_f1": 52.73294741835743}, {"test_em": 48.88030888030888, "test_f1": 54.04154414709766}, {"test_em": 51.657671549730146, "test_f1": 56.28351880418798}, {"test_em": 38.344722854973426, "test_f1": 42.89616739151989}, {"test_em": 49.72847168347556, "test_f1": 54.53570302812637}, {"test_em": 50.8235294117647, "test_f1": 55.90969310403641}, {"test_em": 45.65217391304348, "test_f1": 50.69316248366493}]}, "total": {"test_em": 49.16211279693171, "test_em_se": 2.7332361496004296, "test_f1": 53.75277147211708, "test_f1_se": 2.6827558020440927}}, "num_model_parameters": 470337794, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_em": 53.29202168861348, "test_f1": 58.49444600457071}, {"test_em": 44.10852713178294, "test_f1": 49.79392081213665}, {"test_em": 52.31839258114374, "test_f1": 56.90805568105417}, {"test_em": 48.83177570093458, "test_f1": 54.45568535084171}, {"test_em": 52.277992277992276, "test_f1": 57.31013460097932}, {"test_em": 53.5851966075559, "test_f1": 58.91055196095879}, {"test_em": 51.3287775246773, "test_f1": 56.96606617944867}, {"test_em": 53.995345228859584, "test_f1": 58.46353578742667}, {"test_em": 51.529411764705884, "test_f1": 56.82394543631588}, {"test_em": 53.338509316770185, "test_f1": 59.215982372903575}]}, "total": {"test_em": 51.46059498230359, "test_em_se": 1.850320696564342, "test_f1": 56.73423241866361, "test_f1_se": 1.7380099360128065}}, "num_model_parameters": 470337794, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "sentence-transformers/use-cmlm-multilingual", "results": {"raw": {"test": [{"test_em": 53.83423702556158, "test_f1": 58.807264231240154}, {"test_em": 51.007751937984494, "test_f1": 57.08328711618722}, {"test_em": 50.77279752704791, "test_f1": 56.814595172807095}, {"test_em": 53.73831775700935, "test_f1": 58.89188610894435}, {"test_em": 47.41312741312741, "test_f1": 52.755333419631604}, {"test_em": 50.809560524286816, "test_f1": 55.89242550023083}, {"test_em": 51.0250569476082, "test_f1": 56.90847700495296}, {"test_em": 53.06439100077579, "test_f1": 57.51312446223049}, {"test_em": 54.509803921568626, "test_f1": 59.86816123771136}, {"test_em": 51.475155279503106, "test_f1": 56.577317468719045}]}, "total": {"test_em": 51.765019933447334, "test_em_se": 1.2974740427544313, "test_f1": 57.11118717226551, "test_f1_se": 1.216739646160601}}, "num_model_parameters": 470337794, "max_sequence_length": 512, "vocabulary_size": 501153}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "studio-ousia/mluke-large-lite", "results": {"raw": {"test": [{"test_loss": 0.4696499705314636, "test_mcc": 0.7123322963296794, "test_macro_f1": 0.5892295597484276, "test_runtime": 30.2412, "test_samples_per_second": 67.722, "test_steps_per_second": 8.465}, {"test_loss": 0.44028621912002563, "test_mcc": 0.7291124308054434, "test_macro_f1": 0.7405487623901506, "test_runtime": 49.2236, "test_samples_per_second": 41.606, "test_steps_per_second": 20.803}, {"test_loss": 0.45057883858680725, "test_mcc": 0.7392714647618072, "test_macro_f1": 0.6517802226065573, "test_runtime": 49.7847, "test_samples_per_second": 41.137, "test_steps_per_second": 20.569}, {"test_loss": 0.4057700037956238, "test_mcc": 0.7321821006000621, "test_macro_f1": 0.5936643908519476, "test_runtime": 49.6793, "test_samples_per_second": 41.224, "test_steps_per_second": 20.612}, {"test_loss": 0.453934907913208, "test_mcc": 0.7292471035246331, "test_macro_f1": 0.6896509047229206, "test_runtime": 49.6536, "test_samples_per_second": 41.246, "test_steps_per_second": 20.623}, {"test_loss": 0.409678190946579, "test_mcc": 0.7282721479123662, "test_macro_f1": 0.6245148558754375, "test_runtime": 50.6378, "test_samples_per_second": 40.444, "test_steps_per_second": 20.222}, {"test_loss": 0.382394015789032, "test_mcc": 0.7415786507358961, "test_macro_f1": 0.6673247955340132, "test_runtime": 49.5204, "test_samples_per_second": 41.357, "test_steps_per_second": 20.678}, {"test_loss": 0.501490592956543, "test_mcc": 0.7408577977688231, "test_macro_f1": 0.7127992251382471, "test_runtime": 50.8462, "test_samples_per_second": 40.278, "test_steps_per_second": 20.139}, {"test_loss": 0.48924922943115234, "test_mcc": 0.7291787323807359, "test_macro_f1": 0.728131370911809, "test_runtime": 51.868, "test_samples_per_second": 39.485, "test_steps_per_second": 19.742}, {"test_loss": 0.4521455764770508, "test_mcc": 0.7186737069450145, "test_macro_f1": 0.7035137546788549, "test_runtime": 49.5307, "test_samples_per_second": 41.348, "test_steps_per_second": 20.674}]}, "total": {"test_mcc": 73.0070643176446, "test_mcc_se": 0.5799877737929733, "test_macro_f1": 67.01157842458365, "test_macro_f1_se": 3.3604686434273328}}, "num_model_parameters": 560688131, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "studio-ousia/mluke-large-lite", "results": {"raw": {"test": [{"test_loss": 0.8586369156837463, "test_mcc": 0.4662647145272822, "test_macro_f1": 0.6443627709794005, "test_runtime": 9.1688, "test_samples_per_second": 223.367, "test_steps_per_second": 6.98}, {"test_loss": 0.9243792295455933, "test_mcc": 0.45172591293638337, "test_macro_f1": 0.6133783887705585, "test_runtime": 8.8313, "test_samples_per_second": 231.901, "test_steps_per_second": 7.247}, {"test_loss": 0.9073156118392944, "test_mcc": 0.4803969198290839, "test_macro_f1": 0.6545395562850268, "test_runtime": 9.0694, "test_samples_per_second": 225.814, "test_steps_per_second": 7.057}, {"test_loss": 0.8892822265625, "test_mcc": 0.4696435697891278, "test_macro_f1": 0.6380546985262802, "test_runtime": 8.7154, "test_samples_per_second": 234.986, "test_steps_per_second": 7.343}, {"test_loss": 1.0245038270950317, "test_mcc": 0.31342181384722634, "test_macro_f1": 0.5035015722405064, "test_runtime": 8.7587, "test_samples_per_second": 233.826, "test_steps_per_second": 7.307}, {"test_loss": 0.9481900930404663, "test_mcc": 0.4548316493291494, "test_macro_f1": 0.6360087085564781, "test_runtime": 8.8536, "test_samples_per_second": 231.319, "test_steps_per_second": 7.229}, {"test_loss": 0.9394916296005249, "test_mcc": 0.3741730448579973, "test_macro_f1": 0.542076540498812, "test_runtime": 8.6986, "test_samples_per_second": 235.439, "test_steps_per_second": 7.357}, {"test_loss": 0.9652955532073975, "test_mcc": 0.3312925969825917, "test_macro_f1": 0.5337293343246369, "test_runtime": 8.8374, "test_samples_per_second": 231.742, "test_steps_per_second": 7.242}, {"test_loss": 0.8172018527984619, "test_mcc": 0.46645600402246973, "test_macro_f1": 0.6270656355133398, "test_runtime": 8.9265, "test_samples_per_second": 229.43, "test_steps_per_second": 7.17}, {"test_loss": 0.9651981592178345, "test_mcc": 0.333444096027678, "test_macro_f1": 0.5178623740934376, "test_runtime": 8.6124, "test_samples_per_second": 237.797, "test_steps_per_second": 7.431}]}, "total": {"test_mcc": 41.416503221489904, "test_mcc_se": 4.188988311510789, "test_macro_f1": 59.105795797884774, "test_macro_f1_se": 3.672918849908619}}, "num_model_parameters": 560688131, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "studio-ousia/mluke-large-lite", "results": {"raw": {"test": [{"test_loss": 0.8563604950904846, "test_mcc": 0.5555413530694819, "test_macro_f1": 0.692248109372121, "test_runtime": 7.8158, "test_samples_per_second": 262.033, "test_steps_per_second": 8.189}, {"test_loss": 0.7606499195098877, "test_mcc": 0.4391733535036893, "test_macro_f1": 0.4901523887383745, "test_runtime": 7.1819, "test_samples_per_second": 285.161, "test_steps_per_second": 8.911}, {"test_loss": 0.7804954051971436, "test_mcc": 0.46355201252329403, "test_macro_f1": 0.5602862088154076, "test_runtime": 7.4147, "test_samples_per_second": 276.21, "test_steps_per_second": 8.632}, {"test_loss": 0.8698548078536987, "test_mcc": 0.5655991337702387, "test_macro_f1": 0.6971886319003725, "test_runtime": 7.4302, "test_samples_per_second": 275.634, "test_steps_per_second": 8.614}, {"test_loss": 0.7355318069458008, "test_mcc": 0.5730072682501901, "test_macro_f1": 0.706069041026573, "test_runtime": 7.4684, "test_samples_per_second": 274.223, "test_steps_per_second": 8.569}, {"test_loss": 0.8063688278198242, "test_mcc": 0.5599915616844181, "test_macro_f1": 0.696774596295033, "test_runtime": 7.6336, "test_samples_per_second": 268.287, "test_steps_per_second": 8.384}, {"test_loss": 0.7432441115379333, "test_mcc": 0.5644243185472148, "test_macro_f1": 0.6758890002313702, "test_runtime": 7.3574, "test_samples_per_second": 278.361, "test_steps_per_second": 8.699}, {"test_loss": 0.7802778482437134, "test_mcc": 0.5439791906553243, "test_macro_f1": 0.6780074328014688, "test_runtime": 7.5834, "test_samples_per_second": 270.062, "test_steps_per_second": 8.439}, {"test_loss": 0.8228986263275146, "test_mcc": 0.5581616386953937, "test_macro_f1": 0.6824854040794911, "test_runtime": 7.9115, "test_samples_per_second": 258.863, "test_steps_per_second": 8.089}, {"test_loss": 0.8695023655891418, "test_mcc": 0.5032183392924969, "test_macro_f1": 0.6293994026452712, "test_runtime": 7.8525, "test_samples_per_second": 260.808, "test_steps_per_second": 8.15}]}, "total": {"test_mcc": 53.26648169991742, "test_mcc_se": 2.932976765198548, "test_macro_f1": 65.08500215905484, "test_macro_f1_se": 4.424866607655936}}, "num_model_parameters": 560688131, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "studio-ousia/mluke-large-lite", "results": {"raw": {"test": [{"test_loss": 0.4801683723926544, "test_mcc": 0.675704235351728, "test_macro_f1": 0.8364085808239325, "test_runtime": 6.8179, "test_samples_per_second": 300.386, "test_steps_per_second": 9.387}, {"test_loss": 0.5690985918045044, "test_mcc": 0.5776225966529491, "test_macro_f1": 0.7784096180450881, "test_runtime": 7.0705, "test_samples_per_second": 289.654, "test_steps_per_second": 9.052}, {"test_loss": 0.4626692533493042, "test_mcc": 0.6706603060081818, "test_macro_f1": 0.8276812835059657, "test_runtime": 7.0543, "test_samples_per_second": 290.318, "test_steps_per_second": 9.072}, {"test_loss": 0.43478065729141235, "test_mcc": 0.7202846567211378, "test_macro_f1": 0.8581953613625772, "test_runtime": 6.9127, "test_samples_per_second": 296.267, "test_steps_per_second": 9.258}, {"test_loss": 0.4365212321281433, "test_mcc": 0.6876128790586716, "test_macro_f1": 0.8398180448458035, "test_runtime": 6.9979, "test_samples_per_second": 292.658, "test_steps_per_second": 9.146}, {"test_loss": 0.4643231928348541, "test_mcc": 0.6978375551873296, "test_macro_f1": 0.8427166701705984, "test_runtime": 7.0448, "test_samples_per_second": 290.711, "test_steps_per_second": 9.085}, {"test_loss": 0.3632340133190155, "test_mcc": 0.7287629792175776, "test_macro_f1": 0.8642421467778779, "test_runtime": 6.9968, "test_samples_per_second": 292.704, "test_steps_per_second": 9.147}, {"test_loss": 0.4047085642814636, "test_mcc": 0.7040190113871797, "test_macro_f1": 0.8513241538072109, "test_runtime": 7.1, "test_samples_per_second": 288.451, "test_steps_per_second": 9.014}, {"test_loss": 0.42782914638519287, "test_mcc": 0.7037647293169252, "test_macro_f1": 0.8437322222125636, "test_runtime": 7.0204, "test_samples_per_second": 291.722, "test_steps_per_second": 9.116}, {"test_loss": 0.4468672275543213, "test_mcc": 0.6854388255188474, "test_macro_f1": 0.8243773841766584, "test_runtime": 7.0164, "test_samples_per_second": 291.888, "test_steps_per_second": 9.122}]}, "total": {"test_mcc": 68.51707774420528, "test_mcc_se": 2.602491554409725, "test_macro_f1": 83.66905465728276, "test_macro_f1_se": 1.4842171411397942}}, "num_model_parameters": 560687106, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "studio-ousia/mluke-large-lite", "results": {"raw": {"test": [{"test_loss": 0.6850422620773315, "test_mcc": 0.22653293405485614, "test_macro_f1": 0.4727248874379051, "test_runtime": 7.6063, "test_samples_per_second": 269.25, "test_steps_per_second": 8.414}, {"test_loss": 0.6645408868789673, "test_mcc": 0.0, "test_macro_f1": 0.3382875605815832, "test_runtime": 7.8797, "test_samples_per_second": 259.91, "test_steps_per_second": 8.122}, {"test_loss": 0.6156501770019531, "test_mcc": 0.5448690541709673, "test_macro_f1": 0.7632872893693656, "test_runtime": 7.6913, "test_samples_per_second": 266.276, "test_steps_per_second": 8.321}, {"test_loss": 0.6074072122573853, "test_mcc": 0.4753469456985936, "test_macro_f1": 0.6895486429374844, "test_runtime": 8.2556, "test_samples_per_second": 248.073, "test_steps_per_second": 7.752}, {"test_loss": 0.5726336240768433, "test_mcc": 0.4968058902176383, "test_macro_f1": 0.7202627270754847, "test_runtime": 7.5852, "test_samples_per_second": 269.999, "test_steps_per_second": 8.437}, {"test_loss": 0.5014785528182983, "test_mcc": 0.6021459805233847, "test_macro_f1": 0.7881445161490852, "test_runtime": 7.625, "test_samples_per_second": 268.59, "test_steps_per_second": 8.393}, {"test_loss": 0.594180166721344, "test_mcc": 0.4306571863626449, "test_macro_f1": 0.6650402071691428, "test_runtime": 7.5025, "test_samples_per_second": 272.976, "test_steps_per_second": 8.53}, {"test_loss": 0.4428625702857971, "test_mcc": 0.6512976629479976, "test_macro_f1": 0.8256486345533511, "test_runtime": 7.7646, "test_samples_per_second": 263.761, "test_steps_per_second": 8.243}, {"test_loss": 0.5529788732528687, "test_mcc": 0.5833697011510338, "test_macro_f1": 0.7915034588649583, "test_runtime": 7.7076, "test_samples_per_second": 265.713, "test_steps_per_second": 8.304}, {"test_loss": 0.5520464181900024, "test_mcc": 0.5677735470674258, "test_macro_f1": 0.7790563866513233, "test_runtime": 7.8133, "test_samples_per_second": 262.117, "test_steps_per_second": 8.191}]}, "total": {"test_mcc": 45.78798902194542, "test_mcc_se": 12.384956165842027, "test_macro_f1": 68.33504310789684, "test_macro_f1_se": 9.770444181661544}}, "num_model_parameters": 560687106, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "studio-ousia/mluke-large-lite", "results": {"raw": {"test": [{"test_loss": 0.6208631992340088, "test_mcc": 0.546601815065938, "test_macro_f1": 0.7615921385851122, "test_runtime": 7.0145, "test_samples_per_second": 291.965, "test_steps_per_second": 9.124}, {"test_loss": 0.4677163362503052, "test_mcc": 0.6415593026514668, "test_macro_f1": 0.8077795672656425, "test_runtime": 7.1389, "test_samples_per_second": 286.878, "test_steps_per_second": 8.965}, {"test_loss": 0.6787798404693604, "test_mcc": 0.22397431225593495, "test_macro_f1": 0.6058823529411765, "test_runtime": 7.041, "test_samples_per_second": 290.868, "test_steps_per_second": 9.09}, {"test_loss": 0.5979976654052734, "test_mcc": 0.5021030699988763, "test_macro_f1": 0.7457061741155624, "test_runtime": 7.1706, "test_samples_per_second": 285.612, "test_steps_per_second": 8.925}, {"test_loss": 0.48445725440979004, "test_mcc": 0.57540876408759, "test_macro_f1": 0.782717566633382, "test_runtime": 7.1208, "test_samples_per_second": 287.606, "test_steps_per_second": 8.988}, {"test_loss": 0.519705057144165, "test_mcc": 0.5855053330142316, "test_macro_f1": 0.7918778625954198, "test_runtime": 6.8713, "test_samples_per_second": 298.052, "test_steps_per_second": 9.314}, {"test_loss": 0.4769035577774048, "test_mcc": 0.638056559646403, "test_macro_f1": 0.8166811812303054, "test_runtime": 6.8776, "test_samples_per_second": 297.778, "test_steps_per_second": 9.306}, {"test_loss": 0.6248008608818054, "test_mcc": 0.45659467088814293, "test_macro_f1": 0.7070020061170936, "test_runtime": 7.0033, "test_samples_per_second": 292.432, "test_steps_per_second": 9.139}, {"test_loss": 0.5765519142150879, "test_mcc": 0.5529003010159059, "test_macro_f1": 0.7661034136348988, "test_runtime": 6.9461, "test_samples_per_second": 294.84, "test_steps_per_second": 9.214}, {"test_loss": 0.5935613512992859, "test_mcc": 0.5459169520982033, "test_macro_f1": 0.7707651812770118, "test_runtime": 7.1088, "test_samples_per_second": 288.094, "test_steps_per_second": 9.003}]}, "total": {"test_mcc": 52.68621080722692, "test_mcc_se": 7.450226969261207, "test_macro_f1": 75.56107444395604, "test_macro_f1_se": 3.7958778726985742}}, "num_model_parameters": 560687106, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "studio-ousia/mluke-large-lite", "results": {"raw": {"test": [{"test_loss": 0.6647030115127563, "test_mcc": 0.254486889791665, "test_macro_f1": 0.6017826046552972, "test_runtime": 7.3915, "test_samples_per_second": 277.075, "test_steps_per_second": 8.659}, {"test_loss": 0.6912516951560974, "test_mcc": 0.0, "test_macro_f1": 0.33571196886149857, "test_runtime": 7.7706, "test_samples_per_second": 263.559, "test_steps_per_second": 8.236}, {"test_loss": 0.6112809181213379, "test_mcc": 0.4249215312751579, "test_macro_f1": 0.7043212294239365, "test_runtime": 7.5744, "test_samples_per_second": 270.383, "test_steps_per_second": 8.449}, {"test_loss": 0.6887569427490234, "test_mcc": 0.13227584805916448, "test_macro_f1": 0.4656725584912503, "test_runtime": 7.2459, "test_samples_per_second": 282.643, "test_steps_per_second": 8.833}, {"test_loss": 0.5553594827651978, "test_mcc": 0.5082950905813826, "test_macro_f1": 0.7506148196608584, "test_runtime": 7.3395, "test_samples_per_second": 279.037, "test_steps_per_second": 8.72}, {"test_loss": 0.6911717653274536, "test_mcc": 0.08902395110158974, "test_macro_f1": 0.5444369180606423, "test_runtime": 7.5855, "test_samples_per_second": 269.99, "test_steps_per_second": 8.437}, {"test_loss": 0.6912142038345337, "test_mcc": 0.061722400411413886, "test_macro_f1": 0.34753612402946416, "test_runtime": 7.4894, "test_samples_per_second": 273.451, "test_steps_per_second": 8.545}, {"test_loss": 0.6381264925003052, "test_mcc": 0.38993628823655146, "test_macro_f1": 0.6938265599908441, "test_runtime": 7.5299, "test_samples_per_second": 271.982, "test_steps_per_second": 8.499}, {"test_loss": 0.6596906185150146, "test_mcc": 0.2637343741752245, "test_macro_f1": 0.5679160742159239, "test_runtime": 7.3689, "test_samples_per_second": 277.925, "test_steps_per_second": 8.685}, {"test_loss": 0.6921965479850769, "test_mcc": -0.04338165907319401, "test_macro_f1": 0.33678756476683935, "test_runtime": 7.7869, "test_samples_per_second": 263.005, "test_steps_per_second": 8.219}]}, "total": {"test_mcc": 20.810147145589557, "test_mcc_se": 11.7480792563814, "test_macro_f1": 53.48606422156556, "test_macro_f1_se": 9.799356196569212}}, "num_model_parameters": 560687106, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.3707369565963745, "test_mcc": 0.7602387598392372, "test_macro_f1": 0.7417152087942703, "test_runtime": 84.1125, "test_samples_per_second": 24.348, "test_steps_per_second": 24.348}, {"test_loss": 0.42803701758384705, "test_mcc": 0.734622291505819, "test_macro_f1": 0.6800236923619786, "test_runtime": 80.1379, "test_samples_per_second": 25.556, "test_steps_per_second": 25.556}, {"test_loss": 0.41147327423095703, "test_mcc": 0.7380347746990996, "test_macro_f1": 0.7173670129560076, "test_runtime": 83.9133, "test_samples_per_second": 24.406, "test_steps_per_second": 24.406}, {"test_loss": 0.36210957169532776, "test_mcc": 0.7771376904258805, "test_macro_f1": 0.727442179987587, "test_runtime": 83.6007, "test_samples_per_second": 24.497, "test_steps_per_second": 24.497}, {"test_loss": 0.338920533657074, "test_mcc": 0.7737329334742115, "test_macro_f1": 0.7538684220047309, "test_runtime": 82.6749, "test_samples_per_second": 24.772, "test_steps_per_second": 24.772}, {"test_loss": 0.42525893449783325, "test_mcc": 0.7376822842972697, "test_macro_f1": 0.6093373150329368, "test_runtime": 83.3036, "test_samples_per_second": 24.585, "test_steps_per_second": 24.585}, {"test_loss": 0.4079909920692444, "test_mcc": 0.7652168597260882, "test_macro_f1": 0.7746689467075328, "test_runtime": 83.5862, "test_samples_per_second": 24.502, "test_steps_per_second": 24.502}, {"test_loss": 0.3933856189250946, "test_mcc": 0.7316772772988264, "test_macro_f1": 0.7204410960768173, "test_runtime": 84.4771, "test_samples_per_second": 24.243, "test_steps_per_second": 24.243}, {"test_loss": 0.38926634192466736, "test_mcc": 0.7699706747799059, "test_macro_f1": 0.78692165391671, "test_runtime": 82.7708, "test_samples_per_second": 24.743, "test_steps_per_second": 24.743}, {"test_loss": 0.37373054027557373, "test_mcc": 0.7534667813512089, "test_macro_f1": 0.7561144090468629, "test_runtime": 83.528, "test_samples_per_second": 24.519, "test_steps_per_second": 24.519}]}, "total": {"test_mcc": 75.41780327397547, "test_mcc_se": 1.0813539189945822, "test_macro_f1": 72.67899936885433, "test_macro_f1_se": 3.1897042410762353}}, "num_model_parameters": 559893507, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.9490622282028198, "test_mcc": 0.30835353218928524, "test_macro_f1": 0.49475984644056714, "test_runtime": 9.083, "test_samples_per_second": 225.475, "test_steps_per_second": 7.046}, {"test_loss": 1.0344398021697998, "test_mcc": 0.2750006727608108, "test_macro_f1": 0.5137441428121026, "test_runtime": 8.9213, "test_samples_per_second": 229.563, "test_steps_per_second": 7.174}, {"test_loss": 1.0624220371246338, "test_mcc": 0.13030210424822863, "test_macro_f1": 0.3250431171704679, "test_runtime": 8.8464, "test_samples_per_second": 231.507, "test_steps_per_second": 7.235}, {"test_loss": 0.7818756103515625, "test_mcc": 0.5387188007927386, "test_macro_f1": 0.691720457329034, "test_runtime": 8.8182, "test_samples_per_second": 232.246, "test_steps_per_second": 7.258}, {"test_loss": 1.0760648250579834, "test_mcc": 0.10494655923914652, "test_macro_f1": 0.2851765612012912, "test_runtime": 8.7347, "test_samples_per_second": 234.467, "test_steps_per_second": 7.327}, {"test_loss": 0.7987827658653259, "test_mcc": 0.4760461051549502, "test_macro_f1": 0.6371220913318382, "test_runtime": 8.9355, "test_samples_per_second": 229.199, "test_steps_per_second": 7.162}, {"test_loss": 0.7845360636711121, "test_mcc": 0.48378046750223885, "test_macro_f1": 0.6485159655518785, "test_runtime": 8.7417, "test_samples_per_second": 234.278, "test_steps_per_second": 7.321}, {"test_loss": 0.8613487482070923, "test_mcc": 0.5015291893505958, "test_macro_f1": 0.6669173467841105, "test_runtime": 8.9746, "test_samples_per_second": 228.199, "test_steps_per_second": 7.131}, {"test_loss": 0.8359957933425903, "test_mcc": 0.4726156724656107, "test_macro_f1": 0.6414917010988251, "test_runtime": 8.863, "test_samples_per_second": 231.073, "test_steps_per_second": 7.221}, {"test_loss": 0.7947608828544617, "test_mcc": 0.503181533280701, "test_macro_f1": 0.6721594489015835, "test_runtime": 8.7336, "test_samples_per_second": 234.496, "test_steps_per_second": 7.328}]}, "total": {"test_mcc": 37.94474636984306, "test_mcc_se": 10.076299037952706, "test_macro_f1": 55.766506786216986, "test_macro_f1_se": 9.213138688675485}}, "num_model_parameters": 559893507, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 1.0057768821716309, "test_mcc": 0.19990114954504157, "test_macro_f1": 0.3753682901592869, "test_runtime": 7.8418, "test_samples_per_second": 261.163, "test_steps_per_second": 8.161}, {"test_loss": 0.6572833061218262, "test_mcc": 0.6057056027994557, "test_macro_f1": 0.7260527449665095, "test_runtime": 7.4185, "test_samples_per_second": 276.067, "test_steps_per_second": 8.627}, {"test_loss": 0.6845475435256958, "test_mcc": 0.6010900175441393, "test_macro_f1": 0.6968959295311414, "test_runtime": 7.6611, "test_samples_per_second": 267.326, "test_steps_per_second": 8.354}, {"test_loss": 0.9962397217750549, "test_mcc": 0.0, "test_macro_f1": 0.21635883905013195, "test_runtime": 7.6427, "test_samples_per_second": 267.967, "test_steps_per_second": 8.374}, {"test_loss": 0.9607330560684204, "test_mcc": 0.2264013274090031, "test_macro_f1": 0.37047635969679127, "test_runtime": 7.4842, "test_samples_per_second": 273.645, "test_steps_per_second": 8.551}, {"test_loss": 1.000806450843811, "test_mcc": 0.1805071434278813, "test_macro_f1": 0.360674148764162, "test_runtime": 7.6841, "test_samples_per_second": 266.525, "test_steps_per_second": 8.329}, {"test_loss": 0.6401726007461548, "test_mcc": 0.6170009425883899, "test_macro_f1": 0.7304444588019123, "test_runtime": 7.3574, "test_samples_per_second": 278.36, "test_steps_per_second": 8.699}, {"test_loss": 0.9623479843139648, "test_mcc": 0.16941963595608223, "test_macro_f1": 0.3655525060797323, "test_runtime": 7.6089, "test_samples_per_second": 269.158, "test_steps_per_second": 8.411}, {"test_loss": 0.9019985795021057, "test_mcc": 0.2882367486841176, "test_macro_f1": 0.3882829954936679, "test_runtime": 7.9078, "test_samples_per_second": 258.985, "test_steps_per_second": 8.093}, {"test_loss": 0.988555908203125, "test_mcc": 0.1681250800627226, "test_macro_f1": 0.3661062918697114, "test_runtime": 7.7803, "test_samples_per_second": 263.227, "test_steps_per_second": 8.226}]}, "total": {"test_mcc": 30.563876480168332, "test_mcc_se": 13.682279474611484, "test_macro_f1": 45.962125644130474, "test_macro_f1_se": 11.453398262963871}}, "num_model_parameters": 559893507, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.055007465183734894, "test_micro_f1": 0.7740916271721959, "test_micro_f1_no_misc": 0.8423676012461059, "test_runtime": 14.4125, "test_samples_per_second": 142.099, "test_steps_per_second": 4.441}, {"test_loss": 0.05742444843053818, "test_micro_f1": 0.712358337830545, "test_micro_f1_no_misc": 0.7813267813267812, "test_runtime": 13.5272, "test_samples_per_second": 151.399, "test_steps_per_second": 4.731}, {"test_loss": 0.04682187736034393, "test_micro_f1": 0.765625, "test_micro_f1_no_misc": 0.8002171552660153, "test_runtime": 12.6533, "test_samples_per_second": 161.856, "test_steps_per_second": 5.058}, {"test_loss": 0.051071036607027054, "test_micro_f1": 0.708171206225681, "test_micro_f1_no_misc": 0.7540805223068554, "test_runtime": 14.4241, "test_samples_per_second": 141.985, "test_steps_per_second": 4.437}, {"test_loss": 0.057070113718509674, "test_micro_f1": 0.7875848690591659, "test_micro_f1_no_misc": 0.8319148936170213, "test_runtime": 14.3202, "test_samples_per_second": 143.015, "test_steps_per_second": 4.469}, {"test_loss": 0.048342015594244, "test_micro_f1": 0.7678486997635935, "test_micro_f1_no_misc": 0.8221127531472359, "test_runtime": 11.6174, "test_samples_per_second": 176.288, "test_steps_per_second": 5.509}, {"test_loss": 0.04948620870709419, "test_micro_f1": 0.7474452554744525, "test_micro_f1_no_misc": 0.7945355191256831, "test_runtime": 11.8083, "test_samples_per_second": 173.437, "test_steps_per_second": 5.42}, {"test_loss": 0.05266436189413071, "test_micro_f1": 0.6479305058763413, "test_micro_f1_no_misc": 0.69151376146789, "test_runtime": 13.8118, "test_samples_per_second": 148.279, "test_steps_per_second": 4.634}, {"test_loss": 0.04626833647489548, "test_micro_f1": 0.7592768791627023, "test_micro_f1_no_misc": 0.8098092643051771, "test_runtime": 13.1608, "test_samples_per_second": 155.614, "test_steps_per_second": 4.863}, {"test_loss": 0.053097449243068695, "test_micro_f1": 0.7829495345418913, "test_micro_f1_no_misc": 0.8246392896781354, "test_runtime": 14.3102, "test_samples_per_second": 143.115, "test_steps_per_second": 4.472}]}, "total": {"test_micro_f1": 74.5328191510657, "test_micro_f1_se": 2.70171076461682, "test_micro_f1_no_misc": 79.52517541486901, "test_micro_f1_no_misc_se": 2.7746955892681067}}, "num_model_parameters": 558850057, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.055326227098703384, "test_micro_f1": 0.8617760617760618, "test_micro_f1_no_misc": 0.8760968760968761, "test_runtime": 15.5458, "test_samples_per_second": 131.74, "test_steps_per_second": 4.117}, {"test_loss": 0.05156376212835312, "test_micro_f1": 0.8717225824640541, "test_micro_f1_no_misc": 0.8936484490398818, "test_runtime": 13.109, "test_samples_per_second": 156.228, "test_steps_per_second": 4.882}, {"test_loss": 0.06057353317737579, "test_micro_f1": 0.865695792880259, "test_micro_f1_no_misc": 0.8872072072072072, "test_runtime": 15.6292, "test_samples_per_second": 131.037, "test_steps_per_second": 4.095}, {"test_loss": 0.0595000758767128, "test_micro_f1": 0.8451292765735178, "test_micro_f1_no_misc": 0.8567365801635264, "test_runtime": 15.3331, "test_samples_per_second": 133.567, "test_steps_per_second": 4.174}, {"test_loss": 0.05965651571750641, "test_micro_f1": 0.8239258635214827, "test_micro_f1_no_misc": 0.8362395754359362, "test_runtime": 15.7322, "test_samples_per_second": 130.179, "test_steps_per_second": 4.068}, {"test_loss": 0.0552186593413353, "test_micro_f1": 0.8654684095860566, "test_micro_f1_no_misc": 0.8811506434519304, "test_runtime": 15.6281, "test_samples_per_second": 131.046, "test_steps_per_second": 4.095}, {"test_loss": 0.05620109662413597, "test_micro_f1": 0.8660235798499463, "test_micro_f1_no_misc": 0.8817051509769094, "test_runtime": 15.7265, "test_samples_per_second": 130.226, "test_steps_per_second": 4.07}, {"test_loss": 0.056226618587970734, "test_micro_f1": 0.8506688506688507, "test_micro_f1_no_misc": 0.8759286775631501, "test_runtime": 15.5334, "test_samples_per_second": 131.845, "test_steps_per_second": 4.12}, {"test_loss": 0.057754307985305786, "test_micro_f1": 0.8266595001343724, "test_micro_f1_no_misc": 0.8401624215577704, "test_runtime": 15.1981, "test_samples_per_second": 134.754, "test_steps_per_second": 4.211}, {"test_loss": 0.0565626285970211, "test_micro_f1": 0.8682715715444955, "test_micro_f1_no_misc": 0.8825490922563912, "test_runtime": 13.4079, "test_samples_per_second": 152.746, "test_steps_per_second": 4.773}]}, "total": {"test_micro_f1": 85.45341488999097, "test_micro_f1_se": 1.0794852190427449, "test_micro_f1_no_misc": 87.11424673749579, "test_micro_f1_no_misc_se": 1.2291349292035654}}, "num_model_parameters": 558850057, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.04023643210530281, "test_micro_f1": 0.8810572687224669, "test_micro_f1_no_misc": 0.9116317303740239, "test_runtime": 12.7402, "test_samples_per_second": 160.751, "test_steps_per_second": 5.023}, {"test_loss": 0.02789343148469925, "test_micro_f1": 0.9059701492537314, "test_micro_f1_no_misc": 0.9277566539923955, "test_runtime": 12.5451, "test_samples_per_second": 163.25, "test_steps_per_second": 5.102}, {"test_loss": 0.03945233300328255, "test_micro_f1": 0.8791208791208791, "test_micro_f1_no_misc": 0.9096022498995582, "test_runtime": 11.8408, "test_samples_per_second": 172.961, "test_steps_per_second": 5.405}, {"test_loss": 0.027955984696745872, "test_micro_f1": 0.8936924167257265, "test_micro_f1_no_misc": 0.916042569964525, "test_runtime": 11.5412, "test_samples_per_second": 177.452, "test_steps_per_second": 5.545}, {"test_loss": 0.03065815195441246, "test_micro_f1": 0.8781793842034805, "test_micro_f1_no_misc": 0.9121000367782274, "test_runtime": 12.43, "test_samples_per_second": 164.762, "test_steps_per_second": 5.149}, {"test_loss": 0.028175577521324158, "test_micro_f1": 0.9149741824440619, "test_micro_f1_no_misc": 0.9331797235023042, "test_runtime": 12.6336, "test_samples_per_second": 162.108, "test_steps_per_second": 5.066}, {"test_loss": 0.02913520857691765, "test_micro_f1": 0.898086956521739, "test_micro_f1_no_misc": 0.9202983902630545, "test_runtime": 11.6914, "test_samples_per_second": 175.171, "test_steps_per_second": 5.474}, {"test_loss": 0.03395208716392517, "test_micro_f1": 0.8918918918918919, "test_micro_f1_no_misc": 0.9115543846443357, "test_runtime": 11.3865, "test_samples_per_second": 179.863, "test_steps_per_second": 5.621}, {"test_loss": 0.028481021523475647, "test_micro_f1": 0.8923410404624278, "test_micro_f1_no_misc": 0.9113924050632911, "test_runtime": 11.4686, "test_samples_per_second": 178.575, "test_steps_per_second": 5.58}, {"test_loss": 0.03557838499546051, "test_micro_f1": 0.9129232895646165, "test_micro_f1_no_misc": 0.936495791889824, "test_runtime": 12.586, "test_samples_per_second": 162.72, "test_steps_per_second": 5.085}]}, "total": {"test_micro_f1": 89.48237458911021, "test_micro_f1_se": 0.8258129767475482, "test_micro_f1_no_misc": 91.9005393637154, "test_micro_f1_no_misc_se": 0.6190516870087003}}, "num_model_parameters": 558850057, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.04738037660717964, "test_micro_f1": 0.7782832878374281, "test_micro_f1_no_misc": 0.8227469238443633, "test_runtime": 11.4716, "test_samples_per_second": 178.527, "test_steps_per_second": 5.579}, {"test_loss": 0.04765051603317261, "test_micro_f1": 0.836178496555855, "test_micro_f1_no_misc": 0.8733595800524935, "test_runtime": 11.7613, "test_samples_per_second": 174.131, "test_steps_per_second": 5.442}, {"test_loss": 0.05041375011205673, "test_micro_f1": 0.8183475091130014, "test_micro_f1_no_misc": 0.8527236045729658, "test_runtime": 11.4128, "test_samples_per_second": 179.448, "test_steps_per_second": 5.608}, {"test_loss": 0.048603661358356476, "test_micro_f1": 0.808726838015541, "test_micro_f1_no_misc": 0.8441471571906355, "test_runtime": 12.0699, "test_samples_per_second": 169.678, "test_steps_per_second": 5.302}, {"test_loss": 0.05053834617137909, "test_micro_f1": 0.8484848484848485, "test_micro_f1_no_misc": 0.8845470692717584, "test_runtime": 11.3617, "test_samples_per_second": 180.255, "test_steps_per_second": 5.633}, {"test_loss": 0.04720940813422203, "test_micro_f1": 0.8594449418084154, "test_micro_f1_no_misc": 0.8955017301038062, "test_runtime": 11.7908, "test_samples_per_second": 173.695, "test_steps_per_second": 5.428}, {"test_loss": 0.041180361062288284, "test_micro_f1": 0.8263141715339688, "test_micro_f1_no_misc": 0.8633582596872875, "test_runtime": 11.8309, "test_samples_per_second": 173.106, "test_steps_per_second": 5.41}, {"test_loss": 0.044489555060863495, "test_micro_f1": 0.8700000000000001, "test_micro_f1_no_misc": 0.8997940974605353, "test_runtime": 12.1112, "test_samples_per_second": 169.099, "test_steps_per_second": 5.284}, {"test_loss": 0.05676200985908508, "test_micro_f1": 0.8118195956454122, "test_micro_f1_no_misc": 0.8502747252747253, "test_runtime": 11.141, "test_samples_per_second": 183.826, "test_steps_per_second": 5.745}, {"test_loss": 0.048078205436468124, "test_micro_f1": 0.8347082187595477, "test_micro_f1_no_misc": 0.8722055388722055, "test_runtime": 11.4763, "test_samples_per_second": 178.455, "test_steps_per_second": 5.577}]}, "total": {"test_micro_f1": 82.92307907754018, "test_micro_f1_se": 1.6618541496707848, "test_micro_f1_no_misc": 86.58658686330776, "test_micro_f1_no_misc_se": 1.4938035083612295}}, "num_model_parameters": 558850057, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.6894313097000122, "test_mcc": 0.12302283836922583, "test_macro_f1": 0.5166935098178956, "test_runtime": 7.0868, "test_samples_per_second": 288.989, "test_steps_per_second": 9.031}, {"test_loss": 0.6849953532218933, "test_mcc": 0.171871484201205, "test_macro_f1": 0.45752109515519906, "test_runtime": 7.0804, "test_samples_per_second": 289.249, "test_steps_per_second": 9.039}, {"test_loss": 0.6884191036224365, "test_mcc": 0.08543843589678984, "test_macro_f1": 0.4966875402784765, "test_runtime": 7.2017, "test_samples_per_second": 284.378, "test_steps_per_second": 8.887}, {"test_loss": 0.6899479627609253, "test_mcc": 0.14529207725427168, "test_macro_f1": 0.5186679043090371, "test_runtime": 6.9789, "test_samples_per_second": 293.455, "test_steps_per_second": 9.17}, {"test_loss": 0.4232639968395233, "test_mcc": 0.6709409596745125, "test_macro_f1": 0.8269947972933182, "test_runtime": 7.0364, "test_samples_per_second": 291.056, "test_steps_per_second": 9.096}, {"test_loss": 0.6900116205215454, "test_mcc": 0.17770825514387978, "test_macro_f1": 0.5887102929279053, "test_runtime": 6.9893, "test_samples_per_second": 293.018, "test_steps_per_second": 9.157}, {"test_loss": 0.6899219751358032, "test_mcc": 0.13620199919844023, "test_macro_f1": 0.5093193752411629, "test_runtime": 7.0859, "test_samples_per_second": 289.024, "test_steps_per_second": 9.032}, {"test_loss": 0.6881742477416992, "test_mcc": 0.17618419127003307, "test_macro_f1": 0.580252632190981, "test_runtime": 7.2052, "test_samples_per_second": 284.238, "test_steps_per_second": 8.882}, {"test_loss": 0.6863275766372681, "test_mcc": 0.09460668639690083, "test_macro_f1": 0.4089600481339355, "test_runtime": 7.0637, "test_samples_per_second": 289.931, "test_steps_per_second": 9.06}, {"test_loss": 0.6904871463775635, "test_mcc": 0.06239425803852602, "test_macro_f1": 0.45289278208143036, "test_runtime": 7.0653, "test_samples_per_second": 289.869, "test_steps_per_second": 9.058}]}, "total": {"test_mcc": 18.436611854437846, "test_mcc_se": 10.88055223103157, "test_macro_f1": 53.566999774293414, "test_macro_f1_se": 7.202949432422945}}, "num_model_parameters": 559892482, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.6894785165786743, "test_mcc": 0.07090278375151683, "test_macro_f1": 0.45680812288466544, "test_runtime": 7.6623, "test_samples_per_second": 267.284, "test_steps_per_second": 8.353}, {"test_loss": 0.6903863549232483, "test_mcc": 0.17673144126582996, "test_macro_f1": 0.5199084088656701, "test_runtime": 8.0098, "test_samples_per_second": 255.687, "test_steps_per_second": 7.99}, {"test_loss": 0.6849125027656555, "test_mcc": 0.0, "test_macro_f1": 0.3410553410553411, "test_runtime": 7.6944, "test_samples_per_second": 266.168, "test_steps_per_second": 8.318}, {"test_loss": 0.47288721799850464, "test_mcc": 0.6363847614315337, "test_macro_f1": 0.8131350967171864, "test_runtime": 8.0377, "test_samples_per_second": 254.799, "test_steps_per_second": 7.962}, {"test_loss": 0.6910171508789062, "test_mcc": 0.0828299925639865, "test_macro_f1": 0.5262282702683668, "test_runtime": 7.6964, "test_samples_per_second": 266.1, "test_steps_per_second": 8.316}, {"test_loss": 0.6874823570251465, "test_mcc": 0.12367167543004667, "test_macro_f1": 0.38335766423357664, "test_runtime": 7.7593, "test_samples_per_second": 263.941, "test_steps_per_second": 8.248}, {"test_loss": 0.6899168491363525, "test_mcc": 0.09711764730721899, "test_macro_f1": 0.4059435586495995, "test_runtime": 7.4762, "test_samples_per_second": 273.936, "test_steps_per_second": 8.561}, {"test_loss": 0.6885986328125, "test_mcc": 0.11115308803217815, "test_macro_f1": 0.43430074486350956, "test_runtime": 7.8011, "test_samples_per_second": 262.529, "test_steps_per_second": 8.204}, {"test_loss": 0.6910632848739624, "test_mcc": 0.147776035082954, "test_macro_f1": 0.568025906760646, "test_runtime": 7.571, "test_samples_per_second": 270.507, "test_steps_per_second": 8.453}, {"test_loss": 0.6900005340576172, "test_mcc": 0.07918495644448012, "test_macro_f1": 0.44291045806721063, "test_runtime": 7.7538, "test_samples_per_second": 264.129, "test_steps_per_second": 8.254}]}, "total": {"test_mcc": 15.257523813097452, "test_mcc_se": 10.942213638084164, "test_macro_f1": 48.916735723657716, "test_macro_f1_se": 8.257588465105517}}, "num_model_parameters": 559892482, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.6870373487472534, "test_mcc": 0.1425312355866413, "test_macro_f1": 0.5298687997739754, "test_runtime": 7.2114, "test_samples_per_second": 283.994, "test_steps_per_second": 8.875}, {"test_loss": 0.698140025138855, "test_mcc": 0.016638385480836057, "test_macro_f1": 0.48883256014156584, "test_runtime": 7.1521, "test_samples_per_second": 286.349, "test_steps_per_second": 8.948}, {"test_loss": 0.690955638885498, "test_mcc": 0.18490342427457065, "test_macro_f1": 0.5823427614421995, "test_runtime": 7.0271, "test_samples_per_second": 291.445, "test_steps_per_second": 9.108}, {"test_loss": 0.6906611919403076, "test_mcc": 0.044782025762081, "test_macro_f1": 0.4778554778554779, "test_runtime": 7.2502, "test_samples_per_second": 282.473, "test_steps_per_second": 8.827}, {"test_loss": 0.6889392137527466, "test_mcc": 0.11483797142623772, "test_macro_f1": 0.46052126530642956, "test_runtime": 7.2168, "test_samples_per_second": 283.783, "test_steps_per_second": 8.868}, {"test_loss": 0.6864820718765259, "test_mcc": 0.2734907748174633, "test_macro_f1": 0.6367156319052574, "test_runtime": 6.8932, "test_samples_per_second": 297.103, "test_steps_per_second": 9.284}, {"test_loss": 0.6914941072463989, "test_mcc": 0.03548464245270155, "test_macro_f1": 0.38057738909769584, "test_runtime": 6.9757, "test_samples_per_second": 293.59, "test_steps_per_second": 9.175}, {"test_loss": 0.6923867464065552, "test_mcc": 0.03204727173244391, "test_macro_f1": 0.3420331981947525, "test_runtime": 7.1122, "test_samples_per_second": 287.957, "test_steps_per_second": 8.999}, {"test_loss": 0.691484808921814, "test_mcc": 0.03959029364984973, "test_macro_f1": 0.34594966725311715, "test_runtime": 6.9315, "test_samples_per_second": 295.462, "test_steps_per_second": 9.233}, {"test_loss": 0.6857792139053345, "test_mcc": 0.09504011808851906, "test_macro_f1": 0.43011839857529605, "test_runtime": 7.199, "test_samples_per_second": 284.483, "test_steps_per_second": 8.89}]}, "total": {"test_mcc": 9.793461432713443, "test_mcc_se": 5.133802323128274, "test_macro_f1": 46.74815149545767, "test_macro_f1_se": 6.0514679202445425}}, "num_model_parameters": 559892482, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_loss": 0.6922941207885742, "test_mcc": 0.023689072570785338, "test_macro_f1": 0.4374766027078819, "test_runtime": 7.4291, "test_samples_per_second": 275.673, "test_steps_per_second": 8.615}, {"test_loss": 0.691811203956604, "test_mcc": -0.00578935106806417, "test_macro_f1": 0.4357324372730357, "test_runtime": 7.59, "test_samples_per_second": 269.829, "test_steps_per_second": 8.432}, {"test_loss": 0.6923336386680603, "test_mcc": 0.058171789092343454, "test_macro_f1": 0.5274700813380186, "test_runtime": 7.7586, "test_samples_per_second": 263.964, "test_steps_per_second": 8.249}, {"test_loss": 0.6903643608093262, "test_mcc": 0.16238946584786879, "test_macro_f1": 0.5762556617944038, "test_runtime": 7.5281, "test_samples_per_second": 272.047, "test_steps_per_second": 8.501}, {"test_loss": 0.6901517510414124, "test_mcc": 0.08907473391956225, "test_macro_f1": 0.414112905525622, "test_runtime": 7.4531, "test_samples_per_second": 274.784, "test_steps_per_second": 8.587}, {"test_loss": 0.6883277297019958, "test_mcc": 0.05090433319384621, "test_macro_f1": 0.3705135249197742, "test_runtime": 7.6044, "test_samples_per_second": 269.317, "test_steps_per_second": 8.416}, {"test_loss": 0.6910141706466675, "test_mcc": 0.07526333787750522, "test_macro_f1": 0.5313238124451471, "test_runtime": 7.4339, "test_samples_per_second": 275.495, "test_steps_per_second": 8.609}, {"test_loss": 0.6898267269134521, "test_mcc": 0.08802803593410319, "test_macro_f1": 0.5353202185477798, "test_runtime": 7.479, "test_samples_per_second": 273.835, "test_steps_per_second": 8.557}, {"test_loss": 0.6924172639846802, "test_mcc": 0.03493966456032626, "test_macro_f1": 0.49642292605819327, "test_runtime": 7.5048, "test_samples_per_second": 272.892, "test_steps_per_second": 8.528}, {"test_loss": 0.6920270323753357, "test_mcc": 0.05916051618306162, "test_macro_f1": 0.5269012920187333, "test_runtime": 7.7048, "test_samples_per_second": 265.808, "test_steps_per_second": 8.307}]}, "total": {"test_mcc": 6.358315981113381, "test_mcc_se": 2.816208746091863, "test_macro_f1": 48.5152946262859, "test_macro_f1_se": 4.106821860031689}}, "num_model_parameters": 559892482, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_em": 53.29202168861348, "test_f1": 58.16780384848672}, {"test_em": 52.63565891472868, "test_f1": 57.73209330426067}, {"test_em": 53.168469860896444, "test_f1": 58.301915926612615}, {"test_em": 50.77881619937695, "test_f1": 54.846733896154845}, {"test_em": 50.270270270270274, "test_f1": 55.63802184168312}, {"test_em": 52.35158057054742, "test_f1": 57.82048183074841}, {"test_em": 53.075170842824605, "test_f1": 57.61377641950788}, {"test_em": 54.46082234290147, "test_f1": 60.16681040691999}, {"test_em": 51.529411764705884, "test_f1": 56.66399706244907}, {"test_em": 51.39751552795031, "test_f1": 56.555250209865065}]}, "total": {"test_em": 52.29597379828156, "test_em_se": 0.7992497385538434, "test_f1": 57.35068847466884, "test_f1_se": 0.9296115437121908}}, "num_model_parameters": 558843906, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_em": 50.813323005422156, "test_f1": 55.899282693854495}, {"test_em": 52.945736434108525, "test_f1": 57.87741276318206}, {"test_em": 52.936630602782074, "test_f1": 58.66245402798603}, {"test_em": 51.4797507788162, "test_f1": 56.462399071843215}, {"test_em": 48.648648648648646, "test_f1": 54.14686258140479}, {"test_em": 54.51040863531226, "test_f1": 60.03326817579043}, {"test_em": 56.416097190584665, "test_f1": 61.59048970064472}, {"test_em": 53.45228859581071, "test_f1": 57.75951373096901}, {"test_em": 51.68627450980392, "test_f1": 58.23978160760167}, {"test_em": 54.81366459627329, "test_f1": 60.39712672339637}]}, "total": {"test_em": 52.77028229975625, "test_em_se": 1.3809479902055817, "test_f1": 58.106859107667276, "test_f1_se": 1.3836317214033202}}, "num_model_parameters": 558843906, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "microsoft/infoxlm-large", "results": {"raw": {"test": [{"test_em": 54.996127033307516, "test_f1": 60.20408341727883}, {"test_em": 54.96124031007752, "test_f1": 60.38240580255841}, {"test_em": 53.70942812982999, "test_f1": 59.311998029357476}, {"test_em": 54.67289719626168, "test_f1": 60.47465446037896}, {"test_em": 53.204633204633204, "test_f1": 58.746263846652276}, {"test_em": 54.66461063993832, "test_f1": 60.15698196613428}, {"test_em": 51.252847380410024, "test_f1": 57.3356324453913}, {"test_em": 54.92629945694337, "test_f1": 59.98926689730142}, {"test_em": 57.568627450980394, "test_f1": 62.72553786083192}, {"test_em": 56.05590062111801, "test_f1": 60.66834778403101}]}, "total": {"test_em": 54.601261142350005, "test_em_se": 1.0387660615447896, "test_f1": 59.99951725099159, "test_f1_se": 0.8632221699442486}}, "num_model_parameters": 558843906, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_em": 42.21533694810225, "test_f1": 46.86276402627155}, {"test_em": 42.17054263565891, "test_f1": 46.24977005486867}, {"test_em": 35.85780525502319, "test_f1": 39.86456815470085}, {"test_em": 35.2803738317757, "test_f1": 40.334937051614276}, {"test_em": 40.84942084942085, "test_f1": 44.803994620889796}, {"test_em": 34.6183500385505, "test_f1": 38.30145334451534}, {"test_em": 43.05239179954442, "test_f1": 46.26975909367977}, {"test_em": 41.03956555469356, "test_f1": 44.767119244176776}, {"test_em": 41.254901960784316, "test_f1": 45.44229626070456}, {"test_em": 38.66459627329193, "test_f1": 41.84165242594199}]}, "total": {"test_em": 39.50032851468456, "test_em_se": 1.9599395879433734, "test_f1": 43.47383142773636, "test_f1_se": 1.9228615030283478}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_em": 37.64523625096824, "test_f1": 41.77671018441596}, {"test_em": 40.542635658914726, "test_f1": 45.240516607772015}, {"test_em": 34.77588871715611, "test_f1": 39.40367014331871}, {"test_em": 37.77258566978193, "test_f1": 42.24310421913937}, {"test_em": 35.05791505791506, "test_f1": 40.41549969629121}, {"test_em": 36.85427910562837, "test_f1": 40.8084201434837}, {"test_em": 40.16704631738801, "test_f1": 44.56575391343052}, {"test_em": 35.60899922420481, "test_f1": 40.30647053944929}, {"test_em": 34.90196078431372, "test_f1": 40.5626059989608}, {"test_em": 34.08385093167702, "test_f1": 38.87251867220405}]}, "total": {"test_em": 36.7410397717948, "test_em_se": 1.4088878590773246, "test_f1": 41.41952701184656, "test_f1_se": 1.293702708306598}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "pere/roberta-debug-32", "results": {"raw": {"test": [{"test_em": 41.51820294345469, "test_f1": 46.69234250340528}, {"test_em": 36.89922480620155, "test_f1": 42.474057149238796}, {"test_em": 43.7403400309119, "test_f1": 48.2794734595556}, {"test_em": 42.13395638629284, "test_f1": 46.10696867415059}, {"test_em": 38.14671814671814, "test_f1": 43.316507748377056}, {"test_em": 42.328450269853505, "test_f1": 46.19108120216776}, {"test_em": 34.62414578587699, "test_f1": 39.32115786370043}, {"test_em": 37.315748642358415, "test_f1": 41.87527282319606}, {"test_em": 41.80392156862745, "test_f1": 46.416135300821736}, {"test_em": 40.45031055900621, "test_f1": 45.06026159793965}]}, "total": {"test_em": 39.89610191393017, "test_em_se": 1.8336911617363731, "test_f1": 44.57332583225529, "test_f1_se": 1.6996625444601823}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "studio-ousia/mluke-large", "results": {"raw": {"test": [{"test_loss": 0.8403845429420471, "test_mcc": 0.49363454526937817, "test_macro_f1": 0.6601353531225916, "test_runtime": 9.3785, "test_samples_per_second": 218.373, "test_steps_per_second": 6.824}, {"test_loss": 0.8566241264343262, "test_mcc": 0.4980537425632188, "test_macro_f1": 0.662839775426439, "test_runtime": 9.0058, "test_samples_per_second": 227.409, "test_steps_per_second": 7.107}, {"test_loss": 0.974850058555603, "test_mcc": 0.40863668536594966, "test_macro_f1": 0.5921333890203949, "test_runtime": 8.9136, "test_samples_per_second": 229.762, "test_steps_per_second": 7.18}, {"test_loss": 0.9781476855278015, "test_mcc": 0.45974442757027145, "test_macro_f1": 0.6386229947482329, "test_runtime": 9.0174, "test_samples_per_second": 227.117, "test_steps_per_second": 7.097}, {"test_loss": 0.9340391755104065, "test_mcc": 0.4414086145365619, "test_macro_f1": 0.6157603578076452, "test_runtime": 8.8141, "test_samples_per_second": 232.355, "test_steps_per_second": 7.261}, {"test_loss": 1.063976764678955, "test_mcc": 0.21203085797155338, "test_macro_f1": 0.3695492249664018, "test_runtime": 8.9718, "test_samples_per_second": 228.271, "test_steps_per_second": 7.133}, {"test_loss": 0.9454247951507568, "test_mcc": 0.47789158206794186, "test_macro_f1": 0.656870156606701, "test_runtime": 8.9545, "test_samples_per_second": 228.712, "test_steps_per_second": 7.147}, {"test_loss": 0.8424257040023804, "test_mcc": 0.4857792778486779, "test_macro_f1": 0.6577941331342427, "test_runtime": 9.1204, "test_samples_per_second": 224.553, "test_steps_per_second": 7.017}, {"test_loss": 0.8865067958831787, "test_mcc": 0.4286799231890033, "test_macro_f1": 0.6006108392425791, "test_runtime": 9.0287, "test_samples_per_second": 226.831, "test_steps_per_second": 7.088}, {"test_loss": 0.8737572431564331, "test_mcc": 0.4640902042576175, "test_macro_f1": 0.6389276147141626, "test_runtime": 8.7634, "test_samples_per_second": 233.698, "test_steps_per_second": 7.303}]}, "total": {"test_mcc": 43.69949860640175, "test_mcc_se": 5.216121460529248, "test_macro_f1": 60.9324383878939, "test_macro_f1_se": 5.4542704268736095}}, "num_model_parameters": 867887363, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "studio-ousia/mluke-large", "results": {"raw": {"test": [{"test_loss": 0.7792192697525024, "test_mcc": 0.600252235910194, "test_macro_f1": 0.7229571286554926, "test_runtime": 7.9353, "test_samples_per_second": 258.088, "test_steps_per_second": 8.065}, {"test_loss": 0.8374593257904053, "test_mcc": 0.5144167412655745, "test_macro_f1": 0.6659269423351528, "test_runtime": 7.3006, "test_samples_per_second": 280.524, "test_steps_per_second": 8.766}, {"test_loss": 0.8320730924606323, "test_mcc": 0.49651037832225425, "test_macro_f1": 0.6031894673404107, "test_runtime": 7.5333, "test_samples_per_second": 271.858, "test_steps_per_second": 8.496}, {"test_loss": 0.7915408611297607, "test_mcc": 0.5454887334040337, "test_macro_f1": 0.672999826739229, "test_runtime": 7.6136, "test_samples_per_second": 268.992, "test_steps_per_second": 8.406}, {"test_loss": 0.9182324409484863, "test_mcc": 0.41637979206955616, "test_macro_f1": 0.47534595773633503, "test_runtime": 7.6213, "test_samples_per_second": 268.72, "test_steps_per_second": 8.397}, {"test_loss": 0.7161765098571777, "test_mcc": 0.56150165836536, "test_macro_f1": 0.6904352629183416, "test_runtime": 7.9632, "test_samples_per_second": 257.184, "test_steps_per_second": 8.037}, {"test_loss": 0.7534033060073853, "test_mcc": 0.4656747381901139, "test_macro_f1": 0.48735396597663455, "test_runtime": 7.6208, "test_samples_per_second": 268.739, "test_steps_per_second": 8.398}, {"test_loss": 0.8844997882843018, "test_mcc": 0.48526663634327216, "test_macro_f1": 0.6241856822225599, "test_runtime": 7.6707, "test_samples_per_second": 266.991, "test_steps_per_second": 8.343}, {"test_loss": 0.8301092982292175, "test_mcc": 0.5559232643606704, "test_macro_f1": 0.6884673254487472, "test_runtime": 7.8096, "test_samples_per_second": 262.242, "test_steps_per_second": 8.195}, {"test_loss": 0.7713116407394409, "test_mcc": 0.5041465683620941, "test_macro_f1": 0.6206507980547538, "test_runtime": 8.1399, "test_samples_per_second": 251.599, "test_steps_per_second": 7.862}]}, "total": {"test_mcc": 51.45560746593123, "test_mcc_se": 3.301477429718152, "test_macro_f1": 62.51512357427658, "test_macro_f1_se": 5.21531428403026}}, "num_model_parameters": 867887363, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "studio-ousia/mluke-large", "results": {"raw": {"test": [{"test_loss": 0.36376529932022095, "test_mcc": 0.7508968230226722, "test_macro_f1": 0.8745114494807829, "test_runtime": 7.121, "test_samples_per_second": 287.6, "test_steps_per_second": 8.988}, {"test_loss": 0.5909978151321411, "test_mcc": 0.5433532774813086, "test_macro_f1": 0.7513574237034264, "test_runtime": 7.0966, "test_samples_per_second": 288.588, "test_steps_per_second": 9.018}, {"test_loss": 0.3996143937110901, "test_mcc": 0.7028225181587098, "test_macro_f1": 0.845534995977474, "test_runtime": 7.1294, "test_samples_per_second": 287.262, "test_steps_per_second": 8.977}, {"test_loss": 0.46681466698646545, "test_mcc": 0.7099768941643515, "test_macro_f1": 0.8520671194378604, "test_runtime": 6.9792, "test_samples_per_second": 293.443, "test_steps_per_second": 9.17}, {"test_loss": 0.49379152059555054, "test_mcc": 0.7020026641218218, "test_macro_f1": 0.8484820841758218, "test_runtime": 7.1709, "test_samples_per_second": 285.599, "test_steps_per_second": 8.925}, {"test_loss": 0.4766402840614319, "test_mcc": 0.6826144286571606, "test_macro_f1": 0.8413021993808021, "test_runtime": 7.0986, "test_samples_per_second": 288.506, "test_steps_per_second": 9.016}, {"test_loss": 0.4023135304450989, "test_mcc": 0.6950367814921433, "test_macro_f1": 0.8464682580610658, "test_runtime": 6.9092, "test_samples_per_second": 296.418, "test_steps_per_second": 9.263}, {"test_loss": 0.3697165250778198, "test_mcc": 0.7325535410941534, "test_macro_f1": 0.8526335513270379, "test_runtime": 6.9999, "test_samples_per_second": 292.575, "test_steps_per_second": 9.143}, {"test_loss": 0.3829655945301056, "test_mcc": 0.745206194057718, "test_macro_f1": 0.8718002383484953, "test_runtime": 7.0955, "test_samples_per_second": 288.634, "test_steps_per_second": 9.02}, {"test_loss": 0.473572313785553, "test_mcc": 0.6816726059497762, "test_macro_f1": 0.8379848679633365, "test_runtime": 6.9865, "test_samples_per_second": 293.138, "test_steps_per_second": 9.161}]}, "total": {"test_mcc": 69.46135728199815, "test_mcc_se": 3.6209157389269455, "test_macro_f1": 84.22142187856103, "test_macro_f1_se": 2.1136290343281945}}, "num_model_parameters": 867886338, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "studio-ousia/mluke-large", "results": {"raw": {"test": [{"test_loss": 0.6776037812232971, "test_mcc": 0.18512939889990085, "test_macro_f1": 0.4579489699336287, "test_runtime": 7.9221, "test_samples_per_second": 258.518, "test_steps_per_second": 8.079}, {"test_loss": 0.5304893255233765, "test_mcc": 0.6374746877560398, "test_macro_f1": 0.8121476649100056, "test_runtime": 7.8766, "test_samples_per_second": 260.011, "test_steps_per_second": 8.125}, {"test_loss": 0.6245717406272888, "test_mcc": 0.39432012201979033, "test_macro_f1": 0.6127731875726101, "test_runtime": 7.7253, "test_samples_per_second": 265.103, "test_steps_per_second": 8.284}, {"test_loss": 0.5503579378128052, "test_mcc": 0.60151200592333, "test_macro_f1": 0.7952936925022779, "test_runtime": 8.0231, "test_samples_per_second": 255.262, "test_steps_per_second": 7.977}, {"test_loss": 0.6696659326553345, "test_mcc": 0.3504033870025786, "test_macro_f1": 0.667830010803171, "test_runtime": 7.7197, "test_samples_per_second": 265.294, "test_steps_per_second": 8.29}, {"test_loss": 0.6041553616523743, "test_mcc": 0.49766929969714707, "test_macro_f1": 0.7271844904617474, "test_runtime": 7.8472, "test_samples_per_second": 260.984, "test_steps_per_second": 8.156}, {"test_loss": 0.6653595566749573, "test_mcc": 0.3813833540615574, "test_macro_f1": 0.6743033385218902, "test_runtime": 7.7463, "test_samples_per_second": 264.383, "test_steps_per_second": 8.262}, {"test_loss": 0.46197614073753357, "test_mcc": 0.6326902063962861, "test_macro_f1": 0.8060274861896854, "test_runtime": 7.6402, "test_samples_per_second": 268.057, "test_steps_per_second": 8.377}, {"test_loss": 0.6567813158035278, "test_mcc": 0.31656988330950453, "test_macro_f1": 0.6484465043282082, "test_runtime": 7.6511, "test_samples_per_second": 267.672, "test_steps_per_second": 8.365}, {"test_loss": 0.5910019278526306, "test_mcc": 0.505936645047947, "test_macro_f1": 0.7451524212440697, "test_runtime": 7.7368, "test_samples_per_second": 264.708, "test_steps_per_second": 8.272}]}, "total": {"test_mcc": 45.03088990114081, "test_mcc_se": 9.298626974601643, "test_macro_f1": 69.47107766467295, "test_macro_f1_se": 6.724828288528392}}, "num_model_parameters": 867886338, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "studio-ousia/mluke-large", "results": {"raw": {"test": [{"test_loss": 0.5947601795196533, "test_mcc": 0.49029594503544677, "test_macro_f1": 0.7436296873261379, "test_runtime": 7.1549, "test_samples_per_second": 286.239, "test_steps_per_second": 8.945}, {"test_loss": 0.6546096801757812, "test_mcc": 0.2203758177564697, "test_macro_f1": 0.589265609860387, "test_runtime": 7.4466, "test_samples_per_second": 275.024, "test_steps_per_second": 8.594}, {"test_loss": 0.49299877882003784, "test_mcc": 0.59197517504069, "test_macro_f1": 0.7900166415597321, "test_runtime": 7.3762, "test_samples_per_second": 277.648, "test_steps_per_second": 8.676}, {"test_loss": 0.46172648668289185, "test_mcc": 0.6204687698291155, "test_macro_f1": 0.8064058578811246, "test_runtime": 7.2822, "test_samples_per_second": 281.232, "test_steps_per_second": 8.788}, {"test_loss": 0.666724681854248, "test_mcc": 0.3235272141983157, "test_macro_f1": 0.6383629819939676, "test_runtime": 7.1863, "test_samples_per_second": 284.986, "test_steps_per_second": 8.906}, {"test_loss": 0.4868467450141907, "test_mcc": 0.6951247590843884, "test_macro_f1": 0.846327813224365, "test_runtime": 6.8787, "test_samples_per_second": 297.732, "test_steps_per_second": 9.304}, {"test_loss": 0.4304701089859009, "test_mcc": 0.641639900272041, "test_macro_f1": 0.8165749368002889, "test_runtime": 6.9824, "test_samples_per_second": 293.309, "test_steps_per_second": 9.166}, {"test_loss": 0.5140817165374756, "test_mcc": 0.6379876419718292, "test_macro_f1": 0.8186649941445019, "test_runtime": 7.0241, "test_samples_per_second": 291.567, "test_steps_per_second": 9.111}, {"test_loss": 0.5862935781478882, "test_mcc": 0.4910166909905861, "test_macro_f1": 0.7050712107906101, "test_runtime": 6.9881, "test_samples_per_second": 293.071, "test_steps_per_second": 9.158}, {"test_loss": 0.4668717682361603, "test_mcc": 0.6401957775402213, "test_macro_f1": 0.8153756244346284, "test_runtime": 7.2203, "test_samples_per_second": 283.645, "test_steps_per_second": 8.864}]}, "total": {"test_mcc": 53.52607691719102, "test_mcc_se": 9.621475504798871, "test_macro_f1": 75.69695358015743, "test_macro_f1_se": 5.361907763648057}}, "num_model_parameters": 867886338, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "studio-ousia/mluke-large", "results": {"raw": {"test": [{"test_loss": 0.563541054725647, "test_mcc": 0.5125509347347589, "test_macro_f1": 0.7454232244929919, "test_runtime": 7.6947, "test_samples_per_second": 266.156, "test_steps_per_second": 8.317}, {"test_loss": 0.5361778140068054, "test_mcc": 0.5193284066379744, "test_macro_f1": 0.7579856376693028, "test_runtime": 7.4885, "test_samples_per_second": 273.487, "test_steps_per_second": 8.546}, {"test_loss": 0.6351890563964844, "test_mcc": 0.41554397869015586, "test_macro_f1": 0.6916251817604153, "test_runtime": 7.8912, "test_samples_per_second": 259.53, "test_steps_per_second": 8.11}, {"test_loss": 0.6893004179000854, "test_mcc": 0.04865237865979647, "test_macro_f1": 0.3741543009835693, "test_runtime": 7.4139, "test_samples_per_second": 276.239, "test_steps_per_second": 8.632}, {"test_loss": 0.5811473727226257, "test_mcc": 0.4518369164200824, "test_macro_f1": 0.7250944446629974, "test_runtime": 7.6755, "test_samples_per_second": 266.822, "test_steps_per_second": 8.338}, {"test_loss": 0.6310117840766907, "test_mcc": 0.39715715917009337, "test_macro_f1": 0.6810710542574682, "test_runtime": 7.7068, "test_samples_per_second": 265.739, "test_steps_per_second": 8.304}, {"test_loss": 0.6307476758956909, "test_mcc": 0.46257397242402326, "test_macro_f1": 0.7309338729687074, "test_runtime": 7.5839, "test_samples_per_second": 270.044, "test_steps_per_second": 8.439}, {"test_loss": 0.5689460635185242, "test_mcc": 0.4652730934669228, "test_macro_f1": 0.7292848106695408, "test_runtime": 7.7944, "test_samples_per_second": 262.753, "test_steps_per_second": 8.211}, {"test_loss": 0.6908267736434937, "test_mcc": 0.04232856209372484, "test_macro_f1": 0.33726520681265204, "test_runtime": 7.5046, "test_samples_per_second": 272.901, "test_steps_per_second": 8.528}, {"test_loss": 0.5065163969993591, "test_mcc": 0.531171325394054, "test_macro_f1": 0.7642585132765642, "test_runtime": 7.5685, "test_samples_per_second": 270.594, "test_steps_per_second": 8.456}]}, "total": {"test_mcc": 38.46416727691586, "test_mcc_se": 11.395769661965687, "test_macro_f1": 65.3709624755421, "test_macro_f1_se": 9.881359427501998}}, "num_model_parameters": 867886338, "max_sequence_length": 512, "vocabulary_size": 250004}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_em": 42.3702556158017, "test_f1": 46.46664193386436}, {"test_em": 38.52713178294574, "test_f1": 42.867330033720705}, {"test_em": 34.93044822256569, "test_f1": 39.08509348083401}, {"test_em": 35.046728971962615, "test_f1": 39.56173897647655}, {"test_em": 41.15830115830116, "test_f1": 45.4119804440459}, {"test_em": 43.25366229760987, "test_f1": 47.03684724173181}, {"test_em": 40.16704631738801, "test_f1": 44.27835440975582}, {"test_em": 43.44453064391001, "test_f1": 47.58176518889574}, {"test_em": 38.666666666666664, "test_f1": 42.97433906266543}, {"test_em": 40.29503105590062, "test_f1": 43.99116272062905}]}, "total": {"test_em": 39.78598027330521, "test_em_se": 1.8850693814430497, "test_f1": 43.92552534926194, "test_f1_se": 1.8051515749494254}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_em": 42.447714949651434, "test_f1": 47.0535222195262}, {"test_em": 41.08527131782946, "test_f1": 45.48792495134565}, {"test_em": 38.717156105100464, "test_f1": 42.84762297137823}, {"test_em": 37.53894080996885, "test_f1": 42.368962176834515}, {"test_em": 33.59073359073359, "test_f1": 39.01901037874925}, {"test_em": 36.700077101002314, "test_f1": 41.339797482748246}, {"test_em": 37.73728170083523, "test_f1": 42.61329741959429}, {"test_em": 35.06594259115594, "test_f1": 39.649300199856604}, {"test_em": 39.294117647058826, "test_f1": 44.111126639068026}, {"test_em": 42.1583850931677, "test_f1": 47.493396336422144}]}, "total": {"test_em": 38.43356209065038, "test_em_se": 1.8120344061502465, "test_f1": 43.19839607755232, "test_f1_se": 1.7779206257411964}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "pere/roberta-debug-8", "results": {"raw": {"test": [{"test_em": 38.49728892331526, "test_f1": 43.27283998355451}, {"test_em": 44.57364341085271, "test_f1": 49.231420548235995}, {"test_em": 43.508500772797525, "test_f1": 48.18244688996094}, {"test_em": 37.850467289719624, "test_f1": 42.968659549885516}, {"test_em": 39.84555984555985, "test_f1": 44.34719871694661}, {"test_em": 40.86353122590594, "test_f1": 44.88446357199685}, {"test_em": 40.31890660592255, "test_f1": 45.06858878368857}, {"test_em": 41.66020170674942, "test_f1": 47.02972914492991}, {"test_em": 37.333333333333336, "test_f1": 42.5831307249446}, {"test_em": 45.108695652173914, "test_f1": 49.28517530674366}]}, "total": {"test_em": 40.95601287663301, "test_em_se": 1.7012304274793422, "test_f1": 45.68536532208872, "test_f1_se": 1.5898037402952085}}, "num_model_parameters": 277455362, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "xlm-mlm-17-1280", "results": {"raw": {"test": [{"test_loss": 0.6666779518127441, "test_mcc": 0.517066412223375, "test_macro_f1": 0.5126743538270696, "test_runtime": 28.6465, "test_samples_per_second": 71.492, "test_steps_per_second": 8.937}, {"test_loss": 0.7391824722290039, "test_mcc": 0.49654625331228086, "test_macro_f1": 0.5690571651523322, "test_runtime": 27.3107, "test_samples_per_second": 74.989, "test_steps_per_second": 9.374}, {"test_loss": 0.7551897764205933, "test_mcc": 0.5201001971615132, "test_macro_f1": 0.6001940072199242, "test_runtime": 27.981, "test_samples_per_second": 73.193, "test_steps_per_second": 9.149}, {"test_loss": 0.47593238949775696, "test_mcc": 0.6859042883530188, "test_macro_f1": 0.6635449411362639, "test_runtime": 27.3955, "test_samples_per_second": 74.757, "test_steps_per_second": 9.345}, {"test_loss": 0.47706174850463867, "test_mcc": 0.6904942547370517, "test_macro_f1": 0.6687471462769302, "test_runtime": 26.8615, "test_samples_per_second": 76.243, "test_steps_per_second": 9.53}, {"test_loss": 0.8671406507492065, "test_mcc": 0.4022861248064164, "test_macro_f1": 0.4681816507304977, "test_runtime": 27.8734, "test_samples_per_second": 73.475, "test_steps_per_second": 9.184}, {"test_loss": 0.5454994440078735, "test_mcc": 0.6816868848570076, "test_macro_f1": 0.7132896753024293, "test_runtime": 26.7636, "test_samples_per_second": 76.522, "test_steps_per_second": 9.565}, {"test_loss": 0.6221022605895996, "test_mcc": 0.6450407888707266, "test_macro_f1": 0.6721818743868244, "test_runtime": 28.7117, "test_samples_per_second": 71.33, "test_steps_per_second": 8.916}, {"test_loss": 0.5716241598129272, "test_mcc": 0.6611584660545963, "test_macro_f1": 0.5999402159537957, "test_runtime": 28.2938, "test_samples_per_second": 72.383, "test_steps_per_second": 9.048}, {"test_loss": 0.5696713924407959, "test_mcc": 0.6605168322495364, "test_macro_f1": 0.6008121888568038, "test_runtime": 27.4111, "test_samples_per_second": 74.714, "test_steps_per_second": 9.339}]}, "total": {"test_mcc": 59.60800502625523, "test_mcc_se": 6.35363137100767, "test_macro_f1": 60.686232188428704, "test_macro_f1_se": 4.724733670402684}}, "num_model_parameters": 571500803, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "xlm-mlm-17-1280", "results": {"raw": {"test": [{"test_loss": 1.0317540168762207, "test_mcc": 0.2843450283986234, "test_macro_f1": 0.47812521805044267, "test_runtime": 9.8445, "test_samples_per_second": 208.035, "test_steps_per_second": 6.501}, {"test_loss": 1.0017051696777344, "test_mcc": 0.2912252237893551, "test_macro_f1": 0.5057852889938409, "test_runtime": 9.8859, "test_samples_per_second": 207.164, "test_steps_per_second": 6.474}, {"test_loss": 0.9972758293151855, "test_mcc": 0.2515842456526368, "test_macro_f1": 0.4652161223267688, "test_runtime": 9.8792, "test_samples_per_second": 207.305, "test_steps_per_second": 6.478}, {"test_loss": 1.0846858024597168, "test_mcc": 0.18483376790714004, "test_macro_f1": 0.423092142738451, "test_runtime": 9.9013, "test_samples_per_second": 206.841, "test_steps_per_second": 6.464}, {"test_loss": 1.0318810939788818, "test_mcc": 0.31539642082879404, "test_macro_f1": 0.5419784353224781, "test_runtime": 9.8791, "test_samples_per_second": 207.306, "test_steps_per_second": 6.478}, {"test_loss": 1.0435819625854492, "test_mcc": 0.2014979587929097, "test_macro_f1": 0.38197606431218173, "test_runtime": 10.175, "test_samples_per_second": 201.278, "test_steps_per_second": 6.29}, {"test_loss": 1.0883618593215942, "test_mcc": 0.18059447447566565, "test_macro_f1": 0.36432734255038407, "test_runtime": 10.0223, "test_samples_per_second": 204.344, "test_steps_per_second": 6.386}, {"test_loss": 1.0873634815216064, "test_mcc": 0.15067738163649713, "test_macro_f1": 0.39309764479160697, "test_runtime": 9.8384, "test_samples_per_second": 208.163, "test_steps_per_second": 6.505}, {"test_loss": 1.0257530212402344, "test_mcc": 0.2643336377524051, "test_macro_f1": 0.45831706817287393, "test_runtime": 9.7318, "test_samples_per_second": 210.445, "test_steps_per_second": 6.576}, {"test_loss": 1.0400819778442383, "test_mcc": 0.22306208603335118, "test_macro_f1": 0.4723779930051116, "test_runtime": 9.7952, "test_samples_per_second": 209.082, "test_steps_per_second": 6.534}]}, "total": {"test_mcc": 23.475502252673785, "test_mcc_se": 3.3977421471782105, "test_macro_f1": 44.8429332026414, "test_macro_f1_se": 3.522480968362892}}, "num_model_parameters": 571500803, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "xlm-mlm-17-1280", "results": {"raw": {"test": [{"test_loss": 0.9973660707473755, "test_mcc": 0.1267564721473716, "test_macro_f1": 0.33163127353271704, "test_runtime": 7.9066, "test_samples_per_second": 259.024, "test_steps_per_second": 8.095}, {"test_loss": 0.9833859205245972, "test_mcc": 0.24186101651537364, "test_macro_f1": 0.37729585479852884, "test_runtime": 7.6479, "test_samples_per_second": 267.787, "test_steps_per_second": 8.368}, {"test_loss": 0.9762065410614014, "test_mcc": 0.18527892105402907, "test_macro_f1": 0.38180688200258256, "test_runtime": 7.5257, "test_samples_per_second": 272.133, "test_steps_per_second": 8.504}, {"test_loss": 0.9638457298278809, "test_mcc": 0.2512078652049012, "test_macro_f1": 0.4736183896909312, "test_runtime": 7.7016, "test_samples_per_second": 265.92, "test_steps_per_second": 8.31}, {"test_loss": 0.9881482720375061, "test_mcc": 0.10857756429418403, "test_macro_f1": 0.33093033073133826, "test_runtime": 7.8343, "test_samples_per_second": 261.416, "test_steps_per_second": 8.169}, {"test_loss": 1.072485089302063, "test_mcc": 0.13593166986988495, "test_macro_f1": 0.35596202374367963, "test_runtime": 8.0201, "test_samples_per_second": 255.357, "test_steps_per_second": 7.98}, {"test_loss": 1.004997730255127, "test_mcc": -0.006589258318861822, "test_macro_f1": 0.30262186952115205, "test_runtime": 7.6637, "test_samples_per_second": 267.233, "test_steps_per_second": 8.351}, {"test_loss": 0.9692195653915405, "test_mcc": 0.24634757418389297, "test_macro_f1": 0.39824566163892766, "test_runtime": 7.895, "test_samples_per_second": 259.406, "test_steps_per_second": 8.106}, {"test_loss": 0.984402060508728, "test_mcc": 0.1671504524287366, "test_macro_f1": 0.3807954183481706, "test_runtime": 8.0441, "test_samples_per_second": 254.597, "test_steps_per_second": 7.956}, {"test_loss": 0.970928430557251, "test_mcc": 0.12198384317497342, "test_macro_f1": 0.32702306820888466, "test_runtime": 8.2376, "test_samples_per_second": 248.617, "test_steps_per_second": 7.769}]}, "total": {"test_mcc": 15.785061205544856, "test_mcc_se": 4.9172112881472945, "test_macro_f1": 36.59930772216913, "test_macro_f1_se": 3.0128301393412205}}, "num_model_parameters": 571500803, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "xlm-mlm-17-1280", "results": {"raw": {"test": [{"test_loss": 0.5625850558280945, "test_mcc": 0.4708174550237806, "test_macro_f1": 0.7338257328341612, "test_runtime": 6.8824, "test_samples_per_second": 297.571, "test_steps_per_second": 9.299}, {"test_loss": 0.5158264636993408, "test_mcc": 0.4954423604213217, "test_macro_f1": 0.7285503218085211, "test_runtime": 7.3829, "test_samples_per_second": 277.398, "test_steps_per_second": 8.669}, {"test_loss": 0.6854832172393799, "test_mcc": 0.18908586597125837, "test_macro_f1": 0.5925678905621599, "test_runtime": 7.0271, "test_samples_per_second": 291.444, "test_steps_per_second": 9.108}, {"test_loss": 0.6925078630447388, "test_mcc": 0.10065996786328925, "test_macro_f1": 0.5050893812469011, "test_runtime": 6.8954, "test_samples_per_second": 297.012, "test_steps_per_second": 9.282}, {"test_loss": 0.5355439782142639, "test_mcc": 0.4720760649992535, "test_macro_f1": 0.7253825642040319, "test_runtime": 7.0919, "test_samples_per_second": 288.781, "test_steps_per_second": 9.024}, {"test_loss": 0.559203028678894, "test_mcc": 0.5303698164827246, "test_macro_f1": 0.7651321830050524, "test_runtime": 6.8773, "test_samples_per_second": 297.791, "test_steps_per_second": 9.306}, {"test_loss": 0.5247447490692139, "test_mcc": 0.5078097134645957, "test_macro_f1": 0.753904137742271, "test_runtime": 7.3859, "test_samples_per_second": 277.284, "test_steps_per_second": 8.665}, {"test_loss": 0.7015568614006042, "test_mcc": 0.07551982720367961, "test_macro_f1": 0.4357156144097725, "test_runtime": 7.0042, "test_samples_per_second": 292.397, "test_steps_per_second": 9.137}, {"test_loss": 0.6612187623977661, "test_mcc": 0.3467088382005266, "test_macro_f1": 0.6111980589537243, "test_runtime": 7.1715, "test_samples_per_second": 285.574, "test_steps_per_second": 8.924}, {"test_loss": 0.7021039724349976, "test_mcc": 0.06912446020517603, "test_macro_f1": 0.5273097281146302, "test_runtime": 7.1112, "test_samples_per_second": 287.996, "test_steps_per_second": 9.0}]}, "total": {"test_mcc": 32.576143698356056, "test_mcc_se": 12.126684648584895, "test_macro_f1": 63.78675612881226, "test_macro_f1_se": 7.398341364932051}}, "num_model_parameters": 571499522, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "xlm-mlm-17-1280", "results": {"raw": {"test": [{"test_loss": 0.6952642202377319, "test_mcc": 0.03974264803352869, "test_macro_f1": 0.4935340667824744, "test_runtime": 8.4677, "test_samples_per_second": 241.861, "test_steps_per_second": 7.558}, {"test_loss": 0.6931617259979248, "test_mcc": 0.0037515557822449743, "test_macro_f1": 0.38705052474622925, "test_runtime": 9.0047, "test_samples_per_second": 227.437, "test_steps_per_second": 7.107}, {"test_loss": 0.6965273022651672, "test_mcc": 0.06755119195053876, "test_macro_f1": 0.530260415322731, "test_runtime": 8.6618, "test_samples_per_second": 236.441, "test_steps_per_second": 7.389}, {"test_loss": 0.7414767742156982, "test_mcc": -0.03724099630264406, "test_macro_f1": 0.4547890292643623, "test_runtime": 9.0403, "test_samples_per_second": 226.542, "test_steps_per_second": 7.079}, {"test_loss": 0.7019144296646118, "test_mcc": 0.005239436104917155, "test_macro_f1": 0.4748161272898904, "test_runtime": 9.0058, "test_samples_per_second": 227.408, "test_steps_per_second": 7.106}, {"test_loss": 0.7210749983787537, "test_mcc": 0.021191352537887134, "test_macro_f1": 0.5074640022382425, "test_runtime": 8.4897, "test_samples_per_second": 241.234, "test_steps_per_second": 7.539}, {"test_loss": 0.6920444369316101, "test_mcc": 0.08197618808397147, "test_macro_f1": 0.5137028213628104, "test_runtime": 8.2766, "test_samples_per_second": 247.444, "test_steps_per_second": 7.733}, {"test_loss": 0.7009011507034302, "test_mcc": 0.00781976056159493, "test_macro_f1": 0.3876716400095842, "test_runtime": 8.4591, "test_samples_per_second": 242.107, "test_steps_per_second": 7.566}, {"test_loss": 0.717637300491333, "test_mcc": -0.007929115048494789, "test_macro_f1": 0.4390794607565021, "test_runtime": 8.4026, "test_samples_per_second": 243.735, "test_steps_per_second": 7.617}, {"test_loss": 0.7079287171363831, "test_mcc": 0.05293663864251583, "test_macro_f1": 0.4777501825543482, "test_runtime": 8.7228, "test_samples_per_second": 234.788, "test_steps_per_second": 7.337}]}, "total": {"test_mcc": 2.350386603460601, "test_mcc_se": 2.276584802405908, "test_macro_f1": 46.66118270327175, "test_macro_f1_se": 3.086137337426235}}, "num_model_parameters": 571499522, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "xlm-mlm-17-1280", "results": {"raw": {"test": [{"test_loss": 0.7201765775680542, "test_mcc": 0.025251351307356718, "test_macro_f1": 0.4033613279804138, "test_runtime": 8.0231, "test_samples_per_second": 255.264, "test_steps_per_second": 7.977}, {"test_loss": 0.6928587555885315, "test_mcc": 0.008608989723717235, "test_macro_f1": 0.3613585414724146, "test_runtime": 7.8791, "test_samples_per_second": 259.927, "test_steps_per_second": 8.123}, {"test_loss": 0.7011100053787231, "test_mcc": 0.07915013184562597, "test_macro_f1": 0.46391677268936465, "test_runtime": 7.9059, "test_samples_per_second": 259.047, "test_steps_per_second": 8.095}, {"test_loss": 0.7556521892547607, "test_mcc": -0.004072790007015488, "test_macro_f1": 0.48787768174503365, "test_runtime": 8.034, "test_samples_per_second": 254.917, "test_steps_per_second": 7.966}, {"test_loss": 0.6923911571502686, "test_mcc": 0.0794126524932587, "test_macro_f1": 0.5294619918557363, "test_runtime": 8.0743, "test_samples_per_second": 253.643, "test_steps_per_second": 7.926}, {"test_loss": 0.7136536836624146, "test_mcc": 0.11277779746412955, "test_macro_f1": 0.44155281803556556, "test_runtime": 7.821, "test_samples_per_second": 261.86, "test_steps_per_second": 8.183}, {"test_loss": 0.6998698115348816, "test_mcc": 0.008885269424772586, "test_macro_f1": 0.3636131381223479, "test_runtime": 8.0055, "test_samples_per_second": 255.824, "test_steps_per_second": 7.995}, {"test_loss": 0.7220396399497986, "test_mcc": 0.011447722118799354, "test_macro_f1": 0.40195878560410586, "test_runtime": 7.6981, "test_samples_per_second": 266.041, "test_steps_per_second": 8.314}, {"test_loss": 0.6936630010604858, "test_mcc": -0.00817322883932768, "test_macro_f1": 0.36046568777293886, "test_runtime": 7.6882, "test_samples_per_second": 266.384, "test_steps_per_second": 8.324}, {"test_loss": 0.716612696647644, "test_mcc": -0.004118532337937756, "test_macro_f1": 0.47856125405137595, "test_runtime": 8.0907, "test_samples_per_second": 253.129, "test_steps_per_second": 7.91}]}, "total": {"test_mcc": 3.0916936319337918, "test_mcc_se": 2.6741588759585353, "test_macro_f1": 42.92127999329297, "test_macro_f1_se": 3.714712339193592}}, "num_model_parameters": 571499522, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "xlm-mlm-17-1280", "results": {"raw": {"test": [{"test_loss": 0.6909239888191223, "test_mcc": 0.026903658955585368, "test_macro_f1": 0.49217658846628753, "test_runtime": 7.7065, "test_samples_per_second": 265.749, "test_steps_per_second": 8.305}, {"test_loss": 0.6968351602554321, "test_mcc": 0.050593560596067365, "test_macro_f1": 0.525288763019256, "test_runtime": 8.1704, "test_samples_per_second": 250.662, "test_steps_per_second": 7.833}, {"test_loss": 0.7099180221557617, "test_mcc": 0.007314716262815125, "test_macro_f1": 0.36536596876543903, "test_runtime": 8.0024, "test_samples_per_second": 255.923, "test_steps_per_second": 7.998}, {"test_loss": 0.6949352025985718, "test_mcc": 0.02918561263719654, "test_macro_f1": 0.5117524134036469, "test_runtime": 7.6346, "test_samples_per_second": 268.253, "test_steps_per_second": 8.383}, {"test_loss": 0.7095944881439209, "test_mcc": 0.017291289630597773, "test_macro_f1": 0.4904904904904905, "test_runtime": 7.8292, "test_samples_per_second": 261.586, "test_steps_per_second": 8.175}, {"test_loss": 0.7483018636703491, "test_mcc": 0.032986012030679544, "test_macro_f1": 0.4970139844975314, "test_runtime": 7.9738, "test_samples_per_second": 256.842, "test_steps_per_second": 8.026}, {"test_loss": 0.6895705461502075, "test_mcc": 0.04950425858649184, "test_macro_f1": 0.5102635203128004, "test_runtime": 7.8613, "test_samples_per_second": 260.517, "test_steps_per_second": 8.141}, {"test_loss": 0.6958271265029907, "test_mcc": 0.028995263491674177, "test_macro_f1": 0.5052175441663697, "test_runtime": 7.8516, "test_samples_per_second": 260.837, "test_steps_per_second": 8.151}, {"test_loss": 0.6975195407867432, "test_mcc": 0.017286666164401825, "test_macro_f1": 0.48159741193829886, "test_runtime": 7.7508, "test_samples_per_second": 264.232, "test_steps_per_second": 8.257}, {"test_loss": 0.6977466940879822, "test_mcc": 0.0, "test_macro_f1": 0.3289646133682831, "test_runtime": 8.0581, "test_samples_per_second": 254.154, "test_steps_per_second": 7.942}]}, "total": {"test_mcc": 2.6006103835550953, "test_mcc_se": 1.0127588389436408, "test_macro_f1": 47.08131298428403, "test_macro_f1_se": 4.145970322224725}}, "num_model_parameters": 571499522, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.9242972135543823, "test_mcc": 0.44786718317570456, "test_macro_f1": 0.6375001972287508, "test_runtime": 9.8079, "test_samples_per_second": 208.812, "test_steps_per_second": 6.525}, {"test_loss": 0.8925704956054688, "test_mcc": 0.4594609080077357, "test_macro_f1": 0.6423227177596584, "test_runtime": 9.8566, "test_samples_per_second": 207.779, "test_steps_per_second": 6.493}, {"test_loss": 0.9907219409942627, "test_mcc": 0.36632527746216087, "test_macro_f1": 0.5335004127591035, "test_runtime": 10.4224, "test_samples_per_second": 196.5, "test_steps_per_second": 6.141}, {"test_loss": 0.9479309916496277, "test_mcc": 0.32835434485621834, "test_macro_f1": 0.5422973667526273, "test_runtime": 10.0, "test_samples_per_second": 204.8, "test_steps_per_second": 6.4}, {"test_loss": 0.9496237635612488, "test_mcc": 0.33601718424078586, "test_macro_f1": 0.5588354442736169, "test_runtime": 9.3523, "test_samples_per_second": 218.983, "test_steps_per_second": 6.843}, {"test_loss": 0.9355945587158203, "test_mcc": 0.40525492938391333, "test_macro_f1": 0.5940711015457608, "test_runtime": 9.6525, "test_samples_per_second": 212.172, "test_steps_per_second": 6.63}, {"test_loss": 0.9130759835243225, "test_mcc": 0.4402093565017134, "test_macro_f1": 0.6166107570943576, "test_runtime": 9.6435, "test_samples_per_second": 212.371, "test_steps_per_second": 6.637}, {"test_loss": 0.9196063280105591, "test_mcc": 0.4022163671002124, "test_macro_f1": 0.6005741267350263, "test_runtime": 9.6705, "test_samples_per_second": 211.779, "test_steps_per_second": 6.618}, {"test_loss": 0.9258880019187927, "test_mcc": 0.4219279574941899, "test_macro_f1": 0.6095616891543498, "test_runtime": 9.7311, "test_samples_per_second": 210.459, "test_steps_per_second": 6.577}, {"test_loss": 0.9588680863380432, "test_mcc": 0.32859649586635975, "test_macro_f1": 0.5285825399058831, "test_runtime": 9.4661, "test_samples_per_second": 216.35, "test_steps_per_second": 6.761}]}, "total": {"test_mcc": 39.362300040889934, "test_mcc_se": 3.133937766617244, "test_macro_f1": 58.63856353209134, "test_macro_f1_se": 2.6371980934647037}}, "num_model_parameters": 561463811, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.9119043350219727, "test_mcc": 0.3381067005731012, "test_macro_f1": 0.42742363181229087, "test_runtime": 8.4178, "test_samples_per_second": 243.295, "test_steps_per_second": 7.603}, {"test_loss": 0.8496301174163818, "test_mcc": 0.38651438601741395, "test_macro_f1": 0.45676331279077037, "test_runtime": 7.8913, "test_samples_per_second": 259.526, "test_steps_per_second": 8.11}, {"test_loss": 0.9183294773101807, "test_mcc": 0.3170647343785363, "test_macro_f1": 0.44174609256291714, "test_runtime": 8.2404, "test_samples_per_second": 248.532, "test_steps_per_second": 7.767}, {"test_loss": 0.92252117395401, "test_mcc": 0.24826161742520741, "test_macro_f1": 0.3561895223529104, "test_runtime": 8.1519, "test_samples_per_second": 251.23, "test_steps_per_second": 7.851}, {"test_loss": 0.8659495115280151, "test_mcc": 0.341683983601497, "test_macro_f1": 0.43858084489736165, "test_runtime": 8.2128, "test_samples_per_second": 249.366, "test_steps_per_second": 7.793}, {"test_loss": 0.9106292128562927, "test_mcc": 0.33392523944825503, "test_macro_f1": 0.4319519695886558, "test_runtime": 8.3289, "test_samples_per_second": 245.89, "test_steps_per_second": 7.684}, {"test_loss": 0.8823076486587524, "test_mcc": 0.3646617822416118, "test_macro_f1": 0.43568886385899214, "test_runtime": 8.0334, "test_samples_per_second": 254.937, "test_steps_per_second": 7.967}, {"test_loss": 0.9247609376907349, "test_mcc": 0.3807644637638223, "test_macro_f1": 0.500974145132835, "test_runtime": 8.2763, "test_samples_per_second": 247.453, "test_steps_per_second": 7.733}, {"test_loss": 0.8716704249382019, "test_mcc": 0.3513729863448404, "test_macro_f1": 0.4416647043572783, "test_runtime": 8.4379, "test_samples_per_second": 242.714, "test_steps_per_second": 7.585}, {"test_loss": 0.8836926221847534, "test_mcc": 0.3547317146485598, "test_macro_f1": 0.4433686860571, "test_runtime": 8.4738, "test_samples_per_second": 241.687, "test_steps_per_second": 7.553}]}, "total": {"test_mcc": 34.17087608442845, "test_mcc_se": 2.4213896956680263, "test_macro_f1": 43.74351773411111, "test_macro_f1_se": 2.1882250753692363}}, "num_model_parameters": 561463811, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.06917205452919006, "test_micro_f1": 0.6523835029459025, "test_micro_f1_no_misc": 0.7267267267267267, "test_runtime": 15.685, "test_samples_per_second": 130.571, "test_steps_per_second": 4.08}, {"test_loss": 0.0640857145190239, "test_micro_f1": 0.6528066528066528, "test_micro_f1_no_misc": 0.7083087802003537, "test_runtime": 14.6931, "test_samples_per_second": 139.386, "test_steps_per_second": 4.356}, {"test_loss": 0.05321551114320755, "test_micro_f1": 0.6946640316205533, "test_micro_f1_no_misc": 0.7335824879871864, "test_runtime": 13.4409, "test_samples_per_second": 152.371, "test_steps_per_second": 4.762}, {"test_loss": 0.059355560690164566, "test_micro_f1": 0.6426512968299711, "test_micro_f1_no_misc": 0.6997214484679665, "test_runtime": 15.3301, "test_samples_per_second": 133.593, "test_steps_per_second": 4.175}, {"test_loss": 0.05867598578333855, "test_micro_f1": 0.7024673439767779, "test_micro_f1_no_misc": 0.7497360084477296, "test_runtime": 15.3457, "test_samples_per_second": 133.458, "test_steps_per_second": 4.171}, {"test_loss": 0.05652701109647751, "test_micro_f1": 0.692632566870014, "test_micro_f1_no_misc": 0.765446224256293, "test_runtime": 12.4438, "test_samples_per_second": 164.58, "test_steps_per_second": 5.143}, {"test_loss": 0.05535431206226349, "test_micro_f1": 0.667624521072797, "test_micro_f1_no_misc": 0.7333333333333333, "test_runtime": 12.6963, "test_samples_per_second": 161.307, "test_steps_per_second": 5.041}, {"test_loss": 0.0513240322470665, "test_micro_f1": 0.6829545454545454, "test_micro_f1_no_misc": 0.7621585609593604, "test_runtime": 14.7978, "test_samples_per_second": 138.399, "test_steps_per_second": 4.325}, {"test_loss": 0.051456354558467865, "test_micro_f1": 0.7283292978208231, "test_micro_f1_no_misc": 0.7794528196538247, "test_runtime": 14.2818, "test_samples_per_second": 143.399, "test_steps_per_second": 4.481}, {"test_loss": 0.06086302921175957, "test_micro_f1": 0.7035419699175157, "test_micro_f1_no_misc": 0.7672462142456534, "test_runtime": 15.4273, "test_samples_per_second": 132.752, "test_steps_per_second": 4.148}]}, "total": {"test_micro_f1": 68.20055729315553, "test_micro_f1_se": 1.7021904775945038, "test_micro_f1_no_misc": 74.25712604278428, "test_micro_f1_no_misc_se": 1.6469408808553667}}, "num_model_parameters": 560420361, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.07208795845508575, "test_micro_f1": 0.7599067599067599, "test_micro_f1_no_misc": 0.7771775827143822, "test_runtime": 16.8078, "test_samples_per_second": 121.848, "test_steps_per_second": 3.808}, {"test_loss": 0.06578854471445084, "test_micro_f1": 0.7865296803652968, "test_micro_f1_no_misc": 0.8088012139605464, "test_runtime": 13.9381, "test_samples_per_second": 146.936, "test_steps_per_second": 4.592}, {"test_loss": 0.059114113450050354, "test_micro_f1": 0.802950474183351, "test_micro_f1_no_misc": 0.8236529041287614, "test_runtime": 17.0149, "test_samples_per_second": 120.365, "test_steps_per_second": 3.761}, {"test_loss": 0.07231897115707397, "test_micro_f1": 0.8088047094957769, "test_micro_f1_no_misc": 0.8271304347826088, "test_runtime": 16.5469, "test_samples_per_second": 123.77, "test_steps_per_second": 3.868}, {"test_loss": 0.07338189333677292, "test_micro_f1": 0.7794698251551043, "test_micro_f1_no_misc": 0.8012398295234405, "test_runtime": 16.9111, "test_samples_per_second": 121.104, "test_steps_per_second": 3.784}, {"test_loss": 0.08169233053922653, "test_micro_f1": 0.743109151047409, "test_micro_f1_no_misc": 0.7582133628645256, "test_runtime": 16.7131, "test_samples_per_second": 122.539, "test_steps_per_second": 3.829}, {"test_loss": 0.06651400029659271, "test_micro_f1": 0.7656903765690376, "test_micro_f1_no_misc": 0.7845266372582287, "test_runtime": 17.4509, "test_samples_per_second": 117.358, "test_steps_per_second": 3.667}, {"test_loss": 0.06862208247184753, "test_micro_f1": 0.7512116316639741, "test_micro_f1_no_misc": 0.7874186550976138, "test_runtime": 16.5976, "test_samples_per_second": 123.391, "test_steps_per_second": 3.856}, {"test_loss": 0.061762988567352295, "test_micro_f1": 0.7943646708209159, "test_micro_f1_no_misc": 0.8106060606060606, "test_runtime": 16.6775, "test_samples_per_second": 122.8, "test_steps_per_second": 3.837}, {"test_loss": 0.08230651915073395, "test_micro_f1": 0.7662753468516542, "test_micro_f1_no_misc": 0.7885796891940731, "test_runtime": 14.0186, "test_samples_per_second": 146.092, "test_steps_per_second": 4.565}]}, "total": {"test_micro_f1": 77.58312626059279, "test_micro_f1_se": 1.3733197256124965, "test_micro_f1_no_misc": 79.67346370130241, "test_micro_f1_no_misc_se": 1.335024911682983}}, "num_model_parameters": 560420361, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.0473918616771698, "test_micro_f1": 0.789762340036563, "test_micro_f1_no_misc": 0.8441127694859039, "test_runtime": 13.2511, "test_samples_per_second": 154.554, "test_steps_per_second": 4.83}, {"test_loss": 0.03989529609680176, "test_micro_f1": 0.8236607142857144, "test_micro_f1_no_misc": 0.858691121300542, "test_runtime": 13.2173, "test_samples_per_second": 154.948, "test_steps_per_second": 4.842}, {"test_loss": 0.04678044840693474, "test_micro_f1": 0.8327402135231318, "test_micro_f1_no_misc": 0.8615023474178405, "test_runtime": 12.398, "test_samples_per_second": 165.189, "test_steps_per_second": 5.162}, {"test_loss": 0.036771297454833984, "test_micro_f1": 0.833158447009444, "test_micro_f1_no_misc": 0.8568065908199294, "test_runtime": 12.1777, "test_samples_per_second": 168.176, "test_steps_per_second": 5.255}, {"test_loss": 0.03893528878688812, "test_micro_f1": 0.857238381812103, "test_micro_f1_no_misc": 0.8754183711416883, "test_runtime": 13.3927, "test_samples_per_second": 152.92, "test_steps_per_second": 4.779}, {"test_loss": 0.03206934034824371, "test_micro_f1": 0.8550774526678141, "test_micro_f1_no_misc": 0.8767228177641655, "test_runtime": 13.5501, "test_samples_per_second": 151.143, "test_steps_per_second": 4.723}, {"test_loss": 0.04568791389465332, "test_micro_f1": 0.839378238341969, "test_micro_f1_no_misc": 0.8629872636047857, "test_runtime": 12.3685, "test_samples_per_second": 165.582, "test_steps_per_second": 5.174}, {"test_loss": 0.04327460005879402, "test_micro_f1": 0.8277739959155889, "test_micro_f1_no_misc": 0.8463532025175862, "test_runtime": 12.0824, "test_samples_per_second": 169.502, "test_steps_per_second": 5.297}, {"test_loss": 0.03591035306453705, "test_micro_f1": 0.8421433743664012, "test_micro_f1_no_misc": 0.8714579055441479, "test_runtime": 12.25, "test_samples_per_second": 167.183, "test_steps_per_second": 5.224}, {"test_loss": 0.043666962534189224, "test_micro_f1": 0.8468406593406593, "test_micro_f1_no_misc": 0.872260015117158, "test_runtime": 13.2457, "test_samples_per_second": 154.616, "test_steps_per_second": 4.832}]}, "total": {"test_micro_f1": 83.47773817299388, "test_micro_f1_se": 1.1945982472303835, "test_micro_f1_no_misc": 86.26312404713747, "test_micro_f1_no_misc_se": 0.7131417199279642}}, "num_model_parameters": 560420361, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.05131474882364273, "test_micro_f1": 0.7878041268863567, "test_micro_f1_no_misc": 0.8275160962385631, "test_runtime": 12.2311, "test_samples_per_second": 167.442, "test_steps_per_second": 5.233}, {"test_loss": 0.05482340604066849, "test_micro_f1": 0.7957703927492445, "test_micro_f1_no_misc": 0.8282146473169085, "test_runtime": 12.5878, "test_samples_per_second": 162.697, "test_steps_per_second": 5.084}, {"test_loss": 0.058014579117298126, "test_micro_f1": 0.7728937728937729, "test_micro_f1_no_misc": 0.8178110129163835, "test_runtime": 12.1862, "test_samples_per_second": 168.059, "test_steps_per_second": 5.252}, {"test_loss": 0.0681024044752121, "test_micro_f1": 0.7372525494901021, "test_micro_f1_no_misc": 0.7754152823920266, "test_runtime": 12.6618, "test_samples_per_second": 161.747, "test_steps_per_second": 5.055}, {"test_loss": 0.06262369453907013, "test_micro_f1": 0.7802499238037184, "test_micro_f1_no_misc": 0.8243526941917424, "test_runtime": 12.3685, "test_samples_per_second": 165.581, "test_steps_per_second": 5.174}, {"test_loss": 0.07579471915960312, "test_micro_f1": 0.6786450662739323, "test_micro_f1_no_misc": 0.7251350492532571, "test_runtime": 12.504, "test_samples_per_second": 163.788, "test_steps_per_second": 5.118}, {"test_loss": 0.05873773992061615, "test_micro_f1": 0.8323446768654388, "test_micro_f1_no_misc": 0.8606615059817031, "test_runtime": 12.9216, "test_samples_per_second": 158.494, "test_steps_per_second": 4.953}, {"test_loss": 0.05872299149632454, "test_micro_f1": 0.7659827534939042, "test_micro_f1_no_misc": 0.8039024390243903, "test_runtime": 12.7544, "test_samples_per_second": 160.572, "test_steps_per_second": 5.018}, {"test_loss": 0.06668909639120102, "test_micro_f1": 0.7433846153846154, "test_micro_f1_no_misc": 0.7840216655382531, "test_runtime": 11.8409, "test_samples_per_second": 172.96, "test_steps_per_second": 5.405}, {"test_loss": 0.06944210827350616, "test_micro_f1": 0.7227452171272395, "test_micro_f1_no_misc": 0.7628330084470435, "test_runtime": 12.3848, "test_samples_per_second": 165.364, "test_steps_per_second": 5.168}]}, "total": {"test_micro_f1": 76.17073094968325, "test_micro_f1_se": 2.6674374603729305, "test_micro_f1_no_misc": 80.0986340130027, "test_micro_f1_no_misc_se": 2.4440839418956086}}, "num_model_parameters": 560420361, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.691394567489624, "test_mcc": 0.08537069277718227, "test_macro_f1": 0.49423429380814177, "test_runtime": 7.7249, "test_samples_per_second": 265.118, "test_steps_per_second": 8.285}, {"test_loss": 0.5752620697021484, "test_mcc": 0.40604226079434763, "test_macro_f1": 0.7018925698402941, "test_runtime": 7.748, "test_samples_per_second": 264.326, "test_steps_per_second": 8.26}, {"test_loss": 0.6925915479660034, "test_mcc": 0.028301440041298906, "test_macro_f1": 0.4177243131112379, "test_runtime": 7.7571, "test_samples_per_second": 264.017, "test_steps_per_second": 8.251}, {"test_loss": 0.6910386085510254, "test_mcc": 0.08833956491934032, "test_macro_f1": 0.40462654067837706, "test_runtime": 7.7117, "test_samples_per_second": 265.572, "test_steps_per_second": 8.299}, {"test_loss": 0.5864889025688171, "test_mcc": 0.39824570624274713, "test_macro_f1": 0.690170389342055, "test_runtime": 7.7361, "test_samples_per_second": 264.733, "test_steps_per_second": 8.273}, {"test_loss": 0.6934187412261963, "test_mcc": 0.04993608230225411, "test_macro_f1": 0.44198147204106386, "test_runtime": 7.6169, "test_samples_per_second": 268.876, "test_steps_per_second": 8.402}, {"test_loss": 0.6919265985488892, "test_mcc": 0.027284298278295916, "test_macro_f1": 0.45741222392523156, "test_runtime": 7.5988, "test_samples_per_second": 269.518, "test_steps_per_second": 8.422}, {"test_loss": 0.6914858818054199, "test_mcc": 0.04667743165867642, "test_macro_f1": 0.44760665881484346, "test_runtime": 7.7013, "test_samples_per_second": 265.928, "test_steps_per_second": 8.31}, {"test_loss": 0.5925567150115967, "test_mcc": 0.42461783120866753, "test_macro_f1": 0.6932097840741296, "test_runtime": 7.6973, "test_samples_per_second": 266.068, "test_steps_per_second": 8.315}, {"test_loss": 0.6925638914108276, "test_mcc": 0.05187889574746057, "test_macro_f1": 0.49898500929118406, "test_runtime": 7.648, "test_samples_per_second": 267.782, "test_steps_per_second": 8.368}]}, "total": {"test_mcc": 16.06694203970271, "test_mcc_se": 10.727902221599523, "test_macro_f1": 52.478432549265584, "test_macro_f1_se": 7.504447544059641}}, "num_model_parameters": 561462786, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.6924974322319031, "test_mcc": 0.04961755298913886, "test_macro_f1": 0.49059711960333385, "test_runtime": 8.4845, "test_samples_per_second": 241.38, "test_steps_per_second": 7.543}, {"test_loss": 0.6937682628631592, "test_mcc": 0.04819307936477222, "test_macro_f1": 0.3819196122364992, "test_runtime": 8.6477, "test_samples_per_second": 236.825, "test_steps_per_second": 7.401}, {"test_loss": 0.6925758123397827, "test_mcc": 0.011577556904511958, "test_macro_f1": 0.4996488763203102, "test_runtime": 8.4535, "test_samples_per_second": 242.266, "test_steps_per_second": 7.571}, {"test_loss": 0.6359422206878662, "test_mcc": 0.3456049604008285, "test_macro_f1": 0.6694935758494815, "test_runtime": 8.7189, "test_samples_per_second": 234.891, "test_steps_per_second": 7.34}, {"test_loss": 0.6923727989196777, "test_mcc": 0.030555400832270867, "test_macro_f1": 0.5055740513599284, "test_runtime": 8.2682, "test_samples_per_second": 247.696, "test_steps_per_second": 7.74}, {"test_loss": 0.691068172454834, "test_mcc": 0.06128408290794551, "test_macro_f1": 0.44692221906365487, "test_runtime": 8.2896, "test_samples_per_second": 247.057, "test_steps_per_second": 7.721}, {"test_loss": 0.6925622820854187, "test_mcc": 0.0599377107349603, "test_macro_f1": 0.5287743782943843, "test_runtime": 8.1489, "test_samples_per_second": 251.322, "test_steps_per_second": 7.854}, {"test_loss": 0.6926122307777405, "test_mcc": 0.04552035813545033, "test_macro_f1": 0.4387497291624487, "test_runtime": 8.3255, "test_samples_per_second": 245.991, "test_steps_per_second": 7.687}, {"test_loss": 0.6924490928649902, "test_mcc": 0.05234501017519652, "test_macro_f1": 0.5091465880514462, "test_runtime": 8.3384, "test_samples_per_second": 245.61, "test_steps_per_second": 7.675}, {"test_loss": 0.6927967071533203, "test_mcc": 0.0015865792403164309, "test_macro_f1": 0.4997356533377949, "test_runtime": 8.4336, "test_samples_per_second": 242.837, "test_steps_per_second": 7.589}]}, "total": {"test_mcc": 7.062222916853915, "test_mcc_se": 6.114265691562876, "test_macro_f1": 49.70561803279282, "test_macro_f1_se": 4.628281685999302}}, "num_model_parameters": 561462786, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.6912702918052673, "test_mcc": 0.06928503914120292, "test_macro_f1": 0.5298730414588251, "test_runtime": 7.8177, "test_samples_per_second": 261.971, "test_steps_per_second": 8.187}, {"test_loss": 0.6923010349273682, "test_mcc": 0.030283307428361526, "test_macro_f1": 0.5086371178403536, "test_runtime": 7.7114, "test_samples_per_second": 265.582, "test_steps_per_second": 8.299}, {"test_loss": 0.6925591230392456, "test_mcc": -0.016159564694433887, "test_macro_f1": 0.39457010020073224, "test_runtime": 7.7664, "test_samples_per_second": 263.7, "test_steps_per_second": 8.241}, {"test_loss": 0.6926928758621216, "test_mcc": 0.011337627688490516, "test_macro_f1": 0.4568436528748083, "test_runtime": 7.8416, "test_samples_per_second": 261.17, "test_steps_per_second": 8.162}, {"test_loss": 0.6823005676269531, "test_mcc": 0.19554172399449737, "test_macro_f1": 0.4107639902676399, "test_runtime": 8.1256, "test_samples_per_second": 252.042, "test_steps_per_second": 7.876}, {"test_loss": 0.6903475522994995, "test_mcc": 0.10200107318632827, "test_macro_f1": 0.547869095199921, "test_runtime": 7.4712, "test_samples_per_second": 274.118, "test_steps_per_second": 8.566}, {"test_loss": 0.6913005113601685, "test_mcc": 0.022715341972280156, "test_macro_f1": 0.3404673523636414, "test_runtime": 7.5898, "test_samples_per_second": 269.835, "test_steps_per_second": 8.432}, {"test_loss": 0.606737494468689, "test_mcc": 0.3757855981798828, "test_macro_f1": 0.6606690251220276, "test_runtime": 7.7646, "test_samples_per_second": 263.763, "test_steps_per_second": 8.243}, {"test_loss": 0.6048603057861328, "test_mcc": 0.45397934117561, "test_macro_f1": 0.7097744773830119, "test_runtime": 7.6093, "test_samples_per_second": 269.145, "test_steps_per_second": 8.411}, {"test_loss": 0.6937938928604126, "test_mcc": -0.033472757488875175, "test_macro_f1": 0.4734677087618265, "test_runtime": 8.1255, "test_samples_per_second": 252.048, "test_steps_per_second": 7.876}]}, "total": {"test_mcc": 12.112967305833447, "test_mcc_se": 10.47316863585317, "test_macro_f1": 50.32935561472788, "test_macro_f1_se": 7.158860109794612}}, "num_model_parameters": 561462786, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.6933461427688599, "test_mcc": -0.022552439424315295, "test_macro_f1": 0.42557082221886694, "test_runtime": 8.2176, "test_samples_per_second": 249.222, "test_steps_per_second": 7.788}, {"test_loss": 0.6925855278968811, "test_mcc": 0.08992163454173183, "test_macro_f1": 0.511143340584965, "test_runtime": 8.274, "test_samples_per_second": 247.521, "test_steps_per_second": 7.735}, {"test_loss": 0.6856309175491333, "test_mcc": 0.20226478935643333, "test_macro_f1": 0.4609574405452487, "test_runtime": 8.2893, "test_samples_per_second": 247.065, "test_steps_per_second": 7.721}, {"test_loss": 0.6944746971130371, "test_mcc": -0.038938803794165394, "test_macro_f1": 0.3270775884301783, "test_runtime": 7.9329, "test_samples_per_second": 258.165, "test_steps_per_second": 8.068}, {"test_loss": 0.6920583248138428, "test_mcc": 0.03281359183896173, "test_macro_f1": 0.3527618097396832, "test_runtime": 8.0376, "test_samples_per_second": 254.804, "test_steps_per_second": 7.963}, {"test_loss": 0.6911028027534485, "test_mcc": 0.041456109563671635, "test_macro_f1": 0.4956667795448415, "test_runtime": 8.3567, "test_samples_per_second": 245.074, "test_steps_per_second": 7.659}, {"test_loss": 0.6924246549606323, "test_mcc": 0.051049811473781424, "test_macro_f1": 0.5251723768243219, "test_runtime": 8.0621, "test_samples_per_second": 254.028, "test_steps_per_second": 7.938}, {"test_loss": 0.6943322420120239, "test_mcc": 0.01898544173929992, "test_macro_f1": 0.45566857689735785, "test_runtime": 8.0207, "test_samples_per_second": 255.339, "test_steps_per_second": 7.979}, {"test_loss": 0.6935443878173828, "test_mcc": 0.0028152243499636243, "test_macro_f1": 0.5008547008547009, "test_runtime": 8.1045, "test_samples_per_second": 252.698, "test_steps_per_second": 7.897}, {"test_loss": 0.6917691230773926, "test_mcc": 0.04972552903165431, "test_macro_f1": 0.5198832190175123, "test_runtime": 8.2564, "test_samples_per_second": 248.051, "test_steps_per_second": 7.752}]}, "total": {"test_mcc": 4.275408886770171, "test_mcc_se": 4.1826138743709, "test_macro_f1": 45.74756654657677, "test_macro_f1_se": 4.318925026594101}}, "num_model_parameters": 561462786, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_em": 42.3702556158017, "test_f1": 46.451952975588696}, {"test_em": 37.36434108527132, "test_f1": 41.29561033708202}, {"test_em": 42.65842349304482, "test_f1": 46.929815585511555}, {"test_em": 45.40498442367601, "test_f1": 49.567505777529206}, {"test_em": 44.32432432432432, "test_f1": 48.77452804343561}, {"test_em": 45.95219737856592, "test_f1": 49.67352570085712}, {"test_em": 49.81017463933181, "test_f1": 53.281306530148}, {"test_em": 40.57408844065167, "test_f1": 45.12789889059564}, {"test_em": 41.01960784313726, "test_f1": 45.523972292069914}, {"test_em": 43.63354037267081, "test_f1": 47.230784025987994}]}, "total": {"test_em": 43.311193761647566, "test_em_se": 2.1084109777186284, "test_f1": 47.38569001588057, "test_f1_se": 1.9970856224415956}}, "num_model_parameters": 560413186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_em": 44.2292796281952, "test_f1": 48.68816903506933}, {"test_em": 41.78294573643411, "test_f1": 46.035251809372404}, {"test_em": 34.46676970633694, "test_f1": 40.31781564266217}, {"test_em": 47.97507788161994, "test_f1": 51.71083283525774}, {"test_em": 39.15057915057915, "test_f1": 44.78489172031852}, {"test_em": 41.32613723978412, "test_f1": 46.88931374766871}, {"test_em": 44.2672741078208, "test_f1": 49.011109812679265}, {"test_em": 46.93560899922421, "test_f1": 51.03947241990389}, {"test_em": 46.98039215686274, "test_f1": 51.10311968692589}, {"test_em": 47.98136645962733, "test_f1": 52.31951398026794}]}, "total": {"test_em": 43.50954310664846, "test_em_se": 2.720063081175508, "test_f1": 48.189949069012584, "test_f1_se": 2.327169995860808}}, "num_model_parameters": 560413186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_em": 47.56003098373354, "test_f1": 52.45075158035328}, {"test_em": 47.751937984496124, "test_f1": 52.19422959634637}, {"test_em": 47.2952086553323, "test_f1": 52.39317084617249}, {"test_em": 49.454828660436135, "test_f1": 54.11327187256922}, {"test_em": 24.787644787644787, "test_f1": 30.26030156421863}, {"test_em": 48.11102544333076, "test_f1": 52.35062468628376}, {"test_em": 40.62262718299165, "test_f1": 45.97660810608531}, {"test_em": 44.60822342901474, "test_f1": 49.54404084881187}, {"test_em": 44.627450980392155, "test_f1": 49.55676860624955}, {"test_em": 42.62422360248447, "test_f1": 47.826164037115824}]}, "total": {"test_em": 43.74432017098567, "test_em_se": 4.4637005871527, "test_f1": 48.666593174420626, "test_f1_se": 4.295069632998205}}, "num_model_parameters": 560413186, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Twitter/twhin-bert-large", "results": {"raw": {"test": [{"test_loss": 0.48852699995040894, "test_mcc": 0.698198512083692, "test_macro_f1": 0.6364551727342426, "test_runtime": 59.9734, "test_samples_per_second": 34.148, "test_steps_per_second": 17.074}, {"test_loss": 0.5397130846977234, "test_mcc": 0.6705089475525954, "test_macro_f1": 0.5720616609284112, "test_runtime": 57.5379, "test_samples_per_second": 35.594, "test_steps_per_second": 17.797}, {"test_loss": 0.7513415813446045, "test_mcc": 0.5262180431744657, "test_macro_f1": 0.5069017672121653, "test_runtime": 59.2834, "test_samples_per_second": 34.546, "test_steps_per_second": 17.273}, {"test_loss": 0.5011988878250122, "test_mcc": 0.7115414240843424, "test_macro_f1": 0.7274489030947487, "test_runtime": 59.3984, "test_samples_per_second": 34.479, "test_steps_per_second": 17.24}, {"test_loss": 0.5312958359718323, "test_mcc": 0.6925579509890537, "test_macro_f1": 0.7277106025979512, "test_runtime": 59.1911, "test_samples_per_second": 34.6, "test_steps_per_second": 17.3}, {"test_loss": 0.5561317205429077, "test_mcc": 0.6705313276543722, "test_macro_f1": 0.5691484775314077, "test_runtime": 60.0476, "test_samples_per_second": 34.106, "test_steps_per_second": 17.053}, {"test_loss": 0.8053224086761475, "test_mcc": 0.43758692526159626, "test_macro_f1": 0.4803892753339212, "test_runtime": 59.0382, "test_samples_per_second": 34.689, "test_steps_per_second": 17.345}, {"test_loss": 0.5376129150390625, "test_mcc": 0.6596973173542109, "test_macro_f1": 0.5827938613586324, "test_runtime": 60.1034, "test_samples_per_second": 34.075, "test_steps_per_second": 17.037}, {"test_loss": 0.6141455769538879, "test_mcc": 0.6028753564206009, "test_macro_f1": 0.5387620493300149, "test_runtime": 59.0677, "test_samples_per_second": 34.672, "test_steps_per_second": 17.336}, {"test_loss": 0.528464674949646, "test_mcc": 0.6648837067563528, "test_macro_f1": 0.6911617630872512, "test_runtime": 59.4815, "test_samples_per_second": 34.431, "test_steps_per_second": 17.215}]}, "total": {"test_mcc": 63.345995113312824, "test_mcc_se": 5.427215449653556, "test_macro_f1": 60.32833533208747, "test_macro_f1_se": 5.498776222954465}}, "num_model_parameters": 561463811, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "xlm-mlm-100-1280", "results": {"raw": {"test": [{"test_loss": 0.6801019310951233, "test_mcc": 0.5184444412055575, "test_macro_f1": 0.5131360247614284, "test_runtime": 28.7408, "test_samples_per_second": 71.258, "test_steps_per_second": 8.907, "epoch": 3.75}, {"test_loss": 0.6298381090164185, "test_mcc": 0.582601813595477, "test_macro_f1": 0.6300486188552529, "test_runtime": 27.5165, "test_samples_per_second": 74.428, "test_steps_per_second": 9.303, "epoch": 4.69}, {"test_loss": 0.589760422706604, "test_mcc": 0.6120945107577223, "test_macro_f1": 0.6489008406519414, "test_runtime": 28.2621, "test_samples_per_second": 72.464, "test_steps_per_second": 9.058, "epoch": 4.69}, {"test_loss": 0.5318101644515991, "test_mcc": 0.6617834459395237, "test_macro_f1": 0.676054899698963, "test_runtime": 28.0966, "test_samples_per_second": 72.891, "test_steps_per_second": 9.111, "epoch": 5.62}, {"test_loss": 0.5126230716705322, "test_mcc": 0.6604533317479389, "test_macro_f1": 0.6359540899470794, "test_runtime": 27.3063, "test_samples_per_second": 75.001, "test_steps_per_second": 9.375, "epoch": 5.62}, {"test_loss": 0.5506304502487183, "test_mcc": 0.6647086224192178, "test_macro_f1": 0.698168505006694, "test_runtime": 27.5141, "test_samples_per_second": 74.435, "test_steps_per_second": 9.304, "epoch": 6.56}, {"test_loss": 0.5067229270935059, "test_mcc": 0.6783062768116843, "test_macro_f1": 0.686564956322322, "test_runtime": 27.2609, "test_samples_per_second": 75.126, "test_steps_per_second": 9.391, "epoch": 5.62}, {"test_loss": 0.6010133624076843, "test_mcc": 0.6611816597957824, "test_macro_f1": 0.6317105619966742, "test_runtime": 28.9643, "test_samples_per_second": 70.708, "test_steps_per_second": 8.838, "epoch": 5.62}, {"test_loss": 0.7584002614021301, "test_mcc": 0.4991386760173952, "test_macro_f1": 0.4968495084412193, "test_runtime": 28.2093, "test_samples_per_second": 72.6, "test_steps_per_second": 9.075, "epoch": 3.75}, {"test_loss": 0.6087802648544312, "test_mcc": 0.6504188664868907, "test_macro_f1": 0.5718969098362371, "test_runtime": 27.8405, "test_samples_per_second": 73.562, "test_steps_per_second": 9.195, "epoch": 4.69}]}, "total": {"test_mcc": 61.891316447771906, "test_mcc_se": 4.0153352123028, "test_macro_f1": 61.89284915517812, "test_macro_f1_se": 4.3287779568241795}}, "num_model_parameters": 571500803, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "xlm-mlm-100-1280", "results": {"raw": {"test": [{"test_loss": 1.050073266029358, "test_mcc": 0.3431339653006307, "test_macro_f1": 0.5579671048392466, "test_runtime": 8.9058, "test_samples_per_second": 229.962, "test_steps_per_second": 7.186, "epoch": 6.56}, {"test_loss": 0.9327137470245361, "test_mcc": 0.3814935620677558, "test_macro_f1": 0.5837723950288746, "test_runtime": 8.8641, "test_samples_per_second": 231.044, "test_steps_per_second": 7.22, "epoch": 5.62}, {"test_loss": 1.0516412258148193, "test_mcc": 0.20668838568549372, "test_macro_f1": 0.39672737224461363, "test_runtime": 8.8256, "test_samples_per_second": 232.053, "test_steps_per_second": 7.252, "epoch": 3.75}, {"test_loss": 1.0591294765472412, "test_mcc": 0.1620135400876928, "test_macro_f1": 0.41850749359941847, "test_runtime": 8.7769, "test_samples_per_second": 233.341, "test_steps_per_second": 7.292, "epoch": 2.81}, {"test_loss": 1.13185453414917, "test_mcc": 0.3452861095046005, "test_macro_f1": 0.5526556177642511, "test_runtime": 8.8422, "test_samples_per_second": 231.615, "test_steps_per_second": 7.238, "epoch": 6.56}, {"test_loss": 0.9654273986816406, "test_mcc": 0.3356309045286281, "test_macro_f1": 0.5565491820848231, "test_runtime": 8.8829, "test_samples_per_second": 230.554, "test_steps_per_second": 7.205, "epoch": 4.69}, {"test_loss": 0.9995204210281372, "test_mcc": 0.3014919731540343, "test_macro_f1": 0.506024791786195, "test_runtime": 8.9883, "test_samples_per_second": 227.852, "test_steps_per_second": 7.12, "epoch": 5.62}, {"test_loss": 1.123101830482483, "test_mcc": 0.3215891074352585, "test_macro_f1": 0.5476724588863923, "test_runtime": 8.9882, "test_samples_per_second": 227.853, "test_steps_per_second": 7.12, "epoch": 5.62}, {"test_loss": 0.9199497699737549, "test_mcc": 0.35249505843914036, "test_macro_f1": 0.5678068185137292, "test_runtime": 8.7586, "test_samples_per_second": 233.828, "test_steps_per_second": 7.307, "epoch": 5.62}, {"test_loss": 1.0443737506866455, "test_mcc": 0.319647387124705, "test_macro_f1": 0.5193491569895007, "test_runtime": 8.7561, "test_samples_per_second": 233.895, "test_steps_per_second": 7.309, "epoch": 5.62}]}, "total": {"test_mcc": 30.694699933279395, "test_mcc_se": 4.269067761988433, "test_macro_f1": 52.070323917370445, "test_macro_f1_se": 3.955206970091127}}, "num_model_parameters": 571500803, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "xlm-mlm-100-1280", "results": {"raw": {"test": [{"test_loss": 0.8638354539871216, "test_mcc": 0.3591280013475862, "test_macro_f1": 0.5183314697560387, "test_runtime": 7.2752, "test_samples_per_second": 281.504, "test_steps_per_second": 8.797, "epoch": 4.69}, {"test_loss": 1.0379729270935059, "test_mcc": 0.12025781129590564, "test_macro_f1": 0.3448142580614309, "test_runtime": 6.8755, "test_samples_per_second": 297.871, "test_steps_per_second": 9.308, "epoch": 2.81}, {"test_loss": 0.9085095524787903, "test_mcc": 0.4053474907746902, "test_macro_f1": 0.5475639801677061, "test_runtime": 6.912, "test_samples_per_second": 296.298, "test_steps_per_second": 9.259, "epoch": 6.56}, {"test_loss": 0.9010845422744751, "test_mcc": 0.34354727231205606, "test_macro_f1": 0.49239326219599217, "test_runtime": 7.0288, "test_samples_per_second": 291.371, "test_steps_per_second": 9.105, "epoch": 4.69}, {"test_loss": 0.8683301210403442, "test_mcc": 0.37524723502304336, "test_macro_f1": 0.5218095731974386, "test_runtime": 7.019, "test_samples_per_second": 291.78, "test_steps_per_second": 9.118, "epoch": 5.62}, {"test_loss": 0.9432781338691711, "test_mcc": 0.3097822588612371, "test_macro_f1": 0.4785958031674738, "test_runtime": 7.2719, "test_samples_per_second": 281.632, "test_steps_per_second": 8.801, "epoch": 5.62}, {"test_loss": 0.8998039960861206, "test_mcc": 0.32380798393221505, "test_macro_f1": 0.4535073989755265, "test_runtime": 6.8914, "test_samples_per_second": 297.183, "test_steps_per_second": 9.287, "epoch": 4.69}, {"test_loss": 0.9838737845420837, "test_mcc": 0.37361048638295935, "test_macro_f1": 0.4778642644500586, "test_runtime": 6.9209, "test_samples_per_second": 295.916, "test_steps_per_second": 9.247, "epoch": 5.62}, {"test_loss": 0.9368811845779419, "test_mcc": 0.38375962371372296, "test_macro_f1": 0.48113709053400494, "test_runtime": 7.1449, "test_samples_per_second": 286.639, "test_steps_per_second": 8.957, "epoch": 6.56}, {"test_loss": 0.9868282079696655, "test_mcc": 0.311535880505366, "test_macro_f1": 0.49880177204006565, "test_runtime": 7.248, "test_samples_per_second": 282.559, "test_steps_per_second": 8.83, "epoch": 6.56}]}, "total": {"test_mcc": 33.06024044148782, "test_mcc_se": 4.989545462612503, "test_macro_f1": 48.14818872545736, "test_macro_f1_se": 3.4106404184774495}}, "num_model_parameters": 571500803, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "xlm-mlm-100-1280", "results": {"raw": {"test": [{"test_loss": 0.5390541553497314, "test_mcc": 0.50823011507184, "test_macro_f1": 0.7430882586189493, "test_runtime": 7.0816, "test_samples_per_second": 289.201, "test_steps_per_second": 9.038, "epoch": 6.56}, {"test_loss": 0.5896764993667603, "test_mcc": 0.44035846041562093, "test_macro_f1": 0.7180491857640696, "test_runtime": 7.4018, "test_samples_per_second": 276.691, "test_steps_per_second": 8.647, "epoch": 6.56}, {"test_loss": 0.6658010482788086, "test_mcc": 0.24753520845853208, "test_macro_f1": 0.5321550056693123, "test_runtime": 7.3717, "test_samples_per_second": 277.821, "test_steps_per_second": 8.682, "epoch": 7.5}, {"test_loss": 0.6903964281082153, "test_mcc": 0.03427633416811371, "test_macro_f1": 0.5170482765264096, "test_runtime": 7.1665, "test_samples_per_second": 285.774, "test_steps_per_second": 8.93, "epoch": 3.75}, {"test_loss": 0.5514854192733765, "test_mcc": 0.46376956476462894, "test_macro_f1": 0.7318552786627679, "test_runtime": 7.3072, "test_samples_per_second": 280.27, "test_steps_per_second": 8.758, "epoch": 6.56}, {"test_loss": 0.6421058177947998, "test_mcc": 0.523234626051295, "test_macro_f1": 0.7597585085249501, "test_runtime": 6.9779, "test_samples_per_second": 293.497, "test_steps_per_second": 9.172, "epoch": 8.44}, {"test_loss": 0.5601577162742615, "test_mcc": 0.5419750282650106, "test_macro_f1": 0.7585218489236242, "test_runtime": 7.3132, "test_samples_per_second": 280.041, "test_steps_per_second": 8.751, "epoch": 7.5}, {"test_loss": 0.5344321727752686, "test_mcc": 0.507683816865817, "test_macro_f1": 0.7418038488291212, "test_runtime": 7.1033, "test_samples_per_second": 288.317, "test_steps_per_second": 9.01, "epoch": 7.5}, {"test_loss": 0.6922793388366699, "test_mcc": 0.0654896617193195, "test_macro_f1": 0.5133152435999033, "test_runtime": 7.2531, "test_samples_per_second": 282.36, "test_steps_per_second": 8.824, "epoch": 3.75}, {"test_loss": 0.6231533288955688, "test_mcc": 0.3320949239907641, "test_macro_f1": 0.6084818248812119, "test_runtime": 7.3417, "test_samples_per_second": 278.953, "test_steps_per_second": 8.717, "epoch": 7.5}]}, "total": {"test_mcc": 36.64647739770942, "test_mcc_se": 11.807272940737633, "test_macro_f1": 66.24077280000319, "test_macro_f1_se": 6.620263726856049}}, "num_model_parameters": 571499522, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "xlm-mlm-100-1280", "results": {"raw": {"test": [{"test_loss": 0.6357005834579468, "test_mcc": 0.5224418648049042, "test_macro_f1": 0.7611684590463403, "test_runtime": 7.5198, "test_samples_per_second": 272.348, "test_steps_per_second": 8.511, "epoch": 8.44}, {"test_loss": 0.6908072829246521, "test_mcc": 0.07074234105722627, "test_macro_f1": 0.42801620883426233, "test_runtime": 7.6187, "test_samples_per_second": 268.811, "test_steps_per_second": 8.4, "epoch": 5.62}, {"test_loss": 0.5525080561637878, "test_mcc": 0.504182193532367, "test_macro_f1": 0.7425970040189989, "test_runtime": 7.4564, "test_samples_per_second": 274.664, "test_steps_per_second": 8.583, "epoch": 7.5}, {"test_loss": 0.7222363948822021, "test_mcc": 0.007967037735141373, "test_macro_f1": 0.5010770650547294, "test_runtime": 7.8286, "test_samples_per_second": 261.604, "test_steps_per_second": 8.175, "epoch": 2.81}, {"test_loss": 0.6875512599945068, "test_mcc": 0.10951738463630291, "test_macro_f1": 0.5422558176175523, "test_runtime": 7.3401, "test_samples_per_second": 279.014, "test_steps_per_second": 8.719, "epoch": 3.75}, {"test_loss": 0.6801080703735352, "test_mcc": 0.13270501173287577, "test_macro_f1": 0.5277003947556811, "test_runtime": 7.5414, "test_samples_per_second": 271.568, "test_steps_per_second": 8.486, "epoch": 4.69}, {"test_loss": 0.555920422077179, "test_mcc": 0.47400687914207545, "test_macro_f1": 0.710681964221772, "test_runtime": 7.3647, "test_samples_per_second": 278.085, "test_steps_per_second": 8.69, "epoch": 7.5}, {"test_loss": 0.7011849284172058, "test_mcc": 0.03991132293799955, "test_macro_f1": 0.3700057446059386, "test_runtime": 7.2845, "test_samples_per_second": 281.146, "test_steps_per_second": 8.786, "epoch": 4.69}, {"test_loss": 0.6414223909378052, "test_mcc": 0.2884657620374125, "test_macro_f1": 0.6169983163877666, "test_runtime": 7.4796, "test_samples_per_second": 273.811, "test_steps_per_second": 8.557, "epoch": 6.56}, {"test_loss": 0.6167140007019043, "test_mcc": 0.35858079960912453, "test_macro_f1": 0.6080321285140562, "test_runtime": 7.4692, "test_samples_per_second": 274.193, "test_steps_per_second": 8.569, "epoch": 7.5}]}, "total": {"test_mcc": 25.0852059722543, "test_mcc_se": 12.577614876876215, "test_macro_f1": 58.08533103057096, "test_macro_f1_se": 8.161969889117959}}, "num_model_parameters": 571499522, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "xlm-mlm-100-1280", "results": {"raw": {"test": [{"test_loss": 0.7045105695724487, "test_mcc": 0.08726969226216759, "test_macro_f1": 0.44988533018294097, "test_runtime": 6.7986, "test_samples_per_second": 301.238, "test_steps_per_second": 9.414, "epoch": 4.69}, {"test_loss": 0.6541087627410889, "test_mcc": 0.2855390895866399, "test_macro_f1": 0.5958046244235167, "test_runtime": 6.7282, "test_samples_per_second": 304.393, "test_steps_per_second": 9.512, "epoch": 5.62}, {"test_loss": 0.5610870718955994, "test_mcc": 0.47346235523141295, "test_macro_f1": 0.7118349469846645, "test_runtime": 6.8971, "test_samples_per_second": 296.936, "test_steps_per_second": 9.279, "epoch": 7.5}, {"test_loss": 0.7037111520767212, "test_mcc": 0.12150886030965702, "test_macro_f1": 0.528806015037594, "test_runtime": 6.8799, "test_samples_per_second": 297.68, "test_steps_per_second": 9.303, "epoch": 3.75}, {"test_loss": 0.7356867790222168, "test_mcc": 0.036523180452006414, "test_macro_f1": 0.5126473192307655, "test_runtime": 7.0081, "test_samples_per_second": 292.232, "test_steps_per_second": 9.132, "epoch": 2.81}, {"test_loss": 0.5947489142417908, "test_mcc": 0.5676650528092028, "test_macro_f1": 0.7798033382388376, "test_runtime": 6.6818, "test_samples_per_second": 306.504, "test_steps_per_second": 9.578, "epoch": 8.44}, {"test_loss": 0.5101692080497742, "test_mcc": 0.5278257640076602, "test_macro_f1": 0.7638601328487279, "test_runtime": 6.6421, "test_samples_per_second": 308.337, "test_steps_per_second": 9.636, "epoch": 6.56}, {"test_loss": 0.6805088520050049, "test_mcc": 0.1464956798853482, "test_macro_f1": 0.5687870986060325, "test_runtime": 6.7014, "test_samples_per_second": 305.606, "test_steps_per_second": 9.55, "epoch": 3.75}, {"test_loss": 0.6596508026123047, "test_mcc": 0.21866337597883864, "test_macro_f1": 0.5781290582598182, "test_runtime": 6.6893, "test_samples_per_second": 306.16, "test_steps_per_second": 9.567, "epoch": 6.56}, {"test_loss": 0.6496358513832092, "test_mcc": 0.23406706258561819, "test_macro_f1": 0.5659845439864697, "test_runtime": 6.9117, "test_samples_per_second": 296.308, "test_steps_per_second": 9.26, "epoch": 5.62}]}, "total": {"test_mcc": 26.990201131085517, "test_mcc_se": 11.793494738073864, "test_macro_f1": 60.55542407799368, "test_macro_f1_se": 6.828463825144906}}, "num_model_parameters": 571499522, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "xlm-mlm-100-1280", "results": {"raw": {"test": [{"test_loss": 0.6951742172241211, "test_mcc": 0.10064693607435778, "test_macro_f1": 0.5133127178940633, "test_runtime": 6.9247, "test_samples_per_second": 295.754, "test_steps_per_second": 9.242, "epoch": 3.75}, {"test_loss": 0.7061886787414551, "test_mcc": 0.07571849807487271, "test_macro_f1": 0.5096146667768602, "test_runtime": 7.0393, "test_samples_per_second": 290.94, "test_steps_per_second": 9.092, "epoch": 3.75}, {"test_loss": 0.7138886451721191, "test_mcc": 0.09558687405135562, "test_macro_f1": 0.46737237969217915, "test_runtime": 6.9724, "test_samples_per_second": 293.732, "test_steps_per_second": 9.179, "epoch": 3.75}, {"test_loss": 0.7567762136459351, "test_mcc": 0.013892600078439257, "test_macro_f1": 0.4814011284511671, "test_runtime": 6.705, "test_samples_per_second": 305.444, "test_steps_per_second": 9.545, "epoch": 2.81}, {"test_loss": 0.6878932118415833, "test_mcc": 0.08515646178777843, "test_macro_f1": 0.5402657040107269, "test_runtime": 6.8147, "test_samples_per_second": 300.529, "test_steps_per_second": 9.392, "epoch": 4.69}, {"test_loss": 0.7348794341087341, "test_mcc": 0.05808663608079695, "test_macro_f1": 0.3682628790700473, "test_runtime": 6.9161, "test_samples_per_second": 296.121, "test_steps_per_second": 9.254, "epoch": 3.75}, {"test_loss": 0.7170315980911255, "test_mcc": 0.048211348241051125, "test_macro_f1": 0.5104207102706995, "test_runtime": 6.7955, "test_samples_per_second": 301.375, "test_steps_per_second": 9.418, "epoch": 3.75}, {"test_loss": 0.6934849619865417, "test_mcc": 0.0859828332226168, "test_macro_f1": 0.5201395991499966, "test_runtime": 6.9207, "test_samples_per_second": 295.922, "test_steps_per_second": 9.248, "epoch": 3.75}, {"test_loss": 0.6934633851051331, "test_mcc": 0.0369136957423152, "test_macro_f1": 0.5154369564275023, "test_runtime": 6.924, "test_samples_per_second": 295.782, "test_steps_per_second": 9.243, "epoch": 4.69}, {"test_loss": 0.6867690086364746, "test_mcc": 0.1256554042481559, "test_macro_f1": 0.5578019939717134, "test_runtime": 7.0846, "test_samples_per_second": 289.079, "test_steps_per_second": 9.034, "epoch": 3.75}]}, "total": {"test_mcc": 7.258512876017396, "test_mcc_se": 2.0662182749280316, "test_macro_f1": 49.84028735714956, "test_macro_f1_se": 3.24859792626229}}, "num_model_parameters": 571499522, "max_sequence_length": 512, "vocabulary_size": 200000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.353981077671051, "test_mcc": 0.7705544369164173, "test_macro_f1": 0.7061250800009496, "test_runtime": 67.691, "test_samples_per_second": 30.255, "test_steps_per_second": 15.128, "epoch": 4.69}, {"test_loss": 0.3855235278606415, "test_mcc": 0.7643119725932391, "test_macro_f1": 0.7024926096764609, "test_runtime": 68.6422, "test_samples_per_second": 29.836, "test_steps_per_second": 14.918, "epoch": 4.69}, {"test_loss": 0.3867434859275818, "test_mcc": 0.7732159128590473, "test_macro_f1": 0.7710340250711133, "test_runtime": 68.1187, "test_samples_per_second": 30.065, "test_steps_per_second": 15.033, "epoch": 4.69}, {"test_loss": 0.38560453057289124, "test_mcc": 0.7694585467537876, "test_macro_f1": 0.7266006237222662, "test_runtime": 69.087, "test_samples_per_second": 29.644, "test_steps_per_second": 14.822, "epoch": 4.69}, {"test_loss": 0.3556117117404938, "test_mcc": 0.7731053076506766, "test_macro_f1": 0.7676336765244717, "test_runtime": 64.9257, "test_samples_per_second": 31.544, "test_steps_per_second": 15.772, "epoch": 4.69}, {"test_loss": 0.45491474866867065, "test_mcc": 0.7308370319431727, "test_macro_f1": 0.6148399502325783, "test_runtime": 68.524, "test_samples_per_second": 29.887, "test_steps_per_second": 14.944, "epoch": 4.69}, {"test_loss": 0.3680599331855774, "test_mcc": 0.7765399613323308, "test_macro_f1": 0.7936088094542556, "test_runtime": 67.4322, "test_samples_per_second": 30.371, "test_steps_per_second": 15.186, "epoch": 4.69}, {"test_loss": 0.36492836475372314, "test_mcc": 0.7657934453977222, "test_macro_f1": 0.6702896357075628, "test_runtime": 67.4757, "test_samples_per_second": 30.352, "test_steps_per_second": 15.176, "epoch": 4.69}, {"test_loss": 0.3831196427345276, "test_mcc": 0.752149040341546, "test_macro_f1": 0.7548663940143392, "test_runtime": 65.2815, "test_samples_per_second": 31.372, "test_steps_per_second": 15.686, "epoch": 4.69}, {"test_loss": 0.43406617641448975, "test_mcc": 0.7234769992541681, "test_macro_f1": 0.5932321859082422, "test_runtime": 65.6467, "test_samples_per_second": 31.197, "test_steps_per_second": 15.599, "epoch": 3.75}]}, "total": {"test_mcc": 75.99442655042108, "test_mcc_se": 1.1538340043035595, "test_macro_f1": 71.00722990312241, "test_macro_f1_se": 4.166207547690239}}, "num_model_parameters": 575923843, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.7385133504867554, "test_mcc": 0.5229640681654327, "test_macro_f1": 0.683421931698807, "test_runtime": 13.6792, "test_samples_per_second": 149.717, "test_steps_per_second": 4.679, "epoch": 4.69}, {"test_loss": 0.7658197283744812, "test_mcc": 0.542448982389824, "test_macro_f1": 0.6969907798111784, "test_runtime": 13.4529, "test_samples_per_second": 152.235, "test_steps_per_second": 4.757, "epoch": 5.62}, {"test_loss": 0.8382792472839355, "test_mcc": 0.5027176238337222, "test_macro_f1": 0.6674682282092078, "test_runtime": 13.658, "test_samples_per_second": 149.949, "test_steps_per_second": 4.686, "epoch": 4.69}, {"test_loss": 0.7531769275665283, "test_mcc": 0.5314770997312261, "test_macro_f1": 0.6864648451912797, "test_runtime": 13.3137, "test_samples_per_second": 153.827, "test_steps_per_second": 4.807, "epoch": 4.69}, {"test_loss": 0.820168673992157, "test_mcc": 0.48934551567810114, "test_macro_f1": 0.6598970304255781, "test_runtime": 13.6625, "test_samples_per_second": 149.9, "test_steps_per_second": 4.684, "epoch": 5.62}, {"test_loss": 0.7921892404556274, "test_mcc": 0.4945322515718027, "test_macro_f1": 0.6614014461632572, "test_runtime": 13.5373, "test_samples_per_second": 151.285, "test_steps_per_second": 4.728, "epoch": 4.69}, {"test_loss": 0.7804205417633057, "test_mcc": 0.5231429570749931, "test_macro_f1": 0.6767708819171032, "test_runtime": 13.5802, "test_samples_per_second": 150.808, "test_steps_per_second": 4.713, "epoch": 4.69}, {"test_loss": 0.8016620874404907, "test_mcc": 0.4958766067939298, "test_macro_f1": 0.6335843728702168, "test_runtime": 13.7788, "test_samples_per_second": 148.634, "test_steps_per_second": 4.645, "epoch": 4.69}, {"test_loss": 0.8699901103973389, "test_mcc": 0.44620587634892084, "test_macro_f1": 0.6221095100825953, "test_runtime": 13.7597, "test_samples_per_second": 148.84, "test_steps_per_second": 4.651, "epoch": 5.62}, {"test_loss": 0.8104047775268555, "test_mcc": 0.46984759817717975, "test_macro_f1": 0.6439018173638374, "test_runtime": 13.497, "test_samples_per_second": 151.737, "test_steps_per_second": 4.742, "epoch": 4.69}]}, "total": {"test_mcc": 50.18558579765132, "test_mcc_se": 1.8237251976934659, "test_macro_f1": 66.3201084373306, "test_macro_f1_se": 1.496470080048345}}, "num_model_parameters": 575923843, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.7643834948539734, "test_mcc": 0.6169767504504466, "test_macro_f1": 0.7309113165081743, "test_runtime": 12.3472, "test_samples_per_second": 165.868, "test_steps_per_second": 5.183, "epoch": 5.62}, {"test_loss": 0.7137451767921448, "test_mcc": 0.5318948073403713, "test_macro_f1": 0.66354147628391, "test_runtime": 11.3383, "test_samples_per_second": 180.626, "test_steps_per_second": 5.645, "epoch": 4.69}, {"test_loss": 0.6742170453071594, "test_mcc": 0.5185169192642927, "test_macro_f1": 0.6274448296841744, "test_runtime": 11.514, "test_samples_per_second": 177.87, "test_steps_per_second": 5.558, "epoch": 4.69}, {"test_loss": 0.8406655788421631, "test_mcc": 0.49259331418147506, "test_macro_f1": 0.618309864279588, "test_runtime": 11.6033, "test_samples_per_second": 176.502, "test_steps_per_second": 5.516, "epoch": 5.62}, {"test_loss": 0.7909681797027588, "test_mcc": 0.5388656959889074, "test_macro_f1": 0.6608132402975383, "test_runtime": 11.6182, "test_samples_per_second": 176.275, "test_steps_per_second": 5.509, "epoch": 5.62}, {"test_loss": 0.7604398727416992, "test_mcc": 0.5568788758116663, "test_macro_f1": 0.686020298410616, "test_runtime": 12.0489, "test_samples_per_second": 169.974, "test_steps_per_second": 5.312, "epoch": 5.62}, {"test_loss": 0.8306052088737488, "test_mcc": 0.44716117433180996, "test_macro_f1": 0.47410198212600996, "test_runtime": 11.5492, "test_samples_per_second": 177.328, "test_steps_per_second": 5.542, "epoch": 4.69}, {"test_loss": 0.6273168325424194, "test_mcc": 0.5996430259763634, "test_macro_f1": 0.7140946652521613, "test_runtime": 11.9663, "test_samples_per_second": 171.147, "test_steps_per_second": 5.348, "epoch": 4.69}, {"test_loss": 0.7338007688522339, "test_mcc": 0.5309793299058289, "test_macro_f1": 0.6332509019134889, "test_runtime": 12.1792, "test_samples_per_second": 168.156, "test_steps_per_second": 5.255, "epoch": 4.69}, {"test_loss": 0.6785116791725159, "test_mcc": 0.585506754407758, "test_macro_f1": 0.7098803146360547, "test_runtime": 12.2261, "test_samples_per_second": 167.511, "test_steps_per_second": 5.235, "epoch": 4.69}]}, "total": {"test_mcc": 54.190166476589205, "test_mcc_se": 3.152197989979201, "test_macro_f1": 65.18368889391716, "test_macro_f1_se": 4.551726152611871}}, "num_model_parameters": 575923843, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.04613887518644333, "test_micro_f1": 0.7489583333333334, "test_micro_f1_no_misc": 0.8263845675171126, "test_runtime": 23.0115, "test_samples_per_second": 88.999, "test_steps_per_second": 2.781, "epoch": 5.62}, {"test_loss": 0.05643486976623535, "test_micro_f1": 0.6828512396694214, "test_micro_f1_no_misc": 0.7773584905660377, "test_runtime": 22.3844, "test_samples_per_second": 91.492, "test_steps_per_second": 2.859, "epoch": 4.69}, {"test_loss": 0.04844631999731064, "test_micro_f1": 0.7254335260115606, "test_micro_f1_no_misc": 0.7861842105263157, "test_runtime": 20.8769, "test_samples_per_second": 98.099, "test_steps_per_second": 3.066, "epoch": 5.62}, {"test_loss": 0.04721010476350784, "test_micro_f1": 0.7364729458917835, "test_micro_f1_no_misc": 0.7677984665936474, "test_runtime": 22.7724, "test_samples_per_second": 89.933, "test_steps_per_second": 2.81, "epoch": 4.69}, {"test_loss": 0.059113550931215286, "test_micro_f1": 0.6977363515312915, "test_micro_f1_no_misc": 0.7606793618116316, "test_runtime": 22.8222, "test_samples_per_second": 89.737, "test_steps_per_second": 2.804, "epoch": 4.69}, {"test_loss": 0.04982215538620949, "test_micro_f1": 0.7586529466791393, "test_micro_f1_no_misc": 0.8095496473141616, "test_runtime": 18.0179, "test_samples_per_second": 113.665, "test_steps_per_second": 3.552, "epoch": 6.56}, {"test_loss": 0.0508352555334568, "test_micro_f1": 0.7344913151364765, "test_micro_f1_no_misc": 0.7816349384098544, "test_runtime": 17.8818, "test_samples_per_second": 114.53, "test_steps_per_second": 3.579, "epoch": 7.5}, {"test_loss": 0.04687761887907982, "test_micro_f1": 0.711900915455035, "test_micro_f1_no_misc": 0.7692307692307692, "test_runtime": 22.6743, "test_samples_per_second": 90.322, "test_steps_per_second": 2.823, "epoch": 4.69}, {"test_loss": 0.05180225148797035, "test_micro_f1": 0.712688381137579, "test_micro_f1_no_misc": 0.7428273343766301, "test_runtime": 20.8305, "test_samples_per_second": 98.317, "test_steps_per_second": 3.072, "epoch": 4.69}, {"test_loss": 0.04931566119194031, "test_micro_f1": 0.7490234375, "test_micro_f1_no_misc": 0.8015963511972634, "test_runtime": 22.595, "test_samples_per_second": 90.639, "test_steps_per_second": 2.832, "epoch": 7.5}]}, "total": {"test_micro_f1": 72.5820939234562, "test_micro_f1_se": 1.5100053774578082, "test_micro_f1_no_misc": 78.23244137543425, "test_micro_f1_no_misc_se": 1.5328884880891922}}, "num_model_parameters": 574602505, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.05250069499015808, "test_micro_f1": 0.8276573787409701, "test_micro_f1_no_misc": 0.8455625436757512, "test_runtime": 31.5446, "test_samples_per_second": 64.924, "test_steps_per_second": 8.115, "epoch": 5.62}, {"test_loss": 0.04764295741915703, "test_micro_f1": 0.8336616943428089, "test_micro_f1_no_misc": 0.8593576965669989, "test_runtime": 29.4832, "test_samples_per_second": 69.463, "test_steps_per_second": 8.683, "epoch": 5.62}, {"test_loss": 0.056226696819067, "test_micro_f1": 0.8239254272397721, "test_micro_f1_no_misc": 0.8469775474956823, "test_runtime": 30.9856, "test_samples_per_second": 66.095, "test_steps_per_second": 8.262, "epoch": 5.62}, {"test_loss": 0.058673735707998276, "test_micro_f1": 0.7981744421906694, "test_micro_f1_no_misc": 0.8277015724322517, "test_runtime": 30.7926, "test_samples_per_second": 66.51, "test_steps_per_second": 8.314, "epoch": 5.62}, {"test_loss": 0.06678753346204758, "test_micro_f1": 0.7801169590643274, "test_micro_f1_no_misc": 0.8179399467882934, "test_runtime": 32.2275, "test_samples_per_second": 63.548, "test_steps_per_second": 7.944, "epoch": 4.69}, {"test_loss": 0.05293061211705208, "test_micro_f1": 0.8153544410198935, "test_micro_f1_no_misc": 0.8403298350824587, "test_runtime": 31.9402, "test_samples_per_second": 64.12, "test_steps_per_second": 8.015, "epoch": 4.69}, {"test_loss": 0.05254039540886879, "test_micro_f1": 0.8358606012237297, "test_micro_f1_no_misc": 0.8469170800850461, "test_runtime": 32.1819, "test_samples_per_second": 63.638, "test_steps_per_second": 7.955, "epoch": 5.62}, {"test_loss": 0.06202032044529915, "test_micro_f1": 0.8054882970137208, "test_micro_f1_no_misc": 0.8426586556515209, "test_runtime": 32.3165, "test_samples_per_second": 63.373, "test_steps_per_second": 7.922, "epoch": 5.62}, {"test_loss": 0.06828600913286209, "test_micro_f1": 0.794300518134715, "test_micro_f1_no_misc": 0.8270729978738482, "test_runtime": 31.1078, "test_samples_per_second": 65.836, "test_steps_per_second": 8.229, "epoch": 4.69}, {"test_loss": 0.05076450854539871, "test_micro_f1": 0.853255069370331, "test_micro_f1_no_misc": 0.8766519823788546, "test_runtime": 30.0614, "test_samples_per_second": 68.127, "test_steps_per_second": 8.516, "epoch": 5.62}]}, "total": {"test_micro_f1": 81.67794828340938, "test_micro_f1_se": 1.3819310250033972, "test_micro_f1_no_misc": 84.31169858030707, "test_micro_f1_no_misc_se": 1.0454534122031536}}, "num_model_parameters": 574602505, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.03386813402175903, "test_micro_f1": 0.8588064046579329, "test_micro_f1_no_misc": 0.8950642886768975, "test_runtime": 18.7441, "test_samples_per_second": 109.261, "test_steps_per_second": 3.414, "epoch": 7.5}, {"test_loss": 0.028910694643855095, "test_micro_f1": 0.8855243722304283, "test_micro_f1_no_misc": 0.9050142682429678, "test_runtime": 18.9116, "test_samples_per_second": 108.293, "test_steps_per_second": 3.384, "epoch": 6.56}, {"test_loss": 0.037224095314741135, "test_micro_f1": 0.8475630833045281, "test_micro_f1_no_misc": 0.8862179487179487, "test_runtime": 17.8266, "test_samples_per_second": 114.885, "test_steps_per_second": 3.59, "epoch": 5.62}, {"test_loss": 0.03757033869624138, "test_micro_f1": 0.8044412607449857, "test_micro_f1_no_misc": 0.8576172685761728, "test_runtime": 18.1554, "test_samples_per_second": 112.804, "test_steps_per_second": 3.525, "epoch": 4.69}, {"test_loss": 0.033785730600357056, "test_micro_f1": 0.8738887059598288, "test_micro_f1_no_misc": 0.9027982326951399, "test_runtime": 19.7205, "test_samples_per_second": 103.851, "test_steps_per_second": 3.245, "epoch": 6.56}, {"test_loss": 0.026930049061775208, "test_micro_f1": 0.8792805257696299, "test_micro_f1_no_misc": 0.9125534395647106, "test_runtime": 19.0109, "test_samples_per_second": 107.728, "test_steps_per_second": 3.366, "epoch": 6.56}, {"test_loss": 0.049569446593523026, "test_micro_f1": 0.8141342756183745, "test_micro_f1_no_misc": 0.8582739509105305, "test_runtime": 17.8439, "test_samples_per_second": 114.773, "test_steps_per_second": 3.587, "epoch": 5.62}, {"test_loss": 0.03335641324520111, "test_micro_f1": 0.8878082667592915, "test_micro_f1_no_misc": 0.9149736644093304, "test_runtime": 17.6628, "test_samples_per_second": 115.95, "test_steps_per_second": 3.623, "epoch": 6.56}, {"test_loss": 0.04521986097097397, "test_micro_f1": 0.7524254401724757, "test_micro_f1_no_misc": 0.8166397415185784, "test_runtime": 18.1514, "test_samples_per_second": 112.829, "test_steps_per_second": 3.526, "epoch": 4.69}, {"test_loss": 0.037293992936611176, "test_micro_f1": 0.8913342503438789, "test_micro_f1_no_misc": 0.9206349206349206, "test_runtime": 18.6228, "test_samples_per_second": 109.972, "test_steps_per_second": 3.437, "epoch": 8.44}]}, "total": {"test_micro_f1": 84.95206585561355, "test_micro_f1_se": 2.832177246141356, "test_micro_f1_no_misc": 88.69787723947198, "test_micro_f1_no_misc_se": 2.0500145357898023}}, "num_model_parameters": 574602505, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.044922441244125366, "test_micro_f1": 0.8360248447204969, "test_micro_f1_no_misc": 0.8739851747264384, "test_runtime": 17.2972, "test_samples_per_second": 118.401, "test_steps_per_second": 3.7, "epoch": 6.56}, {"test_loss": 0.04720168560743332, "test_micro_f1": 0.8826952526799388, "test_micro_f1_no_misc": 0.9107755662319835, "test_runtime": 18.2538, "test_samples_per_second": 112.196, "test_steps_per_second": 3.506, "epoch": 7.5}, {"test_loss": 0.049640148878097534, "test_micro_f1": 0.8444990780577749, "test_micro_f1_no_misc": 0.881786941580756, "test_runtime": 17.1355, "test_samples_per_second": 119.518, "test_steps_per_second": 3.735, "epoch": 7.5}, {"test_loss": 0.04908423125743866, "test_micro_f1": 0.7752909579230081, "test_micro_f1_no_misc": 0.8251846640872318, "test_runtime": 18.3112, "test_samples_per_second": 111.844, "test_steps_per_second": 3.495, "epoch": 4.69}, {"test_loss": 0.06221368908882141, "test_micro_f1": 0.7841463414634147, "test_micro_f1_no_misc": 0.8350951374207188, "test_runtime": 17.8552, "test_samples_per_second": 114.7, "test_steps_per_second": 3.584, "epoch": 4.69}, {"test_loss": 0.04877238720655441, "test_micro_f1": 0.8339285714285714, "test_micro_f1_no_misc": 0.878556557945871, "test_runtime": 18.2619, "test_samples_per_second": 112.146, "test_steps_per_second": 3.505, "epoch": 6.56}, {"test_loss": 0.03522640839219093, "test_micro_f1": 0.8324125230202579, "test_micro_f1_no_misc": 0.8746518105849582, "test_runtime": 18.494, "test_samples_per_second": 110.738, "test_steps_per_second": 3.461, "epoch": 5.62}, {"test_loss": 0.04493887722492218, "test_micro_f1": 0.7960048426150121, "test_micro_f1_no_misc": 0.8361272665070133, "test_runtime": 18.2959, "test_samples_per_second": 111.938, "test_steps_per_second": 3.498, "epoch": 4.69}, {"test_loss": 0.05487543344497681, "test_micro_f1": 0.8145612943372744, "test_micro_f1_no_misc": 0.8465869106263194, "test_runtime": 17.6965, "test_samples_per_second": 115.729, "test_steps_per_second": 3.617, "epoch": 6.56}, {"test_loss": 0.04292518272995949, "test_micro_f1": 0.8167164179104479, "test_micro_f1_no_misc": 0.8479685452162515, "test_runtime": 17.8326, "test_samples_per_second": 114.846, "test_steps_per_second": 3.589, "epoch": 4.69}]}, "total": {"test_micro_f1": 82.16280124156195, "test_micro_f1_se": 1.9610645408571319, "test_micro_f1_no_misc": 86.10718574927543, "test_micro_f1_no_misc_se": 1.66860882383303}}, "num_model_parameters": 574602505, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.3774537146091461, "test_mcc": 0.7185149597754906, "test_macro_f1": 0.8592541969082044, "test_runtime": 10.6554, "test_samples_per_second": 192.203, "test_steps_per_second": 6.006, "epoch": 6.56}, {"test_loss": 0.3452196717262268, "test_mcc": 0.7259288050899615, "test_macro_f1": 0.8627913658087074, "test_runtime": 11.0114, "test_samples_per_second": 185.989, "test_steps_per_second": 5.812, "epoch": 5.62}, {"test_loss": 0.34003162384033203, "test_mcc": 0.7394558605012947, "test_macro_f1": 0.869141420051648, "test_runtime": 11.2245, "test_samples_per_second": 182.458, "test_steps_per_second": 5.702, "epoch": 6.56}, {"test_loss": 0.37101832032203674, "test_mcc": 0.7099233880761093, "test_macro_f1": 0.8544920487328042, "test_runtime": 11.0016, "test_samples_per_second": 186.155, "test_steps_per_second": 5.817, "epoch": 4.69}, {"test_loss": 0.39733803272247314, "test_mcc": 0.7104177112325323, "test_macro_f1": 0.8511076160072558, "test_runtime": 11.4371, "test_samples_per_second": 179.066, "test_steps_per_second": 5.596, "epoch": 8.44}, {"test_loss": 0.3758678436279297, "test_mcc": 0.7201804016400286, "test_macro_f1": 0.859838920253006, "test_runtime": 10.8524, "test_samples_per_second": 188.713, "test_steps_per_second": 5.897, "epoch": 5.62}, {"test_loss": 0.3948761820793152, "test_mcc": 0.6975388354392874, "test_macro_f1": 0.844477667931592, "test_runtime": 11.2443, "test_samples_per_second": 182.136, "test_steps_per_second": 5.692, "epoch": 6.56}, {"test_loss": 0.3488313555717468, "test_mcc": 0.7403308443174815, "test_macro_f1": 0.8700458015267176, "test_runtime": 11.37, "test_samples_per_second": 180.123, "test_steps_per_second": 5.629, "epoch": 5.62}, {"test_loss": 0.3965921401977539, "test_mcc": 0.712408215405042, "test_macro_f1": 0.8531845083609153, "test_runtime": 11.109, "test_samples_per_second": 184.355, "test_steps_per_second": 5.761, "epoch": 6.56}, {"test_loss": 0.35089346766471863, "test_mcc": 0.742789634303382, "test_macro_f1": 0.8694346288487065, "test_runtime": 11.254, "test_samples_per_second": 181.979, "test_steps_per_second": 5.687, "epoch": 5.62}]}, "total": {"test_mcc": 72.17488655780609, "test_mcc_se": 0.9407868320086556, "test_macro_f1": 85.93768174429556, "test_macro_f1_se": 0.5366853886957322}}, "num_model_parameters": 575922690, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.39059510827064514, "test_mcc": 0.6978790733876582, "test_macro_f1": 0.8478572075225798, "test_runtime": 11.8301, "test_samples_per_second": 173.118, "test_steps_per_second": 5.41, "epoch": 4.69}, {"test_loss": 0.31801971793174744, "test_mcc": 0.7600640418680004, "test_macro_f1": 0.8796606282962623, "test_runtime": 12.2232, "test_samples_per_second": 167.55, "test_steps_per_second": 5.236, "epoch": 6.56}, {"test_loss": 0.3626095652580261, "test_mcc": 0.7148937811355384, "test_macro_f1": 0.856445175595451, "test_runtime": 12.0343, "test_samples_per_second": 170.18, "test_steps_per_second": 5.318, "epoch": 4.69}, {"test_loss": 0.4027422368526459, "test_mcc": 0.6827117694391442, "test_macro_f1": 0.8412673807567701, "test_runtime": 12.6015, "test_samples_per_second": 162.52, "test_steps_per_second": 5.079, "epoch": 5.62}, {"test_loss": 0.4860234260559082, "test_mcc": 0.6287226011767871, "test_macro_f1": 0.7839643279298784, "test_runtime": 11.9303, "test_samples_per_second": 171.663, "test_steps_per_second": 5.364, "epoch": 4.69}, {"test_loss": 0.38995498418807983, "test_mcc": 0.7157881898062798, "test_macro_f1": 0.8578889800578442, "test_runtime": 11.969, "test_samples_per_second": 171.109, "test_steps_per_second": 5.347, "epoch": 7.5}, {"test_loss": 0.438632607460022, "test_mcc": 0.6742892687413427, "test_macro_f1": 0.8369139069689817, "test_runtime": 11.6371, "test_samples_per_second": 175.989, "test_steps_per_second": 5.5, "epoch": 5.62}, {"test_loss": 0.325814425945282, "test_mcc": 0.7314183623403446, "test_macro_f1": 0.8643476073432148, "test_runtime": 11.9703, "test_samples_per_second": 171.09, "test_steps_per_second": 5.347, "epoch": 5.62}, {"test_loss": 0.4633995294570923, "test_mcc": 0.6724206412656728, "test_macro_f1": 0.8189313919727397, "test_runtime": 11.7824, "test_samples_per_second": 173.819, "test_steps_per_second": 5.432, "epoch": 4.69}, {"test_loss": 0.44437289237976074, "test_mcc": 0.6941736066820027, "test_macro_f1": 0.8430981976978031, "test_runtime": 12.0011, "test_samples_per_second": 170.652, "test_steps_per_second": 5.333, "epoch": 6.56}]}, "total": {"test_mcc": 69.7236133584277, "test_mcc_se": 2.2470262990472656, "test_macro_f1": 84.30374804141525, "test_macro_f1_se": 1.643794392804404}}, "num_model_parameters": 575922690, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.34875065088272095, "test_mcc": 0.7312474406731496, "test_macro_f1": 0.8607557825543537, "test_runtime": 11.2687, "test_samples_per_second": 181.743, "test_steps_per_second": 5.679, "epoch": 4.69}, {"test_loss": 0.42670297622680664, "test_mcc": 0.6582834867761373, "test_macro_f1": 0.8290911310504792, "test_runtime": 11.3025, "test_samples_per_second": 181.198, "test_steps_per_second": 5.662, "epoch": 5.62}, {"test_loss": 0.4705345630645752, "test_mcc": 0.6951126018260282, "test_macro_f1": 0.8466760319717401, "test_runtime": 11.4179, "test_samples_per_second": 179.367, "test_steps_per_second": 5.605, "epoch": 7.5}, {"test_loss": 0.3412783741950989, "test_mcc": 0.7348462902496318, "test_macro_f1": 0.8670576735092864, "test_runtime": 11.2426, "test_samples_per_second": 182.165, "test_steps_per_second": 5.693, "epoch": 5.62}, {"test_loss": 0.39223217964172363, "test_mcc": 0.718588505202546, "test_macro_f1": 0.8575906922395902, "test_runtime": 11.2485, "test_samples_per_second": 182.069, "test_steps_per_second": 5.69, "epoch": 5.62}, {"test_loss": 0.35363417863845825, "test_mcc": 0.7187680343968456, "test_macro_f1": 0.8593315347836207, "test_runtime": 10.5287, "test_samples_per_second": 194.516, "test_steps_per_second": 6.079, "epoch": 4.69}, {"test_loss": 0.4899826645851135, "test_mcc": 0.6940574132528216, "test_macro_f1": 0.8470042233368299, "test_runtime": 10.5669, "test_samples_per_second": 193.812, "test_steps_per_second": 6.057, "epoch": 7.5}, {"test_loss": 0.3711848258972168, "test_mcc": 0.7107535461780964, "test_macro_f1": 0.8541303568440928, "test_runtime": 10.9997, "test_samples_per_second": 186.186, "test_steps_per_second": 5.818, "epoch": 4.69}, {"test_loss": 0.43515780568122864, "test_mcc": 0.6322156367633016, "test_macro_f1": 0.8070701099207437, "test_runtime": 10.7146, "test_samples_per_second": 191.141, "test_steps_per_second": 5.973, "epoch": 4.69}, {"test_loss": 0.4095275402069092, "test_mcc": 0.6889445671344212, "test_macro_f1": 0.8431750917938763, "test_runtime": 10.9082, "test_samples_per_second": 187.749, "test_steps_per_second": 5.867, "epoch": 4.69}]}, "total": {"test_mcc": 69.8281752245298, "test_mcc_se": 2.012750680143095, "test_macro_f1": 84.71882628004612, "test_macro_f1_se": 1.1002621183127443}}, "num_model_parameters": 575922690, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "google/rembert", "results": {"raw": {"test": [{"test_loss": 0.41901564598083496, "test_mcc": 0.6505720711307503, "test_macro_f1": 0.8252415627812256, "test_runtime": 11.6096, "test_samples_per_second": 176.406, "test_steps_per_second": 5.513, "epoch": 6.56}, {"test_loss": 0.46901828050613403, "test_mcc": 0.6138133027208047, "test_macro_f1": 0.8066288225599707, "test_runtime": 12.1359, "test_samples_per_second": 168.755, "test_steps_per_second": 5.274, "epoch": 6.56}, {"test_loss": 0.4843660593032837, "test_mcc": 0.5686546616632147, "test_macro_f1": 0.7834865231538768, "test_runtime": 11.8163, "test_samples_per_second": 173.319, "test_steps_per_second": 5.416, "epoch": 4.69}, {"test_loss": 0.48626261949539185, "test_mcc": 0.5913333147598188, "test_macro_f1": 0.7637824495735908, "test_runtime": 11.3192, "test_samples_per_second": 180.931, "test_steps_per_second": 5.654, "epoch": 4.69}, {"test_loss": 0.424934059381485, "test_mcc": 0.6597960312103127, "test_macro_f1": 0.8297638156386149, "test_runtime": 11.3529, "test_samples_per_second": 180.395, "test_steps_per_second": 5.637, "epoch": 6.56}, {"test_loss": 0.45959049463272095, "test_mcc": 0.5856118906438635, "test_macro_f1": 0.7837141209081342, "test_runtime": 11.7019, "test_samples_per_second": 175.014, "test_steps_per_second": 5.469, "epoch": 5.62}, {"test_loss": 0.4975086450576782, "test_mcc": 0.5817882977622315, "test_macro_f1": 0.7798225289670406, "test_runtime": 11.6052, "test_samples_per_second": 176.472, "test_steps_per_second": 5.515, "epoch": 5.62}, {"test_loss": 0.42205771803855896, "test_mcc": 0.6228673388491757, "test_macro_f1": 0.8111667127685435, "test_runtime": 11.7264, "test_samples_per_second": 174.648, "test_steps_per_second": 5.458, "epoch": 6.56}, {"test_loss": 0.6968398690223694, "test_mcc": -0.023209390782127512, "test_macro_f1": 0.3220787818603112, "test_runtime": 11.5081, "test_samples_per_second": 177.962, "test_steps_per_second": 5.561, "epoch": 4.69}, {"test_loss": 0.48564964532852173, "test_mcc": 0.6328987404868496, "test_macro_f1": 0.8070196729610938, "test_runtime": 11.712, "test_samples_per_second": 174.863, "test_steps_per_second": 5.464, "epoch": 4.69}]}, "total": {"test_mcc": 54.841262584448934, "test_mcc_se": 12.589223876693492, "test_macro_f1": 75.12704991172401, "test_macro_f1_se": 9.437461580047632}}, "num_model_parameters": 575922690, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "google/rembert", "results": {"raw": {"test": [{"test_em": 52.90472501936483, "test_f1": 58.277699130917206, "epoch": 2.43}, {"test_em": 51.70542635658915, "test_f1": 54.74411333713658, "epoch": 3.51}, {"test_em": 50.0, "test_f1": 54.290593486884056, "epoch": 2.7}, {"test_em": 52.18068535825545, "test_f1": 57.10503860249092, "epoch": 2.43}, {"test_em": 52.12355212355212, "test_f1": 56.54774359481778, "epoch": 2.43}, {"test_em": 53.73939861218196, "test_f1": 59.16238624120215, "epoch": 2.43}, {"test_em": 52.771450265755504, "test_f1": 57.54085953778578, "epoch": 2.43}, {"test_em": 48.87509697439876, "test_f1": 52.4567686606887, "epoch": 2.43}, {"test_em": 51.21568627450981, "test_f1": 56.000406158763276, "epoch": 2.16}, {"test_em": 54.81366459627329, "test_f1": 59.23109483321149, "epoch": 2.7}]}, "total": {"test_em": 52.032968558088086, "test_em_se": 1.0707466128083878, "test_f1": 56.535670358389794, "test_f1_se": 1.3658938995527186}}, "num_model_parameters": 574594434, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "google/rembert", "results": {"raw": {"test": [{"test_em": 52.90472501936483, "test_f1": 56.969828758587774, "epoch": 2.5}, {"test_em": 52.55813953488372, "test_f1": 57.795536057955914, "epoch": 2.5}, {"test_em": 47.44976816074188, "test_f1": 53.31224905799504, "epoch": 2.19}, {"test_em": 53.271028037383175, "test_f1": 58.33863248273275, "epoch": 2.5}, {"test_em": 51.58301158301158, "test_f1": 55.59876548486818, "epoch": 2.81}, {"test_em": 53.508095605242865, "test_f1": 57.50568456765895, "epoch": 2.5}, {"test_em": 51.0250569476082, "test_f1": 55.95260214943986, "epoch": 2.19}, {"test_em": 44.99612102404965, "test_f1": 48.45174119349266, "epoch": 2.5}, {"test_em": 52.549019607843135, "test_f1": 58.003535636476805, "epoch": 2.5}, {"test_em": 51.5527950310559, "test_f1": 57.13369959060951, "epoch": 2.5}]}, "total": {"test_em": 51.139776055118496, "test_em_se": 1.7162259367434956, "test_f1": 55.90622749798174, "test_f1_se": 1.8648719277945813}}, "num_model_parameters": 574594434, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "google/rembert", "results": {"raw": {"test": [{"test_em": 45.778466305189774, "test_f1": 50.56524031144707, "epoch": 2.21}, {"test_em": 50.542635658914726, "test_f1": 55.28831696196391, "epoch": 2.52}, {"test_em": 50.38639876352396, "test_f1": 54.90534533402065, "epoch": 3.16}, {"test_em": 49.22118380062305, "test_f1": 53.85758964348269, "epoch": 2.21}, {"test_em": 44.86486486486486, "test_f1": 50.153966827341414, "epoch": 2.21}, {"test_em": 56.12952968388589, "test_f1": 61.81851247898388, "epoch": 2.52}, {"test_em": 50.11389521640091, "test_f1": 55.02419534617661, "epoch": 3.47}, {"test_em": 53.297129557796744, "test_f1": 58.618827220894445, "epoch": 2.21}, {"test_em": 52.94117647058823, "test_f1": 58.114782202733196, "epoch": 2.52}, {"test_em": 54.7360248447205, "test_f1": 59.982261907499364, "epoch": 2.84}]}, "total": {"test_em": 50.801130516650865, "test_em_se": 2.2476830788815563, "test_f1": 55.832903823454316, "test_f1_se": 2.371198975961555}}, "num_model_parameters": 574594434, "max_sequence_length": 256, "vocabulary_size": 250300}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.5582003593444824, "test_mcc": 0.6466302276007955, "test_macro_f1": 0.5643458029521365, "test_runtime": 17.6732, "test_samples_per_second": 115.881, "test_steps_per_second": 57.941}, {"test_loss": 0.6194695234298706, "test_mcc": 0.6197522495930368, "test_macro_f1": 0.6095039024655436, "test_runtime": 17.1828, "test_samples_per_second": 119.189, "test_steps_per_second": 59.594}, {"test_loss": 0.5958386659622192, "test_mcc": 0.6077921765077849, "test_macro_f1": 0.6040623779673374, "test_runtime": 17.5905, "test_samples_per_second": 116.427, "test_steps_per_second": 58.213}, {"test_loss": 0.5375927686691284, "test_mcc": 0.6397872290278677, "test_macro_f1": 0.5712796734557308, "test_runtime": 17.5118, "test_samples_per_second": 116.95, "test_steps_per_second": 58.475}, {"test_loss": 0.558921217918396, "test_mcc": 0.6528677898221379, "test_macro_f1": 0.6171755463501246, "test_runtime": 17.7216, "test_samples_per_second": 115.565, "test_steps_per_second": 57.783}, {"test_loss": 0.5851908922195435, "test_mcc": 0.6397525673335671, "test_macro_f1": 0.6396678184665281, "test_runtime": 17.5934, "test_samples_per_second": 116.407, "test_steps_per_second": 58.204}, {"test_loss": 0.5551247596740723, "test_mcc": 0.6365790844395867, "test_macro_f1": 0.601889365946743, "test_runtime": 17.3727, "test_samples_per_second": 117.886, "test_steps_per_second": 58.943}, {"test_loss": 0.5418359041213989, "test_mcc": 0.6390249426465968, "test_macro_f1": 0.6294546180137757, "test_runtime": 17.8747, "test_samples_per_second": 114.575, "test_steps_per_second": 57.288}, {"test_loss": 0.5388028621673584, "test_mcc": 0.637362506540442, "test_macro_f1": 0.6088602593615193, "test_runtime": 17.7016, "test_samples_per_second": 115.696, "test_steps_per_second": 57.848}, {"test_loss": 0.5895757675170898, "test_mcc": 0.6107123675303554, "test_macro_f1": 0.5495047327073248, "test_runtime": 17.7947, "test_samples_per_second": 115.09, "test_steps_per_second": 57.545}]}, "total": {"test_mcc": 63.302611410421704, "test_mcc_se": 0.9349713751216531, "test_macro_f1": 59.95744097686764, "test_macro_f1_se": 1.7974446046530972}}, "num_model_parameters": 167358723, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.9484952092170715, "test_mcc": 0.3508328705791324, "test_macro_f1": 0.5562880828432976, "test_runtime": 4.4585, "test_samples_per_second": 459.352, "test_steps_per_second": 14.355}, {"test_loss": 0.9691841006278992, "test_mcc": 0.23699061736145016, "test_macro_f1": 0.45975780098684477, "test_runtime": 4.4205, "test_samples_per_second": 463.294, "test_steps_per_second": 14.478}, {"test_loss": 1.009412169456482, "test_mcc": 0.3354958919591306, "test_macro_f1": 0.5511934008689037, "test_runtime": 4.4117, "test_samples_per_second": 464.223, "test_steps_per_second": 14.507}, {"test_loss": 1.098444938659668, "test_mcc": 0.33723881486735957, "test_macro_f1": 0.5534342145601818, "test_runtime": 4.4675, "test_samples_per_second": 458.417, "test_steps_per_second": 14.326}, {"test_loss": 0.9969480037689209, "test_mcc": 0.340351195878914, "test_macro_f1": 0.5408475272688681, "test_runtime": 4.4172, "test_samples_per_second": 463.638, "test_steps_per_second": 14.489}, {"test_loss": 0.9684419631958008, "test_mcc": 0.3511826616157885, "test_macro_f1": 0.5675393216401462, "test_runtime": 4.4626, "test_samples_per_second": 458.922, "test_steps_per_second": 14.341}, {"test_loss": 0.9498534202575684, "test_mcc": 0.3439417284179573, "test_macro_f1": 0.5555228365360018, "test_runtime": 4.6893, "test_samples_per_second": 436.741, "test_steps_per_second": 13.648}, {"test_loss": 0.977405309677124, "test_mcc": 0.29721106894464966, "test_macro_f1": 0.5238204118528805, "test_runtime": 4.5083, "test_samples_per_second": 454.273, "test_steps_per_second": 14.196}, {"test_loss": 0.9468507766723633, "test_mcc": 0.3773415816458762, "test_macro_f1": 0.5743573567227821, "test_runtime": 4.4199, "test_samples_per_second": 463.357, "test_steps_per_second": 14.48}, {"test_loss": 1.026349663734436, "test_mcc": 0.379330516007072, "test_macro_f1": 0.5805785499407788, "test_runtime": 4.3967, "test_samples_per_second": 465.802, "test_steps_per_second": 14.556}]}, "total": {"test_mcc": 33.4991694727733, "test_mcc_se": 2.5653840463097053, "test_macro_f1": 54.633395032206856, "test_macro_f1_se": 2.1368704644890912}}, "num_model_parameters": 167358723, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.9249066114425659, "test_mcc": 0.42418391128515376, "test_macro_f1": 0.5758027969523333, "test_runtime": 3.71, "test_samples_per_second": 552.018, "test_steps_per_second": 17.251}, {"test_loss": 0.8244733214378357, "test_mcc": 0.38648428139205077, "test_macro_f1": 0.5072920303155358, "test_runtime": 3.4778, "test_samples_per_second": 588.883, "test_steps_per_second": 18.403}, {"test_loss": 0.8535137176513672, "test_mcc": 0.4148640122533587, "test_macro_f1": 0.5538615276290962, "test_runtime": 3.5172, "test_samples_per_second": 582.276, "test_steps_per_second": 18.196}, {"test_loss": 0.9754161238670349, "test_mcc": 0.36684055695118445, "test_macro_f1": 0.4721136035158014, "test_runtime": 3.5359, "test_samples_per_second": 579.198, "test_steps_per_second": 18.1}, {"test_loss": 0.9499577283859253, "test_mcc": 0.3850355925775096, "test_macro_f1": 0.472054530455974, "test_runtime": 3.6434, "test_samples_per_second": 562.109, "test_steps_per_second": 17.566}, {"test_loss": 0.8976761698722839, "test_mcc": 0.36491948098464133, "test_macro_f1": 0.4482478133773931, "test_runtime": 3.6963, "test_samples_per_second": 554.061, "test_steps_per_second": 17.314}, {"test_loss": 0.8837578296661377, "test_mcc": 0.3782918550808764, "test_macro_f1": 0.527576480189199, "test_runtime": 3.6051, "test_samples_per_second": 568.078, "test_steps_per_second": 17.752}, {"test_loss": 0.9242693185806274, "test_mcc": 0.30477098568550454, "test_macro_f1": 0.40960213819329844, "test_runtime": 3.6076, "test_samples_per_second": 567.687, "test_steps_per_second": 17.74}, {"test_loss": 0.8787463903427124, "test_mcc": 0.34035302090422836, "test_macro_f1": 0.45547826601469793, "test_runtime": 3.7171, "test_samples_per_second": 550.966, "test_steps_per_second": 17.218}, {"test_loss": 0.872549295425415, "test_mcc": 0.3621198115301501, "test_macro_f1": 0.44737114525444044, "test_runtime": 3.6937, "test_samples_per_second": 554.458, "test_steps_per_second": 17.327}]}, "total": {"test_mcc": 37.278635086446585, "test_mcc_se": 2.134036359636975, "test_macro_f1": 48.6940033189777, "test_macro_f1_se": 3.261159689663208}}, "num_model_parameters": 167358723, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.0846395194530487, "test_micro_f1": 0.6091319618665328, "test_micro_f1_no_misc": 0.6693002257336342, "test_runtime": 7.5356, "test_samples_per_second": 271.777, "test_steps_per_second": 8.493}, {"test_loss": 0.07872151583433151, "test_micro_f1": 0.6383213694091662, "test_micro_f1_no_misc": 0.7128463476070529, "test_runtime": 6.8822, "test_samples_per_second": 297.578, "test_steps_per_second": 9.299}, {"test_loss": 0.07587619870901108, "test_micro_f1": 0.629511677282378, "test_micro_f1_no_misc": 0.6978723404255319, "test_runtime": 7.0648, "test_samples_per_second": 289.887, "test_steps_per_second": 9.059}, {"test_loss": 0.07924629002809525, "test_micro_f1": 0.6928456159225391, "test_micro_f1_no_misc": 0.7331378299120234, "test_runtime": 7.4285, "test_samples_per_second": 275.693, "test_steps_per_second": 8.615}, {"test_loss": 0.08164525777101517, "test_micro_f1": 0.6717339667458432, "test_micro_f1_no_misc": 0.7203791469194312, "test_runtime": 7.3689, "test_samples_per_second": 277.926, "test_steps_per_second": 8.685}, {"test_loss": 0.08697807043790817, "test_micro_f1": 0.6712940009915715, "test_micro_f1_no_misc": 0.725412166003411, "test_runtime": 5.8656, "test_samples_per_second": 349.154, "test_steps_per_second": 10.911}, {"test_loss": 0.08229696750640869, "test_micro_f1": 0.6292362164896308, "test_micro_f1_no_misc": 0.6765027322404372, "test_runtime": 6.6746, "test_samples_per_second": 306.835, "test_steps_per_second": 9.589}, {"test_loss": 0.06775495409965515, "test_micro_f1": 0.6529705719044975, "test_micro_f1_no_misc": 0.687689508793208, "test_runtime": 7.6515, "test_samples_per_second": 267.661, "test_steps_per_second": 8.364}, {"test_loss": 0.06857521831989288, "test_micro_f1": 0.6686159844054581, "test_micro_f1_no_misc": 0.7145877378435518, "test_runtime": 7.1148, "test_samples_per_second": 287.853, "test_steps_per_second": 8.995}, {"test_loss": 0.0738031417131424, "test_micro_f1": 0.6859999999999999, "test_micro_f1_no_misc": 0.7477578475336323, "test_runtime": 7.1057, "test_samples_per_second": 288.221, "test_steps_per_second": 9.007}]}, "total": {"test_micro_f1": 65.49661365017617, "test_micro_f1_se": 1.7066629485755282, "test_micro_f1_no_misc": 70.85485883011914, "test_micro_f1_no_misc_se": 1.564966629112323}}, "num_model_parameters": 166772745, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.08248735964298248, "test_micro_f1": 0.7813229571984436, "test_micro_f1_no_misc": 0.7968374011687864, "test_runtime": 9.0272, "test_samples_per_second": 226.87, "test_steps_per_second": 7.09}, {"test_loss": 0.06897661089897156, "test_micro_f1": 0.767741935483871, "test_micro_f1_no_misc": 0.8007092198581561, "test_runtime": 6.972, "test_samples_per_second": 293.745, "test_steps_per_second": 9.18}, {"test_loss": 0.07545243203639984, "test_micro_f1": 0.77780658542909, "test_micro_f1_no_misc": 0.8045977011494253, "test_runtime": 8.8079, "test_samples_per_second": 232.519, "test_steps_per_second": 7.266}, {"test_loss": 0.07874573022127151, "test_micro_f1": 0.7661562418894368, "test_micro_f1_no_misc": 0.7997247075017206, "test_runtime": 8.3061, "test_samples_per_second": 246.567, "test_steps_per_second": 7.705}, {"test_loss": 0.0785941556096077, "test_micro_f1": 0.7948941108210038, "test_micro_f1_no_misc": 0.8058778035576181, "test_runtime": 9.0474, "test_samples_per_second": 226.362, "test_steps_per_second": 7.074}, {"test_loss": 0.08099998533725739, "test_micro_f1": 0.7859707263186964, "test_micro_f1_no_misc": 0.8018223234624147, "test_runtime": 8.9417, "test_samples_per_second": 229.04, "test_steps_per_second": 7.158}, {"test_loss": 0.06813447177410126, "test_micro_f1": 0.7823721436343852, "test_micro_f1_no_misc": 0.8039914468995011, "test_runtime": 9.1166, "test_samples_per_second": 224.646, "test_steps_per_second": 7.02}, {"test_loss": 0.07310494035482407, "test_micro_f1": 0.7881219903691814, "test_micro_f1_no_misc": 0.8220183486238533, "test_runtime": 8.8569, "test_samples_per_second": 231.233, "test_steps_per_second": 7.226}, {"test_loss": 0.07744461297988892, "test_micro_f1": 0.7666750566322678, "test_micro_f1_no_misc": 0.7889655172413793, "test_runtime": 8.4033, "test_samples_per_second": 243.714, "test_steps_per_second": 7.616}, {"test_loss": 0.07673809677362442, "test_micro_f1": 0.7571927937617638, "test_micro_f1_no_misc": 0.7698803659394793, "test_runtime": 7.2849, "test_samples_per_second": 281.128, "test_steps_per_second": 8.785}]}, "total": {"test_micro_f1": 77.6825454153814, "test_micro_f1_se": 0.7375708941733068, "test_micro_f1_no_misc": 79.94424835402334, "test_micro_f1_no_misc_se": 0.82541946847955}}, "num_model_parameters": 166772745, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.0731828510761261, "test_micro_f1": 0.8051565377532228, "test_micro_f1_no_misc": 0.8400659521846661, "test_runtime": 6.7926, "test_samples_per_second": 301.505, "test_steps_per_second": 9.422}, {"test_loss": 0.07382629811763763, "test_micro_f1": 0.7931661214103962, "test_micro_f1_no_misc": 0.8310838445807772, "test_runtime": 6.7177, "test_samples_per_second": 304.865, "test_steps_per_second": 9.527}, {"test_loss": 0.07712915539741516, "test_micro_f1": 0.7478381182981667, "test_micro_f1_no_misc": 0.7877199550730065, "test_runtime": 6.5027, "test_samples_per_second": 314.947, "test_steps_per_second": 9.842}, {"test_loss": 0.06955516338348389, "test_micro_f1": 0.8139618567830155, "test_micro_f1_no_misc": 0.8522308636921817, "test_runtime": 6.2504, "test_samples_per_second": 327.657, "test_steps_per_second": 10.239}, {"test_loss": 0.0774366706609726, "test_micro_f1": 0.7539548973409625, "test_micro_f1_no_misc": 0.7928649435748087, "test_runtime": 6.7535, "test_samples_per_second": 303.25, "test_steps_per_second": 9.477}, {"test_loss": 0.07023656368255615, "test_micro_f1": 0.8192360163710778, "test_micro_f1_no_misc": 0.8569224836097185, "test_runtime": 6.8235, "test_samples_per_second": 300.14, "test_steps_per_second": 9.379}, {"test_loss": 0.06336621195077896, "test_micro_f1": 0.7758678800134817, "test_micro_f1_no_misc": 0.8184892897406989, "test_runtime": 6.1771, "test_samples_per_second": 331.546, "test_steps_per_second": 10.361}, {"test_loss": 0.0633663535118103, "test_micro_f1": 0.8118393234672304, "test_micro_f1_no_misc": 0.8378481495612362, "test_runtime": 6.5128, "test_samples_per_second": 314.459, "test_steps_per_second": 9.827}, {"test_loss": 0.06660948693752289, "test_micro_f1": 0.7935483870967742, "test_micro_f1_no_misc": 0.8300990099009901, "test_runtime": 6.293, "test_samples_per_second": 325.44, "test_steps_per_second": 10.17}, {"test_loss": 0.08752110600471497, "test_micro_f1": 0.7915949018256976, "test_micro_f1_no_misc": 0.8427672955974842, "test_runtime": 6.5981, "test_samples_per_second": 310.393, "test_steps_per_second": 9.7}]}, "total": {"test_micro_f1": 79.06164040360026, "test_micro_f1_se": 1.5229173342260907, "test_micro_f1_no_misc": 82.90091787515567, "test_micro_f1_no_misc_se": 1.4366546606020172}}, "num_model_parameters": 166772745, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.07815323024988174, "test_micro_f1": 0.7742338961851156, "test_micro_f1_no_misc": 0.8187094571526118, "test_runtime": 6.2927, "test_samples_per_second": 325.455, "test_steps_per_second": 10.17}, {"test_loss": 0.07271116226911545, "test_micro_f1": 0.7304347826086957, "test_micro_f1_no_misc": 0.7725795971410008, "test_runtime": 6.4283, "test_samples_per_second": 318.591, "test_steps_per_second": 9.956}, {"test_loss": 0.07473181188106537, "test_micro_f1": 0.7621896500149568, "test_micro_f1_no_misc": 0.8022561380225615, "test_runtime": 6.0333, "test_samples_per_second": 339.45, "test_steps_per_second": 10.608}, {"test_loss": 0.08899946510791779, "test_micro_f1": 0.6951934349355218, "test_micro_f1_no_misc": 0.7410207939508506, "test_runtime": 6.3352, "test_samples_per_second": 323.272, "test_steps_per_second": 10.102}, {"test_loss": 0.09103651344776154, "test_micro_f1": 0.7088764742396026, "test_micro_f1_no_misc": 0.758998971546109, "test_runtime": 6.0867, "test_samples_per_second": 336.471, "test_steps_per_second": 10.515}, {"test_loss": 0.0830892026424408, "test_micro_f1": 0.723596861798431, "test_micro_f1_no_misc": 0.7837216934689859, "test_runtime": 6.245, "test_samples_per_second": 327.941, "test_steps_per_second": 10.248}, {"test_loss": 0.07184751331806183, "test_micro_f1": 0.7639405204460967, "test_micro_f1_no_misc": 0.8068027210884354, "test_runtime": 6.5337, "test_samples_per_second": 313.45, "test_steps_per_second": 9.795}, {"test_loss": 0.07749247550964355, "test_micro_f1": 0.7157069641242086, "test_micro_f1_no_misc": 0.7600527356624918, "test_runtime": 6.5513, "test_samples_per_second": 312.611, "test_steps_per_second": 9.769}, {"test_loss": 0.08572165668010712, "test_micro_f1": 0.7335811648079307, "test_micro_f1_no_misc": 0.7773558853986883, "test_runtime": 6.087, "test_samples_per_second": 336.456, "test_steps_per_second": 10.514}, {"test_loss": 0.09374947845935822, "test_micro_f1": 0.6756334063184235, "test_micro_f1_no_misc": 0.7119314436387608, "test_runtime": 6.0573, "test_samples_per_second": 338.103, "test_steps_per_second": 10.566}]}, "total": {"test_micro_f1": 72.83387155478984, "test_micro_f1_se": 1.9587912937271394, "test_micro_f1_no_misc": 77.33429437070495, "test_micro_f1_no_misc_se": 1.9963078440911937}}, "num_model_parameters": 166772745, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.5464508533477783, "test_mcc": 0.4646337675211803, "test_macro_f1": 0.7291757968436561, "test_runtime": 3.4173, "test_samples_per_second": 599.304, "test_steps_per_second": 18.728}, {"test_loss": 0.5552977919578552, "test_mcc": 0.5010597911154896, "test_macro_f1": 0.7431329506879544, "test_runtime": 3.6082, "test_samples_per_second": 567.6, "test_steps_per_second": 17.737}, {"test_loss": 0.5916528701782227, "test_mcc": 0.5045110109684073, "test_macro_f1": 0.7433535874215226, "test_runtime": 3.5971, "test_samples_per_second": 569.354, "test_steps_per_second": 17.792}, {"test_loss": 0.5611265301704407, "test_mcc": 0.48529974938458326, "test_macro_f1": 0.7329068687273456, "test_runtime": 3.5431, "test_samples_per_second": 578.019, "test_steps_per_second": 18.063}, {"test_loss": 0.5556396245956421, "test_mcc": 0.4636464983271463, "test_macro_f1": 0.7223588651108743, "test_runtime": 3.5863, "test_samples_per_second": 571.068, "test_steps_per_second": 17.846}, {"test_loss": 0.552375853061676, "test_mcc": 0.48514941958106145, "test_macro_f1": 0.7413523452143265, "test_runtime": 3.5197, "test_samples_per_second": 581.863, "test_steps_per_second": 18.183}, {"test_loss": 0.5526332855224609, "test_mcc": 0.5251761495928431, "test_macro_f1": 0.7585720419554682, "test_runtime": 3.5743, "test_samples_per_second": 572.985, "test_steps_per_second": 17.906}, {"test_loss": 0.5639686584472656, "test_mcc": 0.4927129078254391, "test_macro_f1": 0.7379310344827587, "test_runtime": 3.5569, "test_samples_per_second": 575.784, "test_steps_per_second": 17.993}, {"test_loss": 0.5703517198562622, "test_mcc": 0.48263354913638395, "test_macro_f1": 0.7379617513610418, "test_runtime": 3.5585, "test_samples_per_second": 575.53, "test_steps_per_second": 17.985}, {"test_loss": 0.5602455735206604, "test_mcc": 0.49228560639287683, "test_macro_f1": 0.7312723819826024, "test_runtime": 3.5806, "test_samples_per_second": 571.966, "test_steps_per_second": 17.874}]}, "total": {"test_mcc": 48.97108449845412, "test_mcc_se": 1.1353413730579334, "test_macro_f1": 73.78017623787552, "test_macro_f1_se": 0.6138486293529201}}, "num_model_parameters": 167357954, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.581113338470459, "test_mcc": 0.4364261823794996, "test_macro_f1": 0.7119291846465254, "test_runtime": 3.9637, "test_samples_per_second": 516.688, "test_steps_per_second": 16.147}, {"test_loss": 0.5442367792129517, "test_mcc": 0.47581201180312455, "test_macro_f1": 0.7361446852450787, "test_runtime": 4.1387, "test_samples_per_second": 494.841, "test_steps_per_second": 15.464}, {"test_loss": 0.5611655712127686, "test_mcc": 0.5206200835942884, "test_macro_f1": 0.7601236097725153, "test_runtime": 4.0827, "test_samples_per_second": 501.634, "test_steps_per_second": 15.676}, {"test_loss": 0.6098158955574036, "test_mcc": 0.36904833549443067, "test_macro_f1": 0.6602309041706896, "test_runtime": 4.3107, "test_samples_per_second": 475.096, "test_steps_per_second": 14.847}, {"test_loss": 0.5749890804290771, "test_mcc": 0.423696415241668, "test_macro_f1": 0.7098248408290104, "test_runtime": 3.9956, "test_samples_per_second": 512.568, "test_steps_per_second": 16.018}, {"test_loss": 0.595301628112793, "test_mcc": 0.45648604255727565, "test_macro_f1": 0.7015039025318865, "test_runtime": 3.9354, "test_samples_per_second": 520.408, "test_steps_per_second": 16.263}, {"test_loss": 0.5639051198959351, "test_mcc": 0.4264720381694505, "test_macro_f1": 0.7131868223629039, "test_runtime": 3.858, "test_samples_per_second": 530.85, "test_steps_per_second": 16.589}, {"test_loss": 0.5127357244491577, "test_mcc": 0.5391342756135921, "test_macro_f1": 0.766764687195434, "test_runtime": 3.9134, "test_samples_per_second": 523.329, "test_steps_per_second": 16.354}, {"test_loss": 0.6086395978927612, "test_mcc": 0.4919820030443372, "test_macro_f1": 0.7440539349945414, "test_runtime": 3.9192, "test_samples_per_second": 522.549, "test_steps_per_second": 16.33}, {"test_loss": 0.5486863851547241, "test_mcc": 0.5352310491860464, "test_macro_f1": 0.7669337551398725, "test_runtime": 3.9775, "test_samples_per_second": 514.899, "test_steps_per_second": 16.091}]}, "total": {"test_mcc": 46.74908437083714, "test_mcc_se": 3.431762443136748, "test_macro_f1": 72.70696326888458, "test_macro_f1_se": 2.1138745881296495}}, "num_model_parameters": 167357954, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.5310078859329224, "test_mcc": 0.5019469105909483, "test_macro_f1": 0.740449903731325, "test_runtime": 3.5914, "test_samples_per_second": 570.248, "test_steps_per_second": 17.82}, {"test_loss": 0.5474364757537842, "test_mcc": 0.49222074867890336, "test_macro_f1": 0.7389871148217353, "test_runtime": 3.6057, "test_samples_per_second": 567.994, "test_steps_per_second": 17.75}, {"test_loss": 0.5539782643318176, "test_mcc": 0.48931365031098256, "test_macro_f1": 0.7327760400409176, "test_runtime": 3.5856, "test_samples_per_second": 571.173, "test_steps_per_second": 17.849}, {"test_loss": 0.559794545173645, "test_mcc": 0.4549021891200093, "test_macro_f1": 0.7228071999411654, "test_runtime": 3.692, "test_samples_per_second": 554.708, "test_steps_per_second": 17.335}, {"test_loss": 0.5429325699806213, "test_mcc": 0.5195458635681751, "test_macro_f1": 0.7479531172021493, "test_runtime": 3.6342, "test_samples_per_second": 563.54, "test_steps_per_second": 17.611}, {"test_loss": 0.5270131826400757, "test_mcc": 0.5351284524424159, "test_macro_f1": 0.7635645993017979, "test_runtime": 3.5118, "test_samples_per_second": 583.169, "test_steps_per_second": 18.224}, {"test_loss": 0.5458921194076538, "test_mcc": 0.49130557045555795, "test_macro_f1": 0.7414739438791242, "test_runtime": 3.5433, "test_samples_per_second": 577.995, "test_steps_per_second": 18.062}, {"test_loss": 0.5444141626358032, "test_mcc": 0.5032684970808237, "test_macro_f1": 0.7461866757149269, "test_runtime": 3.6069, "test_samples_per_second": 567.802, "test_steps_per_second": 17.744}, {"test_loss": 0.5674811005592346, "test_mcc": 0.4527084183683335, "test_macro_f1": 0.7136641091219097, "test_runtime": 3.5131, "test_samples_per_second": 582.968, "test_steps_per_second": 18.218}, {"test_loss": 0.5193613171577454, "test_mcc": 0.5001616826312142, "test_macro_f1": 0.7477521862298313, "test_runtime": 3.6117, "test_samples_per_second": 567.04, "test_steps_per_second": 17.72}]}, "total": {"test_mcc": 49.40501983247363, "test_mcc_se": 1.5730499466863723, "test_macro_f1": 73.95614889984883, "test_macro_f1_se": 0.8666827611044645}}, "num_model_parameters": 167357954, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_loss": 0.5675269365310669, "test_mcc": 0.4711530521566678, "test_macro_f1": 0.7352941176470589, "test_runtime": 3.6589, "test_samples_per_second": 559.736, "test_steps_per_second": 17.492}, {"test_loss": 0.6244928240776062, "test_mcc": 0.3912401415846817, "test_macro_f1": 0.656716955604568, "test_runtime": 3.7397, "test_samples_per_second": 547.637, "test_steps_per_second": 17.114}, {"test_loss": 0.6030393242835999, "test_mcc": 0.4374595474041549, "test_macro_f1": 0.7140751658069271, "test_runtime": 3.7996, "test_samples_per_second": 539.011, "test_steps_per_second": 16.844}, {"test_loss": 0.5937036275863647, "test_mcc": 0.37667032411254736, "test_macro_f1": 0.6808946877912395, "test_runtime": 3.5476, "test_samples_per_second": 577.292, "test_steps_per_second": 18.04}, {"test_loss": 0.5464135408401489, "test_mcc": 0.4601560373122045, "test_macro_f1": 0.7270935960591133, "test_runtime": 3.6073, "test_samples_per_second": 567.738, "test_steps_per_second": 17.742}, {"test_loss": 0.561616063117981, "test_mcc": 0.4396423382955955, "test_macro_f1": 0.7187653346470113, "test_runtime": 3.7186, "test_samples_per_second": 550.752, "test_steps_per_second": 17.211}, {"test_loss": 0.6103156208992004, "test_mcc": 0.41819732222314426, "test_macro_f1": 0.7089843750000001, "test_runtime": 3.6053, "test_samples_per_second": 568.056, "test_steps_per_second": 17.752}, {"test_loss": 0.5866260528564453, "test_mcc": 0.41345453528221315, "test_macro_f1": 0.7067189754366336, "test_runtime": 3.6685, "test_samples_per_second": 558.265, "test_steps_per_second": 17.446}, {"test_loss": 0.5480827689170837, "test_mcc": 0.4905217010635989, "test_macro_f1": 0.7426082442419581, "test_runtime": 3.6196, "test_samples_per_second": 565.802, "test_steps_per_second": 17.681}, {"test_loss": 0.5496178865432739, "test_mcc": 0.4592176247468916, "test_macro_f1": 0.7286514172120303, "test_runtime": 3.7177, "test_samples_per_second": 550.877, "test_steps_per_second": 17.215}]}, "total": {"test_mcc": 43.57712624181699, "test_mcc_se": 2.234217324737455, "test_macro_f1": 71.19802869446539, "test_macro_f1_se": 1.6130028245725871}}, "num_model_parameters": 167357954, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_em": 50.735863671572424, "test_f1": 55.049655823714254}, {"test_em": 48.372093023255815, "test_f1": 53.415926842415416}, {"test_em": 48.145285935085006, "test_f1": 52.58108649705257}, {"test_em": 48.20872274143302, "test_f1": 51.75159087191797}, {"test_em": 50.57915057915058, "test_f1": 54.15770244341672}, {"test_em": 50.424055512721665, "test_f1": 54.68469469150832}, {"test_em": 50.26575550493546, "test_f1": 54.86169114234234}, {"test_em": 48.56477889837083, "test_f1": 52.40674838276716}, {"test_em": 49.01960784313726, "test_f1": 53.12593627391279}, {"test_em": 47.36024844720497, "test_f1": 51.13425064675809}]}, "total": {"test_em": 49.1675562156867, "test_em_se": 0.7587045405377559, "test_f1": 53.316928361580565, "test_f1_se": 0.8416813810262049}}, "num_model_parameters": 166767362, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_em": 42.75755228505035, "test_f1": 46.97495513965455}, {"test_em": 51.55038759689923, "test_f1": 56.179180981914506}, {"test_em": 49.304482225656876, "test_f1": 54.04510635157668}, {"test_em": 45.87227414330218, "test_f1": 50.49879839343876}, {"test_em": 44.71042471042471, "test_f1": 49.40428163205694}, {"test_em": 46.954510408635315, "test_f1": 51.491994194241116}, {"test_em": 43.28018223234624, "test_f1": 47.687068040701526}, {"test_em": 46.702870442203256, "test_f1": 50.978046855716215}, {"test_em": 47.68627450980392, "test_f1": 52.86348821994294}, {"test_em": 42.77950310559006, "test_f1": 47.192753322838364}]}, "total": {"test_em": 46.15984616599121, "test_em_se": 1.7973356793508097, "test_f1": 50.73156731320817, "test_f1_se": 1.8885775878826694}}, "num_model_parameters": 166767362, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_em": 43.532145623547635, "test_f1": 48.05780946861252}, {"test_em": 47.286821705426355, "test_f1": 53.15862895984087}, {"test_em": 46.05873261205564, "test_f1": 51.44811147899945}, {"test_em": 43.613707165109034, "test_f1": 48.08429576108698}, {"test_em": 49.26640926640927, "test_f1": 53.72135919703366}, {"test_em": 44.94988434849653, "test_f1": 48.88962908468389}, {"test_em": 44.11541381928625, "test_f1": 48.09098523063542}, {"test_em": 48.79751745539178, "test_f1": 53.863022161084814}, {"test_em": 52.07843137254902, "test_f1": 55.999427933337934}, {"test_em": 42.46894409937888, "test_f1": 46.74035031566086}]}, "total": {"test_em": 46.21680074676504, "test_em_se": 1.9108146876742251, "test_f1": 50.80536195909764, "test_f1_se": 1.9955786064249252}}, "num_model_parameters": 166767362, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "bert-base-multilingual-uncased", "results": {"raw": {"test": [{"test_speed": 1.38}, {"test_speed": 1.34}, {"test_speed": 1.47}, {"test_speed": 1.38}, {"test_speed": 1.34}, {"test_speed": 1.3}, {"test_speed": 1.32}, {"test_speed": 1.33}, {"test_speed": 1.29}, {"test_speed": 1.29}]}, "total": {"test_speed": 1.3439999999999999, "test_speed_se": 0.03397333333333331}}, "num_model_parameters": 167356416, "max_sequence_length": 512, "vocabulary_size": 105879}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.6296008229255676, "test_mcc": 0.5727572800968692, "test_macro_f1": 0.5325663256697739, "test_runtime": 8.6756, "test_samples_per_second": 236.065, "test_steps_per_second": 29.508}, {"test_loss": 0.601911187171936, "test_mcc": 0.6165902087972088, "test_macro_f1": 0.6032707876930128, "test_runtime": 8.4303, "test_samples_per_second": 242.935, "test_steps_per_second": 30.367}, {"test_loss": 0.6548725366592407, "test_mcc": 0.5614000684447906, "test_macro_f1": 0.5437392063170535, "test_runtime": 8.6963, "test_samples_per_second": 235.502, "test_steps_per_second": 29.438}, {"test_loss": 0.6263829469680786, "test_mcc": 0.556381066850414, "test_macro_f1": 0.6063046412723789, "test_runtime": 8.4711, "test_samples_per_second": 241.764, "test_steps_per_second": 30.221}, {"test_loss": 0.5887050032615662, "test_mcc": 0.629854713027701, "test_macro_f1": 0.5931887681574296, "test_runtime": 8.3695, "test_samples_per_second": 244.697, "test_steps_per_second": 30.587}, {"test_loss": 0.5895234942436218, "test_mcc": 0.5879695504309509, "test_macro_f1": 0.6047590656037327, "test_runtime": 8.4515, "test_samples_per_second": 242.324, "test_steps_per_second": 30.291}, {"test_loss": 0.6333373785018921, "test_mcc": 0.6184103517079613, "test_macro_f1": 0.5837110410794194, "test_runtime": 8.2854, "test_samples_per_second": 247.181, "test_steps_per_second": 30.898}, {"test_loss": 0.6275988221168518, "test_mcc": 0.5909486324010194, "test_macro_f1": 0.5475664297905332, "test_runtime": 8.8729, "test_samples_per_second": 230.814, "test_steps_per_second": 28.852}, {"test_loss": 0.6386821269989014, "test_mcc": 0.5887679689375193, "test_macro_f1": 0.5413205887612729, "test_runtime": 8.9374, "test_samples_per_second": 229.15, "test_steps_per_second": 28.644}, {"test_loss": 0.5756620764732361, "test_mcc": 0.6300167455695619, "test_macro_f1": 0.6369859398265219, "test_runtime": 8.5642, "test_samples_per_second": 239.135, "test_steps_per_second": 29.892}]}, "total": {"test_mcc": 59.530965862639974, "test_mcc_se": 1.6878321733893233, "test_macro_f1": 57.93412794171129, "test_macro_f1_se": 2.2049473099665717}}, "num_model_parameters": 68913411, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 1.0432260036468506, "test_mcc": 0.34016454694448284, "test_macro_f1": 0.5598707013628955, "test_runtime": 2.5764, "test_samples_per_second": 794.906, "test_steps_per_second": 24.841}, {"test_loss": 0.9751532673835754, "test_mcc": 0.3528342987460559, "test_macro_f1": 0.5641344457299234, "test_runtime": 2.6113, "test_samples_per_second": 784.28, "test_steps_per_second": 24.509}, {"test_loss": 0.9911783933639526, "test_mcc": 0.3253988638089665, "test_macro_f1": 0.5471995070483497, "test_runtime": 2.6137, "test_samples_per_second": 783.569, "test_steps_per_second": 24.487}, {"test_loss": 1.0225461721420288, "test_mcc": 0.33729317820897886, "test_macro_f1": 0.5516188604282427, "test_runtime": 2.557, "test_samples_per_second": 800.946, "test_steps_per_second": 25.03}, {"test_loss": 0.9949048161506653, "test_mcc": 0.31398553010660274, "test_macro_f1": 0.5290944922975155, "test_runtime": 2.6004, "test_samples_per_second": 787.583, "test_steps_per_second": 24.612}, {"test_loss": 1.0401968955993652, "test_mcc": 0.30794349727959663, "test_macro_f1": 0.522318247559863, "test_runtime": 2.5743, "test_samples_per_second": 795.569, "test_steps_per_second": 24.862}, {"test_loss": 0.9803406000137329, "test_mcc": 0.336697053776755, "test_macro_f1": 0.5509183312291145, "test_runtime": 2.5693, "test_samples_per_second": 797.109, "test_steps_per_second": 24.91}, {"test_loss": 1.032248854637146, "test_mcc": 0.323482985754457, "test_macro_f1": 0.5385309563785589, "test_runtime": 2.5494, "test_samples_per_second": 803.317, "test_steps_per_second": 25.104}, {"test_loss": 1.027948021888733, "test_mcc": 0.324751146603698, "test_macro_f1": 0.5481536783496614, "test_runtime": 2.582, "test_samples_per_second": 793.188, "test_steps_per_second": 24.787}, {"test_loss": 1.033388376235962, "test_mcc": 0.332279301922656, "test_macro_f1": 0.5451977646266493, "test_runtime": 2.5381, "test_samples_per_second": 806.911, "test_steps_per_second": 25.216}]}, "total": {"test_mcc": 32.9483040315225, "test_mcc_se": 0.8158644718806267, "test_macro_f1": 54.570369850107724, "test_macro_f1_se": 0.7962273442647586}}, "num_model_parameters": 68913411, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.8850287199020386, "test_mcc": 0.3907378654820805, "test_macro_f1": 0.5290161564108431, "test_runtime": 2.0147, "test_samples_per_second": 1016.547, "test_steps_per_second": 31.767}, {"test_loss": 0.8916541337966919, "test_mcc": 0.3565167289902039, "test_macro_f1": 0.5326045496330952, "test_runtime": 1.9005, "test_samples_per_second": 1077.597, "test_steps_per_second": 33.675}, {"test_loss": 0.9257313013076782, "test_mcc": 0.3345616446490779, "test_macro_f1": 0.4647206770950501, "test_runtime": 1.9097, "test_samples_per_second": 1072.393, "test_steps_per_second": 33.512}, {"test_loss": 0.8901048898696899, "test_mcc": 0.320754980762772, "test_macro_f1": 0.42673289034723827, "test_runtime": 1.9672, "test_samples_per_second": 1041.064, "test_steps_per_second": 32.533}, {"test_loss": 0.9881107211112976, "test_mcc": 0.27835817025091425, "test_macro_f1": 0.46361600749922555, "test_runtime": 1.9638, "test_samples_per_second": 1042.854, "test_steps_per_second": 32.589}, {"test_loss": 1.0037899017333984, "test_mcc": 0.3351932885814727, "test_macro_f1": 0.5049154366238221, "test_runtime": 1.9906, "test_samples_per_second": 1028.841, "test_steps_per_second": 32.151}, {"test_loss": 0.8812891840934753, "test_mcc": 0.3224267389591733, "test_macro_f1": 0.4629523282310653, "test_runtime": 1.961, "test_samples_per_second": 1044.346, "test_steps_per_second": 32.636}, {"test_loss": 0.9238829612731934, "test_mcc": 0.2640653548432777, "test_macro_f1": 0.3977393791197285, "test_runtime": 1.9776, "test_samples_per_second": 1035.586, "test_steps_per_second": 32.362}, {"test_loss": 0.9212146997451782, "test_mcc": 0.33377519862714267, "test_macro_f1": 0.5043725114447097, "test_runtime": 1.9934, "test_samples_per_second": 1027.374, "test_steps_per_second": 32.105}, {"test_loss": 0.8969298005104065, "test_mcc": 0.29527438966821323, "test_macro_f1": 0.4248481672497113, "test_runtime": 1.9781, "test_samples_per_second": 1035.327, "test_steps_per_second": 32.354}]}, "total": {"test_mcc": 32.31664360814328, "test_mcc_se": 2.2960023090474353, "test_macro_f1": 47.1151810365449, "test_macro_f1_se": 2.850821428776447}}, "num_model_parameters": 68913411, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.06988340616226196, "test_micro_f1": 0.6115869017632241, "test_micro_f1_no_misc": 0.6839012925969447, "test_runtime": 5.0887, "test_samples_per_second": 402.457, "test_steps_per_second": 12.577}, {"test_loss": 0.07213917374610901, "test_micro_f1": 0.6241286863270777, "test_micro_f1_no_misc": 0.6911764705882353, "test_runtime": 4.5774, "test_samples_per_second": 447.42, "test_steps_per_second": 13.982}, {"test_loss": 0.06943459808826447, "test_micro_f1": 0.6266924564796905, "test_micro_f1_no_misc": 0.6673673147661587, "test_runtime": 4.6358, "test_samples_per_second": 441.782, "test_steps_per_second": 13.806}, {"test_loss": 0.0677485242486, "test_micro_f1": 0.6206244087038789, "test_micro_f1_no_misc": 0.6732467532467532, "test_runtime": 4.9482, "test_samples_per_second": 413.889, "test_steps_per_second": 12.934}, {"test_loss": 0.07501760125160217, "test_micro_f1": 0.6363636363636364, "test_micro_f1_no_misc": 0.6874059207225289, "test_runtime": 5.0571, "test_samples_per_second": 404.974, "test_steps_per_second": 12.655}, {"test_loss": 0.0667906180024147, "test_micro_f1": 0.6644736842105263, "test_micro_f1_no_misc": 0.7157120336311089, "test_runtime": 4.1371, "test_samples_per_second": 495.033, "test_steps_per_second": 15.47}, {"test_loss": 0.0717191994190216, "test_micro_f1": 0.6231599607458292, "test_micro_f1_no_misc": 0.6954570947840718, "test_runtime": 4.5475, "test_samples_per_second": 450.354, "test_steps_per_second": 14.074}, {"test_loss": 0.06414690613746643, "test_micro_f1": 0.6307857911733047, "test_micro_f1_no_misc": 0.6913123844731978, "test_runtime": 5.0707, "test_samples_per_second": 403.885, "test_steps_per_second": 12.621}, {"test_loss": 0.061667270958423615, "test_micro_f1": 0.6752258678078935, "test_micro_f1_no_misc": 0.7304159913560236, "test_runtime": 4.8783, "test_samples_per_second": 419.816, "test_steps_per_second": 13.119}, {"test_loss": 0.07145519554615021, "test_micro_f1": 0.6481751824817519, "test_micro_f1_no_misc": 0.6922257720979765, "test_runtime": 4.9421, "test_samples_per_second": 414.398, "test_steps_per_second": 12.95}]}, "total": {"test_micro_f1": 63.61216576056813, "test_micro_f1_se": 1.2651171872821292, "test_micro_f1_no_misc": 69.28221028262999, "test_micro_f1_no_misc_se": 1.1483793649642071}}, "num_model_parameters": 68327433, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.07356113195419312, "test_micro_f1": 0.760408483896308, "test_micro_f1_no_misc": 0.7778929188255612, "test_runtime": 5.7445, "test_samples_per_second": 356.517, "test_steps_per_second": 11.141}, {"test_loss": 0.07242616266012192, "test_micro_f1": 0.735906692585393, "test_micro_f1_no_misc": 0.7596119295724039, "test_runtime": 4.4176, "test_samples_per_second": 463.598, "test_steps_per_second": 14.487}, {"test_loss": 0.07346789538860321, "test_micro_f1": 0.7437450618909667, "test_micro_f1_no_misc": 0.7769936485532816, "test_runtime": 5.6407, "test_samples_per_second": 363.073, "test_steps_per_second": 11.346}, {"test_loss": 0.07584540545940399, "test_micro_f1": 0.7716001044113809, "test_micro_f1_no_misc": 0.8, "test_runtime": 5.3669, "test_samples_per_second": 381.598, "test_steps_per_second": 11.925}, {"test_loss": 0.07767470180988312, "test_micro_f1": 0.7512029436739316, "test_micro_f1_no_misc": 0.7804878048780488, "test_runtime": 5.6529, "test_samples_per_second": 362.295, "test_steps_per_second": 11.322}, {"test_loss": 0.07418546080589294, "test_micro_f1": 0.770546056260342, "test_micro_f1_no_misc": 0.7828020756115642, "test_runtime": 5.4599, "test_samples_per_second": 375.095, "test_steps_per_second": 11.722}, {"test_loss": 0.07583339512348175, "test_micro_f1": 0.7725573945541911, "test_micro_f1_no_misc": 0.7915641476274167, "test_runtime": 5.7436, "test_samples_per_second": 356.57, "test_steps_per_second": 11.143}, {"test_loss": 0.06783251464366913, "test_micro_f1": 0.7605711147721032, "test_micro_f1_no_misc": 0.7931163486719042, "test_runtime": 5.4284, "test_samples_per_second": 377.276, "test_steps_per_second": 11.79}, {"test_loss": 0.07041027396917343, "test_micro_f1": 0.7819589004536962, "test_micro_f1_no_misc": 0.8071481757259866, "test_runtime": 5.3614, "test_samples_per_second": 381.992, "test_steps_per_second": 11.937}, {"test_loss": 0.07400509715080261, "test_micro_f1": 0.7678619574009168, "test_micro_f1_no_misc": 0.7871953437613679, "test_runtime": 4.5978, "test_samples_per_second": 445.434, "test_steps_per_second": 13.92}]}, "total": {"test_micro_f1": 76.1635870989923, "test_micro_f1_se": 0.8870198980845744, "test_micro_f1_no_misc": 78.56812393227536, "test_micro_f1_no_misc_se": 0.8287400488743702}}, "num_model_parameters": 68327433, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.050691843032836914, "test_micro_f1": 0.8190612683625941, "test_micro_f1_no_misc": 0.8507042253521125, "test_runtime": 4.2509, "test_samples_per_second": 481.781, "test_steps_per_second": 15.056}, {"test_loss": 0.0468309111893177, "test_micro_f1": 0.7843567251461989, "test_micro_f1_no_misc": 0.8122199592668025, "test_runtime": 4.1605, "test_samples_per_second": 492.244, "test_steps_per_second": 15.383}, {"test_loss": 0.05039093643426895, "test_micro_f1": 0.7965034965034965, "test_micro_f1_no_misc": 0.8327457892675283, "test_runtime": 3.9367, "test_samples_per_second": 520.233, "test_steps_per_second": 16.257}, {"test_loss": 0.044883761554956436, "test_micro_f1": 0.7974727974727975, "test_micro_f1_no_misc": 0.8215120810600156, "test_runtime": 3.848, "test_samples_per_second": 532.22, "test_steps_per_second": 16.632}, {"test_loss": 0.047573164105415344, "test_micro_f1": 0.7982747179827472, "test_micro_f1_no_misc": 0.8271334792122539, "test_runtime": 4.2064, "test_samples_per_second": 486.88, "test_steps_per_second": 15.215}, {"test_loss": 0.03904074430465698, "test_micro_f1": 0.8212824010914052, "test_micro_f1_no_misc": 0.8569242540168325, "test_runtime": 4.1598, "test_samples_per_second": 492.334, "test_steps_per_second": 15.385}, {"test_loss": 0.04445885866880417, "test_micro_f1": 0.8153526970954358, "test_micro_f1_no_misc": 0.8395721925133689, "test_runtime": 3.8405, "test_samples_per_second": 533.257, "test_steps_per_second": 16.664}, {"test_loss": 0.04214515537023544, "test_micro_f1": 0.8298093587521664, "test_micro_f1_no_misc": 0.8554216867469879, "test_runtime": 3.9283, "test_samples_per_second": 521.34, "test_steps_per_second": 16.292}, {"test_loss": 0.04239786043763161, "test_micro_f1": 0.8278599783471672, "test_micro_f1_no_misc": 0.8520614389652386, "test_runtime": 3.9377, "test_samples_per_second": 520.095, "test_steps_per_second": 16.253}, {"test_loss": 0.04818269610404968, "test_micro_f1": 0.8113659705580281, "test_micro_f1_no_misc": 0.8442056792018419, "test_runtime": 4.0616, "test_samples_per_second": 504.239, "test_steps_per_second": 15.757}]}, "total": {"test_micro_f1": 81.01339411312037, "test_micro_f1_se": 0.9434442603673798, "test_micro_f1_no_misc": 83.92500785602982, "test_micro_f1_no_misc_se": 0.9531211327465285}}, "num_model_parameters": 68327433, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.06295685470104218, "test_micro_f1": 0.7456274930960417, "test_micro_f1_no_misc": 0.7848353841037579, "test_runtime": 3.9791, "test_samples_per_second": 514.684, "test_steps_per_second": 16.084}, {"test_loss": 0.06053133308887482, "test_micro_f1": 0.7753116448768622, "test_micro_f1_no_misc": 0.8145405587344329, "test_runtime": 4.0077, "test_samples_per_second": 511.021, "test_steps_per_second": 15.969}, {"test_loss": 0.06673888862133026, "test_micro_f1": 0.7385991058122204, "test_micro_f1_no_misc": 0.7788366743345383, "test_runtime": 4.024, "test_samples_per_second": 508.947, "test_steps_per_second": 15.905}, {"test_loss": 0.07494829595088959, "test_micro_f1": 0.7435265104808877, "test_micro_f1_no_misc": 0.7878787878787881, "test_runtime": 4.0808, "test_samples_per_second": 501.857, "test_steps_per_second": 15.683}, {"test_loss": 0.07573068141937256, "test_micro_f1": 0.7492410443230115, "test_micro_f1_no_misc": 0.7948360083740406, "test_runtime": 3.9353, "test_samples_per_second": 520.421, "test_steps_per_second": 16.263}, {"test_loss": 0.062318939715623856, "test_micro_f1": 0.7700180614087898, "test_micro_f1_no_misc": 0.8178717598908595, "test_runtime": 3.976, "test_samples_per_second": 515.086, "test_steps_per_second": 16.096}, {"test_loss": 0.06205650418996811, "test_micro_f1": 0.7320662170447578, "test_micro_f1_no_misc": 0.7810096957539284, "test_runtime": 4.0863, "test_samples_per_second": 501.192, "test_steps_per_second": 15.662}, {"test_loss": 0.06291846930980682, "test_micro_f1": 0.7307338041142155, "test_micro_f1_no_misc": 0.7722443559096944, "test_runtime": 3.9976, "test_samples_per_second": 512.308, "test_steps_per_second": 16.01}, {"test_loss": 0.07331448793411255, "test_micro_f1": 0.7484662576687117, "test_micro_f1_no_misc": 0.7916244511989193, "test_runtime": 3.7634, "test_samples_per_second": 544.183, "test_steps_per_second": 17.006}, {"test_loss": 0.05964464321732521, "test_micro_f1": 0.7737003058103975, "test_micro_f1_no_misc": 0.8157894736842105, "test_runtime": 3.8152, "test_samples_per_second": 536.803, "test_steps_per_second": 16.775}]}, "total": {"test_micro_f1": 75.07290444635896, "test_micro_f1_se": 1.0298100451010945, "test_micro_f1_no_misc": 79.39467149863171, "test_micro_f1_no_misc_se": 1.0260271472304179}}, "num_model_parameters": 68327433, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.6369044780731201, "test_mcc": 0.2790886174459414, "test_macro_f1": 0.6321704135382789, "test_runtime": 2.0472, "test_samples_per_second": 1000.374, "test_steps_per_second": 31.262}, {"test_loss": 0.6462407112121582, "test_mcc": 0.2527270875462927, "test_macro_f1": 0.6258609570981024, "test_runtime": 2.1588, "test_samples_per_second": 948.697, "test_steps_per_second": 29.647}, {"test_loss": 0.6539914608001709, "test_mcc": 0.2656506275366375, "test_macro_f1": 0.6298224304471052, "test_runtime": 2.1685, "test_samples_per_second": 944.447, "test_steps_per_second": 29.514}, {"test_loss": 0.6459029316902161, "test_mcc": 0.3024736925849772, "test_macro_f1": 0.647551220869458, "test_runtime": 2.1267, "test_samples_per_second": 962.973, "test_steps_per_second": 30.093}, {"test_loss": 0.6294134855270386, "test_mcc": 0.3066142920947231, "test_macro_f1": 0.6488008267788214, "test_runtime": 2.143, "test_samples_per_second": 955.67, "test_steps_per_second": 29.865}, {"test_loss": 0.6329787969589233, "test_mcc": 0.28146235720650997, "test_macro_f1": 0.6146437742568336, "test_runtime": 2.1094, "test_samples_per_second": 970.905, "test_steps_per_second": 30.341}, {"test_loss": 0.6393125653266907, "test_mcc": 0.3166955733353536, "test_macro_f1": 0.6541917905471849, "test_runtime": 2.1582, "test_samples_per_second": 948.946, "test_steps_per_second": 29.655}, {"test_loss": 0.64583820104599, "test_mcc": 0.3286762037054474, "test_macro_f1": 0.6472666954615005, "test_runtime": 2.1261, "test_samples_per_second": 963.28, "test_steps_per_second": 30.103}, {"test_loss": 0.6520727872848511, "test_mcc": 0.2893553798255673, "test_macro_f1": 0.6156378644131415, "test_runtime": 2.1249, "test_samples_per_second": 963.81, "test_steps_per_second": 30.119}, {"test_loss": 0.6602555513381958, "test_mcc": 0.3136032974294291, "test_macro_f1": 0.6439408653422982, "test_runtime": 2.1536, "test_samples_per_second": 950.968, "test_steps_per_second": 29.718}]}, "total": {"test_mcc": 29.363471287108794, "test_mcc_se": 1.4955000424558142, "test_macro_f1": 63.59886838752724, "test_macro_f1_se": 0.887322119938946}}, "num_model_parameters": 68912642, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.644611120223999, "test_mcc": 0.25753272328717725, "test_macro_f1": 0.6019166532928897, "test_runtime": 2.1635, "test_samples_per_second": 946.625, "test_steps_per_second": 29.582}, {"test_loss": 0.636342465877533, "test_mcc": 0.34804365949519633, "test_macro_f1": 0.6542515133731541, "test_runtime": 2.2552, "test_samples_per_second": 908.141, "test_steps_per_second": 28.379}, {"test_loss": 0.643325686454773, "test_mcc": 0.35095864385350206, "test_macro_f1": 0.660112325608636, "test_runtime": 2.2339, "test_samples_per_second": 916.778, "test_steps_per_second": 28.649}, {"test_loss": 0.6683884859085083, "test_mcc": 0.33519041307197944, "test_macro_f1": 0.6586084467718853, "test_runtime": 2.305, "test_samples_per_second": 888.521, "test_steps_per_second": 27.766}, {"test_loss": 0.5978584289550781, "test_mcc": 0.36750829478994695, "test_macro_f1": 0.6803526783619683, "test_runtime": 2.2367, "test_samples_per_second": 915.619, "test_steps_per_second": 28.613}, {"test_loss": 0.6045434474945068, "test_mcc": 0.3716772162282568, "test_macro_f1": 0.6766671800102086, "test_runtime": 2.1829, "test_samples_per_second": 938.212, "test_steps_per_second": 29.319}, {"test_loss": 0.6268441677093506, "test_mcc": 0.3081373425683316, "test_macro_f1": 0.6538065302761213, "test_runtime": 2.1065, "test_samples_per_second": 972.246, "test_steps_per_second": 30.383}, {"test_loss": 0.6062159538269043, "test_mcc": 0.37360307692140593, "test_macro_f1": 0.6865126747668185, "test_runtime": 2.153, "test_samples_per_second": 951.234, "test_steps_per_second": 29.726}, {"test_loss": 0.6532347202301025, "test_mcc": 0.37528363467907017, "test_macro_f1": 0.685467554072565, "test_runtime": 2.1747, "test_samples_per_second": 941.732, "test_steps_per_second": 29.429}, {"test_loss": 0.6365723013877869, "test_mcc": 0.27510293587925866, "test_macro_f1": 0.6116014882641243, "test_runtime": 2.2028, "test_samples_per_second": 929.745, "test_steps_per_second": 29.055}]}, "total": {"test_mcc": 33.63037940774125, "test_mcc_se": 2.632314672400464, "test_macro_f1": 65.69297044798373, "test_macro_f1_se": 1.8174791353510003}}, "num_model_parameters": 68912642, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.6258718371391296, "test_mcc": 0.3135694081859249, "test_macro_f1": 0.6551547153971276, "test_runtime": 1.9318, "test_samples_per_second": 1060.155, "test_steps_per_second": 33.13}, {"test_loss": 0.6134856343269348, "test_mcc": 0.4174685276844369, "test_macro_f1": 0.6873332087551587, "test_runtime": 1.9339, "test_samples_per_second": 1059.01, "test_steps_per_second": 33.094}, {"test_loss": 0.6190045475959778, "test_mcc": 0.34906345182487536, "test_macro_f1": 0.6631773327947371, "test_runtime": 1.9142, "test_samples_per_second": 1069.924, "test_steps_per_second": 33.435}, {"test_loss": 0.6085360050201416, "test_mcc": 0.32997163165605536, "test_macro_f1": 0.6647317955546647, "test_runtime": 1.9658, "test_samples_per_second": 1041.813, "test_steps_per_second": 32.557}, {"test_loss": 0.6184442043304443, "test_mcc": 0.33696969769114415, "test_macro_f1": 0.6440273109269669, "test_runtime": 1.9564, "test_samples_per_second": 1046.8, "test_steps_per_second": 32.713}, {"test_loss": 0.5795294046401978, "test_mcc": 0.3986606959149152, "test_macro_f1": 0.6873470943551806, "test_runtime": 1.8756, "test_samples_per_second": 1091.941, "test_steps_per_second": 34.123}, {"test_loss": 0.5973532795906067, "test_mcc": 0.3828608990493867, "test_macro_f1": 0.6879118265400034, "test_runtime": 1.8773, "test_samples_per_second": 1090.948, "test_steps_per_second": 34.092}, {"test_loss": 0.621962308883667, "test_mcc": 0.37443674615254474, "test_macro_f1": 0.6740169092223147, "test_runtime": 1.8907, "test_samples_per_second": 1083.215, "test_steps_per_second": 33.85}, {"test_loss": 0.6144572496414185, "test_mcc": 0.3507046856765326, "test_macro_f1": 0.6523310557376106, "test_runtime": 1.9219, "test_samples_per_second": 1065.624, "test_steps_per_second": 33.301}, {"test_loss": 0.6022278070449829, "test_mcc": 0.361527763001613, "test_macro_f1": 0.6412647716384542, "test_runtime": 1.9381, "test_samples_per_second": 1056.691, "test_steps_per_second": 33.022}]}, "total": {"test_mcc": 36.15233506837429, "test_mcc_se": 1.9925443562134146, "test_macro_f1": 66.57296020922217, "test_macro_f1_se": 1.105493028764428}}, "num_model_parameters": 68912642, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_loss": 0.668606162071228, "test_mcc": 0.32117847075904105, "test_macro_f1": 0.6586483538101114, "test_runtime": 2.042, "test_samples_per_second": 1002.938, "test_steps_per_second": 31.342}, {"test_loss": 0.6255916357040405, "test_mcc": 0.3266376032367139, "test_macro_f1": 0.6479678605735508, "test_runtime": 2.0742, "test_samples_per_second": 987.347, "test_steps_per_second": 30.855}, {"test_loss": 0.6560717821121216, "test_mcc": 0.2858874202593568, "test_macro_f1": 0.6411822563547296, "test_runtime": 2.0593, "test_samples_per_second": 994.524, "test_steps_per_second": 31.079}, {"test_loss": 0.6403900384902954, "test_mcc": 0.31904809105401133, "test_macro_f1": 0.6585607027468294, "test_runtime": 1.946, "test_samples_per_second": 1052.401, "test_steps_per_second": 32.888}, {"test_loss": 0.6404144763946533, "test_mcc": 0.28533661386733916, "test_macro_f1": 0.6426607866299499, "test_runtime": 1.9876, "test_samples_per_second": 1030.414, "test_steps_per_second": 32.2}, {"test_loss": 0.6664741039276123, "test_mcc": 0.23904106247839685, "test_macro_f1": 0.591678937813453, "test_runtime": 2.0691, "test_samples_per_second": 989.808, "test_steps_per_second": 30.932}, {"test_loss": 0.6428036689758301, "test_mcc": 0.2911215179082462, "test_macro_f1": 0.6185654508717067, "test_runtime": 2.0067, "test_samples_per_second": 1020.572, "test_steps_per_second": 31.893}, {"test_loss": 0.612391471862793, "test_mcc": 0.32053427219736275, "test_macro_f1": 0.6498113207547169, "test_runtime": 2.0109, "test_samples_per_second": 1018.463, "test_steps_per_second": 31.827}, {"test_loss": 0.6140881776809692, "test_mcc": 0.32882808349965137, "test_macro_f1": 0.6624667124796757, "test_runtime": 2.0138, "test_samples_per_second": 1016.977, "test_steps_per_second": 31.781}, {"test_loss": 0.6274934411048889, "test_mcc": 0.298962591022075, "test_macro_f1": 0.6261777438248026, "test_runtime": 2.039, "test_samples_per_second": 1004.401, "test_steps_per_second": 31.388}]}, "total": {"test_mcc": 30.165757262821945, "test_mcc_se": 1.723145343798827, "test_macro_f1": 63.977201258595265, "test_macro_f1_se": 1.3626566643861935}}, "num_model_parameters": 68912642, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_em": 36.56080557707204, "test_f1": 40.38416126475758}, {"test_em": 36.82170542635659, "test_f1": 40.856358707340256}, {"test_em": 42.8902627511592, "test_f1": 46.39764894035616}, {"test_em": 36.7601246105919, "test_f1": 40.32725177717004}, {"test_em": 42.7027027027027, "test_f1": 46.09824886892556}, {"test_em": 35.92906707787201, "test_f1": 39.72796159359208}, {"test_em": 35.45937737281701, "test_f1": 39.697414357844416}, {"test_em": 36.61753297129558, "test_f1": 40.800964789868125}, {"test_em": 37.333333333333336, "test_f1": 41.235450171857565}, {"test_em": 38.12111801242236, "test_f1": 41.7201735551001}]}, "total": {"test_em": 37.91960298356227, "test_em_se": 1.653801431315705, "test_f1": 41.724563402681184, "test_f1_se": 1.52742888611992}}, "num_model_parameters": 68322050, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_em": 33.61735089078234, "test_f1": 37.63540845026627}, {"test_em": 36.51162790697674, "test_f1": 40.856476741404464}, {"test_em": 38.871715610510044, "test_f1": 42.527831824077666}, {"test_em": 35.43613707165109, "test_f1": 39.50513726654575}, {"test_em": 39.22779922779923, "test_f1": 43.01349530319012}, {"test_em": 36.160370084811106, "test_f1": 40.819153163040255}, {"test_em": 35.535307517084284, "test_f1": 40.105308140245405}, {"test_em": 37.70364623739333, "test_f1": 41.80971520271432}, {"test_em": 39.529411764705884, "test_f1": 44.047877862170346}, {"test_em": 36.18012422360248, "test_f1": 40.92434773592591}]}, "total": {"test_em": 36.87734905353165, "test_em_se": 1.1842827991428915, "test_f1": 41.12447516895805, "test_f1_se": 1.1427411310814495}}, "num_model_parameters": 68322050, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_em": 40.43377226955848, "test_f1": 44.63516967517035}, {"test_em": 39.53488372093023, "test_f1": 44.86121192745843}, {"test_em": 41.88562596599691, "test_f1": 46.50914834165344}, {"test_em": 42.05607476635514, "test_f1": 45.97475115467563}, {"test_em": 41.38996138996139, "test_f1": 46.16153683463259}, {"test_em": 42.94525828835775, "test_f1": 47.37740581290101}, {"test_em": 40.09111617312073, "test_f1": 44.16812542066924}, {"test_em": 40.34134988363072, "test_f1": 44.922156974135234}, {"test_em": 45.09803921568628, "test_f1": 49.01595309050037}, {"test_em": 42.2360248447205, "test_f1": 46.7401743939696}]}, "total": {"test_em": 41.60121065183181, "test_em_se": 1.0178156820328508, "test_f1": 46.03656336257659, "test_f1_se": 0.91211470986753}}, "num_model_parameters": 68322050, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "Geotrend/distilbert-base-en-no-cased", "results": {"raw": {"test": [{"test_speed": 2.56}, {"test_speed": 2.83}, {"test_speed": 2.78}, {"test_speed": 2.86}, {"test_speed": 2.67}, {"test_speed": 2.85}, {"test_speed": 2.77}, {"test_speed": 2.56}, {"test_speed": 2.58}, {"test_speed": 2.57}]}, "total": {"test_speed": 2.7030000000000003, "test_speed_se": 0.07937663916067776}}, "num_model_parameters": 68911104, "max_sequence_length": 512, "vocabulary_size": 33071}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.7415179014205933, "test_mcc": 0.5276386828318305, "test_macro_f1": 0.514360219304595, "test_runtime": 2.0646, "test_samples_per_second": 991.971, "test_steps_per_second": 30.999}, {"test_loss": 0.6739099025726318, "test_mcc": 0.5649730997683773, "test_macro_f1": 0.5301462771806104, "test_runtime": 1.9815, "test_samples_per_second": 1033.541, "test_steps_per_second": 32.298}, {"test_loss": 0.7075062990188599, "test_mcc": 0.5154330187337004, "test_macro_f1": 0.5116802375741957, "test_runtime": 2.1154, "test_samples_per_second": 968.145, "test_steps_per_second": 30.255}, {"test_loss": 0.700143575668335, "test_mcc": 0.536345770080116, "test_macro_f1": 0.518562565657767, "test_runtime": 2.0268, "test_samples_per_second": 1010.484, "test_steps_per_second": 31.578}, {"test_loss": 0.6663820147514343, "test_mcc": 0.5776792230886318, "test_macro_f1": 0.536543389081216, "test_runtime": 1.9358, "test_samples_per_second": 1057.934, "test_steps_per_second": 33.06}, {"test_loss": 0.678130030632019, "test_mcc": 0.5661293739060755, "test_macro_f1": 0.5323365253077975, "test_runtime": 2.0679, "test_samples_per_second": 990.387, "test_steps_per_second": 30.95}, {"test_loss": 0.6227186322212219, "test_mcc": 0.5966734372253764, "test_macro_f1": 0.542967686871172, "test_runtime": 1.9358, "test_samples_per_second": 1057.946, "test_steps_per_second": 33.061}, {"test_loss": 0.6752990484237671, "test_mcc": 0.5499346410380489, "test_macro_f1": 0.5242202200725598, "test_runtime": 2.08, "test_samples_per_second": 984.636, "test_steps_per_second": 30.77}, {"test_loss": 0.6815239191055298, "test_mcc": 0.5640318617353194, "test_macro_f1": 0.5312953235119761, "test_runtime": 2.0554, "test_samples_per_second": 996.394, "test_steps_per_second": 31.137}, {"test_loss": 0.6091880202293396, "test_mcc": 0.6112542887693397, "test_macro_f1": 0.5500675706717356, "test_runtime": 2.0502, "test_samples_per_second": 998.938, "test_steps_per_second": 31.217}]}, "total": {"test_mcc": 56.100933971768164, "test_mcc_se": 1.853345795588233, "test_macro_f1": 52.92180015233626, "test_macro_f1_se": 0.7616770675388266}}, "num_model_parameters": 11549699, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.9965577125549316, "test_mcc": 0.26703337519567744, "test_macro_f1": 0.4954393521929061, "test_runtime": 0.9836, "test_samples_per_second": 2082.216, "test_steps_per_second": 65.069}, {"test_loss": 1.00179123878479, "test_mcc": 0.27663018367528763, "test_macro_f1": 0.49159391295405613, "test_runtime": 0.9285, "test_samples_per_second": 2205.811, "test_steps_per_second": 68.932}, {"test_loss": 1.0139999389648438, "test_mcc": 0.23849582088661542, "test_macro_f1": 0.4706976629219319, "test_runtime": 0.9098, "test_samples_per_second": 2251.152, "test_steps_per_second": 70.349}, {"test_loss": 1.0251177549362183, "test_mcc": 0.2587869599650447, "test_macro_f1": 0.4839172243675829, "test_runtime": 0.8922, "test_samples_per_second": 2295.569, "test_steps_per_second": 71.737}, {"test_loss": 0.9967712759971619, "test_mcc": 0.26982115609071133, "test_macro_f1": 0.4975086250697591, "test_runtime": 0.9086, "test_samples_per_second": 2254.133, "test_steps_per_second": 70.442}, {"test_loss": 1.0308383703231812, "test_mcc": 0.24185049835525516, "test_macro_f1": 0.47401430325827043, "test_runtime": 0.9513, "test_samples_per_second": 2152.864, "test_steps_per_second": 67.277}, {"test_loss": 0.9882400631904602, "test_mcc": 0.2588505102611218, "test_macro_f1": 0.44246732806338085, "test_runtime": 0.9301, "test_samples_per_second": 2201.878, "test_steps_per_second": 68.809}, {"test_loss": 0.9984641671180725, "test_mcc": 0.2794482511334264, "test_macro_f1": 0.5124677003077789, "test_runtime": 0.9319, "test_samples_per_second": 2197.751, "test_steps_per_second": 68.68}, {"test_loss": 1.0203752517700195, "test_mcc": 0.24416579746078212, "test_macro_f1": 0.4789877597464969, "test_runtime": 0.9071, "test_samples_per_second": 2257.647, "test_steps_per_second": 70.551}, {"test_loss": 1.0196764469146729, "test_mcc": 0.26752050745571376, "test_macro_f1": 0.4992946577891213, "test_runtime": 0.9682, "test_samples_per_second": 2115.374, "test_steps_per_second": 66.105}]}, "total": {"test_mcc": 26.026030604796357, "test_mcc_se": 0.901019929634782, "test_macro_f1": 48.46388526671285, "test_macro_f1_se": 1.2114045617327123}}, "num_model_parameters": 11549699, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.9647139310836792, "test_mcc": 0.2265048174080817, "test_macro_f1": 0.3896307851739185, "test_runtime": 0.8147, "test_samples_per_second": 2513.837, "test_steps_per_second": 78.557}, {"test_loss": 0.9376718997955322, "test_mcc": 0.23807331308206922, "test_macro_f1": 0.4009444469953558, "test_runtime": 0.7845, "test_samples_per_second": 2610.465, "test_steps_per_second": 81.577}, {"test_loss": 0.945642352104187, "test_mcc": 0.2601860779737201, "test_macro_f1": 0.4067487407002008, "test_runtime": 0.7435, "test_samples_per_second": 2754.482, "test_steps_per_second": 86.078}, {"test_loss": 0.968808650970459, "test_mcc": 0.2595119231199707, "test_macro_f1": 0.41072398101341623, "test_runtime": 0.7743, "test_samples_per_second": 2644.951, "test_steps_per_second": 82.655}, {"test_loss": 0.9578320980072021, "test_mcc": 0.21690726236690788, "test_macro_f1": 0.39044292153218213, "test_runtime": 0.8034, "test_samples_per_second": 2549.057, "test_steps_per_second": 79.658}, {"test_loss": 0.934886634349823, "test_mcc": 0.24088899529898367, "test_macro_f1": 0.39925317386421827, "test_runtime": 0.8086, "test_samples_per_second": 2532.676, "test_steps_per_second": 79.146}, {"test_loss": 0.9103623032569885, "test_mcc": 0.29956420077727997, "test_macro_f1": 0.44230318436283866, "test_runtime": 0.7631, "test_samples_per_second": 2683.692, "test_steps_per_second": 83.865}, {"test_loss": 0.9613649845123291, "test_mcc": 0.2520899160495911, "test_macro_f1": 0.4044604508470055, "test_runtime": 0.7834, "test_samples_per_second": 2614.236, "test_steps_per_second": 81.695}, {"test_loss": 0.9709311127662659, "test_mcc": 0.21234689423321104, "test_macro_f1": 0.38514272539736166, "test_runtime": 0.8062, "test_samples_per_second": 2540.36, "test_steps_per_second": 79.386}, {"test_loss": 0.9402145743370056, "test_mcc": 0.2526723399668022, "test_macro_f1": 0.4038819109613277, "test_runtime": 0.7925, "test_samples_per_second": 2584.327, "test_steps_per_second": 80.76}]}, "total": {"test_mcc": 24.587457402766177, "test_mcc_se": 1.5710358981656458, "test_macro_f1": 40.33532320847826, "test_macro_f1_se": 0.9894665023956701}}, "num_model_parameters": 11549699, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.10237324237823486, "test_micro_f1": 0.506801007556675, "test_micro_f1_no_misc": 0.5443592552026286, "test_runtime": 2.3596, "test_samples_per_second": 867.926, "test_steps_per_second": 27.123}, {"test_loss": 0.10732226073741913, "test_micro_f1": 0.38505747126436785, "test_micro_f1_no_misc": 0.40750126710593, "test_runtime": 2.2549, "test_samples_per_second": 908.242, "test_steps_per_second": 28.383}, {"test_loss": 0.08879347890615463, "test_micro_f1": 0.5095354523227383, "test_micro_f1_no_misc": 0.5504587155963302, "test_runtime": 2.218, "test_samples_per_second": 923.339, "test_steps_per_second": 28.854}, {"test_loss": 0.10723346471786499, "test_micro_f1": 0.4551341350601295, "test_micro_f1_no_misc": 0.4821073558648111, "test_runtime": 2.3883, "test_samples_per_second": 857.509, "test_steps_per_second": 26.797}, {"test_loss": 0.10356485098600388, "test_micro_f1": 0.5197997269003186, "test_micro_f1_no_misc": 0.5518590998043053, "test_runtime": 2.3811, "test_samples_per_second": 860.11, "test_steps_per_second": 26.878}, {"test_loss": 0.10483255982398987, "test_micro_f1": 0.47968197879858665, "test_micro_f1_no_misc": 0.5163814180929096, "test_runtime": 2.1366, "test_samples_per_second": 958.549, "test_steps_per_second": 29.955}, {"test_loss": 0.11811388283967972, "test_micro_f1": 0.3394047090182141, "test_micro_f1_no_misc": 0.35969868173258, "test_runtime": 2.2318, "test_samples_per_second": 917.628, "test_steps_per_second": 28.676}, {"test_loss": 0.09361182153224945, "test_micro_f1": 0.5278688524590164, "test_micro_f1_no_misc": 0.5574148874783613, "test_runtime": 2.3253, "test_samples_per_second": 880.731, "test_steps_per_second": 27.523}, {"test_loss": 0.10065660625696182, "test_micro_f1": 0.48022079116835326, "test_micro_f1_no_misc": 0.5086294416243654, "test_runtime": 2.2781, "test_samples_per_second": 899.001, "test_steps_per_second": 28.094}, {"test_loss": 0.10284213721752167, "test_micro_f1": 0.5, "test_micro_f1_no_misc": 0.5283018867924528, "test_runtime": 2.3342, "test_samples_per_second": 877.399, "test_steps_per_second": 27.419}]}, "total": {"test_micro_f1": 47.035041245484, "test_micro_f1_se": 3.828250002704845, "test_micro_f1_no_misc": 50.06712009294674, "test_micro_f1_no_misc_se": 4.142339069371447}}, "num_model_parameters": 11485449, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.13391399383544922, "test_micro_f1": 0.5507394186639469, "test_micro_f1_no_misc": 0.5678688524590164, "test_runtime": 2.9356, "test_samples_per_second": 697.638, "test_steps_per_second": 21.801}, {"test_loss": 0.12812376022338867, "test_micro_f1": 0.5409836065573771, "test_micro_f1_no_misc": 0.5538994800693241, "test_runtime": 2.5554, "test_samples_per_second": 801.435, "test_steps_per_second": 25.045}, {"test_loss": 0.13109612464904785, "test_micro_f1": 0.5715775749674055, "test_micro_f1_no_misc": 0.5872311369067941, "test_runtime": 2.8095, "test_samples_per_second": 728.954, "test_steps_per_second": 22.78}, {"test_loss": 0.1313968300819397, "test_micro_f1": 0.5593520627689194, "test_micro_f1_no_misc": 0.5799863852961198, "test_runtime": 2.9393, "test_samples_per_second": 696.756, "test_steps_per_second": 21.774}, {"test_loss": 0.14140364527702332, "test_micro_f1": 0.49124788255223034, "test_micro_f1_no_misc": 0.5211630474788369, "test_runtime": 2.9986, "test_samples_per_second": 682.985, "test_steps_per_second": 21.343}, {"test_loss": 0.13751262426376343, "test_micro_f1": 0.5380212591986917, "test_micro_f1_no_misc": 0.5473309608540926, "test_runtime": 2.9461, "test_samples_per_second": 695.156, "test_steps_per_second": 21.724}, {"test_loss": 0.13422107696533203, "test_micro_f1": 0.5423818325851597, "test_micro_f1_no_misc": 0.5480378890392422, "test_runtime": 3.1423, "test_samples_per_second": 651.747, "test_steps_per_second": 20.367}, {"test_loss": 0.12343103438615799, "test_micro_f1": 0.5466995343741441, "test_micro_f1_no_misc": 0.5707196029776674, "test_runtime": 2.9521, "test_samples_per_second": 693.739, "test_steps_per_second": 21.679}, {"test_loss": 0.12705133855342865, "test_micro_f1": 0.5745625489683991, "test_micro_f1_no_misc": 0.5868512110726644, "test_runtime": 2.8427, "test_samples_per_second": 720.433, "test_steps_per_second": 22.514}, {"test_loss": 0.1286904513835907, "test_micro_f1": 0.5892761394101876, "test_micro_f1_no_misc": 0.6062085803976283, "test_runtime": 2.5641, "test_samples_per_second": 798.736, "test_steps_per_second": 24.96}]}, "total": {"test_micro_f1": 55.04841860046461, "test_micro_f1_se": 1.6583236562989556, "test_micro_f1_no_misc": 56.69297146551385, "test_micro_f1_no_misc_se": 1.5381736796308763}}, "num_model_parameters": 11485449, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.10066180676221848, "test_micro_f1": 0.5850533807829182, "test_micro_f1_no_misc": 0.6227134146341462, "test_runtime": 2.4228, "test_samples_per_second": 845.308, "test_steps_per_second": 26.416}, {"test_loss": 0.09124217927455902, "test_micro_f1": 0.5865039483129936, "test_micro_f1_no_misc": 0.6228373702422145, "test_runtime": 2.3901, "test_samples_per_second": 856.879, "test_steps_per_second": 26.777}, {"test_loss": 0.10150527209043503, "test_micro_f1": 0.5877163216830675, "test_micro_f1_no_misc": 0.624681470695304, "test_runtime": 2.2685, "test_samples_per_second": 902.788, "test_steps_per_second": 28.212}, {"test_loss": 0.09105637669563293, "test_micro_f1": 0.5972789115646259, "test_micro_f1_no_misc": 0.6313481914504933, "test_runtime": 2.3379, "test_samples_per_second": 876.003, "test_steps_per_second": 27.375}, {"test_loss": 0.09136423468589783, "test_micro_f1": 0.627741935483871, "test_micro_f1_no_misc": 0.6588818117480538, "test_runtime": 2.4351, "test_samples_per_second": 841.05, "test_steps_per_second": 26.283}, {"test_loss": 0.10017190128564835, "test_micro_f1": 0.581151832460733, "test_micro_f1_no_misc": 0.6137787056367432, "test_runtime": 2.4452, "test_samples_per_second": 837.563, "test_steps_per_second": 26.174}, {"test_loss": 0.1096438467502594, "test_micro_f1": 0.5324459234608986, "test_micro_f1_no_misc": 0.5607608312786192, "test_runtime": 2.3801, "test_samples_per_second": 860.484, "test_steps_per_second": 26.89}, {"test_loss": 0.09359768033027649, "test_micro_f1": 0.5803421670580342, "test_micro_f1_no_misc": 0.6099290780141844, "test_runtime": 2.3381, "test_samples_per_second": 875.93, "test_steps_per_second": 27.373}, {"test_loss": 0.08955143392086029, "test_micro_f1": 0.5779017079121646, "test_micro_f1_no_misc": 0.6110904354298474, "test_runtime": 2.3285, "test_samples_per_second": 879.527, "test_steps_per_second": 27.485}, {"test_loss": 0.10887415707111359, "test_micro_f1": 0.5680395387149918, "test_micro_f1_no_misc": 0.5986013986013986, "test_runtime": 2.3579, "test_samples_per_second": 868.579, "test_steps_per_second": 27.143}]}, "total": {"test_micro_f1": 58.24175667434297, "test_micro_f1_se": 1.4692123010215856, "test_micro_f1_no_misc": 61.54622707731004, "test_micro_f1_no_misc_se": 1.5541485714623267}}, "num_model_parameters": 11485449, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.10389856994152069, "test_micro_f1": 0.5640253088279602, "test_micro_f1_no_misc": 0.5998077539250241, "test_runtime": 2.4433, "test_samples_per_second": 838.218, "test_steps_per_second": 26.194}, {"test_loss": 0.10540354996919632, "test_micro_f1": 0.5751556477912838, "test_micro_f1_no_misc": 0.6160203432930706, "test_runtime": 2.483, "test_samples_per_second": 824.794, "test_steps_per_second": 25.775}, {"test_loss": 0.12001168727874756, "test_micro_f1": 0.5190023752969122, "test_micro_f1_no_misc": 0.5531645569620253, "test_runtime": 2.4111, "test_samples_per_second": 849.414, "test_steps_per_second": 26.544}, {"test_loss": 0.11726357787847519, "test_micro_f1": 0.5615271659324522, "test_micro_f1_no_misc": 0.602015113350126, "test_runtime": 2.4848, "test_samples_per_second": 824.198, "test_steps_per_second": 25.756}, {"test_loss": 0.12012699991464615, "test_micro_f1": 0.5368731563421829, "test_micro_f1_no_misc": 0.5861513687600645, "test_runtime": 2.2568, "test_samples_per_second": 907.498, "test_steps_per_second": 28.359}, {"test_loss": 0.1229093074798584, "test_micro_f1": 0.5543093270365996, "test_micro_f1_no_misc": 0.5916824196597352, "test_runtime": 2.2135, "test_samples_per_second": 925.236, "test_steps_per_second": 28.914}, {"test_loss": 0.09697708487510681, "test_micro_f1": 0.5909499550494455, "test_micro_f1_no_misc": 0.6378413524057218, "test_runtime": 2.4471, "test_samples_per_second": 836.907, "test_steps_per_second": 26.153}, {"test_loss": 0.10930907726287842, "test_micro_f1": 0.574436090225564, "test_micro_f1_no_misc": 0.6093350383631713, "test_runtime": 2.5724, "test_samples_per_second": 796.148, "test_steps_per_second": 24.88}, {"test_loss": 0.11160348355770111, "test_micro_f1": 0.5855143031040778, "test_micro_f1_no_misc": 0.6236910994764399, "test_runtime": 2.3699, "test_samples_per_second": 864.164, "test_steps_per_second": 27.005}, {"test_loss": 0.12005600333213806, "test_micro_f1": 0.540751879699248, "test_micro_f1_no_misc": 0.5702505550269584, "test_runtime": 2.416, "test_samples_per_second": 847.681, "test_steps_per_second": 26.49}]}, "total": {"test_micro_f1": 56.02545209305726, "test_micro_f1_se": 1.4138880996933552, "test_micro_f1_no_misc": 59.89959601222337, "test_micro_f1_no_misc_se": 1.5557843686680626}}, "num_model_parameters": 11485449, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6882063150405884, "test_mcc": 0.08805559768498852, "test_macro_f1": 0.543877458360217, "test_runtime": 0.688, "test_samples_per_second": 2976.577, "test_steps_per_second": 93.018}, {"test_loss": 0.6870782375335693, "test_mcc": 0.103263272692132, "test_macro_f1": 0.5388585262326542, "test_runtime": 0.7287, "test_samples_per_second": 2810.61, "test_steps_per_second": 87.832}, {"test_loss": 0.6849410533905029, "test_mcc": 0.09385683508579953, "test_macro_f1": 0.5404629791873528, "test_runtime": 1.49, "test_samples_per_second": 1374.498, "test_steps_per_second": 42.953}, {"test_loss": 0.6914747953414917, "test_mcc": 0.04473169926329961, "test_macro_f1": 0.5069301085286049, "test_runtime": 1.4712, "test_samples_per_second": 1392.058, "test_steps_per_second": 43.502}, {"test_loss": 0.6923654079437256, "test_mcc": 0.030387350704938726, "test_macro_f1": 0.5004183348574228, "test_runtime": 1.496, "test_samples_per_second": 1368.94, "test_steps_per_second": 42.779}, {"test_loss": 0.692407488822937, "test_mcc": 0.07614710062390646, "test_macro_f1": 0.504149950460474, "test_runtime": 1.4811, "test_samples_per_second": 1382.788, "test_steps_per_second": 43.212}, {"test_loss": 0.6935364007949829, "test_mcc": 0.014991613249569345, "test_macro_f1": 0.5055984178628755, "test_runtime": 1.2384, "test_samples_per_second": 1653.71, "test_steps_per_second": 51.678}, {"test_loss": 0.6923360824584961, "test_mcc": 0.03224153644725171, "test_macro_f1": 0.5079581669991933, "test_runtime": 1.4828, "test_samples_per_second": 1381.15, "test_steps_per_second": 43.161}, {"test_loss": 0.6931043863296509, "test_mcc": 0.018555281417897706, "test_macro_f1": 0.47621866117163925, "test_runtime": 1.0559, "test_samples_per_second": 1939.631, "test_steps_per_second": 60.613}, {"test_loss": 0.6923031806945801, "test_mcc": 0.0027734586870655, "test_macro_f1": 0.48402629286449667, "test_runtime": 0.7131, "test_samples_per_second": 2871.911, "test_steps_per_second": 89.747}]}, "total": {"test_mcc": 5.050037458568492, "test_mcc_se": 2.2690776975111215, "test_macro_f1": 51.08498896524931, "test_macro_f1_se": 1.4426803705942328}}, "num_model_parameters": 11549442, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6903800368309021, "test_mcc": 0.07582905178781654, "test_macro_f1": 0.5355274261603375, "test_runtime": 1.5875, "test_samples_per_second": 1290.096, "test_steps_per_second": 40.316}, {"test_loss": 0.6932109594345093, "test_mcc": -0.004016983820141676, "test_macro_f1": 0.49795303229744936, "test_runtime": 1.2042, "test_samples_per_second": 1700.695, "test_steps_per_second": 53.147}, {"test_loss": 0.6922320127487183, "test_mcc": 0.035526680261831076, "test_macro_f1": 0.49811786163370414, "test_runtime": 1.5888, "test_samples_per_second": 1288.997, "test_steps_per_second": 40.281}, {"test_loss": 0.6928938627243042, "test_mcc": 0.007515497701718811, "test_macro_f1": 0.5021092305820386, "test_runtime": 1.5731, "test_samples_per_second": 1301.915, "test_steps_per_second": 40.685}, {"test_loss": 0.6929773688316345, "test_mcc": -0.004319647172355303, "test_macro_f1": 0.4605241360008314, "test_runtime": 1.5807, "test_samples_per_second": 1295.659, "test_steps_per_second": 40.489}, {"test_loss": 0.6915575861930847, "test_mcc": 0.05282997934752287, "test_macro_f1": 0.5214832122279651, "test_runtime": 1.5781, "test_samples_per_second": 1297.752, "test_steps_per_second": 40.555}, {"test_loss": 0.6929798126220703, "test_mcc": 0.022545377345957577, "test_macro_f1": 0.5111145061492628, "test_runtime": 1.5765, "test_samples_per_second": 1299.07, "test_steps_per_second": 40.596}, {"test_loss": 0.6922299265861511, "test_mcc": 0.039909189900972857, "test_macro_f1": 0.47416331994645244, "test_runtime": 1.575, "test_samples_per_second": 1300.288, "test_steps_per_second": 40.634}, {"test_loss": 0.6935675144195557, "test_mcc": -0.030400572439524272, "test_macro_f1": 0.47886337416576785, "test_runtime": 0.8193, "test_samples_per_second": 2499.605, "test_steps_per_second": 78.113}, {"test_loss": 0.6928609609603882, "test_mcc": 0.02332300685545813, "test_macro_f1": 0.5005691755587138, "test_runtime": 1.5699, "test_samples_per_second": 1304.571, "test_steps_per_second": 40.768}]}, "total": {"test_mcc": 2.1874157976925663, "test_mcc_se": 1.924716240933877, "test_macro_f1": 49.80425274722523, "test_macro_f1_se": 1.3850176410801704}}, "num_model_parameters": 11549442, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.692196249961853, "test_mcc": 0.03600369402295643, "test_macro_f1": 0.5151141080438841, "test_runtime": 1.5091, "test_samples_per_second": 1357.134, "test_steps_per_second": 42.41}, {"test_loss": 0.6925387382507324, "test_mcc": 0.04861324591442823, "test_macro_f1": 0.5031381289571786, "test_runtime": 1.5296, "test_samples_per_second": 1338.895, "test_steps_per_second": 41.84}, {"test_loss": 0.6927480101585388, "test_mcc": -0.028613551389394656, "test_macro_f1": 0.47772495338772225, "test_runtime": 1.5211, "test_samples_per_second": 1346.372, "test_steps_per_second": 42.074}, {"test_loss": 0.6940613985061646, "test_mcc": 0.034509217506624675, "test_macro_f1": 0.5078552004867456, "test_runtime": 1.5027, "test_samples_per_second": 1362.916, "test_steps_per_second": 42.591}, {"test_loss": 0.6924540400505066, "test_mcc": 0.03412737724749044, "test_macro_f1": 0.514235110578693, "test_runtime": 0.7176, "test_samples_per_second": 2853.973, "test_steps_per_second": 89.187}, {"test_loss": 0.6913284659385681, "test_mcc": 0.0629241212988857, "test_macro_f1": 0.5079929282313661, "test_runtime": 0.771, "test_samples_per_second": 2656.187, "test_steps_per_second": 83.006}, {"test_loss": 0.6908222436904907, "test_mcc": 0.08207088514423186, "test_macro_f1": 0.5394913319377914, "test_runtime": 1.6882, "test_samples_per_second": 1213.106, "test_steps_per_second": 37.91}, {"test_loss": 0.6923397779464722, "test_mcc": 0.06835431046967287, "test_macro_f1": 0.5300507212091223, "test_runtime": 1.6963, "test_samples_per_second": 1207.346, "test_steps_per_second": 37.73}, {"test_loss": 0.6940163373947144, "test_mcc": 0.004556430702698406, "test_macro_f1": 0.5005215719631959, "test_runtime": 1.5288, "test_samples_per_second": 1339.612, "test_steps_per_second": 41.863}, {"test_loss": 0.6954394578933716, "test_mcc": 0.002876574693708254, "test_macro_f1": 0.48340423049269954, "test_runtime": 1.6763, "test_samples_per_second": 1221.706, "test_steps_per_second": 38.178}]}, "total": {"test_mcc": 3.454223056113022, "test_mcc_se": 2.0966380546043104, "test_macro_f1": 50.79528285288399, "test_macro_f1_se": 1.16295520816819}}, "num_model_parameters": 11549442, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_loss": 0.6941943168640137, "test_mcc": -0.002008873365037911, "test_macro_f1": 0.49679389312977096, "test_runtime": 1.7297, "test_samples_per_second": 1184.007, "test_steps_per_second": 37.0}, {"test_loss": 0.6939775943756104, "test_mcc": 0.029910112005358317, "test_macro_f1": 0.45115730032382073, "test_runtime": 1.7639, "test_samples_per_second": 1161.083, "test_steps_per_second": 36.284}, {"test_loss": 0.6916323304176331, "test_mcc": 0.051756028547408, "test_macro_f1": 0.5258778888943196, "test_runtime": 1.7781, "test_samples_per_second": 1151.782, "test_steps_per_second": 35.993}, {"test_loss": 0.6931722164154053, "test_mcc": 0.023489525882442117, "test_macro_f1": 0.5028736982225355, "test_runtime": 1.6944, "test_samples_per_second": 1208.713, "test_steps_per_second": 37.772}, {"test_loss": 0.6916694641113281, "test_mcc": 0.05248893282646973, "test_macro_f1": 0.5245839491637232, "test_runtime": 1.7527, "test_samples_per_second": 1168.468, "test_steps_per_second": 36.515}, {"test_loss": 0.6916199326515198, "test_mcc": 0.04994063113222905, "test_macro_f1": 0.48743167109975494, "test_runtime": 1.7294, "test_samples_per_second": 1184.217, "test_steps_per_second": 37.007}, {"test_loss": 0.6945496201515198, "test_mcc": 0.032122419164754404, "test_macro_f1": 0.44960738498027597, "test_runtime": 1.7454, "test_samples_per_second": 1173.386, "test_steps_per_second": 36.668}, {"test_loss": 0.6918243765830994, "test_mcc": 0.03061048538949522, "test_macro_f1": 0.4423814956954673, "test_runtime": 1.7242, "test_samples_per_second": 1187.812, "test_steps_per_second": 37.119}, {"test_loss": 0.6947650909423828, "test_mcc": -0.02754655513755546, "test_macro_f1": 0.484274588512464, "test_runtime": 1.7075, "test_samples_per_second": 1199.412, "test_steps_per_second": 37.482}, {"test_loss": 0.692441463470459, "test_mcc": 0.03140451795477363, "test_macro_f1": 0.5138691081722617, "test_runtime": 1.6914, "test_samples_per_second": 1210.828, "test_steps_per_second": 37.838}]}, "total": {"test_mcc": 2.721672244003371, "test_mcc_se": 1.557711316272625, "test_macro_f1": 48.78850978194394, "test_macro_f1_se": 1.9234409646708515}}, "num_model_parameters": 11549442, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 25.25174283501162, "test_f1": 31.524844894325934}, {"test_em": 23.023255813953487, "test_f1": 28.788411707358375}, {"test_em": 18.778979907264297, "test_f1": 25.23939349245839}, {"test_em": 22.819314641744548, "test_f1": 30.289475803675355}, {"test_em": 19.69111969111969, "test_f1": 25.581958367672666}, {"test_em": 22.8218966846569, "test_f1": 28.59640956198624}, {"test_em": 20.50113895216401, "test_f1": 27.204977207992087}, {"test_em": 26.299456943366952, "test_f1": 32.36106683505132}, {"test_em": 20.862745098039216, "test_f1": 26.828472322243968}, {"test_em": 21.506211180124225, "test_f1": 27.11666550678245}]}, "total": {"test_em": 22.155586174744496, "test_em_se": 1.4710970928742646, "test_f1": 28.353167569954678, "test_f1_se": 1.499365849455357}}, "num_model_parameters": 11483650, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 23.78001549186677, "test_f1": 30.71626238587884}, {"test_em": 20.62015503875969, "test_f1": 27.616537326109675}, {"test_em": 22.48840803709428, "test_f1": 30.157131302414857}, {"test_em": 23.909657320872274, "test_f1": 30.92252761408389}, {"test_em": 24.092664092664094, "test_f1": 30.802387976647182}, {"test_em": 24.67232074016962, "test_f1": 32.08406883913115}, {"test_em": 25.588458618071375, "test_f1": 32.97219555142857}, {"test_em": 23.81691233514352, "test_f1": 30.669716134498813}, {"test_em": 26.03921568627451, "test_f1": 33.2715181935907}, {"test_em": 16.38198757763975, "test_f1": 24.412032735008108}]}, "total": {"test_em": 23.13897949385559, "test_em_se": 1.7477257911887796, "test_f1": 30.362437805879175, "test_f1_se": 1.6261820611273814}}, "num_model_parameters": 11483650, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_em": 20.604182804027886, "test_f1": 28.774842264788}, {"test_em": 20.62015503875969, "test_f1": 28.415181517679763}, {"test_em": 22.642967542503865, "test_f1": 30.450074997324528}, {"test_em": 23.98753894080997, "test_f1": 31.40892358853467}, {"test_em": 20.463320463320464, "test_f1": 27.72476016435982}, {"test_em": 18.581341557440247, "test_f1": 24.887090344152508}, {"test_em": 24.06985573272589, "test_f1": 31.409373401217376}, {"test_em": 22.498060512024825, "test_f1": 29.40217944397754}, {"test_em": 22.431372549019606, "test_f1": 29.656943690314552}, {"test_em": 20.652173913043477, "test_f1": 27.886900957574593}]}, "total": {"test_em": 21.655096905367593, "test_em_se": 1.0855975993810538, "test_f1": 29.001627036992335, "test_f1_se": 1.2131252654677243}}, "num_model_parameters": 11483650, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "dbmdz/bert-mini-historic-multilingual-cased", "results": {"raw": {"test": [{"test_speed": 20.77}, {"test_speed": 20.63}, {"test_speed": 21.05}, {"test_speed": 21.19}, {"test_speed": 20.71}, {"test_speed": 21.09}, {"test_speed": 21.46}, {"test_speed": 21.41}, {"test_speed": 21.57}, {"test_speed": 21.13}]}, "total": {"test_speed": 21.101, "test_speed_se": 0.20031779595876606}}, "num_model_parameters": 11548928, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.6709308624267578, "test_mcc": 0.559896477057958, "test_macro_f1": 0.5300793442431667, "test_runtime": 2.8496, "test_samples_per_second": 718.688, "test_steps_per_second": 22.459}, {"test_loss": 0.7164244651794434, "test_mcc": 0.4985444087612308, "test_macro_f1": 0.5052145439820884, "test_runtime": 2.8172, "test_samples_per_second": 726.956, "test_steps_per_second": 22.717}, {"test_loss": 0.7096316814422607, "test_mcc": 0.5119696575415622, "test_macro_f1": 0.5116118452289645, "test_runtime": 2.9494, "test_samples_per_second": 694.374, "test_steps_per_second": 21.699}, {"test_loss": 0.6879781484603882, "test_mcc": 0.5410424537799371, "test_macro_f1": 0.5225291679501105, "test_runtime": 2.8716, "test_samples_per_second": 713.184, "test_steps_per_second": 22.287}, {"test_loss": 0.7066825032234192, "test_mcc": 0.5088534775889724, "test_macro_f1": 0.5092896334347713, "test_runtime": 2.8226, "test_samples_per_second": 725.581, "test_steps_per_second": 22.674}, {"test_loss": 0.7282177209854126, "test_mcc": 0.5027203319159339, "test_macro_f1": 0.5065874848784779, "test_runtime": 2.8962, "test_samples_per_second": 707.133, "test_steps_per_second": 22.098}, {"test_loss": 0.6896346211433411, "test_mcc": 0.5426296375352716, "test_macro_f1": 0.5225984534856571, "test_runtime": 2.8143, "test_samples_per_second": 727.719, "test_steps_per_second": 22.741}, {"test_loss": 0.700527548789978, "test_mcc": 0.5292735183571804, "test_macro_f1": 0.5163865391964152, "test_runtime": 2.8728, "test_samples_per_second": 712.904, "test_steps_per_second": 22.278}, {"test_loss": 0.6969815492630005, "test_mcc": 0.5151143002499108, "test_macro_f1": 0.5122126311125105, "test_runtime": 2.8982, "test_samples_per_second": 706.652, "test_steps_per_second": 22.083}, {"test_loss": 0.7002851963043213, "test_mcc": 0.5209705524691278, "test_macro_f1": 0.5147595635334751, "test_runtime": 2.8919, "test_samples_per_second": 708.185, "test_steps_per_second": 22.131}]}, "total": {"test_mcc": 52.31014815257085, "test_mcc_se": 1.2238266131170739, "test_macro_f1": 51.51269207045637, "test_macro_f1_se": 0.4897880845818574}}, "num_model_parameters": 80109315, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 1.0437631607055664, "test_mcc": 0.20175496259590697, "test_macro_f1": 0.4085098044917041, "test_runtime": 0.9009, "test_samples_per_second": 2273.354, "test_steps_per_second": 71.042}, {"test_loss": 1.013871192932129, "test_mcc": 0.2618378926346633, "test_macro_f1": 0.4901977300672093, "test_runtime": 0.848, "test_samples_per_second": 2415.083, "test_steps_per_second": 75.471}, {"test_loss": 1.0524853467941284, "test_mcc": 0.1781781157792534, "test_macro_f1": 0.35725504511285483, "test_runtime": 0.9037, "test_samples_per_second": 2266.185, "test_steps_per_second": 70.818}, {"test_loss": 1.0498595237731934, "test_mcc": 0.17093775101241318, "test_macro_f1": 0.3626381138987776, "test_runtime": 0.8782, "test_samples_per_second": 2331.967, "test_steps_per_second": 72.874}, {"test_loss": 1.0397958755493164, "test_mcc": 0.23064430226696003, "test_macro_f1": 0.469596634422839, "test_runtime": 0.8725, "test_samples_per_second": 2347.188, "test_steps_per_second": 73.35}, {"test_loss": 1.0661402940750122, "test_mcc": 0.1977990886560072, "test_macro_f1": 0.4185589650539949, "test_runtime": 0.9438, "test_samples_per_second": 2169.942, "test_steps_per_second": 67.811}, {"test_loss": 1.037433385848999, "test_mcc": 0.2188412534914005, "test_macro_f1": 0.41288720047380584, "test_runtime": 0.9588, "test_samples_per_second": 2136.028, "test_steps_per_second": 66.751}, {"test_loss": 1.0444236993789673, "test_mcc": 0.17483514980656925, "test_macro_f1": 0.3656188923237349, "test_runtime": 0.904, "test_samples_per_second": 2265.398, "test_steps_per_second": 70.794}, {"test_loss": 1.0249050855636597, "test_mcc": 0.22516602450288564, "test_macro_f1": 0.42726633605999337, "test_runtime": 0.8672, "test_samples_per_second": 2361.641, "test_steps_per_second": 73.801}, {"test_loss": 1.0569684505462646, "test_mcc": 0.17269528654457536, "test_macro_f1": 0.38294011450947146, "test_runtime": 0.8642, "test_samples_per_second": 2369.713, "test_steps_per_second": 74.054}]}, "total": {"test_mcc": 20.326898272906348, "test_mcc_se": 1.8881228530984346, "test_macro_f1": 40.954688364143855, "test_macro_f1_se": 2.778811776235053}}, "num_model_parameters": 80109315, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.9967845678329468, "test_mcc": 0.0956273847764537, "test_macro_f1": 0.3197091545185367, "test_runtime": 0.8054, "test_samples_per_second": 2542.864, "test_steps_per_second": 79.465}, {"test_loss": 0.9603617787361145, "test_mcc": 0.13788472189285206, "test_macro_f1": 0.3516567020449361, "test_runtime": 0.7421, "test_samples_per_second": 2759.791, "test_steps_per_second": 86.243}, {"test_loss": 0.939403772354126, "test_mcc": 0.18832405833027396, "test_macro_f1": 0.3766135999012712, "test_runtime": 0.7887, "test_samples_per_second": 2596.636, "test_steps_per_second": 81.145}, {"test_loss": 0.9794791340827942, "test_mcc": 0.1574538694745831, "test_macro_f1": 0.3630600663915084, "test_runtime": 0.7936, "test_samples_per_second": 2580.502, "test_steps_per_second": 80.641}, {"test_loss": 0.9802365899085999, "test_mcc": 0.1260259592017799, "test_macro_f1": 0.3511760618248436, "test_runtime": 0.7737, "test_samples_per_second": 2646.969, "test_steps_per_second": 82.718}, {"test_loss": 0.9753826856613159, "test_mcc": 0.11208171405928108, "test_macro_f1": 0.33586472472414114, "test_runtime": 0.734, "test_samples_per_second": 2790.38, "test_steps_per_second": 87.199}, {"test_loss": 0.9481692314147949, "test_mcc": 0.16455671752595813, "test_macro_f1": 0.3681853246289708, "test_runtime": 0.7488, "test_samples_per_second": 2735.178, "test_steps_per_second": 85.474}, {"test_loss": 0.9541620016098022, "test_mcc": 0.18780354816938935, "test_macro_f1": 0.3764617641776935, "test_runtime": 0.7544, "test_samples_per_second": 2714.87, "test_steps_per_second": 84.84}, {"test_loss": 0.9695781469345093, "test_mcc": 0.17470577217330113, "test_macro_f1": 0.37242613315038525, "test_runtime": 0.7523, "test_samples_per_second": 2722.374, "test_steps_per_second": 85.074}, {"test_loss": 0.9798018932342529, "test_mcc": 0.16268136193347207, "test_macro_f1": 0.3653066986000661, "test_runtime": 0.7574, "test_samples_per_second": 2704.107, "test_steps_per_second": 84.503}]}, "total": {"test_mcc": 15.07145107537345, "test_mcc_se": 1.9651218709983393, "test_macro_f1": 35.80460229962353, "test_macro_f1_se": 1.154218457119263}}, "num_model_parameters": 80109315, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.1407371610403061, "test_micro_f1": 0.2369337979094077, "test_micro_f1_no_misc": 0.2559598494353827, "test_runtime": 2.8836, "test_samples_per_second": 710.224, "test_steps_per_second": 22.195}, {"test_loss": 0.13921725749969482, "test_micro_f1": 0.263030303030303, "test_micro_f1_no_misc": 0.2825520833333333, "test_runtime": 2.6069, "test_samples_per_second": 785.594, "test_steps_per_second": 24.55}, {"test_loss": 0.14208030700683594, "test_micro_f1": 0.22585924713584288, "test_micro_f1_no_misc": 0.23701109165207238, "test_runtime": 2.5852, "test_samples_per_second": 792.194, "test_steps_per_second": 24.756}, {"test_loss": 0.14675813913345337, "test_micro_f1": 0.19090398652442447, "test_micro_f1_no_misc": 0.20322773460848775, "test_runtime": 2.7234, "test_samples_per_second": 751.994, "test_steps_per_second": 23.5}, {"test_loss": 0.15008185803890228, "test_micro_f1": 0.21723237597911227, "test_micro_f1_no_misc": 0.23012784880489162, "test_runtime": 2.7015, "test_samples_per_second": 758.111, "test_steps_per_second": 23.691}, {"test_loss": 0.15564677119255066, "test_micro_f1": 0.2286840808279941, "test_micro_f1_no_misc": 0.24574468085106382, "test_runtime": 2.4318, "test_samples_per_second": 842.167, "test_steps_per_second": 26.318}, {"test_loss": 0.1569209098815918, "test_micro_f1": 0.21928934010152284, "test_micro_f1_no_misc": 0.23452054794520547, "test_runtime": 2.6274, "test_samples_per_second": 779.476, "test_steps_per_second": 24.359}, {"test_loss": 0.12847453355789185, "test_micro_f1": 0.25524266027561415, "test_micro_f1_no_misc": 0.2714468629961587, "test_runtime": 2.8391, "test_samples_per_second": 721.359, "test_steps_per_second": 22.542}, {"test_loss": 0.13918957114219666, "test_micro_f1": 0.2102366538249862, "test_micro_f1_no_misc": 0.2236533957845433, "test_runtime": 2.7859, "test_samples_per_second": 735.131, "test_steps_per_second": 22.973}, {"test_loss": 0.14568525552749634, "test_micro_f1": 0.25784369652025096, "test_micro_f1_no_misc": 0.2766217870257038, "test_runtime": 2.7983, "test_samples_per_second": 731.882, "test_steps_per_second": 22.871}]}, "total": {"test_micro_f1": 23.052561421294584, "test_micro_f1_se": 1.4260749464383606, "test_micro_f1_no_misc": 24.60865882436843, "test_micro_f1_no_misc_se": 1.5753086260024967}}, "num_model_parameters": 79963785, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.21001604199409485, "test_micro_f1": 0.3234256926952141, "test_micro_f1_no_misc": 0.31171284634760704, "test_runtime": 3.1104, "test_samples_per_second": 658.445, "test_steps_per_second": 20.576}, {"test_loss": 0.20315484702587128, "test_micro_f1": 0.3104575163398693, "test_micro_f1_no_misc": 0.3033401499659168, "test_runtime": 2.7194, "test_samples_per_second": 753.109, "test_steps_per_second": 23.535}, {"test_loss": 0.20861348509788513, "test_micro_f1": 0.3211946554886036, "test_micro_f1_no_misc": 0.30915254237288137, "test_runtime": 3.127, "test_samples_per_second": 654.942, "test_steps_per_second": 20.467}, {"test_loss": 0.20524728298187256, "test_micro_f1": 0.29864932466233113, "test_micro_f1_no_misc": 0.2893973573960683, "test_runtime": 3.0439, "test_samples_per_second": 672.822, "test_steps_per_second": 21.026}, {"test_loss": 0.20617416501045227, "test_micro_f1": 0.3110624315443593, "test_micro_f1_no_misc": 0.3064008394543547, "test_runtime": 3.0577, "test_samples_per_second": 669.781, "test_steps_per_second": 20.931}, {"test_loss": 0.21650516986846924, "test_micro_f1": 0.2722744881018262, "test_micro_f1_no_misc": 0.26151142355008794, "test_runtime": 2.9549, "test_samples_per_second": 693.084, "test_steps_per_second": 21.659}, {"test_loss": 0.20302414894104004, "test_micro_f1": 0.27586206896551724, "test_micro_f1_no_misc": 0.2627877237851662, "test_runtime": 3.0751, "test_samples_per_second": 666.005, "test_steps_per_second": 20.813}, {"test_loss": 0.1966516077518463, "test_micro_f1": 0.3322972591127437, "test_micro_f1_no_misc": 0.3223052294557097, "test_runtime": 2.9917, "test_samples_per_second": 684.565, "test_steps_per_second": 21.393}, {"test_loss": 0.21173545718193054, "test_micro_f1": 0.2738126824091271, "test_micro_f1_no_misc": 0.2650130548302872, "test_runtime": 3.0723, "test_samples_per_second": 666.607, "test_steps_per_second": 20.831}, {"test_loss": 0.2088819295167923, "test_micro_f1": 0.32791878172588834, "test_micro_f1_no_misc": 0.30585962652929816, "test_runtime": 2.7484, "test_samples_per_second": 745.153, "test_steps_per_second": 23.286}]}, "total": {"test_micro_f1": 30.4695490104548, "test_micro_f1_se": 1.4418923442311031, "test_micro_f1_no_misc": 29.374807936873772, "test_micro_f1_no_misc_se": 1.4037861984832347}}, "num_model_parameters": 79963785, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.16047194600105286, "test_micro_f1": 0.34779516358463725, "test_micro_f1_no_misc": 0.36507936507936506, "test_runtime": 2.4993, "test_samples_per_second": 819.431, "test_steps_per_second": 25.607}, {"test_loss": 0.16558343172073364, "test_micro_f1": 0.2959537572254335, "test_micro_f1_no_misc": 0.30948419301164726, "test_runtime": 2.5257, "test_samples_per_second": 810.878, "test_steps_per_second": 25.34}, {"test_loss": 0.17206154763698578, "test_micro_f1": 0.30190007037297684, "test_micro_f1_no_misc": 0.3156673114119923, "test_runtime": 2.5058, "test_samples_per_second": 817.319, "test_steps_per_second": 25.541}, {"test_loss": 0.17972241342067719, "test_micro_f1": 0.22982023264011278, "test_micro_f1_no_misc": 0.2424242424242424, "test_runtime": 2.4753, "test_samples_per_second": 827.369, "test_steps_per_second": 25.855}, {"test_loss": 0.17531590163707733, "test_micro_f1": 0.30769230769230765, "test_micro_f1_no_misc": 0.32569444444444445, "test_runtime": 2.5096, "test_samples_per_second": 816.078, "test_steps_per_second": 25.502}, {"test_loss": 0.16408737003803253, "test_micro_f1": 0.3472733355637337, "test_micro_f1_no_misc": 0.36972343522561857, "test_runtime": 2.4185, "test_samples_per_second": 846.791, "test_steps_per_second": 26.462}, {"test_loss": 0.1765913963317871, "test_micro_f1": 0.30148482892188505, "test_micro_f1_no_misc": 0.31398601398601395, "test_runtime": 2.3891, "test_samples_per_second": 857.23, "test_steps_per_second": 26.788}, {"test_loss": 0.16357064247131348, "test_micro_f1": 0.32876712328767127, "test_micro_f1_no_misc": 0.34293948126801155, "test_runtime": 2.3966, "test_samples_per_second": 854.532, "test_steps_per_second": 26.704}, {"test_loss": 0.16346251964569092, "test_micro_f1": 0.2794636556104446, "test_micro_f1_no_misc": 0.2962121212121212, "test_runtime": 2.4705, "test_samples_per_second": 828.994, "test_steps_per_second": 25.906}, {"test_loss": 0.17765052616596222, "test_micro_f1": 0.290473017988008, "test_micro_f1_no_misc": 0.30581478822684854, "test_runtime": 2.3525, "test_samples_per_second": 870.546, "test_steps_per_second": 27.205}]}, "total": {"test_micro_f1": 30.306234928872104, "test_micro_f1_se": 2.144285058464929, "test_micro_f1_no_misc": 31.87025396290305, "test_micro_f1_no_misc_se": 2.2629287796348896}}, "num_model_parameters": 79963785, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.16661185026168823, "test_micro_f1": 0.3585780525502318, "test_micro_f1_no_misc": 0.37812911725955206, "test_runtime": 2.4094, "test_samples_per_second": 850.001, "test_steps_per_second": 26.563}, {"test_loss": 0.1768149733543396, "test_micro_f1": 0.31641086186540734, "test_micro_f1_no_misc": 0.33542713567839194, "test_runtime": 2.5457, "test_samples_per_second": 804.485, "test_steps_per_second": 25.14}, {"test_loss": 0.17905163764953613, "test_micro_f1": 0.285132382892057, "test_micro_f1_no_misc": 0.30419906687402803, "test_runtime": 2.3649, "test_samples_per_second": 866.01, "test_steps_per_second": 27.063}, {"test_loss": 0.1924823522567749, "test_micro_f1": 0.2990381812882541, "test_micro_f1_no_misc": 0.3188315724052207, "test_runtime": 2.5947, "test_samples_per_second": 789.292, "test_steps_per_second": 24.665}, {"test_loss": 0.1931917518377304, "test_micro_f1": 0.2958199356913183, "test_micro_f1_no_misc": 0.31638774865803604, "test_runtime": 2.3885, "test_samples_per_second": 857.441, "test_steps_per_second": 26.795}, {"test_loss": 0.18945077061653137, "test_micro_f1": 0.33039388594944147, "test_micro_f1_no_misc": 0.3514195583596214, "test_runtime": 2.4705, "test_samples_per_second": 828.978, "test_steps_per_second": 25.906}, {"test_loss": 0.1766628623008728, "test_micro_f1": 0.28923631990378834, "test_micro_f1_no_misc": 0.30705394190871366, "test_runtime": 2.6718, "test_samples_per_second": 766.534, "test_steps_per_second": 23.954}, {"test_loss": 0.17747867107391357, "test_micro_f1": 0.30128597672994495, "test_micro_f1_no_misc": 0.31924577373211965, "test_runtime": 2.6443, "test_samples_per_second": 774.494, "test_steps_per_second": 24.203}, {"test_loss": 0.18200485408306122, "test_micro_f1": 0.29220976053349496, "test_micro_f1_no_misc": 0.3110680864795095, "test_runtime": 2.4077, "test_samples_per_second": 850.61, "test_steps_per_second": 26.582}, {"test_loss": 0.17698737978935242, "test_micro_f1": 0.2905466626396859, "test_micro_f1_no_misc": 0.3053968253968254, "test_runtime": 2.4939, "test_samples_per_second": 821.197, "test_steps_per_second": 25.662}]}, "total": {"test_micro_f1": 30.58652020043624, "test_micro_f1_se": 1.4295158803540415, "test_micro_f1_no_misc": 32.47158826752018, "test_micro_f1_no_misc_se": 1.476456445780214}}, "num_model_parameters": 79963785, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.6925308704376221, "test_mcc": -0.021433687395141586, "test_macro_f1": 0.3517145271635134, "test_runtime": 0.7964, "test_samples_per_second": 2571.46, "test_steps_per_second": 80.358}, {"test_loss": 0.6907345652580261, "test_mcc": 0.05535859888257549, "test_macro_f1": 0.5276237908337716, "test_runtime": 0.7528, "test_samples_per_second": 2720.371, "test_steps_per_second": 85.012}, {"test_loss": 0.6927478313446045, "test_mcc": 0.031442160546532746, "test_macro_f1": 0.5151356783440364, "test_runtime": 0.8145, "test_samples_per_second": 2514.313, "test_steps_per_second": 78.572}, {"test_loss": 0.694523274898529, "test_mcc": -0.04987933245363682, "test_macro_f1": 0.3514451292910353, "test_runtime": 0.8023, "test_samples_per_second": 2552.67, "test_steps_per_second": 79.771}, {"test_loss": 0.6929658055305481, "test_mcc": 0.008425943545303112, "test_macro_f1": 0.4857068576358114, "test_runtime": 0.7599, "test_samples_per_second": 2695.071, "test_steps_per_second": 84.221}, {"test_loss": 0.6933721303939819, "test_mcc": 0.019315657973047566, "test_macro_f1": 0.5068731424546373, "test_runtime": 0.7885, "test_samples_per_second": 2597.318, "test_steps_per_second": 81.166}, {"test_loss": 0.6928492188453674, "test_mcc": 0.02596517840740902, "test_macro_f1": 0.502847757768915, "test_runtime": 0.7814, "test_samples_per_second": 2621.066, "test_steps_per_second": 81.908}, {"test_loss": 0.6926555037498474, "test_mcc": 0.02218318908418054, "test_macro_f1": 0.5095559949116435, "test_runtime": 0.8111, "test_samples_per_second": 2525.069, "test_steps_per_second": 78.908}, {"test_loss": 0.6931877136230469, "test_mcc": 0.0050329440686377675, "test_macro_f1": 0.4123154131143324, "test_runtime": 0.773, "test_samples_per_second": 2649.416, "test_steps_per_second": 82.794}, {"test_loss": 0.6924698352813721, "test_mcc": 0.03546640392705038, "test_macro_f1": 0.5167962739277012, "test_runtime": 0.7764, "test_samples_per_second": 2637.895, "test_steps_per_second": 82.434}]}, "total": {"test_mcc": 1.318770565859582, "test_mcc_se": 1.8657157941156892, "test_macro_f1": 46.80014565445398, "test_macro_f1_se": 4.290758306678853}}, "num_model_parameters": 80108930, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.6924414038658142, "test_mcc": 0.02693689809923087, "test_macro_f1": 0.5127792321460487, "test_runtime": 0.8074, "test_samples_per_second": 2536.643, "test_steps_per_second": 79.27}, {"test_loss": 0.6933864951133728, "test_mcc": 0.001733578923500983, "test_macro_f1": 0.49653438017542784, "test_runtime": 0.8169, "test_samples_per_second": 2507.151, "test_steps_per_second": 78.348}, {"test_loss": 0.6921628713607788, "test_mcc": 0.030796768239644605, "test_macro_f1": 0.508264595905914, "test_runtime": 0.7821, "test_samples_per_second": 2618.464, "test_steps_per_second": 81.827}, {"test_loss": 0.6922633647918701, "test_mcc": 0.03756578274552327, "test_macro_f1": 0.5181411046926723, "test_runtime": 0.827, "test_samples_per_second": 2476.412, "test_steps_per_second": 77.388}, {"test_loss": 0.6931569576263428, "test_mcc": -0.01757667845411537, "test_macro_f1": 0.48954643892242883, "test_runtime": 0.8183, "test_samples_per_second": 2502.754, "test_steps_per_second": 78.211}, {"test_loss": 0.6926693320274353, "test_mcc": 0.012340415727397297, "test_macro_f1": 0.5029477545338782, "test_runtime": 0.809, "test_samples_per_second": 2531.476, "test_steps_per_second": 79.109}, {"test_loss": 0.6928646564483643, "test_mcc": 0.02551711479525897, "test_macro_f1": 0.5106879326278447, "test_runtime": 0.8114, "test_samples_per_second": 2524.151, "test_steps_per_second": 78.88}, {"test_loss": 0.6936618685722351, "test_mcc": -0.021097485533988655, "test_macro_f1": 0.462964960861174, "test_runtime": 0.7838, "test_samples_per_second": 2613.047, "test_steps_per_second": 81.658}, {"test_loss": 0.6929067373275757, "test_mcc": 0.01650486991530552, "test_macro_f1": 0.5052401649103299, "test_runtime": 0.772, "test_samples_per_second": 2652.811, "test_steps_per_second": 82.9}, {"test_loss": 0.6940379738807678, "test_mcc": -0.022408380433021124, "test_macro_f1": 0.3774771857116569, "test_runtime": 0.8092, "test_samples_per_second": 2530.883, "test_steps_per_second": 79.09}]}, "total": {"test_mcc": 0.9031288402473636, "test_mcc_se": 1.4019424836117897, "test_macro_f1": 48.84583750487374, "test_macro_f1_se": 2.603820065142767}}, "num_model_parameters": 80108930, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.6927293539047241, "test_mcc": 0.024332924650808673, "test_macro_f1": 0.49194717960461026, "test_runtime": 0.7446, "test_samples_per_second": 2750.308, "test_steps_per_second": 85.947}, {"test_loss": 0.6937640309333801, "test_mcc": 0.00237607921502963, "test_macro_f1": 0.4075927334192454, "test_runtime": 0.7402, "test_samples_per_second": 2766.993, "test_steps_per_second": 86.469}, {"test_loss": 0.6928485035896301, "test_mcc": 0.01743550841700011, "test_macro_f1": 0.4831598653963473, "test_runtime": 0.7316, "test_samples_per_second": 2799.509, "test_steps_per_second": 87.485}, {"test_loss": 0.6929488778114319, "test_mcc": -0.00451832519512692, "test_macro_f1": 0.4793358226741877, "test_runtime": 0.7357, "test_samples_per_second": 2783.776, "test_steps_per_second": 86.993}, {"test_loss": 0.6928746104240417, "test_mcc": 0.016472471629502293, "test_macro_f1": 0.503539508884124, "test_runtime": 0.7372, "test_samples_per_second": 2777.934, "test_steps_per_second": 86.81}, {"test_loss": 0.6933313012123108, "test_mcc": 0.03024546877703239, "test_macro_f1": 0.5043768166950865, "test_runtime": 0.7061, "test_samples_per_second": 2900.629, "test_steps_per_second": 90.645}, {"test_loss": 0.6913025379180908, "test_mcc": 0.04863816186897375, "test_macro_f1": 0.5014639532199545, "test_runtime": 0.7705, "test_samples_per_second": 2657.864, "test_steps_per_second": 83.058}, {"test_loss": 0.6931753158569336, "test_mcc": 0.012048193581494506, "test_macro_f1": 0.4925782823676532, "test_runtime": 0.764, "test_samples_per_second": 2680.465, "test_steps_per_second": 83.765}, {"test_loss": 0.693701982498169, "test_mcc": -0.026154986836080533, "test_macro_f1": 0.48680351906158353, "test_runtime": 0.7479, "test_samples_per_second": 2738.509, "test_steps_per_second": 85.578}, {"test_loss": 0.6934241056442261, "test_mcc": 0.0051166059561713086, "test_macro_f1": 0.4913771317905526, "test_runtime": 0.7286, "test_samples_per_second": 2810.898, "test_steps_per_second": 87.841}]}, "total": {"test_mcc": 1.2599210206480522, "test_mcc_se": 1.263819535137487, "test_macro_f1": 48.42174813113345, "test_macro_f1_se": 1.7483328046725657}}, "num_model_parameters": 80108930, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_loss": 0.693085789680481, "test_mcc": -0.0015461936327245903, "test_macro_f1": 0.45271433238187553, "test_runtime": 0.8054, "test_samples_per_second": 2542.82, "test_steps_per_second": 79.463}, {"test_loss": 0.6939791440963745, "test_mcc": -0.0252850867798973, "test_macro_f1": 0.3624934057256323, "test_runtime": 0.7758, "test_samples_per_second": 2639.736, "test_steps_per_second": 82.492}, {"test_loss": 0.6926892995834351, "test_mcc": 0.008483301407236143, "test_macro_f1": 0.4974572996367571, "test_runtime": 0.764, "test_samples_per_second": 2680.518, "test_steps_per_second": 83.766}, {"test_loss": 0.6930035352706909, "test_mcc": -0.006770045082372115, "test_macro_f1": 0.49549426808151453, "test_runtime": 0.7738, "test_samples_per_second": 2646.619, "test_steps_per_second": 82.707}, {"test_loss": 0.691977858543396, "test_mcc": 0.04657250228995917, "test_macro_f1": 0.5224058257149806, "test_runtime": 0.7808, "test_samples_per_second": 2623.058, "test_steps_per_second": 81.971}, {"test_loss": 0.692406177520752, "test_mcc": 0.024716686434960097, "test_macro_f1": 0.512248297322967, "test_runtime": 0.7759, "test_samples_per_second": 2639.646, "test_steps_per_second": 82.489}, {"test_loss": 0.6927149891853333, "test_mcc": 0.011401617279317978, "test_macro_f1": 0.5004929661906654, "test_runtime": 0.7712, "test_samples_per_second": 2655.597, "test_steps_per_second": 82.987}, {"test_loss": 0.692267894744873, "test_mcc": -0.025428010956793725, "test_macro_f1": 0.4148363066623936, "test_runtime": 0.8236, "test_samples_per_second": 2486.757, "test_steps_per_second": 77.711}, {"test_loss": 0.6954142451286316, "test_mcc": -0.019949468971479808, "test_macro_f1": 0.3497202412440635, "test_runtime": 0.7369, "test_samples_per_second": 2779.385, "test_steps_per_second": 86.856}, {"test_loss": 0.6926085948944092, "test_mcc": 0.03725411956874828, "test_macro_f1": 0.48481616389285787, "test_runtime": 0.7494, "test_samples_per_second": 2732.977, "test_steps_per_second": 85.406}]}, "total": {"test_mcc": 0.4944942155695413, "test_mcc_se": 1.5811943078548198, "test_macro_f1": 45.92679106853708, "test_macro_f1_se": 3.8816703557500087}}, "num_model_parameters": 80108930, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_em": 4.802478698683191, "test_f1": 11.434740368619362}, {"test_em": 5.348837209302325, "test_f1": 11.359300968416116}, {"test_em": 3.6321483771251932, "test_f1": 9.252567010287814}, {"test_em": 3.426791277258567, "test_f1": 9.096297907132382}, {"test_em": 5.714285714285714, "test_f1": 12.31598948272988}, {"test_em": 4.934464148033925, "test_f1": 11.491554721263208}, {"test_em": 5.239179954441913, "test_f1": 11.93464577670522}, {"test_em": 5.896043444530644, "test_f1": 13.650449773251202}, {"test_em": 5.333333333333333, "test_f1": 12.074266054470039}, {"test_em": 3.4937888198757765, "test_f1": 8.581402159152493}]}, "total": {"test_em": 4.782135097687059, "test_em_se": 0.5765065242462225, "test_f1": 11.119121422202772, "test_f1_se": 1.0064167958694912}}, "num_model_parameters": 79961090, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_em": 4.260263361735089, "test_f1": 10.180877178818395}, {"test_em": 3.4108527131782944, "test_f1": 9.37719911294323}, {"test_em": 3.400309119010819, "test_f1": 10.066072392348469}, {"test_em": 2.8816199376947043, "test_f1": 9.293865368921075}, {"test_em": 5.173745173745174, "test_f1": 13.86111046792162}, {"test_em": 2.8527370855821124, "test_f1": 9.305834357119663}, {"test_em": 3.0372057706909645, "test_f1": 8.888673323887051}, {"test_em": 5.818463925523662, "test_f1": 12.45121974595227}, {"test_em": 4.627450980392157, "test_f1": 11.65361689714268}, {"test_em": 2.872670807453416, "test_f1": 10.062346523584345}]}, "total": {"test_em": 3.8335318875006394, "test_em_se": 0.6643586617673107, "test_f1": 10.51408153686388, "test_f1_se": 1.0047895400865805}}, "num_model_parameters": 79961090, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_em": 3.098373353989156, "test_f1": 8.342853361097074}, {"test_em": 4.263565891472868, "test_f1": 10.434004504653952}, {"test_em": 4.559505409582689, "test_f1": 12.853950168520646}, {"test_em": 1.2461059190031152, "test_f1": 3.4389151586100457}, {"test_em": 5.482625482625482, "test_f1": 13.258311980337654}, {"test_em": 4.240555127216654, "test_f1": 10.001671831680838}, {"test_em": 2.3538344722854974, "test_f1": 8.359814006572961}, {"test_em": 4.422032583397983, "test_f1": 11.785313804639044}, {"test_em": 4.078431372549019, "test_f1": 10.739216620203702}, {"test_em": 4.736024844720497, "test_f1": 10.798483497029748}]}, "total": {"test_em": 3.848105445684296, "test_em_se": 0.7796475675499868, "test_f1": 10.001253493334566, "test_f1_se": 1.7507080331430178}}, "num_model_parameters": 79961090, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "RabotaRu/HRBert-mini", "results": {"raw": {"test": [{"test_speed": 20.51}, {"test_speed": 20.15}, {"test_speed": 20.38}, {"test_speed": 19.33}, {"test_speed": 19.65}, {"test_speed": 20.07}, {"test_speed": 20.95}, {"test_speed": 20.1}, {"test_speed": 20.33}, {"test_speed": 19.2}]}, "total": {"test_speed": 20.066999999999997, "test_speed_se": 0.33440265309952333}}, "num_model_parameters": 80108160, "max_sequence_length": 512, "vocabulary_size": 200001}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "xlm-roberta-large-finetuned-conll02-dutch", "results": {"raw": {"test": [{"test_speed": 0.41}, {"test_speed": 0.4}, {"test_speed": 0.41}, {"test_speed": 0.4}, {"test_speed": 0.4}, {"test_speed": 0.39}, {"test_speed": 0.41}, {"test_speed": 0.4}, {"test_speed": 0.41}, {"test_speed": 0.41}]}, "total": {"test_speed": 0.404, "test_speed_se": 0.004333723059397709}}, "num_model_parameters": 559890432, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.3877604007720947, "test_mcc": 0.7463857074985523, "test_macro_f1": 0.6593477270953642, "test_runtime": 13.3439, "test_samples_per_second": 153.478, "test_steps_per_second": 19.185}, {"test_loss": 0.37566137313842773, "test_mcc": 0.7501524615240566, "test_macro_f1": 0.7165769604048239, "test_runtime": 12.7598, "test_samples_per_second": 160.503, "test_steps_per_second": 20.063}, {"test_loss": 0.3735033869743347, "test_mcc": 0.7543217339740927, "test_macro_f1": 0.718920938471444, "test_runtime": 13.2654, "test_samples_per_second": 154.387, "test_steps_per_second": 19.298}, {"test_loss": 0.34633171558380127, "test_mcc": 0.7679974496704314, "test_macro_f1": 0.7165234103059216, "test_runtime": 12.5518, "test_samples_per_second": 163.164, "test_steps_per_second": 20.395}, {"test_loss": 0.34944647550582886, "test_mcc": 0.7650365035037751, "test_macro_f1": 0.7381415335772795, "test_runtime": 12.3958, "test_samples_per_second": 165.217, "test_steps_per_second": 20.652}, {"test_loss": 0.3445262908935547, "test_mcc": 0.784754693689589, "test_macro_f1": 0.7820943535203955, "test_runtime": 12.911, "test_samples_per_second": 158.625, "test_steps_per_second": 19.828}, {"test_loss": 0.3594313859939575, "test_mcc": 0.7711901161711213, "test_macro_f1": 0.7490804786558609, "test_runtime": 12.2959, "test_samples_per_second": 166.56, "test_steps_per_second": 20.82}, {"test_loss": 0.37877553701400757, "test_mcc": 0.742511821492044, "test_macro_f1": 0.6962259109874429, "test_runtime": 13.2482, "test_samples_per_second": 154.588, "test_steps_per_second": 19.323}, {"test_loss": 0.4008479118347168, "test_mcc": 0.7573587623177114, "test_macro_f1": 0.7497312393353545, "test_runtime": 13.0557, "test_samples_per_second": 156.866, "test_steps_per_second": 19.608}, {"test_loss": 0.38093632459640503, "test_mcc": 0.7691994840081928, "test_macro_f1": 0.7478168830698179, "test_runtime": 12.788, "test_samples_per_second": 160.151, "test_steps_per_second": 20.019}]}, "total": {"test_mcc": 76.08908733849566, "test_mcc_se": 0.8085013288212437, "test_macro_f1": 72.74459435423705, "test_macro_f1_se": 2.1072078215576497}}, "num_model_parameters": 135293955, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.9041610956192017, "test_mcc": 0.40000667101967247, "test_macro_f1": 0.5836838503390731, "test_runtime": 5.2437, "test_samples_per_second": 390.566, "test_steps_per_second": 12.205}, {"test_loss": 0.9042923450469971, "test_mcc": 0.4060147869873455, "test_macro_f1": 0.5971352793694663, "test_runtime": 5.1626, "test_samples_per_second": 396.696, "test_steps_per_second": 12.397}, {"test_loss": 0.9101371169090271, "test_mcc": 0.38007069498361246, "test_macro_f1": 0.5862375152125966, "test_runtime": 5.1281, "test_samples_per_second": 399.372, "test_steps_per_second": 12.48}, {"test_loss": 0.8868207931518555, "test_mcc": 0.4125175631912283, "test_macro_f1": 0.5984695316995641, "test_runtime": 5.1402, "test_samples_per_second": 398.429, "test_steps_per_second": 12.451}, {"test_loss": 0.9276384115219116, "test_mcc": 0.39494129545692497, "test_macro_f1": 0.5938935012669501, "test_runtime": 5.0954, "test_samples_per_second": 401.929, "test_steps_per_second": 12.56}, {"test_loss": 0.9379671812057495, "test_mcc": 0.3606204901258798, "test_macro_f1": 0.571462104378914, "test_runtime": 5.2629, "test_samples_per_second": 389.137, "test_steps_per_second": 12.161}, {"test_loss": 0.8866485953330994, "test_mcc": 0.38865977806673513, "test_macro_f1": 0.585364330146661, "test_runtime": 5.1511, "test_samples_per_second": 397.588, "test_steps_per_second": 12.425}, {"test_loss": 0.9492048025131226, "test_mcc": 0.41573362779454187, "test_macro_f1": 0.6029292269868921, "test_runtime": 5.1397, "test_samples_per_second": 398.467, "test_steps_per_second": 12.452}, {"test_loss": 0.8694826364517212, "test_mcc": 0.4098434562620628, "test_macro_f1": 0.5993079703084723, "test_runtime": 5.1214, "test_samples_per_second": 399.889, "test_steps_per_second": 12.497}, {"test_loss": 0.9608210325241089, "test_mcc": 0.3719560425746463, "test_macro_f1": 0.5831967599530512, "test_runtime": 5.0889, "test_samples_per_second": 402.443, "test_steps_per_second": 12.576}]}, "total": {"test_mcc": 39.4036440646265, "test_mcc_se": 1.1447781608371086, "test_macro_f1": 59.016800696616414, "test_macro_f1_se": 0.6047490676712629}}, "num_model_parameters": 135293955, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.832777738571167, "test_mcc": 0.4082237904829369, "test_macro_f1": 0.5468926190235041, "test_runtime": 4.1433, "test_samples_per_second": 494.291, "test_steps_per_second": 15.447}, {"test_loss": 0.8287040591239929, "test_mcc": 0.4234839387961589, "test_macro_f1": 0.5772875680274818, "test_runtime": 3.8904, "test_samples_per_second": 526.423, "test_steps_per_second": 16.451}, {"test_loss": 0.828415036201477, "test_mcc": 0.4066118480967404, "test_macro_f1": 0.5433235859198444, "test_runtime": 3.8681, "test_samples_per_second": 529.453, "test_steps_per_second": 16.545}, {"test_loss": 0.878247857093811, "test_mcc": 0.39623149824930237, "test_macro_f1": 0.5611504175031031, "test_runtime": 3.9685, "test_samples_per_second": 516.064, "test_steps_per_second": 16.127}, {"test_loss": 0.8401111960411072, "test_mcc": 0.441662848575773, "test_macro_f1": 0.596691329027553, "test_runtime": 4.0401, "test_samples_per_second": 506.918, "test_steps_per_second": 15.841}, {"test_loss": 0.851566731929779, "test_mcc": 0.3990876075222708, "test_macro_f1": 0.5586195218359405, "test_runtime": 4.1072, "test_samples_per_second": 498.637, "test_steps_per_second": 15.582}, {"test_loss": 0.8585464358329773, "test_mcc": 0.3880902940171544, "test_macro_f1": 0.5039370253349856, "test_runtime": 3.9707, "test_samples_per_second": 515.781, "test_steps_per_second": 16.118}, {"test_loss": 0.8847986459732056, "test_mcc": 0.4205510942331562, "test_macro_f1": 0.5877453508624138, "test_runtime": 4.0205, "test_samples_per_second": 509.385, "test_steps_per_second": 15.918}, {"test_loss": 0.8469448089599609, "test_mcc": 0.3491866066768304, "test_macro_f1": 0.46642994186567055, "test_runtime": 4.1395, "test_samples_per_second": 494.746, "test_steps_per_second": 15.461}, {"test_loss": 0.8861976861953735, "test_mcc": 0.3873253531753301, "test_macro_f1": 0.5255271232019261, "test_runtime": 4.1214, "test_samples_per_second": 496.924, "test_steps_per_second": 15.529}]}, "total": {"test_mcc": 40.20454879825653, "test_mcc_se": 1.5568901306155378, "test_macro_f1": 54.67604482602424, "test_macro_f1_se": 2.462121003589295}}, "num_model_parameters": 135293955, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.05180666223168373, "test_micro_f1": 0.7336683417085427, "test_micro_f1_no_misc": 0.7948866937826846, "test_runtime": 6.6756, "test_samples_per_second": 306.789, "test_steps_per_second": 9.587}, {"test_loss": 0.0504164844751358, "test_micro_f1": 0.7072282891315652, "test_micro_f1_no_misc": 0.7721594289113622, "test_runtime": 6.2168, "test_samples_per_second": 329.433, "test_steps_per_second": 10.295}, {"test_loss": 0.047351837158203125, "test_micro_f1": 0.7049808429118775, "test_micro_f1_no_misc": 0.7492163009404388, "test_runtime": 6.3227, "test_samples_per_second": 323.91, "test_steps_per_second": 10.122}, {"test_loss": 0.04423368349671364, "test_micro_f1": 0.7501208313194782, "test_micro_f1_no_misc": 0.814773980154355, "test_runtime": 6.6444, "test_samples_per_second": 308.23, "test_steps_per_second": 9.632}, {"test_loss": 0.05199434608221054, "test_micro_f1": 0.7195866604039455, "test_micro_f1_no_misc": 0.7887628309022151, "test_runtime": 6.5114, "test_samples_per_second": 314.523, "test_steps_per_second": 9.829}, {"test_loss": 0.046774446964263916, "test_micro_f1": 0.7240598096964206, "test_micro_f1_no_misc": 0.7862433862433863, "test_runtime": 5.3091, "test_samples_per_second": 385.751, "test_steps_per_second": 12.055}, {"test_loss": 0.050688207149505615, "test_micro_f1": 0.7215909090909093, "test_micro_f1_no_misc": 0.7834151663938898, "test_runtime": 5.7287, "test_samples_per_second": 357.496, "test_steps_per_second": 11.172}, {"test_loss": 0.04218379408121109, "test_micro_f1": 0.7280468334220331, "test_micro_f1_no_misc": 0.7858017135862913, "test_runtime": 6.5129, "test_samples_per_second": 314.454, "test_steps_per_second": 9.827}, {"test_loss": 0.04396270960569382, "test_micro_f1": 0.7472324723247232, "test_micro_f1_no_misc": 0.7957446808510638, "test_runtime": 6.5255, "test_samples_per_second": 313.844, "test_steps_per_second": 9.808}, {"test_loss": 0.04613237828016281, "test_micro_f1": 0.7559902200488997, "test_micro_f1_no_misc": 0.8197997775305895, "test_runtime": 6.6271, "test_samples_per_second": 309.034, "test_steps_per_second": 9.657}]}, "total": {"test_micro_f1": 72.92505210058395, "test_micro_f1_se": 1.083016469593993, "test_micro_f1_no_misc": 78.90803959296277, "test_micro_f1_no_misc_se": 1.2410626370643254}}, "num_model_parameters": 134707977, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.07301127910614014, "test_micro_f1": 0.761713856176397, "test_micro_f1_no_misc": 0.7795462241788013, "test_runtime": 9.5869, "test_samples_per_second": 213.625, "test_steps_per_second": 6.676}, {"test_loss": 0.07209831476211548, "test_micro_f1": 0.7329295154185023, "test_micro_f1_no_misc": 0.7733526430123099, "test_runtime": 7.7784, "test_samples_per_second": 263.293, "test_steps_per_second": 8.228}, {"test_loss": 0.07378187775611877, "test_micro_f1": 0.7412441191845269, "test_micro_f1_no_misc": 0.7584033613445379, "test_runtime": 9.4544, "test_samples_per_second": 216.618, "test_steps_per_second": 6.769}, {"test_loss": 0.07222302258014679, "test_micro_f1": 0.7615842609370955, "test_micro_f1_no_misc": 0.7869639794168096, "test_runtime": 9.0772, "test_samples_per_second": 225.621, "test_steps_per_second": 7.051}, {"test_loss": 0.08318567276000977, "test_micro_f1": 0.7298757428417072, "test_micro_f1_no_misc": 0.7704979408461251, "test_runtime": 9.7682, "test_samples_per_second": 209.661, "test_steps_per_second": 6.552}, {"test_loss": 0.07911437749862671, "test_micro_f1": 0.7223600771987868, "test_micro_f1_no_misc": 0.7447118891320204, "test_runtime": 9.2219, "test_samples_per_second": 222.08, "test_steps_per_second": 6.94}, {"test_loss": 0.07480031251907349, "test_micro_f1": 0.7419186652763294, "test_micro_f1_no_misc": 0.7775061124694376, "test_runtime": 9.8925, "test_samples_per_second": 207.026, "test_steps_per_second": 6.47}, {"test_loss": 0.07144685834646225, "test_micro_f1": 0.7503425596053713, "test_micro_f1_no_misc": 0.7833572453371593, "test_runtime": 9.5597, "test_samples_per_second": 214.232, "test_steps_per_second": 6.695}, {"test_loss": 0.07652122527360916, "test_micro_f1": 0.7649527806925498, "test_micro_f1_no_misc": 0.7920646583394563, "test_runtime": 9.034, "test_samples_per_second": 226.699, "test_steps_per_second": 7.084}, {"test_loss": 0.07456713914871216, "test_micro_f1": 0.7478621404508939, "test_micro_f1_no_misc": 0.7868383404864092, "test_runtime": 8.2247, "test_samples_per_second": 249.005, "test_steps_per_second": 7.781}]}, "total": {"test_micro_f1": 74.5478371778216, "test_micro_f1_se": 0.8999788613749307, "test_micro_f1_no_misc": 77.53242394563067, "test_micro_f1_no_misc_se": 0.8972403095022237}}, "num_model_parameters": 134707977, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.05816267430782318, "test_micro_f1": 0.768840579710145, "test_micro_f1_no_misc": 0.8110076891946579, "test_runtime": 7.1344, "test_samples_per_second": 287.059, "test_steps_per_second": 8.971}, {"test_loss": 0.04308444261550903, "test_micro_f1": 0.7965850037119525, "test_micro_f1_no_misc": 0.837304847986853, "test_runtime": 7.1031, "test_samples_per_second": 288.325, "test_steps_per_second": 9.01}, {"test_loss": 0.05206775665283203, "test_micro_f1": 0.7918852745715284, "test_micro_f1_no_misc": 0.823391812865497, "test_runtime": 6.9374, "test_samples_per_second": 295.211, "test_steps_per_second": 9.225}, {"test_loss": 0.05141838267445564, "test_micro_f1": 0.7901662049861495, "test_micro_f1_no_misc": 0.808166409861325, "test_runtime": 6.9533, "test_samples_per_second": 294.538, "test_steps_per_second": 9.204}, {"test_loss": 0.04900066554546356, "test_micro_f1": 0.8143236074270558, "test_micro_f1_no_misc": 0.836443468715697, "test_runtime": 7.1753, "test_samples_per_second": 285.424, "test_steps_per_second": 8.92}, {"test_loss": 0.050936564803123474, "test_micro_f1": 0.7978616772469094, "test_micro_f1_no_misc": 0.8284862043251305, "test_runtime": 7.1992, "test_samples_per_second": 284.474, "test_steps_per_second": 8.89}, {"test_loss": 0.04272157698869705, "test_micro_f1": 0.8099965765148921, "test_micro_f1_no_misc": 0.8409436834094369, "test_runtime": 6.6417, "test_samples_per_second": 308.354, "test_steps_per_second": 9.636}, {"test_loss": 0.05798414349555969, "test_micro_f1": 0.7496607869742197, "test_micro_f1_no_misc": 0.7776978417266187, "test_runtime": 6.8519, "test_samples_per_second": 298.897, "test_steps_per_second": 9.341}, {"test_loss": 0.047717925161123276, "test_micro_f1": 0.8118107435076485, "test_micro_f1_no_misc": 0.836059034702832, "test_runtime": 6.8253, "test_samples_per_second": 300.061, "test_steps_per_second": 9.377}, {"test_loss": 0.057428646832704544, "test_micro_f1": 0.781787521079258, "test_micro_f1_no_misc": 0.820839580209895, "test_runtime": 6.8821, "test_samples_per_second": 297.584, "test_steps_per_second": 9.3}]}, "total": {"test_micro_f1": 79.12917975729758, "test_micro_f1_se": 1.256998763157729, "test_micro_f1_no_misc": 82.20340572997942, "test_micro_f1_no_misc_se": 1.1903573878184202}}, "num_model_parameters": 134707977, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.06664535403251648, "test_micro_f1": 0.7419550698239223, "test_micro_f1_no_misc": 0.7753743760399334, "test_runtime": 6.6992, "test_samples_per_second": 305.707, "test_steps_per_second": 9.553}, {"test_loss": 0.07080018520355225, "test_micro_f1": 0.7191883019994031, "test_micro_f1_no_misc": 0.7620311981413872, "test_runtime": 6.8599, "test_samples_per_second": 298.545, "test_steps_per_second": 9.33}, {"test_loss": 0.07319113612174988, "test_micro_f1": 0.7079856972586414, "test_micro_f1_no_misc": 0.7452271231073074, "test_runtime": 6.5206, "test_samples_per_second": 314.08, "test_steps_per_second": 9.815}, {"test_loss": 0.07416946440935135, "test_micro_f1": 0.7486404833836857, "test_micro_f1_no_misc": 0.7759972724173202, "test_runtime": 6.8482, "test_samples_per_second": 299.056, "test_steps_per_second": 9.345}, {"test_loss": 0.0710180401802063, "test_micro_f1": 0.7446744674467447, "test_micro_f1_no_misc": 0.7868628121792679, "test_runtime": 6.8359, "test_samples_per_second": 299.596, "test_steps_per_second": 9.362}, {"test_loss": 0.07649977505207062, "test_micro_f1": 0.682884448305821, "test_micro_f1_no_misc": 0.7323585505403688, "test_runtime": 6.9637, "test_samples_per_second": 294.097, "test_steps_per_second": 9.191}, {"test_loss": 0.065965935587883, "test_micro_f1": 0.7377557346559207, "test_micro_f1_no_misc": 0.7791666666666666, "test_runtime": 7.0974, "test_samples_per_second": 288.557, "test_steps_per_second": 9.017}, {"test_loss": 0.06318599730730057, "test_micro_f1": 0.7192825112107624, "test_micro_f1_no_misc": 0.7588254701418673, "test_runtime": 7.1554, "test_samples_per_second": 286.217, "test_steps_per_second": 8.944}, {"test_loss": 0.07201267778873444, "test_micro_f1": 0.7246022031823746, "test_micro_f1_no_misc": 0.7626245276537273, "test_runtime": 6.6308, "test_samples_per_second": 308.864, "test_steps_per_second": 9.652}, {"test_loss": 0.0666719451546669, "test_micro_f1": 0.7630200308166409, "test_micro_f1_no_misc": 0.7853297442799461, "test_runtime": 7.0227, "test_samples_per_second": 291.626, "test_steps_per_second": 9.113}]}, "total": {"test_micro_f1": 72.89988948083918, "test_micro_f1_se": 1.433107385832989, "test_micro_f1_no_misc": 76.63797741167792, "test_micro_f1_no_misc_se": 1.0952871298863944}}, "num_model_parameters": 134707977, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.37372124195098877, "test_mcc": 0.7305845169999244, "test_macro_f1": 0.8551055183222593, "test_runtime": 3.1188, "test_samples_per_second": 656.669, "test_steps_per_second": 20.521}, {"test_loss": 0.3686695396900177, "test_mcc": 0.7633908339200822, "test_macro_f1": 0.8741733361364786, "test_runtime": 3.0771, "test_samples_per_second": 665.555, "test_steps_per_second": 20.799}, {"test_loss": 0.39558660984039307, "test_mcc": 0.7124623554758807, "test_macro_f1": 0.8434164709445835, "test_runtime": 3.1647, "test_samples_per_second": 647.14, "test_steps_per_second": 20.223}, {"test_loss": 0.4092741310596466, "test_mcc": 0.6912537979793579, "test_macro_f1": 0.8266229134250686, "test_runtime": 3.2278, "test_samples_per_second": 634.479, "test_steps_per_second": 19.827}, {"test_loss": 0.43212443590164185, "test_mcc": 0.6622240258125455, "test_macro_f1": 0.80699131861526, "test_runtime": 3.2423, "test_samples_per_second": 631.653, "test_steps_per_second": 19.739}, {"test_loss": 0.3791195750236511, "test_mcc": 0.7113355010539345, "test_macro_f1": 0.8431138665123298, "test_runtime": 3.0702, "test_samples_per_second": 667.047, "test_steps_per_second": 20.845}, {"test_loss": 0.4343310594558716, "test_mcc": 0.6784918892775464, "test_macro_f1": 0.8192060415522544, "test_runtime": 2.8822, "test_samples_per_second": 710.579, "test_steps_per_second": 22.206}, {"test_loss": 0.4691808521747589, "test_mcc": 0.6504860293570999, "test_macro_f1": 0.8001427845032589, "test_runtime": 2.9912, "test_samples_per_second": 684.666, "test_steps_per_second": 21.396}, {"test_loss": 0.4200775623321533, "test_mcc": 0.723760043992313, "test_macro_f1": 0.8523970389632503, "test_runtime": 2.941, "test_samples_per_second": 696.363, "test_steps_per_second": 21.761}, {"test_loss": 0.4887200593948364, "test_mcc": 0.6844082474112523, "test_macro_f1": 0.8183466856670779, "test_runtime": 2.9309, "test_samples_per_second": 698.757, "test_steps_per_second": 21.836}]}, "total": {"test_mcc": 70.08397241279937, "test_mcc_se": 2.112597340468716, "test_macro_f1": 83.39515974641823, "test_macro_f1_se": 1.4555687094842191}}, "num_model_parameters": 135293186, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.667719841003418, "test_mcc": 0.19229487152406013, "test_macro_f1": 0.5961404701015195, "test_runtime": 4.5532, "test_samples_per_second": 449.794, "test_steps_per_second": 14.056}, {"test_loss": 0.6608805060386658, "test_mcc": 0.2364911783465871, "test_macro_f1": 0.6069015319917631, "test_runtime": 4.6579, "test_samples_per_second": 439.682, "test_steps_per_second": 13.74}, {"test_loss": 0.649686336517334, "test_mcc": 0.24278624245809086, "test_macro_f1": 0.5854361488854907, "test_runtime": 4.5271, "test_samples_per_second": 452.388, "test_steps_per_second": 14.137}, {"test_loss": 0.639716386795044, "test_mcc": 0.28922985225322906, "test_macro_f1": 0.6356403778662567, "test_runtime": 4.7588, "test_samples_per_second": 430.359, "test_steps_per_second": 13.449}, {"test_loss": 0.6607440114021301, "test_mcc": 0.24349352756431858, "test_macro_f1": 0.5875068014361426, "test_runtime": 4.532, "test_samples_per_second": 451.898, "test_steps_per_second": 14.122}, {"test_loss": 0.6663540601730347, "test_mcc": 0.1983236302225468, "test_macro_f1": 0.5900962240380325, "test_runtime": 4.437, "test_samples_per_second": 461.573, "test_steps_per_second": 14.424}, {"test_loss": 0.667776882648468, "test_mcc": 0.20214365182740668, "test_macro_f1": 0.5637255972028288, "test_runtime": 4.3241, "test_samples_per_second": 473.62, "test_steps_per_second": 14.801}, {"test_loss": 0.6490758657455444, "test_mcc": 0.25943470459089313, "test_macro_f1": 0.5692850745786644, "test_runtime": 4.4135, "test_samples_per_second": 464.033, "test_steps_per_second": 14.501}, {"test_loss": 0.6673798561096191, "test_mcc": 0.23794293773949077, "test_macro_f1": 0.6188556507398415, "test_runtime": 4.453, "test_samples_per_second": 459.917, "test_steps_per_second": 14.372}, {"test_loss": 0.6503787040710449, "test_mcc": 0.2480863733968119, "test_macro_f1": 0.6005041107147231, "test_runtime": 4.5609, "test_samples_per_second": 449.034, "test_steps_per_second": 14.032}]}, "total": {"test_mcc": 23.50226969923435, "test_mcc_se": 1.859563130827392, "test_macro_f1": 59.540919875552625, "test_macro_f1_se": 1.3394621247913547}}, "num_model_parameters": 135293186, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.6544628143310547, "test_mcc": 0.2544574196089837, "test_macro_f1": 0.582088824689641, "test_runtime": 3.9292, "test_samples_per_second": 521.224, "test_steps_per_second": 16.288}, {"test_loss": 0.674890398979187, "test_mcc": 0.2868847632753386, "test_macro_f1": 0.6265284145537715, "test_runtime": 3.9617, "test_samples_per_second": 516.952, "test_steps_per_second": 16.155}, {"test_loss": 0.6695735454559326, "test_mcc": 0.23218140375290872, "test_macro_f1": 0.5604166666666667, "test_runtime": 3.9396, "test_samples_per_second": 519.851, "test_steps_per_second": 16.245}, {"test_loss": 0.6732446551322937, "test_mcc": 0.17589431870382685, "test_macro_f1": 0.5541365801003881, "test_runtime": 4.1487, "test_samples_per_second": 493.649, "test_steps_per_second": 15.427}, {"test_loss": 0.6308393478393555, "test_mcc": 0.303118037946048, "test_macro_f1": 0.6432520374701716, "test_runtime": 3.9798, "test_samples_per_second": 514.604, "test_steps_per_second": 16.081}, {"test_loss": 0.6584520936012268, "test_mcc": 0.23150580334018742, "test_macro_f1": 0.5948325320988388, "test_runtime": 3.8395, "test_samples_per_second": 533.408, "test_steps_per_second": 16.669}, {"test_loss": 0.6607875227928162, "test_mcc": 0.2379322831042623, "test_macro_f1": 0.5776455276766161, "test_runtime": 3.9628, "test_samples_per_second": 516.808, "test_steps_per_second": 16.15}, {"test_loss": 0.6710947751998901, "test_mcc": 0.2171001708968061, "test_macro_f1": 0.5833662418476635, "test_runtime": 3.8717, "test_samples_per_second": 528.966, "test_steps_per_second": 16.53}, {"test_loss": 0.6753054857254028, "test_mcc": 0.2602525566944773, "test_macro_f1": 0.5949924024106679, "test_runtime": 3.8702, "test_samples_per_second": 529.165, "test_steps_per_second": 16.536}, {"test_loss": 0.6645427942276001, "test_mcc": 0.2455263009605762, "test_macro_f1": 0.5581926127351008, "test_runtime": 3.9981, "test_samples_per_second": 512.243, "test_steps_per_second": 16.008}]}, "total": {"test_mcc": 24.448530582834152, "test_mcc_se": 2.2061112499455504, "test_macro_f1": 58.75451840249526, "test_macro_f1_se": 1.7999796481623427}}, "num_model_parameters": 135293186, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_loss": 0.67122483253479, "test_mcc": 0.21489386963575088, "test_macro_f1": 0.6014943960149439, "test_runtime": 4.4673, "test_samples_per_second": 458.439, "test_steps_per_second": 14.326}, {"test_loss": 0.6819773316383362, "test_mcc": 0.1605368079288271, "test_macro_f1": 0.5635635635635635, "test_runtime": 4.1589, "test_samples_per_second": 492.434, "test_steps_per_second": 15.389}, {"test_loss": 0.6618355512619019, "test_mcc": 0.2174080883342541, "test_macro_f1": 0.5754471030533009, "test_runtime": 4.2044, "test_samples_per_second": 487.104, "test_steps_per_second": 15.222}, {"test_loss": 0.6536577343940735, "test_mcc": 0.23888875490639638, "test_macro_f1": 0.606676549264159, "test_runtime": 3.9091, "test_samples_per_second": 523.912, "test_steps_per_second": 16.372}, {"test_loss": 0.6575366258621216, "test_mcc": 0.26144928713505833, "test_macro_f1": 0.6286285827721533, "test_runtime": 4.0229, "test_samples_per_second": 509.092, "test_steps_per_second": 15.909}, {"test_loss": 0.6671980023384094, "test_mcc": 0.20656306178833775, "test_macro_f1": 0.6031519212687868, "test_runtime": 4.1629, "test_samples_per_second": 491.962, "test_steps_per_second": 15.374}, {"test_loss": 0.6780897378921509, "test_mcc": 0.1774276080085607, "test_macro_f1": 0.5788324933816804, "test_runtime": 4.0407, "test_samples_per_second": 506.845, "test_steps_per_second": 15.839}, {"test_loss": 0.6698198914527893, "test_mcc": 0.18104715377389063, "test_macro_f1": 0.5455074588085334, "test_runtime": 4.0652, "test_samples_per_second": 503.791, "test_steps_per_second": 15.743}, {"test_loss": 0.6677155494689941, "test_mcc": 0.20753896853942086, "test_macro_f1": 0.5746481701321484, "test_runtime": 4.0223, "test_samples_per_second": 509.156, "test_steps_per_second": 15.911}, {"test_loss": 0.6901779770851135, "test_mcc": 0.05219103747309877, "test_macro_f1": 0.5146913484948177, "test_runtime": 4.1362, "test_samples_per_second": 495.14, "test_steps_per_second": 15.473}]}, "total": {"test_mcc": 19.179446375235955, "test_mcc_se": 3.5493127400955125, "test_macro_f1": 57.92641586754087, "test_macro_f1_se": 2.049929411609142}}, "num_model_parameters": 135293186, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_em": 41.2858249419055, "test_f1": 46.59048761215343}, {"test_em": 38.91472868217054, "test_f1": 43.85511221404735}, {"test_em": 36.321483771251934, "test_f1": 41.536597349171224}, {"test_em": 33.64485981308411, "test_f1": 37.99605262084648}, {"test_em": 40.463320463320464, "test_f1": 45.631987438710105}, {"test_em": 41.017733230531995, "test_f1": 46.21319859727257}, {"test_em": 46.69703872437358, "test_f1": 51.93608726001865}, {"test_em": 34.44530643910008, "test_f1": 39.38392866608997}, {"test_em": 40.94117647058823, "test_f1": 46.72402030879538}, {"test_em": 40.52795031055901, "test_f1": 45.64199070729943}]}, "total": {"test_em": 39.42594228468854, "test_em_se": 2.3698532211568577, "test_f1": 44.55094627744046, "test_f1_se": 2.5115512025960514}}, "num_model_parameters": 134702594, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_em": 31.913245546088305, "test_f1": 36.79501153358031}, {"test_em": 38.29457364341085, "test_f1": 43.217561937826154}, {"test_em": 38.948995363214834, "test_f1": 44.60172898542296}, {"test_em": 33.64485981308411, "test_f1": 38.00930812484661}, {"test_em": 41.15830115830116, "test_f1": 46.55519534090962}, {"test_em": 44.17887432536623, "test_f1": 49.49850763114166}, {"test_em": 42.14123006833713, "test_f1": 48.15297328331422}, {"test_em": 35.29868114817688, "test_f1": 39.876335462895476}, {"test_em": 44.07843137254902, "test_f1": 50.25618896640565}, {"test_em": 41.537267080745345, "test_f1": 47.20584872598338}]}, "total": {"test_em": 39.11944595192738, "test_em_se": 2.666139984334136, "test_f1": 44.416865999232606, "test_f1_se": 2.975849313680214}}, "num_model_parameters": 134702594, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_em": 46.630518977536795, "test_f1": 52.70647445836836}, {"test_em": 49.689922480620154, "test_f1": 55.19362833908516}, {"test_em": 43.81761978361669, "test_f1": 50.75078520902544}, {"test_em": 45.17133956386293, "test_f1": 51.022465094341605}, {"test_em": 46.1003861003861, "test_f1": 52.03113914102703}, {"test_em": 47.49421742482652, "test_f1": 52.75762159028734}, {"test_em": 49.81017463933181, "test_f1": 55.30120954239588}, {"test_em": 47.78898370830101, "test_f1": 53.54241128439092}, {"test_em": 49.490196078431374, "test_f1": 55.160477913528354}, {"test_em": 47.36024844720497, "test_f1": 53.25471234404372}]}, "total": {"test_em": 47.335360720411835, "test_em_se": 1.2331060853724738, "test_f1": 53.17209249164938, "test_f1_se": 1.0307640013642283}}, "num_model_parameters": 134702594, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KBLab/megatron-bert-base-swedish-cased-600k", "results": {"raw": {"test": [{"test_speed": 2.01}, {"test_speed": 1.97}, {"test_speed": 1.96}, {"test_speed": 1.98}, {"test_speed": 2.0}, {"test_speed": 1.98}, {"test_speed": 1.99}, {"test_speed": 1.94}, {"test_speed": 1.97}, {"test_speed": 2.03}]}, "total": {"test_speed": 1.983, "test_speed_se": 0.016016663544918156}}, "num_model_parameters": 135291648, "max_sequence_length": 512, "vocabulary_size": 64128}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "xlm-roberta-large-finetuned-conll02-spanish", "results": {"raw": {"test": [{"test_speed": 0.52}, {"test_speed": 0.53}, {"test_speed": 0.54}, {"test_speed": 0.54}, {"test_speed": 0.55}, {"test_speed": 0.54}, {"test_speed": 0.53}, {"test_speed": 0.53}, {"test_speed": 0.54}, {"test_speed": 0.53}]}, "total": {"test_speed": 0.535, "test_speed_se": 0.005267341728888391}}, "num_model_parameters": 559890432, "max_sequence_length": 512, "vocabulary_size": 250002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "ltgoslo/norbert2", "results": {"raw": {"test": [{"test_speed": 1.4}, {"test_speed": 1.46}, {"test_speed": 1.47}, {"test_speed": 1.44}, {"test_speed": 1.45}, {"test_speed": 1.52}, {"test_speed": 1.52}, {"test_speed": 1.57}, {"test_speed": 1.51}, {"test_speed": 1.59}]}, "total": {"test_speed": 1.4929999999999999, "test_speed_se": 0.03696388868431823}}, "num_model_parameters": 124521216, "max_sequence_length": 512, "vocabulary_size": 50104}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.5323670506477356, "test_mcc": 0.6512896123165518, "test_macro_f1": 0.6684097003863654, "test_runtime": 17.4057, "test_samples_per_second": 117.663, "test_steps_per_second": 14.708}, {"test_loss": 0.6213445067405701, "test_mcc": 0.5878029031513444, "test_macro_f1": 0.5408801588344355, "test_runtime": 16.7393, "test_samples_per_second": 122.347, "test_steps_per_second": 15.293}, {"test_loss": 0.590938150882721, "test_mcc": 0.6019532439359926, "test_macro_f1": 0.5492271352629029, "test_runtime": 17.0015, "test_samples_per_second": 120.46, "test_steps_per_second": 15.058}, {"test_loss": 0.5560789704322815, "test_mcc": 0.6211874393067656, "test_macro_f1": 0.5940679441167123, "test_runtime": 16.8539, "test_samples_per_second": 121.515, "test_steps_per_second": 15.189}, {"test_loss": 0.5269079208374023, "test_mcc": 0.6462150948759408, "test_macro_f1": 0.6270894967304796, "test_runtime": 16.647, "test_samples_per_second": 123.025, "test_steps_per_second": 15.378}, {"test_loss": 0.5458776354789734, "test_mcc": 0.6413695418739565, "test_macro_f1": 0.6241494865132522, "test_runtime": 17.0208, "test_samples_per_second": 120.324, "test_steps_per_second": 15.04}, {"test_loss": 0.5533732771873474, "test_mcc": 0.6148593938619307, "test_macro_f1": 0.6599588969640852, "test_runtime": 16.4942, "test_samples_per_second": 124.165, "test_steps_per_second": 15.521}, {"test_loss": 0.5675100088119507, "test_mcc": 0.6410167900941715, "test_macro_f1": 0.5786975909487796, "test_runtime": 17.4485, "test_samples_per_second": 117.374, "test_steps_per_second": 14.672}, {"test_loss": 0.5716121196746826, "test_mcc": 0.6099790208834406, "test_macro_f1": 0.6019275475605612, "test_runtime": 17.2599, "test_samples_per_second": 118.657, "test_steps_per_second": 14.832}, {"test_loss": 0.5719267129898071, "test_mcc": 0.6433066556146723, "test_macro_f1": 0.5724049072979328, "test_runtime": 16.9475, "test_samples_per_second": 120.844, "test_steps_per_second": 15.105}]}, "total": {"test_mcc": 62.58979695914766, "test_mcc_se": 1.3469711528284503, "test_macro_f1": 60.16812864615506, "test_macro_f1_se": 2.685108884260258}}, "num_model_parameters": 111327747, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.883594274520874, "test_mcc": 0.432382710568404, "test_macro_f1": 0.6209199922884133, "test_runtime": 4.8542, "test_samples_per_second": 421.898, "test_steps_per_second": 13.184}, {"test_loss": 0.898974597454071, "test_mcc": 0.4294863919806522, "test_macro_f1": 0.6077532198161397, "test_runtime": 4.7983, "test_samples_per_second": 426.822, "test_steps_per_second": 13.338}, {"test_loss": 0.9206861257553101, "test_mcc": 0.3906868256389306, "test_macro_f1": 0.5789752246008453, "test_runtime": 4.8108, "test_samples_per_second": 425.709, "test_steps_per_second": 13.303}, {"test_loss": 0.9043861627578735, "test_mcc": 0.3805004218883229, "test_macro_f1": 0.5875550180383342, "test_runtime": 4.7672, "test_samples_per_second": 429.6, "test_steps_per_second": 13.425}, {"test_loss": 0.8977035284042358, "test_mcc": 0.3971940045590192, "test_macro_f1": 0.5990773822204524, "test_runtime": 4.7568, "test_samples_per_second": 430.545, "test_steps_per_second": 13.455}, {"test_loss": 0.8945850133895874, "test_mcc": 0.3894473434253985, "test_macro_f1": 0.5957818717737055, "test_runtime": 4.8388, "test_samples_per_second": 423.245, "test_steps_per_second": 13.226}, {"test_loss": 0.9287931323051453, "test_mcc": 0.39037119913507334, "test_macro_f1": 0.5848820965842243, "test_runtime": 4.786, "test_samples_per_second": 427.918, "test_steps_per_second": 13.372}, {"test_loss": 0.882462203502655, "test_mcc": 0.39294959745278935, "test_macro_f1": 0.5879539166887332, "test_runtime": 4.8147, "test_samples_per_second": 425.36, "test_steps_per_second": 13.292}, {"test_loss": 0.862562894821167, "test_mcc": 0.4095345901999577, "test_macro_f1": 0.6086323986967658, "test_runtime": 4.7757, "test_samples_per_second": 428.84, "test_steps_per_second": 13.401}, {"test_loss": 1.011960506439209, "test_mcc": 0.3932173500535808, "test_macro_f1": 0.5902109986499545, "test_runtime": 4.7526, "test_samples_per_second": 430.921, "test_steps_per_second": 13.466}]}, "total": {"test_mcc": 40.057704349021286, "test_mcc_se": 1.089381786573999, "test_macro_f1": 59.61742119357568, "test_macro_f1_se": 0.8030836793299662}}, "num_model_parameters": 111327747, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.7291301488876343, "test_mcc": 0.47983040823018597, "test_macro_f1": 0.5615248492064798, "test_runtime": 3.541, "test_samples_per_second": 578.374, "test_steps_per_second": 18.074}, {"test_loss": 0.7273789644241333, "test_mcc": 0.5135393069633617, "test_macro_f1": 0.650663601482633, "test_runtime": 3.3176, "test_samples_per_second": 617.309, "test_steps_per_second": 19.291}, {"test_loss": 0.7043187618255615, "test_mcc": 0.5275361727739283, "test_macro_f1": 0.6472381562811889, "test_runtime": 3.3132, "test_samples_per_second": 618.14, "test_steps_per_second": 19.317}, {"test_loss": 0.7623671293258667, "test_mcc": 0.48895002862065023, "test_macro_f1": 0.5860107854116509, "test_runtime": 3.3854, "test_samples_per_second": 604.95, "test_steps_per_second": 18.905}, {"test_loss": 0.7079168558120728, "test_mcc": 0.5283918156624995, "test_macro_f1": 0.6578223152797961, "test_runtime": 3.4147, "test_samples_per_second": 599.753, "test_steps_per_second": 18.742}, {"test_loss": 0.6854901313781738, "test_mcc": 0.5674664365514475, "test_macro_f1": 0.6971466362611108, "test_runtime": 3.5245, "test_samples_per_second": 581.077, "test_steps_per_second": 18.159}, {"test_loss": 0.6517875790596008, "test_mcc": 0.5676066246546712, "test_macro_f1": 0.6902798526423485, "test_runtime": 3.4179, "test_samples_per_second": 599.197, "test_steps_per_second": 18.725}, {"test_loss": 0.677922248840332, "test_mcc": 0.5184781656241345, "test_macro_f1": 0.6388558182458289, "test_runtime": 3.4447, "test_samples_per_second": 594.536, "test_steps_per_second": 18.579}, {"test_loss": 0.7095608711242676, "test_mcc": 0.533849013832332, "test_macro_f1": 0.6601123859915229, "test_runtime": 3.4915, "test_samples_per_second": 586.56, "test_steps_per_second": 18.33}, {"test_loss": 0.6800172328948975, "test_mcc": 0.5398251371664231, "test_macro_f1": 0.6440951799923219, "test_runtime": 3.5124, "test_samples_per_second": 583.073, "test_steps_per_second": 18.221}]}, "total": {"test_mcc": 52.65473110079635, "test_mcc_se": 1.7802082453992802, "test_macro_f1": 64.33749580794881, "test_macro_f1_se": 2.5853687587250476}}, "num_model_parameters": 111327747, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.08091980218887329, "test_micro_f1": 0.5808678500986194, "test_micro_f1_no_misc": 0.6722189173111243, "test_runtime": 8.8839, "test_samples_per_second": 230.53, "test_steps_per_second": 7.204}, {"test_loss": 0.07704302668571472, "test_micro_f1": 0.6008316008316008, "test_micro_f1_no_misc": 0.6966434452184928, "test_runtime": 7.9128, "test_samples_per_second": 258.822, "test_steps_per_second": 8.088}, {"test_loss": 0.0713057890534401, "test_micro_f1": 0.6335227272727273, "test_micro_f1_no_misc": 0.6948704389212058, "test_runtime": 7.9134, "test_samples_per_second": 258.8, "test_steps_per_second": 8.088}, {"test_loss": 0.07138156145811081, "test_micro_f1": 0.6695736434108527, "test_micro_f1_no_misc": 0.7008722421754746, "test_runtime": 8.5987, "test_samples_per_second": 238.176, "test_steps_per_second": 7.443}, {"test_loss": 0.07970401644706726, "test_micro_f1": 0.6319737458977965, "test_micro_f1_no_misc": 0.7070166041778254, "test_runtime": 8.9291, "test_samples_per_second": 229.361, "test_steps_per_second": 7.168}, {"test_loss": 0.07574361562728882, "test_micro_f1": 0.6613283089967028, "test_micro_f1_no_misc": 0.7105263157894736, "test_runtime": 6.7976, "test_samples_per_second": 301.282, "test_steps_per_second": 9.415}, {"test_loss": 0.07875256985425949, "test_micro_f1": 0.6222430783669639, "test_micro_f1_no_misc": 0.6959868059373282, "test_runtime": 7.3433, "test_samples_per_second": 278.894, "test_steps_per_second": 8.715}, {"test_loss": 0.07073095440864563, "test_micro_f1": 0.6514830508474575, "test_micro_f1_no_misc": 0.6943181818181818, "test_runtime": 8.719, "test_samples_per_second": 234.889, "test_steps_per_second": 7.34}, {"test_loss": 0.0728951245546341, "test_micro_f1": 0.6414048059149723, "test_micro_f1_no_misc": 0.682092555331992, "test_runtime": 8.2636, "test_samples_per_second": 247.834, "test_steps_per_second": 7.745}, {"test_loss": 0.07387718558311462, "test_micro_f1": 0.6334975369458128, "test_micro_f1_no_misc": 0.6673640167364016, "test_runtime": 8.6841, "test_samples_per_second": 235.833, "test_steps_per_second": 7.37}]}, "total": {"test_micro_f1": 63.26726348583506, "test_micro_f1_se": 1.6555483477497708, "test_micro_f1_no_misc": 69.219095234175, "test_micro_f1_no_misc_se": 0.875204510617854}}, "num_model_parameters": 110741769, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.07801887392997742, "test_micro_f1": 0.7739423825590448, "test_micro_f1_no_misc": 0.7937716262975777, "test_runtime": 9.1322, "test_samples_per_second": 224.261, "test_steps_per_second": 7.008}, {"test_loss": 0.0740649402141571, "test_micro_f1": 0.7544679681055815, "test_micro_f1_no_misc": 0.7919312663429211, "test_runtime": 7.2237, "test_samples_per_second": 283.51, "test_steps_per_second": 8.86}, {"test_loss": 0.07380778342485428, "test_micro_f1": 0.7698788836229595, "test_micro_f1_no_misc": 0.8040418621436304, "test_runtime": 8.8709, "test_samples_per_second": 230.867, "test_steps_per_second": 7.215}, {"test_loss": 0.083313949406147, "test_micro_f1": 0.7567708333333334, "test_micro_f1_no_misc": 0.7749469214437367, "test_runtime": 8.8351, "test_samples_per_second": 231.804, "test_steps_per_second": 7.244}, {"test_loss": 0.09202234447002411, "test_micro_f1": 0.6935300794551646, "test_micro_f1_no_misc": 0.7304283604135894, "test_runtime": 9.1031, "test_samples_per_second": 224.978, "test_steps_per_second": 7.031}, {"test_loss": 0.07987755537033081, "test_micro_f1": 0.7463087248322148, "test_micro_f1_no_misc": 0.7718518518518518, "test_runtime": 8.7623, "test_samples_per_second": 233.729, "test_steps_per_second": 7.304}, {"test_loss": 0.0775376707315445, "test_micro_f1": 0.7728473322768094, "test_micro_f1_no_misc": 0.7893428063943162, "test_runtime": 9.2169, "test_samples_per_second": 222.2, "test_steps_per_second": 6.944}, {"test_loss": 0.07069015502929688, "test_micro_f1": 0.7891801450083659, "test_micro_f1_no_misc": 0.8211773417252869, "test_runtime": 9.2011, "test_samples_per_second": 222.582, "test_steps_per_second": 6.956}, {"test_loss": 0.07544100284576416, "test_micro_f1": 0.7821199143468951, "test_micro_f1_no_misc": 0.8005886681383371, "test_runtime": 8.7884, "test_samples_per_second": 233.035, "test_steps_per_second": 7.282}, {"test_loss": 0.07386980950832367, "test_micro_f1": 0.8009841443411699, "test_micro_f1_no_misc": 0.8225331369661266, "test_runtime": 7.2859, "test_samples_per_second": 281.09, "test_steps_per_second": 8.784}]}, "total": {"test_micro_f1": 76.40030407881537, "test_micro_f1_se": 1.8437428719253537, "test_micro_f1_no_misc": 79.00613841717374, "test_micro_f1_no_misc_se": 1.6609071429775093}}, "num_model_parameters": 110741769, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.03829224407672882, "test_micro_f1": 0.8657047724750278, "test_micro_f1_no_misc": 0.8924731182795698, "test_runtime": 5.7773, "test_samples_per_second": 354.49, "test_steps_per_second": 11.078}, {"test_loss": 0.033558472990989685, "test_micro_f1": 0.882660687593423, "test_micro_f1_no_misc": 0.9041322314049587, "test_runtime": 5.7741, "test_samples_per_second": 354.69, "test_steps_per_second": 11.084}, {"test_loss": 0.042915746569633484, "test_micro_f1": 0.8680057388809181, "test_micro_f1_no_misc": 0.9036860879904874, "test_runtime": 5.3509, "test_samples_per_second": 382.737, "test_steps_per_second": 11.961}, {"test_loss": 0.03586737811565399, "test_micro_f1": 0.8719747457032622, "test_micro_f1_no_misc": 0.8989819890368049, "test_runtime": 5.2978, "test_samples_per_second": 386.573, "test_steps_per_second": 12.08}, {"test_loss": 0.032313719391822815, "test_micro_f1": 0.8963660834454913, "test_micro_f1_no_misc": 0.9166666666666667, "test_runtime": 5.8211, "test_samples_per_second": 351.822, "test_steps_per_second": 10.994}, {"test_loss": 0.03560297191143036, "test_micro_f1": 0.8774811772758385, "test_micro_f1_no_misc": 0.9032009255688391, "test_runtime": 5.7962, "test_samples_per_second": 353.335, "test_steps_per_second": 11.042}, {"test_loss": 0.03195072337985039, "test_micro_f1": 0.8955017301038063, "test_micro_f1_no_misc": 0.9226030034655373, "test_runtime": 5.3147, "test_samples_per_second": 385.344, "test_steps_per_second": 12.042}, {"test_loss": 0.033369824290275574, "test_micro_f1": 0.8872600349040138, "test_micro_f1_no_misc": 0.9163828982217178, "test_runtime": 5.2482, "test_samples_per_second": 390.229, "test_steps_per_second": 12.195}, {"test_loss": 0.03399176523089409, "test_micro_f1": 0.8851744186046512, "test_micro_f1_no_misc": 0.9048197650870797, "test_runtime": 5.3108, "test_samples_per_second": 385.63, "test_steps_per_second": 12.051}, {"test_loss": 0.043168678879737854, "test_micro_f1": 0.8589125946317963, "test_micro_f1_no_misc": 0.8920972644376899, "test_runtime": 5.847, "test_samples_per_second": 350.264, "test_steps_per_second": 10.946}]}, "total": {"test_micro_f1": 87.89041983618228, "test_micro_f1_se": 0.7857267514078894, "test_micro_f1_no_misc": 90.55043950159349, "test_micro_f1_no_misc_se": 0.6328812104424414}}, "num_model_parameters": 110741769, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.04883753880858421, "test_micro_f1": 0.8249459709786972, "test_micro_f1_no_misc": 0.8645937813440321, "test_runtime": 5.6632, "test_samples_per_second": 361.631, "test_steps_per_second": 11.301}, {"test_loss": 0.042478177696466446, "test_micro_f1": 0.8702522029778184, "test_micro_f1_no_misc": 0.9008152173913043, "test_runtime": 5.8913, "test_samples_per_second": 347.633, "test_steps_per_second": 10.864}, {"test_loss": 0.05529692769050598, "test_micro_f1": 0.7984565152864351, "test_micro_f1_no_misc": 0.8373633653527658, "test_runtime": 5.6655, "test_samples_per_second": 361.486, "test_steps_per_second": 11.296}, {"test_loss": 0.05412723869085312, "test_micro_f1": 0.7918293781916491, "test_micro_f1_no_misc": 0.8312646762831265, "test_runtime": 5.7245, "test_samples_per_second": 357.762, "test_steps_per_second": 11.18}, {"test_loss": 0.052743639796972275, "test_micro_f1": 0.818978543366576, "test_micro_f1_no_misc": 0.8568435754189945, "test_runtime": 5.5425, "test_samples_per_second": 369.506, "test_steps_per_second": 11.547}, {"test_loss": 0.04578070342540741, "test_micro_f1": 0.8403461653237839, "test_micro_f1_no_misc": 0.8725687458081824, "test_runtime": 5.5506, "test_samples_per_second": 368.97, "test_steps_per_second": 11.53}, {"test_loss": 0.04412183165550232, "test_micro_f1": 0.8472049689440994, "test_micro_f1_no_misc": 0.8819175185054635, "test_runtime": 5.9248, "test_samples_per_second": 345.667, "test_steps_per_second": 10.802}, {"test_loss": 0.05136534571647644, "test_micro_f1": 0.7895535985423626, "test_micro_f1_no_misc": 0.8271806599150604, "test_runtime": 5.9652, "test_samples_per_second": 343.326, "test_steps_per_second": 10.729}, {"test_loss": 0.051443200558423996, "test_micro_f1": 0.8228395061728395, "test_micro_f1_no_misc": 0.8545326774420238, "test_runtime": 5.2771, "test_samples_per_second": 388.092, "test_steps_per_second": 12.128}, {"test_loss": 0.049432508647441864, "test_micro_f1": 0.8174916489523231, "test_micro_f1_no_misc": 0.8449483161053684, "test_runtime": 5.4501, "test_samples_per_second": 375.775, "test_steps_per_second": 11.743}]}, "total": {"test_micro_f1": 82.21898498736584, "test_micro_f1_se": 1.5810067194049162, "test_micro_f1_no_misc": 85.72028533566322, "test_micro_f1_no_misc_se": 1.4504512730981491}}, "num_model_parameters": 110741769, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.6530805826187134, "test_mcc": 0.2637927577793519, "test_macro_f1": 0.6178864382283706, "test_runtime": 3.9337, "test_samples_per_second": 520.636, "test_steps_per_second": 16.27}, {"test_loss": 0.6598288416862488, "test_mcc": 0.23476103884477584, "test_macro_f1": 0.611187211319866, "test_runtime": 4.178, "test_samples_per_second": 490.181, "test_steps_per_second": 15.318}, {"test_loss": 0.6823898553848267, "test_mcc": 0.15817780877037096, "test_macro_f1": 0.5674220005384997, "test_runtime": 4.1717, "test_samples_per_second": 490.929, "test_steps_per_second": 15.342}, {"test_loss": 0.6479360461235046, "test_mcc": 0.24013755209793236, "test_macro_f1": 0.6196215604177461, "test_runtime": 4.0793, "test_samples_per_second": 502.045, "test_steps_per_second": 15.689}, {"test_loss": 0.6316192150115967, "test_mcc": 0.30734439235922273, "test_macro_f1": 0.651640769833534, "test_runtime": 4.1605, "test_samples_per_second": 492.244, "test_steps_per_second": 15.383}, {"test_loss": 0.6475845575332642, "test_mcc": 0.26428300586816933, "test_macro_f1": 0.6315984349651684, "test_runtime": 4.0883, "test_samples_per_second": 500.939, "test_steps_per_second": 15.654}, {"test_loss": 0.6625286936759949, "test_mcc": 0.1883213491749273, "test_macro_f1": 0.5826980686447727, "test_runtime": 4.1539, "test_samples_per_second": 493.031, "test_steps_per_second": 15.407}, {"test_loss": 0.6586676239967346, "test_mcc": 0.22985391076888248, "test_macro_f1": 0.6008301780411105, "test_runtime": 4.0805, "test_samples_per_second": 501.903, "test_steps_per_second": 15.684}, {"test_loss": 0.6862449645996094, "test_mcc": 0.12866689027847872, "test_macro_f1": 0.4603476399380563, "test_runtime": 4.082, "test_samples_per_second": 501.717, "test_steps_per_second": 15.679}, {"test_loss": 0.6409159898757935, "test_mcc": 0.27135745368689035, "test_macro_f1": 0.6356296005159064, "test_runtime": 4.0988, "test_samples_per_second": 499.661, "test_steps_per_second": 15.614}]}, "total": {"test_mcc": 22.866961596290018, "test_mcc_se": 3.412474814031033, "test_macro_f1": 59.788619024430304, "test_macro_f1_se": 3.368581500828737}}, "num_model_parameters": 111326978, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.5770600438117981, "test_mcc": 0.4414229564640501, "test_macro_f1": 0.7186953209052656, "test_runtime": 4.0839, "test_samples_per_second": 501.478, "test_steps_per_second": 15.671}, {"test_loss": 0.6780046820640564, "test_mcc": 0.17145364684257075, "test_macro_f1": 0.5834534594026715, "test_runtime": 4.1523, "test_samples_per_second": 493.219, "test_steps_per_second": 15.413}, {"test_loss": 0.5998332500457764, "test_mcc": 0.3706909837937279, "test_macro_f1": 0.6673767314637931, "test_runtime": 4.3551, "test_samples_per_second": 470.251, "test_steps_per_second": 14.695}, {"test_loss": 0.678545355796814, "test_mcc": 0.18398222446838133, "test_macro_f1": 0.5167372289285677, "test_runtime": 4.4686, "test_samples_per_second": 458.307, "test_steps_per_second": 14.322}, {"test_loss": 0.6548745632171631, "test_mcc": 0.26500346019387905, "test_macro_f1": 0.6071481106009105, "test_runtime": 4.3779, "test_samples_per_second": 467.807, "test_steps_per_second": 14.619}, {"test_loss": 0.590586245059967, "test_mcc": 0.42672574158684995, "test_macro_f1": 0.7075761570587717, "test_runtime": 4.4144, "test_samples_per_second": 463.933, "test_steps_per_second": 14.498}, {"test_loss": 0.621972918510437, "test_mcc": 0.3439259775534685, "test_macro_f1": 0.6643997554965226, "test_runtime": 4.2945, "test_samples_per_second": 476.891, "test_steps_per_second": 14.903}, {"test_loss": 0.5951959490776062, "test_mcc": 0.3542433254524145, "test_macro_f1": 0.6769002927336887, "test_runtime": 4.3017, "test_samples_per_second": 476.087, "test_steps_per_second": 14.878}, {"test_loss": 0.5800295472145081, "test_mcc": 0.431159347283715, "test_macro_f1": 0.7126233172616221, "test_runtime": 4.3074, "test_samples_per_second": 475.466, "test_steps_per_second": 14.858}, {"test_loss": 0.5934567451477051, "test_mcc": 0.3843826368311888, "test_macro_f1": 0.6850143078819353, "test_runtime": 4.3866, "test_samples_per_second": 466.872, "test_steps_per_second": 14.59}]}, "total": {"test_mcc": 33.72990300470246, "test_mcc_se": 6.113084172303357, "test_macro_f1": 65.39924681733747, "test_macro_f1_se": 4.042173213170665}}, "num_model_parameters": 111326978, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.41756850481033325, "test_mcc": 0.657552749397962, "test_macro_f1": 0.8153441515458726, "test_runtime": 3.3294, "test_samples_per_second": 615.129, "test_steps_per_second": 19.223}, {"test_loss": 0.4436715245246887, "test_mcc": 0.6434263070617383, "test_macro_f1": 0.8081693350586145, "test_runtime": 3.3022, "test_samples_per_second": 620.195, "test_steps_per_second": 19.381}, {"test_loss": 0.40634921193122864, "test_mcc": 0.6776396057480276, "test_macro_f1": 0.8235460037062887, "test_runtime": 3.2954, "test_samples_per_second": 621.465, "test_steps_per_second": 19.421}, {"test_loss": 0.4522554278373718, "test_mcc": 0.7043190375522607, "test_macro_f1": 0.8463336575117527, "test_runtime": 3.4072, "test_samples_per_second": 601.079, "test_steps_per_second": 18.784}, {"test_loss": 0.44688886404037476, "test_mcc": 0.6525864928351301, "test_macro_f1": 0.8083322366015939, "test_runtime": 3.3934, "test_samples_per_second": 603.53, "test_steps_per_second": 18.86}, {"test_loss": 0.4330417513847351, "test_mcc": 0.7122541851218616, "test_macro_f1": 0.8490885903299261, "test_runtime": 3.2747, "test_samples_per_second": 625.408, "test_steps_per_second": 19.544}, {"test_loss": 0.4905976951122284, "test_mcc": 0.5648142635156911, "test_macro_f1": 0.7551293701276962, "test_runtime": 3.2614, "test_samples_per_second": 627.955, "test_steps_per_second": 19.624}, {"test_loss": 0.41497451066970825, "test_mcc": 0.6677035847727365, "test_macro_f1": 0.8229385808030893, "test_runtime": 3.2732, "test_samples_per_second": 625.685, "test_steps_per_second": 19.553}, {"test_loss": 0.43012142181396484, "test_mcc": 0.7011739072188179, "test_macro_f1": 0.8421957408366878, "test_runtime": 3.0523, "test_samples_per_second": 670.979, "test_steps_per_second": 20.968}, {"test_loss": 0.4067097306251526, "test_mcc": 0.7032673610324586, "test_macro_f1": 0.8410157625369068, "test_runtime": 3.0777, "test_samples_per_second": 665.433, "test_steps_per_second": 20.795}]}, "total": {"test_mcc": 66.84737494256684, "test_mcc_se": 2.7182474568684825, "test_macro_f1": 82.12093429058429, "test_macro_f1_se": 1.7268876670629103}}, "num_model_parameters": 111326978, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_loss": 0.45325997471809387, "test_mcc": 0.5939521343633912, "test_macro_f1": 0.7886124870614148, "test_runtime": 3.3713, "test_samples_per_second": 607.481, "test_steps_per_second": 18.984}, {"test_loss": 0.464773952960968, "test_mcc": 0.6065244255599248, "test_macro_f1": 0.794011773175793, "test_runtime": 3.4319, "test_samples_per_second": 596.755, "test_steps_per_second": 18.649}, {"test_loss": 0.6872829794883728, "test_mcc": 0.07809928486916176, "test_macro_f1": 0.5305461739310817, "test_runtime": 3.3691, "test_samples_per_second": 607.883, "test_steps_per_second": 18.996}, {"test_loss": 0.4857012629508972, "test_mcc": 0.572864293628936, "test_macro_f1": 0.7747230220082413, "test_runtime": 3.2129, "test_samples_per_second": 637.434, "test_steps_per_second": 19.92}, {"test_loss": 0.4723972976207733, "test_mcc": 0.6039257835057196, "test_macro_f1": 0.7924799949846222, "test_runtime": 3.2843, "test_samples_per_second": 623.574, "test_steps_per_second": 19.487}, {"test_loss": 0.44715699553489685, "test_mcc": 0.6272646574837331, "test_macro_f1": 0.8071450761105934, "test_runtime": 3.368, "test_samples_per_second": 608.08, "test_steps_per_second": 19.002}, {"test_loss": 0.47628575563430786, "test_mcc": 0.589917159670894, "test_macro_f1": 0.7824600706850268, "test_runtime": 3.3632, "test_samples_per_second": 608.942, "test_steps_per_second": 19.029}, {"test_loss": 0.4622882008552551, "test_mcc": 0.6243856834248105, "test_macro_f1": 0.8101833384169057, "test_runtime": 3.3152, "test_samples_per_second": 617.752, "test_steps_per_second": 19.305}, {"test_loss": 0.4287862777709961, "test_mcc": 0.6016128576420249, "test_macro_f1": 0.7999392763322904, "test_runtime": 3.2427, "test_samples_per_second": 631.568, "test_steps_per_second": 19.736}, {"test_loss": 0.45745983719825745, "test_mcc": 0.5873898086401519, "test_macro_f1": 0.786933154709102, "test_runtime": 3.3952, "test_samples_per_second": 603.201, "test_steps_per_second": 18.85}]}, "total": {"test_mcc": 54.85936088788749, "test_mcc_se": 10.296715612672179, "test_macro_f1": 76.67034367415071, "test_macro_f1_se": 5.186203921036084}}, "num_model_parameters": 111326978, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_em": 34.08210689388071, "test_f1": 38.40663399285487}, {"test_em": 30.0, "test_f1": 34.764038704641536}, {"test_em": 30.757341576506956, "test_f1": 34.2997367061337}, {"test_em": 36.21495327102804, "test_f1": 40.158268483946266}, {"test_em": 32.972972972972975, "test_f1": 37.223139983644195}, {"test_em": 37.62528912875867, "test_f1": 41.83711200557649}, {"test_em": 34.62414578587699, "test_f1": 38.129703518448174}, {"test_em": 27.385570209464703, "test_f1": 32.311285655917665}, {"test_em": 38.90196078431372, "test_f1": 43.00763102010598}, {"test_em": 31.366459627329192, "test_f1": 35.7986059831914}]}, "total": {"test_em": 33.39308002501319, "test_em_se": 2.235188581737415, "test_f1": 37.59361560544603, "test_f1_se": 2.1166701683099167}}, "num_model_parameters": 110736386, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_em": 39.11696359411309, "test_f1": 44.368391781592635}, {"test_em": 43.17829457364341, "test_f1": 48.68898051373608}, {"test_em": 36.78516228748068, "test_f1": 41.712756075655065}, {"test_em": 37.38317757009346, "test_f1": 42.11856057994157}, {"test_em": 37.22007722007722, "test_f1": 42.747662243404804}, {"test_em": 35.92906707787201, "test_f1": 40.69088321649603}, {"test_em": 36.75018982536067, "test_f1": 42.4876089849619}, {"test_em": 37.78122575640031, "test_f1": 42.62541424644792}, {"test_em": 37.254901960784316, "test_f1": 42.84990558414565}, {"test_em": 35.40372670807454, "test_f1": 40.87518970185934}]}, "total": {"test_em": 37.68027865738997, "test_em_se": 1.3500333362465287, "test_f1": 42.91653529282409, "test_f1_se": 1.4154457995443943}}, "num_model_parameters": 110736386, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_em": 36.018590240123935, "test_f1": 40.84888499676038}, {"test_em": 37.98449612403101, "test_f1": 42.85828709973716}, {"test_em": 32.38021638330758, "test_f1": 37.64675959393422}, {"test_em": 34.50155763239876, "test_f1": 39.347341766434106}, {"test_em": 32.8957528957529, "test_f1": 37.58405207985041}, {"test_em": 36.85427910562837, "test_f1": 41.30340114579766}, {"test_em": 21.716021260440396, "test_f1": 26.826224364518552}, {"test_em": 33.514352211016295, "test_f1": 37.926206863998985}, {"test_em": 34.35294117647059, "test_f1": 39.40742821125267}, {"test_em": 37.03416149068323, "test_f1": 41.26329505905068}]}, "total": {"test_em": 33.72523685198531, "test_em_se": 2.862019033600515, "test_f1": 38.501188118133484, "test_f1_se": 2.76971295373656}}, "num_model_parameters": 110736386, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "ltgoslo/norbert", "results": {"raw": {"test": [{"test_speed": 1.55}, {"test_speed": 1.65}, {"test_speed": 1.59}, {"test_speed": 1.65}, {"test_speed": 1.61}, {"test_speed": 1.64}, {"test_speed": 1.59}, {"test_speed": 1.6}, {"test_speed": 1.62}, {"test_speed": 1.64}]}, "total": {"test_speed": 1.614, "test_speed_se": 0.020073394221096587}}, "num_model_parameters": 111325440, "max_sequence_length": 512, "vocabulary_size": 32922}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.6491849422454834, "test_mcc": 0.5832872621299628, "test_macro_f1": 0.5390490114174323, "test_runtime": 19.306, "test_samples_per_second": 106.081, "test_steps_per_second": 13.26}, {"test_loss": 0.6758764982223511, "test_mcc": 0.5308863646556945, "test_macro_f1": 0.5163905544195289, "test_runtime": 18.5874, "test_samples_per_second": 110.182, "test_steps_per_second": 13.773}, {"test_loss": 0.6853536367416382, "test_mcc": 0.5860902514091024, "test_macro_f1": 0.5407498148059737, "test_runtime": 18.8197, "test_samples_per_second": 108.822, "test_steps_per_second": 13.603}, {"test_loss": 0.760913610458374, "test_mcc": 0.46276839980347856, "test_macro_f1": 0.48581720402830975, "test_runtime": 18.9013, "test_samples_per_second": 108.352, "test_steps_per_second": 13.544}, {"test_loss": 0.6866938471794128, "test_mcc": 0.5385120815665818, "test_macro_f1": 0.5211591069176208, "test_runtime": 18.7225, "test_samples_per_second": 109.387, "test_steps_per_second": 13.673}, {"test_loss": 0.7117565870285034, "test_mcc": 0.5516489100867995, "test_macro_f1": 0.5261435354910035, "test_runtime": 19.0619, "test_samples_per_second": 107.439, "test_steps_per_second": 13.43}, {"test_loss": 0.6536270380020142, "test_mcc": 0.6178080351046759, "test_macro_f1": 0.551738515374879, "test_runtime": 18.6245, "test_samples_per_second": 109.963, "test_steps_per_second": 13.745}, {"test_loss": 0.7478624582290649, "test_mcc": 0.4999848369936136, "test_macro_f1": 0.49811076867436793, "test_runtime": 19.0918, "test_samples_per_second": 107.271, "test_steps_per_second": 13.409}, {"test_loss": 0.678650975227356, "test_mcc": 0.5740324105424066, "test_macro_f1": 0.5349751118205778, "test_runtime": 19.1411, "test_samples_per_second": 106.995, "test_steps_per_second": 13.374}, {"test_loss": 0.6501655578613281, "test_mcc": 0.5642982747230205, "test_macro_f1": 0.5301358504775767, "test_runtime": 18.9053, "test_samples_per_second": 108.329, "test_steps_per_second": 13.541}]}, "total": {"test_mcc": 55.093168270153356, "test_mcc_se": 2.8019307046010167, "test_macro_f1": 52.4426947342727, "test_macro_f1_se": 1.2450209880546799}}, "num_model_parameters": 124444419, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.9958999156951904, "test_mcc": 0.25044348423815505, "test_macro_f1": 0.4882259623083252, "test_runtime": 5.9515, "test_samples_per_second": 344.117, "test_steps_per_second": 10.754}, {"test_loss": 0.9960809350013733, "test_mcc": 0.26430345653482357, "test_macro_f1": 0.4935157173680272, "test_runtime": 5.9048, "test_samples_per_second": 346.837, "test_steps_per_second": 10.839}, {"test_loss": 1.0595728158950806, "test_mcc": 0.19154774757042464, "test_macro_f1": 0.3589412182889058, "test_runtime": 5.9754, "test_samples_per_second": 342.737, "test_steps_per_second": 10.711}, {"test_loss": 1.063905119895935, "test_mcc": 0.26757983748507835, "test_macro_f1": 0.5134778543651964, "test_runtime": 5.9001, "test_samples_per_second": 347.113, "test_steps_per_second": 10.847}, {"test_loss": 1.0356762409210205, "test_mcc": 0.18014217327112245, "test_macro_f1": 0.3634644018114305, "test_runtime": 6.017, "test_samples_per_second": 340.368, "test_steps_per_second": 10.636}, {"test_loss": 1.0498650074005127, "test_mcc": 0.18715037946061597, "test_macro_f1": 0.39405109484289763, "test_runtime": 5.9615, "test_samples_per_second": 343.538, "test_steps_per_second": 10.736}, {"test_loss": 1.0237467288970947, "test_mcc": 0.2551613601866399, "test_macro_f1": 0.4753607036371014, "test_runtime": 5.9444, "test_samples_per_second": 344.525, "test_steps_per_second": 10.766}, {"test_loss": 1.0378104448318481, "test_mcc": 0.2439749398430332, "test_macro_f1": 0.4692798201980522, "test_runtime": 6.077, "test_samples_per_second": 337.006, "test_steps_per_second": 10.531}, {"test_loss": 0.9987737536430359, "test_mcc": 0.2588204648989739, "test_macro_f1": 0.49445263211764917, "test_runtime": 5.9586, "test_samples_per_second": 343.706, "test_steps_per_second": 10.741}, {"test_loss": 1.0286908149719238, "test_mcc": 0.17092836882245432, "test_macro_f1": 0.3612776332987699, "test_runtime": 5.8169, "test_samples_per_second": 352.076, "test_steps_per_second": 11.002}]}, "total": {"test_mcc": 22.700522123113213, "test_mcc_se": 2.432836374715879, "test_macro_f1": 44.12047038236356, "test_macro_f1_se": 3.940833370633401}}, "num_model_parameters": 124444419, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.9819560647010803, "test_mcc": 0.0697357152370234, "test_macro_f1": 0.2667586236393576, "test_runtime": 4.8893, "test_samples_per_second": 418.873, "test_steps_per_second": 13.09}, {"test_loss": 0.9680371284484863, "test_mcc": 0.15856637032317486, "test_macro_f1": 0.36739592466351584, "test_runtime": 4.5902, "test_samples_per_second": 446.166, "test_steps_per_second": 13.943}, {"test_loss": 0.9263041615486145, "test_mcc": 0.24893592704082856, "test_macro_f1": 0.40289974653257027, "test_runtime": 4.5059, "test_samples_per_second": 454.513, "test_steps_per_second": 14.204}, {"test_loss": 0.9817181825637817, "test_mcc": 0.2019913381547046, "test_macro_f1": 0.3805786898643147, "test_runtime": 4.6314, "test_samples_per_second": 442.198, "test_steps_per_second": 13.819}, {"test_loss": 0.9732826352119446, "test_mcc": 0.152010567683322, "test_macro_f1": 0.3586641203207919, "test_runtime": 4.7104, "test_samples_per_second": 434.785, "test_steps_per_second": 13.587}, {"test_loss": 0.9630251526832581, "test_mcc": 0.04252539482173418, "test_macro_f1": 0.25061198824460457, "test_runtime": 4.8212, "test_samples_per_second": 424.79, "test_steps_per_second": 13.275}, {"test_loss": 0.9636411666870117, "test_mcc": 0.07494113486767216, "test_macro_f1": 0.3321936029415258, "test_runtime": 4.5746, "test_samples_per_second": 447.686, "test_steps_per_second": 13.99}, {"test_loss": 0.929184079170227, "test_mcc": 0.23827055619205179, "test_macro_f1": 0.40345021756718813, "test_runtime": 4.7074, "test_samples_per_second": 435.063, "test_steps_per_second": 13.596}, {"test_loss": 0.9745023250579834, "test_mcc": 0.0, "test_macro_f1": 0.21695212999560828, "test_runtime": 4.8691, "test_samples_per_second": 420.609, "test_steps_per_second": 13.144}, {"test_loss": 0.9517430663108826, "test_mcc": 0.22590363038773184, "test_macro_f1": 0.39158131257669204, "test_runtime": 4.8298, "test_samples_per_second": 424.033, "test_steps_per_second": 13.251}]}, "total": {"test_mcc": 14.128806347082435, "test_mcc_se": 5.524044225132144, "test_macro_f1": 33.71086356346169, "test_macro_f1_se": 4.227076274919272}}, "num_model_parameters": 124444419, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.08772130310535431, "test_micro_f1": 0.562564632885212, "test_micro_f1_no_misc": 0.6044444444444445, "test_runtime": 10.089, "test_samples_per_second": 202.994, "test_steps_per_second": 6.344}, {"test_loss": 0.07752818614244461, "test_micro_f1": 0.5995762711864406, "test_micro_f1_no_misc": 0.6419612314709235, "test_runtime": 9.2985, "test_samples_per_second": 220.25, "test_steps_per_second": 6.883}, {"test_loss": 0.07615511119365692, "test_micro_f1": 0.6068499758803667, "test_micro_f1_no_misc": 0.650893796004206, "test_runtime": 9.6393, "test_samples_per_second": 212.464, "test_steps_per_second": 6.639}, {"test_loss": 0.0781388059258461, "test_micro_f1": 0.5851223165252122, "test_micro_f1_no_misc": 0.6183574879227053, "test_runtime": 9.9057, "test_samples_per_second": 206.749, "test_steps_per_second": 6.461}, {"test_loss": 0.0833887904882431, "test_micro_f1": 0.6061776061776062, "test_micro_f1_no_misc": 0.6432264736297828, "test_runtime": 9.4229, "test_samples_per_second": 217.343, "test_steps_per_second": 6.792}, {"test_loss": 0.07457248121500015, "test_micro_f1": 0.5908872901678657, "test_micro_f1_no_misc": 0.6513614522156967, "test_runtime": 7.9033, "test_samples_per_second": 259.131, "test_steps_per_second": 8.098}, {"test_loss": 0.09321795403957367, "test_micro_f1": 0.5897435897435898, "test_micro_f1_no_misc": 0.6265060240963856, "test_runtime": 8.9414, "test_samples_per_second": 229.046, "test_steps_per_second": 7.158}, {"test_loss": 0.06990346312522888, "test_micro_f1": 0.625879805089334, "test_micro_f1_no_misc": 0.6654991243432574, "test_runtime": 9.4958, "test_samples_per_second": 215.673, "test_steps_per_second": 6.74}, {"test_loss": 0.0795350894331932, "test_micro_f1": 0.5733722060252673, "test_micro_f1_no_misc": 0.6057494866529773, "test_runtime": 9.261, "test_samples_per_second": 221.142, "test_steps_per_second": 6.911}, {"test_loss": 0.0799727588891983, "test_micro_f1": 0.6032350142721219, "test_micro_f1_no_misc": 0.6430020283975659, "test_runtime": 9.9118, "test_samples_per_second": 206.622, "test_steps_per_second": 6.457}]}, "total": {"test_micro_f1": 59.434087079530165, "test_micro_f1_se": 1.1250361584144812, "test_micro_f1_no_misc": 63.510015491779455, "test_micro_f1_no_misc_se": 1.2683634295340296}}, "num_model_parameters": 123858441, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.0956043004989624, "test_micro_f1": 0.7002372791985236, "test_micro_f1_no_misc": 0.7408906882591093, "test_runtime": 11.0128, "test_samples_per_second": 185.966, "test_steps_per_second": 5.811}, {"test_loss": 0.0944216325879097, "test_micro_f1": 0.656241114586295, "test_micro_f1_no_misc": 0.6971955981540646, "test_runtime": 8.495, "test_samples_per_second": 241.084, "test_steps_per_second": 7.534}, {"test_loss": 0.09966333955526352, "test_micro_f1": 0.689989235737352, "test_micro_f1_no_misc": 0.719798052650559, "test_runtime": 10.9296, "test_samples_per_second": 187.381, "test_steps_per_second": 5.856}, {"test_loss": 0.10016188770532608, "test_micro_f1": 0.6887139107611548, "test_micro_f1_no_misc": 0.7181599725369036, "test_runtime": 10.4801, "test_samples_per_second": 195.417, "test_steps_per_second": 6.107}, {"test_loss": 0.10269585251808167, "test_micro_f1": 0.6339410939691443, "test_micro_f1_no_misc": 0.6842900302114804, "test_runtime": 10.9819, "test_samples_per_second": 186.488, "test_steps_per_second": 5.828}, {"test_loss": 0.10384421050548553, "test_micro_f1": 0.668887038578962, "test_micro_f1_no_misc": 0.7133479212253829, "test_runtime": 11.0266, "test_samples_per_second": 185.733, "test_steps_per_second": 5.804}, {"test_loss": 0.1089470311999321, "test_micro_f1": 0.6804123711340206, "test_micro_f1_no_misc": 0.7044070225725547, "test_runtime": 11.02, "test_samples_per_second": 185.845, "test_steps_per_second": 5.808}, {"test_loss": 0.09034720063209534, "test_micro_f1": 0.6865671641791044, "test_micro_f1_no_misc": 0.7391304347826086, "test_runtime": 10.8005, "test_samples_per_second": 189.621, "test_steps_per_second": 5.926}, {"test_loss": 0.0951775461435318, "test_micro_f1": 0.6873115922170457, "test_micro_f1_no_misc": 0.7081824764663288, "test_runtime": 10.5166, "test_samples_per_second": 194.739, "test_steps_per_second": 6.086}, {"test_loss": 0.10023707151412964, "test_micro_f1": 0.6934564213956014, "test_micro_f1_no_misc": 0.7259936686598664, "test_runtime": 8.6823, "test_samples_per_second": 235.883, "test_steps_per_second": 7.371}]}, "total": {"test_micro_f1": 67.85757221757204, "test_micro_f1_se": 1.2485705276544088, "test_micro_f1_no_misc": 71.51395865518857, "test_micro_f1_no_misc_se": 1.098648797991385}}, "num_model_parameters": 123858441, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.06866739690303802, "test_micro_f1": 0.7272064186725018, "test_micro_f1_no_misc": 0.7711038961038961, "test_runtime": 8.7387, "test_samples_per_second": 234.361, "test_steps_per_second": 7.324}, {"test_loss": 0.05899681895971298, "test_micro_f1": 0.7080882352941177, "test_micro_f1_no_misc": 0.7501009285425918, "test_runtime": 8.6325, "test_samples_per_second": 237.243, "test_steps_per_second": 7.414}, {"test_loss": 0.07749335467815399, "test_micro_f1": 0.686962276637988, "test_micro_f1_no_misc": 0.7221613727637824, "test_runtime": 8.4038, "test_samples_per_second": 243.698, "test_steps_per_second": 7.616}, {"test_loss": 0.06160995364189148, "test_micro_f1": 0.7511126326600479, "test_micro_f1_no_misc": 0.7740458015267176, "test_runtime": 8.5605, "test_samples_per_second": 239.238, "test_steps_per_second": 7.476}, {"test_loss": 0.06087430194020271, "test_micro_f1": 0.7238095238095239, "test_micro_f1_no_misc": 0.7615632843313015, "test_runtime": 8.7275, "test_samples_per_second": 234.661, "test_steps_per_second": 7.333}, {"test_loss": 0.06595797091722488, "test_micro_f1": 0.7220553887220553, "test_micro_f1_no_misc": 0.7638888888888888, "test_runtime": 8.7831, "test_samples_per_second": 233.176, "test_steps_per_second": 7.287}, {"test_loss": 0.06878054141998291, "test_micro_f1": 0.7109004739336492, "test_micro_f1_no_misc": 0.7489803485354096, "test_runtime": 8.1197, "test_samples_per_second": 252.226, "test_steps_per_second": 7.882}, {"test_loss": 0.06514847278594971, "test_micro_f1": 0.7353041114509006, "test_micro_f1_no_misc": 0.7757712565838977, "test_runtime": 8.3327, "test_samples_per_second": 245.779, "test_steps_per_second": 7.681}, {"test_loss": 0.06765006482601166, "test_micro_f1": 0.6914185639229421, "test_micro_f1_no_misc": 0.7266409266409267, "test_runtime": 8.3237, "test_samples_per_second": 246.044, "test_steps_per_second": 7.689}, {"test_loss": 0.07049603760242462, "test_micro_f1": 0.7139431312093183, "test_micro_f1_no_misc": 0.7560884226301986, "test_runtime": 7.8807, "test_samples_per_second": 259.874, "test_steps_per_second": 8.121}]}, "total": {"test_micro_f1": 71.70800756313044, "test_micro_f1_se": 1.197114300501956, "test_micro_f1_no_misc": 75.5034512654761, "test_micro_f1_no_misc_se": 1.1539491581142407}}, "num_model_parameters": 123858441, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.0787120908498764, "test_micro_f1": 0.6668744157058274, "test_micro_f1_no_misc": 0.7084450402144773, "test_runtime": 7.7838, "test_samples_per_second": 263.109, "test_steps_per_second": 8.222}, {"test_loss": 0.08939766883850098, "test_micro_f1": 0.6603018170619033, "test_micro_f1_no_misc": 0.7104736490993997, "test_runtime": 8.2667, "test_samples_per_second": 247.742, "test_steps_per_second": 7.742}, {"test_loss": 0.08250480890274048, "test_micro_f1": 0.6684684684684684, "test_micro_f1_no_misc": 0.7194762684124386, "test_runtime": 7.8776, "test_samples_per_second": 259.978, "test_steps_per_second": 8.124}, {"test_loss": 0.09585119783878326, "test_micro_f1": 0.6788210270434518, "test_micro_f1_no_misc": 0.7251501000667111, "test_runtime": 7.774, "test_samples_per_second": 263.443, "test_steps_per_second": 8.233}, {"test_loss": 0.09961120784282684, "test_micro_f1": 0.6458524640342822, "test_micro_f1_no_misc": 0.7036418309388573, "test_runtime": 7.3385, "test_samples_per_second": 279.075, "test_steps_per_second": 8.721}, {"test_loss": 0.08613195270299911, "test_micro_f1": 0.6670687575392038, "test_micro_f1_no_misc": 0.7199736755511682, "test_runtime": 7.268, "test_samples_per_second": 281.783, "test_steps_per_second": 8.806}, {"test_loss": 0.07358832657337189, "test_micro_f1": 0.6549274019153537, "test_micro_f1_no_misc": 0.7114544843802486, "test_runtime": 8.1976, "test_samples_per_second": 249.83, "test_steps_per_second": 7.807}, {"test_loss": 0.07778318226337433, "test_micro_f1": 0.687863038826047, "test_micro_f1_no_misc": 0.7301164725457571, "test_runtime": 8.1676, "test_samples_per_second": 250.746, "test_steps_per_second": 7.836}, {"test_loss": 0.09361806511878967, "test_micro_f1": 0.6739393939393938, "test_micro_f1_no_misc": 0.7160744500846024, "test_runtime": 7.1803, "test_samples_per_second": 285.226, "test_steps_per_second": 8.913}, {"test_loss": 0.07594792544841766, "test_micro_f1": 0.7048322560787934, "test_micro_f1_no_misc": 0.7435549525101763, "test_runtime": 7.5801, "test_samples_per_second": 270.183, "test_steps_per_second": 8.443}]}, "total": {"test_micro_f1": 67.08949040612724, "test_micro_f1_se": 1.0418041813083543, "test_micro_f1_no_misc": 71.88360923803836, "test_micro_f1_no_misc_se": 0.7306605100068744}}, "num_model_parameters": 123858441, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.6929888725280762, "test_mcc": 0.040455331149623526, "test_macro_f1": 0.4299187843856432, "test_runtime": 4.7286, "test_samples_per_second": 433.11, "test_steps_per_second": 13.535}, {"test_loss": 0.6924201846122742, "test_mcc": 0.05545585844191756, "test_macro_f1": 0.40687885671353646, "test_runtime": 4.952, "test_samples_per_second": 413.569, "test_steps_per_second": 12.924}, {"test_loss": 0.6935184001922607, "test_mcc": 0.004629134519899167, "test_macro_f1": 0.5023145672599496, "test_runtime": 4.9609, "test_samples_per_second": 412.827, "test_steps_per_second": 12.901}, {"test_loss": 0.6929382085800171, "test_mcc": -0.01751650819414767, "test_macro_f1": 0.47283314835622303, "test_runtime": 4.9148, "test_samples_per_second": 416.699, "test_steps_per_second": 13.022}, {"test_loss": 0.6927366256713867, "test_mcc": 0.04215997977568805, "test_macro_f1": 0.500891265597148, "test_runtime": 4.9613, "test_samples_per_second": 412.792, "test_steps_per_second": 12.9}, {"test_loss": 0.6934035420417786, "test_mcc": -0.012176139080689343, "test_macro_f1": 0.33712685418072896, "test_runtime": 4.7927, "test_samples_per_second": 427.316, "test_steps_per_second": 13.354}, {"test_loss": 0.6930451989173889, "test_mcc": 0.036243306566391964, "test_macro_f1": 0.3389576854590374, "test_runtime": 4.8732, "test_samples_per_second": 420.258, "test_steps_per_second": 13.133}, {"test_loss": 0.6929306983947754, "test_mcc": 0.0362389664044885, "test_macro_f1": 0.4671578057084518, "test_runtime": 4.904, "test_samples_per_second": 417.622, "test_steps_per_second": 13.051}, {"test_loss": 0.6932183504104614, "test_mcc": -0.026201526018292894, "test_macro_f1": 0.38124187241238283, "test_runtime": 4.8711, "test_samples_per_second": 420.44, "test_steps_per_second": 13.139}, {"test_loss": 0.693287193775177, "test_mcc": -0.006311798806713067, "test_macro_f1": 0.4175549607490935, "test_runtime": 4.9099, "test_samples_per_second": 417.119, "test_steps_per_second": 13.035}]}, "total": {"test_mcc": 1.5297660475816581, "test_mcc_se": 1.8454764181900083, "test_macro_f1": 42.548758008221945, "test_macro_f1_se": 3.7671724660624455}}, "num_model_parameters": 124443650, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.6935010552406311, "test_mcc": 0.0, "test_macro_f1": 0.33506493506493507, "test_runtime": 4.9686, "test_samples_per_second": 412.189, "test_steps_per_second": 12.881}, {"test_loss": 0.692834734916687, "test_mcc": 0.0, "test_macro_f1": 0.3382875605815832, "test_runtime": 5.3194, "test_samples_per_second": 385.006, "test_steps_per_second": 12.031}, {"test_loss": 0.6936017870903015, "test_mcc": -0.045875481110022154, "test_macro_f1": 0.32631558178229103, "test_runtime": 5.192, "test_samples_per_second": 394.453, "test_steps_per_second": 12.327}, {"test_loss": 0.692652702331543, "test_mcc": 0.025875456620851108, "test_macro_f1": 0.48020833333333324, "test_runtime": 5.33, "test_samples_per_second": 384.24, "test_steps_per_second": 12.007}, {"test_loss": 0.6929581165313721, "test_mcc": -0.05890687729011145, "test_macro_f1": 0.33566506093753107, "test_runtime": 5.1109, "test_samples_per_second": 400.709, "test_steps_per_second": 12.522}, {"test_loss": 0.692829966545105, "test_mcc": 0.03120690796796799, "test_macro_f1": 0.4466339384252388, "test_runtime": 5.0723, "test_samples_per_second": 403.76, "test_steps_per_second": 12.617}, {"test_loss": 0.6926764845848083, "test_mcc": 0.04634452860344334, "test_macro_f1": 0.41901011333592175, "test_runtime": 4.9521, "test_samples_per_second": 413.565, "test_steps_per_second": 12.924}, {"test_loss": 0.6932375431060791, "test_mcc": -0.027808253268488056, "test_macro_f1": 0.48407179903917397, "test_runtime": 5.0222, "test_samples_per_second": 407.79, "test_steps_per_second": 12.743}, {"test_loss": 0.6926777362823486, "test_mcc": -0.03778122031594132, "test_macro_f1": 0.3357119688614985, "test_runtime": 5.0066, "test_samples_per_second": 409.06, "test_steps_per_second": 12.783}, {"test_loss": 0.6930810809135437, "test_mcc": 0.040177618595771174, "test_macro_f1": 0.4426569605162264, "test_runtime": 5.1417, "test_samples_per_second": 398.31, "test_steps_per_second": 12.447}]}, "total": {"test_mcc": -0.26767320196529365, "test_mcc_se": 2.36549231494049, "test_macro_f1": 39.43626251877733, "test_macro_f1_se": 4.093939400641332}}, "num_model_parameters": 124443650, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.6932910680770874, "test_mcc": -0.03516145114185405, "test_macro_f1": 0.4055152394775037, "test_runtime": 4.6338, "test_samples_per_second": 441.965, "test_steps_per_second": 13.811}, {"test_loss": 0.6928408145904541, "test_mcc": 0.001250365919588573, "test_macro_f1": 0.41803086274848966, "test_runtime": 4.7411, "test_samples_per_second": 431.969, "test_steps_per_second": 13.499}, {"test_loss": 0.6937001347541809, "test_mcc": 0.023202234142765992, "test_macro_f1": 0.4470448101733018, "test_runtime": 4.7932, "test_samples_per_second": 427.276, "test_steps_per_second": 13.352}, {"test_loss": 0.6923565864562988, "test_mcc": 0.041173756936139116, "test_macro_f1": 0.36258353458121007, "test_runtime": 4.8595, "test_samples_per_second": 421.443, "test_steps_per_second": 13.17}, {"test_loss": 0.6930917501449585, "test_mcc": 0.02047574301022654, "test_macro_f1": 0.4884881226662429, "test_runtime": 4.8093, "test_samples_per_second": 425.84, "test_steps_per_second": 13.307}, {"test_loss": 0.6918394565582275, "test_mcc": 0.06879663048131565, "test_macro_f1": 0.5340797118522328, "test_runtime": 4.5742, "test_samples_per_second": 447.731, "test_steps_per_second": 13.992}, {"test_loss": 0.6926292181015015, "test_mcc": 0.040263684825566824, "test_macro_f1": 0.423704765336879, "test_runtime": 4.6408, "test_samples_per_second": 441.303, "test_steps_per_second": 13.791}, {"test_loss": 0.6927685737609863, "test_mcc": 0.0, "test_macro_f1": 0.3359273670557717, "test_runtime": 4.6785, "test_samples_per_second": 437.748, "test_steps_per_second": 13.68}, {"test_loss": 0.6936405897140503, "test_mcc": -0.051088561823797805, "test_macro_f1": 0.46654566310309875, "test_runtime": 4.6062, "test_samples_per_second": 444.618, "test_steps_per_second": 13.894}, {"test_loss": 0.6933340430259705, "test_mcc": -0.04058228437682087, "test_macro_f1": 0.3378877437047782, "test_runtime": 4.7546, "test_samples_per_second": 430.745, "test_steps_per_second": 13.461}]}, "total": {"test_mcc": 0.6833011797312996, "test_mcc_se": 2.44760084599764, "test_macro_f1": 42.198078206995085, "test_macro_f1_se": 4.022017901059471}}, "num_model_parameters": 124443650, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.6945269703865051, "test_mcc": 0.0, "test_macro_f1": 0.3236459709379128, "test_runtime": 4.6514, "test_samples_per_second": 440.297, "test_steps_per_second": 13.759}, {"test_loss": 0.6933544874191284, "test_mcc": 0.0, "test_macro_f1": 0.33571196886149857, "test_runtime": 4.8019, "test_samples_per_second": 426.501, "test_steps_per_second": 13.328}, {"test_loss": 0.6928654313087463, "test_mcc": 0.03082561340055326, "test_macro_f1": 0.35311004784688993, "test_runtime": 4.8612, "test_samples_per_second": 421.295, "test_steps_per_second": 13.165}, {"test_loss": 0.6925583481788635, "test_mcc": -0.009347847840772026, "test_macro_f1": 0.3498661363114816, "test_runtime": 4.5573, "test_samples_per_second": 449.388, "test_steps_per_second": 14.043}, {"test_loss": 0.6933917999267578, "test_mcc": -0.026406733990484443, "test_macro_f1": 0.33273580532881863, "test_runtime": 4.6525, "test_samples_per_second": 440.196, "test_steps_per_second": 13.756}, {"test_loss": 0.6930301189422607, "test_mcc": 0.0, "test_macro_f1": 0.3431686978832585, "test_runtime": 4.7944, "test_samples_per_second": 427.162, "test_steps_per_second": 13.349}, {"test_loss": 0.6926504373550415, "test_mcc": 0.032417286679109994, "test_macro_f1": 0.513083202545602, "test_runtime": 4.652, "test_samples_per_second": 440.245, "test_steps_per_second": 13.758}, {"test_loss": 0.6925371885299683, "test_mcc": 0.04518199889588115, "test_macro_f1": 0.38680110333883505, "test_runtime": 4.6819, "test_samples_per_second": 437.433, "test_steps_per_second": 13.67}, {"test_loss": 0.6943572759628296, "test_mcc": -0.016607366741971052, "test_macro_f1": 0.3803028285786907, "test_runtime": 4.6255, "test_samples_per_second": 442.763, "test_steps_per_second": 13.836}, {"test_loss": 0.6930636167526245, "test_mcc": 0.035462323774357485, "test_macro_f1": 0.44916140036299224, "test_runtime": 4.7606, "test_samples_per_second": 430.195, "test_steps_per_second": 13.444}]}, "total": {"test_mcc": 0.9152527417667435, "test_mcc_se": 1.5353893878860876, "test_macro_f1": 37.67587161995979, "test_macro_f1_se": 3.7414101843265968}}, "num_model_parameters": 124443650, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_em": 37.72269558481797, "test_f1": 41.81060999418863}, {"test_em": 37.36434108527132, "test_f1": 40.51511364199463}, {"test_em": 28.361669242658422, "test_f1": 30.803572986498715}, {"test_em": 27.414330218068535, "test_f1": 29.78819270085076}, {"test_em": 33.513513513513516, "test_f1": 35.97452911738626}, {"test_em": 23.053199691595992, "test_f1": 25.805454290419586}, {"test_em": 31.131359149582384, "test_f1": 34.31427861918283}, {"test_em": 19.937936384794416, "test_f1": 21.095919854647555}, {"test_em": 34.509803921568626, "test_f1": 37.06856201596687}, {"test_em": 32.142857142857146, "test_f1": 34.48762587532226}]}, "total": {"test_em": 30.515170593472835, "test_em_se": 3.6296617195710468, "test_f1": 33.1663859096458, "test_f1_se": 3.983602845394626}}, "num_model_parameters": 123853826, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_em": 32.30054221533695, "test_f1": 36.09417456628921}, {"test_em": 30.930232558139537, "test_f1": 34.630579799184474}, {"test_em": 17.465224111282843, "test_f1": 20.359931988489144}, {"test_em": 32.55451713395639, "test_f1": 36.49091346521255}, {"test_em": 28.64864864864865, "test_f1": 32.82483882483883}, {"test_em": 34.84965304548959, "test_f1": 38.05164250097904}, {"test_em": 30.903568716780562, "test_f1": 34.324775873750816}, {"test_em": 31.264546159813808, "test_f1": 34.54632213747808}, {"test_em": 34.11764705882353, "test_f1": 37.90462323110294}, {"test_em": 30.97826086956522, "test_f1": 34.32984760236314}]}, "total": {"test_em": 30.401284051783705, "test_em_se": 3.021385986894607, "test_f1": 33.95576499896883, "test_f1_se": 3.137193303400558}}, "num_model_parameters": 123853826, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_em": 21.378776142525176, "test_f1": 25.26834482933267}, {"test_em": 32.17054263565891, "test_f1": 36.150461080693645}, {"test_em": 34.77588871715611, "test_f1": 38.30520222521769}, {"test_em": 32.47663551401869, "test_f1": 35.66525655894815}, {"test_em": 32.58687258687259, "test_f1": 36.49701221129793}, {"test_em": 25.597532767925983, "test_f1": 29.41526147791619}, {"test_em": 34.54821564160972, "test_f1": 38.77104946011552}, {"test_em": 35.91931730023274, "test_f1": 39.689796239447126}, {"test_em": 31.45098039215686, "test_f1": 35.33121584298056}, {"test_em": 30.434782608695652, "test_f1": 33.80205176983127}]}, "total": {"test_em": 31.133954430685243, "test_em_se": 2.765797419152852, "test_f1": 34.88956516957807, "test_f1_se": 2.7600049399288524}}, "num_model_parameters": 123853826, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_speed": 1.68}, {"test_speed": 1.68}, {"test_speed": 1.58}, {"test_speed": 1.67}, {"test_speed": 1.58}, {"test_speed": 1.65}, {"test_speed": 1.72}, {"test_speed": 1.65}, {"test_speed": 1.64}, {"test_speed": 1.68}]}, "total": {"test_speed": 1.653, "test_speed_se": 0.027571905185451984}}, "num_model_parameters": 124442112, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.5481635332107544, "test_mcc": 0.6411021387523087, "test_macro_f1": 0.6458525055426004, "test_runtime": 16.669, "test_samples_per_second": 122.863, "test_steps_per_second": 15.358}, {"test_loss": 0.6106001138687134, "test_mcc": 0.5674490999711927, "test_macro_f1": 0.533390252854418, "test_runtime": 16.056, "test_samples_per_second": 127.554, "test_steps_per_second": 15.944}, {"test_loss": 0.5944387316703796, "test_mcc": 0.5874928995342751, "test_macro_f1": 0.5554549768367099, "test_runtime": 16.3145, "test_samples_per_second": 125.532, "test_steps_per_second": 15.692}, {"test_loss": 0.5549104809761047, "test_mcc": 0.6419954837531573, "test_macro_f1": 0.6720270069919764, "test_runtime": 15.9811, "test_samples_per_second": 128.151, "test_steps_per_second": 16.019}, {"test_loss": 0.5679100751876831, "test_mcc": 0.6422153499674392, "test_macro_f1": 0.6427068575720501, "test_runtime": 15.9097, "test_samples_per_second": 128.727, "test_steps_per_second": 16.091}, {"test_loss": 0.5859102010726929, "test_mcc": 0.6082755070031378, "test_macro_f1": 0.5563752185910593, "test_runtime": 16.228, "test_samples_per_second": 126.201, "test_steps_per_second": 15.775}, {"test_loss": 0.5303558111190796, "test_mcc": 0.6736787491138151, "test_macro_f1": 0.7089134408651537, "test_runtime": 15.7791, "test_samples_per_second": 129.792, "test_steps_per_second": 16.224}, {"test_loss": 0.5297726392745972, "test_mcc": 0.6664693435481654, "test_macro_f1": 0.644705280347564, "test_runtime": 16.6711, "test_samples_per_second": 122.847, "test_steps_per_second": 15.356}, {"test_loss": 0.5649661421775818, "test_mcc": 0.6584004026823618, "test_macro_f1": 0.6296473439698198, "test_runtime": 16.5157, "test_samples_per_second": 124.004, "test_steps_per_second": 15.5}, {"test_loss": 0.5696961283683777, "test_mcc": 0.6398575138484984, "test_macro_f1": 0.6377978118709319, "test_runtime": 16.1531, "test_samples_per_second": 126.786, "test_steps_per_second": 15.848}]}, "total": {"test_mcc": 63.269364881743506, "test_mcc_se": 2.1347938671365614, "test_macro_f1": 62.26870695442284, "test_macro_f1_se": 3.4853826883428027}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.8562606573104858, "test_mcc": 0.40114405686544385, "test_macro_f1": 0.6049169871305456, "test_runtime": 4.5521, "test_samples_per_second": 449.897, "test_steps_per_second": 14.059}, {"test_loss": 0.8988076448440552, "test_mcc": 0.41546311226869925, "test_macro_f1": 0.6044521776262476, "test_runtime": 4.5657, "test_samples_per_second": 448.562, "test_steps_per_second": 14.018}, {"test_loss": 0.9191274046897888, "test_mcc": 0.41027218924638137, "test_macro_f1": 0.6046167599202155, "test_runtime": 4.634, "test_samples_per_second": 441.955, "test_steps_per_second": 13.811}, {"test_loss": 0.9645107388496399, "test_mcc": 0.40052635037629897, "test_macro_f1": 0.6047501073438402, "test_runtime": 4.4977, "test_samples_per_second": 455.339, "test_steps_per_second": 14.229}, {"test_loss": 0.9276816844940186, "test_mcc": 0.404449243212496, "test_macro_f1": 0.6046798371023545, "test_runtime": 4.515, "test_samples_per_second": 453.602, "test_steps_per_second": 14.175}, {"test_loss": 0.8941185474395752, "test_mcc": 0.4083533203524117, "test_macro_f1": 0.6055696267850347, "test_runtime": 4.6653, "test_samples_per_second": 438.987, "test_steps_per_second": 13.718}, {"test_loss": 0.8669670820236206, "test_mcc": 0.4091096725817246, "test_macro_f1": 0.6088928303740823, "test_runtime": 4.5277, "test_samples_per_second": 452.327, "test_steps_per_second": 14.135}, {"test_loss": 0.8723194599151611, "test_mcc": 0.4089825123965805, "test_macro_f1": 0.6065602066335051, "test_runtime": 4.753, "test_samples_per_second": 430.882, "test_steps_per_second": 13.465}, {"test_loss": 0.8736447095870972, "test_mcc": 0.4222270579477132, "test_macro_f1": 0.6095803141462021, "test_runtime": 4.6514, "test_samples_per_second": 440.299, "test_steps_per_second": 13.759}, {"test_loss": 0.901422381401062, "test_mcc": 0.38575890559630355, "test_macro_f1": 0.5865296339240835, "test_runtime": 4.52, "test_samples_per_second": 453.098, "test_steps_per_second": 14.159}]}, "total": {"test_mcc": 40.66286420844053, "test_mcc_se": 0.6047901159337571, "test_macro_f1": 60.40548480986111, "test_macro_f1_se": 0.3983363481849464}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6660993695259094, "test_mcc": 0.588551590196608, "test_macro_f1": 0.7099414293034162, "test_runtime": 3.1462, "test_samples_per_second": 650.954, "test_steps_per_second": 20.342}, {"test_loss": 0.6801551580429077, "test_mcc": 0.5514192331267854, "test_macro_f1": 0.6762802440559658, "test_runtime": 2.968, "test_samples_per_second": 690.018, "test_steps_per_second": 21.563}, {"test_loss": 0.6676303744316101, "test_mcc": 0.5900948396461583, "test_macro_f1": 0.7077377264383494, "test_runtime": 3.0158, "test_samples_per_second": 679.1, "test_steps_per_second": 21.222}, {"test_loss": 0.6991735100746155, "test_mcc": 0.5627092597468434, "test_macro_f1": 0.6831253240991032, "test_runtime": 3.0285, "test_samples_per_second": 676.235, "test_steps_per_second": 21.132}, {"test_loss": 0.7147447466850281, "test_mcc": 0.5626813470215265, "test_macro_f1": 0.6972397204743209, "test_runtime": 3.0917, "test_samples_per_second": 662.427, "test_steps_per_second": 20.701}, {"test_loss": 0.7023226618766785, "test_mcc": 0.571172014679802, "test_macro_f1": 0.7094754963018053, "test_runtime": 3.1793, "test_samples_per_second": 644.167, "test_steps_per_second": 20.13}, {"test_loss": 0.6312255859375, "test_mcc": 0.6028902512812813, "test_macro_f1": 0.7222341011653012, "test_runtime": 3.038, "test_samples_per_second": 674.131, "test_steps_per_second": 21.067}, {"test_loss": 0.6517571806907654, "test_mcc": 0.5844384796214985, "test_macro_f1": 0.7110457108418134, "test_runtime": 3.0733, "test_samples_per_second": 666.388, "test_steps_per_second": 20.825}, {"test_loss": 0.680678129196167, "test_mcc": 0.5930032817974179, "test_macro_f1": 0.714073485416177, "test_runtime": 3.1662, "test_samples_per_second": 646.826, "test_steps_per_second": 20.213}, {"test_loss": 0.6641526222229004, "test_mcc": 0.6089411426535788, "test_macro_f1": 0.729608124500805, "test_runtime": 3.1447, "test_samples_per_second": 651.259, "test_steps_per_second": 20.352}]}, "total": {"test_mcc": 58.15901439771499, "test_mcc_se": 1.1675832002617423, "test_macro_f1": 70.60761362597057, "test_macro_f1_se": 1.0174736544778265}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.0851312056183815, "test_micro_f1": 0.5812658227848101, "test_micro_f1_no_misc": 0.6538908246225319, "test_runtime": 8.3854, "test_samples_per_second": 244.233, "test_steps_per_second": 7.632}, {"test_loss": 0.06998836994171143, "test_micro_f1": 0.6098929117797043, "test_micro_f1_no_misc": 0.6795547744581136, "test_runtime": 7.4994, "test_samples_per_second": 273.088, "test_steps_per_second": 8.534}, {"test_loss": 0.06290800869464874, "test_micro_f1": 0.6609929078014184, "test_micro_f1_no_misc": 0.729934924078091, "test_runtime": 7.5395, "test_samples_per_second": 271.637, "test_steps_per_second": 8.489}, {"test_loss": 0.06668991595506668, "test_micro_f1": 0.6295238095238096, "test_micro_f1_no_misc": 0.6867140513942044, "test_runtime": 8.0233, "test_samples_per_second": 255.256, "test_steps_per_second": 7.977}, {"test_loss": 0.07099653035402298, "test_micro_f1": 0.6701127819548873, "test_micro_f1_no_misc": 0.7103377686796316, "test_runtime": 8.4001, "test_samples_per_second": 243.808, "test_steps_per_second": 7.619}, {"test_loss": 0.07028654217720032, "test_micro_f1": 0.646780303030303, "test_micro_f1_no_misc": 0.7004754358161648, "test_runtime": 6.4025, "test_samples_per_second": 319.876, "test_steps_per_second": 9.996}, {"test_loss": 0.07018869370222092, "test_micro_f1": 0.6434955312810328, "test_micro_f1_no_misc": 0.7094555873925501, "test_runtime": 6.9805, "test_samples_per_second": 293.39, "test_steps_per_second": 9.168}, {"test_loss": 0.06521230936050415, "test_micro_f1": 0.6356107660455488, "test_micro_f1_no_misc": 0.6937573616018845, "test_runtime": 8.2994, "test_samples_per_second": 246.765, "test_steps_per_second": 7.711}, {"test_loss": 0.065725177526474, "test_micro_f1": 0.6339202965708989, "test_micro_f1_no_misc": 0.6697294538029607, "test_runtime": 7.6509, "test_samples_per_second": 267.68, "test_steps_per_second": 8.365}, {"test_loss": 0.07325445115566254, "test_micro_f1": 0.6440677966101696, "test_micro_f1_no_misc": 0.6868160500260552, "test_runtime": 7.9014, "test_samples_per_second": 259.195, "test_steps_per_second": 8.1}]}, "total": {"test_micro_f1": 63.55662927382583, "test_micro_f1_se": 1.5663333185447357, "test_micro_f1_no_misc": 69.20666231872188, "test_micro_f1_no_misc_se": 1.3568101327444122}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.07796835154294968, "test_micro_f1": 0.7327281896116994, "test_micro_f1_no_misc": 0.7772312016865778, "test_runtime": 8.4277, "test_samples_per_second": 243.009, "test_steps_per_second": 7.594}, {"test_loss": 0.06930581480264664, "test_micro_f1": 0.740782122905028, "test_micro_f1_no_misc": 0.7749820273184759, "test_runtime": 6.5176, "test_samples_per_second": 314.224, "test_steps_per_second": 9.82}, {"test_loss": 0.0800262913107872, "test_micro_f1": 0.7590233545647558, "test_micro_f1_no_misc": 0.7899821109123434, "test_runtime": 8.1991, "test_samples_per_second": 249.782, "test_steps_per_second": 7.806}, {"test_loss": 0.07529066503047943, "test_micro_f1": 0.7568270481144344, "test_micro_f1_no_misc": 0.7801857585139318, "test_runtime": 7.9907, "test_samples_per_second": 256.298, "test_steps_per_second": 8.009}, {"test_loss": 0.0841134786605835, "test_micro_f1": 0.757259656047364, "test_micro_f1_no_misc": 0.7822189017556967, "test_runtime": 8.4646, "test_samples_per_second": 241.949, "test_steps_per_second": 7.561}, {"test_loss": 0.07918112725019455, "test_micro_f1": 0.7361598703753713, "test_micro_f1_no_misc": 0.756596060943887, "test_runtime": 8.3553, "test_samples_per_second": 245.115, "test_steps_per_second": 7.66}, {"test_loss": 0.07809332758188248, "test_micro_f1": 0.7542796944956545, "test_micro_f1_no_misc": 0.7838312829525483, "test_runtime": 8.5119, "test_samples_per_second": 240.606, "test_steps_per_second": 7.519}, {"test_loss": 0.07354526221752167, "test_micro_f1": 0.7387722561785809, "test_micro_f1_no_misc": 0.770893371757925, "test_runtime": 8.4101, "test_samples_per_second": 243.518, "test_steps_per_second": 7.61}, {"test_loss": 0.07940199226140976, "test_micro_f1": 0.7267064624967557, "test_micro_f1_no_misc": 0.752384316495938, "test_runtime": 8.1107, "test_samples_per_second": 252.505, "test_steps_per_second": 7.891}, {"test_loss": 0.07711851596832275, "test_micro_f1": 0.7428110722923944, "test_micro_f1_no_misc": 0.7691192461036607, "test_runtime": 6.9094, "test_samples_per_second": 296.406, "test_steps_per_second": 9.263}]}, "total": {"test_micro_f1": 74.45349727082038, "test_micro_f1_se": 0.7143620741498805, "test_micro_f1_no_misc": 77.37424278440986, "test_micro_f1_no_misc_se": 0.7369198379196051}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.0452781543135643, "test_micro_f1": 0.8376316745368689, "test_micro_f1_no_misc": 0.8715176715176716, "test_runtime": 5.3233, "test_samples_per_second": 384.725, "test_steps_per_second": 12.023}, {"test_loss": 0.03671842813491821, "test_micro_f1": 0.8536312849162011, "test_micro_f1_no_misc": 0.8779884583676835, "test_runtime": 5.292, "test_samples_per_second": 387.003, "test_steps_per_second": 12.094}, {"test_loss": 0.04266595095396042, "test_micro_f1": 0.8638132295719845, "test_micro_f1_no_misc": 0.8915281076801268, "test_runtime": 5.0215, "test_samples_per_second": 407.843, "test_steps_per_second": 12.745}, {"test_loss": 0.03458332270383835, "test_micro_f1": 0.8645024700070572, "test_micro_f1_no_misc": 0.8916139240506329, "test_runtime": 4.9849, "test_samples_per_second": 410.842, "test_steps_per_second": 12.839}, {"test_loss": 0.034779030829668045, "test_micro_f1": 0.8741588156123822, "test_micro_f1_no_misc": 0.9043674698795181, "test_runtime": 5.3502, "test_samples_per_second": 382.79, "test_steps_per_second": 11.962}, {"test_loss": 0.035779066383838654, "test_micro_f1": 0.8580142324635717, "test_micro_f1_no_misc": 0.8863636363636362, "test_runtime": 5.3655, "test_samples_per_second": 381.699, "test_steps_per_second": 11.928}, {"test_loss": 0.03780335932970047, "test_micro_f1": 0.8649395509499136, "test_micro_f1_no_misc": 0.8943526699961583, "test_runtime": 5.0012, "test_samples_per_second": 409.506, "test_steps_per_second": 12.797}, {"test_loss": 0.042713090777397156, "test_micro_f1": 0.8620568620568619, "test_micro_f1_no_misc": 0.8835249042145594, "test_runtime": 4.852, "test_samples_per_second": 422.093, "test_steps_per_second": 13.19}, {"test_loss": 0.0393541194498539, "test_micro_f1": 0.8471830985915493, "test_micro_f1_no_misc": 0.8818770226537215, "test_runtime": 5.0792, "test_samples_per_second": 403.217, "test_steps_per_second": 12.601}, {"test_loss": 0.04887606203556061, "test_micro_f1": 0.8458927359131025, "test_micro_f1_no_misc": 0.8743870237646171, "test_runtime": 5.3792, "test_samples_per_second": 380.723, "test_steps_per_second": 11.898}]}, "total": {"test_micro_f1": 85.71823954619492, "test_micro_f1_se": 0.682931667010376, "test_micro_f1_no_misc": 88.57520888488327, "test_micro_f1_no_misc_se": 0.6200245864023062}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.04646119475364685, "test_micro_f1": 0.7972636815920396, "test_micro_f1_no_misc": 0.834991423670669, "test_runtime": 5.2914, "test_samples_per_second": 387.04, "test_steps_per_second": 12.095}, {"test_loss": 0.05053246021270752, "test_micro_f1": 0.7853466545564639, "test_micro_f1_no_misc": 0.820100502512563, "test_runtime": 5.2463, "test_samples_per_second": 390.373, "test_steps_per_second": 12.199}, {"test_loss": 0.052158817648887634, "test_micro_f1": 0.7797118847539016, "test_micro_f1_no_misc": 0.8300368756285618, "test_runtime": 5.1523, "test_samples_per_second": 397.495, "test_steps_per_second": 12.422}, {"test_loss": 0.05537733808159828, "test_micro_f1": 0.7984237647772052, "test_micro_f1_no_misc": 0.8338409475465313, "test_runtime": 5.2978, "test_samples_per_second": 386.577, "test_steps_per_second": 12.081}, {"test_loss": 0.05556890740990639, "test_micro_f1": 0.789966757328498, "test_micro_f1_no_misc": 0.8401826484018264, "test_runtime": 5.1647, "test_samples_per_second": 396.537, "test_steps_per_second": 12.392}, {"test_loss": 0.04949288070201874, "test_micro_f1": 0.7958750379132543, "test_micro_f1_no_misc": 0.8356489325652322, "test_runtime": 5.2439, "test_samples_per_second": 390.552, "test_steps_per_second": 12.205}, {"test_loss": 0.0428490936756134, "test_micro_f1": 0.8096714197148172, "test_micro_f1_no_misc": 0.8434571329399514, "test_runtime": 5.2555, "test_samples_per_second": 389.69, "test_steps_per_second": 12.178}, {"test_loss": 0.050741489976644516, "test_micro_f1": 0.8106151990349819, "test_micro_f1_no_misc": 0.8521320495185694, "test_runtime": 5.2721, "test_samples_per_second": 388.457, "test_steps_per_second": 12.139}, {"test_loss": 0.053211841732263565, "test_micro_f1": 0.8229457364341085, "test_micro_f1_no_misc": 0.8633297834575789, "test_runtime": 4.919, "test_samples_per_second": 416.348, "test_steps_per_second": 13.011}, {"test_loss": 0.051203854382038116, "test_micro_f1": 0.7677554689841175, "test_micro_f1_no_misc": 0.8061915511125443, "test_runtime": 5.0985, "test_samples_per_second": 401.684, "test_steps_per_second": 12.553}]}, "total": {"test_micro_f1": 79.57575605089386, "test_micro_f1_se": 1.0007808242807998, "test_micro_f1_no_misc": 83.59911847354027, "test_micro_f1_no_misc_se": 0.9828186009350729}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6110059022903442, "test_mcc": 0.3515086059306804, "test_macro_f1": 0.669525578900998, "test_runtime": 3.7723, "test_samples_per_second": 542.905, "test_steps_per_second": 16.966}, {"test_loss": 0.6530894041061401, "test_mcc": 0.22813724795138166, "test_macro_f1": 0.5808378834076415, "test_runtime": 4.0305, "test_samples_per_second": 508.128, "test_steps_per_second": 15.879}, {"test_loss": 0.6819665431976318, "test_mcc": 0.10740890953861076, "test_macro_f1": 0.5328934839309438, "test_runtime": 4.0292, "test_samples_per_second": 508.296, "test_steps_per_second": 15.884}, {"test_loss": 0.6909406185150146, "test_mcc": 0.08398337168092952, "test_macro_f1": 0.534049716969172, "test_runtime": 3.9235, "test_samples_per_second": 521.981, "test_steps_per_second": 16.312}, {"test_loss": 0.6258681416511536, "test_mcc": 0.31410572594998987, "test_macro_f1": 0.6314228413873745, "test_runtime": 4.0211, "test_samples_per_second": 509.308, "test_steps_per_second": 15.916}, {"test_loss": 0.6443067789077759, "test_mcc": 0.2615602394411684, "test_macro_f1": 0.6300209887753605, "test_runtime": 3.9258, "test_samples_per_second": 521.683, "test_steps_per_second": 16.303}, {"test_loss": 0.6224725246429443, "test_mcc": 0.3232693666675599, "test_macro_f1": 0.6418082962624996, "test_runtime": 3.9822, "test_samples_per_second": 514.291, "test_steps_per_second": 16.072}, {"test_loss": 0.6444629430770874, "test_mcc": 0.33560798944939274, "test_macro_f1": 0.6240515202404547, "test_runtime": 3.9273, "test_samples_per_second": 521.475, "test_steps_per_second": 16.296}, {"test_loss": 0.6468648314476013, "test_mcc": 0.2889345048266499, "test_macro_f1": 0.6444647933001393, "test_runtime": 3.9381, "test_samples_per_second": 520.045, "test_steps_per_second": 16.251}, {"test_loss": 0.6410598754882812, "test_mcc": 0.3326265931574248, "test_macro_f1": 0.6553439045974845, "test_runtime": 3.9682, "test_samples_per_second": 516.108, "test_steps_per_second": 16.128}]}, "total": {"test_mcc": 26.271425545937877, "test_mcc_se": 5.928529501834209, "test_macro_f1": 61.444190077720684, "test_macro_f1_se": 3.0098153938559897}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.5862284302711487, "test_mcc": 0.40122781164980775, "test_macro_f1": 0.6784115417031189, "test_runtime": 3.7476, "test_samples_per_second": 546.483, "test_steps_per_second": 17.078}, {"test_loss": 0.6529415845870972, "test_mcc": 0.28346584003612246, "test_macro_f1": 0.6066613924837918, "test_runtime": 3.9257, "test_samples_per_second": 521.688, "test_steps_per_second": 16.303}, {"test_loss": 0.6917945146560669, "test_mcc": 0.051334792717572304, "test_macro_f1": 0.5028823622867844, "test_runtime": 3.7795, "test_samples_per_second": 541.874, "test_steps_per_second": 16.934}, {"test_loss": 0.591031551361084, "test_mcc": 0.49417919103091124, "test_macro_f1": 0.736832463640735, "test_runtime": 3.9294, "test_samples_per_second": 521.194, "test_steps_per_second": 16.287}, {"test_loss": 0.6314379572868347, "test_mcc": 0.33066934465565284, "test_macro_f1": 0.6549690937045811, "test_runtime": 3.7169, "test_samples_per_second": 551.0, "test_steps_per_second": 17.219}, {"test_loss": 0.6112167835235596, "test_mcc": 0.4638799406598515, "test_macro_f1": 0.7100278029558154, "test_runtime": 3.7139, "test_samples_per_second": 551.436, "test_steps_per_second": 17.232}, {"test_loss": 0.6467742323875427, "test_mcc": 0.3229361538112175, "test_macro_f1": 0.6194746082058822, "test_runtime": 3.6318, "test_samples_per_second": 563.902, "test_steps_per_second": 17.622}, {"test_loss": 0.560920238494873, "test_mcc": 0.483468098551793, "test_macro_f1": 0.7352259000690802, "test_runtime": 3.6884, "test_samples_per_second": 555.25, "test_steps_per_second": 17.352}, {"test_loss": 0.6758313775062561, "test_mcc": 0.4444318597407937, "test_macro_f1": 0.6996195465373994, "test_runtime": 3.6721, "test_samples_per_second": 557.717, "test_steps_per_second": 17.429}, {"test_loss": 0.6262643337249756, "test_mcc": 0.38464079525227346, "test_macro_f1": 0.644484870141472, "test_runtime": 3.8441, "test_samples_per_second": 532.767, "test_steps_per_second": 16.649}]}, "total": {"test_mcc": 36.60233828105996, "test_mcc_se": 8.172622930692427, "test_macro_f1": 65.88589581728661, "test_macro_f1_se": 4.40212460540281}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.4883882403373718, "test_mcc": 0.6105296602013117, "test_macro_f1": 0.7700104745790025, "test_runtime": 2.8053, "test_samples_per_second": 730.039, "test_steps_per_second": 22.814}, {"test_loss": 0.4818059206008911, "test_mcc": 0.5962855018399725, "test_macro_f1": 0.767221426209633, "test_runtime": 2.8239, "test_samples_per_second": 725.232, "test_steps_per_second": 22.663}, {"test_loss": 0.4119018316268921, "test_mcc": 0.6901124246049718, "test_macro_f1": 0.8305730070001376, "test_runtime": 2.9213, "test_samples_per_second": 701.056, "test_steps_per_second": 21.908}, {"test_loss": 0.391650915145874, "test_mcc": 0.6973020434464828, "test_macro_f1": 0.837936375914351, "test_runtime": 2.8722, "test_samples_per_second": 713.046, "test_steps_per_second": 22.283}, {"test_loss": 0.47539734840393066, "test_mcc": 0.6621602501506209, "test_macro_f1": 0.8057187684013813, "test_runtime": 2.8791, "test_samples_per_second": 711.327, "test_steps_per_second": 22.229}, {"test_loss": 0.4344378411769867, "test_mcc": 0.656203230811853, "test_macro_f1": 0.8059857831024879, "test_runtime": 2.7711, "test_samples_per_second": 739.058, "test_steps_per_second": 23.096}, {"test_loss": 0.48893874883651733, "test_mcc": 0.5947603615889694, "test_macro_f1": 0.7613007345820464, "test_runtime": 2.7744, "test_samples_per_second": 738.169, "test_steps_per_second": 23.068}, {"test_loss": 0.40307313203811646, "test_mcc": 0.6958533015501782, "test_macro_f1": 0.8368257509361805, "test_runtime": 2.8287, "test_samples_per_second": 724.001, "test_steps_per_second": 22.625}, {"test_loss": 0.4442414939403534, "test_mcc": 0.6110014530910819, "test_macro_f1": 0.7908316768210566, "test_runtime": 2.7573, "test_samples_per_second": 742.745, "test_steps_per_second": 23.211}, {"test_loss": 0.4445499777793884, "test_mcc": 0.6718392901008844, "test_macro_f1": 0.8174603174603174, "test_runtime": 2.8397, "test_samples_per_second": 721.196, "test_steps_per_second": 22.537}]}, "total": {"test_mcc": 64.86047517386326, "test_mcc_se": 2.5811474177754365, "test_macro_f1": 80.23864315006594, "test_macro_f1_se": 1.8013476035572695}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.5372342467308044, "test_mcc": 0.5337208389479405, "test_macro_f1": 0.7360493918705389, "test_runtime": 3.1846, "test_samples_per_second": 643.094, "test_steps_per_second": 20.097}, {"test_loss": 0.4969674348831177, "test_mcc": 0.5133477308741667, "test_macro_f1": 0.7468755895199347, "test_runtime": 3.2496, "test_samples_per_second": 630.238, "test_steps_per_second": 19.695}, {"test_loss": 0.5035934448242188, "test_mcc": 0.5565007272351046, "test_macro_f1": 0.7569882871035811, "test_runtime": 3.2413, "test_samples_per_second": 631.848, "test_steps_per_second": 19.745}, {"test_loss": 0.532875120639801, "test_mcc": 0.49509058887328533, "test_macro_f1": 0.710707222902345, "test_runtime": 3.0821, "test_samples_per_second": 664.489, "test_steps_per_second": 20.765}, {"test_loss": 0.4718684256076813, "test_mcc": 0.5637471435999977, "test_macro_f1": 0.7789185050014005, "test_runtime": 3.1026, "test_samples_per_second": 660.097, "test_steps_per_second": 20.628}, {"test_loss": 0.5084753036499023, "test_mcc": 0.5387649533982561, "test_macro_f1": 0.7523888407443625, "test_runtime": 3.1849, "test_samples_per_second": 643.031, "test_steps_per_second": 20.095}, {"test_loss": 0.5266667604446411, "test_mcc": 0.5094820372933455, "test_macro_f1": 0.7285811473454494, "test_runtime": 3.1355, "test_samples_per_second": 653.16, "test_steps_per_second": 20.411}, {"test_loss": 0.5511592030525208, "test_mcc": 0.4893926953564462, "test_macro_f1": 0.7081399150049035, "test_runtime": 3.2094, "test_samples_per_second": 638.123, "test_steps_per_second": 19.941}, {"test_loss": 0.5503783226013184, "test_mcc": 0.4895794010994523, "test_macro_f1": 0.7152794629135323, "test_runtime": 3.1085, "test_samples_per_second": 658.831, "test_steps_per_second": 20.588}, {"test_loss": 0.4769285321235657, "test_mcc": 0.5821069153952361, "test_macro_f1": 0.7889958903269336, "test_runtime": 3.211, "test_samples_per_second": 637.81, "test_steps_per_second": 19.932}]}, "total": {"test_mcc": 52.7173303207323, "test_mcc_se": 2.0417879877839202, "test_macro_f1": 74.2292425273298, "test_macro_f1_se": 1.7263693190108464}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_em": 31.835786212238574, "test_f1": 35.12519588664153}, {"test_em": 33.333333333333336, "test_f1": 37.05035321222592}, {"test_em": 32.53477588871716, "test_f1": 36.17644279385658}, {"test_em": 37.61682242990654, "test_f1": 42.24326202947337}, {"test_em": 27.335907335907336, "test_f1": 31.279525033395007}, {"test_em": 36.160370084811106, "test_f1": 39.98090120176455}, {"test_em": 31.58694001518603, "test_f1": 35.24660760155868}, {"test_em": 34.44530643910008, "test_f1": 38.495545924691584}, {"test_em": 33.72549019607843, "test_f1": 37.470828703190755}, {"test_em": 36.56832298136646, "test_f1": 40.73129931603841}]}, "total": {"test_em": 33.51430549166451, "test_em_se": 1.8452206719398698, "test_f1": 37.37999617028364, "test_f1_se": 1.974195839899506}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_em": 35.70875290472502, "test_f1": 38.9853381669971}, {"test_em": 36.74418604651163, "test_f1": 40.549258712794455}, {"test_em": 35.7032457496136, "test_f1": 39.93159697480992}, {"test_em": 34.034267912772584, "test_f1": 37.63745238852894}, {"test_em": 35.5984555984556, "test_f1": 39.542298635841334}, {"test_em": 38.16499614494988, "test_f1": 42.72645739189752}, {"test_em": 31.9665907365224, "test_f1": 36.63722393647568}, {"test_em": 36.074476338246704, "test_f1": 39.604039504431164}, {"test_em": 32.07843137254902, "test_f1": 36.90979156709006}, {"test_em": 39.20807453416149, "test_f1": 43.94325234948009}]}, "total": {"test_em": 35.52814773385079, "test_em_se": 1.4485327337900942, "test_f1": 39.64667096283462, "test_f1_se": 1.4590829886868606}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_em": 32.45546088303641, "test_f1": 36.79430827218681}, {"test_em": 36.89922480620155, "test_f1": 41.33567143450865}, {"test_em": 35.7032457496136, "test_f1": 39.768270578912464}, {"test_em": 37.850467289719624, "test_f1": 42.26473434508487}, {"test_em": 29.343629343629345, "test_f1": 34.85457423626375}, {"test_em": 35.92906707787201, "test_f1": 40.65614270430815}, {"test_em": 34.54821564160972, "test_f1": 38.42165787937545}, {"test_em": 35.29868114817688, "test_f1": 39.45612513814037}, {"test_em": 34.431372549019606, "test_f1": 38.895855557163}, {"test_em": 32.68633540372671, "test_f1": 36.979325478384446}]}, "total": {"test_em": 34.51456998926055, "test_em_se": 1.5346023267048128, "test_f1": 38.94266656243279, "test_f1_se": 1.4027685996102977}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_speed": 2.03}, {"test_speed": 2.08}, {"test_speed": 2.07}, {"test_speed": 2.04}, {"test_speed": 1.98}, {"test_speed": 2.0}, {"test_speed": 2.0}, {"test_speed": 1.92}, {"test_speed": 2.01}, {"test_speed": 1.96}]}, "total": {"test_speed": 2.0089999999999995, "test_speed_se": 0.030286774524718067}}, "num_model_parameters": 124645632, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6067636013031006, "test_mcc": 0.5955934039663341, "test_macro_f1": 0.5433340237256905, "test_runtime": 19.258, "test_samples_per_second": 106.346, "test_steps_per_second": 13.293}, {"test_loss": 0.7326443195343018, "test_mcc": 0.5432581248992854, "test_macro_f1": 0.5135414161398575, "test_runtime": 18.5938, "test_samples_per_second": 110.145, "test_steps_per_second": 13.768}, {"test_loss": 0.6557263135910034, "test_mcc": 0.598123477405271, "test_macro_f1": 0.5433527476731489, "test_runtime": 18.7698, "test_samples_per_second": 109.111, "test_steps_per_second": 13.639}, {"test_loss": 0.5900120735168457, "test_mcc": 0.5879805407651506, "test_macro_f1": 0.6185475497209799, "test_runtime": 18.7452, "test_samples_per_second": 109.255, "test_steps_per_second": 13.657}, {"test_loss": 0.6483114957809448, "test_mcc": 0.5712085328633058, "test_macro_f1": 0.5322826923403707, "test_runtime": 18.6339, "test_samples_per_second": 109.907, "test_steps_per_second": 13.738}, {"test_loss": 0.7056110501289368, "test_mcc": 0.5309952794519942, "test_macro_f1": 0.5143022983491047, "test_runtime": 18.961, "test_samples_per_second": 108.011, "test_steps_per_second": 13.501}, {"test_loss": 0.6675591468811035, "test_mcc": 0.5489261138381858, "test_macro_f1": 0.5242582897033158, "test_runtime": 18.4978, "test_samples_per_second": 110.716, "test_steps_per_second": 13.84}, {"test_loss": 0.6543031930923462, "test_mcc": 0.5588755534649782, "test_macro_f1": 0.5465397057941529, "test_runtime": 19.112, "test_samples_per_second": 107.158, "test_steps_per_second": 13.395}, {"test_loss": 0.6232612729072571, "test_mcc": 0.5884751488709925, "test_macro_f1": 0.5408838004862672, "test_runtime": 19.0654, "test_samples_per_second": 107.42, "test_steps_per_second": 13.427}, {"test_loss": 0.5904529094696045, "test_mcc": 0.6407591270617552, "test_macro_f1": 0.6287577393437783, "test_runtime": 18.9259, "test_samples_per_second": 108.212, "test_steps_per_second": 13.526}]}, "total": {"test_mcc": 57.641953025872525, "test_mcc_se": 2.014890200825071, "test_macro_f1": 55.058002632766666, "test_macro_f1_se": 2.5016760882572378}}, "num_model_parameters": 124524291, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.9650079011917114, "test_mcc": 0.3005161224248839, "test_macro_f1": 0.5180411616110546, "test_runtime": 5.4794, "test_samples_per_second": 373.761, "test_steps_per_second": 11.68}, {"test_loss": 1.0239757299423218, "test_mcc": 0.28155033955195224, "test_macro_f1": 0.5168117278775036, "test_runtime": 5.4031, "test_samples_per_second": 379.038, "test_steps_per_second": 11.845}, {"test_loss": 0.9927920699119568, "test_mcc": 0.28414444209114703, "test_macro_f1": 0.5165375107574822, "test_runtime": 5.4454, "test_samples_per_second": 376.099, "test_steps_per_second": 11.753}, {"test_loss": 1.0341163873672485, "test_mcc": 0.2748010641527794, "test_macro_f1": 0.5028012358456725, "test_runtime": 5.4231, "test_samples_per_second": 377.644, "test_steps_per_second": 11.801}, {"test_loss": 1.0028992891311646, "test_mcc": 0.26792556733129547, "test_macro_f1": 0.5069905989712644, "test_runtime": 5.3917, "test_samples_per_second": 379.845, "test_steps_per_second": 11.87}, {"test_loss": 1.076905608177185, "test_mcc": 0.2544802068791916, "test_macro_f1": 0.4744450210713172, "test_runtime": 5.3996, "test_samples_per_second": 379.287, "test_steps_per_second": 11.853}, {"test_loss": 1.0192923545837402, "test_mcc": 0.28318659516170913, "test_macro_f1": 0.5122611817295054, "test_runtime": 5.398, "test_samples_per_second": 379.397, "test_steps_per_second": 11.856}, {"test_loss": 1.0540380477905273, "test_mcc": 0.24666426722457135, "test_macro_f1": 0.4906065123732272, "test_runtime": 5.436, "test_samples_per_second": 376.747, "test_steps_per_second": 11.773}, {"test_loss": 0.9945924878120422, "test_mcc": 0.28585401338326133, "test_macro_f1": 0.49549340418303894, "test_runtime": 5.383, "test_samples_per_second": 380.456, "test_steps_per_second": 11.889}, {"test_loss": 0.9823271036148071, "test_mcc": 0.29193352913276654, "test_macro_f1": 0.505104044306186, "test_runtime": 5.3978, "test_samples_per_second": 379.414, "test_steps_per_second": 11.857}]}, "total": {"test_mcc": 27.71056147333558, "test_mcc_se": 1.0286424358262551, "test_macro_f1": 50.390923987262525, "test_macro_f1_se": 0.8577081355412077}}, "num_model_parameters": 124524291, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.9606672525405884, "test_mcc": 0.11735217110474636, "test_macro_f1": 0.30986833957218574, "test_runtime": 4.6046, "test_samples_per_second": 444.768, "test_steps_per_second": 13.899}, {"test_loss": 0.9596224427223206, "test_mcc": 0.18411977601507623, "test_macro_f1": 0.37169437182459425, "test_runtime": 4.3442, "test_samples_per_second": 471.434, "test_steps_per_second": 14.732}, {"test_loss": 0.9401116371154785, "test_mcc": 0.19724787014976017, "test_macro_f1": 0.3800583453366908, "test_runtime": 4.3534, "test_samples_per_second": 470.435, "test_steps_per_second": 14.701}, {"test_loss": 0.963089644908905, "test_mcc": 0.18351392689547646, "test_macro_f1": 0.37523272089044896, "test_runtime": 4.4133, "test_samples_per_second": 464.053, "test_steps_per_second": 14.502}, {"test_loss": 0.9519307017326355, "test_mcc": 0.21330117032974835, "test_macro_f1": 0.39320994122232206, "test_runtime": 4.5052, "test_samples_per_second": 454.582, "test_steps_per_second": 14.206}, {"test_loss": 0.9579856395721436, "test_mcc": 0.24428156538534218, "test_macro_f1": 0.37411020513816085, "test_runtime": 4.6447, "test_samples_per_second": 440.929, "test_steps_per_second": 13.779}, {"test_loss": 0.9452316164970398, "test_mcc": 0.22377589985912805, "test_macro_f1": 0.3921297534780166, "test_runtime": 4.372, "test_samples_per_second": 468.431, "test_steps_per_second": 14.638}, {"test_loss": 0.9547326564788818, "test_mcc": 0.14080895209700003, "test_macro_f1": 0.3395374253208631, "test_runtime": 4.5984, "test_samples_per_second": 445.371, "test_steps_per_second": 13.918}, {"test_loss": 0.9547107219696045, "test_mcc": 0.24026899429948012, "test_macro_f1": 0.46436770411457146, "test_runtime": 4.6137, "test_samples_per_second": 443.896, "test_steps_per_second": 13.872}, {"test_loss": 0.9702872633934021, "test_mcc": 0.1852458039259192, "test_macro_f1": 0.3745247239697295, "test_runtime": 4.6178, "test_samples_per_second": 443.498, "test_steps_per_second": 13.859}]}, "total": {"test_mcc": 19.299161300616774, "test_mcc_se": 2.523335816622333, "test_macro_f1": 37.74733530867584, "test_macro_f1_se": 2.452199039644575}}, "num_model_parameters": 124524291, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.08673973381519318, "test_micro_f1": 0.5903983656792646, "test_micro_f1_no_misc": 0.6452353616532722, "test_runtime": 10.0015, "test_samples_per_second": 204.769, "test_steps_per_second": 6.399}, {"test_loss": 0.07977369427680969, "test_micro_f1": 0.5696969696969698, "test_micro_f1_no_misc": 0.6246134817563389, "test_runtime": 9.1285, "test_samples_per_second": 224.352, "test_steps_per_second": 7.011}, {"test_loss": 0.0796307623386383, "test_micro_f1": 0.5703529411764705, "test_micro_f1_no_misc": 0.6165176223040505, "test_runtime": 9.1433, "test_samples_per_second": 223.988, "test_steps_per_second": 7.0}, {"test_loss": 0.07655902206897736, "test_micro_f1": 0.5953582240161452, "test_micro_f1_no_misc": 0.6386275594908688, "test_runtime": 9.7977, "test_samples_per_second": 209.029, "test_steps_per_second": 6.532}, {"test_loss": 0.0884755551815033, "test_micro_f1": 0.577939835916135, "test_micro_f1_no_misc": 0.6190954773869346, "test_runtime": 9.997, "test_samples_per_second": 204.862, "test_steps_per_second": 6.402}, {"test_loss": 0.0791633278131485, "test_micro_f1": 0.6077140169332079, "test_micro_f1_no_misc": 0.6508620689655172, "test_runtime": 7.5981, "test_samples_per_second": 269.54, "test_steps_per_second": 8.423}, {"test_loss": 0.08819326758384705, "test_micro_f1": 0.5560493827160494, "test_micro_f1_no_misc": 0.608648056923919, "test_runtime": 8.6579, "test_samples_per_second": 236.546, "test_steps_per_second": 7.392}, {"test_loss": 0.07314595580101013, "test_micro_f1": 0.573170731707317, "test_micro_f1_no_misc": 0.606275902901125, "test_runtime": 9.9625, "test_samples_per_second": 205.571, "test_steps_per_second": 6.424}, {"test_loss": 0.08783416450023651, "test_micro_f1": 0.5731166912850811, "test_micro_f1_no_misc": 0.6282051282051281, "test_runtime": 9.5309, "test_samples_per_second": 214.879, "test_steps_per_second": 6.715}, {"test_loss": 0.07793207466602325, "test_micro_f1": 0.6230179028132993, "test_micro_f1_no_misc": 0.6666666666666666, "test_runtime": 9.8001, "test_samples_per_second": 208.977, "test_steps_per_second": 6.531}]}, "total": {"test_micro_f1": 58.36815061939941, "test_micro_f1_se": 1.256403697179687, "test_micro_f1_no_misc": 63.04747326253821, "test_micro_f1_no_misc_se": 1.210982052583273}}, "num_model_parameters": 123938313, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.12308970093727112, "test_micro_f1": 0.6358866736621196, "test_micro_f1_no_misc": 0.6752255378209576, "test_runtime": 10.1242, "test_samples_per_second": 202.287, "test_steps_per_second": 6.321}, {"test_loss": 0.11976610869169235, "test_micro_f1": 0.6364980774918664, "test_micro_f1_no_misc": 0.678227360308285, "test_runtime": 8.6624, "test_samples_per_second": 236.423, "test_steps_per_second": 7.388}, {"test_loss": 0.1167520135641098, "test_micro_f1": 0.6273532668881505, "test_micro_f1_no_misc": 0.679597165236852, "test_runtime": 10.1223, "test_samples_per_second": 202.325, "test_steps_per_second": 6.323}, {"test_loss": 0.12070129811763763, "test_micro_f1": 0.6388286334056399, "test_micro_f1_no_misc": 0.6771653543307087, "test_runtime": 9.9515, "test_samples_per_second": 205.798, "test_steps_per_second": 6.431}, {"test_loss": 0.12983134388923645, "test_micro_f1": 0.5939530940943769, "test_micro_f1_no_misc": 0.6454580298965121, "test_runtime": 10.235, "test_samples_per_second": 200.098, "test_steps_per_second": 6.253}, {"test_loss": 0.12446138262748718, "test_micro_f1": 0.6294730910115525, "test_micro_f1_no_misc": 0.66058532877233, "test_runtime": 10.1871, "test_samples_per_second": 201.039, "test_steps_per_second": 6.282}, {"test_loss": 0.12293657660484314, "test_micro_f1": 0.6480067854113656, "test_micro_f1_no_misc": 0.6747076023391813, "test_runtime": 10.605, "test_samples_per_second": 193.117, "test_steps_per_second": 6.035}, {"test_loss": 0.11285701394081116, "test_micro_f1": 0.6640755136035535, "test_micro_f1_no_misc": 0.703354692800603, "test_runtime": 10.081, "test_samples_per_second": 203.154, "test_steps_per_second": 6.349}, {"test_loss": 0.11259151995182037, "test_micro_f1": 0.6349916154276133, "test_micro_f1_no_misc": 0.6618813751416698, "test_runtime": 9.9022, "test_samples_per_second": 206.822, "test_steps_per_second": 6.463}, {"test_loss": 0.11486399173736572, "test_micro_f1": 0.6441529444599499, "test_micro_f1_no_misc": 0.6885245901639344, "test_runtime": 8.4472, "test_samples_per_second": 242.446, "test_steps_per_second": 7.576}]}, "total": {"test_micro_f1": 63.53219695456188, "test_micro_f1_se": 1.1104472732541997, "test_micro_f1_no_misc": 67.44727036811035, "test_micro_f1_no_misc_se": 0.9850192715225862}}, "num_model_parameters": 123938313, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.08407709002494812, "test_micro_f1": 0.6864661654135339, "test_micro_f1_no_misc": 0.7273497036409822, "test_runtime": 8.1502, "test_samples_per_second": 251.283, "test_steps_per_second": 7.853}, {"test_loss": 0.08608980476856232, "test_micro_f1": 0.6748148148148148, "test_micro_f1_no_misc": 0.7080383173677633, "test_runtime": 8.1995, "test_samples_per_second": 249.772, "test_steps_per_second": 7.805}, {"test_loss": 0.08539137989282608, "test_micro_f1": 0.709700176366843, "test_micro_f1_no_misc": 0.732461355529132, "test_runtime": 8.0218, "test_samples_per_second": 255.305, "test_steps_per_second": 7.978}, {"test_loss": 0.08641523867845535, "test_micro_f1": 0.649789029535865, "test_micro_f1_no_misc": 0.6779400461183704, "test_runtime": 7.9795, "test_samples_per_second": 256.659, "test_steps_per_second": 8.021}, {"test_loss": 0.07814390957355499, "test_micro_f1": 0.7389530931339225, "test_micro_f1_no_misc": 0.763746681835419, "test_runtime": 8.1917, "test_samples_per_second": 250.01, "test_steps_per_second": 7.813}, {"test_loss": 0.08166789263486862, "test_micro_f1": 0.6808957312806159, "test_micro_f1_no_misc": 0.712901975978303, "test_runtime": 8.1557, "test_samples_per_second": 251.113, "test_steps_per_second": 7.847}, {"test_loss": 0.08898264169692993, "test_micro_f1": 0.6826792963464141, "test_micro_f1_no_misc": 0.7044935262757044, "test_runtime": 7.6459, "test_samples_per_second": 267.855, "test_steps_per_second": 8.37}, {"test_loss": 0.08251219987869263, "test_micro_f1": 0.7126275061554695, "test_micro_f1_no_misc": 0.7410266306445388, "test_runtime": 7.8065, "test_samples_per_second": 262.346, "test_steps_per_second": 8.198}, {"test_loss": 0.07443509995937347, "test_micro_f1": 0.6887608069164265, "test_micro_f1_no_misc": 0.7148014440433214, "test_runtime": 8.0023, "test_samples_per_second": 255.926, "test_steps_per_second": 7.998}, {"test_loss": 0.08819664269685745, "test_micro_f1": 0.7044025157232705, "test_micro_f1_no_misc": 0.7382962394474291, "test_runtime": 7.6649, "test_samples_per_second": 267.193, "test_steps_per_second": 8.35}]}, "total": {"test_micro_f1": 69.29089135687175, "test_micro_f1_se": 1.5206446639286713, "test_micro_f1_no_misc": 72.21055920880964, "test_micro_f1_no_misc_se": 1.473348703193872}}, "num_model_parameters": 123938313, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.10964769124984741, "test_micro_f1": 0.5668257756563246, "test_micro_f1_no_misc": 0.5947334617854849, "test_runtime": 7.8895, "test_samples_per_second": 259.584, "test_steps_per_second": 8.112}, {"test_loss": 0.10533583164215088, "test_micro_f1": 0.6137534080581641, "test_micro_f1_no_misc": 0.6570680628272251, "test_runtime": 8.2526, "test_samples_per_second": 248.165, "test_steps_per_second": 7.755}, {"test_loss": 0.11174331605434418, "test_micro_f1": 0.561105874960729, "test_micro_f1_no_misc": 0.5989159891598916, "test_runtime": 7.6967, "test_samples_per_second": 266.088, "test_steps_per_second": 8.315}, {"test_loss": 0.11870172619819641, "test_micro_f1": 0.5795654726952437, "test_micro_f1_no_misc": 0.6290587077730404, "test_runtime": 7.8747, "test_samples_per_second": 260.074, "test_steps_per_second": 8.127}, {"test_loss": 0.1222635805606842, "test_micro_f1": 0.581729300336083, "test_micro_f1_no_misc": 0.6368985808238146, "test_runtime": 7.368, "test_samples_per_second": 277.96, "test_steps_per_second": 8.686}, {"test_loss": 0.10805745422840118, "test_micro_f1": 0.6201879357381024, "test_micro_f1_no_misc": 0.6634681288553803, "test_runtime": 7.6509, "test_samples_per_second": 267.679, "test_steps_per_second": 8.365}, {"test_loss": 0.10072778165340424, "test_micro_f1": 0.614298864682418, "test_micro_f1_no_misc": 0.6573474258438459, "test_runtime": 8.3288, "test_samples_per_second": 245.893, "test_steps_per_second": 7.684}, {"test_loss": 0.10158608853816986, "test_micro_f1": 0.6038437693738377, "test_micro_f1_no_misc": 0.6420168067226891, "test_runtime": 8.3874, "test_samples_per_second": 244.175, "test_steps_per_second": 7.63}, {"test_loss": 0.11634865403175354, "test_micro_f1": 0.5439024390243903, "test_micro_f1_no_misc": 0.5821872953503603, "test_runtime": 7.2837, "test_samples_per_second": 281.175, "test_steps_per_second": 8.787}, {"test_loss": 0.10881122946739197, "test_micro_f1": 0.6357120598317233, "test_micro_f1_no_misc": 0.6728079153872398, "test_runtime": 7.5963, "test_samples_per_second": 269.606, "test_steps_per_second": 8.425}]}, "total": {"test_micro_f1": 59.209249003570164, "test_micro_f1_se": 1.8453182277632179, "test_micro_f1_no_misc": 63.34502374528972, "test_micro_f1_no_misc_se": 1.960330218601745}}, "num_model_parameters": 123938313, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6943896412849426, "test_mcc": 0.020085063803777566, "test_macro_f1": 0.4575951974574775, "test_runtime": 4.6389, "test_samples_per_second": 441.479, "test_steps_per_second": 13.796}, {"test_loss": 0.6924585103988647, "test_mcc": 0.04961363853709031, "test_macro_f1": 0.47450598858711374, "test_runtime": 4.931, "test_samples_per_second": 415.335, "test_steps_per_second": 12.979}, {"test_loss": 0.7021721601486206, "test_mcc": 0.007643700281213138, "test_macro_f1": 0.3397084907372528, "test_runtime": 4.9482, "test_samples_per_second": 413.887, "test_steps_per_second": 12.934}, {"test_loss": 0.6821296811103821, "test_mcc": 0.04799610165569028, "test_macro_f1": 0.5238929760623174, "test_runtime": 4.8575, "test_samples_per_second": 421.616, "test_steps_per_second": 13.175}, {"test_loss": 0.6822723150253296, "test_mcc": 0.04248244414919645, "test_macro_f1": 0.48835817509185675, "test_runtime": 4.9219, "test_samples_per_second": 416.099, "test_steps_per_second": 13.003}, {"test_loss": 0.6846822500228882, "test_mcc": 0.0446180044947045, "test_macro_f1": 0.508198902117903, "test_runtime": 4.791, "test_samples_per_second": 427.469, "test_steps_per_second": 13.358}, {"test_loss": 0.6936373114585876, "test_mcc": -0.011276409853199044, "test_macro_f1": 0.44525216383404936, "test_runtime": 4.8559, "test_samples_per_second": 421.756, "test_steps_per_second": 13.18}, {"test_loss": 0.69163978099823, "test_mcc": 0.06150601037117656, "test_macro_f1": 0.48173739190026055, "test_runtime": 4.8181, "test_samples_per_second": 425.061, "test_steps_per_second": 13.283}, {"test_loss": 0.6912856101989746, "test_mcc": 0.058542282134734315, "test_macro_f1": 0.4887913139634891, "test_runtime": 4.8294, "test_samples_per_second": 424.072, "test_steps_per_second": 13.252}, {"test_loss": 0.6934062242507935, "test_mcc": -0.03237525712696539, "test_macro_f1": 0.34730082212361674, "test_runtime": 4.8627, "test_samples_per_second": 421.168, "test_steps_per_second": 13.161}]}, "total": {"test_mcc": 2.8883557844741876, "test_mcc_se": 1.9671087572213828, "test_macro_f1": 45.55341421875337, "test_macro_f1_se": 3.915451527857605}}, "num_model_parameters": 124523522, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.690284252166748, "test_mcc": 0.034406672595431745, "test_macro_f1": 0.5056596582608144, "test_runtime": 4.6239, "test_samples_per_second": 442.918, "test_steps_per_second": 13.841}, {"test_loss": 0.6939222812652588, "test_mcc": 0.011907394592540952, "test_macro_f1": 0.3790930444218429, "test_runtime": 4.9129, "test_samples_per_second": 416.858, "test_steps_per_second": 13.027}, {"test_loss": 0.6950326561927795, "test_mcc": 0.012143048387000768, "test_macro_f1": 0.46496389612046574, "test_runtime": 4.6884, "test_samples_per_second": 436.826, "test_steps_per_second": 13.651}, {"test_loss": 0.6850733757019043, "test_mcc": 0.06351220952298638, "test_macro_f1": 0.48325432229251186, "test_runtime": 4.8857, "test_samples_per_second": 419.18, "test_steps_per_second": 13.099}, {"test_loss": 0.6926622986793518, "test_mcc": 0.0055601030958266654, "test_macro_f1": 0.49613883968369743, "test_runtime": 4.7165, "test_samples_per_second": 434.222, "test_steps_per_second": 13.569}, {"test_loss": 0.6803902983665466, "test_mcc": 0.11040824245892307, "test_macro_f1": 0.5471627849240461, "test_runtime": 4.7141, "test_samples_per_second": 434.442, "test_steps_per_second": 13.576}, {"test_loss": 0.6946858167648315, "test_mcc": 0.008679430436543898, "test_macro_f1": 0.481792527942858, "test_runtime": 4.5856, "test_samples_per_second": 446.615, "test_steps_per_second": 13.957}, {"test_loss": 0.690547525882721, "test_mcc": 0.02608831422291635, "test_macro_f1": 0.4963705817748243, "test_runtime": 4.6795, "test_samples_per_second": 437.652, "test_steps_per_second": 13.677}, {"test_loss": 0.6924353837966919, "test_mcc": 0.020971716873997365, "test_macro_f1": 0.4368892437542368, "test_runtime": 4.636, "test_samples_per_second": 441.758, "test_steps_per_second": 13.805}, {"test_loss": 0.6934229135513306, "test_mcc": 0.013108862443668923, "test_macro_f1": 0.49837373058346834, "test_runtime": 4.7541, "test_samples_per_second": 430.787, "test_steps_per_second": 13.462}]}, "total": {"test_mcc": 3.067859946298361, "test_mcc_se": 2.0330718753783468, "test_macro_f1": 47.89698629758766, "test_macro_f1_se": 2.795269481243311}}, "num_model_parameters": 124523522, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6913621425628662, "test_mcc": 0.060326536120674776, "test_macro_f1": 0.38143038257886497, "test_runtime": 4.412, "test_samples_per_second": 464.188, "test_steps_per_second": 14.506}, {"test_loss": 0.6932447552680969, "test_mcc": 0.0007131906392189275, "test_macro_f1": 0.4123732845036942, "test_runtime": 4.4247, "test_samples_per_second": 462.857, "test_steps_per_second": 14.464}, {"test_loss": 0.6944621801376343, "test_mcc": 0.034256183817161404, "test_macro_f1": 0.45587076930771053, "test_runtime": 4.4712, "test_samples_per_second": 458.047, "test_steps_per_second": 14.314}, {"test_loss": 0.6916650533676147, "test_mcc": 0.008440165599227105, "test_macro_f1": 0.4693471902774229, "test_runtime": 4.5932, "test_samples_per_second": 445.875, "test_steps_per_second": 13.934}, {"test_loss": 0.6978974938392639, "test_mcc": -0.06236958672058657, "test_macro_f1": 0.371336205088324, "test_runtime": 4.5119, "test_samples_per_second": 453.907, "test_steps_per_second": 14.185}, {"test_loss": 0.6927925944328308, "test_mcc": 0.021352453278831424, "test_macro_f1": 0.49430900090471286, "test_runtime": 4.2575, "test_samples_per_second": 481.036, "test_steps_per_second": 15.032}, {"test_loss": 0.6972231268882751, "test_mcc": -0.04234099144530385, "test_macro_f1": 0.4642426013883814, "test_runtime": 4.3188, "test_samples_per_second": 474.202, "test_steps_per_second": 14.819}, {"test_loss": 0.6917457580566406, "test_mcc": 0.06906535316654681, "test_macro_f1": 0.45219481282137036, "test_runtime": 4.4282, "test_samples_per_second": 462.491, "test_steps_per_second": 14.453}, {"test_loss": 0.6936131715774536, "test_mcc": 0.007762071321744046, "test_macro_f1": 0.48734136909748044, "test_runtime": 4.3224, "test_samples_per_second": 473.809, "test_steps_per_second": 14.807}, {"test_loss": 0.6948586702346802, "test_mcc": 0.013659538845060144, "test_macro_f1": 0.45334665334665336, "test_runtime": 4.4495, "test_samples_per_second": 460.276, "test_steps_per_second": 14.384}]}, "total": {"test_mcc": 1.1086491462257422, "test_mcc_se": 2.5143512004977535, "test_macro_f1": 44.417922693146146, "test_macro_f1_se": 2.609414878208399}}, "num_model_parameters": 124523522, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6912438273429871, "test_mcc": 0.05634241751034599, "test_macro_f1": 0.5155854324212908, "test_runtime": 4.6219, "test_samples_per_second": 443.107, "test_steps_per_second": 13.847}, {"test_loss": 0.7053773403167725, "test_mcc": 0.01365228162267595, "test_macro_f1": 0.38210737245162507, "test_runtime": 4.8123, "test_samples_per_second": 425.577, "test_steps_per_second": 13.299}, {"test_loss": 0.6927926540374756, "test_mcc": 0.048470361037658095, "test_macro_f1": 0.4542388217107902, "test_runtime": 4.7392, "test_samples_per_second": 432.14, "test_steps_per_second": 13.504}, {"test_loss": 0.6903175115585327, "test_mcc": 0.043228532296676205, "test_macro_f1": 0.5138350692381691, "test_runtime": 4.552, "test_samples_per_second": 449.912, "test_steps_per_second": 14.06}, {"test_loss": 0.6991490125656128, "test_mcc": -0.033432203187956755, "test_macro_f1": 0.3815193584537984, "test_runtime": 4.6231, "test_samples_per_second": 442.989, "test_steps_per_second": 13.843}, {"test_loss": 0.6915504336357117, "test_mcc": 0.051834727146250946, "test_macro_f1": 0.503110432536911, "test_runtime": 4.7338, "test_samples_per_second": 432.632, "test_steps_per_second": 13.52}, {"test_loss": 0.702118992805481, "test_mcc": 0.026771165245621325, "test_macro_f1": 0.3559393794778608, "test_runtime": 4.5694, "test_samples_per_second": 448.201, "test_steps_per_second": 14.006}, {"test_loss": 0.6926060914993286, "test_mcc": 0.022043616567992773, "test_macro_f1": 0.5018963107017175, "test_runtime": 4.626, "test_samples_per_second": 442.713, "test_steps_per_second": 13.835}, {"test_loss": 0.6966947913169861, "test_mcc": 0.0015341033731531277, "test_macro_f1": 0.3289291622272243, "test_runtime": 4.6046, "test_samples_per_second": 444.776, "test_steps_per_second": 13.899}, {"test_loss": 0.6923413276672363, "test_mcc": 0.03618215344865398, "test_macro_f1": 0.4968597767219191, "test_runtime": 4.6824, "test_samples_per_second": 437.382, "test_steps_per_second": 13.668}]}, "total": {"test_mcc": 2.6662715506107166, "test_mcc_se": 1.7022561943558154, "test_macro_f1": 44.340211159413066, "test_macro_f1_se": 4.54868995305093}}, "num_model_parameters": 124523522, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_em": 39.27188226181255, "test_f1": 43.64705774625127}, {"test_em": 37.51937984496124, "test_f1": 42.00614253760629}, {"test_em": 29.443585780525503, "test_f1": 32.71744393437275}, {"test_em": 35.82554517133956, "test_f1": 38.91701427187597}, {"test_em": 35.05791505791506, "test_f1": 38.799622060126275}, {"test_em": 34.926754047802625, "test_f1": 38.54142254659285}, {"test_em": 34.3204252088079, "test_f1": 38.71851957692985}, {"test_em": 37.85880527540729, "test_f1": 42.042923496074366}, {"test_em": 36.78431372549019, "test_f1": 41.250723488184796}, {"test_em": 38.04347826086956, "test_f1": 42.03580408549354}]}, "total": {"test_em": 35.90520846349315, "test_em_se": 1.7167548523245622, "test_f1": 39.8676673743508, "test_f1_se": 1.9209765604847489}}, "num_model_parameters": 123932930, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_em": 39.11696359411309, "test_f1": 43.4400383247546}, {"test_em": 38.44961240310077, "test_f1": 43.013239752223846}, {"test_em": 36.08964451313756, "test_f1": 39.83729609714617}, {"test_em": 39.797507788161994, "test_f1": 43.66719852787964}, {"test_em": 40.38610038610039, "test_f1": 44.50127127946678}, {"test_em": 38.781804163454126, "test_f1": 43.14068824447026}, {"test_em": 40.31890660592255, "test_f1": 44.99110795606844}, {"test_em": 33.74709076803724, "test_f1": 37.652634123876865}, {"test_em": 28.784313725490197, "test_f1": 33.387915237396214}, {"test_em": 38.66459627329193, "test_f1": 43.49893170037901}]}, "total": {"test_em": 37.41365402208098, "test_em_se": 2.263515311299247, "test_f1": 41.71303212436618, "test_f1_se": 2.2778046995641654}}, "num_model_parameters": 123932930, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_em": 38.49728892331526, "test_f1": 42.34633597869912}, {"test_em": 36.97674418604651, "test_f1": 41.526087392366456}, {"test_em": 36.476043276661514, "test_f1": 40.13392891518176}, {"test_em": 36.838006230529594, "test_f1": 41.458994017405224}, {"test_em": 34.826254826254825, "test_f1": 39.60216079123643}, {"test_em": 36.85427910562837, "test_f1": 40.42251580087764}, {"test_em": 36.29460895975702, "test_f1": 40.76085424613604}, {"test_em": 36.92785104732351, "test_f1": 41.06471474392343}, {"test_em": 39.21568627450981, "test_f1": 43.78535137808494}, {"test_em": 35.48136645962733, "test_f1": 39.227711046626546}]}, "total": {"test_em": 36.838812928965375, "test_em_se": 0.7934187438502022, "test_f1": 41.032865431053764, "test_f1_se": 0.8337965156126026}}, "num_model_parameters": 123932930, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_speed": 1.89}, {"test_speed": 2.09}, {"test_speed": 2.08}, {"test_speed": 2.08}, {"test_speed": 2.06}, {"test_speed": 2.01}, {"test_speed": 2.05}, {"test_speed": 2.01}, {"test_speed": 1.98}, {"test_speed": 1.93}]}, "total": {"test_speed": 2.018, "test_speed_se": 0.042017003965326025}}, "num_model_parameters": 124521984, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.6491348147392273, "test_mcc": 0.556085547461903, "test_macro_f1": 0.5252941718088847, "test_runtime": 19.2514, "test_samples_per_second": 106.382, "test_steps_per_second": 13.298}, {"test_loss": 0.7632032632827759, "test_mcc": 0.45799122953589, "test_macro_f1": 0.4899083666421949, "test_runtime": 18.5698, "test_samples_per_second": 110.286, "test_steps_per_second": 13.786}, {"test_loss": 0.76799476146698, "test_mcc": 0.4302623930022742, "test_macro_f1": 0.4676311497146511, "test_runtime": 18.8226, "test_samples_per_second": 108.805, "test_steps_per_second": 13.601}, {"test_loss": 0.632042646408081, "test_mcc": 0.5759850052908879, "test_macro_f1": 0.587520906884473, "test_runtime": 18.7303, "test_samples_per_second": 109.342, "test_steps_per_second": 13.668}, {"test_loss": 0.6493436694145203, "test_mcc": 0.5729106035948843, "test_macro_f1": 0.5409414117779524, "test_runtime": 18.6193, "test_samples_per_second": 109.994, "test_steps_per_second": 13.749}, {"test_loss": 0.6188099384307861, "test_mcc": 0.5818214492034978, "test_macro_f1": 0.5426954485330892, "test_runtime": 18.996, "test_samples_per_second": 107.812, "test_steps_per_second": 13.476}, {"test_loss": 0.6656240224838257, "test_mcc": 0.5475539607874329, "test_macro_f1": 0.543396219239833, "test_runtime": 18.4855, "test_samples_per_second": 110.789, "test_steps_per_second": 13.849}, {"test_loss": 0.7047853469848633, "test_mcc": 0.511097613306368, "test_macro_f1": 0.5049877451115469, "test_runtime": 19.1019, "test_samples_per_second": 107.215, "test_steps_per_second": 13.402}, {"test_loss": 0.6979519128799438, "test_mcc": 0.553126841407999, "test_macro_f1": 0.5258748628430395, "test_runtime": 19.0801, "test_samples_per_second": 107.337, "test_steps_per_second": 13.417}, {"test_loss": 0.6398752927780151, "test_mcc": 0.5946854388417928, "test_macro_f1": 0.6213294942015462, "test_runtime": 18.951, "test_samples_per_second": 108.068, "test_steps_per_second": 13.509}]}, "total": {"test_mcc": 53.8152008243293, "test_mcc_se": 3.4057821399183204, "test_macro_f1": 53.495797767572114, "test_macro_f1_se": 2.7738790258795945}}, "num_model_parameters": 109929987, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 1.0245237350463867, "test_mcc": 0.270248149751763, "test_macro_f1": 0.5154929556812823, "test_runtime": 5.7759, "test_samples_per_second": 354.576, "test_steps_per_second": 11.08}, {"test_loss": 0.9913815259933472, "test_mcc": 0.27794192513847144, "test_macro_f1": 0.5016610216557439, "test_runtime": 5.6972, "test_samples_per_second": 359.474, "test_steps_per_second": 11.234}, {"test_loss": 1.0476908683776855, "test_mcc": 0.25737625688853344, "test_macro_f1": 0.5012016860921537, "test_runtime": 5.741, "test_samples_per_second": 356.735, "test_steps_per_second": 11.148}, {"test_loss": 1.0559991598129272, "test_mcc": 0.27139688442948234, "test_macro_f1": 0.5065289864706349, "test_runtime": 5.7649, "test_samples_per_second": 355.256, "test_steps_per_second": 11.102}, {"test_loss": 0.9872147440910339, "test_mcc": 0.3055545011514116, "test_macro_f1": 0.5111200261464081, "test_runtime": 5.6729, "test_samples_per_second": 361.016, "test_steps_per_second": 11.282}, {"test_loss": 1.041698932647705, "test_mcc": 0.2318986326043642, "test_macro_f1": 0.47065816219995726, "test_runtime": 5.6709, "test_samples_per_second": 361.144, "test_steps_per_second": 11.286}, {"test_loss": 0.978852391242981, "test_mcc": 0.30607737081937314, "test_macro_f1": 0.5208548797153966, "test_runtime": 5.723, "test_samples_per_second": 357.854, "test_steps_per_second": 11.183}, {"test_loss": 0.9911614060401917, "test_mcc": 0.299448785981307, "test_macro_f1": 0.5295328889264158, "test_runtime": 5.8328, "test_samples_per_second": 351.118, "test_steps_per_second": 10.972}, {"test_loss": 1.009556770324707, "test_mcc": 0.30208947490275395, "test_macro_f1": 0.5252435343178291, "test_runtime": 5.7417, "test_samples_per_second": 356.689, "test_steps_per_second": 11.147}, {"test_loss": 1.0223554372787476, "test_mcc": 0.23825760847671812, "test_macro_f1": 0.4754462221443026, "test_runtime": 5.7021, "test_samples_per_second": 359.167, "test_steps_per_second": 11.224}]}, "total": {"test_mcc": 27.602895901441784, "test_mcc_se": 1.7015440113844, "test_macro_f1": 50.57740363350124, "test_macro_f1_se": 1.219706567209524}}, "num_model_parameters": 109929987, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.9655096530914307, "test_mcc": 0.1743211712705144, "test_macro_f1": 0.4215712277748069, "test_runtime": 4.7881, "test_samples_per_second": 427.727, "test_steps_per_second": 13.366}, {"test_loss": 0.9632906317710876, "test_mcc": 0.237006753965814, "test_macro_f1": 0.38171041921041926, "test_runtime": 4.5271, "test_samples_per_second": 452.389, "test_steps_per_second": 14.137}, {"test_loss": 0.9577916264533997, "test_mcc": 0.1581998377817628, "test_macro_f1": 0.35070775149419015, "test_runtime": 4.4818, "test_samples_per_second": 456.963, "test_steps_per_second": 14.28}, {"test_loss": 0.9947920441627502, "test_mcc": 0.1431613266123992, "test_macro_f1": 0.33396201192105474, "test_runtime": 4.654, "test_samples_per_second": 440.048, "test_steps_per_second": 13.751}, {"test_loss": 0.9427566528320312, "test_mcc": 0.17789796441518005, "test_macro_f1": 0.4042331026976957, "test_runtime": 4.6674, "test_samples_per_second": 438.792, "test_steps_per_second": 13.712}, {"test_loss": 0.9693564772605896, "test_mcc": 0.19535393945564977, "test_macro_f1": 0.3715866368262832, "test_runtime": 4.7835, "test_samples_per_second": 428.139, "test_steps_per_second": 13.379}, {"test_loss": 0.9517514109611511, "test_mcc": 0.1721939145143215, "test_macro_f1": 0.3630392679400698, "test_runtime": 4.5158, "test_samples_per_second": 453.517, "test_steps_per_second": 14.172}, {"test_loss": 0.9373582601547241, "test_mcc": 0.20882230079953368, "test_macro_f1": 0.3855241358989616, "test_runtime": 4.6561, "test_samples_per_second": 439.852, "test_steps_per_second": 13.745}, {"test_loss": 0.9470341205596924, "test_mcc": 0.16442782210545362, "test_macro_f1": 0.35998645330623996, "test_runtime": 4.8067, "test_samples_per_second": 426.074, "test_steps_per_second": 13.315}, {"test_loss": 0.978742778301239, "test_mcc": 0.24240527617808624, "test_macro_f1": 0.3747035016352836, "test_runtime": 4.8676, "test_samples_per_second": 420.744, "test_steps_per_second": 13.148}]}, "total": {"test_mcc": 18.737903070987155, "test_mcc_se": 2.049279362438397, "test_macro_f1": 37.470245087050046, "test_macro_f1_se": 1.5778763983211752}}, "num_model_parameters": 109929987, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.08561846613883972, "test_micro_f1": 0.5774793388429752, "test_micro_f1_no_misc": 0.6414201183431953, "test_runtime": 9.934, "test_samples_per_second": 206.16, "test_steps_per_second": 6.443}, {"test_loss": 0.07623293250799179, "test_micro_f1": 0.5759162303664921, "test_micro_f1_no_misc": 0.6288416075650118, "test_runtime": 9.1537, "test_samples_per_second": 223.734, "test_steps_per_second": 6.992}, {"test_loss": 0.07122348248958588, "test_micro_f1": 0.5954274353876738, "test_micro_f1_no_misc": 0.6480134303301622, "test_runtime": 9.2543, "test_samples_per_second": 221.302, "test_steps_per_second": 6.916}, {"test_loss": 0.07724165916442871, "test_micro_f1": 0.5699899295065458, "test_micro_f1_no_misc": 0.5986842105263157, "test_runtime": 9.6915, "test_samples_per_second": 211.318, "test_steps_per_second": 6.604}, {"test_loss": 0.08254660665988922, "test_micro_f1": 0.6184145741014279, "test_micro_f1_no_misc": 0.6517094017094017, "test_runtime": 9.8523, "test_samples_per_second": 207.87, "test_steps_per_second": 6.496}, {"test_loss": 0.07170544564723969, "test_micro_f1": 0.6277573529411764, "test_micro_f1_no_misc": 0.6708138932089166, "test_runtime": 7.8194, "test_samples_per_second": 261.912, "test_steps_per_second": 8.185}, {"test_loss": 0.08395247161388397, "test_micro_f1": 0.5911574764033781, "test_micro_f1_no_misc": 0.6319218241042346, "test_runtime": 8.6813, "test_samples_per_second": 235.91, "test_steps_per_second": 7.372}, {"test_loss": 0.07078178226947784, "test_micro_f1": 0.6140254003313086, "test_micro_f1_no_misc": 0.6469544648137197, "test_runtime": 9.8327, "test_samples_per_second": 208.284, "test_steps_per_second": 6.509}, {"test_loss": 0.07504595071077347, "test_micro_f1": 0.6034318398474737, "test_micro_f1_no_misc": 0.6359832635983262, "test_runtime": 9.258, "test_samples_per_second": 221.214, "test_steps_per_second": 6.913}, {"test_loss": 0.07449300587177277, "test_micro_f1": 0.6119691119691119, "test_micro_f1_no_misc": 0.6728361458900382, "test_runtime": 9.5805, "test_samples_per_second": 213.767, "test_steps_per_second": 6.68}]}, "total": {"test_micro_f1": 59.855686896975634, "test_micro_f1_se": 1.2270499206416958, "test_micro_f1_no_misc": 64.27178360089322, "test_micro_f1_no_misc_se": 1.3258713757833722}}, "num_model_parameters": 109344009, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.09221403300762177, "test_micro_f1": 0.6859676577986437, "test_micro_f1_no_misc": 0.706950750960531, "test_runtime": 10.5375, "test_samples_per_second": 194.353, "test_steps_per_second": 6.074}, {"test_loss": 0.0871737003326416, "test_micro_f1": 0.7098050296693982, "test_micro_f1_no_misc": 0.7353048557867835, "test_runtime": 8.9078, "test_samples_per_second": 229.911, "test_steps_per_second": 7.185}, {"test_loss": 0.08974488079547882, "test_micro_f1": 0.7074721780604133, "test_micro_f1_no_misc": 0.7440828402366865, "test_runtime": 10.6452, "test_samples_per_second": 192.388, "test_steps_per_second": 6.012}, {"test_loss": 0.09505504369735718, "test_micro_f1": 0.6774278909764488, "test_micro_f1_no_misc": 0.697594501718213, "test_runtime": 10.0061, "test_samples_per_second": 204.676, "test_steps_per_second": 6.396}, {"test_loss": 0.09720031917095184, "test_micro_f1": 0.6887068461088356, "test_micro_f1_no_misc": 0.7155756207674944, "test_runtime": 10.8204, "test_samples_per_second": 189.273, "test_steps_per_second": 5.915}, {"test_loss": 0.09241355955600739, "test_micro_f1": 0.7046775532798228, "test_micro_f1_no_misc": 0.7178329571106093, "test_runtime": 10.5063, "test_samples_per_second": 194.932, "test_steps_per_second": 6.092}, {"test_loss": 0.0925607979297638, "test_micro_f1": 0.7070815450643776, "test_micro_f1_no_misc": 0.7355163727959698, "test_runtime": 11.34, "test_samples_per_second": 180.599, "test_steps_per_second": 5.644}, {"test_loss": 0.08080564439296722, "test_micro_f1": 0.719369736484651, "test_micro_f1_no_misc": 0.7542857142857142, "test_runtime": 10.4625, "test_samples_per_second": 195.747, "test_steps_per_second": 6.117}, {"test_loss": 0.09704940021038055, "test_micro_f1": 0.722971114167813, "test_micro_f1_no_misc": 0.7425149700598802, "test_runtime": 10.2796, "test_samples_per_second": 199.229, "test_steps_per_second": 6.226}, {"test_loss": 0.09105999767780304, "test_micro_f1": 0.684669939989089, "test_micro_f1_no_misc": 0.7109540636042403, "test_runtime": 8.5384, "test_samples_per_second": 239.858, "test_steps_per_second": 7.496}]}, "total": {"test_micro_f1": 70.08149491599494, "test_micro_f1_se": 0.9666618068259947, "test_micro_f1_no_misc": 72.60612647326121, "test_micro_f1_no_misc_se": 1.1592596576605938}}, "num_model_parameters": 109344009, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.07756244391202927, "test_micro_f1": 0.6727140783744557, "test_micro_f1_no_misc": 0.6996753246753247, "test_runtime": 8.5891, "test_samples_per_second": 238.441, "test_steps_per_second": 7.451}, {"test_loss": 0.07446400821208954, "test_micro_f1": 0.667401690554943, "test_micro_f1_no_misc": 0.6933667083854818, "test_runtime": 8.5441, "test_samples_per_second": 239.698, "test_steps_per_second": 7.491}, {"test_loss": 0.07502730190753937, "test_micro_f1": 0.7020464793617759, "test_micro_f1_no_misc": 0.7201233616037008, "test_runtime": 8.3073, "test_samples_per_second": 246.53, "test_steps_per_second": 7.704}, {"test_loss": 0.07102906703948975, "test_micro_f1": 0.7154989384288747, "test_micro_f1_no_misc": 0.7310891089108912, "test_runtime": 8.2414, "test_samples_per_second": 248.502, "test_steps_per_second": 7.766}, {"test_loss": 0.06891202181577682, "test_micro_f1": 0.7000331455087836, "test_micro_f1_no_misc": 0.7278785634950018, "test_runtime": 8.6854, "test_samples_per_second": 235.798, "test_steps_per_second": 7.369}, {"test_loss": 0.06638216972351074, "test_micro_f1": 0.7114864864864866, "test_micro_f1_no_misc": 0.7449638920562522, "test_runtime": 8.6397, "test_samples_per_second": 237.045, "test_steps_per_second": 7.408}, {"test_loss": 0.0757710263133049, "test_micro_f1": 0.6770247933884298, "test_micro_f1_no_misc": 0.7037173352962827, "test_runtime": 7.6867, "test_samples_per_second": 266.434, "test_steps_per_second": 8.326}, {"test_loss": 0.07228563725948334, "test_micro_f1": 0.6899653979238753, "test_micro_f1_no_misc": 0.7122168585220944, "test_runtime": 8.1767, "test_samples_per_second": 250.468, "test_steps_per_second": 7.827}, {"test_loss": 0.06473032385110855, "test_micro_f1": 0.7131837307152875, "test_micro_f1_no_misc": 0.7320365224295354, "test_runtime": 8.241, "test_samples_per_second": 248.514, "test_steps_per_second": 7.766}, {"test_loss": 0.07826768606901169, "test_micro_f1": 0.6877361731363792, "test_micro_f1_no_misc": 0.7157974300831444, "test_runtime": 7.8261, "test_samples_per_second": 261.688, "test_steps_per_second": 8.178}]}, "total": {"test_micro_f1": 69.37090913879291, "test_micro_f1_se": 1.0815631306377542, "test_micro_f1_no_misc": 71.80865105457708, "test_micro_f1_no_misc_se": 1.008401191665528}}, "num_model_parameters": 109344009, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.0869465321302414, "test_micro_f1": 0.6313178294573643, "test_micro_f1_no_misc": 0.6648847310390913, "test_runtime": 8.232, "test_samples_per_second": 248.786, "test_steps_per_second": 7.775}, {"test_loss": 0.0854405090212822, "test_micro_f1": 0.6730367273813078, "test_micro_f1_no_misc": 0.6967615309126595, "test_runtime": 8.9336, "test_samples_per_second": 229.246, "test_steps_per_second": 7.164}, {"test_loss": 0.09420055896043777, "test_micro_f1": 0.6546894031668696, "test_micro_f1_no_misc": 0.6865771812080537, "test_runtime": 8.0411, "test_samples_per_second": 254.693, "test_steps_per_second": 7.959}, {"test_loss": 0.08919773995876312, "test_micro_f1": 0.6686585001493875, "test_micro_f1_no_misc": 0.6986211424819435, "test_runtime": 8.4782, "test_samples_per_second": 241.561, "test_steps_per_second": 7.549}, {"test_loss": 0.09962497651576996, "test_micro_f1": 0.6365754222481071, "test_micro_f1_no_misc": 0.6729153199741436, "test_runtime": 7.7992, "test_samples_per_second": 262.592, "test_steps_per_second": 8.206}, {"test_loss": 0.09891995042562485, "test_micro_f1": 0.6172839506172839, "test_micro_f1_no_misc": 0.651559934318555, "test_runtime": 8.0968, "test_samples_per_second": 252.939, "test_steps_per_second": 7.904}, {"test_loss": 0.08411511778831482, "test_micro_f1": 0.6840944881889763, "test_micro_f1_no_misc": 0.7210418094585334, "test_runtime": 9.0417, "test_samples_per_second": 226.506, "test_steps_per_second": 7.078}, {"test_loss": 0.08281829953193665, "test_micro_f1": 0.669632265717675, "test_micro_f1_no_misc": 0.6989351403678605, "test_runtime": 8.9919, "test_samples_per_second": 227.76, "test_steps_per_second": 7.118}, {"test_loss": 0.10052265226840973, "test_micro_f1": 0.5903245560318433, "test_micro_f1_no_misc": 0.6150218928932301, "test_runtime": 7.4146, "test_samples_per_second": 276.211, "test_steps_per_second": 8.632}, {"test_loss": 0.0872705727815628, "test_micro_f1": 0.6829997012249777, "test_micro_f1_no_misc": 0.7084701247537754, "test_runtime": 8.0762, "test_samples_per_second": 253.586, "test_steps_per_second": 7.925}]}, "total": {"test_micro_f1": 65.08612844183791, "test_micro_f1_se": 1.9260577348603856, "test_micro_f1_no_misc": 68.14788807407845, "test_micro_f1_no_misc_se": 1.9394492165459183}}, "num_model_parameters": 109344009, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.69487065076828, "test_mcc": -0.017182567514002395, "test_macro_f1": 0.49112658389801833, "test_runtime": 4.5361, "test_samples_per_second": 451.486, "test_steps_per_second": 14.109}, {"test_loss": 0.6931120157241821, "test_mcc": 0.048237615472006376, "test_macro_f1": 0.5238657295634601, "test_runtime": 4.8191, "test_samples_per_second": 424.974, "test_steps_per_second": 13.28}, {"test_loss": 0.7002115249633789, "test_mcc": 0.0020310930662805777, "test_macro_f1": 0.3704749903486856, "test_runtime": 4.8475, "test_samples_per_second": 422.488, "test_steps_per_second": 13.203}, {"test_loss": 0.6914193630218506, "test_mcc": 0.022109078253397828, "test_macro_f1": 0.5055405318488183, "test_runtime": 4.6331, "test_samples_per_second": 442.035, "test_steps_per_second": 13.814}, {"test_loss": 0.6934490203857422, "test_mcc": 0.0063962331640363196, "test_macro_f1": 0.47415344271403237, "test_runtime": 4.7777, "test_samples_per_second": 428.657, "test_steps_per_second": 13.396}, {"test_loss": 0.695875883102417, "test_mcc": -0.014563904898308923, "test_macro_f1": 0.4145014397781267, "test_runtime": 4.6151, "test_samples_per_second": 443.764, "test_steps_per_second": 13.868}, {"test_loss": 0.6952886581420898, "test_mcc": -0.0029703721765947304, "test_macro_f1": 0.49847190180684464, "test_runtime": 4.7158, "test_samples_per_second": 434.281, "test_steps_per_second": 13.571}, {"test_loss": 0.6947013139724731, "test_mcc": 0.018027911216826564, "test_macro_f1": 0.474765344734385, "test_runtime": 4.728, "test_samples_per_second": 433.162, "test_steps_per_second": 13.536}, {"test_loss": 0.6929490566253662, "test_mcc": 0.013622189595630323, "test_macro_f1": 0.4890999601604008, "test_runtime": 4.7101, "test_samples_per_second": 434.813, "test_steps_per_second": 13.588}, {"test_loss": 0.6941555142402649, "test_mcc": -0.006256994251569226, "test_macro_f1": 0.4944341726755914, "test_runtime": 4.7919, "test_samples_per_second": 427.385, "test_steps_per_second": 13.356}]}, "total": {"test_mcc": 0.6945028192770271, "test_mcc_se": 1.2125050908562105, "test_macro_f1": 47.364340975283625, "test_macro_f1_se": 2.868423391300339}}, "num_model_parameters": 109929218, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.6916577816009521, "test_mcc": 0.04847489781774298, "test_macro_f1": 0.5239491691104595, "test_runtime": 4.9628, "test_samples_per_second": 412.674, "test_steps_per_second": 12.896}, {"test_loss": 0.6947141885757446, "test_mcc": 0.01148603466624871, "test_macro_f1": 0.49617932335092707, "test_runtime": 5.274, "test_samples_per_second": 388.321, "test_steps_per_second": 12.135}, {"test_loss": 0.6938430070877075, "test_mcc": 0.002561779162380153, "test_macro_f1": 0.4967198071389688, "test_runtime": 5.0617, "test_samples_per_second": 404.605, "test_steps_per_second": 12.644}, {"test_loss": 0.69411301612854, "test_mcc": 0.0237009363950456, "test_macro_f1": 0.5046474888597545, "test_runtime": 5.3206, "test_samples_per_second": 384.922, "test_steps_per_second": 12.029}, {"test_loss": 0.6926843523979187, "test_mcc": 0.015838980492447575, "test_macro_f1": 0.5048421157559799, "test_runtime": 5.1306, "test_samples_per_second": 399.17, "test_steps_per_second": 12.474}, {"test_loss": 0.691635012626648, "test_mcc": 0.08798049060726659, "test_macro_f1": 0.4801500743979358, "test_runtime": 5.056, "test_samples_per_second": 405.063, "test_steps_per_second": 12.658}, {"test_loss": 0.6906079053878784, "test_mcc": 0.06615897830905142, "test_macro_f1": 0.5217628415696465, "test_runtime": 4.9543, "test_samples_per_second": 413.375, "test_steps_per_second": 12.918}, {"test_loss": 0.6941685676574707, "test_mcc": -0.0016849122902191107, "test_macro_f1": 0.49791423263297013, "test_runtime": 5.0199, "test_samples_per_second": 407.973, "test_steps_per_second": 12.749}, {"test_loss": 0.6935298442840576, "test_mcc": 0.018884587091171974, "test_macro_f1": 0.508075507017301, "test_runtime": 4.9935, "test_samples_per_second": 410.134, "test_steps_per_second": 12.817}, {"test_loss": 0.6962765455245972, "test_mcc": -0.024335375421452997, "test_macro_f1": 0.4731593107959884, "test_runtime": 5.1656, "test_samples_per_second": 396.468, "test_steps_per_second": 12.39}]}, "total": {"test_mcc": 2.4906639682968286, "test_mcc_se": 2.0831769025475593, "test_macro_f1": 50.073998706299314, "test_macro_f1_se": 0.9899923203077282}}, "num_model_parameters": 109929218, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.7027457356452942, "test_mcc": 0.017743301785732007, "test_macro_f1": 0.35462702364629195, "test_runtime": 4.6941, "test_samples_per_second": 436.291, "test_steps_per_second": 13.634}, {"test_loss": 0.6922891139984131, "test_mcc": 0.03734346052533397, "test_macro_f1": 0.5169399137639257, "test_runtime": 4.7909, "test_samples_per_second": 427.476, "test_steps_per_second": 13.359}, {"test_loss": 0.6933209300041199, "test_mcc": 0.03333231077096406, "test_macro_f1": 0.4089416598284014, "test_runtime": 4.7028, "test_samples_per_second": 435.488, "test_steps_per_second": 13.609}, {"test_loss": 0.6938389539718628, "test_mcc": 0.01674488733762254, "test_macro_f1": 0.5041053937302364, "test_runtime": 4.8257, "test_samples_per_second": 424.398, "test_steps_per_second": 13.262}, {"test_loss": 0.6923919320106506, "test_mcc": 0.02927269336828006, "test_macro_f1": 0.4971194481975729, "test_runtime": 4.7969, "test_samples_per_second": 426.94, "test_steps_per_second": 13.342}, {"test_loss": 0.690656304359436, "test_mcc": 0.032391537375181995, "test_macro_f1": 0.4875030332443582, "test_runtime": 4.5444, "test_samples_per_second": 450.667, "test_steps_per_second": 14.083}, {"test_loss": 0.6915527582168579, "test_mcc": 0.02510100625078018, "test_macro_f1": 0.4343942250918995, "test_runtime": 4.5585, "test_samples_per_second": 449.266, "test_steps_per_second": 14.04}, {"test_loss": 0.6912904381752014, "test_mcc": 0.03749129345105499, "test_macro_f1": 0.49864612720732016, "test_runtime": 4.6016, "test_samples_per_second": 445.062, "test_steps_per_second": 13.908}, {"test_loss": 0.6939613819122314, "test_mcc": -0.046891875876948645, "test_macro_f1": 0.3846581356897726, "test_runtime": 4.564, "test_samples_per_second": 448.73, "test_steps_per_second": 14.023}, {"test_loss": 0.697387158870697, "test_mcc": -0.015585313732959178, "test_macro_f1": 0.48577800398627724, "test_runtime": 4.6939, "test_samples_per_second": 436.314, "test_steps_per_second": 13.635}]}, "total": {"test_mcc": 1.6694330125504198, "test_mcc_se": 1.6907701566257365, "test_macro_f1": 45.72712964386055, "test_macro_f1_se": 3.5453644075325927}}, "num_model_parameters": 109929218, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.6948407888412476, "test_mcc": 0.012176231225560672, "test_macro_f1": 0.4832319484220663, "test_runtime": 4.6906, "test_samples_per_second": 436.621, "test_steps_per_second": 13.644}, {"test_loss": 0.6979110240936279, "test_mcc": -0.014283018397361564, "test_macro_f1": 0.4143336242432227, "test_runtime": 4.834, "test_samples_per_second": 423.664, "test_steps_per_second": 13.239}, {"test_loss": 0.6970826387405396, "test_mcc": 0.06760635964465905, "test_macro_f1": 0.3611132538107784, "test_runtime": 4.8455, "test_samples_per_second": 422.662, "test_steps_per_second": 13.208}, {"test_loss": 0.6945791244506836, "test_mcc": 0.0012766035496727041, "test_macro_f1": 0.5005635656424398, "test_runtime": 4.6354, "test_samples_per_second": 441.819, "test_steps_per_second": 13.807}, {"test_loss": 0.700110673904419, "test_mcc": -0.0022126055478807424, "test_macro_f1": 0.3644660518631094, "test_runtime": 4.7551, "test_samples_per_second": 430.692, "test_steps_per_second": 13.459}, {"test_loss": 0.6940208673477173, "test_mcc": 0.025451299296357203, "test_macro_f1": 0.4809662281828551, "test_runtime": 4.8808, "test_samples_per_second": 419.601, "test_steps_per_second": 13.113}, {"test_loss": 0.6939679384231567, "test_mcc": 0.02135753798807745, "test_macro_f1": 0.483647815698057, "test_runtime": 4.6905, "test_samples_per_second": 436.628, "test_steps_per_second": 13.645}, {"test_loss": 0.6938952207565308, "test_mcc": 0.021011610097124024, "test_macro_f1": 0.5104411755908762, "test_runtime": 4.7017, "test_samples_per_second": 435.592, "test_steps_per_second": 13.612}, {"test_loss": 0.7032066583633423, "test_mcc": -0.01223250018504436, "test_macro_f1": 0.35050203631890187, "test_runtime": 4.6578, "test_samples_per_second": 439.695, "test_steps_per_second": 13.74}, {"test_loss": 0.6953990459442139, "test_mcc": -0.035717234472604165, "test_macro_f1": 0.47482120108880244, "test_runtime": 4.8339, "test_samples_per_second": 423.67, "test_steps_per_second": 13.24}]}, "total": {"test_mcc": 0.8443428319856027, "test_mcc_se": 1.7515245648574544, "test_macro_f1": 44.24086900861109, "test_macro_f1_se": 3.910946993320926}}, "num_model_parameters": 109929218, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_em": 34.3144848954299, "test_f1": 37.96770524104076}, {"test_em": 38.29457364341085, "test_f1": 42.34186458776061}, {"test_em": 37.94435857805255, "test_f1": 41.95982558924644}, {"test_em": 30.685358255451714, "test_f1": 34.15819343698675}, {"test_em": 35.5984555984556, "test_f1": 39.076537790823515}, {"test_em": 32.45952197378566, "test_f1": 37.74156285256562}, {"test_em": 24.905087319665906, "test_f1": 29.02240241681486}, {"test_em": 36.46237393328161, "test_f1": 39.85404516230968}, {"test_em": 35.21568627450981, "test_f1": 38.317554750772736}, {"test_em": 37.03416149068323, "test_f1": 40.81533444430777}]}, "total": {"test_em": 34.29140619627268, "test_em_se": 2.5187740151441567, "test_f1": 38.125502627262875, "test_f1_se": 2.4656079191505524}}, "num_model_parameters": 109338626, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_em": 38.342370255615805, "test_f1": 42.634126702216555}, {"test_em": 36.74418604651163, "test_f1": 40.99692447948263}, {"test_em": 37.24884080370943, "test_f1": 40.80977379865798}, {"test_em": 35.82554517133956, "test_f1": 39.43544867595823}, {"test_em": 33.513513513513516, "test_f1": 37.76194560228174}, {"test_em": 35.31225905936777, "test_f1": 39.267738420641905}, {"test_em": 35.45937737281701, "test_f1": 40.07087878151795}, {"test_em": 32.35065942591156, "test_f1": 36.363360243038734}, {"test_em": 36.86274509803921, "test_f1": 41.08123270997066}, {"test_em": 39.0527950310559, "test_f1": 43.027562043364014}]}, "total": {"test_em": 36.07122917778814, "test_em_se": 1.2720596614940485, "test_f1": 40.14489914571304, "test_f1_se": 1.2703501637553096}}, "num_model_parameters": 109338626, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_em": 37.8001549186677, "test_f1": 41.885965929798814}, {"test_em": 36.201550387596896, "test_f1": 39.58555942208474}, {"test_em": 37.17156105100464, "test_f1": 41.33103464758615}, {"test_em": 37.46105919003115, "test_f1": 41.46570665984041}, {"test_em": 32.74131274131274, "test_f1": 37.48041267789169}, {"test_em": 37.162683114880494, "test_f1": 40.92453742607946}, {"test_em": 38.041002277904326, "test_f1": 41.93884772405474}, {"test_em": 37.23816912335143, "test_f1": 41.81879455267399}, {"test_em": 38.745098039215684, "test_f1": 43.23397682671041}, {"test_em": 39.90683229813665, "test_f1": 43.277576739624585}]}, "total": {"test_em": 37.246942314210166, "test_em_se": 1.1633793459326895, "test_f1": 41.2942412606345, "test_f1_se": 1.060924070871973}}, "num_model_parameters": 109338626, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_speed": 2.01}, {"test_speed": 1.97}, {"test_speed": 1.97}, {"test_speed": 1.96}, {"test_speed": 1.96}, {"test_speed": 1.97}, {"test_speed": 1.99}, {"test_speed": 2.06}, {"test_speed": 2.01}, {"test_speed": 1.97}]}, "total": {"test_speed": 1.9869999999999997, "test_speed_se": 0.019610885865876743}}, "num_model_parameters": 109927680, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6571614742279053, "test_mcc": 0.6217131662425853, "test_macro_f1": 0.5853504692241916, "test_runtime": 19.1893, "test_samples_per_second": 106.726, "test_steps_per_second": 13.341}, {"test_loss": 0.7577610611915588, "test_mcc": 0.47061735369751306, "test_macro_f1": 0.4932006934181004, "test_runtime": 18.5561, "test_samples_per_second": 110.368, "test_steps_per_second": 13.796}, {"test_loss": 0.7939605712890625, "test_mcc": 0.4667534336850368, "test_macro_f1": 0.48967074879483646, "test_runtime": 18.7185, "test_samples_per_second": 109.411, "test_steps_per_second": 13.676}, {"test_loss": 0.7120708227157593, "test_mcc": 0.5045446656981655, "test_macro_f1": 0.505871206789355, "test_runtime": 18.8087, "test_samples_per_second": 108.886, "test_steps_per_second": 13.611}, {"test_loss": 0.6877242922782898, "test_mcc": 0.5588557676446889, "test_macro_f1": 0.5282824729575236, "test_runtime": 18.6396, "test_samples_per_second": 109.873, "test_steps_per_second": 13.734}, {"test_loss": 0.6787518262863159, "test_mcc": 0.5471894286230842, "test_macro_f1": 0.5238004939341813, "test_runtime": 18.9851, "test_samples_per_second": 107.874, "test_steps_per_second": 13.484}, {"test_loss": 0.6791466474533081, "test_mcc": 0.5646757049450608, "test_macro_f1": 0.5240781009332246, "test_runtime": 18.5177, "test_samples_per_second": 110.597, "test_steps_per_second": 13.825}, {"test_loss": 0.6997355222702026, "test_mcc": 0.5133175340630494, "test_macro_f1": 0.5103365007173989, "test_runtime": 18.9994, "test_samples_per_second": 107.793, "test_steps_per_second": 13.474}, {"test_loss": 0.6746968030929565, "test_mcc": 0.5476867214684028, "test_macro_f1": 0.5241088481820873, "test_runtime": 19.0177, "test_samples_per_second": 107.689, "test_steps_per_second": 13.461}, {"test_loss": 0.6483197212219238, "test_mcc": 0.5790637425670226, "test_macro_f1": 0.5372740489867115, "test_runtime": 18.8861, "test_samples_per_second": 108.44, "test_steps_per_second": 13.555}]}, "total": {"test_mcc": 53.74417518634609, "test_mcc_se": 3.019560853911611, "test_macro_f1": 52.2197358393761, "test_macro_f1_se": 1.6744235807166812}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 1.0056288242340088, "test_mcc": 0.2846239515125608, "test_macro_f1": 0.5283961122155775, "test_runtime": 5.5321, "test_samples_per_second": 370.205, "test_steps_per_second": 11.569}, {"test_loss": 0.9761267304420471, "test_mcc": 0.32922521944795236, "test_macro_f1": 0.5443991598517496, "test_runtime": 5.5692, "test_samples_per_second": 367.74, "test_steps_per_second": 11.492}, {"test_loss": 0.9785354733467102, "test_mcc": 0.29887796323982474, "test_macro_f1": 0.525032987054643, "test_runtime": 5.5561, "test_samples_per_second": 368.606, "test_steps_per_second": 11.519}, {"test_loss": 0.9899750351905823, "test_mcc": 0.318652859633215, "test_macro_f1": 0.5446575659201015, "test_runtime": 5.5385, "test_samples_per_second": 369.778, "test_steps_per_second": 11.556}, {"test_loss": 0.9764093160629272, "test_mcc": 0.3166661010065646, "test_macro_f1": 0.5202958343077989, "test_runtime": 5.4894, "test_samples_per_second": 373.085, "test_steps_per_second": 11.659}, {"test_loss": 1.039671540260315, "test_mcc": 0.2880353006637674, "test_macro_f1": 0.5057946351032465, "test_runtime": 5.5976, "test_samples_per_second": 365.873, "test_steps_per_second": 11.434}, {"test_loss": 0.9826193451881409, "test_mcc": 0.31767723963489997, "test_macro_f1": 0.5281019298712414, "test_runtime": 5.5641, "test_samples_per_second": 368.075, "test_steps_per_second": 11.502}, {"test_loss": 1.0732860565185547, "test_mcc": 0.16493791138439695, "test_macro_f1": 0.333033062528355, "test_runtime": 5.6417, "test_samples_per_second": 363.014, "test_steps_per_second": 11.344}, {"test_loss": 1.001868486404419, "test_mcc": 0.3286068902422553, "test_macro_f1": 0.5503417318484402, "test_runtime": 5.551, "test_samples_per_second": 368.942, "test_steps_per_second": 11.529}, {"test_loss": 0.9914250373840332, "test_mcc": 0.2796047201864285, "test_macro_f1": 0.5199877305612257, "test_runtime": 5.5252, "test_samples_per_second": 370.665, "test_steps_per_second": 11.583}]}, "total": {"test_mcc": 29.26908156951865, "test_mcc_se": 3.0021338369089845, "test_macro_f1": 51.0004074926238, "test_macro_f1_se": 3.944138905960855}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.9795445799827576, "test_mcc": 0.23040377200769563, "test_macro_f1": 0.38655478757589884, "test_runtime": 4.7177, "test_samples_per_second": 434.112, "test_steps_per_second": 13.566}, {"test_loss": 0.9477376937866211, "test_mcc": 0.1809400449302411, "test_macro_f1": 0.37292280040644804, "test_runtime": 4.423, "test_samples_per_second": 463.034, "test_steps_per_second": 14.47}, {"test_loss": 0.9251837134361267, "test_mcc": 0.20168030737616705, "test_macro_f1": 0.37842340763093857, "test_runtime": 4.3821, "test_samples_per_second": 467.36, "test_steps_per_second": 14.605}, {"test_loss": 0.9693202376365662, "test_mcc": 0.09757932198608983, "test_macro_f1": 0.2695219572692937, "test_runtime": 4.5409, "test_samples_per_second": 451.008, "test_steps_per_second": 14.094}, {"test_loss": 0.9713656902313232, "test_mcc": 0.158266706830084, "test_macro_f1": 0.35814647730437205, "test_runtime": 4.5624, "test_samples_per_second": 448.89, "test_steps_per_second": 14.028}, {"test_loss": 0.9493840336799622, "test_mcc": 0.12130423396594218, "test_macro_f1": 0.32040541344690693, "test_runtime": 4.6062, "test_samples_per_second": 444.619, "test_steps_per_second": 13.894}, {"test_loss": 0.9205485582351685, "test_mcc": 0.24098587882127892, "test_macro_f1": 0.39659901446797025, "test_runtime": 4.401, "test_samples_per_second": 465.351, "test_steps_per_second": 14.542}, {"test_loss": 0.9485695362091064, "test_mcc": 0.24842454404364744, "test_macro_f1": 0.40154232804232803, "test_runtime": 4.5712, "test_samples_per_second": 448.023, "test_steps_per_second": 14.001}, {"test_loss": 0.975283145904541, "test_mcc": 0.02065816375280161, "test_macro_f1": 0.22187414394561977, "test_runtime": 4.7147, "test_samples_per_second": 434.387, "test_steps_per_second": 13.575}, {"test_loss": 0.9516667127609253, "test_mcc": 0.225161586989993, "test_macro_f1": 0.38486384769836235, "test_runtime": 4.655, "test_samples_per_second": 439.957, "test_steps_per_second": 13.749}]}, "total": {"test_mcc": 17.25404560703941, "test_mcc_se": 4.573160392566692, "test_macro_f1": 34.90854177788138, "test_macro_f1_se": 3.7268618397524462}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.08651402592658997, "test_micro_f1": 0.5852895148669797, "test_micro_f1_no_misc": 0.6479713603818616, "test_runtime": 10.244, "test_samples_per_second": 199.922, "test_steps_per_second": 6.248}, {"test_loss": 0.0794895589351654, "test_micro_f1": 0.5792052259118127, "test_micro_f1_no_misc": 0.6210526315789473, "test_runtime": 9.509, "test_samples_per_second": 215.374, "test_steps_per_second": 6.73}, {"test_loss": 0.07394558191299438, "test_micro_f1": 0.6122448979591837, "test_micro_f1_no_misc": 0.6502057613168725, "test_runtime": 9.4265, "test_samples_per_second": 217.26, "test_steps_per_second": 6.789}, {"test_loss": 0.0762106329202652, "test_micro_f1": 0.6391015824400205, "test_micro_f1_no_misc": 0.686936936936937, "test_runtime": 9.8425, "test_samples_per_second": 208.077, "test_steps_per_second": 6.502}, {"test_loss": 0.08457084745168686, "test_micro_f1": 0.6061204343534057, "test_micro_f1_no_misc": 0.658734451054624, "test_runtime": 10.2634, "test_samples_per_second": 199.543, "test_steps_per_second": 6.236}, {"test_loss": 0.08268577605485916, "test_micro_f1": 0.5972420351878269, "test_micro_f1_no_misc": 0.6493236212278877, "test_runtime": 7.8177, "test_samples_per_second": 261.969, "test_steps_per_second": 8.187}, {"test_loss": 0.0880296379327774, "test_micro_f1": 0.6163901458019104, "test_micro_f1_no_misc": 0.6626373626373626, "test_runtime": 8.8708, "test_samples_per_second": 230.87, "test_steps_per_second": 7.215}, {"test_loss": 0.07300800085067749, "test_micro_f1": 0.6218487394957983, "test_micro_f1_no_misc": 0.6594464500601684, "test_runtime": 10.2351, "test_samples_per_second": 200.095, "test_steps_per_second": 6.253}, {"test_loss": 0.08243335783481598, "test_micro_f1": 0.5749880210828942, "test_micro_f1_no_misc": 0.6120777891504606, "test_runtime": 9.4299, "test_samples_per_second": 217.182, "test_steps_per_second": 6.787}, {"test_loss": 0.07433697581291199, "test_micro_f1": 0.5977680737506066, "test_micro_f1_no_misc": 0.6547619047619048, "test_runtime": 9.8233, "test_samples_per_second": 208.484, "test_steps_per_second": 6.515}]}, "total": {"test_micro_f1": 60.30198670850439, "test_micro_f1_se": 1.2495838669320336, "test_micro_f1_no_misc": 65.03148269107027, "test_micro_f1_no_misc_se": 1.3053446793881252}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.09445084631443024, "test_micro_f1": 0.7065217391304347, "test_micro_f1_no_misc": 0.7354020687354021, "test_runtime": 10.9519, "test_samples_per_second": 187.0, "test_steps_per_second": 5.844}, {"test_loss": 0.0945800244808197, "test_micro_f1": 0.6843003412969283, "test_micro_f1_no_misc": 0.7142326272761054, "test_runtime": 8.4662, "test_samples_per_second": 241.904, "test_steps_per_second": 7.559}, {"test_loss": 0.09938602149486542, "test_micro_f1": 0.6516549104720565, "test_micro_f1_no_misc": 0.6885127835794023, "test_runtime": 10.8749, "test_samples_per_second": 188.323, "test_steps_per_second": 5.885}, {"test_loss": 0.09496335685253143, "test_micro_f1": 0.7113642246958324, "test_micro_f1_no_misc": 0.7387451258419, "test_runtime": 10.3204, "test_samples_per_second": 198.441, "test_steps_per_second": 6.201}, {"test_loss": 0.09873586148023605, "test_micro_f1": 0.6657326982347996, "test_micro_f1_no_misc": 0.7069943289224953, "test_runtime": 10.8976, "test_samples_per_second": 187.931, "test_steps_per_second": 5.873}, {"test_loss": 0.09664447605609894, "test_micro_f1": 0.7024471635150167, "test_micro_f1_no_misc": 0.7227256252265314, "test_runtime": 10.8977, "test_samples_per_second": 187.93, "test_steps_per_second": 5.873}, {"test_loss": 0.09087011218070984, "test_micro_f1": 0.7287952458130741, "test_micro_f1_no_misc": 0.7567954220314735, "test_runtime": 11.0167, "test_samples_per_second": 185.9, "test_steps_per_second": 5.809}, {"test_loss": 0.08708226680755615, "test_micro_f1": 0.7275196957348546, "test_micro_f1_no_misc": 0.7618018018018017, "test_runtime": 10.7814, "test_samples_per_second": 189.957, "test_steps_per_second": 5.936}, {"test_loss": 0.09841752052307129, "test_micro_f1": 0.6736222578919209, "test_micro_f1_no_misc": 0.6873198847262247, "test_runtime": 10.413, "test_samples_per_second": 196.677, "test_steps_per_second": 6.146}, {"test_loss": 0.1012464389204979, "test_micro_f1": 0.7284017278617709, "test_micro_f1_no_misc": 0.7554444841128168, "test_runtime": 8.7187, "test_samples_per_second": 234.896, "test_steps_per_second": 7.341}]}, "total": {"test_micro_f1": 69.8036000464669, "test_micro_f1_se": 1.7268296511340646, "test_micro_f1_no_misc": 72.67974152254155, "test_micro_f1_no_misc_se": 1.697841498535073}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.08256593346595764, "test_micro_f1": 0.6493411420204978, "test_micro_f1_no_misc": 0.696656050955414, "test_runtime": 8.4514, "test_samples_per_second": 242.325, "test_steps_per_second": 7.573}, {"test_loss": 0.06495697796344757, "test_micro_f1": 0.728619029988893, "test_micro_f1_no_misc": 0.7626199415936588, "test_runtime": 8.3856, "test_samples_per_second": 244.228, "test_steps_per_second": 7.632}, {"test_loss": 0.07125574350357056, "test_micro_f1": 0.7115520907158044, "test_micro_f1_no_misc": 0.7372549019607844, "test_runtime": 8.1776, "test_samples_per_second": 250.44, "test_steps_per_second": 7.826}, {"test_loss": 0.06070487201213837, "test_micro_f1": 0.7347931873479319, "test_micro_f1_no_misc": 0.7607170693686672, "test_runtime": 8.3622, "test_samples_per_second": 244.911, "test_steps_per_second": 7.653}, {"test_loss": 0.07495957612991333, "test_micro_f1": 0.7839838492597577, "test_micro_f1_no_misc": 0.8039364118092355, "test_runtime": 8.5563, "test_samples_per_second": 239.357, "test_steps_per_second": 7.48}, {"test_loss": 0.05929843708872795, "test_micro_f1": 0.7625602202339986, "test_micro_f1_no_misc": 0.7838353030880671, "test_runtime": 8.4717, "test_samples_per_second": 241.746, "test_steps_per_second": 7.555}, {"test_loss": 0.05879717320203781, "test_micro_f1": 0.7581252138214164, "test_micro_f1_no_misc": 0.7782805429864255, "test_runtime": 8.1723, "test_samples_per_second": 250.604, "test_steps_per_second": 7.831}, {"test_loss": 0.06962599605321884, "test_micro_f1": 0.7100712105798577, "test_micro_f1_no_misc": 0.7320974191203199, "test_runtime": 8.3006, "test_samples_per_second": 246.729, "test_steps_per_second": 7.71}, {"test_loss": 0.061486661434173584, "test_micro_f1": 0.7246170288564304, "test_micro_f1_no_misc": 0.7482185273159145, "test_runtime": 8.1683, "test_samples_per_second": 250.725, "test_steps_per_second": 7.835}, {"test_loss": 0.06523088365793228, "test_micro_f1": 0.7609289617486338, "test_micro_f1_no_misc": 0.7932618683001532, "test_runtime": 7.6628, "test_samples_per_second": 267.265, "test_steps_per_second": 8.352}]}, "total": {"test_micro_f1": 73.24591934573222, "test_micro_f1_se": 2.351888150489882, "test_micro_f1_no_misc": 75.96878036498642, "test_micro_f1_no_misc_se": 2.0022951930274218}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.0871765986084938, "test_micro_f1": 0.6163522012578617, "test_micro_f1_no_misc": 0.6545338441890165, "test_runtime": 8.4298, "test_samples_per_second": 242.946, "test_steps_per_second": 7.592}, {"test_loss": 0.09259843826293945, "test_micro_f1": 0.6169772256728778, "test_micro_f1_no_misc": 0.6548560582094275, "test_runtime": 8.7389, "test_samples_per_second": 234.355, "test_steps_per_second": 7.324}, {"test_loss": 0.08692196011543274, "test_micro_f1": 0.6386006522383634, "test_micro_f1_no_misc": 0.6764518187619656, "test_runtime": 7.8976, "test_samples_per_second": 259.318, "test_steps_per_second": 8.104}, {"test_loss": 0.09707008302211761, "test_micro_f1": 0.6604901374775852, "test_micro_f1_no_misc": 0.7020169160702668, "test_runtime": 8.3163, "test_samples_per_second": 246.265, "test_steps_per_second": 7.696}, {"test_loss": 0.09715482592582703, "test_micro_f1": 0.6638271980529359, "test_micro_f1_no_misc": 0.7096556380823769, "test_runtime": 7.5656, "test_samples_per_second": 270.698, "test_steps_per_second": 8.459}, {"test_loss": 0.10106851160526276, "test_micro_f1": 0.5611095059231436, "test_micro_f1_no_misc": 0.5979064039408867, "test_runtime": 7.8138, "test_samples_per_second": 262.099, "test_steps_per_second": 8.191}, {"test_loss": 0.08337565511465073, "test_micro_f1": 0.6425652310594153, "test_micro_f1_no_misc": 0.6875420875420876, "test_runtime": 8.7881, "test_samples_per_second": 233.042, "test_steps_per_second": 7.283}, {"test_loss": 0.08332694321870804, "test_micro_f1": 0.670878459687124, "test_micro_f1_no_misc": 0.7088353413654617, "test_runtime": 8.8176, "test_samples_per_second": 232.262, "test_steps_per_second": 7.258}, {"test_loss": 0.08791721612215042, "test_micro_f1": 0.651896813353566, "test_micro_f1_no_misc": 0.6913499344692006, "test_runtime": 7.344, "test_samples_per_second": 278.868, "test_steps_per_second": 8.715}, {"test_loss": 0.08216047286987305, "test_micro_f1": 0.6716462503734687, "test_micro_f1_no_misc": 0.7056579783852511, "test_runtime": 8.0914, "test_samples_per_second": 253.107, "test_steps_per_second": 7.91}]}, "total": {"test_micro_f1": 63.943436750963414, "test_micro_f1_se": 2.1071793264315257, "test_micro_f1_no_misc": 67.88806021015941, "test_micro_f1_no_misc_se": 2.1727508188780074}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6928497552871704, "test_mcc": 0.03846378380598497, "test_macro_f1": 0.48972205708251515, "test_runtime": 4.7147, "test_samples_per_second": 434.39, "test_steps_per_second": 13.575}, {"test_loss": 0.6927927136421204, "test_mcc": 0.024204794839172466, "test_macro_f1": 0.3779424902977207, "test_runtime": 5.0102, "test_samples_per_second": 408.764, "test_steps_per_second": 12.774}, {"test_loss": 0.6926897168159485, "test_mcc": 0.017056526847921815, "test_macro_f1": 0.38850831411579073, "test_runtime": 5.0682, "test_samples_per_second": 404.089, "test_steps_per_second": 12.628}, {"test_loss": 0.6928503513336182, "test_mcc": 0.04039834745525655, "test_macro_f1": 0.38442028455344035, "test_runtime": 4.8588, "test_samples_per_second": 421.505, "test_steps_per_second": 13.172}, {"test_loss": 0.6932584047317505, "test_mcc": 0.005891433713581681, "test_macro_f1": 0.33622794094599256, "test_runtime": 4.9856, "test_samples_per_second": 410.779, "test_steps_per_second": 12.837}, {"test_loss": 0.6930623054504395, "test_mcc": 0.012297772738405774, "test_macro_f1": 0.4417556323377151, "test_runtime": 4.898, "test_samples_per_second": 418.127, "test_steps_per_second": 13.066}, {"test_loss": 0.6932264566421509, "test_mcc": 0.036960203392506163, "test_macro_f1": 0.3507947466769319, "test_runtime": 4.944, "test_samples_per_second": 414.243, "test_steps_per_second": 12.945}, {"test_loss": 0.6943217515945435, "test_mcc": 0.0, "test_macro_f1": 0.330718954248366, "test_runtime": 5.0091, "test_samples_per_second": 408.855, "test_steps_per_second": 12.777}, {"test_loss": 0.6928850412368774, "test_mcc": 0.020347768416717454, "test_macro_f1": 0.38961292876115267, "test_runtime": 4.9614, "test_samples_per_second": 412.787, "test_steps_per_second": 12.9}, {"test_loss": 0.6929174065589905, "test_mcc": 0.07126768338782413, "test_macro_f1": 0.36742983568250187, "test_runtime": 5.0226, "test_samples_per_second": 407.76, "test_steps_per_second": 12.742}]}, "total": {"test_mcc": 2.6688831459737097, "test_mcc_se": 1.2919597387702937, "test_macro_f1": 38.57133184702127, "test_macro_f1_se": 2.9989644250757275}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6926891803741455, "test_mcc": 0.03723053233709367, "test_macro_f1": 0.380429838646552, "test_runtime": 4.9009, "test_samples_per_second": 417.883, "test_steps_per_second": 13.059}, {"test_loss": 0.692988932132721, "test_mcc": -0.0016099485095588922, "test_macro_f1": 0.4792075262777984, "test_runtime": 5.1576, "test_samples_per_second": 397.083, "test_steps_per_second": 12.409}, {"test_loss": 0.6927875280380249, "test_mcc": 0.04876394854041717, "test_macro_f1": 0.4593955401908293, "test_runtime": 4.964, "test_samples_per_second": 412.574, "test_steps_per_second": 12.893}, {"test_loss": 0.6931469440460205, "test_mcc": -0.007556685712124145, "test_macro_f1": 0.4389796134142005, "test_runtime": 5.2051, "test_samples_per_second": 393.461, "test_steps_per_second": 12.296}, {"test_loss": 0.6930997371673584, "test_mcc": -0.021889122745952474, "test_macro_f1": 0.39211568264083835, "test_runtime": 5.0257, "test_samples_per_second": 407.507, "test_steps_per_second": 12.735}, {"test_loss": 0.6929491758346558, "test_mcc": 0.0, "test_macro_f1": 0.3311561071195297, "test_runtime": 4.9, "test_samples_per_second": 417.956, "test_steps_per_second": 13.061}, {"test_loss": 0.6931184530258179, "test_mcc": 0.021664040695365497, "test_macro_f1": 0.3723996346432615, "test_runtime": 4.8217, "test_samples_per_second": 424.742, "test_steps_per_second": 13.273}, {"test_loss": 0.6930773258209229, "test_mcc": 0.0, "test_macro_f1": 0.33657272432782637, "test_runtime": 4.9295, "test_samples_per_second": 415.456, "test_steps_per_second": 12.983}, {"test_loss": 0.6925796866416931, "test_mcc": 0.04176207069547759, "test_macro_f1": 0.5119637669600693, "test_runtime": 4.8839, "test_samples_per_second": 419.336, "test_steps_per_second": 13.104}, {"test_loss": 0.6932117938995361, "test_mcc": 0.0, "test_macro_f1": 0.3324641460234681, "test_runtime": 5.0446, "test_samples_per_second": 405.979, "test_steps_per_second": 12.687}]}, "total": {"test_mcc": 1.183648353007184, "test_mcc_se": 1.4776375347599096, "test_macro_f1": 40.34684580244374, "test_macro_f1_se": 4.041550949180352}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6929190754890442, "test_mcc": 0.026897485300908575, "test_macro_f1": 0.4952568347970757, "test_runtime": 4.591, "test_samples_per_second": 446.087, "test_steps_per_second": 13.94}, {"test_loss": 0.6923366189002991, "test_mcc": -0.01138000090106426, "test_macro_f1": 0.49343552500011956, "test_runtime": 4.6536, "test_samples_per_second": 440.092, "test_steps_per_second": 13.753}, {"test_loss": 0.6930631399154663, "test_mcc": 0.056532853083416386, "test_macro_f1": 0.47570265300761755, "test_runtime": 4.6863, "test_samples_per_second": 437.019, "test_steps_per_second": 13.657}, {"test_loss": 0.6926524639129639, "test_mcc": 0.0619714635453023, "test_macro_f1": 0.3836234192864174, "test_runtime": 4.7808, "test_samples_per_second": 428.377, "test_steps_per_second": 13.387}, {"test_loss": 0.6929433941841125, "test_mcc": 0.02646007204731468, "test_macro_f1": 0.50551754918958, "test_runtime": 4.7132, "test_samples_per_second": 434.52, "test_steps_per_second": 13.579}, {"test_loss": 0.6927275657653809, "test_mcc": 0.08714510133156102, "test_macro_f1": 0.5312364280879401, "test_runtime": 4.4832, "test_samples_per_second": 456.815, "test_steps_per_second": 14.275}, {"test_loss": 0.6925349235534668, "test_mcc": 0.03213219425624112, "test_macro_f1": 0.3415779266732302, "test_runtime": 4.5281, "test_samples_per_second": 452.291, "test_steps_per_second": 14.134}, {"test_loss": 0.6929305791854858, "test_mcc": 0.0, "test_macro_f1": 0.3359273670557717, "test_runtime": 4.5911, "test_samples_per_second": 446.076, "test_steps_per_second": 13.94}, {"test_loss": 0.6930640935897827, "test_mcc": 0.015143790318034544, "test_macro_f1": 0.48290418312266215, "test_runtime": 4.6283, "test_samples_per_second": 442.499, "test_steps_per_second": 13.828}, {"test_loss": 0.6926523447036743, "test_mcc": 3.185134848296604e-05, "test_macro_f1": 0.3573375240082057, "test_runtime": 4.6643, "test_samples_per_second": 439.082, "test_steps_per_second": 13.721}]}, "total": {"test_mcc": 2.9493481033019733, "test_mcc_se": 1.9322512079128222, "test_macro_f1": 44.02519410228621, "test_macro_f1_se": 4.718927803635993}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6933687329292297, "test_mcc": 0.0, "test_macro_f1": 0.3236459709379128, "test_runtime": 4.7283, "test_samples_per_second": 433.136, "test_steps_per_second": 13.535}, {"test_loss": 0.692864179611206, "test_mcc": 0.005830522912319483, "test_macro_f1": 0.46399665369949383, "test_runtime": 4.8411, "test_samples_per_second": 423.041, "test_steps_per_second": 13.22}, {"test_loss": 0.6930549144744873, "test_mcc": 0.0, "test_macro_f1": 0.33289902280130296, "test_runtime": 4.9368, "test_samples_per_second": 414.846, "test_steps_per_second": 12.964}, {"test_loss": 0.6925548315048218, "test_mcc": 0.047680418835157515, "test_macro_f1": 0.4618749176338882, "test_runtime": 4.6299, "test_samples_per_second": 442.346, "test_steps_per_second": 13.823}, {"test_loss": 0.6923044919967651, "test_mcc": 0.05871263147799296, "test_macro_f1": 0.4857353817476804, "test_runtime": 4.6847, "test_samples_per_second": 437.165, "test_steps_per_second": 13.661}, {"test_loss": 0.6927347183227539, "test_mcc": 0.015184647453831997, "test_macro_f1": 0.40782533934910675, "test_runtime": 4.8439, "test_samples_per_second": 422.8, "test_steps_per_second": 13.212}, {"test_loss": 0.692948579788208, "test_mcc": 0.04252763830859258, "test_macro_f1": 0.48544560496751726, "test_runtime": 4.667, "test_samples_per_second": 438.822, "test_steps_per_second": 13.713}, {"test_loss": 0.6933274269104004, "test_mcc": 0.0035107649631269024, "test_macro_f1": 0.4699959977956861, "test_runtime": 4.7488, "test_samples_per_second": 431.269, "test_steps_per_second": 13.477}, {"test_loss": 0.6938642263412476, "test_mcc": -0.043352480871805786, "test_macro_f1": 0.4178030745605982, "test_runtime": 4.6954, "test_samples_per_second": 436.172, "test_steps_per_second": 13.63}, {"test_loss": 0.6930320262908936, "test_mcc": 0.0, "test_macro_f1": 0.33764553686934023, "test_runtime": 4.8021, "test_samples_per_second": 426.482, "test_steps_per_second": 13.328}]}, "total": {"test_mcc": 1.3009414307921565, "test_mcc_se": 1.847106148337756, "test_macro_f1": 41.86867500362526, "test_macro_f1_se": 4.058132077243437}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "roberta-base", "results": {"raw": {"test": [{"test_em": 42.60263361735089, "test_f1": 45.94800844219899}, {"test_em": 35.42635658914729, "test_f1": 38.912746854535335}, {"test_em": 35.085007727975274, "test_f1": 38.27473780546668}, {"test_em": 36.37071651090343, "test_f1": 39.53438897398491}, {"test_em": 31.1969111969112, "test_f1": 35.1570675048936}, {"test_em": 37.008481110254436, "test_f1": 40.16921611755846}, {"test_em": 41.45785876993166, "test_f1": 44.741295151317935}, {"test_em": 33.514352211016295, "test_f1": 37.55723773430159}, {"test_em": 32.549019607843135, "test_f1": 35.63175974352445}, {"test_em": 36.49068322981366, "test_f1": 39.30060665697312}]}, "total": {"test_em": 36.17020205711473, "test_em_se": 2.232949499959924, "test_f1": 39.52270649847551, "test_f1_se": 2.1567564140847013}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "roberta-base", "results": {"raw": {"test": [{"test_em": 40.35631293570875, "test_f1": 44.472623208669134}, {"test_em": 35.736434108527135, "test_f1": 39.266331700848234}, {"test_em": 37.480680061823804, "test_f1": 41.589329541812965}, {"test_em": 40.965732087227416, "test_f1": 44.88751238013414}, {"test_em": 34.20849420849421, "test_f1": 38.27213896961797}, {"test_em": 35.389360061680804, "test_f1": 39.36829658869208}, {"test_em": 35.7630979498861, "test_f1": 39.765952040347834}, {"test_em": 35.06594259115594, "test_f1": 38.78377419494566}, {"test_em": 32.0, "test_f1": 35.94338687072253}, {"test_em": 30.20186335403727, "test_f1": 34.37588184500621}]}, "total": {"test_em": 35.71679173585414, "test_em_se": 2.0580012164094326, "test_f1": 39.67252273407968, "test_f1_se": 2.0545158345281536}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "roberta-base", "results": {"raw": {"test": [{"test_em": 39.504260263361736, "test_f1": 43.95966856713201}, {"test_em": 38.21705426356589, "test_f1": 41.92639629712133}, {"test_em": 35.7032457496136, "test_f1": 39.81269859031474}, {"test_em": 42.912772585669785, "test_f1": 47.50924309335526}, {"test_em": 41.6988416988417, "test_f1": 46.68706832240666}, {"test_em": 43.79336931380108, "test_f1": 47.211860999447744}, {"test_em": 35.68716780561883, "test_f1": 39.47889545113041}, {"test_em": 37.85880527540729, "test_f1": 42.09826863685302}, {"test_em": 45.568627450980394, "test_f1": 49.34210542757255}, {"test_em": 41.692546583850934, "test_f1": 45.63314661528948}]}, "total": {"test_em": 40.26366909907112, "test_em_se": 2.1070486859589335, "test_f1": 44.365935200062324, "test_f1_se": 2.1231751951793756}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "roberta-base", "results": {"raw": {"test": [{"test_speed": 1.92}, {"test_speed": 1.9}, {"test_speed": 1.85}, {"test_speed": 1.82}, {"test_speed": 1.91}, {"test_speed": 1.94}, {"test_speed": 1.93}, {"test_speed": 1.97}, {"test_speed": 2.01}, {"test_speed": 1.95}]}, "total": {"test_speed": 1.92, "test_speed_se": 0.034198739417963565}}, "num_model_parameters": 124645632, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.7206524610519409, "test_mcc": 0.5155661558407136, "test_macro_f1": 0.5097095592737312, "test_runtime": 19.0805, "test_samples_per_second": 107.335, "test_steps_per_second": 13.417}, {"test_loss": 0.716641366481781, "test_mcc": 0.5336997336874298, "test_macro_f1": 0.5179463184878347, "test_runtime": 18.3274, "test_samples_per_second": 111.745, "test_steps_per_second": 13.968}, {"test_loss": 0.7387231588363647, "test_mcc": 0.48657327504237086, "test_macro_f1": 0.499542443673636, "test_runtime": 18.4995, "test_samples_per_second": 110.706, "test_steps_per_second": 13.838}, {"test_loss": 0.6145859360694885, "test_mcc": 0.5829982535767981, "test_macro_f1": 0.5375839425290538, "test_runtime": 18.5314, "test_samples_per_second": 110.515, "test_steps_per_second": 13.814}, {"test_loss": 0.6219760179519653, "test_mcc": 0.5931412806115902, "test_macro_f1": 0.5463170653400607, "test_runtime": 18.3785, "test_samples_per_second": 111.434, "test_steps_per_second": 13.929}, {"test_loss": 0.6757204532623291, "test_mcc": 0.5205766288005247, "test_macro_f1": 0.5124632974764901, "test_runtime": 18.7098, "test_samples_per_second": 109.462, "test_steps_per_second": 13.683}, {"test_loss": 0.7293461561203003, "test_mcc": 0.48900600120662474, "test_macro_f1": 0.4899110722725208, "test_runtime": 18.2363, "test_samples_per_second": 112.304, "test_steps_per_second": 14.038}, {"test_loss": 0.7031986713409424, "test_mcc": 0.49888192256239156, "test_macro_f1": 0.5050109640217656, "test_runtime": 18.8149, "test_samples_per_second": 108.85, "test_steps_per_second": 13.606}, {"test_loss": 0.6476960182189941, "test_mcc": 0.5779767136257327, "test_macro_f1": 0.5326491327044548, "test_runtime": 18.6754, "test_samples_per_second": 109.663, "test_steps_per_second": 13.708}, {"test_loss": 0.6531686782836914, "test_mcc": 0.5968259664940406, "test_macro_f1": 0.5614005767124263, "test_runtime": 18.648, "test_samples_per_second": 109.824, "test_steps_per_second": 13.728}]}, "total": {"test_mcc": 53.95245931448216, "test_mcc_se": 2.733204928414402, "test_macro_f1": 52.12534372491974, "test_macro_f1_se": 1.3975102791998277}}, "num_model_parameters": 116764419, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 1.03652024269104, "test_mcc": 0.2459339306138409, "test_macro_f1": 0.4935847371886388, "test_runtime": 5.6077, "test_samples_per_second": 365.214, "test_steps_per_second": 11.413}, {"test_loss": 0.9753551483154297, "test_mcc": 0.29356510847989564, "test_macro_f1": 0.5133016120348662, "test_runtime": 5.6299, "test_samples_per_second": 363.77, "test_steps_per_second": 11.368}, {"test_loss": 0.9960486888885498, "test_mcc": 0.3122407942754223, "test_macro_f1": 0.5368938960473961, "test_runtime": 5.6182, "test_samples_per_second": 364.527, "test_steps_per_second": 11.391}, {"test_loss": 0.9908627867698669, "test_mcc": 0.290820286810516, "test_macro_f1": 0.5216593428333328, "test_runtime": 5.581, "test_samples_per_second": 366.959, "test_steps_per_second": 11.467}, {"test_loss": 0.9601826667785645, "test_mcc": 0.33636892958442377, "test_macro_f1": 0.556612609490248, "test_runtime": 5.5287, "test_samples_per_second": 370.428, "test_steps_per_second": 11.576}, {"test_loss": 1.0005719661712646, "test_mcc": 0.27743522330511194, "test_macro_f1": 0.5027824472485776, "test_runtime": 5.6241, "test_samples_per_second": 364.145, "test_steps_per_second": 11.38}, {"test_loss": 0.9719862341880798, "test_mcc": 0.3346952123033075, "test_macro_f1": 0.5440815834028695, "test_runtime": 5.6536, "test_samples_per_second": 362.244, "test_steps_per_second": 11.32}, {"test_loss": 1.0009160041809082, "test_mcc": 0.30943827923977185, "test_macro_f1": 0.5398598784563075, "test_runtime": 5.7248, "test_samples_per_second": 357.742, "test_steps_per_second": 11.179}, {"test_loss": 0.9831584692001343, "test_mcc": 0.28894570838676137, "test_macro_f1": 0.5250612873308101, "test_runtime": 5.6377, "test_samples_per_second": 363.268, "test_steps_per_second": 11.352}, {"test_loss": 0.9749265313148499, "test_mcc": 0.28598280323312625, "test_macro_f1": 0.5190892448710861, "test_runtime": 5.5879, "test_samples_per_second": 366.509, "test_steps_per_second": 11.453}]}, "total": {"test_mcc": 29.75426276232177, "test_mcc_se": 1.6761089743620587, "test_macro_f1": 52.52926638904133, "test_macro_f1_se": 1.2026267073124028}}, "num_model_parameters": 116764419, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.9624254703521729, "test_mcc": 0.21752319218619134, "test_macro_f1": 0.3848238057265862, "test_runtime": 4.5922, "test_samples_per_second": 445.977, "test_steps_per_second": 13.937}, {"test_loss": 0.9214726090431213, "test_mcc": 0.24701848295228987, "test_macro_f1": 0.4066507581792979, "test_runtime": 4.2916, "test_samples_per_second": 477.208, "test_steps_per_second": 14.913}, {"test_loss": 0.941436231136322, "test_mcc": 0.1771849115009047, "test_macro_f1": 0.33621151099317886, "test_runtime": 4.3407, "test_samples_per_second": 471.816, "test_steps_per_second": 14.744}, {"test_loss": 0.9603099822998047, "test_mcc": 0.24236315087740512, "test_macro_f1": 0.4204838811821898, "test_runtime": 4.4058, "test_samples_per_second": 464.846, "test_steps_per_second": 14.526}, {"test_loss": 0.9513602256774902, "test_mcc": 0.18606128601545718, "test_macro_f1": 0.3769571499632849, "test_runtime": 4.5017, "test_samples_per_second": 454.942, "test_steps_per_second": 14.217}, {"test_loss": 0.9517605304718018, "test_mcc": 0.22841357190472758, "test_macro_f1": 0.42757255494898067, "test_runtime": 4.5495, "test_samples_per_second": 450.154, "test_steps_per_second": 14.067}, {"test_loss": 0.929668664932251, "test_mcc": 0.18179007664912641, "test_macro_f1": 0.39563162921370604, "test_runtime": 4.3721, "test_samples_per_second": 468.429, "test_steps_per_second": 14.638}, {"test_loss": 0.925506591796875, "test_mcc": 0.2211213360521134, "test_macro_f1": 0.3857273832194634, "test_runtime": 4.5065, "test_samples_per_second": 454.45, "test_steps_per_second": 14.202}, {"test_loss": 0.9785333871841431, "test_mcc": 0.012742443066394741, "test_macro_f1": 0.2355135954847727, "test_runtime": 4.6282, "test_samples_per_second": 442.503, "test_steps_per_second": 13.828}, {"test_loss": 0.9434542655944824, "test_mcc": 0.19753334325772848, "test_macro_f1": 0.3770597091111154, "test_runtime": 4.5807, "test_samples_per_second": 447.097, "test_steps_per_second": 13.972}]}, "total": {"test_mcc": 19.117517944623387, "test_mcc_se": 4.178525008044485, "test_macro_f1": 37.46631978022577, "test_macro_f1_se": 3.422345462356898}}, "num_model_parameters": 116764419, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.09347143769264221, "test_micro_f1": 0.5301701908200104, "test_micro_f1_no_misc": 0.5773195876288659, "test_runtime": 10.0891, "test_samples_per_second": 202.992, "test_steps_per_second": 6.343}, {"test_loss": 0.09314437955617905, "test_micro_f1": 0.5166212534059945, "test_micro_f1_no_misc": 0.5515615792575131, "test_runtime": 9.3719, "test_samples_per_second": 218.526, "test_steps_per_second": 6.829}, {"test_loss": 0.0877617746591568, "test_micro_f1": 0.5064133016627079, "test_micro_f1_no_misc": 0.5457429931253306, "test_runtime": 9.4154, "test_samples_per_second": 217.516, "test_steps_per_second": 6.797}, {"test_loss": 0.08669845014810562, "test_micro_f1": 0.548014077425842, "test_micro_f1_no_misc": 0.5914396887159533, "test_runtime": 9.7245, "test_samples_per_second": 210.602, "test_steps_per_second": 6.581}, {"test_loss": 0.09047938138246536, "test_micro_f1": 0.548868560423688, "test_micro_f1_no_misc": 0.575089697590979, "test_runtime": 10.0026, "test_samples_per_second": 204.747, "test_steps_per_second": 6.398}, {"test_loss": 0.08628236502408981, "test_micro_f1": 0.5539772727272727, "test_micro_f1_no_misc": 0.5972944849115505, "test_runtime": 7.9057, "test_samples_per_second": 259.052, "test_steps_per_second": 8.095}, {"test_loss": 0.09745647758245468, "test_micro_f1": 0.533135509396637, "test_micro_f1_no_misc": 0.583100167879127, "test_runtime": 8.6718, "test_samples_per_second": 236.167, "test_steps_per_second": 7.38}, {"test_loss": 0.08055458217859268, "test_micro_f1": 0.5329018338727076, "test_micro_f1_no_misc": 0.5645821157218002, "test_runtime": 10.0794, "test_samples_per_second": 203.187, "test_steps_per_second": 6.35}, {"test_loss": 0.08342316746711731, "test_micro_f1": 0.5475504322766571, "test_micro_f1_no_misc": 0.5991140642303434, "test_runtime": 9.1892, "test_samples_per_second": 222.87, "test_steps_per_second": 6.965}, {"test_loss": 0.08407115936279297, "test_micro_f1": 0.5564874198322644, "test_micro_f1_no_misc": 0.5970307529162248, "test_runtime": 9.7728, "test_samples_per_second": 209.561, "test_steps_per_second": 6.549}]}, "total": {"test_micro_f1": 53.74139851843782, "test_micro_f1_se": 1.0265803834544394, "test_micro_f1_no_misc": 57.82275131977689, "test_micro_f1_no_misc_se": 1.1895057474677142}}, "num_model_parameters": 116178441, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.12104997038841248, "test_micro_f1": 0.6143520908621579, "test_micro_f1_no_misc": 0.6494367130550034, "test_runtime": 10.5096, "test_samples_per_second": 194.869, "test_steps_per_second": 6.09}, {"test_loss": 0.11136318743228912, "test_micro_f1": 0.6319619367478309, "test_micro_f1_no_misc": 0.6606886657101865, "test_runtime": 8.1147, "test_samples_per_second": 252.382, "test_steps_per_second": 7.887}, {"test_loss": 0.11153827607631683, "test_micro_f1": 0.6235011990407674, "test_micro_f1_no_misc": 0.6545071904594879, "test_runtime": 10.5899, "test_samples_per_second": 193.392, "test_steps_per_second": 6.043}, {"test_loss": 0.11415274441242218, "test_micro_f1": 0.618163317222081, "test_micro_f1_no_misc": 0.6609938733832538, "test_runtime": 9.9398, "test_samples_per_second": 206.04, "test_steps_per_second": 6.439}, {"test_loss": 0.11878751963376999, "test_micro_f1": 0.6212207644038791, "test_micro_f1_no_misc": 0.6630513376717281, "test_runtime": 10.6798, "test_samples_per_second": 191.763, "test_steps_per_second": 5.993}, {"test_loss": 0.11432121694087982, "test_micro_f1": 0.6191004997223765, "test_micro_f1_no_misc": 0.6483314998166483, "test_runtime": 10.3349, "test_samples_per_second": 198.163, "test_steps_per_second": 6.193}, {"test_loss": 0.11141449958086014, "test_micro_f1": 0.6416200373034905, "test_micro_f1_no_misc": 0.6675967910708057, "test_runtime": 10.7778, "test_samples_per_second": 190.021, "test_steps_per_second": 5.938}, {"test_loss": 0.10710138082504272, "test_micro_f1": 0.6073298429319373, "test_micro_f1_no_misc": 0.6327724945135333, "test_runtime": 10.2903, "test_samples_per_second": 199.022, "test_steps_per_second": 6.219}, {"test_loss": 0.11260691285133362, "test_micro_f1": 0.6247576848518415, "test_micro_f1_no_misc": 0.6741410488245931, "test_runtime": 9.9234, "test_samples_per_second": 206.382, "test_steps_per_second": 6.449}, {"test_loss": 0.11790213733911514, "test_micro_f1": 0.6415591256254939, "test_micro_f1_no_misc": 0.6925287356321839, "test_runtime": 8.2094, "test_samples_per_second": 249.471, "test_steps_per_second": 7.796}]}, "total": {"test_micro_f1": 62.435664987118564, "test_micro_f1_se": 0.6909611907562004, "test_micro_f1_no_misc": 66.04048350137424, "test_micro_f1_no_misc_se": 1.0002996054183542}}, "num_model_parameters": 116178441, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.07627305388450623, "test_micro_f1": 0.6087272727272727, "test_micro_f1_no_misc": 0.65083135391924, "test_runtime": 7.9724, "test_samples_per_second": 256.886, "test_steps_per_second": 8.028}, {"test_loss": 0.07644087076187134, "test_micro_f1": 0.6568345323741006, "test_micro_f1_no_misc": 0.6751188589540411, "test_runtime": 7.9056, "test_samples_per_second": 259.058, "test_steps_per_second": 8.096}, {"test_loss": 0.08249145746231079, "test_micro_f1": 0.6517086641353124, "test_micro_f1_no_misc": 0.6692337312283404, "test_runtime": 7.9172, "test_samples_per_second": 258.677, "test_steps_per_second": 8.084}, {"test_loss": 0.08325359225273132, "test_micro_f1": 0.6153846153846154, "test_micro_f1_no_misc": 0.6360924683072334, "test_runtime": 8.0177, "test_samples_per_second": 255.434, "test_steps_per_second": 7.982}, {"test_loss": 0.07885035872459412, "test_micro_f1": 0.6219035202086051, "test_micro_f1_no_misc": 0.6440677966101696, "test_runtime": 7.9944, "test_samples_per_second": 256.179, "test_steps_per_second": 8.006}, {"test_loss": 0.07709117233753204, "test_micro_f1": 0.6613065326633166, "test_micro_f1_no_misc": 0.6704246523863209, "test_runtime": 7.9542, "test_samples_per_second": 257.475, "test_steps_per_second": 8.046}, {"test_loss": 0.072735495865345, "test_micro_f1": 0.6847090663058186, "test_micro_f1_no_misc": 0.7021755438859715, "test_runtime": 7.4876, "test_samples_per_second": 273.517, "test_steps_per_second": 8.547}, {"test_loss": 0.07203476130962372, "test_micro_f1": 0.6940298507462687, "test_micro_f1_no_misc": 0.7119505993461679, "test_runtime": 7.8566, "test_samples_per_second": 260.673, "test_steps_per_second": 8.146}, {"test_loss": 0.0729895830154419, "test_micro_f1": 0.6652690426275332, "test_micro_f1_no_misc": 0.6739984289080911, "test_runtime": 7.8945, "test_samples_per_second": 259.421, "test_steps_per_second": 8.107}, {"test_loss": 0.07666300237178802, "test_micro_f1": 0.6678047115056334, "test_micro_f1_no_misc": 0.6958861976163014, "test_runtime": 7.3096, "test_samples_per_second": 280.181, "test_steps_per_second": 8.756}]}, "total": {"test_micro_f1": 65.27677808678477, "test_micro_f1_se": 1.7874888897237424, "test_micro_f1_no_misc": 67.29779631161878, "test_micro_f1_no_misc_se": 1.5473280399592564}}, "num_model_parameters": 116178441, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.09151124954223633, "test_micro_f1": 0.590727663494013, "test_micro_f1_no_misc": 0.6272965879265091, "test_runtime": 8.016, "test_samples_per_second": 255.489, "test_steps_per_second": 7.984}, {"test_loss": 0.09439918398857117, "test_micro_f1": 0.641203007518797, "test_micro_f1_no_misc": 0.6769432600852738, "test_runtime": 8.598, "test_samples_per_second": 238.195, "test_steps_per_second": 7.444}, {"test_loss": 0.1029835194349289, "test_micro_f1": 0.5767333913548013, "test_micro_f1_no_misc": 0.6131929389903996, "test_runtime": 7.712, "test_samples_per_second": 265.559, "test_steps_per_second": 8.299}, {"test_loss": 0.1111832708120346, "test_micro_f1": 0.5806071323312703, "test_micro_f1_no_misc": 0.6175260993356533, "test_runtime": 7.9797, "test_samples_per_second": 256.652, "test_steps_per_second": 8.02}, {"test_loss": 0.10945311188697815, "test_micro_f1": 0.5486090338019742, "test_micro_f1_no_misc": 0.5923734385272847, "test_runtime": 7.3101, "test_samples_per_second": 280.161, "test_steps_per_second": 8.755}, {"test_loss": 0.09860499203205109, "test_micro_f1": 0.624381728251382, "test_micro_f1_no_misc": 0.6566592143085277, "test_runtime": 7.2598, "test_samples_per_second": 282.102, "test_steps_per_second": 8.816}, {"test_loss": 0.08210226148366928, "test_micro_f1": 0.656960873521383, "test_micro_f1_no_misc": 0.6965769358590894, "test_runtime": 8.7157, "test_samples_per_second": 234.98, "test_steps_per_second": 7.343}, {"test_loss": 0.09531781077384949, "test_micro_f1": 0.5897590361445784, "test_micro_f1_no_misc": 0.6277561608300908, "test_runtime": 8.6239, "test_samples_per_second": 237.48, "test_steps_per_second": 7.421}, {"test_loss": 0.10889127105474472, "test_micro_f1": 0.536014405762305, "test_micro_f1_no_misc": 0.5719806763285024, "test_runtime": 7.1364, "test_samples_per_second": 286.98, "test_steps_per_second": 8.968}, {"test_loss": 0.09697894752025604, "test_micro_f1": 0.6488970588235293, "test_micro_f1_no_misc": 0.6772172766238048, "test_runtime": 7.6873, "test_samples_per_second": 266.413, "test_steps_per_second": 8.325}]}, "total": {"test_micro_f1": 59.93893331004033, "test_micro_f1_se": 2.5942640482188346, "test_micro_f1_no_misc": 63.57522588815135, "test_micro_f1_no_misc_se": 2.4859206228268973}}, "num_model_parameters": 116178441, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.6939754486083984, "test_mcc": 0.009508464720369083, "test_macro_f1": 0.45921055593738375, "test_runtime": 4.6128, "test_samples_per_second": 443.986, "test_steps_per_second": 13.875}, {"test_loss": 0.6915080547332764, "test_mcc": 0.054797381783963074, "test_macro_f1": 0.4795180722891566, "test_runtime": 4.949, "test_samples_per_second": 413.824, "test_steps_per_second": 12.932}, {"test_loss": 0.6927154660224915, "test_mcc": 0.027227842456737365, "test_macro_f1": 0.5126655679667949, "test_runtime": 4.9638, "test_samples_per_second": 412.587, "test_steps_per_second": 12.893}, {"test_loss": 0.6960396766662598, "test_mcc": -0.034410670974418835, "test_macro_f1": 0.448431422285597, "test_runtime": 4.8395, "test_samples_per_second": 423.189, "test_steps_per_second": 13.225}, {"test_loss": 0.6938647031784058, "test_mcc": 0.0029081474647419414, "test_macro_f1": 0.48299966117724147, "test_runtime": 4.9358, "test_samples_per_second": 414.93, "test_steps_per_second": 12.967}, {"test_loss": 0.6945037841796875, "test_mcc": -0.014284652109759923, "test_macro_f1": 0.48393706186823304, "test_runtime": 4.7938, "test_samples_per_second": 427.217, "test_steps_per_second": 13.351}, {"test_loss": 0.6937869191169739, "test_mcc": -0.014476478693927772, "test_macro_f1": 0.44905926963860887, "test_runtime": 4.9294, "test_samples_per_second": 415.467, "test_steps_per_second": 12.983}, {"test_loss": 0.6920794248580933, "test_mcc": 0.050429320212507886, "test_macro_f1": 0.4966817281664714, "test_runtime": 4.8263, "test_samples_per_second": 424.345, "test_steps_per_second": 13.261}, {"test_loss": 0.6926367282867432, "test_mcc": 0.004160573928664382, "test_macro_f1": 0.4990805154474362, "test_runtime": 4.8521, "test_samples_per_second": 422.083, "test_steps_per_second": 13.19}, {"test_loss": 0.6923709511756897, "test_mcc": 0.02992457506265195, "test_macro_f1": 0.5148117795679108, "test_runtime": 4.9148, "test_samples_per_second": 416.696, "test_steps_per_second": 13.022}]}, "total": {"test_mcc": 1.1578450385152916, "test_mcc_se": 1.7958934820484815, "test_macro_f1": 48.263956343448335, "test_macro_f1_se": 1.4987426875198608}}, "num_model_parameters": 116763650, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.6924730539321899, "test_mcc": 0.011654889404087508, "test_macro_f1": 0.4773956800415511, "test_runtime": 4.8268, "test_samples_per_second": 424.296, "test_steps_per_second": 13.259}, {"test_loss": 0.693625807762146, "test_mcc": -0.021172176178366062, "test_macro_f1": 0.39830556411739376, "test_runtime": 5.1096, "test_samples_per_second": 400.811, "test_steps_per_second": 12.525}, {"test_loss": 0.6915827989578247, "test_mcc": 0.054075572264090176, "test_macro_f1": 0.49234894799975576, "test_runtime": 4.9319, "test_samples_per_second": 415.256, "test_steps_per_second": 12.977}, {"test_loss": 0.6920537948608398, "test_mcc": 0.030696863123913603, "test_macro_f1": 0.5107708549257735, "test_runtime": 5.1296, "test_samples_per_second": 399.252, "test_steps_per_second": 12.477}, {"test_loss": 0.6922067403793335, "test_mcc": 0.05071585020535826, "test_macro_f1": 0.5239206289099316, "test_runtime": 5.0575, "test_samples_per_second": 404.939, "test_steps_per_second": 12.654}, {"test_loss": 0.6920521259307861, "test_mcc": 0.011207079648684818, "test_macro_f1": 0.5023744146279034, "test_runtime": 4.8671, "test_samples_per_second": 420.782, "test_steps_per_second": 13.149}, {"test_loss": 0.6921658515930176, "test_mcc": 0.021636956386661754, "test_macro_f1": 0.49666610216328055, "test_runtime": 4.7761, "test_samples_per_second": 428.801, "test_steps_per_second": 13.4}, {"test_loss": 0.6936370730400085, "test_mcc": 0.023397588165531464, "test_macro_f1": 0.4633633171450927, "test_runtime": 4.8374, "test_samples_per_second": 423.365, "test_steps_per_second": 13.23}, {"test_loss": 0.6923224329948425, "test_mcc": 0.028507680764370522, "test_macro_f1": 0.5041162227602906, "test_runtime": 4.8352, "test_samples_per_second": 423.56, "test_steps_per_second": 13.236}, {"test_loss": 0.6930304765701294, "test_mcc": 0.009941328912737885, "test_macro_f1": 0.48698001932976986, "test_runtime": 4.959, "test_samples_per_second": 412.99, "test_steps_per_second": 12.906}]}, "total": {"test_mcc": 2.206616326970699, "test_mcc_se": 1.3399269050986595, "test_macro_f1": 48.56241752020743, "test_macro_f1_se": 2.174557852531493}}, "num_model_parameters": 116763650, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.6929004192352295, "test_mcc": -0.021318762249847335, "test_macro_f1": 0.4877863316181606, "test_runtime": 4.4549, "test_samples_per_second": 459.718, "test_steps_per_second": 14.366}, {"test_loss": 0.6925418972969055, "test_mcc": 0.025003628018236926, "test_macro_f1": 0.5091604086084066, "test_runtime": 4.5313, "test_samples_per_second": 451.964, "test_steps_per_second": 14.124}, {"test_loss": 0.694667398929596, "test_mcc": 0.03692621939090287, "test_macro_f1": 0.459628503936395, "test_runtime": 4.5371, "test_samples_per_second": 451.394, "test_steps_per_second": 14.106}, {"test_loss": 0.6943166851997375, "test_mcc": -0.022061898944965175, "test_macro_f1": 0.4730110838420224, "test_runtime": 4.6577, "test_samples_per_second": 439.699, "test_steps_per_second": 13.741}, {"test_loss": 0.6930721998214722, "test_mcc": -0.009406002149326189, "test_macro_f1": 0.4919804292360798, "test_runtime": 4.5928, "test_samples_per_second": 445.916, "test_steps_per_second": 13.935}, {"test_loss": 0.6928310394287109, "test_mcc": 0.056592985762079245, "test_macro_f1": 0.4582649992471381, "test_runtime": 4.3301, "test_samples_per_second": 472.967, "test_steps_per_second": 14.78}, {"test_loss": 0.6945306062698364, "test_mcc": -0.009685810703982242, "test_macro_f1": 0.34918546072929196, "test_runtime": 4.3971, "test_samples_per_second": 465.759, "test_steps_per_second": 14.555}, {"test_loss": 0.6932755708694458, "test_mcc": 0.006027876785522978, "test_macro_f1": 0.4762392972508308, "test_runtime": 4.4463, "test_samples_per_second": 460.608, "test_steps_per_second": 14.394}, {"test_loss": 0.6979036331176758, "test_mcc": -0.01908822923310685, "test_macro_f1": 0.41111726029094486, "test_runtime": 4.3827, "test_samples_per_second": 467.29, "test_steps_per_second": 14.603}, {"test_loss": 0.6962311267852783, "test_mcc": 0.0015852755885581646, "test_macro_f1": 0.3966131148051345, "test_runtime": 4.6069, "test_samples_per_second": 444.551, "test_steps_per_second": 13.892}]}, "total": {"test_mcc": 0.4457528226407239, "test_mcc_se": 1.6681777965694329, "test_macro_f1": 45.12986889564405, "test_macro_f1_se": 3.104390769144534}}, "num_model_parameters": 116763650, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.6921854019165039, "test_mcc": 0.013540103518466419, "test_macro_f1": 0.4699343097282169, "test_runtime": 4.5244, "test_samples_per_second": 452.66, "test_steps_per_second": 14.146}, {"test_loss": 0.694069504737854, "test_mcc": 0.0109091645041809, "test_macro_f1": 0.5016423556629679, "test_runtime": 4.6741, "test_samples_per_second": 438.156, "test_steps_per_second": 13.692}, {"test_loss": 0.6921954154968262, "test_mcc": 0.02955746825121002, "test_macro_f1": 0.5077892229859071, "test_runtime": 4.7746, "test_samples_per_second": 428.934, "test_steps_per_second": 13.404}, {"test_loss": 0.6954584717750549, "test_mcc": 0.05543603364837706, "test_macro_f1": 0.4236936238962427, "test_runtime": 4.4974, "test_samples_per_second": 455.375, "test_steps_per_second": 14.23}, {"test_loss": 0.6934809684753418, "test_mcc": 0.007983393099317934, "test_macro_f1": 0.49361327704324426, "test_runtime": 4.5734, "test_samples_per_second": 447.811, "test_steps_per_second": 13.994}, {"test_loss": 0.6923661231994629, "test_mcc": 0.032081900614997556, "test_macro_f1": 0.5141265604024257, "test_runtime": 4.6827, "test_samples_per_second": 437.358, "test_steps_per_second": 13.667}, {"test_loss": 0.6932305097579956, "test_mcc": 0.003093898629237732, "test_macro_f1": 0.4174066057624737, "test_runtime": 4.5398, "test_samples_per_second": 451.117, "test_steps_per_second": 14.097}, {"test_loss": 0.6970522403717041, "test_mcc": -0.04928609146294533, "test_macro_f1": 0.4014641516645257, "test_runtime": 4.5801, "test_samples_per_second": 447.147, "test_steps_per_second": 13.973}, {"test_loss": 0.6930812001228333, "test_mcc": 0.018858015462824142, "test_macro_f1": 0.4944101569388115, "test_runtime": 4.5739, "test_samples_per_second": 447.754, "test_steps_per_second": 13.992}, {"test_loss": 0.6940118670463562, "test_mcc": 0.02603934048853639, "test_macro_f1": 0.4427715796944475, "test_runtime": 4.6635, "test_samples_per_second": 439.156, "test_steps_per_second": 13.724}]}, "total": {"test_mcc": 1.482132267542028, "test_mcc_se": 1.68070198783511, "test_macro_f1": 46.66851843779263, "test_macro_f1_se": 2.5943898129839633}}, "num_model_parameters": 116763650, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_em": 34.70178156467854, "test_f1": 38.042334634123954}, {"test_em": 33.72093023255814, "test_f1": 36.86963049616949}, {"test_em": 37.557959814528594, "test_f1": 41.418915486258946}, {"test_em": 33.177570093457945, "test_f1": 37.224885248524615}, {"test_em": 26.409266409266408, "test_f1": 30.44371265799838}, {"test_em": 34.926754047802625, "test_f1": 38.64940364486829}, {"test_em": 38.876233864844345, "test_f1": 42.47905808330218}, {"test_em": 33.9022498060512, "test_f1": 37.27007670374624}, {"test_em": 27.764705882352942, "test_f1": 30.69255385137739}, {"test_em": 26.242236024844722, "test_f1": 29.576915571774027}]}, "total": {"test_em": 32.727968774038544, "test_em_se": 2.7645522495050057, "test_f1": 36.26674863781435, "test_f1_se": 2.817592574049825}}, "num_model_parameters": 116173826, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_em": 27.652982184353213, "test_f1": 31.929427460491542}, {"test_em": 31.86046511627907, "test_f1": 36.17000062734097}, {"test_em": 27.820710973724886, "test_f1": 31.58504240352591}, {"test_em": 35.66978193146417, "test_f1": 39.3875744884288}, {"test_em": 31.73745173745174, "test_f1": 35.97870453045155}, {"test_em": 25.905936777178102, "test_f1": 30.261138278729483}, {"test_em": 33.029612756264235, "test_f1": 38.032567070152496}, {"test_em": 27.307990690457718, "test_f1": 31.179376090005626}, {"test_em": 33.490196078431374, "test_f1": 37.50888401480279}, {"test_em": 29.503105590062113, "test_f1": 34.034966159176555}]}, "total": {"test_em": 30.397823383566664, "test_em_se": 1.9915079906807356, "test_f1": 34.606768112310576, "test_f1_se": 2.0094417924933503}}, "num_model_parameters": 116173826, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_em": 31.913245546088305, "test_f1": 36.2944096096691}, {"test_em": 34.72868217054263, "test_f1": 39.19825462575121}, {"test_em": 30.293663060278206, "test_f1": 34.39478645224621}, {"test_em": 32.165109034267914, "test_f1": 36.80646504656951}, {"test_em": 26.332046332046332, "test_f1": 30.988874908129567}, {"test_em": 32.76792598303778, "test_f1": 35.9015012658035}, {"test_em": 35.15565679574791, "test_f1": 39.1670164516205}, {"test_em": 27.773467804499614, "test_f1": 32.2907436703321}, {"test_em": 34.431372549019606, "test_f1": 38.613466464331516}, {"test_em": 28.571428571428573, "test_f1": 32.61800145466112}]}, "total": {"test_em": 31.41325978469568, "test_em_se": 1.9064941312992774, "test_f1": 35.62735199491143, "test_f1_se": 1.8401712283284417}}, "num_model_parameters": 116173826, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_speed": 1.92}, {"test_speed": 1.95}, {"test_speed": 1.97}, {"test_speed": 1.98}, {"test_speed": 1.87}, {"test_speed": 1.95}, {"test_speed": 1.94}, {"test_speed": 2.0}, {"test_speed": 1.93}, {"test_speed": 1.86}]}, "total": {"test_speed": 1.937, "test_speed_se": 0.027726284360592626}}, "num_model_parameters": 116762112, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.7384111881256104, "test_mcc": 0.5314722185512725, "test_macro_f1": 0.5176635149123398, "test_runtime": 19.879, "test_samples_per_second": 103.023, "test_steps_per_second": 12.878}, {"test_loss": 0.6734020709991455, "test_mcc": 0.5330811432821562, "test_macro_f1": 0.5192945478665375, "test_runtime": 19.2064, "test_samples_per_second": 106.631, "test_steps_per_second": 13.329}, {"test_loss": 0.7195488214492798, "test_mcc": 0.5177610985263739, "test_macro_f1": 0.5068264625774151, "test_runtime": 19.4719, "test_samples_per_second": 105.177, "test_steps_per_second": 13.147}, {"test_loss": 0.6175428628921509, "test_mcc": 0.6187424035942315, "test_macro_f1": 0.576992474023558, "test_runtime": 19.4972, "test_samples_per_second": 105.04, "test_steps_per_second": 13.13}, {"test_loss": 0.6731233596801758, "test_mcc": 0.5869212663932493, "test_macro_f1": 0.5606318558054456, "test_runtime": 19.3412, "test_samples_per_second": 105.888, "test_steps_per_second": 13.236}, {"test_loss": 0.6758898496627808, "test_mcc": 0.5454799001705948, "test_macro_f1": 0.5318809297929995, "test_runtime": 19.7324, "test_samples_per_second": 103.788, "test_steps_per_second": 12.974}, {"test_loss": 0.7287730574607849, "test_mcc": 0.5145489528877778, "test_macro_f1": 0.5098328195102388, "test_runtime": 19.1415, "test_samples_per_second": 106.993, "test_steps_per_second": 13.374}, {"test_loss": 0.7425206303596497, "test_mcc": 0.4952419026363108, "test_macro_f1": 0.4955661940813651, "test_runtime": 19.7039, "test_samples_per_second": 103.939, "test_steps_per_second": 12.992}, {"test_loss": 0.6573132276535034, "test_mcc": 0.5747141301656779, "test_macro_f1": 0.5347727827639664, "test_runtime": 19.7962, "test_samples_per_second": 103.454, "test_steps_per_second": 12.932}, {"test_loss": 0.6626361608505249, "test_mcc": 0.5503329731601369, "test_macro_f1": 0.5259444226835531, "test_runtime": 19.6028, "test_samples_per_second": 104.475, "test_steps_per_second": 13.059}]}, "total": {"test_mcc": 54.682959893677804, "test_mcc_se": 2.313908285443464, "test_macro_f1": 52.794060040174195, "test_macro_f1_se": 1.5382035882149183}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.9863331317901611, "test_mcc": 0.280045636893865, "test_macro_f1": 0.49320394102204784, "test_runtime": 5.9749, "test_samples_per_second": 342.765, "test_steps_per_second": 10.711}, {"test_loss": 1.0009880065917969, "test_mcc": 0.2478041216074928, "test_macro_f1": 0.4863886775230155, "test_runtime": 5.9887, "test_samples_per_second": 341.975, "test_steps_per_second": 10.687}, {"test_loss": 1.0022282600402832, "test_mcc": 0.2860916246198011, "test_macro_f1": 0.5128827693255412, "test_runtime": 5.9902, "test_samples_per_second": 341.891, "test_steps_per_second": 10.684}, {"test_loss": 1.0445024967193604, "test_mcc": 0.2560429385084245, "test_macro_f1": 0.4879246299746893, "test_runtime": 6.009, "test_samples_per_second": 340.823, "test_steps_per_second": 10.651}, {"test_loss": 1.0084413290023804, "test_mcc": 0.2913889777796579, "test_macro_f1": 0.5250002069467792, "test_runtime": 5.9177, "test_samples_per_second": 346.08, "test_steps_per_second": 10.815}, {"test_loss": 1.1546990871429443, "test_mcc": 0.21818415785346137, "test_macro_f1": 0.4732496306951958, "test_runtime": 5.9222, "test_samples_per_second": 345.817, "test_steps_per_second": 10.807}, {"test_loss": 1.0140525102615356, "test_mcc": 0.25530274999426, "test_macro_f1": 0.460014597010112, "test_runtime": 6.0132, "test_samples_per_second": 340.582, "test_steps_per_second": 10.643}, {"test_loss": 1.0355253219604492, "test_mcc": 0.26699465917031956, "test_macro_f1": 0.4869272555540256, "test_runtime": 6.067, "test_samples_per_second": 337.562, "test_steps_per_second": 10.549}, {"test_loss": 0.9794947504997253, "test_mcc": 0.29053564934793885, "test_macro_f1": 0.5141027903462277, "test_runtime": 6.0354, "test_samples_per_second": 339.333, "test_steps_per_second": 10.604}, {"test_loss": 0.9918527007102966, "test_mcc": 0.24869156573170084, "test_macro_f1": 0.48432219803332316, "test_runtime": 6.0284, "test_samples_per_second": 339.723, "test_steps_per_second": 10.616}]}, "total": {"test_mcc": 26.41082081506922, "test_mcc_se": 1.4525986305722263, "test_macro_f1": 49.24016696430957, "test_macro_f1_se": 1.2259173645389534}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 1.0188121795654297, "test_mcc": 0.2186780577045275, "test_macro_f1": 0.3871889418939971, "test_runtime": 4.9053, "test_samples_per_second": 417.509, "test_steps_per_second": 13.047}, {"test_loss": 0.9605257511138916, "test_mcc": 0.2148416757469636, "test_macro_f1": 0.38438680379264006, "test_runtime": 4.7879, "test_samples_per_second": 427.747, "test_steps_per_second": 13.367}, {"test_loss": 0.9406746625900269, "test_mcc": 0.20269356841909666, "test_macro_f1": 0.3828958310319009, "test_runtime": 4.5787, "test_samples_per_second": 447.287, "test_steps_per_second": 13.978}, {"test_loss": 0.9865502119064331, "test_mcc": 0.2423525067651538, "test_macro_f1": 0.39848380652978355, "test_runtime": 4.8199, "test_samples_per_second": 424.901, "test_steps_per_second": 13.278}, {"test_loss": 0.9598957896232605, "test_mcc": 0.23104371682192748, "test_macro_f1": 0.3696403627013633, "test_runtime": 4.8398, "test_samples_per_second": 423.158, "test_steps_per_second": 13.224}, {"test_loss": 0.9843264222145081, "test_mcc": 0.21348242412580648, "test_macro_f1": 0.38501807850651254, "test_runtime": 4.8764, "test_samples_per_second": 419.984, "test_steps_per_second": 13.125}, {"test_loss": 0.9443251490592957, "test_mcc": 0.21748935793995577, "test_macro_f1": 0.431460729371899, "test_runtime": 4.6645, "test_samples_per_second": 439.06, "test_steps_per_second": 13.721}, {"test_loss": 0.9947927594184875, "test_mcc": 0.11969670182204467, "test_macro_f1": 0.2979177093286015, "test_runtime": 4.9277, "test_samples_per_second": 415.606, "test_steps_per_second": 12.988}, {"test_loss": 0.9926725029945374, "test_mcc": 0.22560486377497557, "test_macro_f1": 0.37497903585615266, "test_runtime": 5.0059, "test_samples_per_second": 409.115, "test_steps_per_second": 12.785}, {"test_loss": 0.9646279811859131, "test_mcc": 0.247795933769008, "test_macro_f1": 0.4003220903664784, "test_runtime": 4.989, "test_samples_per_second": 410.504, "test_steps_per_second": 12.828}]}, "total": {"test_mcc": 21.336788068894595, "test_mcc_se": 2.208148634902175, "test_macro_f1": 38.12293389379329, "test_macro_f1_se": 2.1031102284778114}}, "num_model_parameters": 177855747, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.08707877993583679, "test_micro_f1": 0.5715725806451613, "test_micro_f1_no_misc": 0.6203501094091904, "test_runtime": 10.7889, "test_samples_per_second": 189.825, "test_steps_per_second": 5.932}, {"test_loss": 0.07932537794113159, "test_micro_f1": 0.5890339425587467, "test_micro_f1_no_misc": 0.6332002281802624, "test_runtime": 10.064, "test_samples_per_second": 203.498, "test_steps_per_second": 6.359}, {"test_loss": 0.0793847069144249, "test_micro_f1": 0.5750487329434698, "test_micro_f1_no_misc": 0.6272381985892566, "test_runtime": 10.0542, "test_samples_per_second": 203.695, "test_steps_per_second": 6.365}, {"test_loss": 0.07705096155405045, "test_micro_f1": 0.5992179863147605, "test_micro_f1_no_misc": 0.6408296943231441, "test_runtime": 10.6953, "test_samples_per_second": 191.486, "test_steps_per_second": 5.984}, {"test_loss": 0.08517476916313171, "test_micro_f1": 0.6049856184084372, "test_micro_f1_no_misc": 0.6425992779783394, "test_runtime": 10.7421, "test_samples_per_second": 190.651, "test_steps_per_second": 5.958}, {"test_loss": 0.08146794140338898, "test_micro_f1": 0.5947467166979362, "test_micro_f1_no_misc": 0.6366594360086768, "test_runtime": 8.4397, "test_samples_per_second": 242.662, "test_steps_per_second": 7.583}, {"test_loss": 0.08775599300861359, "test_micro_f1": 0.5857988165680473, "test_micro_f1_no_misc": 0.6288770053475936, "test_runtime": 9.5733, "test_samples_per_second": 213.928, "test_steps_per_second": 6.685}, {"test_loss": 0.07245352864265442, "test_micro_f1": 0.617310832879695, "test_micro_f1_no_misc": 0.6733291692692068, "test_runtime": 10.7806, "test_samples_per_second": 189.97, "test_steps_per_second": 5.937}, {"test_loss": 0.08732984960079193, "test_micro_f1": 0.5213634181469036, "test_micro_f1_no_misc": 0.5620779220779221, "test_runtime": 10.1707, "test_samples_per_second": 201.363, "test_steps_per_second": 6.293}, {"test_loss": 0.08144128322601318, "test_micro_f1": 0.55893536121673, "test_micro_f1_no_misc": 0.6420454545454546, "test_runtime": 10.6744, "test_samples_per_second": 191.86, "test_steps_per_second": 5.996}]}, "total": {"test_micro_f1": 58.18014006379888, "test_micro_f1_se": 1.686494697398042, "test_micro_f1_no_misc": 63.07206495729047, "test_micro_f1_no_misc_se": 1.7363613686030142}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.09868432581424713, "test_micro_f1": 0.6941387253647299, "test_micro_f1_no_misc": 0.7089297886843899, "test_runtime": 11.4559, "test_samples_per_second": 178.772, "test_steps_per_second": 5.587}, {"test_loss": 0.09242330491542816, "test_micro_f1": 0.6981185060376298, "test_micro_f1_no_misc": 0.7202595529920692, "test_runtime": 9.4547, "test_samples_per_second": 216.612, "test_steps_per_second": 6.769}, {"test_loss": 0.09236490726470947, "test_micro_f1": 0.6941970310391363, "test_micro_f1_no_misc": 0.7192048278310259, "test_runtime": 11.9208, "test_samples_per_second": 171.8, "test_steps_per_second": 5.369}, {"test_loss": 0.09557066857814789, "test_micro_f1": 0.6723470178156468, "test_micro_f1_no_misc": 0.688237276710482, "test_runtime": 11.2803, "test_samples_per_second": 181.556, "test_steps_per_second": 5.674}, {"test_loss": 0.10607593506574631, "test_micro_f1": 0.6822799097065463, "test_micro_f1_no_misc": 0.695554725438924, "test_runtime": 11.8408, "test_samples_per_second": 172.961, "test_steps_per_second": 5.405}, {"test_loss": 0.1039966493844986, "test_micro_f1": 0.7220376522702104, "test_micro_f1_no_misc": 0.7382005899705015, "test_runtime": 11.9084, "test_samples_per_second": 171.98, "test_steps_per_second": 5.374}, {"test_loss": 0.09284865856170654, "test_micro_f1": 0.6906970580439967, "test_micro_f1_no_misc": 0.7093837535014006, "test_runtime": 11.9534, "test_samples_per_second": 171.332, "test_steps_per_second": 5.354}, {"test_loss": 0.08583573997020721, "test_micro_f1": 0.7102177554438862, "test_micro_f1_no_misc": 0.7282089003310039, "test_runtime": 11.3808, "test_samples_per_second": 179.952, "test_steps_per_second": 5.623}, {"test_loss": 0.10072578489780426, "test_micro_f1": 0.6650692225772099, "test_micro_f1_no_misc": 0.6630939621293318, "test_runtime": 11.287, "test_samples_per_second": 181.447, "test_steps_per_second": 5.67}, {"test_loss": 0.10317958891391754, "test_micro_f1": 0.7065462753950339, "test_micro_f1_no_misc": 0.7386448250186151, "test_runtime": 9.1308, "test_samples_per_second": 224.295, "test_steps_per_second": 7.009}]}, "total": {"test_micro_f1": 69.35649153694027, "test_micro_f1_se": 1.0687089984502713, "test_micro_f1_no_misc": 71.09718202607745, "test_micro_f1_no_misc_se": 1.4626336988159723}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.07083114236593246, "test_micro_f1": 0.685360524399126, "test_micro_f1_no_misc": 0.7218409366168752, "test_runtime": 8.9412, "test_samples_per_second": 229.052, "test_steps_per_second": 7.158}, {"test_loss": 0.060701631009578705, "test_micro_f1": 0.7023238657322022, "test_micro_f1_no_misc": 0.7291835084882782, "test_runtime": 8.906, "test_samples_per_second": 229.958, "test_steps_per_second": 7.186}, {"test_loss": 0.07217133790254593, "test_micro_f1": 0.7089475488515598, "test_micro_f1_no_misc": 0.740428790199081, "test_runtime": 8.7703, "test_samples_per_second": 233.517, "test_steps_per_second": 7.297}, {"test_loss": 0.06424513459205627, "test_micro_f1": 0.7385575589459085, "test_micro_f1_no_misc": 0.7681331747919145, "test_runtime": 8.6512, "test_samples_per_second": 236.729, "test_steps_per_second": 7.398}, {"test_loss": 0.06563962250947952, "test_micro_f1": 0.7542595019659241, "test_micro_f1_no_misc": 0.7886693999254566, "test_runtime": 9.0046, "test_samples_per_second": 227.438, "test_steps_per_second": 7.107}, {"test_loss": 0.06436467170715332, "test_micro_f1": 0.7505970658478334, "test_micro_f1_no_misc": 0.7720894956389838, "test_runtime": 9.0045, "test_samples_per_second": 227.443, "test_steps_per_second": 7.108}, {"test_loss": 0.07167469710111618, "test_micro_f1": 0.7160170324271209, "test_micro_f1_no_misc": 0.7397459165154265, "test_runtime": 8.484, "test_samples_per_second": 241.396, "test_steps_per_second": 7.544}, {"test_loss": 0.06720788031816483, "test_micro_f1": 0.733446519524618, "test_micro_f1_no_misc": 0.7489952502740227, "test_runtime": 8.53, "test_samples_per_second": 240.094, "test_steps_per_second": 7.503}, {"test_loss": 0.06489096581935883, "test_micro_f1": 0.7041847041847042, "test_micro_f1_no_misc": 0.7300163132137032, "test_runtime": 8.6849, "test_samples_per_second": 235.813, "test_steps_per_second": 7.369}, {"test_loss": 0.06958110630512238, "test_micro_f1": 0.7084042191221503, "test_micro_f1_no_misc": 0.7430503380916605, "test_runtime": 8.3913, "test_samples_per_second": 244.062, "test_steps_per_second": 7.627}]}, "total": {"test_micro_f1": 72.02098541001148, "test_micro_f1_se": 1.4118034213666733, "test_micro_f1_no_misc": 74.82153123755401, "test_micro_f1_no_misc_se": 1.3312454654576402}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.08169994503259659, "test_micro_f1": 0.6519164848862573, "test_micro_f1_no_misc": 0.69, "test_runtime": 8.7853, "test_samples_per_second": 233.116, "test_steps_per_second": 7.285}, {"test_loss": 0.08538803458213806, "test_micro_f1": 0.7160268129189519, "test_micro_f1_no_misc": 0.7491385251550655, "test_runtime": 9.3222, "test_samples_per_second": 219.69, "test_steps_per_second": 6.865}, {"test_loss": 0.08563776314258575, "test_micro_f1": 0.6495119787045253, "test_micro_f1_no_misc": 0.6887332908975176, "test_runtime": 8.3372, "test_samples_per_second": 245.646, "test_steps_per_second": 7.676}, {"test_loss": 0.09145403653383255, "test_micro_f1": 0.6649061032863849, "test_micro_f1_no_misc": 0.7037990985189956, "test_runtime": 8.8913, "test_samples_per_second": 230.337, "test_steps_per_second": 7.198}, {"test_loss": 0.09316878020763397, "test_micro_f1": 0.6440377804014169, "test_micro_f1_no_misc": 0.6972357723577236, "test_runtime": 8.19, "test_samples_per_second": 250.061, "test_steps_per_second": 7.814}, {"test_loss": 0.08327196538448334, "test_micro_f1": 0.7526555386949925, "test_micro_f1_no_misc": 0.7769633507853404, "test_runtime": 8.206, "test_samples_per_second": 249.574, "test_steps_per_second": 7.799}, {"test_loss": 0.07854057848453522, "test_micro_f1": 0.6947969543147209, "test_micro_f1_no_misc": 0.7312866505691618, "test_runtime": 9.1675, "test_samples_per_second": 223.398, "test_steps_per_second": 6.981}, {"test_loss": 0.07411137223243713, "test_micro_f1": 0.7157438911227961, "test_micro_f1_no_misc": 0.7488054607508533, "test_runtime": 9.4038, "test_samples_per_second": 217.785, "test_steps_per_second": 6.806}, {"test_loss": 0.09397657960653305, "test_micro_f1": 0.6790726052471019, "test_micro_f1_no_misc": 0.7178451178451178, "test_runtime": 8.0829, "test_samples_per_second": 253.373, "test_steps_per_second": 7.918}, {"test_loss": 0.07759986072778702, "test_micro_f1": 0.7102572048342112, "test_micro_f1_no_misc": 0.7479242776486219, "test_runtime": 8.2689, "test_samples_per_second": 247.676, "test_steps_per_second": 7.74}]}, "total": {"test_micro_f1": 68.78925354411358, "test_micro_f1_se": 2.2257563901689736, "test_micro_f1_no_misc": 72.51731544528397, "test_micro_f1_no_misc_se": 1.87383698690186}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6915550827980042, "test_mcc": 0.022581167922538732, "test_macro_f1": 0.4972203745886177, "test_runtime": 5.0044, "test_samples_per_second": 409.239, "test_steps_per_second": 12.789}, {"test_loss": 0.6925045251846313, "test_mcc": 0.00431050017645387, "test_macro_f1": 0.42852593846849696, "test_runtime": 5.2078, "test_samples_per_second": 393.253, "test_steps_per_second": 12.289}, {"test_loss": 0.6852593421936035, "test_mcc": 0.0926609696082631, "test_macro_f1": 0.49992774924664085, "test_runtime": 5.3178, "test_samples_per_second": 385.123, "test_steps_per_second": 12.035}, {"test_loss": 0.6871240735054016, "test_mcc": 0.12495201705807527, "test_macro_f1": 0.5116475391325082, "test_runtime": 5.0719, "test_samples_per_second": 403.794, "test_steps_per_second": 12.619}, {"test_loss": 0.6879567503929138, "test_mcc": 0.10333521849049751, "test_macro_f1": 0.5427841814684111, "test_runtime": 5.253, "test_samples_per_second": 389.872, "test_steps_per_second": 12.183}, {"test_loss": 0.6911604404449463, "test_mcc": 0.0421937585780955, "test_macro_f1": 0.520822327318156, "test_runtime": 5.064, "test_samples_per_second": 404.42, "test_steps_per_second": 12.638}, {"test_loss": 0.6868475675582886, "test_mcc": 0.05517295188118652, "test_macro_f1": 0.5237461022144707, "test_runtime": 5.1549, "test_samples_per_second": 397.296, "test_steps_per_second": 12.415}, {"test_loss": 0.6834360361099243, "test_mcc": 0.084823488490337, "test_macro_f1": 0.47439298102428074, "test_runtime": 5.2438, "test_samples_per_second": 390.553, "test_steps_per_second": 12.205}, {"test_loss": 0.6942963004112244, "test_mcc": 0.02731044624987409, "test_macro_f1": 0.4660566507434569, "test_runtime": 5.2219, "test_samples_per_second": 392.198, "test_steps_per_second": 12.256}, {"test_loss": 0.681082010269165, "test_mcc": 0.058088347599197225, "test_macro_f1": 0.5128443129101617, "test_runtime": 5.2157, "test_samples_per_second": 392.659, "test_steps_per_second": 12.271}]}, "total": {"test_mcc": 6.1542886605451885, "test_mcc_se": 2.415563260697149, "test_macro_f1": 49.77968157115201, "test_macro_f1_se": 2.0664529091118435}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6891615986824036, "test_mcc": 0.0, "test_macro_f1": 0.33159268929503916, "test_runtime": 5.2672, "test_samples_per_second": 388.823, "test_steps_per_second": 12.151}, {"test_loss": 0.6858373880386353, "test_mcc": 0.11064691074049778, "test_macro_f1": 0.4201104972375691, "test_runtime": 5.6139, "test_samples_per_second": 364.807, "test_steps_per_second": 11.4}, {"test_loss": 0.693644642829895, "test_mcc": 0.00849831137594612, "test_macro_f1": 0.4601349377676135, "test_runtime": 5.5147, "test_samples_per_second": 371.369, "test_steps_per_second": 11.605}, {"test_loss": 0.6917983293533325, "test_mcc": 0.01719095671483781, "test_macro_f1": 0.5080003247699147, "test_runtime": 5.6345, "test_samples_per_second": 363.474, "test_steps_per_second": 11.359}, {"test_loss": 0.6923857927322388, "test_mcc": 0.06486523173431358, "test_macro_f1": 0.4711413447557939, "test_runtime": 5.4431, "test_samples_per_second": 376.256, "test_steps_per_second": 11.758}, {"test_loss": 0.6926118731498718, "test_mcc": 0.05473801549638965, "test_macro_f1": 0.34203319819475253, "test_runtime": 5.3707, "test_samples_per_second": 381.326, "test_steps_per_second": 11.916}, {"test_loss": 0.6930511593818665, "test_mcc": 0.049978669886458674, "test_macro_f1": 0.3997771684773536, "test_runtime": 5.1981, "test_samples_per_second": 393.99, "test_steps_per_second": 12.312}, {"test_loss": 0.6932425498962402, "test_mcc": -0.031771934844214096, "test_macro_f1": 0.395307378034664, "test_runtime": 5.2402, "test_samples_per_second": 390.827, "test_steps_per_second": 12.213}, {"test_loss": 0.6922553777694702, "test_mcc": 0.042246748997071655, "test_macro_f1": 0.4825606399668142, "test_runtime": 5.17, "test_samples_per_second": 396.132, "test_steps_per_second": 12.379}, {"test_loss": 0.6904910206794739, "test_mcc": 0.06768785917622294, "test_macro_f1": 0.5250703460053172, "test_runtime": 5.5078, "test_samples_per_second": 371.835, "test_steps_per_second": 11.62}]}, "total": {"test_mcc": 3.840807692775241, "test_mcc_se": 2.5249614500226767, "test_macro_f1": 43.357285245048324, "test_macro_f1_se": 4.131788218679915}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6911618113517761, "test_mcc": 0.06256519425973858, "test_macro_f1": 0.4527175832783008, "test_runtime": 4.9267, "test_samples_per_second": 415.694, "test_steps_per_second": 12.99}, {"test_loss": 0.693406343460083, "test_mcc": 0.06313035377063628, "test_macro_f1": 0.35229506272739064, "test_runtime": 4.9985, "test_samples_per_second": 409.719, "test_steps_per_second": 12.804}, {"test_loss": 0.6928956508636475, "test_mcc": 0.005017608404865511, "test_macro_f1": 0.5007246812404405, "test_runtime": 4.9842, "test_samples_per_second": 410.895, "test_steps_per_second": 12.84}, {"test_loss": 0.6898891925811768, "test_mcc": 0.0, "test_macro_f1": 0.33093760209082, "test_runtime": 5.1388, "test_samples_per_second": 398.535, "test_steps_per_second": 12.454}, {"test_loss": 0.6934006214141846, "test_mcc": -0.007155900466127027, "test_macro_f1": 0.42485989256265017, "test_runtime": 5.0372, "test_samples_per_second": 406.573, "test_steps_per_second": 12.705}, {"test_loss": 0.6908746957778931, "test_mcc": 0.11154545551387479, "test_macro_f1": 0.555653468453132, "test_runtime": 4.7173, "test_samples_per_second": 434.148, "test_steps_per_second": 13.567}, {"test_loss": 0.6787679195404053, "test_mcc": 0.129575126809308, "test_macro_f1": 0.4872675250357653, "test_runtime": 4.7507, "test_samples_per_second": 431.092, "test_steps_per_second": 13.472}, {"test_loss": 0.6861588358879089, "test_mcc": 0.1150268974815483, "test_macro_f1": 0.521403525958944, "test_runtime": 4.8385, "test_samples_per_second": 423.273, "test_steps_per_second": 13.227}, {"test_loss": 0.6918019652366638, "test_mcc": 0.07145939028889492, "test_macro_f1": 0.5354589777996379, "test_runtime": 4.921, "test_samples_per_second": 416.179, "test_steps_per_second": 13.006}, {"test_loss": 0.6901100277900696, "test_mcc": -0.029972728983973497, "test_macro_f1": 0.3389860308130619, "test_runtime": 5.0129, "test_samples_per_second": 408.544, "test_steps_per_second": 12.767}]}, "total": {"test_mcc": 5.211913970787658, "test_mcc_se": 3.535268672725421, "test_macro_f1": 45.00304349960144, "test_macro_f1_se": 5.235309214675757}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6962172389030457, "test_mcc": 0.0199360866256611, "test_macro_f1": 0.45933589621063214, "test_runtime": 5.0578, "test_samples_per_second": 404.919, "test_steps_per_second": 12.654}, {"test_loss": 0.6925530433654785, "test_mcc": 0.029906408862661785, "test_macro_f1": 0.4814168165022304, "test_runtime": 5.1314, "test_samples_per_second": 399.114, "test_steps_per_second": 12.472}, {"test_loss": 0.6925523281097412, "test_mcc": 0.053361521095283665, "test_macro_f1": 0.4599103903958098, "test_runtime": 5.0949, "test_samples_per_second": 401.97, "test_steps_per_second": 12.562}, {"test_loss": 0.6941110491752625, "test_mcc": 0.011270651365964075, "test_macro_f1": 0.3755274852000975, "test_runtime": 4.9039, "test_samples_per_second": 417.627, "test_steps_per_second": 13.051}, {"test_loss": 0.6902379989624023, "test_mcc": 0.09513280105580114, "test_macro_f1": 0.4476521659292924, "test_runtime": 5.1067, "test_samples_per_second": 401.039, "test_steps_per_second": 12.532}, {"test_loss": 0.6922268867492676, "test_mcc": -0.021082538759402573, "test_macro_f1": 0.35639358474208926, "test_runtime": 5.1359, "test_samples_per_second": 398.765, "test_steps_per_second": 12.461}, {"test_loss": 0.6925852298736572, "test_mcc": 0.0010249191481545268, "test_macro_f1": 0.46161433316049255, "test_runtime": 5.0579, "test_samples_per_second": 404.914, "test_steps_per_second": 12.654}, {"test_loss": 0.6931455135345459, "test_mcc": 0.022546631947694438, "test_macro_f1": 0.43573039471145464, "test_runtime": 5.0016, "test_samples_per_second": 409.469, "test_steps_per_second": 12.796}, {"test_loss": 0.6940393447875977, "test_mcc": 1.612669595055809e-05, "test_macro_f1": 0.4826549300222005, "test_runtime": 5.0264, "test_samples_per_second": 407.445, "test_steps_per_second": 12.733}, {"test_loss": 0.6921687126159668, "test_mcc": 0.08830008950726465, "test_macro_f1": 0.3977575821646732, "test_runtime": 5.0849, "test_samples_per_second": 402.764, "test_steps_per_second": 12.586}]}, "total": {"test_mcc": 3.0041269754503337, "test_mcc_se": 2.359480737714313, "test_macro_f1": 43.579935790389726, "test_macro_f1_se": 2.7411803983613425}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_em": 32.06816421378776, "test_f1": 35.914580058540515}, {"test_em": 41.395348837209305, "test_f1": 44.90864098928034}, {"test_em": 41.88562596599691, "test_f1": 45.76110474669435}, {"test_em": 36.29283489096573, "test_f1": 40.08041048216391}, {"test_em": 34.5945945945946, "test_f1": 38.049532230204505}, {"test_em": 41.32613723978412, "test_f1": 45.15826300578444}, {"test_em": 31.890660592255124, "test_f1": 35.52243014825088}, {"test_em": 32.893716058960436, "test_f1": 36.525126987181494}, {"test_em": 34.11764705882353, "test_f1": 37.66609947786418}, {"test_em": 33.850931677018636, "test_f1": 37.28837699060571}]}, "total": {"test_em": 36.031566112939615, "test_em_se": 2.4820289194547795, "test_f1": 39.68745651165703, "test_f1_se": 2.5163151684788465}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_em": 34.70178156467854, "test_f1": 39.11160336666882}, {"test_em": 34.96124031007752, "test_f1": 38.49619427153808}, {"test_em": 41.190108191653785, "test_f1": 45.30591956066639}, {"test_em": 41.43302180685358, "test_f1": 45.04318348967161}, {"test_em": 34.826254826254825, "test_f1": 39.22683925530879}, {"test_em": 39.4757131842714, "test_f1": 43.54255880395031}, {"test_em": 37.50949126803341, "test_f1": 41.8763292184098}, {"test_em": 38.40186190845617, "test_f1": 42.578191604316466}, {"test_em": 41.72549019607843, "test_f1": 46.44326198627387}, {"test_em": 39.36335403726708, "test_f1": 43.842477860629465}]}, "total": {"test_em": 38.35883172936248, "test_em_se": 1.7183737711520426, "test_f1": 42.54665594174336, "test_f1_se": 1.7454890666959137}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_em": 31.835786212238574, "test_f1": 35.711178399017285}, {"test_em": 43.10077519379845, "test_f1": 47.99617047352667}, {"test_em": 39.799072642967545, "test_f1": 44.939633371175745}, {"test_em": 41.822429906542055, "test_f1": 46.261348452680295}, {"test_em": 36.833976833976834, "test_f1": 41.064278873655276}, {"test_em": 40.78643022359291, "test_f1": 44.79968658389449}, {"test_em": 38.80030372057707, "test_f1": 42.58007916322267}, {"test_em": 37.70364623739333, "test_f1": 41.472094319833104}, {"test_em": 36.94117647058823, "test_f1": 41.47592468708842}, {"test_em": 27.63975155279503, "test_f1": 32.6925438167168}]}, "total": {"test_em": 37.52633489944701, "test_em_se": 2.9066171907407896, "test_f1": 41.89929381408108, "test_f1_se": 2.9103403847297797}}, "num_model_parameters": 177264386, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_speed": 1.9}, {"test_speed": 2.01}, {"test_speed": 1.93}, {"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.89}, {"test_speed": 2.06}, {"test_speed": 1.91}, {"test_speed": 1.93}, {"test_speed": 1.92}]}, "total": {"test_speed": 1.943, "test_speed_se": 0.032542296579477416}}, "num_model_parameters": 177853440, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.6279563903808594, "test_mcc": 0.6007288030220764, "test_macro_f1": 0.5457481276695337, "test_runtime": 20.5051, "test_samples_per_second": 99.878, "test_steps_per_second": 12.485}, {"test_loss": 0.6529032588005066, "test_mcc": 0.5420448962808627, "test_macro_f1": 0.5348143702927483, "test_runtime": 19.8031, "test_samples_per_second": 103.418, "test_steps_per_second": 12.927}, {"test_loss": 0.643058180809021, "test_mcc": 0.5643877756897561, "test_macro_f1": 0.5356411159025362, "test_runtime": 20.0048, "test_samples_per_second": 102.376, "test_steps_per_second": 12.797}, {"test_loss": 0.5994942784309387, "test_mcc": 0.5943566781554822, "test_macro_f1": 0.5876632031143493, "test_runtime": 20.0585, "test_samples_per_second": 102.102, "test_steps_per_second": 12.763}, {"test_loss": 0.6197933554649353, "test_mcc": 0.5737266798671975, "test_macro_f1": 0.531794174964752, "test_runtime": 19.9615, "test_samples_per_second": 102.598, "test_steps_per_second": 12.825}, {"test_loss": 0.6641470789909363, "test_mcc": 0.5536197738497176, "test_macro_f1": 0.5273842525635655, "test_runtime": 20.3181, "test_samples_per_second": 100.797, "test_steps_per_second": 12.6}, {"test_loss": 0.5877896547317505, "test_mcc": 0.613465642492026, "test_macro_f1": 0.5767142320935547, "test_runtime": 19.7939, "test_samples_per_second": 103.466, "test_steps_per_second": 12.933}, {"test_loss": 0.5796481370925903, "test_mcc": 0.6104601012991435, "test_macro_f1": 0.5516780726593049, "test_runtime": 20.2614, "test_samples_per_second": 101.079, "test_steps_per_second": 12.635}, {"test_loss": 0.6197817325592041, "test_mcc": 0.5962782348183671, "test_macro_f1": 0.578306987091726, "test_runtime": 20.3363, "test_samples_per_second": 100.707, "test_steps_per_second": 12.588}, {"test_loss": 0.5985528230667114, "test_mcc": 0.606565585674237, "test_macro_f1": 0.54814883163356, "test_runtime": 20.1644, "test_samples_per_second": 101.565, "test_steps_per_second": 12.696}]}, "total": {"test_mcc": 58.556341711488656, "test_mcc_se": 1.5685936009707364, "test_macro_f1": 55.1789336798563, "test_macro_f1_se": 1.3398051626973166}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 1.0781573057174683, "test_mcc": 0.21915062638461616, "test_macro_f1": 0.4610671666751487, "test_runtime": 6.8135, "test_samples_per_second": 300.582, "test_steps_per_second": 9.393}, {"test_loss": 0.9991355538368225, "test_mcc": 0.2934819529646751, "test_macro_f1": 0.5011771742312591, "test_runtime": 6.8056, "test_samples_per_second": 300.928, "test_steps_per_second": 9.404}, {"test_loss": 1.0073580741882324, "test_mcc": 0.23476364698569765, "test_macro_f1": 0.4507084777944416, "test_runtime": 6.7449, "test_samples_per_second": 303.639, "test_steps_per_second": 9.489}, {"test_loss": 1.0187289714813232, "test_mcc": 0.2548887063127422, "test_macro_f1": 0.498415396897357, "test_runtime": 6.7093, "test_samples_per_second": 305.247, "test_steps_per_second": 9.539}, {"test_loss": 1.0212205648422241, "test_mcc": 0.2918236812118562, "test_macro_f1": 0.5179480321597614, "test_runtime": 6.6599, "test_samples_per_second": 307.512, "test_steps_per_second": 9.61}, {"test_loss": 1.0611870288848877, "test_mcc": 0.22258131420421728, "test_macro_f1": 0.45518517623103855, "test_runtime": 6.6612, "test_samples_per_second": 307.454, "test_steps_per_second": 9.608}, {"test_loss": 1.016588807106018, "test_mcc": 0.2825055570590826, "test_macro_f1": 0.4842810920863809, "test_runtime": 6.6944, "test_samples_per_second": 305.926, "test_steps_per_second": 9.56}, {"test_loss": 1.067988395690918, "test_mcc": 0.17260334919884174, "test_macro_f1": 0.3390546459710486, "test_runtime": 6.713, "test_samples_per_second": 305.078, "test_steps_per_second": 9.534}, {"test_loss": 0.9761707186698914, "test_mcc": 0.27630067164019007, "test_macro_f1": 0.47118961710179397, "test_runtime": 6.6841, "test_samples_per_second": 306.396, "test_steps_per_second": 9.575}, {"test_loss": 1.0322694778442383, "test_mcc": 0.265321767267708, "test_macro_f1": 0.47888386933446875, "test_runtime": 6.7195, "test_samples_per_second": 304.783, "test_steps_per_second": 9.524}]}, "total": {"test_mcc": 25.13421273229627, "test_mcc_se": 2.4053614828832734, "test_macro_f1": 46.57910648482699, "test_macro_f1_se": 3.064664340784906}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.9931261539459229, "test_mcc": 0.22019907621497337, "test_macro_f1": 0.3774911761145103, "test_runtime": 5.7062, "test_samples_per_second": 358.906, "test_steps_per_second": 11.216}, {"test_loss": 0.9520732164382935, "test_mcc": 0.13756689243167552, "test_macro_f1": 0.3411722293035199, "test_runtime": 5.2764, "test_samples_per_second": 388.142, "test_steps_per_second": 12.129}, {"test_loss": 0.9526150226593018, "test_mcc": 0.17967929092077128, "test_macro_f1": 0.35924836443503083, "test_runtime": 5.3342, "test_samples_per_second": 383.939, "test_steps_per_second": 11.998}, {"test_loss": 0.9675060510635376, "test_mcc": 0.16218987829545167, "test_macro_f1": 0.3552285793819288, "test_runtime": 5.4922, "test_samples_per_second": 372.895, "test_steps_per_second": 11.653}, {"test_loss": 0.9788132309913635, "test_mcc": 0.13151485481557426, "test_macro_f1": 0.3215922991155999, "test_runtime": 5.5006, "test_samples_per_second": 372.325, "test_steps_per_second": 11.635}, {"test_loss": 0.9747970104217529, "test_mcc": 0.19448056109907189, "test_macro_f1": 0.36848421608805376, "test_runtime": 5.5976, "test_samples_per_second": 365.87, "test_steps_per_second": 11.433}, {"test_loss": 0.9491562843322754, "test_mcc": 0.21050830305133977, "test_macro_f1": 0.39365863925995015, "test_runtime": 5.3492, "test_samples_per_second": 382.859, "test_steps_per_second": 11.964}, {"test_loss": 0.9758124947547913, "test_mcc": 0.18877060953760041, "test_macro_f1": 0.37598767969113567, "test_runtime": 5.5104, "test_samples_per_second": 371.663, "test_steps_per_second": 11.614}, {"test_loss": 0.9612818360328674, "test_mcc": 0.1592415336457022, "test_macro_f1": 0.3658009200627175, "test_runtime": 5.7334, "test_samples_per_second": 357.208, "test_steps_per_second": 11.163}, {"test_loss": 0.9737873077392578, "test_mcc": 0.17077147460839118, "test_macro_f1": 0.3537372349992194, "test_runtime": 5.6708, "test_samples_per_second": 361.147, "test_steps_per_second": 11.286}]}, "total": {"test_mcc": 17.549224746205518, "test_mcc_se": 1.802879816080144, "test_macro_f1": 36.124013384516665, "test_macro_f1_se": 1.2527816992205951}}, "num_model_parameters": 110619651, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.19129356741905212, "test_micro_f1": 0.04795204795204795, "test_micro_f1_no_misc": 0.05485714285714286, "test_runtime": 11.3139, "test_samples_per_second": 181.016, "test_steps_per_second": 5.657}, {"test_loss": 0.19010189175605774, "test_micro_f1": 0.03125000000000001, "test_micro_f1_no_misc": 0.03525264394829612, "test_runtime": 10.52, "test_samples_per_second": 194.676, "test_steps_per_second": 6.084}, {"test_loss": 0.18578070402145386, "test_micro_f1": 0.08108108108108107, "test_micro_f1_no_misc": 0.08823529411764706, "test_runtime": 10.4438, "test_samples_per_second": 196.097, "test_steps_per_second": 6.128}, {"test_loss": 0.1803910881280899, "test_micro_f1": 0.13767579570688376, "test_micro_f1_no_misc": 0.1488, "test_runtime": 11.2163, "test_samples_per_second": 182.591, "test_steps_per_second": 5.706}, {"test_loss": 0.18848752975463867, "test_micro_f1": 0.17817371937639198, "test_micro_f1_no_misc": 0.19433198380566802, "test_runtime": 11.2032, "test_samples_per_second": 182.805, "test_steps_per_second": 5.713}, {"test_loss": 0.20538222789764404, "test_micro_f1": 0.08149405772495756, "test_micro_f1_no_misc": 0.0923076923076923, "test_runtime": 8.5469, "test_samples_per_second": 239.62, "test_steps_per_second": 7.488}, {"test_loss": 0.2017725706100464, "test_micro_f1": 0.11291702309666381, "test_micro_f1_no_misc": 0.12559467174119887, "test_runtime": 9.8666, "test_samples_per_second": 207.57, "test_steps_per_second": 6.487}, {"test_loss": 0.17862024903297424, "test_micro_f1": 0.032327586206896554, "test_micro_f1_no_misc": 0.036101083032490974, "test_runtime": 11.1732, "test_samples_per_second": 183.296, "test_steps_per_second": 5.728}, {"test_loss": 0.18182511627674103, "test_micro_f1": 0.15067519545131486, "test_micro_f1_no_misc": 0.1632024634334103, "test_runtime": 10.9785, "test_samples_per_second": 186.547, "test_steps_per_second": 5.83}, {"test_loss": 0.18600407242774963, "test_micro_f1": 0.21739130434782608, "test_micro_f1_no_misc": 0.23512123438648053, "test_runtime": 11.1638, "test_samples_per_second": 183.449, "test_steps_per_second": 5.733}]}, "total": {"test_micro_f1": 10.709378109440637, "test_micro_f1_se": 3.934044631250086, "test_micro_f1_no_misc": 11.73804209630027, "test_micro_f1_no_misc_se": 4.217787053597155}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.22585737705230713, "test_micro_f1": 0.3831722569641842, "test_micro_f1_no_misc": 0.3536679536679536, "test_runtime": 13.0655, "test_samples_per_second": 156.748, "test_steps_per_second": 4.898}, {"test_loss": 0.22680675983428955, "test_micro_f1": 0.38489091501139694, "test_micro_f1_no_misc": 0.348898678414097, "test_runtime": 10.4953, "test_samples_per_second": 195.134, "test_steps_per_second": 6.098}, {"test_loss": 0.2332625687122345, "test_micro_f1": 0.4199288256227758, "test_micro_f1_no_misc": 0.38689788053949903, "test_runtime": 13.2441, "test_samples_per_second": 154.634, "test_steps_per_second": 4.832}, {"test_loss": 0.2337539792060852, "test_micro_f1": 0.37400681044267875, "test_micro_f1_no_misc": 0.3435148295706064, "test_runtime": 12.4325, "test_samples_per_second": 164.729, "test_steps_per_second": 5.148}, {"test_loss": 0.21642324328422546, "test_micro_f1": 0.38053982005998, "test_micro_f1_no_misc": 0.36634123663412366, "test_runtime": 13.2153, "test_samples_per_second": 154.972, "test_steps_per_second": 4.843}, {"test_loss": 0.2233828604221344, "test_micro_f1": 0.35418671799807505, "test_micro_f1_no_misc": 0.3069438301636444, "test_runtime": 13.1365, "test_samples_per_second": 155.902, "test_steps_per_second": 4.872}, {"test_loss": 0.21612201631069183, "test_micro_f1": 0.3877878950187466, "test_micro_f1_no_misc": 0.35926449787835923, "test_runtime": 13.3682, "test_samples_per_second": 153.199, "test_steps_per_second": 4.787}, {"test_loss": 0.22205404937267303, "test_micro_f1": 0.33381628513474354, "test_micro_f1_no_misc": 0.30518742900416507, "test_runtime": 13.0061, "test_samples_per_second": 157.464, "test_steps_per_second": 4.921}, {"test_loss": 0.2287173569202423, "test_micro_f1": 0.3566333808844508, "test_micro_f1_no_misc": 0.3338235294117647, "test_runtime": 12.4728, "test_samples_per_second": 164.197, "test_steps_per_second": 5.131}, {"test_loss": 0.2351110577583313, "test_micro_f1": 0.3962649547709367, "test_micro_f1_no_misc": 0.3569449940641076, "test_runtime": 10.7429, "test_samples_per_second": 190.637, "test_steps_per_second": 5.957}]}, "total": {"test_micro_f1": 37.71227861907968, "test_micro_f1_se": 1.4972857106227169, "test_micro_f1_no_misc": 34.61484859348321, "test_micro_f1_no_misc_se": 1.572704370520227}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.21532070636749268, "test_micro_f1": 0.3121516164994426, "test_micro_f1_no_misc": 0.32076253626191464, "test_runtime": 10.5074, "test_samples_per_second": 194.91, "test_steps_per_second": 6.091}, {"test_loss": 0.20402425527572632, "test_micro_f1": 0.3787638668779714, "test_micro_f1_no_misc": 0.3748302399275691, "test_runtime": 10.5662, "test_samples_per_second": 193.826, "test_steps_per_second": 6.057}, {"test_loss": 0.21279382705688477, "test_micro_f1": 0.28960817717206133, "test_micro_f1_no_misc": 0.29348882410106897, "test_runtime": 10.5693, "test_samples_per_second": 193.769, "test_steps_per_second": 6.055}, {"test_loss": 0.21271860599517822, "test_micro_f1": 0.3244919049259387, "test_micro_f1_no_misc": 0.31963119477525936, "test_runtime": 10.2576, "test_samples_per_second": 199.657, "test_steps_per_second": 6.239}, {"test_loss": 0.22324544191360474, "test_micro_f1": 0.3385948622717425, "test_micro_f1_no_misc": 0.3386537126995142, "test_runtime": 10.4889, "test_samples_per_second": 195.254, "test_steps_per_second": 6.102}, {"test_loss": 0.19973935186862946, "test_micro_f1": 0.3206165703275529, "test_micro_f1_no_misc": 0.33042720139494336, "test_runtime": 10.479, "test_samples_per_second": 195.439, "test_steps_per_second": 6.107}, {"test_loss": 0.21890345215797424, "test_micro_f1": 0.3109565217391304, "test_micro_f1_no_misc": 0.30901287553648066, "test_runtime": 9.6603, "test_samples_per_second": 212.001, "test_steps_per_second": 6.625}, {"test_loss": 0.21740171313285828, "test_micro_f1": 0.2708840227088402, "test_micro_f1_no_misc": 0.27982456140350875, "test_runtime": 10.4026, "test_samples_per_second": 196.873, "test_steps_per_second": 6.152}, {"test_loss": 0.19973969459533691, "test_micro_f1": 0.31324278438030567, "test_micro_f1_no_misc": 0.3153846153846154, "test_runtime": 10.3399, "test_samples_per_second": 198.067, "test_steps_per_second": 6.19}, {"test_loss": 0.22263294458389282, "test_micro_f1": 0.27611634575993443, "test_micro_f1_no_misc": 0.29503799731783636, "test_runtime": 9.4831, "test_samples_per_second": 215.963, "test_steps_per_second": 6.749}]}, "total": {"test_micro_f1": 31.354266726629206, "test_micro_f1_se": 1.9439719719212138, "test_micro_f1_no_misc": 31.77053758802711, "test_micro_f1_no_misc_se": 1.6647999694373052}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.21630539000034332, "test_micro_f1": 0.3295417614559636, "test_micro_f1_no_misc": 0.34227240649259, "test_runtime": 9.825, "test_samples_per_second": 208.448, "test_steps_per_second": 6.514}, {"test_loss": 0.23075896501541138, "test_micro_f1": 0.34390323635174896, "test_micro_f1_no_misc": 0.35357142857142854, "test_runtime": 10.4402, "test_samples_per_second": 196.165, "test_steps_per_second": 6.13}, {"test_loss": 0.22031117975711823, "test_micro_f1": 0.2589641434262948, "test_micro_f1_no_misc": 0.2721039335979791, "test_runtime": 9.6937, "test_samples_per_second": 211.272, "test_steps_per_second": 6.602}, {"test_loss": 0.23524397611618042, "test_micro_f1": 0.3185316755476613, "test_micro_f1_no_misc": 0.32084155161078237, "test_runtime": 9.789, "test_samples_per_second": 209.215, "test_steps_per_second": 6.538}, {"test_loss": 0.2284580022096634, "test_micro_f1": 0.35744404800518975, "test_micro_f1_no_misc": 0.3710440160058202, "test_runtime": 9.1466, "test_samples_per_second": 223.908, "test_steps_per_second": 6.997}, {"test_loss": 0.23211851716041565, "test_micro_f1": 0.32402877697841725, "test_micro_f1_no_misc": 0.3455334987593052, "test_runtime": 8.893, "test_samples_per_second": 230.294, "test_steps_per_second": 7.197}, {"test_loss": 0.21515333652496338, "test_micro_f1": 0.3327696990192763, "test_micro_f1_no_misc": 0.3370955605718586, "test_runtime": 10.4225, "test_samples_per_second": 196.497, "test_steps_per_second": 6.141}, {"test_loss": 0.2195291519165039, "test_micro_f1": 0.3788741302972802, "test_micro_f1_no_misc": 0.3882886023004531, "test_runtime": 10.4448, "test_samples_per_second": 196.079, "test_steps_per_second": 6.127}, {"test_loss": 0.2284867763519287, "test_micro_f1": 0.36343366778149383, "test_micro_f1_no_misc": 0.3801151864201273, "test_runtime": 9.1149, "test_samples_per_second": 224.687, "test_steps_per_second": 7.021}, {"test_loss": 0.21535804867744446, "test_micro_f1": 0.3483309143686502, "test_micro_f1_no_misc": 0.35938959825599504, "test_runtime": 9.4765, "test_samples_per_second": 216.113, "test_steps_per_second": 6.754}]}, "total": {"test_micro_f1": 33.558220532319766, "test_micro_f1_se": 2.0346410053620207, "test_micro_f1_no_misc": 34.702557825863394, "test_micro_f1_no_misc_se": 2.0652405183718074}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.6980428695678711, "test_mcc": 0.04772473085823613, "test_macro_f1": 0.37159271656814563, "test_runtime": 5.2542, "test_samples_per_second": 389.783, "test_steps_per_second": 12.181}, {"test_loss": 0.6948578357696533, "test_mcc": 0.03177849870883995, "test_macro_f1": 0.3830273025626289, "test_runtime": 5.5561, "test_samples_per_second": 368.605, "test_steps_per_second": 11.519}, {"test_loss": 0.6928316950798035, "test_mcc": 0.01005469956975122, "test_macro_f1": 0.5020920661971777, "test_runtime": 5.572, "test_samples_per_second": 367.55, "test_steps_per_second": 11.486}, {"test_loss": 0.6963111162185669, "test_mcc": -0.03197235222301775, "test_macro_f1": 0.4355057483770355, "test_runtime": 5.456, "test_samples_per_second": 375.365, "test_steps_per_second": 11.73}, {"test_loss": 0.6950109004974365, "test_mcc": 0.04376471430172104, "test_macro_f1": 0.33522048042596503, "test_runtime": 5.5712, "test_samples_per_second": 367.607, "test_steps_per_second": 11.488}, {"test_loss": 0.6927376389503479, "test_mcc": 0.05782595411427081, "test_macro_f1": 0.459160983629899, "test_runtime": 5.4348, "test_samples_per_second": 376.828, "test_steps_per_second": 11.776}, {"test_loss": 0.6941267848014832, "test_mcc": 0.027384838972110245, "test_macro_f1": 0.4124405206178605, "test_runtime": 5.5015, "test_samples_per_second": 372.259, "test_steps_per_second": 11.633}, {"test_loss": 0.6928625702857971, "test_mcc": 0.036665220934816375, "test_macro_f1": 0.48425984932354216, "test_runtime": 5.456, "test_samples_per_second": 375.368, "test_steps_per_second": 11.73}, {"test_loss": 0.6934435367584229, "test_mcc": 0.019650010654230523, "test_macro_f1": 0.4991842180426711, "test_runtime": 5.4906, "test_samples_per_second": 373.003, "test_steps_per_second": 11.656}, {"test_loss": 0.6930800080299377, "test_mcc": 0.0244917907881677, "test_macro_f1": 0.5074679327087213, "test_runtime": 5.5728, "test_samples_per_second": 367.5, "test_steps_per_second": 11.484}]}, "total": {"test_mcc": 2.6736810667912625, "test_mcc_se": 1.5463049542793779, "test_macro_f1": 43.89951818453647, "test_macro_f1_se": 3.804510671972089}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.6936035752296448, "test_mcc": 0.006754473958373481, "test_macro_f1": 0.5010110389336322, "test_runtime": 5.9926, "test_samples_per_second": 341.753, "test_steps_per_second": 10.68}, {"test_loss": 0.6959350109100342, "test_mcc": 0.028485235868327775, "test_macro_f1": 0.4050334852145195, "test_runtime": 6.3682, "test_samples_per_second": 321.597, "test_steps_per_second": 10.05}, {"test_loss": 0.6930049061775208, "test_mcc": 0.013040414239505083, "test_macro_f1": 0.5058589037503278, "test_runtime": 6.2542, "test_samples_per_second": 327.459, "test_steps_per_second": 10.233}, {"test_loss": 0.6939978003501892, "test_mcc": 0.03086231695157821, "test_macro_f1": 0.3694671887434905, "test_runtime": 6.4589, "test_samples_per_second": 317.084, "test_steps_per_second": 9.909}, {"test_loss": 0.6932588219642639, "test_mcc": 0.011283246462786566, "test_macro_f1": 0.4654934957723802, "test_runtime": 6.1697, "test_samples_per_second": 331.946, "test_steps_per_second": 10.373}, {"test_loss": 0.693440318107605, "test_mcc": 0.0019392998989049832, "test_macro_f1": 0.4894860935301749, "test_runtime": 6.0485, "test_samples_per_second": 338.595, "test_steps_per_second": 10.581}, {"test_loss": 0.6945834159851074, "test_mcc": 0.010744820028020572, "test_macro_f1": 0.4661083571280188, "test_runtime": 5.8932, "test_samples_per_second": 347.52, "test_steps_per_second": 10.86}, {"test_loss": 0.6936495900154114, "test_mcc": -0.005515132206013075, "test_macro_f1": 0.49583184398133456, "test_runtime": 5.9608, "test_samples_per_second": 343.579, "test_steps_per_second": 10.737}, {"test_loss": 0.6933061480522156, "test_mcc": 0.0, "test_macro_f1": 0.33635774465327284, "test_runtime": 6.0802, "test_samples_per_second": 336.833, "test_steps_per_second": 10.526}, {"test_loss": 0.6981726288795471, "test_mcc": 0.01117028075893731, "test_macro_f1": 0.4284210252428355, "test_runtime": 6.1779, "test_samples_per_second": 331.506, "test_steps_per_second": 10.36}]}, "total": {"test_mcc": 1.087649559604209, "test_mcc_se": 0.7151838528351858, "test_macro_f1": 44.63069176949986, "test_macro_f1_se": 3.674552931968818}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.6937224864959717, "test_mcc": 0.0026476561022557624, "test_macro_f1": 0.34349391727493916, "test_runtime": 5.5416, "test_samples_per_second": 369.57, "test_steps_per_second": 11.549}, {"test_loss": 0.6924514770507812, "test_mcc": 0.059665265136832006, "test_macro_f1": 0.45354390282319457, "test_runtime": 5.6814, "test_samples_per_second": 360.478, "test_steps_per_second": 11.265}, {"test_loss": 0.6913857460021973, "test_mcc": 0.0656339684701024, "test_macro_f1": 0.5302885697381838, "test_runtime": 5.582, "test_samples_per_second": 366.893, "test_steps_per_second": 11.465}, {"test_loss": 0.6953734159469604, "test_mcc": 0.0, "test_macro_f1": 0.33093760209082, "test_runtime": 5.8113, "test_samples_per_second": 352.414, "test_steps_per_second": 11.013}, {"test_loss": 0.6921361684799194, "test_mcc": 0.02735983640115038, "test_macro_f1": 0.48233158270116067, "test_runtime": 5.8078, "test_samples_per_second": 352.629, "test_steps_per_second": 11.02}, {"test_loss": 0.6934442520141602, "test_mcc": 0.012549697535936839, "test_macro_f1": 0.479455951102168, "test_runtime": 5.3925, "test_samples_per_second": 379.784, "test_steps_per_second": 11.868}, {"test_loss": 0.6921344995498657, "test_mcc": 0.04732571692122019, "test_macro_f1": 0.5234211379632632, "test_runtime": 5.4847, "test_samples_per_second": 373.402, "test_steps_per_second": 11.669}, {"test_loss": 0.6902618408203125, "test_mcc": 0.07462361388185876, "test_macro_f1": 0.5226867749967548, "test_runtime": 5.5383, "test_samples_per_second": 369.79, "test_steps_per_second": 11.556}, {"test_loss": 0.6937458515167236, "test_mcc": -0.0062511090746058765, "test_macro_f1": 0.4924085577092241, "test_runtime": 5.4864, "test_samples_per_second": 373.287, "test_steps_per_second": 11.665}, {"test_loss": 0.6954299807548523, "test_mcc": -0.05444049300810828, "test_macro_f1": 0.445711210060185, "test_runtime": 5.63, "test_samples_per_second": 363.764, "test_steps_per_second": 11.368}]}, "total": {"test_mcc": 2.291141523666422, "test_mcc_se": 2.4742923445328016, "test_macro_f1": 46.04279206459893, "test_macro_f1_se": 4.39702037151035}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.6921796202659607, "test_mcc": 0.01790343180986199, "test_macro_f1": 0.4052710407822177, "test_runtime": 5.6522, "test_samples_per_second": 362.336, "test_steps_per_second": 11.323}, {"test_loss": 0.7024747133255005, "test_mcc": -0.03926307983899262, "test_macro_f1": 0.44377771447416653, "test_runtime": 5.8861, "test_samples_per_second": 347.937, "test_steps_per_second": 10.873}, {"test_loss": 0.6929718852043152, "test_mcc": 0.06281573202642204, "test_macro_f1": 0.4380128413922961, "test_runtime": 5.8991, "test_samples_per_second": 347.17, "test_steps_per_second": 10.849}, {"test_loss": 0.69416344165802, "test_mcc": -0.016186332145345865, "test_macro_f1": 0.4915887564369809, "test_runtime": 5.5734, "test_samples_per_second": 367.458, "test_steps_per_second": 11.483}, {"test_loss": 0.6940025091171265, "test_mcc": 0.03308588235541808, "test_macro_f1": 0.48444636242672706, "test_runtime": 5.7232, "test_samples_per_second": 357.839, "test_steps_per_second": 11.182}, {"test_loss": 0.6936998963356018, "test_mcc": -0.017881577386965726, "test_macro_f1": 0.48971872012901996, "test_runtime": 5.824, "test_samples_per_second": 351.651, "test_steps_per_second": 10.989}, {"test_loss": 0.6958378553390503, "test_mcc": 0.012906260151261527, "test_macro_f1": 0.3435261414808872, "test_runtime": 5.6563, "test_samples_per_second": 362.074, "test_steps_per_second": 11.315}, {"test_loss": 0.6927764415740967, "test_mcc": 0.021524650230727038, "test_macro_f1": 0.5100534956650064, "test_runtime": 5.7226, "test_samples_per_second": 357.877, "test_steps_per_second": 11.184}, {"test_loss": 0.6964184641838074, "test_mcc": -0.02622674908901788, "test_macro_f1": 0.48686697390687494, "test_runtime": 5.6285, "test_samples_per_second": 363.862, "test_steps_per_second": 11.371}, {"test_loss": 0.692962646484375, "test_mcc": 0.02236331153226498, "test_macro_f1": 0.5062257954703299, "test_runtime": 5.8055, "test_samples_per_second": 352.771, "test_steps_per_second": 11.024}]}, "total": {"test_mcc": 0.7104152964563357, "test_mcc_se": 1.9378261574784923, "test_macro_f1": 45.99487842164507, "test_macro_f1_se": 3.276496143621816}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_em": 24.786986831913246, "test_f1": 30.26528661114254}, {"test_em": 26.2015503875969, "test_f1": 31.988771994585964}, {"test_em": 30.293663060278206, "test_f1": 35.26004582793839}, {"test_em": 18.613707165109034, "test_f1": 24.945097737153816}, {"test_em": 26.332046332046332, "test_f1": 32.51714630286062}, {"test_em": 34.30994602929838, "test_f1": 39.26222582352112}, {"test_em": 27.638572513287777, "test_f1": 32.506052118808405}, {"test_em": 28.85958107059736, "test_f1": 34.120126920747566}, {"test_em": 27.372549019607842, "test_f1": 32.442218348100724}, {"test_em": 31.90993788819876, "test_f1": 36.7058114418363}]}, "total": {"test_em": 27.631854029793384, "test_em_se": 2.6515535569960744, "test_f1": 33.00127831266955, "test_f1_se": 2.3869650084068255}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_em": 32.997676219984506, "test_f1": 38.39921202818183}, {"test_em": 18.75968992248062, "test_f1": 24.77582064791369}, {"test_em": 27.975270479134466, "test_f1": 31.92488260494445}, {"test_em": 25.31152647975078, "test_f1": 30.795830597232495}, {"test_em": 23.55212355212355, "test_f1": 28.017998089426673}, {"test_em": 29.144178874325366, "test_f1": 33.66144289542177}, {"test_em": 33.029612756264235, "test_f1": 37.813681298874926}, {"test_em": 30.643910007757952, "test_f1": 34.65769770269383}, {"test_em": 28.862745098039216, "test_f1": 34.76540746194726}, {"test_em": 33.850931677018636, "test_f1": 38.36406347275914}]}, "total": {"test_em": 28.412766506687934, "test_em_se": 2.9526227630362625, "test_f1": 33.31760367993961, "test_f1_se": 2.809039433757258}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_em": 23.392718822618125, "test_f1": 29.895062979880958}, {"test_em": 27.441860465116278, "test_f1": 32.9110532017509}, {"test_em": 39.258114374034, "test_f1": 44.11009799920156}, {"test_em": 23.598130841121495, "test_f1": 29.112707126725827}, {"test_em": 31.35135135135135, "test_f1": 35.95270278463556}, {"test_em": 24.518118735543563, "test_f1": 29.078812173056814}, {"test_em": 24.449506454062263, "test_f1": 29.5187093267624}, {"test_em": 36.22963537626067, "test_f1": 40.76561822545944}, {"test_em": 29.568627450980394, "test_f1": 35.11952909323155}, {"test_em": 36.87888198757764, "test_f1": 41.849849598296814}]}, "total": {"test_em": 29.668694585866575, "test_em_se": 3.723414406965807, "test_f1": 34.83141425090018, "test_f1_se": 3.5423906104486558}}, "num_model_parameters": 110028290, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_speed": 1.94}, {"test_speed": 2.0}, {"test_speed": 2.0}, {"test_speed": 1.97}, {"test_speed": 1.92}, {"test_speed": 1.95}, {"test_speed": 1.99}, {"test_speed": 2.02}, {"test_speed": 1.92}, {"test_speed": 1.87}]}, "total": {"test_speed": 1.9580000000000002, "test_speed_se": 0.028894769999661413}}, "num_model_parameters": 110617344, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.19192424416542053, "test_micro_f1": 0.23268698060941825, "test_micro_f1_no_misc": 0.25582599689280167, "test_runtime": 4.8769, "test_samples_per_second": 419.939, "test_steps_per_second": 13.123}, {"test_loss": 0.20903602242469788, "test_micro_f1": 0.28197017623136017, "test_micro_f1_no_misc": 0.30745501285347043, "test_runtime": 4.3774, "test_samples_per_second": 467.854, "test_steps_per_second": 14.62}, {"test_loss": 0.19951903820037842, "test_micro_f1": 0.27595628415300544, "test_micro_f1_no_misc": 0.2938090241343127, "test_runtime": 4.3952, "test_samples_per_second": 465.967, "test_steps_per_second": 14.561}, {"test_loss": 0.2128157615661621, "test_micro_f1": 0.23873664653971202, "test_micro_f1_no_misc": 0.26434965771458657, "test_runtime": 4.6726, "test_samples_per_second": 438.299, "test_steps_per_second": 13.697}, {"test_loss": 0.20237445831298828, "test_micro_f1": 0.25998052580331066, "test_micro_f1_no_misc": 0.2868131868131868, "test_runtime": 4.7256, "test_samples_per_second": 433.386, "test_steps_per_second": 13.543}, {"test_loss": 0.2068522721529007, "test_micro_f1": 0.25179856115107907, "test_micro_f1_no_misc": 0.2794042116076014, "test_runtime": 4.3156, "test_samples_per_second": 474.555, "test_steps_per_second": 14.83}, {"test_loss": 0.2074030041694641, "test_micro_f1": 0.24696901661427934, "test_micro_f1_no_misc": 0.2758969176351693, "test_runtime": 4.3318, "test_samples_per_second": 472.784, "test_steps_per_second": 14.774}, {"test_loss": 0.21882492303848267, "test_micro_f1": 0.20462046204620463, "test_micro_f1_no_misc": 0.22505543237250558, "test_runtime": 4.7042, "test_samples_per_second": 435.354, "test_steps_per_second": 13.605}, {"test_loss": 0.18748153746128082, "test_micro_f1": 0.2879098360655738, "test_micro_f1_no_misc": 0.3015015015015015, "test_runtime": 4.8385, "test_samples_per_second": 423.268, "test_steps_per_second": 13.227}, {"test_loss": 0.20117753744125366, "test_micro_f1": 0.2912359550561798, "test_micro_f1_no_misc": 0.3259557344064386, "test_runtime": 4.673, "test_samples_per_second": 438.263, "test_steps_per_second": 13.696}]}, "total": {"test_micro_f1": 25.718644442701233, "test_micro_f1_se": 1.7180144434138769, "test_micro_f1_no_misc": 28.16066675931575, "test_micro_f1_no_misc_se": 1.7778264939053146}}, "num_model_parameters": 24340941, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.20971877872943878, "test_micro_f1": 0.7493102814051867, "test_micro_f1_no_misc": 0.7493102814051867, "test_runtime": 3.5957, "test_samples_per_second": 569.569, "test_steps_per_second": 17.799}, {"test_loss": 0.2222018986940384, "test_micro_f1": 0.7354563244974203, "test_micro_f1_no_misc": 0.7354563244974203, "test_runtime": 3.5286, "test_samples_per_second": 580.403, "test_steps_per_second": 18.138}, {"test_loss": 0.21999873220920563, "test_micro_f1": 0.7242931748604358, "test_micro_f1_no_misc": 0.7242931748604358, "test_runtime": 3.4917, "test_samples_per_second": 586.536, "test_steps_per_second": 18.329}, {"test_loss": 0.22378185391426086, "test_micro_f1": 0.7406712919557472, "test_micro_f1_no_misc": 0.7406712919557472, "test_runtime": 3.5528, "test_samples_per_second": 576.447, "test_steps_per_second": 18.014}, {"test_loss": 0.22559036314487457, "test_micro_f1": 0.7467579250720461, "test_micro_f1_no_misc": 0.7467579250720461, "test_runtime": 3.6971, "test_samples_per_second": 553.945, "test_steps_per_second": 17.311}, {"test_loss": 0.24513521790504456, "test_micro_f1": 0.7240079008798708, "test_micro_f1_no_misc": 0.7240079008798708, "test_runtime": 3.5131, "test_samples_per_second": 582.966, "test_steps_per_second": 18.218}, {"test_loss": 0.21968162059783936, "test_micro_f1": 0.7324444444444445, "test_micro_f1_no_misc": 0.7324444444444445, "test_runtime": 3.5206, "test_samples_per_second": 581.718, "test_steps_per_second": 18.179}, {"test_loss": 0.2281348556280136, "test_micro_f1": 0.740873299928418, "test_micro_f1_no_misc": 0.740873299928418, "test_runtime": 3.5596, "test_samples_per_second": 575.352, "test_steps_per_second": 17.98}, {"test_loss": 0.21958163380622864, "test_micro_f1": 0.7433467006926723, "test_micro_f1_no_misc": 0.7433467006926723, "test_runtime": 3.5719, "test_samples_per_second": 573.359, "test_steps_per_second": 17.917}, {"test_loss": 0.23004275560379028, "test_micro_f1": 0.7182044887780549, "test_micro_f1_no_misc": 0.7182044887780549, "test_runtime": 3.5023, "test_samples_per_second": 584.755, "test_steps_per_second": 18.274}]}, "total": {"test_micro_f1": 73.55365832514296, "test_micro_f1_se": 0.653585144177361, "test_micro_f1_no_misc": 73.55365832514296, "test_micro_f1_no_misc_se": 0.653585144177361}}, "num_model_parameters": 24340941, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6929325461387634, "test_mcc": 0.026945682540470826, "test_macro_f1": 0.4966189373803195, "test_runtime": 2.9447, "test_samples_per_second": 695.479, "test_steps_per_second": 21.734}, {"test_loss": 0.6934617161750793, "test_mcc": 0.050891035541230374, "test_macro_f1": 0.3910969311759155, "test_runtime": 2.915, "test_samples_per_second": 702.584, "test_steps_per_second": 21.956}, {"test_loss": 0.6920770406723022, "test_mcc": 0.05909850663648972, "test_macro_f1": 0.5241348014739677, "test_runtime": 3.1062, "test_samples_per_second": 659.335, "test_steps_per_second": 20.604}, {"test_loss": 0.692654550075531, "test_mcc": 0.011911261606997119, "test_macro_f1": 0.4554201122041705, "test_runtime": 2.9639, "test_samples_per_second": 690.985, "test_steps_per_second": 21.593}, {"test_loss": 0.693556010723114, "test_mcc": 0.007381252502315273, "test_macro_f1": 0.44345017829509525, "test_runtime": 2.9816, "test_samples_per_second": 686.876, "test_steps_per_second": 21.465}, {"test_loss": 0.6924477219581604, "test_mcc": 0.008137393074148508, "test_macro_f1": 0.4972050439837496, "test_runtime": 2.9108, "test_samples_per_second": 703.575, "test_steps_per_second": 21.987}, {"test_loss": 0.6927106976509094, "test_mcc": 0.050820485707828954, "test_macro_f1": 0.5102333942217321, "test_runtime": 2.9286, "test_samples_per_second": 699.318, "test_steps_per_second": 21.854}, {"test_loss": 0.6930778622627258, "test_mcc": 0.001331209303297703, "test_macro_f1": 0.4967730541382077, "test_runtime": 2.9896, "test_samples_per_second": 685.046, "test_steps_per_second": 21.408}, {"test_loss": 0.6936303973197937, "test_mcc": -0.009567041937708484, "test_macro_f1": 0.46603373251339586, "test_runtime": 2.9561, "test_samples_per_second": 692.794, "test_steps_per_second": 21.65}, {"test_loss": 0.6932517290115356, "test_mcc": -0.0020310874908882775, "test_macro_f1": 0.49891591652032574, "test_runtime": 2.9846, "test_samples_per_second": 686.2, "test_steps_per_second": 21.444}]}, "total": {"test_mcc": 2.049186974841817, "test_mcc_se": 1.5394506567564725, "test_macro_f1": 47.7988210190688, "test_macro_f1_se": 2.450800274983052}}, "num_model_parameters": 24486086, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "sarnikowski/convbert-medium-small-da-cased", "results": {"raw": {"test": [{"test_loss": 0.6940294504165649, "test_mcc": -0.08934956095466055, "test_macro_f1": 0.43963376601979454, "test_runtime": 1.5068, "test_samples_per_second": 679.567, "test_steps_per_second": 21.236}, {"test_loss": 0.6893959045410156, "test_mcc": 0.088334491930943, "test_macro_f1": 0.5438926801817913, "test_runtime": 1.4475, "test_samples_per_second": 707.449, "test_steps_per_second": 22.108}, {"test_loss": 0.6912418603897095, "test_mcc": 0.03360445773388723, "test_macro_f1": 0.5150255901000687, "test_runtime": 1.4274, "test_samples_per_second": 717.373, "test_steps_per_second": 22.418}, {"test_loss": 0.6915982961654663, "test_mcc": 0.03739928703077852, "test_macro_f1": 0.48091855174770864, "test_runtime": 1.4395, "test_samples_per_second": 711.339, "test_steps_per_second": 22.229}, {"test_loss": 0.6889550089836121, "test_mcc": 0.13773083488770238, "test_macro_f1": 0.5661752245382139, "test_runtime": 1.454, "test_samples_per_second": 704.265, "test_steps_per_second": 22.008}, {"test_loss": 0.6939781904220581, "test_mcc": -0.0026266528231579764, "test_macro_f1": 0.4904177944065391, "test_runtime": 1.4576, "test_samples_per_second": 702.519, "test_steps_per_second": 21.954}, {"test_loss": 0.6896756291389465, "test_mcc": 0.10690314715668346, "test_macro_f1": 0.5466516881982151, "test_runtime": 1.4471, "test_samples_per_second": 707.6, "test_steps_per_second": 22.112}, {"test_loss": 0.6903156042098999, "test_mcc": 0.07031732847354995, "test_macro_f1": 0.5351402903084288, "test_runtime": 1.4716, "test_samples_per_second": 695.83, "test_steps_per_second": 21.745}, {"test_loss": 0.692993700504303, "test_mcc": 0.0379001820245624, "test_macro_f1": 0.45295186851638225, "test_runtime": 1.4948, "test_samples_per_second": 685.036, "test_steps_per_second": 21.407}, {"test_loss": 0.6911380290985107, "test_mcc": 0.03765252109726913, "test_macro_f1": 0.512550107924761, "test_runtime": 1.4582, "test_samples_per_second": 702.254, "test_steps_per_second": 21.945}]}, "total": {"test_mcc": 4.578660365575575, "test_mcc_se": 3.8956305903099153, "test_macro_f1": 50.83357561941902, "test_macro_f1_se": 2.590275289523582}}, "num_model_parameters": 24486086, "max_sequence_length": 512, "vocabulary_size": 28995}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.10206052660942078, "test_micro_f1": 0.5742424242424242, "test_micro_f1_no_misc": 0.6116751269035532, "test_runtime": 12.4398, "test_samples_per_second": 164.633, "test_steps_per_second": 20.579}, {"test_loss": 0.11533177644014359, "test_micro_f1": 0.5369978858350951, "test_micro_f1_no_misc": 0.5726664040961008, "test_runtime": 11.1993, "test_samples_per_second": 182.868, "test_steps_per_second": 22.859}, {"test_loss": 0.12470892071723938, "test_micro_f1": 0.5337787676317745, "test_micro_f1_no_misc": 0.576717400246812, "test_runtime": 10.2048, "test_samples_per_second": 200.69, "test_steps_per_second": 25.086}, {"test_loss": 0.12219100445508957, "test_micro_f1": 0.554627949183303, "test_micro_f1_no_misc": 0.6057287278854254, "test_runtime": 11.1689, "test_samples_per_second": 183.366, "test_steps_per_second": 22.921}, {"test_loss": 0.12450326234102249, "test_micro_f1": 0.5499265785609396, "test_micro_f1_no_misc": 0.5942622950819672, "test_runtime": 11.1746, "test_samples_per_second": 183.273, "test_steps_per_second": 22.909}, {"test_loss": 0.13076560199260712, "test_micro_f1": 0.5632980663991244, "test_micro_f1_no_misc": 0.6047098402018504, "test_runtime": 10.208, "test_samples_per_second": 200.627, "test_steps_per_second": 25.078}, {"test_loss": 0.12163851410150528, "test_micro_f1": 0.5437386569872958, "test_micro_f1_no_misc": 0.5994983277591973, "test_runtime": 10.3028, "test_samples_per_second": 198.781, "test_steps_per_second": 24.848}, {"test_loss": 0.1239025741815567, "test_micro_f1": 0.5223463687150838, "test_micro_f1_no_misc": 0.5665369649805447, "test_runtime": 11.4781, "test_samples_per_second": 178.426, "test_steps_per_second": 22.303}, {"test_loss": 0.10708903521299362, "test_micro_f1": 0.6132186155651154, "test_micro_f1_no_misc": 0.6621682411156095, "test_runtime": 12.4456, "test_samples_per_second": 164.556, "test_steps_per_second": 20.569}, {"test_loss": 0.11458992213010788, "test_micro_f1": 0.569545612209504, "test_micro_f1_no_misc": 0.6149116064565718, "test_runtime": 11.1919, "test_samples_per_second": 182.99, "test_steps_per_second": 22.874}]}, "total": {"test_micro_f1": 55.61720925329659, "test_micro_f1_se": 1.6029643705386953, "test_micro_f1_no_misc": 60.08874934727633, "test_micro_f1_no_misc_se": 1.6927300357379764}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.1484258770942688, "test_micro_f1": 0.8565822333214413, "test_micro_f1_no_misc": 0.8565822333214413, "test_runtime": 5.9049, "test_samples_per_second": 346.828, "test_steps_per_second": 10.838}, {"test_loss": 0.1687673181295395, "test_micro_f1": 0.8176460082157528, "test_micro_f1_no_misc": 0.8176460082157528, "test_runtime": 6.0632, "test_samples_per_second": 337.774, "test_steps_per_second": 10.555}, {"test_loss": 0.14959901571273804, "test_micro_f1": 0.831416946753936, "test_micro_f1_no_misc": 0.831416946753936, "test_runtime": 6.1088, "test_samples_per_second": 335.253, "test_steps_per_second": 10.477}, {"test_loss": 0.17674586176872253, "test_micro_f1": 0.8492952656306468, "test_micro_f1_no_misc": 0.8492952656306468, "test_runtime": 6.006, "test_samples_per_second": 340.993, "test_steps_per_second": 10.656}, {"test_loss": 0.1586424559354782, "test_micro_f1": 0.8450903934774903, "test_micro_f1_no_misc": 0.8450903934774903, "test_runtime": 6.188, "test_samples_per_second": 330.961, "test_steps_per_second": 10.343}, {"test_loss": 0.1861240267753601, "test_micro_f1": 0.7990204652789925, "test_micro_f1_no_misc": 0.7990204652789925, "test_runtime": 5.7134, "test_samples_per_second": 358.453, "test_steps_per_second": 11.202}, {"test_loss": 0.16470351815223694, "test_micro_f1": 0.8380646313158365, "test_micro_f1_no_misc": 0.8380646313158365, "test_runtime": 5.9143, "test_samples_per_second": 346.281, "test_steps_per_second": 10.821}, {"test_loss": 0.17637231945991516, "test_micro_f1": 0.8161389172625128, "test_micro_f1_no_misc": 0.8161389172625128, "test_runtime": 6.1387, "test_samples_per_second": 333.621, "test_steps_per_second": 10.426}, {"test_loss": 0.16071295738220215, "test_micro_f1": 0.845244397388389, "test_micro_f1_no_misc": 0.845244397388389, "test_runtime": 6.7128, "test_samples_per_second": 305.09, "test_steps_per_second": 9.534}, {"test_loss": 0.16515636444091797, "test_micro_f1": 0.8289844851904091, "test_micro_f1_no_misc": 0.8289844851904091, "test_runtime": 6.1676, "test_samples_per_second": 332.056, "test_steps_per_second": 10.377}]}, "total": {"test_micro_f1": 83.27483743835407, "test_micro_f1_se": 1.1002525170229904, "test_micro_f1_no_misc": 83.27483743835407, "test_micro_f1_no_misc_se": 1.1002525170229904}}, "num_model_parameters": 124107273, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6942892670631409, "test_mcc": -0.01005446058123401, "test_macro_f1": 0.49096996025376716, "test_runtime": 7.1836, "test_samples_per_second": 285.095, "test_steps_per_second": 35.637}, {"test_loss": 0.692848801612854, "test_mcc": 0.0413198552330043, "test_macro_f1": 0.45323523803046606, "test_runtime": 7.1999, "test_samples_per_second": 284.449, "test_steps_per_second": 35.556}, {"test_loss": 0.6944273710250854, "test_mcc": 0.016557903302787034, "test_macro_f1": 0.46925908346398115, "test_runtime": 7.5255, "test_samples_per_second": 272.141, "test_steps_per_second": 34.018}, {"test_loss": 0.6931366920471191, "test_mcc": 0.06788358497446786, "test_macro_f1": 0.38275048577196374, "test_runtime": 7.147, "test_samples_per_second": 286.553, "test_steps_per_second": 35.819}, {"test_loss": 0.695380449295044, "test_mcc": -0.0007991362004767906, "test_macro_f1": 0.47510313180441477, "test_runtime": 7.3079, "test_samples_per_second": 280.246, "test_steps_per_second": 35.031}, {"test_loss": 0.6941866874694824, "test_mcc": 0.005020383478294239, "test_macro_f1": 0.3649303582455063, "test_runtime": 7.1585, "test_samples_per_second": 286.094, "test_steps_per_second": 35.762}, {"test_loss": 0.6931477785110474, "test_mcc": 0.043867755069151394, "test_macro_f1": 0.5031523565948117, "test_runtime": 7.1773, "test_samples_per_second": 285.344, "test_steps_per_second": 35.668}, {"test_loss": 0.693153977394104, "test_mcc": 0.008741375016314308, "test_macro_f1": 0.4379241516966068, "test_runtime": 7.1386, "test_samples_per_second": 286.891, "test_steps_per_second": 35.861}, {"test_loss": 0.6931756734848022, "test_mcc": 0.016012569484003352, "test_macro_f1": 0.38737731470463943, "test_runtime": 7.2622, "test_samples_per_second": 282.009, "test_steps_per_second": 35.251}, {"test_loss": 0.6948630809783936, "test_mcc": -0.012730070528065808, "test_macro_f1": 0.4690173710137413, "test_runtime": 7.3836, "test_samples_per_second": 277.373, "test_steps_per_second": 34.672}]}, "total": {"test_mcc": 1.7581975924824589, "test_mcc_se": 1.606270275274519, "test_macro_f1": 44.33719451579899, "test_macro_f1_se": 3.0127362943477705}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "KB/bert-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6921786069869995, "test_mcc": 0.054112604979603914, "test_macro_f1": 0.5260376753476413, "test_runtime": 3.0979, "test_samples_per_second": 330.542, "test_steps_per_second": 10.329}, {"test_loss": 0.6937379837036133, "test_mcc": 0.04133339116802563, "test_macro_f1": 0.4607826768215153, "test_runtime": 2.8828, "test_samples_per_second": 355.21, "test_steps_per_second": 11.1}, {"test_loss": 0.6874309778213501, "test_mcc": 0.038338710791641625, "test_macro_f1": 0.48592213722746436, "test_runtime": 2.8163, "test_samples_per_second": 363.592, "test_steps_per_second": 11.362}, {"test_loss": 0.6967711448669434, "test_mcc": -0.02382497422600508, "test_macro_f1": 0.40432425967304375, "test_runtime": 2.7511, "test_samples_per_second": 372.212, "test_steps_per_second": 11.632}, {"test_loss": 0.6825643181800842, "test_mcc": 0.11523955952486445, "test_macro_f1": 0.5029535170711641, "test_runtime": 2.8397, "test_samples_per_second": 360.601, "test_steps_per_second": 11.269}, {"test_loss": 0.693682074546814, "test_mcc": -0.01864937463489617, "test_macro_f1": 0.48031740909690956, "test_runtime": 2.7702, "test_samples_per_second": 369.65, "test_steps_per_second": 11.552}, {"test_loss": 0.6911294460296631, "test_mcc": 0.06353176399688995, "test_macro_f1": 0.45883821554571785, "test_runtime": 2.8203, "test_samples_per_second": 363.087, "test_steps_per_second": 11.346}, {"test_loss": 0.6928625106811523, "test_mcc": 0.05225747691227767, "test_macro_f1": 0.5201079326037105, "test_runtime": 2.9508, "test_samples_per_second": 347.024, "test_steps_per_second": 10.845}, {"test_loss": 0.6918282508850098, "test_mcc": 0.07619265873337713, "test_macro_f1": 0.4761321290974547, "test_runtime": 2.9511, "test_samples_per_second": 346.991, "test_steps_per_second": 10.843}, {"test_loss": 0.695432186126709, "test_mcc": -0.0006530679372047825, "test_macro_f1": 0.43097299776105313, "test_runtime": 2.8549, "test_samples_per_second": 358.681, "test_steps_per_second": 11.209}]}, "total": {"test_mcc": 3.9787874930857434, "test_mcc_se": 2.697261279057496, "test_macro_f1": 47.46388950245674, "test_macro_f1_se": 2.352479736091407}}, "num_model_parameters": 124692482, "max_sequence_length": 512, "vocabulary_size": 50325}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.0437038391828537, "test_micro_f1": 0.8005759539236861, "test_micro_f1_no_misc": 0.8345085026959769, "test_runtime": 6.2379, "test_samples_per_second": 328.318, "test_steps_per_second": 10.26}, {"test_loss": 0.050300657749176025, "test_micro_f1": 0.842361111111111, "test_micro_f1_no_misc": 0.8782608695652174, "test_runtime": 6.0839, "test_samples_per_second": 336.627, "test_steps_per_second": 10.52}, {"test_loss": 0.05624500662088394, "test_micro_f1": 0.8058864751226349, "test_micro_f1_no_misc": 0.8387096774193549, "test_runtime": 5.5524, "test_samples_per_second": 368.847, "test_steps_per_second": 11.526}, {"test_loss": 0.05743762105703354, "test_micro_f1": 0.7995874871089721, "test_micro_f1_no_misc": 0.8374948833401555, "test_runtime": 5.836, "test_samples_per_second": 350.923, "test_steps_per_second": 10.966}, {"test_loss": 0.05194944515824318, "test_micro_f1": 0.8309143686502176, "test_micro_f1_no_misc": 0.877601998334721, "test_runtime": 5.8276, "test_samples_per_second": 351.433, "test_steps_per_second": 10.982}, {"test_loss": 0.06480447947978973, "test_micro_f1": 0.8191223688904744, "test_micro_f1_no_misc": 0.8557130942452045, "test_runtime": 6.1128, "test_samples_per_second": 335.036, "test_steps_per_second": 10.47}, {"test_loss": 0.06170589476823807, "test_micro_f1": 0.8125884016973126, "test_micro_f1_no_misc": 0.8512396694214877, "test_runtime": 5.735, "test_samples_per_second": 357.108, "test_steps_per_second": 11.16}, {"test_loss": 0.05771379545331001, "test_micro_f1": 0.8199932455251605, "test_micro_f1_no_misc": 0.8616978876046234, "test_runtime": 5.7753, "test_samples_per_second": 354.615, "test_steps_per_second": 11.082}, {"test_loss": 0.05146859586238861, "test_micro_f1": 0.7888596161083928, "test_micro_f1_no_misc": 0.829205807002562, "test_runtime": 6.2035, "test_samples_per_second": 330.138, "test_steps_per_second": 10.317}, {"test_loss": 0.0473308190703392, "test_micro_f1": 0.8358308358308357, "test_micro_f1_no_misc": 0.8672911787665886, "test_runtime": 5.6428, "test_samples_per_second": 362.939, "test_steps_per_second": 11.342}]}, "total": {"test_micro_f1": 81.55719863968798, "test_micro_f1_se": 1.0719976602020704, "test_micro_f1_no_misc": 85.31723568395891, "test_micro_f1_no_misc_se": 1.1099255630358815}}, "num_model_parameters": 123858441, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.12062391638755798, "test_micro_f1": 0.8715259570005244, "test_micro_f1_no_misc": 0.8715259570005244, "test_runtime": 5.2971, "test_samples_per_second": 386.626, "test_steps_per_second": 12.082}, {"test_loss": 0.1439843326807022, "test_micro_f1": 0.876345034397601, "test_micro_f1_no_misc": 0.876345034397601, "test_runtime": 5.3188, "test_samples_per_second": 385.048, "test_steps_per_second": 12.033}, {"test_loss": 0.12567874789237976, "test_micro_f1": 0.876456053653371, "test_micro_f1_no_misc": 0.876456053653371, "test_runtime": 5.243, "test_samples_per_second": 390.614, "test_steps_per_second": 12.207}, {"test_loss": 0.1415630429983139, "test_micro_f1": 0.8719203215096977, "test_micro_f1_no_misc": 0.8719203215096977, "test_runtime": 5.062, "test_samples_per_second": 404.581, "test_steps_per_second": 12.643}, {"test_loss": 0.12091067433357239, "test_micro_f1": 0.8629970480986283, "test_micro_f1_no_misc": 0.8629970480986283, "test_runtime": 5.0377, "test_samples_per_second": 406.536, "test_steps_per_second": 12.704}, {"test_loss": 0.15523450076580048, "test_micro_f1": 0.8481802426343154, "test_micro_f1_no_misc": 0.8481802426343154, "test_runtime": 5.0856, "test_samples_per_second": 402.707, "test_steps_per_second": 12.585}, {"test_loss": 0.12891355156898499, "test_micro_f1": 0.8701045543150806, "test_micro_f1_no_misc": 0.8701045543150806, "test_runtime": 5.093, "test_samples_per_second": 402.122, "test_steps_per_second": 12.566}, {"test_loss": 0.15895378589630127, "test_micro_f1": 0.8561064087061669, "test_micro_f1_no_misc": 0.8561064087061669, "test_runtime": 5.23, "test_samples_per_second": 391.585, "test_steps_per_second": 12.237}, {"test_loss": 0.13447274267673492, "test_micro_f1": 0.875894571478443, "test_micro_f1_no_misc": 0.875894571478443, "test_runtime": 5.3175, "test_samples_per_second": 385.14, "test_steps_per_second": 12.036}, {"test_loss": 0.14559350907802582, "test_micro_f1": 0.8288320515113575, "test_micro_f1_no_misc": 0.8288320515113575, "test_runtime": 5.0143, "test_samples_per_second": 408.435, "test_steps_per_second": 12.764}]}, "total": {"test_micro_f1": 86.38362243305187, "test_micro_f1_se": 0.9592586279698229, "test_micro_f1_no_misc": 86.38362243305187, "test_micro_f1_no_misc_se": 0.9592586279698229}}, "num_model_parameters": 123858441, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.4437659978866577, "test_mcc": 0.6327330097910936, "test_macro_f1": 0.7976190476190477, "test_runtime": 3.6488, "test_samples_per_second": 561.285, "test_steps_per_second": 17.54}, {"test_loss": 0.558133602142334, "test_mcc": 0.5644140865548432, "test_macro_f1": 0.7448556484379576, "test_runtime": 3.5911, "test_samples_per_second": 570.299, "test_steps_per_second": 17.822}, {"test_loss": 0.4627489447593689, "test_mcc": 0.6238506328073463, "test_macro_f1": 0.8009223757114929, "test_runtime": 3.906, "test_samples_per_second": 524.323, "test_steps_per_second": 16.385}, {"test_loss": 0.5002641081809998, "test_mcc": 0.6383225936542662, "test_macro_f1": 0.7996031746031746, "test_runtime": 3.6503, "test_samples_per_second": 561.042, "test_steps_per_second": 17.533}, {"test_loss": 0.5017119646072388, "test_mcc": 0.5597679256244955, "test_macro_f1": 0.7539067537309059, "test_runtime": 3.5826, "test_samples_per_second": 571.644, "test_steps_per_second": 17.864}, {"test_loss": 0.43681228160858154, "test_mcc": 0.6431438249873606, "test_macro_f1": 0.8091332712022368, "test_runtime": 3.5298, "test_samples_per_second": 580.196, "test_steps_per_second": 18.131}, {"test_loss": 0.4791945517063141, "test_mcc": 0.5735446990917881, "test_macro_f1": 0.7561312223598435, "test_runtime": 3.5596, "test_samples_per_second": 575.352, "test_steps_per_second": 17.98}, {"test_loss": 0.5162738561630249, "test_mcc": 0.6058498188403406, "test_macro_f1": 0.7842176764146006, "test_runtime": 3.7008, "test_samples_per_second": 553.4, "test_steps_per_second": 17.294}, {"test_loss": 0.49202123284339905, "test_mcc": 0.5881972596172785, "test_macro_f1": 0.7747392151984887, "test_runtime": 3.6531, "test_samples_per_second": 560.617, "test_steps_per_second": 17.519}, {"test_loss": 0.46246641874313354, "test_mcc": 0.614634032880708, "test_macro_f1": 0.7894174018549365, "test_runtime": 3.6749, "test_samples_per_second": 557.288, "test_steps_per_second": 17.415}]}, "total": {"test_mcc": 60.44457883849521, "test_mcc_se": 1.9320562470743596, "test_macro_f1": 78.10545787132685, "test_macro_f1_se": 1.3997109499666651}}, "num_model_parameters": 124443650, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "mideind/IceBERT", "results": {"raw": {"test": [{"test_loss": 0.6930318474769592, "test_mcc": 0.010203273273279908, "test_macro_f1": 0.468845231148285, "test_runtime": 2.3773, "test_samples_per_second": 430.748, "test_steps_per_second": 13.461}, {"test_loss": 0.6916108727455139, "test_mcc": 0.10154157473540756, "test_macro_f1": 0.4601754683997962, "test_runtime": 2.235, "test_samples_per_second": 458.174, "test_steps_per_second": 14.318}, {"test_loss": 0.693063497543335, "test_mcc": -0.005446584953325901, "test_macro_f1": 0.4953809148257408, "test_runtime": 2.1952, "test_samples_per_second": 466.468, "test_steps_per_second": 14.577}, {"test_loss": 0.6909461617469788, "test_mcc": 0.05147606767013146, "test_macro_f1": 0.35829939457108484, "test_runtime": 2.1801, "test_samples_per_second": 469.705, "test_steps_per_second": 14.678}, {"test_loss": 0.6158862709999084, "test_mcc": 0.3676802068771261, "test_macro_f1": 0.6813294232649071, "test_runtime": 2.2391, "test_samples_per_second": 457.323, "test_steps_per_second": 14.291}, {"test_loss": 0.6322636008262634, "test_mcc": 0.33846719000537956, "test_macro_f1": 0.6326325608093564, "test_runtime": 2.1921, "test_samples_per_second": 467.125, "test_steps_per_second": 14.598}, {"test_loss": 0.6896024346351624, "test_mcc": 0.08056686834794642, "test_macro_f1": 0.507002801120448, "test_runtime": 2.2333, "test_samples_per_second": 458.509, "test_steps_per_second": 14.328}, {"test_loss": 0.6927606463432312, "test_mcc": -0.021145493821617175, "test_macro_f1": 0.3402563933461513, "test_runtime": 2.3042, "test_samples_per_second": 444.399, "test_steps_per_second": 13.887}, {"test_loss": 0.6931760311126709, "test_mcc": 0.05260962090246297, "test_macro_f1": 0.3631933978139038, "test_runtime": 2.2993, "test_samples_per_second": 445.359, "test_steps_per_second": 13.917}, {"test_loss": 0.6927870512008667, "test_mcc": 0.03752883381169762, "test_macro_f1": 0.42358994571465136, "test_runtime": 2.2282, "test_samples_per_second": 459.557, "test_steps_per_second": 14.361}]}, "total": {"test_mcc": 10.134815568484886, "test_mcc_se": 8.549506954565251, "test_macro_f1": 47.30705531014324, "test_macro_f1_se": 7.036567340512806}}, "num_model_parameters": 124443650, "max_sequence_length": 512, "vocabulary_size": 50000}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.10216853767633438, "test_micro_f1": 0.5307302964569777, "test_micro_f1_no_misc": 0.5715450468813698, "test_runtime": 13.3426, "test_samples_per_second": 153.494, "test_steps_per_second": 19.187}, {"test_loss": 0.10981855541467667, "test_micro_f1": 0.597165991902834, "test_micro_f1_no_misc": 0.6361933308355189, "test_runtime": 11.8914, "test_samples_per_second": 172.225, "test_steps_per_second": 21.528}, {"test_loss": 0.10924717783927917, "test_micro_f1": 0.5700680272108843, "test_micro_f1_no_misc": 0.6146823887409663, "test_runtime": 10.7697, "test_samples_per_second": 190.163, "test_steps_per_second": 23.77}, {"test_loss": 0.11779147386550903, "test_micro_f1": 0.5586086956521739, "test_micro_f1_no_misc": 0.6018808777429466, "test_runtime": 12.1136, "test_samples_per_second": 169.066, "test_steps_per_second": 21.133}, {"test_loss": 0.11027301102876663, "test_micro_f1": 0.578768417075935, "test_micro_f1_no_misc": 0.6208387375702551, "test_runtime": 12.4824, "test_samples_per_second": 164.072, "test_steps_per_second": 20.509}, {"test_loss": 0.11229187250137329, "test_micro_f1": 0.6021807949349279, "test_micro_f1_no_misc": 0.6524764633647155, "test_runtime": 10.4769, "test_samples_per_second": 195.478, "test_steps_per_second": 24.435}, {"test_loss": 0.1273442655801773, "test_micro_f1": 0.5706540155879364, "test_micro_f1_no_misc": 0.6226046147829487, "test_runtime": 10.6886, "test_samples_per_second": 191.607, "test_steps_per_second": 23.951}, {"test_loss": 0.12010687589645386, "test_micro_f1": 0.5424729419481797, "test_micro_f1_no_misc": 0.5832410483573274, "test_runtime": 12.557, "test_samples_per_second": 163.097, "test_steps_per_second": 20.387}, {"test_loss": 0.11114417016506195, "test_micro_f1": 0.5575935436537051, "test_micro_f1_no_misc": 0.6031746031746033, "test_runtime": 13.4573, "test_samples_per_second": 152.185, "test_steps_per_second": 19.023}, {"test_loss": 0.11262646317481995, "test_micro_f1": 0.5330475169703466, "test_micro_f1_no_misc": 0.5726837060702875, "test_runtime": 12.4798, "test_samples_per_second": 164.105, "test_steps_per_second": 20.513}]}, "total": {"test_micro_f1": 56.412902413939, "test_micro_f1_se": 1.5259557901892893, "test_micro_f1_no_misc": 60.79320817520938, "test_micro_f1_no_misc_se": 1.6587069110500445}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.18407943844795227, "test_micro_f1": 0.8136436311955942, "test_micro_f1_no_misc": 0.8136436311955942, "test_runtime": 5.7132, "test_samples_per_second": 358.468, "test_steps_per_second": 11.202}, {"test_loss": 0.18141895532608032, "test_micro_f1": 0.8256624825662483, "test_micro_f1_no_misc": 0.8256624825662483, "test_runtime": 5.797, "test_samples_per_second": 353.287, "test_steps_per_second": 11.04}, {"test_loss": 0.17289641499519348, "test_micro_f1": 0.8087354702359986, "test_micro_f1_no_misc": 0.8087354702359986, "test_runtime": 5.8663, "test_samples_per_second": 349.114, "test_steps_per_second": 10.91}, {"test_loss": 0.19571438431739807, "test_micro_f1": 0.8038766519823789, "test_micro_f1_no_misc": 0.8038766519823789, "test_runtime": 5.6423, "test_samples_per_second": 362.975, "test_steps_per_second": 11.343}, {"test_loss": 0.1792406439781189, "test_micro_f1": 0.808291930786363, "test_micro_f1_no_misc": 0.808291930786363, "test_runtime": 5.8599, "test_samples_per_second": 349.493, "test_steps_per_second": 10.922}, {"test_loss": 0.21167708933353424, "test_micro_f1": 0.7959923993781309, "test_micro_f1_no_misc": 0.7959923993781309, "test_runtime": 5.6811, "test_samples_per_second": 360.492, "test_steps_per_second": 11.265}, {"test_loss": 0.17540694773197174, "test_micro_f1": 0.8249383585769636, "test_micro_f1_no_misc": 0.8249383585769636, "test_runtime": 5.8566, "test_samples_per_second": 349.694, "test_steps_per_second": 10.928}, {"test_loss": 0.20181581377983093, "test_micro_f1": 0.7852574890609222, "test_micro_f1_no_misc": 0.7852574890609222, "test_runtime": 5.8769, "test_samples_per_second": 348.483, "test_steps_per_second": 10.89}, {"test_loss": 0.1783583015203476, "test_micro_f1": 0.8281739130434782, "test_micro_f1_no_misc": 0.8281739130434782, "test_runtime": 5.9135, "test_samples_per_second": 346.327, "test_steps_per_second": 10.823}, {"test_loss": 0.1896492838859558, "test_micro_f1": 0.8012298788207634, "test_micro_f1_no_misc": 0.8012298788207634, "test_runtime": 5.8323, "test_samples_per_second": 351.151, "test_steps_per_second": 10.973}]}, "total": {"test_micro_f1": 80.95802205646841, "test_micro_f1_se": 0.8612124439536916, "test_micro_f1_no_misc": 80.95802205646841, "test_micro_f1_no_misc_se": 0.8612124439536916}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6952534317970276, "test_mcc": 0.0067194452652298235, "test_macro_f1": 0.4863253003212227, "test_runtime": 8.0894, "test_samples_per_second": 253.17, "test_steps_per_second": 31.646}, {"test_loss": 0.6922227144241333, "test_mcc": 0.026526350585721725, "test_macro_f1": 0.4979040199998619, "test_runtime": 8.0356, "test_samples_per_second": 254.867, "test_steps_per_second": 31.858}, {"test_loss": 0.6913065910339355, "test_mcc": 0.044517550138764204, "test_macro_f1": 0.5221984732824427, "test_runtime": 8.4384, "test_samples_per_second": 242.701, "test_steps_per_second": 30.338}, {"test_loss": 0.6964941620826721, "test_mcc": 0.0189735282643546, "test_macro_f1": 0.45129792807811386, "test_runtime": 7.9538, "test_samples_per_second": 257.487, "test_steps_per_second": 32.186}, {"test_loss": 0.6934257745742798, "test_mcc": 0.013951787765040857, "test_macro_f1": 0.3581957309706001, "test_runtime": 8.0758, "test_samples_per_second": 253.597, "test_steps_per_second": 31.7}, {"test_loss": 0.6931824684143066, "test_mcc": 0.020984132435368084, "test_macro_f1": 0.4580568386440147, "test_runtime": 7.9694, "test_samples_per_second": 256.982, "test_steps_per_second": 32.123}, {"test_loss": 0.6933799386024475, "test_mcc": 0.019591210569298245, "test_macro_f1": 0.44918133566061247, "test_runtime": 7.9993, "test_samples_per_second": 256.021, "test_steps_per_second": 32.003}, {"test_loss": 0.6939382553100586, "test_mcc": 0.026898457777495957, "test_macro_f1": 0.40658966959116755, "test_runtime": 8.0089, "test_samples_per_second": 255.715, "test_steps_per_second": 31.964}, {"test_loss": 0.6973861455917358, "test_mcc": -0.022757552375346556, "test_macro_f1": 0.4106754144534834, "test_runtime": 8.1384, "test_samples_per_second": 251.648, "test_steps_per_second": 31.456}, {"test_loss": 0.6952742338180542, "test_mcc": -0.02636598790516595, "test_macro_f1": 0.430148398854465, "test_runtime": 8.2282, "test_samples_per_second": 248.9, "test_steps_per_second": 31.112}]}, "total": {"test_mcc": 1.29038922520761, "test_mcc_se": 1.3674660251897028, "test_macro_f1": 44.70573109855984, "test_macro_f1_se": 2.998266546860632}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "patrickvonplaten/norwegian-roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6839535236358643, "test_mcc": 0.12440791410947977, "test_macro_f1": 0.5613021171760427, "test_runtime": 3.0596, "test_samples_per_second": 334.68, "test_steps_per_second": 10.459}, {"test_loss": 0.6889971494674683, "test_mcc": 0.03752173777898063, "test_macro_f1": 0.5184991249028332, "test_runtime": 2.8667, "test_samples_per_second": 357.201, "test_steps_per_second": 11.163}, {"test_loss": 0.694381833076477, "test_mcc": 0.03321366136888155, "test_macro_f1": 0.49386300607631956, "test_runtime": 2.7553, "test_samples_per_second": 371.652, "test_steps_per_second": 11.614}, {"test_loss": 0.6936350464820862, "test_mcc": 0.03683066044098653, "test_macro_f1": 0.5161016556853426, "test_runtime": 2.7232, "test_samples_per_second": 376.023, "test_steps_per_second": 11.751}, {"test_loss": 0.6974901556968689, "test_mcc": 0.035117109113356894, "test_macro_f1": 0.3833042842581815, "test_runtime": 2.8069, "test_samples_per_second": 364.811, "test_steps_per_second": 11.4}, {"test_loss": 0.694637656211853, "test_mcc": -0.03894188844575526, "test_macro_f1": 0.45548814736554355, "test_runtime": 2.7611, "test_samples_per_second": 370.862, "test_steps_per_second": 11.589}, {"test_loss": 0.692603349685669, "test_mcc": 0.13700541641675604, "test_macro_f1": 0.42843046421608477, "test_runtime": 2.7592, "test_samples_per_second": 371.128, "test_steps_per_second": 11.598}, {"test_loss": 0.6948966979980469, "test_mcc": 0.02953928975460867, "test_macro_f1": 0.48773773398955755, "test_runtime": 2.9037, "test_samples_per_second": 352.651, "test_steps_per_second": 11.02}, {"test_loss": 0.6897354125976562, "test_mcc": 0.1365992175954166, "test_macro_f1": 0.5092167723167585, "test_runtime": 2.9478, "test_samples_per_second": 347.376, "test_steps_per_second": 10.856}, {"test_loss": 0.6894989013671875, "test_mcc": 0.042746790841062726, "test_macro_f1": 0.5213017661156143, "test_runtime": 2.8224, "test_samples_per_second": 362.807, "test_steps_per_second": 11.338}]}, "total": {"test_mcc": 5.740399089737741, "test_mcc_se": 3.534771424220477, "test_macro_f1": 48.7524507210228, "test_macro_f1_se": 3.217372145660576}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.1821906864643097, "test_micro_f1": 0.27846975088967973, "test_micro_f1_no_misc": 0.29821073558648115, "test_runtime": 9.724, "test_samples_per_second": 210.613, "test_steps_per_second": 26.327}, {"test_loss": 0.19742563366889954, "test_micro_f1": 0.32182916307161347, "test_micro_f1_no_misc": 0.3484626647144949, "test_runtime": 8.6543, "test_samples_per_second": 236.645, "test_steps_per_second": 29.581}, {"test_loss": 0.19450026750564575, "test_micro_f1": 0.33144845585036975, "test_micro_f1_no_misc": 0.3639128231120122, "test_runtime": 8.5892, "test_samples_per_second": 238.439, "test_steps_per_second": 29.805}, {"test_loss": 0.19921442866325378, "test_micro_f1": 0.33260774923813674, "test_micro_f1_no_misc": 0.35592343507501295, "test_runtime": 9.3271, "test_samples_per_second": 219.575, "test_steps_per_second": 27.447}, {"test_loss": 0.19961820542812347, "test_micro_f1": 0.3260363297624593, "test_micro_f1_no_misc": 0.3439829605963791, "test_runtime": 9.3685, "test_samples_per_second": 218.604, "test_steps_per_second": 27.326}, {"test_loss": 0.20078478753566742, "test_micro_f1": 0.3204225352112676, "test_micro_f1_no_misc": 0.34205231388329976, "test_runtime": 8.3851, "test_samples_per_second": 244.242, "test_steps_per_second": 30.53}, {"test_loss": 0.19400013983249664, "test_micro_f1": 0.3397065362383282, "test_micro_f1_no_misc": 0.3720452209660843, "test_runtime": 8.3821, "test_samples_per_second": 244.33, "test_steps_per_second": 30.541}, {"test_loss": 0.20841658115386963, "test_micro_f1": 0.3323805634953042, "test_micro_f1_no_misc": 0.3592592592592593, "test_runtime": 9.3845, "test_samples_per_second": 218.232, "test_steps_per_second": 27.279}, {"test_loss": 0.19236740469932556, "test_micro_f1": 0.24751066856330015, "test_micro_f1_no_misc": 0.26543878656554715, "test_runtime": 9.6698, "test_samples_per_second": 211.794, "test_steps_per_second": 26.474}, {"test_loss": 0.1856640875339508, "test_micro_f1": 0.37935375577003777, "test_micro_f1_no_misc": 0.4082784571966134, "test_runtime": 9.3844, "test_samples_per_second": 218.236, "test_steps_per_second": 27.279}]}, "total": {"test_micro_f1": 32.09765508090497, "test_micro_f1_se": 2.2024608585995686, "test_micro_f1_no_misc": 34.57566656955184, "test_micro_f1_no_misc_se": 2.440281748044534}}, "num_model_parameters": 123938313, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.2280302345752716, "test_micro_f1": 0.7323632344814883, "test_micro_f1_no_misc": 0.7323632344814883, "test_runtime": 5.0644, "test_samples_per_second": 404.392, "test_steps_per_second": 12.637}, {"test_loss": 0.2551445960998535, "test_micro_f1": 0.7279398275545771, "test_micro_f1_no_misc": 0.7279398275545771, "test_runtime": 4.4217, "test_samples_per_second": 463.166, "test_steps_per_second": 14.474}, {"test_loss": 0.2502326965332031, "test_micro_f1": 0.7135056425191117, "test_micro_f1_no_misc": 0.7135056425191117, "test_runtime": 4.4005, "test_samples_per_second": 465.402, "test_steps_per_second": 14.544}, {"test_loss": 0.25594741106033325, "test_micro_f1": 0.7358738501971092, "test_micro_f1_no_misc": 0.7358738501971092, "test_runtime": 4.3517, "test_samples_per_second": 470.623, "test_steps_per_second": 14.707}, {"test_loss": 0.25661855936050415, "test_micro_f1": 0.7028301886792453, "test_micro_f1_no_misc": 0.7028301886792453, "test_runtime": 5.5156, "test_samples_per_second": 371.313, "test_steps_per_second": 11.604}, {"test_loss": 0.2624799311161041, "test_micro_f1": 0.7135714285714285, "test_micro_f1_no_misc": 0.7135714285714285, "test_runtime": 4.5577, "test_samples_per_second": 449.354, "test_steps_per_second": 14.042}, {"test_loss": 0.2519542872905731, "test_micro_f1": 0.7057796403003318, "test_micro_f1_no_misc": 0.7057796403003318, "test_runtime": 4.5745, "test_samples_per_second": 447.695, "test_steps_per_second": 13.99}, {"test_loss": 0.2730441391468048, "test_micro_f1": 0.6941340782122905, "test_micro_f1_no_misc": 0.6941340782122905, "test_runtime": 4.5889, "test_samples_per_second": 446.296, "test_steps_per_second": 13.947}, {"test_loss": 0.24509242177009583, "test_micro_f1": 0.7335824879871864, "test_micro_f1_no_misc": 0.7335824879871864, "test_runtime": 5.0523, "test_samples_per_second": 405.356, "test_steps_per_second": 12.667}, {"test_loss": 0.24913755059242249, "test_micro_f1": 0.7375705700236751, "test_micro_f1_no_misc": 0.7375705700236751, "test_runtime": 4.6004, "test_samples_per_second": 445.182, "test_steps_per_second": 13.912}]}, "total": {"test_micro_f1": 71.97150948526443, "test_micro_f1_se": 0.9712139890835364, "test_micro_f1_no_misc": 71.97150948526443, "test_micro_f1_no_misc_se": 0.9712139890835364}}, "num_model_parameters": 123938313, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.6934583187103271, "test_mcc": -0.001924751448740967, "test_macro_f1": 0.495263923336411, "test_runtime": 6.0769, "test_samples_per_second": 337.014, "test_steps_per_second": 42.127}, {"test_loss": 0.6930043697357178, "test_mcc": 0.044373039059580864, "test_macro_f1": 0.48609151189368993, "test_runtime": 6.0834, "test_samples_per_second": 336.655, "test_steps_per_second": 42.082}, {"test_loss": 0.6952980756759644, "test_mcc": -0.02374530865083106, "test_macro_f1": 0.4762686912015716, "test_runtime": 6.2917, "test_samples_per_second": 325.509, "test_steps_per_second": 40.689}, {"test_loss": 0.6923324465751648, "test_mcc": 0.03425235881189614, "test_macro_f1": 0.5137593686721789, "test_runtime": 5.9974, "test_samples_per_second": 341.479, "test_steps_per_second": 42.685}, {"test_loss": 0.6929969787597656, "test_mcc": 0.025993647209173566, "test_macro_f1": 0.4968467777213117, "test_runtime": 6.0458, "test_samples_per_second": 338.745, "test_steps_per_second": 42.343}, {"test_loss": 0.6942217350006104, "test_mcc": -0.010489247865032832, "test_macro_f1": 0.46835391894239664, "test_runtime": 5.9329, "test_samples_per_second": 345.195, "test_steps_per_second": 43.149}, {"test_loss": 0.6944873332977295, "test_mcc": -0.002709132668834844, "test_macro_f1": 0.49528462739816315, "test_runtime": 5.9974, "test_samples_per_second": 341.479, "test_steps_per_second": 42.685}, {"test_loss": 0.6950209736824036, "test_mcc": 0.011265085108719826, "test_macro_f1": 0.37645466847090664, "test_runtime": 6.1411, "test_samples_per_second": 333.49, "test_steps_per_second": 41.686}, {"test_loss": 0.6986585259437561, "test_mcc": -0.036044351115926986, "test_macro_f1": 0.35784364656464757, "test_runtime": 6.1054, "test_samples_per_second": 335.438, "test_steps_per_second": 41.93}, {"test_loss": 0.6921619772911072, "test_mcc": 0.014093607622217378, "test_macro_f1": 0.4576911419866324, "test_runtime": 6.0942, "test_samples_per_second": 336.057, "test_steps_per_second": 42.007}]}, "total": {"test_mcc": 0.5506494606222108, "test_mcc_se": 1.5767250538334725, "test_macro_f1": 46.2385827618791, "test_macro_f1_se": 3.2742157884149274}}, "num_model_parameters": 124523522, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "TurkuNLP/bert-base-finnish-cased-v1", "results": {"raw": {"test": [{"test_loss": 0.693535327911377, "test_mcc": 0.012850901061851657, "test_macro_f1": 0.44135653782960327, "test_runtime": 2.5935, "test_samples_per_second": 394.835, "test_steps_per_second": 12.339}, {"test_loss": 0.6942424178123474, "test_mcc": 0.007146450737276738, "test_macro_f1": 0.37872363942615556, "test_runtime": 2.3559, "test_samples_per_second": 434.659, "test_steps_per_second": 13.583}, {"test_loss": 0.6888463497161865, "test_mcc": -0.00024724447844633163, "test_macro_f1": 0.4958235627691694, "test_runtime": 2.2935, "test_samples_per_second": 446.479, "test_steps_per_second": 13.952}, {"test_loss": 0.6926959753036499, "test_mcc": -0.0018344697891375945, "test_macro_f1": 0.4990751356722464, "test_runtime": 2.3275, "test_samples_per_second": 439.953, "test_steps_per_second": 13.749}, {"test_loss": 0.6920357942581177, "test_mcc": -0.006778028037217746, "test_macro_f1": 0.4708333333333333, "test_runtime": 2.3282, "test_samples_per_second": 439.82, "test_steps_per_second": 13.744}, {"test_loss": 0.6934943199157715, "test_mcc": 0.03467039133594572, "test_macro_f1": 0.4153959484346224, "test_runtime": 2.3051, "test_samples_per_second": 444.234, "test_steps_per_second": 13.882}, {"test_loss": 0.6922250986099243, "test_mcc": 0.02412533309622637, "test_macro_f1": 0.5120582654623203, "test_runtime": 2.4144, "test_samples_per_second": 424.119, "test_steps_per_second": 13.254}, {"test_loss": 0.6931942701339722, "test_mcc": 0.003855450454517918, "test_macro_f1": 0.4884296391702281, "test_runtime": 2.3943, "test_samples_per_second": 427.687, "test_steps_per_second": 13.365}, {"test_loss": 0.6916480660438538, "test_mcc": 0.04594345950914253, "test_macro_f1": 0.4725491414661174, "test_runtime": 2.4744, "test_samples_per_second": 413.832, "test_steps_per_second": 12.932}, {"test_loss": 0.6924878358840942, "test_mcc": 0.05739557445566298, "test_macro_f1": 0.5169468363344217, "test_runtime": 2.4049, "test_samples_per_second": 425.803, "test_steps_per_second": 13.306}]}, "total": {"test_mcc": 1.7712781834582227, "test_mcc_se": 1.3598352552824386, "test_macro_f1": 46.91192039898218, "test_macro_f1_se": 2.768594611574175}}, "num_model_parameters": 124523522, "max_sequence_length": 512, "vocabulary_size": 50105}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.12015730887651443, "test_micro_f1": 0.4990730441230998, "test_micro_f1_no_misc": 0.54702329594478, "test_runtime": 13.2518, "test_samples_per_second": 154.546, "test_steps_per_second": 19.318}, {"test_loss": 0.12336938083171844, "test_micro_f1": 0.5166312809624912, "test_micro_f1_no_misc": 0.5514563106796116, "test_runtime": 11.7966, "test_samples_per_second": 173.609, "test_steps_per_second": 21.701}, {"test_loss": 0.13436928391456604, "test_micro_f1": 0.5398818316100443, "test_micro_f1_no_misc": 0.5863655374320368, "test_runtime": 10.579, "test_samples_per_second": 193.591, "test_steps_per_second": 24.199}, {"test_loss": 0.13063421845436096, "test_micro_f1": 0.5210954848260547, "test_micro_f1_no_misc": 0.5630821337849281, "test_runtime": 11.971, "test_samples_per_second": 171.08, "test_steps_per_second": 21.385}, {"test_loss": 0.13521692156791687, "test_micro_f1": 0.5217054263565891, "test_micro_f1_no_misc": 0.5670194003527336, "test_runtime": 12.0434, "test_samples_per_second": 170.051, "test_steps_per_second": 21.256}, {"test_loss": 0.1417074203491211, "test_micro_f1": 0.5400221320545924, "test_micro_f1_no_misc": 0.5819706498951782, "test_runtime": 10.7433, "test_samples_per_second": 190.631, "test_steps_per_second": 23.829}, {"test_loss": 0.1266804337501526, "test_micro_f1": 0.49489795918367346, "test_micro_f1_no_misc": 0.5555079297042433, "test_runtime": 10.8309, "test_samples_per_second": 189.089, "test_steps_per_second": 23.636}, {"test_loss": 0.13696607947349548, "test_micro_f1": 0.4838255977496484, "test_micro_f1_no_misc": 0.5231607629427794, "test_runtime": 12.1073, "test_samples_per_second": 169.154, "test_steps_per_second": 21.144}, {"test_loss": 0.12232479453086853, "test_micro_f1": 0.545176110260337, "test_micro_f1_no_misc": 0.5919361984935756, "test_runtime": 13.1745, "test_samples_per_second": 155.452, "test_steps_per_second": 19.432}, {"test_loss": 0.11599265784025192, "test_micro_f1": 0.5763790664780765, "test_micro_f1_no_misc": 0.6210191082802549, "test_runtime": 12.0723, "test_samples_per_second": 169.645, "test_steps_per_second": 21.206}]}, "total": {"test_micro_f1": 52.386879336046064, "test_micro_f1_se": 1.710065172910969, "test_micro_f1_no_misc": 56.885413275101214, "test_micro_f1_no_misc_se": 1.7055148463766403}}, "num_model_parameters": 109344009, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.15917688608169556, "test_micro_f1": 0.8204145619230099, "test_micro_f1_no_misc": 0.8204145619230099, "test_runtime": 6.4972, "test_samples_per_second": 315.211, "test_steps_per_second": 9.85}, {"test_loss": 0.1804414987564087, "test_micro_f1": 0.8076262452765374, "test_micro_f1_no_misc": 0.8076262452765374, "test_runtime": 6.3327, "test_samples_per_second": 323.401, "test_steps_per_second": 10.106}, {"test_loss": 0.15755394101142883, "test_micro_f1": 0.8189825633650908, "test_micro_f1_no_misc": 0.8189825633650908, "test_runtime": 6.3537, "test_samples_per_second": 322.33, "test_steps_per_second": 10.073}, {"test_loss": 0.20141315460205078, "test_micro_f1": 0.8412870571221982, "test_micro_f1_no_misc": 0.8412870571221982, "test_runtime": 6.3822, "test_samples_per_second": 320.892, "test_steps_per_second": 10.028}, {"test_loss": 0.17457345128059387, "test_micro_f1": 0.7978237978237979, "test_micro_f1_no_misc": 0.7978237978237979, "test_runtime": 6.5969, "test_samples_per_second": 310.45, "test_steps_per_second": 9.702}, {"test_loss": 0.1875404417514801, "test_micro_f1": 0.801115565626634, "test_micro_f1_no_misc": 0.801115565626634, "test_runtime": 6.3751, "test_samples_per_second": 321.252, "test_steps_per_second": 10.039}, {"test_loss": 0.16781733930110931, "test_micro_f1": 0.8052910052910053, "test_micro_f1_no_misc": 0.8052910052910053, "test_runtime": 6.4056, "test_samples_per_second": 319.722, "test_steps_per_second": 9.991}, {"test_loss": 0.20748138427734375, "test_micro_f1": 0.8044077134986225, "test_micro_f1_no_misc": 0.8044077134986225, "test_runtime": 6.5478, "test_samples_per_second": 312.777, "test_steps_per_second": 9.774}, {"test_loss": 0.1652025580406189, "test_micro_f1": 0.8254915730337078, "test_micro_f1_no_misc": 0.8254915730337078, "test_runtime": 7.0432, "test_samples_per_second": 290.777, "test_steps_per_second": 9.087}, {"test_loss": 0.18029269576072693, "test_micro_f1": 0.820838627700127, "test_micro_f1_no_misc": 0.820838627700127, "test_runtime": 6.4856, "test_samples_per_second": 315.778, "test_steps_per_second": 9.868}]}, "total": {"test_micro_f1": 81.43278710660731, "test_micro_f1_se": 0.8327028925919324, "test_micro_f1_no_misc": 81.43278710660731, "test_micro_f1_no_misc_se": 0.8327028925919324}}, "num_model_parameters": 109344009, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.6951045989990234, "test_mcc": -0.0011222761672059277, "test_macro_f1": 0.48462022123299864, "test_runtime": 7.5678, "test_samples_per_second": 270.619, "test_steps_per_second": 33.827}, {"test_loss": 0.6926870346069336, "test_mcc": 0.029441050950489715, "test_macro_f1": 0.4374890758820445, "test_runtime": 7.4997, "test_samples_per_second": 273.078, "test_steps_per_second": 34.135}, {"test_loss": 0.6959007978439331, "test_mcc": 0.017020610267318426, "test_macro_f1": 0.4978996787744008, "test_runtime": 7.8134, "test_samples_per_second": 262.115, "test_steps_per_second": 32.764}, {"test_loss": 0.6924363374710083, "test_mcc": -0.0277940025163536, "test_macro_f1": 0.37397725680097044, "test_runtime": 7.4586, "test_samples_per_second": 274.583, "test_steps_per_second": 34.323}, {"test_loss": 0.6953465342521667, "test_mcc": -0.014068183295154654, "test_macro_f1": 0.41253309796999116, "test_runtime": 7.6251, "test_samples_per_second": 268.586, "test_steps_per_second": 33.573}, {"test_loss": 0.693289041519165, "test_mcc": 0.039814543888208015, "test_macro_f1": 0.49065482706827923, "test_runtime": 7.3999, "test_samples_per_second": 276.762, "test_steps_per_second": 34.595}, {"test_loss": 0.6970000863075256, "test_mcc": -0.02456227484716891, "test_macro_f1": 0.4877131536163396, "test_runtime": 7.4525, "test_samples_per_second": 274.807, "test_steps_per_second": 34.351}, {"test_loss": 0.6951079368591309, "test_mcc": -0.024162721346683395, "test_macro_f1": 0.4743095178725963, "test_runtime": 7.5654, "test_samples_per_second": 270.707, "test_steps_per_second": 33.838}, {"test_loss": 0.6928592324256897, "test_mcc": 0.015159361526663853, "test_macro_f1": 0.42897862845136625, "test_runtime": 7.6542, "test_samples_per_second": 267.566, "test_steps_per_second": 33.446}, {"test_loss": 0.6960527896881104, "test_mcc": -0.022853874911969857, "test_macro_f1": 0.4599693704171316, "test_runtime": 7.678, "test_samples_per_second": 266.735, "test_steps_per_second": 33.342}]}, "total": {"test_mcc": -0.13127766451856335, "test_mcc_se": 1.5509435517730958, "test_macro_f1": 45.48144828086119, "test_macro_f1_se": 2.514122418451677}}, "num_model_parameters": 109929218, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "deepset/gbert-base", "results": {"raw": {"test": [{"test_loss": 0.6928615570068359, "test_mcc": -0.0034615810791905383, "test_macro_f1": 0.4980392156862745, "test_runtime": 3.499, "test_samples_per_second": 292.659, "test_steps_per_second": 9.146}, {"test_loss": 0.6959563493728638, "test_mcc": -0.026992574841436228, "test_macro_f1": 0.4862791327603112, "test_runtime": 3.2829, "test_samples_per_second": 311.918, "test_steps_per_second": 9.747}, {"test_loss": 0.6937333345413208, "test_mcc": -0.02538259275809727, "test_macro_f1": 0.4786410565868102, "test_runtime": 3.1329, "test_samples_per_second": 326.852, "test_steps_per_second": 10.214}, {"test_loss": 0.6939877271652222, "test_mcc": -0.027042813348344186, "test_macro_f1": 0.43238425056220764, "test_runtime": 3.1284, "test_samples_per_second": 327.32, "test_steps_per_second": 10.229}, {"test_loss": 0.6936043500900269, "test_mcc": -0.00380171886492848, "test_macro_f1": 0.4748192050789488, "test_runtime": 3.2096, "test_samples_per_second": 319.043, "test_steps_per_second": 9.97}, {"test_loss": 0.6954988241195679, "test_mcc": 0.05523326700719085, "test_macro_f1": 0.38496308430073833, "test_runtime": 3.0883, "test_samples_per_second": 331.575, "test_steps_per_second": 10.362}, {"test_loss": 0.6933573484420776, "test_mcc": 0.03431823277383726, "test_macro_f1": 0.40008100757999493, "test_runtime": 3.1398, "test_samples_per_second": 326.14, "test_steps_per_second": 10.192}, {"test_loss": 0.6972468495368958, "test_mcc": -0.026118668228705982, "test_macro_f1": 0.4847872666054484, "test_runtime": 3.325, "test_samples_per_second": 307.974, "test_steps_per_second": 9.624}, {"test_loss": 0.6914112567901611, "test_mcc": 0.04542729390904729, "test_macro_f1": 0.4985791577696791, "test_runtime": 3.3904, "test_samples_per_second": 302.03, "test_steps_per_second": 9.438}, {"test_loss": 0.6943141222000122, "test_mcc": 0.03740264660439924, "test_macro_f1": 0.4392089142887428, "test_runtime": 3.2209, "test_samples_per_second": 317.927, "test_steps_per_second": 9.935}]}, "total": {"test_mcc": 0.5958149117377195, "test_mcc_se": 2.0813425903229406, "test_macro_f1": 45.77782291219156, "test_macro_f1_se": 2.544965482731002}}, "num_model_parameters": 109929218, "max_sequence_length": 512, "vocabulary_size": 31102}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.1109972596168518, "test_micro_f1": 0.46692334616730835, "test_micro_f1_no_misc": 0.5074045206547156, "test_runtime": 14.6334, "test_samples_per_second": 139.954, "test_steps_per_second": 17.494}, {"test_loss": 0.10776175558567047, "test_micro_f1": 0.5834172541121181, "test_micro_f1_no_misc": 0.6204111600587371, "test_runtime": 12.96, "test_samples_per_second": 158.025, "test_steps_per_second": 19.753}, {"test_loss": 0.10923169553279877, "test_micro_f1": 0.6140963014654571, "test_micro_f1_no_misc": 0.659270998415214, "test_runtime": 12.2649, "test_samples_per_second": 166.98, "test_steps_per_second": 20.873}, {"test_loss": 0.11893551051616669, "test_micro_f1": 0.5228621291448515, "test_micro_f1_no_misc": 0.5914396887159532, "test_runtime": 13.2105, "test_samples_per_second": 155.029, "test_steps_per_second": 19.379}, {"test_loss": 0.11122727394104004, "test_micro_f1": 0.5737473535638673, "test_micro_f1_no_misc": 0.6138227254978523, "test_runtime": 13.8106, "test_samples_per_second": 148.292, "test_steps_per_second": 18.537}, {"test_loss": 0.11183726042509079, "test_micro_f1": 0.5854341736694677, "test_micro_f1_no_misc": 0.6306796116504855, "test_runtime": 10.9939, "test_samples_per_second": 186.286, "test_steps_per_second": 23.286}, {"test_loss": 0.11853204667568207, "test_micro_f1": 0.5142055419151176, "test_micro_f1_no_misc": 0.5539795114263201, "test_runtime": 11.1304, "test_samples_per_second": 184.001, "test_steps_per_second": 23.0}, {"test_loss": 0.12170189619064331, "test_micro_f1": 0.5062706270627062, "test_micro_f1_no_misc": 0.546112115732369, "test_runtime": 13.8872, "test_samples_per_second": 147.474, "test_steps_per_second": 18.434}, {"test_loss": 0.11150605976581573, "test_micro_f1": 0.5767272727272728, "test_micro_f1_no_misc": 0.6272340425531915, "test_runtime": 14.6106, "test_samples_per_second": 140.172, "test_steps_per_second": 17.522}, {"test_loss": 0.10837606340646744, "test_micro_f1": 0.6259592926259593, "test_micro_f1_no_misc": 0.667910447761194, "test_runtime": 13.7716, "test_samples_per_second": 148.712, "test_steps_per_second": 18.589}]}, "total": {"test_micro_f1": 55.69643292454125, "test_micro_f1_se": 3.192347679843577, "test_micro_f1_no_misc": 60.182648224660326, "test_micro_f1_no_misc_se": 3.20407388016474}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.15858684480190277, "test_micro_f1": 0.8162828066416711, "test_micro_f1_no_misc": 0.8162828066416711, "test_runtime": 6.9787, "test_samples_per_second": 293.465, "test_steps_per_second": 9.171}, {"test_loss": 0.1540757566690445, "test_micro_f1": 0.8367743073936826, "test_micro_f1_no_misc": 0.8367743073936826, "test_runtime": 6.8733, "test_samples_per_second": 297.966, "test_steps_per_second": 9.311}, {"test_loss": 0.15873686969280243, "test_micro_f1": 0.8444365698086463, "test_micro_f1_no_misc": 0.8444365698086463, "test_runtime": 6.8651, "test_samples_per_second": 298.32, "test_steps_per_second": 9.323}, {"test_loss": 0.1636410653591156, "test_micro_f1": 0.8384386486959566, "test_micro_f1_no_misc": 0.8384386486959566, "test_runtime": 6.6902, "test_samples_per_second": 306.121, "test_steps_per_second": 9.566}, {"test_loss": 0.17697685956954956, "test_micro_f1": 0.8117359413202934, "test_micro_f1_no_misc": 0.8117359413202934, "test_runtime": 6.6772, "test_samples_per_second": 306.714, "test_steps_per_second": 9.585}, {"test_loss": 0.1902076005935669, "test_micro_f1": 0.835153222965833, "test_micro_f1_no_misc": 0.835153222965833, "test_runtime": 6.7027, "test_samples_per_second": 305.55, "test_steps_per_second": 9.548}, {"test_loss": 0.16687564551830292, "test_micro_f1": 0.8129996524157108, "test_micro_f1_no_misc": 0.8129996524157108, "test_runtime": 6.9219, "test_samples_per_second": 295.873, "test_steps_per_second": 9.246}, {"test_loss": 0.18103814125061035, "test_micro_f1": 0.8100646514066048, "test_micro_f1_no_misc": 0.8100646514066048, "test_runtime": 6.8824, "test_samples_per_second": 297.569, "test_steps_per_second": 9.299}, {"test_loss": 0.14710839092731476, "test_micro_f1": 0.8385751520417029, "test_micro_f1_no_misc": 0.8385751520417029, "test_runtime": 7.0649, "test_samples_per_second": 289.885, "test_steps_per_second": 9.059}, {"test_loss": 0.16435030102729797, "test_micro_f1": 0.8232064421669106, "test_micro_f1_no_misc": 0.8232064421669106, "test_runtime": 6.7344, "test_samples_per_second": 304.11, "test_steps_per_second": 9.503}]}, "total": {"test_micro_f1": 82.6766739485701, "test_micro_f1_se": 0.8200271338548756, "test_micro_f1_no_misc": 82.6766739485701, "test_micro_f1_no_misc_se": 0.8200271338548756}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6934807896614075, "test_mcc": 0.0, "test_macro_f1": 0.3278634722678044, "test_runtime": 8.4082, "test_samples_per_second": 243.573, "test_steps_per_second": 30.447}, {"test_loss": 0.6928055286407471, "test_mcc": 0.021040733694308922, "test_macro_f1": 0.5089026675063836, "test_runtime": 8.3776, "test_samples_per_second": 244.461, "test_steps_per_second": 30.558}, {"test_loss": 0.6932184100151062, "test_mcc": 0.03624132352414999, "test_macro_f1": 0.34137986798194675, "test_runtime": 8.6374, "test_samples_per_second": 237.109, "test_steps_per_second": 29.639}, {"test_loss": 0.6930162310600281, "test_mcc": 0.01269264292304884, "test_macro_f1": 0.5058518348973831, "test_runtime": 8.29, "test_samples_per_second": 247.043, "test_steps_per_second": 30.88}, {"test_loss": 0.6930017471313477, "test_mcc": 0.03162108842435155, "test_macro_f1": 0.47970627018787576, "test_runtime": 8.4615, "test_samples_per_second": 242.037, "test_steps_per_second": 30.255}, {"test_loss": 0.6934366822242737, "test_mcc": -0.019350650177928492, "test_macro_f1": 0.40618724962218106, "test_runtime": 8.255, "test_samples_per_second": 248.092, "test_steps_per_second": 31.011}, {"test_loss": 0.6929938793182373, "test_mcc": 0.058818535984623214, "test_macro_f1": 0.4930306856658261, "test_runtime": 8.3493, "test_samples_per_second": 245.289, "test_steps_per_second": 30.661}, {"test_loss": 0.6932185888290405, "test_mcc": -0.021010726231708163, "test_macro_f1": 0.4172431336998592, "test_runtime": 8.3839, "test_samples_per_second": 244.276, "test_steps_per_second": 30.535}, {"test_loss": 0.6930884122848511, "test_mcc": -0.006140802143345611, "test_macro_f1": 0.4670486446154236, "test_runtime": 8.4871, "test_samples_per_second": 241.306, "test_steps_per_second": 30.163}, {"test_loss": 0.6934544444084167, "test_mcc": -0.007270489305203504, "test_macro_f1": 0.33934430452098463, "test_runtime": 8.5629, "test_samples_per_second": 239.17, "test_steps_per_second": 29.896}]}, "total": {"test_mcc": 1.0664165669229673, "test_mcc_se": 1.6196851547442996, "test_macro_f1": 42.86558130965668, "test_macro_f1_se": 4.479546258809056}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "roberta-base", "results": {"raw": {"test": [{"test_loss": 0.6941837668418884, "test_mcc": -0.08527740503445738, "test_macro_f1": 0.3740975666013147, "test_runtime": 3.4766, "test_samples_per_second": 294.541, "test_steps_per_second": 9.204}, {"test_loss": 0.6933739185333252, "test_mcc": 0.0, "test_macro_f1": 0.330718954248366, "test_runtime": 3.2586, "test_samples_per_second": 314.249, "test_steps_per_second": 9.82}, {"test_loss": 0.6931620836257935, "test_mcc": -0.008175989055141107, "test_macro_f1": 0.40766195311649855, "test_runtime": 3.1749, "test_samples_per_second": 322.534, "test_steps_per_second": 10.079}, {"test_loss": 0.693225622177124, "test_mcc": -0.013162296777686934, "test_macro_f1": 0.3336971317304229, "test_runtime": 3.0911, "test_samples_per_second": 331.274, "test_steps_per_second": 10.352}, {"test_loss": 0.69304358959198, "test_mcc": -0.03230872612392922, "test_macro_f1": 0.39224376666701644, "test_runtime": 3.2074, "test_samples_per_second": 319.265, "test_steps_per_second": 9.977}, {"test_loss": 0.693306565284729, "test_mcc": -0.03217038736481284, "test_macro_f1": 0.33109237375795375, "test_runtime": 3.1082, "test_samples_per_second": 329.449, "test_steps_per_second": 10.295}, {"test_loss": 0.6930280923843384, "test_mcc": 0.06795461675396505, "test_macro_f1": 0.5117958166163643, "test_runtime": 3.1487, "test_samples_per_second": 325.218, "test_steps_per_second": 10.163}, {"test_loss": 0.6930493116378784, "test_mcc": 0.0, "test_macro_f1": 0.3359273670557717, "test_runtime": 3.2841, "test_samples_per_second": 311.802, "test_steps_per_second": 9.744}, {"test_loss": 0.6924405097961426, "test_mcc": -0.014708820439230767, "test_macro_f1": 0.41916929226324207, "test_runtime": 3.3406, "test_samples_per_second": 306.53, "test_steps_per_second": 9.579}, {"test_loss": 0.6933896541595459, "test_mcc": 0.0, "test_macro_f1": 0.33159268929503916, "test_runtime": 3.2177, "test_samples_per_second": 318.239, "test_steps_per_second": 9.945}]}, "total": {"test_mcc": -1.178490080412932, "test_mcc_se": 2.358927538836053, "test_macro_f1": 37.679969113519896, "test_macro_f1_se": 3.637728133869568}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.10990259796380997, "test_micro_f1": 0.4892193308550186, "test_micro_f1_no_misc": 0.5225672877846792, "test_runtime": 14.8155, "test_samples_per_second": 138.234, "test_steps_per_second": 17.279}, {"test_loss": 0.11888931691646576, "test_micro_f1": 0.5266030013642565, "test_micro_f1_no_misc": 0.5636836242109171, "test_runtime": 13.5616, "test_samples_per_second": 151.015, "test_steps_per_second": 18.877}, {"test_loss": 0.1380084753036499, "test_micro_f1": 0.5303385853167952, "test_micro_f1_no_misc": 0.571972581873572, "test_runtime": 12.7451, "test_samples_per_second": 160.689, "test_steps_per_second": 20.086}, {"test_loss": 0.12350453436374664, "test_micro_f1": 0.49893992932862197, "test_micro_f1_no_misc": 0.5320312500000001, "test_runtime": 13.8588, "test_samples_per_second": 147.776, "test_steps_per_second": 18.472}, {"test_loss": 0.12942707538604736, "test_micro_f1": 0.43655197928227896, "test_micro_f1_no_misc": 0.4764610389610389, "test_runtime": 14.2058, "test_samples_per_second": 144.166, "test_steps_per_second": 18.021}, {"test_loss": 0.11955713480710983, "test_micro_f1": 0.5299618981641843, "test_micro_f1_no_misc": 0.5781803859787318, "test_runtime": 12.1961, "test_samples_per_second": 167.922, "test_steps_per_second": 20.99}, {"test_loss": 0.12855002284049988, "test_micro_f1": 0.5191370911621433, "test_micro_f1_no_misc": 0.5659937888198757, "test_runtime": 12.3089, "test_samples_per_second": 166.383, "test_steps_per_second": 20.798}, {"test_loss": 0.12408575415611267, "test_micro_f1": 0.49625040756439515, "test_micro_f1_no_misc": 0.5386882829771555, "test_runtime": 14.2471, "test_samples_per_second": 143.748, "test_steps_per_second": 17.969}, {"test_loss": 0.10850098729133606, "test_micro_f1": 0.5302396348421453, "test_micro_f1_no_misc": 0.5807860262008734, "test_runtime": 15.039, "test_samples_per_second": 136.179, "test_steps_per_second": 17.022}, {"test_loss": 0.10885705053806305, "test_micro_f1": 0.5783132530120483, "test_micro_f1_no_misc": 0.6237054085155351, "test_runtime": 14.303, "test_samples_per_second": 143.187, "test_steps_per_second": 17.898}]}, "total": {"test_micro_f1": 51.355551108918874, "test_micro_f1_se": 2.28750956309633, "test_micro_f1_no_misc": 55.540696753223784, "test_micro_f1_no_misc_se": 2.4808821196021054}}, "num_model_parameters": 116178441, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.16748040914535522, "test_micro_f1": 0.8217376254759432, "test_micro_f1_no_misc": 0.8217376254759432, "test_runtime": 7.0838, "test_samples_per_second": 289.109, "test_steps_per_second": 9.035}, {"test_loss": 0.16787448525428772, "test_micro_f1": 0.811113052594793, "test_micro_f1_no_misc": 0.811113052594793, "test_runtime": 7.0073, "test_samples_per_second": 292.267, "test_steps_per_second": 9.133}, {"test_loss": 0.17326772212982178, "test_micro_f1": 0.8138679740850989, "test_micro_f1_no_misc": 0.8138679740850989, "test_runtime": 6.9542, "test_samples_per_second": 294.498, "test_steps_per_second": 9.203}, {"test_loss": 0.18987694382667542, "test_micro_f1": 0.8257722859664608, "test_micro_f1_no_misc": 0.8257722859664608, "test_runtime": 7.0335, "test_samples_per_second": 291.179, "test_steps_per_second": 9.099}, {"test_loss": 0.1753198504447937, "test_micro_f1": 0.8102493074792242, "test_micro_f1_no_misc": 0.8102493074792242, "test_runtime": 6.8942, "test_samples_per_second": 297.059, "test_steps_per_second": 9.283}, {"test_loss": 0.20461414754390717, "test_micro_f1": 0.7868398268398268, "test_micro_f1_no_misc": 0.7868398268398268, "test_runtime": 6.7845, "test_samples_per_second": 301.863, "test_steps_per_second": 9.433}, {"test_loss": 0.17248119413852692, "test_micro_f1": 0.7942867096324682, "test_micro_f1_no_misc": 0.7942867096324682, "test_runtime": 6.8781, "test_samples_per_second": 297.758, "test_steps_per_second": 9.305}, {"test_loss": 0.19281193614006042, "test_micro_f1": 0.810940994323069, "test_micro_f1_no_misc": 0.810940994323069, "test_runtime": 7.0174, "test_samples_per_second": 291.845, "test_steps_per_second": 9.12}, {"test_loss": 0.17837145924568176, "test_micro_f1": 0.8224134902511856, "test_micro_f1_no_misc": 0.8224134902511856, "test_runtime": 7.5167, "test_samples_per_second": 272.461, "test_steps_per_second": 8.514}, {"test_loss": 0.19900009036064148, "test_micro_f1": 0.8032241107411952, "test_micro_f1_no_misc": 0.8032241107411952, "test_runtime": 6.8866, "test_samples_per_second": 297.388, "test_steps_per_second": 9.293}]}, "total": {"test_micro_f1": 81.00445377389265, "test_micro_f1_se": 0.7694295557450933, "test_micro_f1_no_misc": 81.00445377389265, "test_micro_f1_no_misc_se": 0.7694295557450933}}, "num_model_parameters": 116178441, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.6925982236862183, "test_mcc": 0.02761520049515006, "test_macro_f1": 0.4940099126268461, "test_runtime": 9.0255, "test_samples_per_second": 226.913, "test_steps_per_second": 28.364}, {"test_loss": 0.6931018829345703, "test_mcc": 0.03659781450511908, "test_macro_f1": 0.419796375240534, "test_runtime": 8.9381, "test_samples_per_second": 229.131, "test_steps_per_second": 28.641}, {"test_loss": 0.6982766389846802, "test_mcc": 0.003657085109445588, "test_macro_f1": 0.3482361563832044, "test_runtime": 9.2935, "test_samples_per_second": 220.37, "test_steps_per_second": 27.546}, {"test_loss": 0.6936328411102295, "test_mcc": 0.0017034615900964588, "test_macro_f1": 0.42092988392106556, "test_runtime": 8.8407, "test_samples_per_second": 231.657, "test_steps_per_second": 28.957}, {"test_loss": 0.6941378712654114, "test_mcc": 0.04234431660881611, "test_macro_f1": 0.4797065219600431, "test_runtime": 9.116, "test_samples_per_second": 224.66, "test_steps_per_second": 28.082}, {"test_loss": 0.6938005685806274, "test_mcc": -0.013701908675692844, "test_macro_f1": 0.46368139998713254, "test_runtime": 8.9107, "test_samples_per_second": 229.836, "test_steps_per_second": 28.73}, {"test_loss": 0.6935877203941345, "test_mcc": 0.02397311464651267, "test_macro_f1": 0.47818664113763737, "test_runtime": 8.9635, "test_samples_per_second": 228.482, "test_steps_per_second": 28.56}, {"test_loss": 0.6949476003646851, "test_mcc": -0.011978749040195325, "test_macro_f1": 0.35840142246306256, "test_runtime": 8.9245, "test_samples_per_second": 229.48, "test_steps_per_second": 28.685}, {"test_loss": 0.6959384679794312, "test_mcc": -0.012561746044679002, "test_macro_f1": 0.38711641612205283, "test_runtime": 9.0722, "test_samples_per_second": 225.744, "test_steps_per_second": 28.218}, {"test_loss": 0.6929605603218079, "test_mcc": 0.008256663986875534, "test_macro_f1": 0.47666116152792953, "test_runtime": 9.1209, "test_samples_per_second": 224.54, "test_steps_per_second": 28.068}]}, "total": {"test_mcc": 1.0590525318144832, "test_mcc_se": 1.2938040980043923, "test_macro_f1": 43.26725891369508, "test_macro_f1_se": 3.3292637256600326}}, "num_model_parameters": 116763650, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "pdelobelle/robbert-v2-dutch-base", "results": {"raw": {"test": [{"test_loss": 0.6897448301315308, "test_mcc": 0.06923033212917228, "test_macro_f1": 0.5126617715282111, "test_runtime": 3.6469, "test_samples_per_second": 280.784, "test_steps_per_second": 8.775}, {"test_loss": 0.6925219297409058, "test_mcc": 0.011008604793587604, "test_macro_f1": 0.5051779527318427, "test_runtime": 3.3701, "test_samples_per_second": 303.851, "test_steps_per_second": 9.495}, {"test_loss": 0.693963885307312, "test_mcc": -0.027368316313056893, "test_macro_f1": 0.3903200729746611, "test_runtime": 3.2414, "test_samples_per_second": 315.912, "test_steps_per_second": 9.872}, {"test_loss": 0.6968690156936646, "test_mcc": -0.0788098994162415, "test_macro_f1": 0.4347055179761639, "test_runtime": 3.1657, "test_samples_per_second": 323.462, "test_steps_per_second": 10.108}, {"test_loss": 0.6935513019561768, "test_mcc": -0.00799909442365064, "test_macro_f1": 0.48947893722136354, "test_runtime": 3.3399, "test_samples_per_second": 306.593, "test_steps_per_second": 9.581}, {"test_loss": 0.6927286386489868, "test_mcc": 0.008274335873408738, "test_macro_f1": 0.4953169074446366, "test_runtime": 3.1753, "test_samples_per_second": 322.491, "test_steps_per_second": 10.078}, {"test_loss": 0.693781852722168, "test_mcc": -0.007790725749915427, "test_macro_f1": 0.3821119221411192, "test_runtime": 3.2906, "test_samples_per_second": 311.192, "test_steps_per_second": 9.725}, {"test_loss": 0.6946021318435669, "test_mcc": 0.002676623340746494, "test_macro_f1": 0.49437560757325594, "test_runtime": 3.3937, "test_samples_per_second": 301.74, "test_steps_per_second": 9.429}, {"test_loss": 0.6908547282218933, "test_mcc": 0.047239029356167854, "test_macro_f1": 0.5206465206532216, "test_runtime": 3.4486, "test_samples_per_second": 296.93, "test_steps_per_second": 9.279}, {"test_loss": 0.6928436756134033, "test_mcc": 0.048621831990749736, "test_macro_f1": 0.5147601350860277, "test_runtime": 3.3336, "test_samples_per_second": 307.172, "test_steps_per_second": 9.599}]}, "total": {"test_mcc": 0.6508272158096825, "test_mcc_se": 2.633378753222248, "test_macro_f1": 47.39555345330504, "test_macro_f1_se": 3.2274298222471853}}, "num_model_parameters": 116763650, "max_sequence_length": 512, "vocabulary_size": 40000}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.10061919689178467, "test_micro_f1": 0.5544973544973545, "test_micro_f1_no_misc": 0.6021678040947411, "test_runtime": 14.6964, "test_samples_per_second": 139.354, "test_steps_per_second": 17.419}, {"test_loss": 0.10263916850090027, "test_micro_f1": 0.5668299510146956, "test_micro_f1_no_misc": 0.6081916537867079, "test_runtime": 12.4737, "test_samples_per_second": 164.186, "test_steps_per_second": 20.523}, {"test_loss": 0.11341378092765808, "test_micro_f1": 0.6097646645591851, "test_micro_f1_no_misc": 0.6477181745396318, "test_runtime": 11.6434, "test_samples_per_second": 175.893, "test_steps_per_second": 21.987}, {"test_loss": 0.11872245371341705, "test_micro_f1": 0.5902657921988264, "test_micro_f1_no_misc": 0.6416161616161615, "test_runtime": 13.2128, "test_samples_per_second": 155.001, "test_steps_per_second": 19.375}, {"test_loss": 0.11188437044620514, "test_micro_f1": 0.6039567002612916, "test_micro_f1_no_misc": 0.6541666666666667, "test_runtime": 13.2855, "test_samples_per_second": 154.153, "test_steps_per_second": 19.269}, {"test_loss": 0.11563339829444885, "test_micro_f1": 0.5565642458100559, "test_micro_f1_no_misc": 0.6022099447513812, "test_runtime": 11.0277, "test_samples_per_second": 185.713, "test_steps_per_second": 23.214}, {"test_loss": 0.11600017547607422, "test_micro_f1": 0.5175879396984926, "test_micro_f1_no_misc": 0.5607701564380264, "test_runtime": 11.1961, "test_samples_per_second": 182.92, "test_steps_per_second": 22.865}, {"test_loss": 0.1187957376241684, "test_micro_f1": 0.5676500508646999, "test_micro_f1_no_misc": 0.6135209066041423, "test_runtime": 13.3961, "test_samples_per_second": 152.88, "test_steps_per_second": 19.11}, {"test_loss": 0.10461202263832092, "test_micro_f1": 0.6093023255813953, "test_micro_f1_no_misc": 0.6449934980494149, "test_runtime": 14.6556, "test_samples_per_second": 139.742, "test_steps_per_second": 17.468}, {"test_loss": 0.10332447290420532, "test_micro_f1": 0.5751765893037335, "test_micro_f1_no_misc": 0.6198565496413742, "test_runtime": 13.337, "test_samples_per_second": 153.558, "test_steps_per_second": 19.195}]}, "total": {"test_micro_f1": 57.515956137897305, "test_micro_f1_se": 1.8051039059888623, "test_micro_f1_no_misc": 61.95211516188248, "test_micro_f1_no_misc_se": 1.7711699965171115}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.1540115475654602, "test_micro_f1": 0.8405134517320205, "test_micro_f1_no_misc": 0.8405134517320205, "test_runtime": 6.6327, "test_samples_per_second": 308.775, "test_steps_per_second": 9.649}, {"test_loss": 0.1530567705631256, "test_micro_f1": 0.829346092503987, "test_micro_f1_no_misc": 0.829346092503987, "test_runtime": 6.4953, "test_samples_per_second": 315.305, "test_steps_per_second": 9.853}, {"test_loss": 0.15891319513320923, "test_micro_f1": 0.8307093578630815, "test_micro_f1_no_misc": 0.8307093578630815, "test_runtime": 6.4917, "test_samples_per_second": 315.478, "test_steps_per_second": 9.859}, {"test_loss": 0.16507285833358765, "test_micro_f1": 0.8279085872576177, "test_micro_f1_no_misc": 0.8279085872576177, "test_runtime": 6.3746, "test_samples_per_second": 321.276, "test_steps_per_second": 10.04}, {"test_loss": 0.16092801094055176, "test_micro_f1": 0.8314993122420908, "test_micro_f1_no_misc": 0.8314993122420908, "test_runtime": 6.6809, "test_samples_per_second": 306.545, "test_steps_per_second": 9.58}, {"test_loss": 0.17431777715682983, "test_micro_f1": 0.8206014517801589, "test_micro_f1_no_misc": 0.8206014517801589, "test_runtime": 6.4014, "test_samples_per_second": 319.928, "test_steps_per_second": 9.998}, {"test_loss": 0.15308809280395508, "test_micro_f1": 0.8307161345987921, "test_micro_f1_no_misc": 0.8307161345987921, "test_runtime": 6.6071, "test_samples_per_second": 309.969, "test_steps_per_second": 9.687}, {"test_loss": 0.17688827216625214, "test_micro_f1": 0.826956826956827, "test_micro_f1_no_misc": 0.826956826956827, "test_runtime": 6.5233, "test_samples_per_second": 313.95, "test_steps_per_second": 9.811}, {"test_loss": 0.1619585156440735, "test_micro_f1": 0.8443661971830986, "test_micro_f1_no_misc": 0.8443661971830986, "test_runtime": 7.0026, "test_samples_per_second": 292.465, "test_steps_per_second": 9.14}, {"test_loss": 0.16938118636608124, "test_micro_f1": 0.8295702840495266, "test_micro_f1_no_misc": 0.8295702840495266, "test_runtime": 6.6732, "test_samples_per_second": 306.901, "test_steps_per_second": 9.591}]}, "total": {"test_micro_f1": 83.121876961672, "test_micro_f1_se": 0.417269908374432, "test_micro_f1_no_misc": 83.121876961672, "test_micro_f1_no_misc_se": 0.417269908374432}}, "num_model_parameters": 177269769, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6933400630950928, "test_mcc": 0.01647487572910602, "test_macro_f1": 0.4828107237906938, "test_runtime": 8.2316, "test_samples_per_second": 248.797, "test_steps_per_second": 31.1}, {"test_loss": 0.6931626796722412, "test_mcc": 0.0023884396526924257, "test_macro_f1": 0.36471573676483443, "test_runtime": 8.2309, "test_samples_per_second": 248.819, "test_steps_per_second": 31.102}, {"test_loss": 0.6930271983146667, "test_mcc": 0.03281811219732135, "test_macro_f1": 0.4392683691138141, "test_runtime": 8.5596, "test_samples_per_second": 239.264, "test_steps_per_second": 29.908}, {"test_loss": 0.6934463977813721, "test_mcc": 0.004249904468357468, "test_macro_f1": 0.4981047258595438, "test_runtime": 8.193, "test_samples_per_second": 249.971, "test_steps_per_second": 31.246}, {"test_loss": 0.6922677755355835, "test_mcc": 0.02973836886092199, "test_macro_f1": 0.3457778599664888, "test_runtime": 8.3037, "test_samples_per_second": 246.636, "test_steps_per_second": 30.83}, {"test_loss": 0.6927660703659058, "test_mcc": 0.048842832843301744, "test_macro_f1": 0.40244258263515487, "test_runtime": 8.0681, "test_samples_per_second": 253.84, "test_steps_per_second": 31.73}, {"test_loss": 0.6925914287567139, "test_mcc": 0.002684664650238046, "test_macro_f1": 0.4725646031100146, "test_runtime": 8.2002, "test_samples_per_second": 249.75, "test_steps_per_second": 31.219}, {"test_loss": 0.692852258682251, "test_mcc": 0.018031273769949764, "test_macro_f1": 0.4765359282778622, "test_runtime": 8.1745, "test_samples_per_second": 250.536, "test_steps_per_second": 31.317}, {"test_loss": 0.6931415796279907, "test_mcc": 0.015918135538328312, "test_macro_f1": 0.5034723320252794, "test_runtime": 8.3554, "test_samples_per_second": 245.11, "test_steps_per_second": 30.639}, {"test_loss": 0.6933414936065674, "test_mcc": 0.06882430988453461, "test_macro_f1": 0.36361240584498594, "test_runtime": 8.3826, "test_samples_per_second": 244.316, "test_steps_per_second": 30.539}]}, "total": {"test_mcc": 2.399709175947517, "test_mcc_se": 1.3399087887490821, "test_macro_f1": 43.49305267388672, "test_macro_f1_se": 3.7626372177486775}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "DeepPavlov/rubert-base-cased", "results": {"raw": {"test": [{"test_loss": 0.6903948783874512, "test_mcc": 0.051099505134201015, "test_macro_f1": 0.48897305851641265, "test_runtime": 3.533, "test_samples_per_second": 289.841, "test_steps_per_second": 9.058}, {"test_loss": 0.6912487745285034, "test_mcc": -0.005027368191086329, "test_macro_f1": 0.4966470937015856, "test_runtime": 3.2928, "test_samples_per_second": 310.985, "test_steps_per_second": 9.718}, {"test_loss": 0.6933062672615051, "test_mcc": -0.014176298493264612, "test_macro_f1": 0.4921568627450981, "test_runtime": 3.2009, "test_samples_per_second": 319.911, "test_steps_per_second": 9.997}, {"test_loss": 0.6790693998336792, "test_mcc": 0.0383361270085558, "test_macro_f1": 0.5191185061030319, "test_runtime": 3.1792, "test_samples_per_second": 322.098, "test_steps_per_second": 10.066}, {"test_loss": 0.6925630569458008, "test_mcc": 0.05261691406116351, "test_macro_f1": 0.4428858663512714, "test_runtime": 3.261, "test_samples_per_second": 314.01, "test_steps_per_second": 9.813}, {"test_loss": 0.6927367448806763, "test_mcc": -0.04879549146561001, "test_macro_f1": 0.3330648569368832, "test_runtime": 3.1348, "test_samples_per_second": 326.656, "test_steps_per_second": 10.208}, {"test_loss": 0.6855273246765137, "test_mcc": 0.11765961575461434, "test_macro_f1": 0.5212716222533894, "test_runtime": 3.2424, "test_samples_per_second": 315.817, "test_steps_per_second": 9.869}, {"test_loss": 0.6931444406509399, "test_mcc": 0.05819236129142144, "test_macro_f1": 0.5132369474743093, "test_runtime": 3.3266, "test_samples_per_second": 307.825, "test_steps_per_second": 9.62}, {"test_loss": 0.6938548684120178, "test_mcc": 0.017738963383086778, "test_macro_f1": 0.46858450474011115, "test_runtime": 3.4007, "test_samples_per_second": 301.111, "test_steps_per_second": 9.41}, {"test_loss": 0.6901257038116455, "test_mcc": 0.053262991515739315, "test_macro_f1": 0.5213572623925212, "test_runtime": 3.2665, "test_samples_per_second": 313.487, "test_steps_per_second": 9.796}]}, "total": {"test_mcc": 3.2090731999882127, "test_mcc_se": 2.8880143075396254, "test_macro_f1": 47.972965812146136, "test_macro_f1_se": 3.5575863265678374}}, "num_model_parameters": 177854978, "max_sequence_length": 512, "vocabulary_size": 119547}
{"dataset": "mim-gold-ner", "task": "named-entity-recognition", "dataset_languages": ["is"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.22842136025428772, "test_micro_f1": 0.1518987341772152, "test_micro_f1_no_misc": 0.1715399610136452, "test_runtime": 14.7434, "test_samples_per_second": 138.91, "test_steps_per_second": 17.364}, {"test_loss": 0.23797255754470825, "test_micro_f1": 0.14555555555555558, "test_micro_f1_no_misc": 0.1634435433562071, "test_runtime": 13.09, "test_samples_per_second": 156.455, "test_steps_per_second": 19.557}, {"test_loss": 0.23949816823005676, "test_micro_f1": 0.2451669595782074, "test_micro_f1_no_misc": 0.26884920634920634, "test_runtime": 12.2692, "test_samples_per_second": 166.922, "test_steps_per_second": 20.865}, {"test_loss": 0.24819470942020416, "test_micro_f1": 0.1651376146788991, "test_micro_f1_no_misc": 0.18304668304668303, "test_runtime": 13.3002, "test_samples_per_second": 153.982, "test_steps_per_second": 19.248}, {"test_loss": 0.23146933317184448, "test_micro_f1": 0.25140186915887847, "test_micro_f1_no_misc": 0.27589852008456656, "test_runtime": 14.0285, "test_samples_per_second": 145.988, "test_steps_per_second": 18.249}, {"test_loss": 0.24850165843963623, "test_micro_f1": 0.212, "test_micro_f1_no_misc": 0.23110720562390158, "test_runtime": 11.2721, "test_samples_per_second": 181.687, "test_steps_per_second": 22.711}, {"test_loss": 0.23719866573810577, "test_micro_f1": 0.24727838258164853, "test_micro_f1_no_misc": 0.2670835194283162, "test_runtime": 11.3771, "test_samples_per_second": 180.01, "test_steps_per_second": 22.501}, {"test_loss": 0.23950859904289246, "test_micro_f1": 0.2621722846441948, "test_micro_f1_no_misc": 0.28942486085343233, "test_runtime": 14.0951, "test_samples_per_second": 145.299, "test_steps_per_second": 18.162}, {"test_loss": 0.221495121717453, "test_micro_f1": 0.12812299807815503, "test_micro_f1_no_misc": 0.14652014652014653, "test_runtime": 14.8022, "test_samples_per_second": 138.358, "test_steps_per_second": 17.295}, {"test_loss": 0.2349821925163269, "test_micro_f1": 0.2330827067669173, "test_micro_f1_no_misc": 0.2541589648798521, "test_runtime": 13.9772, "test_samples_per_second": 146.525, "test_steps_per_second": 18.316}]}, "total": {"test_micro_f1": 20.418171052196715, "test_micro_f1_se": 3.167559302596064, "test_micro_f1_no_misc": 22.510726111559567, "test_micro_f1_no_misc_se": 3.324225680679877}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "wikiann-fo", "task": "named-entity-recognition", "dataset_languages": ["fo"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.23947873711585999, "test_micro_f1": 0.7214298609857375, "test_micro_f1_no_misc": 0.7214298609857375, "test_runtime": 7.5287, "test_samples_per_second": 272.024, "test_steps_per_second": 8.501}, {"test_loss": 0.2841331958770752, "test_micro_f1": 0.7094631986718318, "test_micro_f1_no_misc": 0.7094631986718318, "test_runtime": 7.3974, "test_samples_per_second": 276.853, "test_steps_per_second": 8.652}, {"test_loss": 0.283719539642334, "test_micro_f1": 0.683686402317581, "test_micro_f1_no_misc": 0.683686402317581, "test_runtime": 7.243, "test_samples_per_second": 282.757, "test_steps_per_second": 8.836}, {"test_loss": 0.27719753980636597, "test_micro_f1": 0.7046089385474861, "test_micro_f1_no_misc": 0.7046089385474861, "test_runtime": 7.3368, "test_samples_per_second": 279.141, "test_steps_per_second": 8.723}, {"test_loss": 0.2677728235721588, "test_micro_f1": 0.695904313156941, "test_micro_f1_no_misc": 0.695904313156941, "test_runtime": 7.3087, "test_samples_per_second": 280.212, "test_steps_per_second": 8.757}, {"test_loss": 0.27306896448135376, "test_micro_f1": 0.7095895077499574, "test_micro_f1_no_misc": 0.7095895077499574, "test_runtime": 7.2832, "test_samples_per_second": 281.194, "test_steps_per_second": 8.787}, {"test_loss": 0.2678290605545044, "test_micro_f1": 0.7160933879878808, "test_micro_f1_no_misc": 0.7160933879878808, "test_runtime": 7.2837, "test_samples_per_second": 281.176, "test_steps_per_second": 8.787}, {"test_loss": 0.2733212113380432, "test_micro_f1": 0.7142348754448399, "test_micro_f1_no_misc": 0.7142348754448399, "test_runtime": 7.2797, "test_samples_per_second": 281.33, "test_steps_per_second": 8.792}, {"test_loss": 0.26875853538513184, "test_micro_f1": 0.7115454216431415, "test_micro_f1_no_misc": 0.7115454216431415, "test_runtime": 7.7868, "test_samples_per_second": 263.01, "test_steps_per_second": 8.219}, {"test_loss": 0.2571530342102051, "test_micro_f1": 0.7041409691629956, "test_micro_f1_no_misc": 0.7041409691629956, "test_runtime": 7.1391, "test_samples_per_second": 286.872, "test_steps_per_second": 8.965}]}, "total": {"test_micro_f1": 70.70696875668393, "test_micro_f1_se": 0.6717488517365668, "test_micro_f1_no_misc": 70.70696875668393, "test_micro_f1_no_misc_se": 0.6717488517365668}}, "num_model_parameters": 110033673, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-is", "task": "linguistic-acceptability", "dataset_languages": ["is"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.6936849355697632, "test_mcc": -0.0023979560260106226, "test_macro_f1": 0.4455252933467498, "test_runtime": 8.2143, "test_samples_per_second": 249.322, "test_steps_per_second": 31.165}, {"test_loss": 0.6935114860534668, "test_mcc": 0.013905384739167335, "test_macro_f1": 0.38751918599035784, "test_runtime": 8.1694, "test_samples_per_second": 250.693, "test_steps_per_second": 31.337}, {"test_loss": 0.6926842331886292, "test_mcc": 0.043067944765880134, "test_macro_f1": 0.5125798490913838, "test_runtime": 8.5809, "test_samples_per_second": 238.669, "test_steps_per_second": 29.834}, {"test_loss": 0.6967350244522095, "test_mcc": 0.008404066718395109, "test_macro_f1": 0.4252491694352159, "test_runtime": 8.1753, "test_samples_per_second": 250.511, "test_steps_per_second": 31.314}, {"test_loss": 0.6941392421722412, "test_mcc": -0.00839409429594078, "test_macro_f1": 0.49245570976801156, "test_runtime": 8.3383, "test_samples_per_second": 245.614, "test_steps_per_second": 30.702}, {"test_loss": 0.6924037933349609, "test_mcc": 0.0002279172838787775, "test_macro_f1": 0.4006697858693883, "test_runtime": 8.1117, "test_samples_per_second": 252.476, "test_steps_per_second": 31.56}, {"test_loss": 0.695480227470398, "test_mcc": 0.001683546353441171, "test_macro_f1": 0.3861799121792867, "test_runtime": 8.2282, "test_samples_per_second": 248.9, "test_steps_per_second": 31.112}, {"test_loss": 0.6930854916572571, "test_mcc": 0.007785485405047528, "test_macro_f1": 0.49006962174862917, "test_runtime": 8.1813, "test_samples_per_second": 250.327, "test_steps_per_second": 31.291}, {"test_loss": 0.6994599103927612, "test_mcc": -0.008689004417909287, "test_macro_f1": 0.34028439927225124, "test_runtime": 8.386, "test_samples_per_second": 244.216, "test_steps_per_second": 30.527}, {"test_loss": 0.694567084312439, "test_mcc": -0.03295667515155899, "test_macro_f1": 0.4414559255157332, "test_runtime": 8.4248, "test_samples_per_second": 243.092, "test_steps_per_second": 30.387}]}, "total": {"test_mcc": 0.22636615374390365, "test_mcc_se": 1.1991731062624393, "test_macro_f1": 43.21988852217007, "test_macro_f1_se": 3.414188301776391}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "scala-fo", "task": "linguistic-acceptability", "dataset_languages": ["fo"], "model": "asafaya/bert-base-arabic", "results": {"raw": {"test": [{"test_loss": 0.6916399002075195, "test_mcc": 0.04320406801074533, "test_macro_f1": 0.5194955498405436, "test_runtime": 3.805, "test_samples_per_second": 269.119, "test_steps_per_second": 8.41}, {"test_loss": 0.6963785886764526, "test_mcc": -0.06724688912996718, "test_macro_f1": 0.4637223671629887, "test_runtime": 3.5075, "test_samples_per_second": 291.946, "test_steps_per_second": 9.123}, {"test_loss": 0.6948316693305969, "test_mcc": 0.015320240428380053, "test_macro_f1": 0.500018779342723, "test_runtime": 3.3952, "test_samples_per_second": 301.603, "test_steps_per_second": 9.425}, {"test_loss": 0.6940177083015442, "test_mcc": -0.055259845871495385, "test_macro_f1": 0.4536353137560454, "test_runtime": 3.3613, "test_samples_per_second": 304.64, "test_steps_per_second": 9.52}, {"test_loss": 0.6939805746078491, "test_mcc": -0.0038380482078297696, "test_macro_f1": 0.3532434722172901, "test_runtime": 3.4757, "test_samples_per_second": 294.618, "test_steps_per_second": 9.207}, {"test_loss": 0.6940566897392273, "test_mcc": 0.04510583724771185, "test_macro_f1": 0.5184705519580635, "test_runtime": 3.328, "test_samples_per_second": 307.689, "test_steps_per_second": 9.615}, {"test_loss": 0.693248987197876, "test_mcc": 0.036163379589267186, "test_macro_f1": 0.4878841642752527, "test_runtime": 3.3939, "test_samples_per_second": 301.714, "test_steps_per_second": 9.429}, {"test_loss": 0.6969266533851624, "test_mcc": 0.0, "test_macro_f1": 0.330718954248366, "test_runtime": 3.684, "test_samples_per_second": 277.961, "test_steps_per_second": 8.686}, {"test_loss": 0.6963832974433899, "test_mcc": -0.03195867590428065, "test_macro_f1": 0.4838709677419355, "test_runtime": 3.5985, "test_samples_per_second": 284.563, "test_steps_per_second": 8.893}, {"test_loss": 0.6938010454177856, "test_mcc": 0.012993691300934553, "test_macro_f1": 0.43521594684385384, "test_runtime": 3.4491, "test_samples_per_second": 296.887, "test_steps_per_second": 9.278}]}, "total": {"test_mcc": -0.055162425365340266, "test_mcc_se": 2.463794687813894, "test_macro_f1": 45.46276067387061, "test_macro_f1_se": 4.048448507738589}}, "num_model_parameters": 110618882, "max_sequence_length": 512, "vocabulary_size": 32000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.5366963148117065, "test_mcc": 0.6790075681053048, "test_macro_f1": 0.6792015302641247, "test_runtime": 16.7369, "test_samples_per_second": 122.364, "test_steps_per_second": 15.296, "epoch": 9.38}, {"test_loss": 0.5886090397834778, "test_mcc": 0.6600034021601879, "test_macro_f1": 0.6484433366700538, "test_runtime": 16.0605, "test_samples_per_second": 127.518, "test_steps_per_second": 15.94, "epoch": 8.44}, {"test_loss": 0.6290489435195923, "test_mcc": 0.5982009594078681, "test_macro_f1": 0.545074811233906, "test_runtime": 16.2895, "test_samples_per_second": 125.725, "test_steps_per_second": 15.716, "epoch": 6.56}, {"test_loss": 0.5492852926254272, "test_mcc": 0.6534076053254703, "test_macro_f1": 0.614565656212085, "test_runtime": 16.0562, "test_samples_per_second": 127.552, "test_steps_per_second": 15.944, "epoch": 7.5}, {"test_loss": 0.5317858457565308, "test_mcc": 0.6875077787151657, "test_macro_f1": 0.6439339188273351, "test_runtime": 15.9145, "test_samples_per_second": 128.688, "test_steps_per_second": 16.086, "epoch": 7.5}, {"test_loss": 0.5646153688430786, "test_mcc": 0.6269866907830124, "test_macro_f1": 0.5549774164408311, "test_runtime": 16.3013, "test_samples_per_second": 125.634, "test_steps_per_second": 15.704, "epoch": 6.56}, {"test_loss": 0.5622410774230957, "test_mcc": 0.6316619496009314, "test_macro_f1": 0.5572484670796488, "test_runtime": 15.8255, "test_samples_per_second": 129.411, "test_steps_per_second": 16.176, "epoch": 6.56}, {"test_loss": 0.5517137050628662, "test_mcc": 0.6393602612314934, "test_macro_f1": 0.6111792626802007, "test_runtime": 16.7498, "test_samples_per_second": 122.27, "test_steps_per_second": 15.284, "epoch": 7.5}, {"test_loss": 0.5802503824234009, "test_mcc": 0.6399456385780319, "test_macro_f1": 0.566077006259488, "test_runtime": 16.6259, "test_samples_per_second": 123.181, "test_steps_per_second": 15.398, "epoch": 7.5}, {"test_loss": 0.5248724222183228, "test_mcc": 0.66375836483367, "test_macro_f1": 0.5892065144928734, "test_runtime": 16.2514, "test_samples_per_second": 126.02, "test_steps_per_second": 15.752, "epoch": 7.5}]}, "total": {"test_mcc": 64.79840218741137, "test_mcc_se": 1.636196937553846, "test_macro_f1": 60.09907920160546, "test_macro_f1_se": 2.8490066494658555}}, "num_model_parameters": 109083651, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.9312211275100708, "test_mcc": 0.4145626293721301, "test_macro_f1": 0.6096921849566869, "test_runtime": 4.1737, "test_samples_per_second": 490.689, "test_steps_per_second": 15.334, "epoch": 7.5}, {"test_loss": 0.9563318490982056, "test_mcc": 0.42041162258791986, "test_macro_f1": 0.6109007912111174, "test_runtime": 4.1612, "test_samples_per_second": 492.162, "test_steps_per_second": 15.38, "epoch": 9.38}, {"test_loss": 0.9657158851623535, "test_mcc": 0.34980147822035584, "test_macro_f1": 0.5635163853372066, "test_runtime": 4.1523, "test_samples_per_second": 493.219, "test_steps_per_second": 15.413, "epoch": 6.56}, {"test_loss": 0.9822458624839783, "test_mcc": 0.3002789826301579, "test_macro_f1": 0.41942181080878127, "test_runtime": 4.1568, "test_samples_per_second": 492.691, "test_steps_per_second": 15.397, "epoch": 7.5}, {"test_loss": 0.9298093318939209, "test_mcc": 0.33605335416651466, "test_macro_f1": 0.5059653367364007, "test_runtime": 4.1209, "test_samples_per_second": 496.983, "test_steps_per_second": 15.531, "epoch": 6.56}, {"test_loss": 1.0405144691467285, "test_mcc": 0.34248524407633435, "test_macro_f1": 0.5544597905910882, "test_runtime": 4.1813, "test_samples_per_second": 489.794, "test_steps_per_second": 15.306, "epoch": 7.5}, {"test_loss": 0.9607250690460205, "test_mcc": 0.40996446289469207, "test_macro_f1": 0.6052192763538349, "test_runtime": 4.1399, "test_samples_per_second": 494.696, "test_steps_per_second": 15.459, "epoch": 8.44}, {"test_loss": 0.9740879535675049, "test_mcc": 0.38084128883740964, "test_macro_f1": 0.5885281040341649, "test_runtime": 4.1399, "test_samples_per_second": 494.697, "test_steps_per_second": 15.459, "epoch": 8.44}, {"test_loss": 0.9822030067443848, "test_mcc": 0.3712122837604183, "test_macro_f1": 0.5785032790688954, "test_runtime": 4.1662, "test_samples_per_second": 491.572, "test_steps_per_second": 15.362, "epoch": 8.44}, {"test_loss": 0.9990576505661011, "test_mcc": 0.3733570088916837, "test_macro_f1": 0.5841677587739734, "test_runtime": 4.1192, "test_samples_per_second": 497.183, "test_steps_per_second": 15.537, "epoch": 9.38}]}, "total": {"test_mcc": 36.989683554376164, "test_mcc_se": 2.394528726311113, "test_macro_f1": 56.2037471787215, "test_macro_f1_se": 3.6685006683194024}}, "num_model_parameters": 109083651, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.7461754679679871, "test_mcc": 0.5226454088584553, "test_macro_f1": 0.6384270053059203, "test_runtime": 3.1282, "test_samples_per_second": 654.683, "test_steps_per_second": 20.459, "epoch": 6.56}, {"test_loss": 0.707892656326294, "test_mcc": 0.5553350315502357, "test_macro_f1": 0.7048070282686978, "test_runtime": 2.9763, "test_samples_per_second": 688.094, "test_steps_per_second": 21.503, "epoch": 6.56}, {"test_loss": 0.7150896191596985, "test_mcc": 0.5925706856864608, "test_macro_f1": 0.7137406600162733, "test_runtime": 3.0322, "test_samples_per_second": 675.424, "test_steps_per_second": 21.107, "epoch": 7.5}, {"test_loss": 0.7113965749740601, "test_mcc": 0.5679553989953051, "test_macro_f1": 0.6924056935433581, "test_runtime": 3.0192, "test_samples_per_second": 678.33, "test_steps_per_second": 21.198, "epoch": 6.56}, {"test_loss": 0.6915885210037231, "test_mcc": 0.5825796481599658, "test_macro_f1": 0.7185272114024087, "test_runtime": 3.0829, "test_samples_per_second": 664.315, "test_steps_per_second": 20.76, "epoch": 6.56}, {"test_loss": 0.7174226641654968, "test_mcc": 0.5729178954820175, "test_macro_f1": 0.6983429146769663, "test_runtime": 3.1488, "test_samples_per_second": 650.412, "test_steps_per_second": 20.325, "epoch": 6.56}, {"test_loss": 0.7438719272613525, "test_mcc": 0.5711094398494273, "test_macro_f1": 0.6966473993958874, "test_runtime": 3.033, "test_samples_per_second": 675.228, "test_steps_per_second": 21.101, "epoch": 8.44}, {"test_loss": 0.7105841636657715, "test_mcc": 0.5724436347165863, "test_macro_f1": 0.7101018742177664, "test_runtime": 3.1347, "test_samples_per_second": 653.342, "test_steps_per_second": 20.417, "epoch": 7.5}, {"test_loss": 0.7153247594833374, "test_mcc": 0.5621058279858947, "test_macro_f1": 0.7054765400584522, "test_runtime": 3.1668, "test_samples_per_second": 646.715, "test_steps_per_second": 20.21, "epoch": 7.5}, {"test_loss": 0.6844514012336731, "test_mcc": 0.5635640434986481, "test_macro_f1": 0.7017067669550808, "test_runtime": 3.1026, "test_samples_per_second": 660.098, "test_steps_per_second": 20.628, "epoch": 6.56}]}, "total": {"test_mcc": 56.63227014782996, "test_mcc_se": 1.152834938013808, "test_macro_f1": 69.8018309384081, "test_macro_f1_se": 1.3880444960934164}}, "num_model_parameters": 109083651, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.11086997389793396, "test_micro_f1": 0.3568605307735742, "test_micro_f1_no_misc": 0.3841945288753799, "test_runtime": 8.074, "test_samples_per_second": 253.654, "test_steps_per_second": 7.927, "epoch": 8.44}, {"test_loss": 0.09859219193458557, "test_micro_f1": 0.43240159726183686, "test_micro_f1_no_misc": 0.4610705596107056, "test_runtime": 7.4666, "test_samples_per_second": 274.287, "test_steps_per_second": 8.571, "epoch": 9.38}, {"test_loss": 0.10179083794355392, "test_micro_f1": 0.39395518499218346, "test_micro_f1_no_misc": 0.41470104223806914, "test_runtime": 7.4776, "test_samples_per_second": 273.886, "test_steps_per_second": 8.559, "epoch": 11.25}, {"test_loss": 0.09890047460794449, "test_micro_f1": 0.4065643197458973, "test_micro_f1_no_misc": 0.42953020134228187, "test_runtime": 7.5393, "test_samples_per_second": 271.645, "test_steps_per_second": 8.489, "epoch": 8.44}, {"test_loss": 0.11581231653690338, "test_micro_f1": 0.3323013415892672, "test_micro_f1_no_misc": 0.35152838427947597, "test_runtime": 7.9279, "test_samples_per_second": 258.329, "test_steps_per_second": 8.073, "epoch": 8.44}, {"test_loss": 0.1077875867486, "test_micro_f1": 0.41231069858329267, "test_micro_f1_no_misc": 0.44211629125196444, "test_runtime": 6.5345, "test_samples_per_second": 313.413, "test_steps_per_second": 9.794, "epoch": 10.31}, {"test_loss": 0.11586855351924896, "test_micro_f1": 0.42936148818501757, "test_micro_f1_no_misc": 0.45570971184631803, "test_runtime": 6.8299, "test_samples_per_second": 299.859, "test_steps_per_second": 9.371, "epoch": 10.31}, {"test_loss": 0.09676189720630646, "test_micro_f1": 0.37919075144508674, "test_micro_f1_no_misc": 0.4017146356399266, "test_runtime": 8.0054, "test_samples_per_second": 255.827, "test_steps_per_second": 7.995, "epoch": 8.44}, {"test_loss": 0.10089365392923355, "test_micro_f1": 0.40647118301314467, "test_micro_f1_no_misc": 0.42971672902191344, "test_runtime": 7.5171, "test_samples_per_second": 272.447, "test_steps_per_second": 8.514, "epoch": 9.38}, {"test_loss": 0.10384225845336914, "test_micro_f1": 0.4024452368823229, "test_micro_f1_no_misc": 0.4265658747300216, "test_runtime": 7.5833, "test_samples_per_second": 270.068, "test_steps_per_second": 8.44, "epoch": 12.19}]}, "total": {"test_micro_f1": 39.51862332471624, "test_micro_f1_se": 1.942106577381262, "test_micro_f1_no_misc": 41.968479588360566, "test_micro_f1_no_misc_se": 2.067187229692546}}, "num_model_parameters": 108497673, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.13530650734901428, "test_micro_f1": 0.5481325618095739, "test_micro_f1_no_misc": 0.5133426966292135, "test_runtime": 7.6269, "test_samples_per_second": 268.524, "test_steps_per_second": 8.391, "epoch": 14.06}, {"test_loss": 0.12872928380966187, "test_micro_f1": 0.49472784269022513, "test_micro_f1_no_misc": 0.4627563871896365, "test_runtime": 6.5193, "test_samples_per_second": 314.145, "test_steps_per_second": 9.817, "epoch": 11.25}, {"test_loss": 0.13289451599121094, "test_micro_f1": 0.5529028757460662, "test_micro_f1_no_misc": 0.5184389545291801, "test_runtime": 7.3396, "test_samples_per_second": 279.034, "test_steps_per_second": 8.72, "epoch": 14.06}, {"test_loss": 0.12664471566677094, "test_micro_f1": 0.5709033613445379, "test_micro_f1_no_misc": 0.5236925236925237, "test_runtime": 7.1495, "test_samples_per_second": 286.452, "test_steps_per_second": 8.952, "epoch": 14.06}, {"test_loss": 0.12804770469665527, "test_micro_f1": 0.5413234876455553, "test_micro_f1_no_misc": 0.5052710843373494, "test_runtime": 7.6357, "test_samples_per_second": 268.212, "test_steps_per_second": 8.382, "epoch": 12.19}, {"test_loss": 0.13135845959186554, "test_micro_f1": 0.5417965429300086, "test_micro_f1_no_misc": 0.494876660341556, "test_runtime": 7.3655, "test_samples_per_second": 278.053, "test_steps_per_second": 8.689, "epoch": 11.25}, {"test_loss": 0.12365321069955826, "test_micro_f1": 0.538815255612659, "test_micro_f1_no_misc": 0.4895397489539749, "test_runtime": 7.6919, "test_samples_per_second": 266.255, "test_steps_per_second": 8.32, "epoch": 10.31}, {"test_loss": 0.12257050722837448, "test_micro_f1": 0.5389425810119386, "test_micro_f1_no_misc": 0.5042016806722688, "test_runtime": 7.5035, "test_samples_per_second": 272.941, "test_steps_per_second": 8.529, "epoch": 11.25}, {"test_loss": 0.12615634500980377, "test_micro_f1": 0.5200531208499336, "test_micro_f1_no_misc": 0.4740213523131672, "test_runtime": 7.124, "test_samples_per_second": 287.478, "test_steps_per_second": 8.984, "epoch": 10.31}, {"test_loss": 0.1350708305835724, "test_micro_f1": 0.507717750826902, "test_micro_f1_no_misc": 0.4565217391304348, "test_runtime": 6.8473, "test_samples_per_second": 299.097, "test_steps_per_second": 9.347, "epoch": 12.19}]}, "total": {"test_micro_f1": 53.553153804674004, "test_micro_f1_se": 1.3836266974507359, "test_micro_f1_no_misc": 49.426628277893045, "test_micro_f1_no_misc_se": 1.4438582495047507}}, "num_model_parameters": 108497673, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.09982860088348389, "test_micro_f1": 0.48943918426802624, "test_micro_f1_no_misc": 0.5014504765851637, "test_runtime": 5.4881, "test_samples_per_second": 373.174, "test_steps_per_second": 11.662, "epoch": 11.25}, {"test_loss": 0.09968066215515137, "test_micro_f1": 0.4905247813411079, "test_micro_f1_no_misc": 0.4898969072164949, "test_runtime": 5.4939, "test_samples_per_second": 372.775, "test_steps_per_second": 11.649, "epoch": 10.31}, {"test_loss": 0.10969232022762299, "test_micro_f1": 0.5148995148995149, "test_micro_f1_no_misc": 0.5266362252663622, "test_runtime": 5.0517, "test_samples_per_second": 405.404, "test_steps_per_second": 12.669, "epoch": 13.12}, {"test_loss": 0.09900306165218353, "test_micro_f1": 0.6033783783783784, "test_micro_f1_no_misc": 0.6100299401197604, "test_runtime": 5.0035, "test_samples_per_second": 409.314, "test_steps_per_second": 12.791, "epoch": 14.06}, {"test_loss": 0.09951174259185791, "test_micro_f1": 0.5987674343172235, "test_micro_f1_no_misc": 0.6107091172214183, "test_runtime": 5.565, "test_samples_per_second": 368.015, "test_steps_per_second": 11.5, "epoch": 15.0}, {"test_loss": 0.10720635950565338, "test_micro_f1": 0.45430463576158936, "test_micro_f1_no_misc": 0.4686346863468635, "test_runtime": 5.5274, "test_samples_per_second": 370.518, "test_steps_per_second": 11.579, "epoch": 11.25}, {"test_loss": 0.11062497645616531, "test_micro_f1": 0.4940495336120939, "test_micro_f1_no_misc": 0.5033580770590314, "test_runtime": 4.9892, "test_samples_per_second": 410.485, "test_steps_per_second": 12.828, "epoch": 10.31}, {"test_loss": 0.09929157793521881, "test_micro_f1": 0.5082242363209132, "test_micro_f1_no_misc": 0.5231884057971015, "test_runtime": 4.9992, "test_samples_per_second": 409.664, "test_steps_per_second": 12.802, "epoch": 9.38}, {"test_loss": 0.0989609956741333, "test_micro_f1": 0.4879432624113475, "test_micro_f1_no_misc": 0.4965404965404966, "test_runtime": 5.0812, "test_samples_per_second": 403.056, "test_steps_per_second": 12.595, "epoch": 10.31}, {"test_loss": 0.11750220507383347, "test_micro_f1": 0.5383338864918686, "test_micro_f1_no_misc": 0.5491624180626365, "test_runtime": 5.5052, "test_samples_per_second": 372.011, "test_steps_per_second": 11.625, "epoch": 14.06}]}, "total": {"test_micro_f1": 51.798648478020645, "test_micro_f1_se": 3.0248860046140287, "test_micro_f1_no_misc": 52.796067502153285, "test_micro_f1_no_misc_se": 3.016705453920542}}, "num_model_parameters": 108497673, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.10939188301563263, "test_micro_f1": 0.4837702871410736, "test_micro_f1_no_misc": 0.5110451697988789, "test_runtime": 5.3227, "test_samples_per_second": 384.765, "test_steps_per_second": 12.024, "epoch": 9.38}, {"test_loss": 0.10835032165050507, "test_micro_f1": 0.4959471630141099, "test_micro_f1_no_misc": 0.5256778309409887, "test_runtime": 5.3911, "test_samples_per_second": 379.884, "test_steps_per_second": 11.871, "epoch": 9.38}, {"test_loss": 0.11595644056797028, "test_micro_f1": 0.4570596797671034, "test_micro_f1_no_misc": 0.48636926889715, "test_runtime": 5.3631, "test_samples_per_second": 381.87, "test_steps_per_second": 11.933, "epoch": 11.25}, {"test_loss": 0.11679600179195404, "test_micro_f1": 0.4916943521594684, "test_micro_f1_no_misc": 0.5246535610699323, "test_runtime": 5.4141, "test_samples_per_second": 378.271, "test_steps_per_second": 11.821, "epoch": 8.44}, {"test_loss": 0.12183396518230438, "test_micro_f1": 0.49281565270559463, "test_micro_f1_no_misc": 0.532892561983471, "test_runtime": 5.3789, "test_samples_per_second": 380.749, "test_steps_per_second": 11.898, "epoch": 11.25}, {"test_loss": 0.12537188827991486, "test_micro_f1": 0.46007151370679383, "test_micro_f1_no_misc": 0.49344838606583574, "test_runtime": 5.3302, "test_samples_per_second": 384.222, "test_steps_per_second": 12.007, "epoch": 10.31}, {"test_loss": 0.10288643836975098, "test_micro_f1": 0.5116843702579665, "test_micro_f1_no_misc": 0.5433451498549791, "test_runtime": 5.408, "test_samples_per_second": 378.697, "test_steps_per_second": 11.834, "epoch": 11.25}, {"test_loss": 0.10352523624897003, "test_micro_f1": 0.5392390011890608, "test_micro_f1_no_misc": 0.5725439167208849, "test_runtime": 5.4486, "test_samples_per_second": 375.873, "test_steps_per_second": 11.746, "epoch": 13.12}, {"test_loss": 0.11290432512760162, "test_micro_f1": 0.5507158087115444, "test_micro_f1_no_misc": 0.5643835616438356, "test_runtime": 5.0876, "test_samples_per_second": 402.546, "test_steps_per_second": 12.58, "epoch": 13.12}, {"test_loss": 0.10625419020652771, "test_micro_f1": 0.578808335779278, "test_micro_f1_no_misc": 0.5962854349951124, "test_runtime": 5.1533, "test_samples_per_second": 397.411, "test_steps_per_second": 12.419, "epoch": 14.06}]}, "total": {"test_micro_f1": 50.61806164431994, "test_micro_f1_se": 2.4371744580332626, "test_micro_f1_no_misc": 53.50644841971069, "test_micro_f1_no_misc_se": 2.1631308545604346}}, "num_model_parameters": 108497673, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.5951162576675415, "test_mcc": 0.3856170685538035, "test_macro_f1": 0.6927356405733633, "test_runtime": 3.7916, "test_samples_per_second": 540.138, "test_steps_per_second": 16.879, "epoch": 7.5}, {"test_loss": 0.6453253030776978, "test_mcc": 0.25731167669671623, "test_macro_f1": 0.6073811426165867, "test_runtime": 4.0115, "test_samples_per_second": 510.535, "test_steps_per_second": 15.954, "epoch": 6.56}, {"test_loss": 0.6039740443229675, "test_mcc": 0.3525098897684958, "test_macro_f1": 0.6762387823038605, "test_runtime": 4.0109, "test_samples_per_second": 510.613, "test_steps_per_second": 15.957, "epoch": 7.5}, {"test_loss": 0.6516032218933105, "test_mcc": 0.3635845448296195, "test_macro_f1": 0.679734442381768, "test_runtime": 3.9858, "test_samples_per_second": 513.83, "test_steps_per_second": 16.057, "epoch": 9.38}, {"test_loss": 0.6431182622909546, "test_mcc": 0.3705584327117414, "test_macro_f1": 0.6800849543276619, "test_runtime": 4.0127, "test_samples_per_second": 510.376, "test_steps_per_second": 15.949, "epoch": 9.38}, {"test_loss": 0.6382583975791931, "test_mcc": 0.3632176257177906, "test_macro_f1": 0.6783103323765165, "test_runtime": 3.9175, "test_samples_per_second": 522.789, "test_steps_per_second": 16.337, "epoch": 8.44}, {"test_loss": 0.6398614645004272, "test_mcc": 0.3703076016813649, "test_macro_f1": 0.6841579553994578, "test_runtime": 3.9564, "test_samples_per_second": 517.642, "test_steps_per_second": 16.176, "epoch": 9.38}, {"test_loss": 0.6177501678466797, "test_mcc": 0.3680078850508581, "test_macro_f1": 0.6828240843815765, "test_runtime": 3.9862, "test_samples_per_second": 513.77, "test_steps_per_second": 16.055, "epoch": 7.5}, {"test_loss": 0.6117832660675049, "test_mcc": 0.3653392386874297, "test_macro_f1": 0.678174561634655, "test_runtime": 3.997, "test_samples_per_second": 512.383, "test_steps_per_second": 16.012, "epoch": 7.5}, {"test_loss": 0.6182987093925476, "test_mcc": 0.3317111363639739, "test_macro_f1": 0.655738465105495, "test_runtime": 3.9993, "test_samples_per_second": 512.085, "test_steps_per_second": 16.003, "epoch": 7.5}]}, "total": {"test_mcc": 35.28165100061793, "test_mcc_se": 2.251397012639689, "test_macro_f1": 67.1538036110094, "test_macro_f1_se": 1.511721355577206}}, "num_model_parameters": 109082882, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.596893846988678, "test_mcc": 0.4209157911940164, "test_macro_f1": 0.6792181581102827, "test_runtime": 3.5965, "test_samples_per_second": 569.445, "test_steps_per_second": 17.795, "epoch": 6.56}, {"test_loss": 0.5708779096603394, "test_mcc": 0.4335874942605837, "test_macro_f1": 0.704661448159777, "test_runtime": 3.8363, "test_samples_per_second": 533.853, "test_steps_per_second": 16.683, "epoch": 6.56}, {"test_loss": 0.5395311713218689, "test_mcc": 0.48565899194563295, "test_macro_f1": 0.7384864010234685, "test_runtime": 3.7298, "test_samples_per_second": 549.086, "test_steps_per_second": 17.159, "epoch": 7.5}, {"test_loss": 0.5442560911178589, "test_mcc": 0.48241540874695926, "test_macro_f1": 0.7347239677380524, "test_runtime": 3.9018, "test_samples_per_second": 524.881, "test_steps_per_second": 16.403, "epoch": 7.5}, {"test_loss": 0.5727405548095703, "test_mcc": 0.4551798033676568, "test_macro_f1": 0.7164171782699211, "test_runtime": 3.656, "test_samples_per_second": 560.179, "test_steps_per_second": 17.506, "epoch": 6.56}, {"test_loss": 0.5818513035774231, "test_mcc": 0.4387574803502308, "test_macro_f1": 0.7099994844241635, "test_runtime": 3.6107, "test_samples_per_second": 567.196, "test_steps_per_second": 17.725, "epoch": 7.5}, {"test_loss": 0.6095736026763916, "test_mcc": 0.40897751240783226, "test_macro_f1": 0.6738904223827062, "test_runtime": 3.5418, "test_samples_per_second": 578.243, "test_steps_per_second": 18.07, "epoch": 7.5}, {"test_loss": 0.5690293312072754, "test_mcc": 0.4360540503578465, "test_macro_f1": 0.7086469504624492, "test_runtime": 3.598, "test_samples_per_second": 569.202, "test_steps_per_second": 17.788, "epoch": 7.5}, {"test_loss": 0.6182857155799866, "test_mcc": 0.34392948657632005, "test_macro_f1": 0.6405385102206818, "test_runtime": 3.5662, "test_samples_per_second": 574.286, "test_steps_per_second": 17.946, "epoch": 5.62}, {"test_loss": 0.591427206993103, "test_mcc": 0.404533562560908, "test_macro_f1": 0.6880584132542913, "test_runtime": 3.7061, "test_samples_per_second": 552.601, "test_steps_per_second": 17.269, "epoch": 6.56}]}, "total": {"test_mcc": 43.100095817679865, "test_mcc_se": 2.5452056719208116, "test_macro_f1": 69.94640934045793, "test_macro_f1_se": 1.8411905400933386}}, "num_model_parameters": 109082882, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.4555000066757202, "test_mcc": 0.6261739101466607, "test_macro_f1": 0.7842568101233467, "test_runtime": 2.8515, "test_samples_per_second": 718.23, "test_steps_per_second": 22.445, "epoch": 5.62}, {"test_loss": 0.4126208424568176, "test_mcc": 0.6851642101351926, "test_macro_f1": 0.8354834292861462, "test_runtime": 2.8459, "test_samples_per_second": 719.635, "test_steps_per_second": 22.489, "epoch": 6.56}, {"test_loss": 0.383364200592041, "test_mcc": 0.6999357319518386, "test_macro_f1": 0.8460457218814247, "test_runtime": 2.8547, "test_samples_per_second": 717.403, "test_steps_per_second": 22.419, "epoch": 6.56}, {"test_loss": 0.38133764266967773, "test_mcc": 0.7017922903821076, "test_macro_f1": 0.847269691068631, "test_runtime": 2.9209, "test_samples_per_second": 701.159, "test_steps_per_second": 21.911, "epoch": 5.62}, {"test_loss": 0.40819644927978516, "test_mcc": 0.6928208979061866, "test_macro_f1": 0.8430782109153739, "test_runtime": 2.8938, "test_samples_per_second": 707.729, "test_steps_per_second": 22.117, "epoch": 8.44}, {"test_loss": 0.42043331265449524, "test_mcc": 0.7177785909758687, "test_macro_f1": 0.8466301664274221, "test_runtime": 2.7929, "test_samples_per_second": 733.292, "test_steps_per_second": 22.915, "epoch": 7.5}, {"test_loss": 0.44249778985977173, "test_mcc": 0.6568500938420204, "test_macro_f1": 0.8171082846285413, "test_runtime": 2.7688, "test_samples_per_second": 739.662, "test_steps_per_second": 23.114, "epoch": 6.56}, {"test_loss": 0.45934006571769714, "test_mcc": 0.6447948683538971, "test_macro_f1": 0.8075575943530806, "test_runtime": 2.833, "test_samples_per_second": 722.9, "test_steps_per_second": 22.591, "epoch": 6.56}, {"test_loss": 0.47037190198898315, "test_mcc": 0.6687957079832814, "test_macro_f1": 0.8238428114981915, "test_runtime": 2.7709, "test_samples_per_second": 739.108, "test_steps_per_second": 23.097, "epoch": 7.5}, {"test_loss": 0.46216413378715515, "test_mcc": 0.6580339183706059, "test_macro_f1": 0.8183094172505943, "test_runtime": 2.8581, "test_samples_per_second": 716.559, "test_steps_per_second": 22.392, "epoch": 7.5}]}, "total": {"test_mcc": 67.5214022004766, "test_mcc_se": 1.7942489182521373, "test_macro_f1": 82.69582137432752, "test_macro_f1_se": 1.2865410453108008}}, "num_model_parameters": 109082882, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_loss": 0.5167158246040344, "test_mcc": 0.5656726993891449, "test_macro_f1": 0.7754983636003465, "test_runtime": 3.1366, "test_samples_per_second": 652.927, "test_steps_per_second": 20.404, "epoch": 7.5}, {"test_loss": 0.4641709327697754, "test_mcc": 0.5598155999365638, "test_macro_f1": 0.7773529554421581, "test_runtime": 3.1733, "test_samples_per_second": 645.393, "test_steps_per_second": 20.169, "epoch": 6.56}, {"test_loss": 0.48851507902145386, "test_mcc": 0.6123550158052052, "test_macro_f1": 0.8036223485365674, "test_runtime": 3.1578, "test_samples_per_second": 648.552, "test_steps_per_second": 20.267, "epoch": 7.5}, {"test_loss": 0.4874229431152344, "test_mcc": 0.5835144544996168, "test_macro_f1": 0.7781033923181546, "test_runtime": 3.1008, "test_samples_per_second": 660.477, "test_steps_per_second": 20.64, "epoch": 6.56}, {"test_loss": 0.4788624346256256, "test_mcc": 0.5940332401360658, "test_macro_f1": 0.7882010901071754, "test_runtime": 3.0879, "test_samples_per_second": 663.24, "test_steps_per_second": 20.726, "epoch": 7.5}, {"test_loss": 0.4873156249523163, "test_mcc": 0.5561176240976131, "test_macro_f1": 0.77013297611387, "test_runtime": 3.223, "test_samples_per_second": 635.426, "test_steps_per_second": 19.857, "epoch": 6.56}, {"test_loss": 0.49599671363830566, "test_mcc": 0.5674117968756884, "test_macro_f1": 0.7807272129367273, "test_runtime": 3.1141, "test_samples_per_second": 657.658, "test_steps_per_second": 20.552, "epoch": 7.5}, {"test_loss": 0.47653087973594666, "test_mcc": 0.5677085057499072, "test_macro_f1": 0.7700807128254217, "test_runtime": 3.1203, "test_samples_per_second": 656.339, "test_steps_per_second": 20.511, "epoch": 6.56}, {"test_loss": 0.4677073359489441, "test_mcc": 0.5767258475180866, "test_macro_f1": 0.783783574362655, "test_runtime": 3.1085, "test_samples_per_second": 658.848, "test_steps_per_second": 20.589, "epoch": 6.56}, {"test_loss": 0.5034085512161255, "test_mcc": 0.5329869887244828, "test_macro_f1": 0.7541769137183035, "test_runtime": 3.1446, "test_samples_per_second": 651.272, "test_steps_per_second": 20.352, "epoch": 5.62}]}, "total": {"test_mcc": 57.163417727323754, "test_mcc_se": 1.350014458370143, "test_macro_f1": 77.81679539961381, "test_macro_f1_se": 0.8001678433535945}}, "num_model_parameters": 109082882, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_em": 26.49109217660728, "test_f1": 30.89401975937462, "epoch": 5.71}, {"test_em": 21.782945736434108, "test_f1": 25.851858276257165, "epoch": 4.76}, {"test_em": 26.120556414219475, "test_f1": 30.45321500576285, "epoch": 7.14}, {"test_em": 25.54517133956386, "test_f1": 29.42352559687972, "epoch": 6.66}, {"test_em": 23.474903474903474, "test_f1": 26.990587363873512, "epoch": 6.66}, {"test_em": 26.522744795682343, "test_f1": 31.374861155603046, "epoch": 6.19}, {"test_em": 18.223234624145785, "test_f1": 21.86334781301991, "epoch": 4.28}, {"test_em": 29.16989914662529, "test_f1": 34.11019047499557, "epoch": 6.66}, {"test_em": 26.03921568627451, "test_f1": 31.973617415947295, "epoch": 7.14}, {"test_em": 20.885093167701864, "test_f1": 25.583415796994622, "epoch": 5.71}]}, "total": {"test_em": 24.425485656215795, "test_em_se": 2.0326405578011926, "test_f1": 28.851863865870833, "test_f1_se": 2.289547691928293}}, "num_model_parameters": 108492290, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_em": 26.56855151045701, "test_f1": 31.338339863703503, "epoch": 6.92}, {"test_em": 30.54263565891473, "test_f1": 35.63890792303566, "epoch": 8.08}, {"test_em": 20.865533230293664, "test_f1": 25.69772084525558, "epoch": 5.19}, {"test_em": 23.67601246105919, "test_f1": 27.71407048279591, "epoch": 6.92}, {"test_em": 22.857142857142858, "test_f1": 27.53928066241979, "epoch": 6.35}, {"test_em": 26.908249807247493, "test_f1": 32.28788714718251, "epoch": 7.5}, {"test_em": 29.23310554290053, "test_f1": 33.797029156997844, "epoch": 7.5}, {"test_em": 25.83397982932506, "test_f1": 29.917978773383002, "epoch": 5.77}, {"test_em": 31.45098039215686, "test_f1": 37.42679808952975, "epoch": 8.08}, {"test_em": 31.133540372670808, "test_f1": 36.989820113305804, "epoch": 8.65}]}, "total": {"test_em": 26.906973166216822, "test_em_se": 2.2796173500908, "test_f1": 31.834783305760936, "test_f1_se": 2.5587644509325687}}, "num_model_parameters": 108492290, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_em": 24.709527498063515, "test_f1": 29.48087922740376, "epoch": 7.09}, {"test_em": 24.88372093023256, "test_f1": 29.371661911587957, "epoch": 7.09}, {"test_em": 21.483771251931994, "test_f1": 26.04192901752225, "epoch": 7.09}, {"test_em": 20.794392523364486, "test_f1": 25.00602884227129, "epoch": 6.0}, {"test_em": 17.83783783783784, "test_f1": 22.020741320800944, "epoch": 6.0}, {"test_em": 21.89668465690054, "test_f1": 26.443795809413306, "epoch": 6.54}, {"test_em": 22.17160212604404, "test_f1": 26.672936400786785, "epoch": 7.09}, {"test_em": 20.636152055857252, "test_f1": 25.261560669983062, "epoch": 6.0}, {"test_em": 24.235294117647058, "test_f1": 29.337605297005524, "epoch": 6.54}, {"test_em": 23.13664596273292, "test_f1": 27.984300761718654, "epoch": 7.09}]}, "total": {"test_em": 22.17856289606122, "test_em_se": 1.3480028993557505, "test_f1": 26.76214392584935, "test_f1_se": 1.4721381311719788}}, "num_model_parameters": 108492290, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "ViktorAlm/electra-base-norwegian-uncased-discriminator", "results": {"raw": {"test": [{"test_speed": 1.97}, {"test_speed": 1.91}, {"test_speed": 1.92}, {"test_speed": 1.99}, {"test_speed": 1.99}, {"test_speed": 1.94}, {"test_speed": 1.97}, {"test_speed": 1.92}, {"test_speed": 1.99}, {"test_speed": 1.91}]}, "total": {"test_speed": 1.9509999999999998, "test_speed_se": 0.021361102759715186}}, "num_model_parameters": 109081344, "max_sequence_length": 512, "vocabulary_size": 30000}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.5673252940177917, "test_mcc": 0.6128009853720933, "test_macro_f1": 0.5632531522796297, "test_runtime": 14.2995, "test_samples_per_second": 143.222, "test_steps_per_second": 17.903, "epoch": 4.69}, {"test_loss": 0.5696067810058594, "test_mcc": 0.616612952144676, "test_macro_f1": 0.5885390136451177, "test_runtime": 13.807, "test_samples_per_second": 148.33, "test_steps_per_second": 18.541, "epoch": 5.62}, {"test_loss": 0.6104450821876526, "test_mcc": 0.6081314272301845, "test_macro_f1": 0.5770065904282605, "test_runtime": 14.2142, "test_samples_per_second": 144.081, "test_steps_per_second": 18.01, "epoch": 5.62}, {"test_loss": 0.5565341711044312, "test_mcc": 0.6180079279977949, "test_macro_f1": 0.5833854220565267, "test_runtime": 13.7523, "test_samples_per_second": 148.921, "test_steps_per_second": 18.615, "epoch": 5.62}, {"test_loss": 0.5502386689186096, "test_mcc": 0.641348340026566, "test_macro_f1": 0.5951765927348216, "test_runtime": 13.4549, "test_samples_per_second": 152.212, "test_steps_per_second": 19.027, "epoch": 5.62}, {"test_loss": 0.5640736818313599, "test_mcc": 0.6146870788877798, "test_macro_f1": 0.5962753189827525, "test_runtime": 13.9053, "test_samples_per_second": 147.282, "test_steps_per_second": 18.41, "epoch": 5.62}, {"test_loss": 0.5732977390289307, "test_mcc": 0.6195837462083842, "test_macro_f1": 0.5554829768654926, "test_runtime": 13.4126, "test_samples_per_second": 152.692, "test_steps_per_second": 19.087, "epoch": 4.69}, {"test_loss": 0.5378319025039673, "test_mcc": 0.6473556691898618, "test_macro_f1": 0.6252764413376677, "test_runtime": 14.5394, "test_samples_per_second": 140.858, "test_steps_per_second": 17.607, "epoch": 5.62}, {"test_loss": 0.6166664361953735, "test_mcc": 0.5820412313393375, "test_macro_f1": 0.5458435865131416, "test_runtime": 14.3603, "test_samples_per_second": 142.615, "test_steps_per_second": 17.827, "epoch": 4.69}, {"test_loss": 0.5421223640441895, "test_mcc": 0.6390821335158517, "test_macro_f1": 0.6379041819053635, "test_runtime": 13.9227, "test_samples_per_second": 147.098, "test_steps_per_second": 18.387, "epoch": 5.62}]}, "total": {"test_mcc": 61.9965149191253, "test_mcc_se": 1.1770154448181862, "test_macro_f1": 58.68143276748774, "test_macro_f1_se": 1.7981809342038757}}, "num_model_parameters": 109484547, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 1.0537476539611816, "test_mcc": 0.2490526717299843, "test_macro_f1": 0.49297092637349177, "test_runtime": 5.1074, "test_samples_per_second": 400.985, "test_steps_per_second": 12.531, "epoch": 5.62}, {"test_loss": 0.9954158067703247, "test_mcc": 0.2831402906381869, "test_macro_f1": 0.493891566621107, "test_runtime": 5.0889, "test_samples_per_second": 402.444, "test_steps_per_second": 12.576, "epoch": 4.69}, {"test_loss": 1.028732419013977, "test_mcc": 0.2878269146316707, "test_macro_f1": 0.5191688031499523, "test_runtime": 5.0405, "test_samples_per_second": 406.308, "test_steps_per_second": 12.697, "epoch": 4.69}, {"test_loss": 1.0115163326263428, "test_mcc": 0.22349860348128758, "test_macro_f1": 0.45336054440150364, "test_runtime": 5.1131, "test_samples_per_second": 400.539, "test_steps_per_second": 12.517, "epoch": 4.69}, {"test_loss": 1.0267796516418457, "test_mcc": 0.25154582259327546, "test_macro_f1": 0.49027214796264956, "test_runtime": 5.039, "test_samples_per_second": 406.427, "test_steps_per_second": 12.701, "epoch": 5.62}, {"test_loss": 1.0512170791625977, "test_mcc": 0.23338961966441943, "test_macro_f1": 0.4721743385431803, "test_runtime": 5.1091, "test_samples_per_second": 400.851, "test_steps_per_second": 12.527, "epoch": 4.69}, {"test_loss": 0.9947637319564819, "test_mcc": 0.2880713736306145, "test_macro_f1": 0.5029123726501964, "test_runtime": 5.0736, "test_samples_per_second": 403.655, "test_steps_per_second": 12.614, "epoch": 4.69}, {"test_loss": 1.0525116920471191, "test_mcc": 0.2492165149951271, "test_macro_f1": 0.45162906529648633, "test_runtime": 5.2028, "test_samples_per_second": 393.637, "test_steps_per_second": 12.301, "epoch": 4.69}, {"test_loss": 0.9908899068832397, "test_mcc": 0.26495535063574704, "test_macro_f1": 0.49589893276826685, "test_runtime": 5.0428, "test_samples_per_second": 406.127, "test_steps_per_second": 12.691, "epoch": 4.69}, {"test_loss": 1.0003652572631836, "test_mcc": 0.2678619926326579, "test_macro_f1": 0.4969396556316535, "test_runtime": 5.143, "test_samples_per_second": 398.212, "test_steps_per_second": 12.444, "epoch": 4.69}]}, "total": {"test_mcc": 25.985591546329704, "test_mcc_se": 1.3908538375971677, "test_macro_f1": 48.692183533984874, "test_macro_f1_se": 1.332917050054489}}, "num_model_parameters": 109484547, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.9353669881820679, "test_mcc": 0.24291961710781518, "test_macro_f1": 0.3967701952753992, "test_runtime": 4.1587, "test_samples_per_second": 492.462, "test_steps_per_second": 15.389, "epoch": 4.69}, {"test_loss": 0.9243040084838867, "test_mcc": 0.25748576018935454, "test_macro_f1": 0.41478521478521474, "test_runtime": 3.9482, "test_samples_per_second": 518.72, "test_steps_per_second": 16.21, "epoch": 4.69}, {"test_loss": 0.9321931600570679, "test_mcc": 0.19721769735768532, "test_macro_f1": 0.37330813147172864, "test_runtime": 3.9609, "test_samples_per_second": 517.056, "test_steps_per_second": 16.158, "epoch": 4.69}, {"test_loss": 0.9180956482887268, "test_mcc": 0.25508558221993116, "test_macro_f1": 0.40736477596206583, "test_runtime": 4.0526, "test_samples_per_second": 505.36, "test_steps_per_second": 15.792, "epoch": 4.69}, {"test_loss": 0.9148104786872864, "test_mcc": 0.2724147683525152, "test_macro_f1": 0.42115218319632747, "test_runtime": 4.043, "test_samples_per_second": 506.549, "test_steps_per_second": 15.83, "epoch": 4.69}, {"test_loss": 0.9285092949867249, "test_mcc": 0.26061937921189543, "test_macro_f1": 0.4175327087081541, "test_runtime": 4.1162, "test_samples_per_second": 497.545, "test_steps_per_second": 15.548, "epoch": 4.69}, {"test_loss": 0.9138267040252686, "test_mcc": 0.26204753714291884, "test_macro_f1": 0.4101010914295939, "test_runtime": 3.9566, "test_samples_per_second": 517.615, "test_steps_per_second": 16.175, "epoch": 4.69}, {"test_loss": 0.9347682595252991, "test_mcc": 0.20888900138957778, "test_macro_f1": 0.3808924366376927, "test_runtime": 4.0577, "test_samples_per_second": 504.714, "test_steps_per_second": 15.772, "epoch": 4.69}, {"test_loss": 0.959931492805481, "test_mcc": 0.24829563493344853, "test_macro_f1": 0.45711896209299957, "test_runtime": 4.1699, "test_samples_per_second": 491.14, "test_steps_per_second": 15.348, "epoch": 5.62}, {"test_loss": 0.9225611686706543, "test_mcc": 0.24351655200634856, "test_macro_f1": 0.40025199824747926, "test_runtime": 4.1366, "test_samples_per_second": 495.095, "test_steps_per_second": 15.472, "epoch": 4.69}]}, "total": {"test_mcc": 24.48491529911491, "test_mcc_se": 1.4823730455909447, "test_macro_f1": 40.792776978066556, "test_macro_f1_se": 1.4390867216893313}}, "num_model_parameters": 109484547, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.09555843472480774, "test_micro_f1": 0.5786802030456853, "test_micro_f1_no_misc": 0.6303405572755418, "test_runtime": 7.1091, "test_samples_per_second": 288.08, "test_steps_per_second": 9.003, "epoch": 5.62}, {"test_loss": 0.09534715861082077, "test_micro_f1": 0.5501400560224089, "test_micro_f1_no_misc": 0.5968331303288673, "test_runtime": 6.5087, "test_samples_per_second": 314.656, "test_steps_per_second": 9.833, "epoch": 5.62}, {"test_loss": 0.09066697210073471, "test_micro_f1": 0.5546311702717692, "test_micro_f1_no_misc": 0.5908278737343657, "test_runtime": 6.5217, "test_samples_per_second": 314.029, "test_steps_per_second": 9.813, "epoch": 5.62}, {"test_loss": 0.09128706157207489, "test_micro_f1": 0.5387634936211971, "test_micro_f1_no_misc": 0.5862628447809626, "test_runtime": 6.9286, "test_samples_per_second": 295.585, "test_steps_per_second": 9.237, "epoch": 5.62}, {"test_loss": 0.09875170886516571, "test_micro_f1": 0.5644900161899623, "test_micro_f1_no_misc": 0.6061663757998836, "test_runtime": 7.0201, "test_samples_per_second": 291.732, "test_steps_per_second": 9.117, "epoch": 5.62}, {"test_loss": 0.09714118391275406, "test_micro_f1": 0.5785900783289818, "test_micro_f1_no_misc": 0.6269005847953216, "test_runtime": 5.7222, "test_samples_per_second": 357.903, "test_steps_per_second": 11.184, "epoch": 5.62}, {"test_loss": 0.09961988031864166, "test_micro_f1": 0.5571187394485088, "test_micro_f1_no_misc": 0.6064356435643564, "test_runtime": 6.2858, "test_samples_per_second": 325.813, "test_steps_per_second": 10.182, "epoch": 5.62}, {"test_loss": 0.08546002954244614, "test_micro_f1": 0.58420085731782, "test_micro_f1_no_misc": 0.6242544731610338, "test_runtime": 6.9615, "test_samples_per_second": 294.191, "test_steps_per_second": 9.193, "epoch": 5.62}, {"test_loss": 0.08829253166913986, "test_micro_f1": 0.5700110253583242, "test_micro_f1_no_misc": 0.6150178784266985, "test_runtime": 6.3401, "test_samples_per_second": 323.025, "test_steps_per_second": 10.095, "epoch": 5.62}, {"test_loss": 0.09165991097688675, "test_micro_f1": 0.6050884955752213, "test_micro_f1_no_misc": 0.6468842729970327, "test_runtime": 6.8118, "test_samples_per_second": 300.656, "test_steps_per_second": 9.395, "epoch": 5.62}]}, "total": {"test_micro_f1": 56.817141351798796, "test_micro_f1_se": 1.1960086214086438, "test_micro_f1_no_misc": 61.29923634864064, "test_micro_f1_no_misc_se": 1.1922993379574778}}, "num_model_parameters": 108898569, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.15321943163871765, "test_micro_f1": 0.5781520931384692, "test_micro_f1_no_misc": 0.5807308970099668, "test_runtime": 9.3512, "test_samples_per_second": 219.008, "test_steps_per_second": 6.844, "epoch": 7.5}, {"test_loss": 0.13643965125083923, "test_micro_f1": 0.5738980121002593, "test_micro_f1_no_misc": 0.5877362128808329, "test_runtime": 7.7614, "test_samples_per_second": 263.87, "test_steps_per_second": 8.246, "epoch": 5.62}, {"test_loss": 0.1426311880350113, "test_micro_f1": 0.5939553219448094, "test_micro_f1_no_misc": 0.5912508544087492, "test_runtime": 9.2699, "test_samples_per_second": 220.931, "test_steps_per_second": 6.904, "epoch": 6.56}, {"test_loss": 0.14056742191314697, "test_micro_f1": 0.6137350012764872, "test_micro_f1_no_misc": 0.623157894736842, "test_runtime": 8.8574, "test_samples_per_second": 231.22, "test_steps_per_second": 7.226, "epoch": 7.5}, {"test_loss": 0.14077268540859222, "test_micro_f1": 0.5873228135865204, "test_micro_f1_no_misc": 0.6046176046176046, "test_runtime": 9.7484, "test_samples_per_second": 210.086, "test_steps_per_second": 6.565, "epoch": 7.5}, {"test_loss": 0.14887389540672302, "test_micro_f1": 0.6018957345971564, "test_micro_f1_no_misc": 0.593625498007968, "test_runtime": 9.3007, "test_samples_per_second": 220.198, "test_steps_per_second": 6.881, "epoch": 6.56}, {"test_loss": 0.1331130564212799, "test_micro_f1": 0.5838779956427016, "test_micro_f1_no_misc": 0.5841620626151013, "test_runtime": 9.7417, "test_samples_per_second": 210.229, "test_steps_per_second": 6.57, "epoch": 7.5}, {"test_loss": 0.1319817155599594, "test_micro_f1": 0.6008510638297873, "test_micro_f1_no_misc": 0.6101179155572461, "test_runtime": 9.3313, "test_samples_per_second": 219.476, "test_steps_per_second": 6.859, "epoch": 6.56}, {"test_loss": 0.13666227459907532, "test_micro_f1": 0.5922194234536804, "test_micro_f1_no_misc": 0.5823076923076922, "test_runtime": 8.9131, "test_samples_per_second": 229.775, "test_steps_per_second": 7.18, "epoch": 6.56}, {"test_loss": 0.13783490657806396, "test_micro_f1": 0.6464940354960721, "test_micro_f1_no_misc": 0.6533589251439539, "test_runtime": 8.3759, "test_samples_per_second": 244.512, "test_steps_per_second": 7.641, "epoch": 6.56}]}, "total": {"test_micro_f1": 59.72401495065943, "test_micro_f1_se": 1.29927064042139, "test_micro_f1_no_misc": 60.11065557285957, "test_micro_f1_no_misc_se": 1.4160389913443994}}, "num_model_parameters": 108898569, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.1272413283586502, "test_micro_f1": 0.5854205607476636, "test_micro_f1_no_misc": 0.6252605252188412, "test_runtime": 7.6164, "test_samples_per_second": 268.895, "test_steps_per_second": 8.403, "epoch": 6.56}, {"test_loss": 0.11534728854894638, "test_micro_f1": 0.5803741886216113, "test_micro_f1_no_misc": 0.6148732862484421, "test_runtime": 7.5599, "test_samples_per_second": 270.903, "test_steps_per_second": 8.466, "epoch": 6.56}, {"test_loss": 0.12604451179504395, "test_micro_f1": 0.5824486907289455, "test_micro_f1_no_misc": 0.6233269598470365, "test_runtime": 7.3297, "test_samples_per_second": 279.412, "test_steps_per_second": 8.732, "epoch": 6.56}, {"test_loss": 0.11691401153802872, "test_micro_f1": 0.5908096280087527, "test_micro_f1_no_misc": 0.626746506986028, "test_runtime": 7.3571, "test_samples_per_second": 278.369, "test_steps_per_second": 8.699, "epoch": 6.56}, {"test_loss": 0.12485162913799286, "test_micro_f1": 0.5929144385026739, "test_micro_f1_no_misc": 0.6207650273224042, "test_runtime": 7.6076, "test_samples_per_second": 269.204, "test_steps_per_second": 8.413, "epoch": 6.56}, {"test_loss": 0.11993865668773651, "test_micro_f1": 0.6094695621217516, "test_micro_f1_no_misc": 0.6451361867704282, "test_runtime": 7.5922, "test_samples_per_second": 269.752, "test_steps_per_second": 8.43, "epoch": 6.56}, {"test_loss": 0.1123257726430893, "test_micro_f1": 0.6203768318213537, "test_micro_f1_no_misc": 0.6661472536034281, "test_runtime": 6.8573, "test_samples_per_second": 298.661, "test_steps_per_second": 9.333, "epoch": 7.5}, {"test_loss": 0.12220495939254761, "test_micro_f1": 0.5882352941176471, "test_micro_f1_no_misc": 0.6174819566960706, "test_runtime": 7.0851, "test_samples_per_second": 289.057, "test_steps_per_second": 9.033, "epoch": 6.56}, {"test_loss": 0.12477977573871613, "test_micro_f1": 0.5798376184032477, "test_micro_f1_no_misc": 0.6121979286536249, "test_runtime": 7.2483, "test_samples_per_second": 282.55, "test_steps_per_second": 8.83, "epoch": 6.56}, {"test_loss": 0.13659478724002838, "test_micro_f1": 0.6268320180383314, "test_micro_f1_no_misc": 0.6647181628392484, "test_runtime": 7.0219, "test_samples_per_second": 291.659, "test_steps_per_second": 9.114, "epoch": 7.5}]}, "total": {"test_micro_f1": 59.56718831111979, "test_micro_f1_se": 1.0580971143497033, "test_micro_f1_no_misc": 63.16653794185553, "test_micro_f1_no_misc_se": 1.235929625933592}}, "num_model_parameters": 108898569, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.14169155061244965, "test_micro_f1": 0.5483769303498267, "test_micro_f1_no_misc": 0.5870236869207004, "test_runtime": 6.7276, "test_samples_per_second": 304.415, "test_steps_per_second": 9.513, "epoch": 7.5}, {"test_loss": 0.1405722200870514, "test_micro_f1": 0.5617103984450923, "test_micro_f1_no_misc": 0.5982966643009227, "test_runtime": 7.098, "test_samples_per_second": 288.534, "test_steps_per_second": 9.017, "epoch": 6.56}, {"test_loss": 0.1473589837551117, "test_micro_f1": 0.5558297347316471, "test_micro_f1_no_misc": 0.5912926088423894, "test_runtime": 6.5901, "test_samples_per_second": 310.77, "test_steps_per_second": 9.712, "epoch": 7.5}, {"test_loss": 0.15965670347213745, "test_micro_f1": 0.5257318952234206, "test_micro_f1_no_misc": 0.5617597292724196, "test_runtime": 6.7353, "test_samples_per_second": 304.069, "test_steps_per_second": 9.502, "epoch": 7.5}, {"test_loss": 0.1530526876449585, "test_micro_f1": 0.5320924261874197, "test_micro_f1_no_misc": 0.5795975997176139, "test_runtime": 6.4586, "test_samples_per_second": 317.095, "test_steps_per_second": 9.909, "epoch": 6.56}, {"test_loss": 0.1566285490989685, "test_micro_f1": 0.5571336346029697, "test_micro_f1_no_misc": 0.5964539007092198, "test_runtime": 6.4489, "test_samples_per_second": 317.571, "test_steps_per_second": 9.924, "epoch": 7.5}, {"test_loss": 0.1474001705646515, "test_micro_f1": 0.5303558967201675, "test_micro_f1_no_misc": 0.5673003802281369, "test_runtime": 7.0562, "test_samples_per_second": 290.242, "test_steps_per_second": 9.07, "epoch": 6.56}, {"test_loss": 0.14290326833724976, "test_micro_f1": 0.5440888308295232, "test_micro_f1_no_misc": 0.5795128939828081, "test_runtime": 7.0407, "test_samples_per_second": 290.881, "test_steps_per_second": 9.09, "epoch": 6.56}, {"test_loss": 0.15477189421653748, "test_micro_f1": 0.5348133198789102, "test_micro_f1_no_misc": 0.5743589743589744, "test_runtime": 6.4462, "test_samples_per_second": 317.707, "test_steps_per_second": 9.928, "epoch": 6.56}, {"test_loss": 0.148068368434906, "test_micro_f1": 0.5360610263522886, "test_micro_f1_no_misc": 0.5697373288938217, "test_runtime": 6.6865, "test_samples_per_second": 306.289, "test_steps_per_second": 9.572, "epoch": 5.62}]}, "total": {"test_micro_f1": 54.26194093321265, "test_micro_f1_se": 0.7827184774929197, "test_micro_f1_no_misc": 58.05333767227007, "test_micro_f1_no_misc_se": 0.7760763115103456}}, "num_model_parameters": 108898569, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.6390318870544434, "test_mcc": 0.2760649085035798, "test_macro_f1": 0.6366300366300366, "test_runtime": 3.2255, "test_samples_per_second": 634.933, "test_steps_per_second": 19.842, "epoch": 7.5}, {"test_loss": 0.6450642347335815, "test_mcc": 0.3056058071165939, "test_macro_f1": 0.647885429248259, "test_runtime": 3.309, "test_samples_per_second": 618.924, "test_steps_per_second": 19.341, "epoch": 8.44}, {"test_loss": 0.6280627250671387, "test_mcc": 0.2989051559971274, "test_macro_f1": 0.648297332431512, "test_runtime": 3.3169, "test_samples_per_second": 617.449, "test_steps_per_second": 19.295, "epoch": 7.5}, {"test_loss": 0.6279929280281067, "test_mcc": 0.30505757860343113, "test_macro_f1": 0.6524600728194443, "test_runtime": 3.2465, "test_samples_per_second": 630.825, "test_steps_per_second": 19.713, "epoch": 7.5}, {"test_loss": 0.6519942879676819, "test_mcc": 0.2513757925809319, "test_macro_f1": 0.6179783925415437, "test_runtime": 3.3111, "test_samples_per_second": 618.53, "test_steps_per_second": 19.329, "epoch": 6.56}, {"test_loss": 0.6455016136169434, "test_mcc": 0.2550834456480565, "test_macro_f1": 0.6270885263350066, "test_runtime": 3.2069, "test_samples_per_second": 638.624, "test_steps_per_second": 19.957, "epoch": 7.5}, {"test_loss": 0.6355534195899963, "test_mcc": 0.25127791947438516, "test_macro_f1": 0.6218854511642002, "test_runtime": 3.2721, "test_samples_per_second": 625.892, "test_steps_per_second": 19.559, "epoch": 6.56}, {"test_loss": 0.6203430891036987, "test_mcc": 0.3466586738196137, "test_macro_f1": 0.6728774285970096, "test_runtime": 3.2963, "test_samples_per_second": 621.306, "test_steps_per_second": 19.416, "epoch": 7.5}, {"test_loss": 0.6669173240661621, "test_mcc": 0.23944941580328896, "test_macro_f1": 0.6124218273387834, "test_runtime": 3.318, "test_samples_per_second": 617.238, "test_steps_per_second": 19.289, "epoch": 6.56}, {"test_loss": 0.6310832500457764, "test_mcc": 0.24696876951349087, "test_macro_f1": 0.6231555538690321, "test_runtime": 3.313, "test_samples_per_second": 618.162, "test_steps_per_second": 19.318, "epoch": 7.5}]}, "total": {"test_mcc": 27.764474670605, "test_mcc_se": 2.1712780167132366, "test_macro_f1": 63.60680050974828, "test_macro_f1_se": 1.1774582902904023}}, "num_model_parameters": 109483778, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.692589282989502, "test_mcc": 0.013963192679834547, "test_macro_f1": 0.49672346002621226, "test_runtime": 4.4642, "test_samples_per_second": 458.758, "test_steps_per_second": 14.336, "epoch": 3.75}, {"test_loss": 0.6960722804069519, "test_mcc": 0.008932767653341129, "test_macro_f1": 0.4477493073614926, "test_runtime": 4.6878, "test_samples_per_second": 436.878, "test_steps_per_second": 13.652, "epoch": 4.69}, {"test_loss": 0.6934158802032471, "test_mcc": 0.014822805028563424, "test_macro_f1": 0.5008651994833175, "test_runtime": 4.5789, "test_samples_per_second": 447.267, "test_steps_per_second": 13.977, "epoch": 2.81}, {"test_loss": 0.6978017091751099, "test_mcc": 0.016638893605141165, "test_macro_f1": 0.5004887737210421, "test_runtime": 4.7765, "test_samples_per_second": 428.766, "test_steps_per_second": 13.399, "epoch": 2.81}, {"test_loss": 0.6901965737342834, "test_mcc": 0.0526943028084047, "test_macro_f1": 0.5103252116001684, "test_runtime": 4.5688, "test_samples_per_second": 448.257, "test_steps_per_second": 14.008, "epoch": 8.44}, {"test_loss": 0.6910862922668457, "test_mcc": 0.04067673252913905, "test_macro_f1": 0.49730447441250347, "test_runtime": 4.4874, "test_samples_per_second": 456.384, "test_steps_per_second": 14.262, "epoch": 3.75}, {"test_loss": 0.6922509670257568, "test_mcc": 0.07100611168960438, "test_macro_f1": 0.5024610118106483, "test_runtime": 4.371, "test_samples_per_second": 468.54, "test_steps_per_second": 14.642, "epoch": 4.69}, {"test_loss": 0.6932688355445862, "test_mcc": 0.023424769539721363, "test_macro_f1": 0.5109505157919924, "test_runtime": 4.4242, "test_samples_per_second": 462.91, "test_steps_per_second": 14.466, "epoch": 6.56}, {"test_loss": 0.6916534900665283, "test_mcc": 0.03910621495708954, "test_macro_f1": 0.4921435295733789, "test_runtime": 4.4742, "test_samples_per_second": 457.737, "test_steps_per_second": 14.304, "epoch": 4.69}, {"test_loss": 0.699668824672699, "test_mcc": -0.036742402557300054, "test_macro_f1": 0.4804072613398954, "test_runtime": 4.6009, "test_samples_per_second": 445.133, "test_steps_per_second": 13.91, "epoch": 2.81}]}, "total": {"test_mcc": 2.445233879335393, "test_mcc_se": 1.8121420738608847, "test_macro_f1": 49.39418745120651, "test_macro_f1_se": 1.1429216563832274}}, "num_model_parameters": 109483778, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.6902970671653748, "test_mcc": 0.0663235954349748, "test_macro_f1": 0.507125878990278, "test_runtime": 3.978, "test_samples_per_second": 514.834, "test_steps_per_second": 16.089, "epoch": 3.75}, {"test_loss": 0.6895076632499695, "test_mcc": 0.06246902776331779, "test_macro_f1": 0.5240396900111962, "test_runtime": 4.081, "test_samples_per_second": 501.844, "test_steps_per_second": 15.683, "epoch": 6.56}, {"test_loss": 0.6852307915687561, "test_mcc": 0.07476417794749704, "test_macro_f1": 0.5373800354544899, "test_runtime": 4.0396, "test_samples_per_second": 506.977, "test_steps_per_second": 15.843, "epoch": 7.5}, {"test_loss": 0.6849900484085083, "test_mcc": 0.09035477047003429, "test_macro_f1": 0.5413368358128531, "test_runtime": 4.1271, "test_samples_per_second": 496.236, "test_steps_per_second": 15.507, "epoch": 8.44}, {"test_loss": 0.6938595771789551, "test_mcc": 0.03427275810570666, "test_macro_f1": 0.5170178738048381, "test_runtime": 4.0884, "test_samples_per_second": 500.925, "test_steps_per_second": 15.654, "epoch": 3.75}, {"test_loss": 0.6903514862060547, "test_mcc": 0.07086650926105864, "test_macro_f1": 0.529555327698088, "test_runtime": 3.935, "test_samples_per_second": 520.463, "test_steps_per_second": 16.264, "epoch": 4.69}, {"test_loss": 0.6903356313705444, "test_mcc": 0.04166473724788792, "test_macro_f1": 0.4781496044949175, "test_runtime": 3.9267, "test_samples_per_second": 521.561, "test_steps_per_second": 16.299, "epoch": 3.75}, {"test_loss": 0.6883449554443359, "test_mcc": 0.08746310994705035, "test_macro_f1": 0.5226920603967501, "test_runtime": 3.9699, "test_samples_per_second": 515.884, "test_steps_per_second": 16.121, "epoch": 6.56}, {"test_loss": 0.6931416988372803, "test_mcc": -0.02106800468054134, "test_macro_f1": 0.48513878653893383, "test_runtime": 3.9402, "test_samples_per_second": 519.766, "test_steps_per_second": 16.243, "epoch": 3.75}, {"test_loss": 0.6914370059967041, "test_mcc": 0.05221581813643948, "test_macro_f1": 0.45872187564030464, "test_runtime": 4.0658, "test_samples_per_second": 503.712, "test_steps_per_second": 15.741, "epoch": 7.5}]}, "total": {"test_mcc": 5.593264996334256, "test_mcc_se": 2.016148428753227, "test_macro_f1": 51.01157968842649, "test_macro_f1_se": 1.7026356102977356}}, "num_model_parameters": 109483778, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_loss": 0.6938235759735107, "test_mcc": -0.023734359056941462, "test_macro_f1": 0.43494985122188706, "test_runtime": 3.9419, "test_samples_per_second": 519.552, "test_steps_per_second": 16.236, "epoch": 2.81}, {"test_loss": 0.6909682750701904, "test_mcc": 0.059443950966429904, "test_macro_f1": 0.5051669682542166, "test_runtime": 4.0708, "test_samples_per_second": 503.097, "test_steps_per_second": 15.722, "epoch": 9.38}, {"test_loss": 0.6918154954910278, "test_mcc": 0.03605219515329639, "test_macro_f1": 0.508222903508625, "test_runtime": 4.095, "test_samples_per_second": 500.127, "test_steps_per_second": 15.629, "epoch": 4.69}, {"test_loss": 0.6829744577407837, "test_mcc": 0.14592407038015479, "test_macro_f1": 0.5717975498898477, "test_runtime": 3.8814, "test_samples_per_second": 527.651, "test_steps_per_second": 16.489, "epoch": 10.31}, {"test_loss": 0.6823748350143433, "test_mcc": 0.1663532680859616, "test_macro_f1": 0.5825146539731132, "test_runtime": 3.9755, "test_samples_per_second": 515.156, "test_steps_per_second": 16.099, "epoch": 11.25}, {"test_loss": 0.6893892884254456, "test_mcc": 0.04895990653891313, "test_macro_f1": 0.46179161622392506, "test_runtime": 4.0875, "test_samples_per_second": 501.035, "test_steps_per_second": 15.657, "epoch": 5.62}, {"test_loss": 0.6982858180999756, "test_mcc": -0.011984081642163488, "test_macro_f1": 0.47779490740195907, "test_runtime": 3.9563, "test_samples_per_second": 517.655, "test_steps_per_second": 16.177, "epoch": 2.81}, {"test_loss": 0.689678430557251, "test_mcc": 0.047365205112051015, "test_macro_f1": 0.5188249933836976, "test_runtime": 3.9617, "test_samples_per_second": 516.944, "test_steps_per_second": 16.154, "epoch": 3.75}, {"test_loss": 0.694350004196167, "test_mcc": 0.03669517364296821, "test_macro_f1": 0.5182819575633946, "test_runtime": 3.9627, "test_samples_per_second": 516.823, "test_steps_per_second": 16.151, "epoch": 3.75}, {"test_loss": 0.6920092105865479, "test_mcc": 0.004155381856061151, "test_macro_f1": 0.4921727970952685, "test_runtime": 4.0657, "test_samples_per_second": 503.72, "test_steps_per_second": 15.741, "epoch": 5.62}]}, "total": {"test_mcc": 5.0923071103673125, "test_mcc_se": 3.841926240485009, "test_macro_f1": 50.715181985159354, "test_macro_f1_se": 2.808628918209359}}, "num_model_parameters": 109483778, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_em": 34.00464756003098, "test_f1": 39.23029150089799, "epoch": 4.05}, {"test_em": 32.945736434108525, "test_f1": 38.36241591139824, "epoch": 3.64}, {"test_em": 31.143740340030913, "test_f1": 37.13287640341418, "epoch": 3.64}, {"test_em": 30.685358255451714, "test_f1": 35.586878793148166, "epoch": 3.64}, {"test_em": 31.35135135135135, "test_f1": 36.32669300250017, "epoch": 3.64}, {"test_em": 31.457208943716267, "test_f1": 36.830610944665544, "epoch": 3.64}, {"test_em": 31.738800303720577, "test_f1": 36.81579414588577, "epoch": 3.64}, {"test_em": 31.65244375484872, "test_f1": 36.90209177831884, "epoch": 3.64}, {"test_em": 32.549019607843135, "test_f1": 37.63739338893941, "epoch": 3.64}, {"test_em": 36.33540372670807, "test_f1": 41.1436697437986, "epoch": 4.45}]}, "total": {"test_em": 32.38637102778103, "test_em_se": 1.0510994888472525, "test_f1": 37.59687156129669, "test_f1_se": 0.9990705836032081}}, "num_model_parameters": 108893186, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_em": 29.43454686289698, "test_f1": 35.508242724185216}, {"test_em": 32.248062015503876, "test_f1": 37.10821233576656}, {"test_em": 36.6306027820711, "test_f1": 42.11981838015405}, {"test_em": 29.595015576323988, "test_f1": 34.6420835809667}, {"test_em": 32.2007722007722, "test_f1": 37.29082466737028}, {"test_em": 29.144178874325366, "test_f1": 34.821709627805404}, {"test_em": 29.00531511009871, "test_f1": 33.90268790711435}, {"test_em": 29.09231962761831, "test_f1": 34.55775166072918}, {"test_em": 30.745098039215687, "test_f1": 36.90739062340103}, {"test_em": 32.453416149068325, "test_f1": 38.08576777059364}]}, "total": {"test_em": 31.054932723789456, "test_em_se": 1.494650856715337, "test_f1": 36.49444892780864, "test_f1_se": 1.5044900098363465}}, "num_model_parameters": 108893186, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_em": 34.546862896979086, "test_f1": 40.71611336465774}, {"test_em": 33.64341085271318, "test_f1": 40.54413317161288}, {"test_em": 34.003091190108194, "test_f1": 39.913651309245736}, {"test_em": 34.65732087227414, "test_f1": 40.6572205267628}, {"test_em": 31.428571428571427, "test_f1": 38.423775588718016}, {"test_em": 34.926754047802625, "test_f1": 41.041065479379924}, {"test_em": 38.95216400911162, "test_f1": 44.14951710591237}, {"test_em": 34.678044996121024, "test_f1": 40.45613459575459}, {"test_em": 38.745098039215684, "test_f1": 45.18717305957993}, {"test_em": 33.15217391304348, "test_f1": 39.72584510269823}]}, "total": {"test_em": 34.87334922459405, "test_em_se": 1.4450407448900842, "test_f1": 41.081462930432224, "test_f1_se": 1.265671261630328}}, "num_model_parameters": 108893186, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "af-ai-center/bert-base-swedish-uncased", "results": {"raw": {"test": [{"test_speed": 1.96}, {"test_speed": 1.98}, {"test_speed": 1.95}, {"test_speed": 1.95}, {"test_speed": 1.92}, {"test_speed": 1.97}, {"test_speed": 1.91}, {"test_speed": 1.85}, {"test_speed": 1.97}, {"test_speed": 1.99}]}, "total": {"test_speed": 1.9449999999999996, "test_speed_se": 0.025845919514607234}}, "num_model_parameters": 109482240, "max_sequence_length": 512, "vocabulary_size": 30522}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.43570560216903687, "test_mcc": 0.7120864398672015, "test_macro_f1": 0.6294574120144134, "test_runtime": 9.9445, "test_samples_per_second": 205.942, "test_steps_per_second": 6.436}, {"test_loss": 0.47933146357536316, "test_mcc": 0.6688219600058491, "test_macro_f1": 0.6115006117960826, "test_runtime": 7.9446, "test_samples_per_second": 257.784, "test_steps_per_second": 32.223}, {"test_loss": 0.43872010707855225, "test_mcc": 0.716745551419627, "test_macro_f1": 0.6991465324798657, "test_runtime": 8.1767, "test_samples_per_second": 250.469, "test_steps_per_second": 31.309}, {"test_loss": 0.40220510959625244, "test_mcc": 0.7365150482288447, "test_macro_f1": 0.7225549382542011, "test_runtime": 7.8116, "test_samples_per_second": 262.175, "test_steps_per_second": 32.772}, {"test_loss": 0.39561161398887634, "test_mcc": 0.7513733066695453, "test_macro_f1": 0.7631917262918778, "test_runtime": 7.7756, "test_samples_per_second": 263.388, "test_steps_per_second": 32.924}, {"test_loss": 0.4030728340148926, "test_mcc": 0.7450768303124121, "test_macro_f1": 0.726271510498815, "test_runtime": 8.0385, "test_samples_per_second": 254.773, "test_steps_per_second": 31.847}, {"test_loss": 0.44774705171585083, "test_mcc": 0.7080331373687794, "test_macro_f1": 0.7131375827181633, "test_runtime": 7.7173, "test_samples_per_second": 265.377, "test_steps_per_second": 33.172}, {"test_loss": 0.42764830589294434, "test_mcc": 0.7146776463239695, "test_macro_f1": 0.6931091710658124, "test_runtime": 8.2521, "test_samples_per_second": 248.179, "test_steps_per_second": 31.022}, {"test_loss": 0.47869938611984253, "test_mcc": 0.7189645930246248, "test_macro_f1": 0.725948116727544, "test_runtime": 8.2091, "test_samples_per_second": 249.479, "test_steps_per_second": 31.185}, {"test_loss": 0.43600040674209595, "test_mcc": 0.7296589141364419, "test_macro_f1": 0.7424938197574518, "test_runtime": 8.044, "test_samples_per_second": 254.599, "test_steps_per_second": 31.825}]}, "total": {"test_mcc": 72.01953427357294, "test_mcc_se": 1.4378981488556197, "test_macro_f1": 70.26811421604228, "test_macro_f1_se": 2.96734639031199}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.9382097721099854, "test_mcc": 0.3601474665382138, "test_macro_f1": 0.5754185401839539, "test_runtime": 2.983, "test_samples_per_second": 686.559, "test_steps_per_second": 21.455}, {"test_loss": 0.9829001426696777, "test_mcc": 0.3478236722045846, "test_macro_f1": 0.5680091158685159, "test_runtime": 2.9986, "test_samples_per_second": 682.996, "test_steps_per_second": 21.344}, {"test_loss": 0.9646426439285278, "test_mcc": 0.33409566692422166, "test_macro_f1": 0.555982082069264, "test_runtime": 2.9915, "test_samples_per_second": 684.597, "test_steps_per_second": 21.394}, {"test_loss": 0.9448145627975464, "test_mcc": 0.3541417762031273, "test_macro_f1": 0.5710735419419825, "test_runtime": 2.9828, "test_samples_per_second": 686.595, "test_steps_per_second": 21.456}, {"test_loss": 0.9439566135406494, "test_mcc": 0.3567820848881784, "test_macro_f1": 0.5764164384103637, "test_runtime": 2.9789, "test_samples_per_second": 687.505, "test_steps_per_second": 21.485}, {"test_loss": 0.9580175280570984, "test_mcc": 0.3491407343802394, "test_macro_f1": 0.5672404032896, "test_runtime": 3.0331, "test_samples_per_second": 675.219, "test_steps_per_second": 21.101}, {"test_loss": 0.9606152176856995, "test_mcc": 0.36323054142226463, "test_macro_f1": 0.5758519535145471, "test_runtime": 2.982, "test_samples_per_second": 686.789, "test_steps_per_second": 21.462}, {"test_loss": 0.9390347003936768, "test_mcc": 0.3874865781253232, "test_macro_f1": 0.5814444195467151, "test_runtime": 3.0446, "test_samples_per_second": 672.656, "test_steps_per_second": 21.02}, {"test_loss": 0.9343072772026062, "test_mcc": 0.34555006892079687, "test_macro_f1": 0.5551774727053705, "test_runtime": 3.0198, "test_samples_per_second": 678.18, "test_steps_per_second": 21.193}, {"test_loss": 0.9830420017242432, "test_mcc": 0.35535545541718244, "test_macro_f1": 0.5703300762171314, "test_runtime": 3.1515, "test_samples_per_second": 649.847, "test_steps_per_second": 20.308}]}, "total": {"test_mcc": 35.53754045024132, "test_mcc_se": 0.8678196031109678, "test_macro_f1": 56.96944043747444, "test_macro_f1_se": 0.5323232531870674}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.8559168577194214, "test_mcc": 0.41460334474310384, "test_macro_f1": 0.5698573273603604, "test_runtime": 2.5169, "test_samples_per_second": 813.698, "test_steps_per_second": 25.428}, {"test_loss": 0.8935182690620422, "test_mcc": 0.3154472885127021, "test_macro_f1": 0.44612842230540783, "test_runtime": 2.3637, "test_samples_per_second": 866.455, "test_steps_per_second": 27.077}, {"test_loss": 0.8342487812042236, "test_mcc": 0.3753417740037377, "test_macro_f1": 0.49378099762832006, "test_runtime": 2.3604, "test_samples_per_second": 867.658, "test_steps_per_second": 27.114}, {"test_loss": 0.9151924848556519, "test_mcc": 0.38118840634011464, "test_macro_f1": 0.5629266293361304, "test_runtime": 2.4216, "test_samples_per_second": 845.729, "test_steps_per_second": 26.429}, {"test_loss": 0.8527063727378845, "test_mcc": 0.35608066098871594, "test_macro_f1": 0.49664566082635275, "test_runtime": 2.4345, "test_samples_per_second": 841.25, "test_steps_per_second": 26.289}, {"test_loss": 0.9078145623207092, "test_mcc": 0.3515110378047134, "test_macro_f1": 0.5368410832344548, "test_runtime": 2.4664, "test_samples_per_second": 830.369, "test_steps_per_second": 25.949}, {"test_loss": 0.8790813684463501, "test_mcc": 0.34819365326229146, "test_macro_f1": 0.4825520984606068, "test_runtime": 2.3798, "test_samples_per_second": 860.562, "test_steps_per_second": 26.893}, {"test_loss": 0.8299562335014343, "test_mcc": 0.3740244563525278, "test_macro_f1": 0.536959193517359, "test_runtime": 2.4164, "test_samples_per_second": 847.53, "test_steps_per_second": 26.485}, {"test_loss": 0.8770409822463989, "test_mcc": 0.34045431638794255, "test_macro_f1": 0.46094380454283534, "test_runtime": 2.5144, "test_samples_per_second": 814.52, "test_steps_per_second": 25.454}, {"test_loss": 0.84211266040802, "test_mcc": 0.39805521907476893, "test_macro_f1": 0.5557381793207449, "test_runtime": 2.4865, "test_samples_per_second": 823.651, "test_steps_per_second": 25.739}]}, "total": {"test_mcc": 36.54900157470618, "test_mcc_se": 1.8014850799164164, "test_macro_f1": 51.423733965325724, "test_macro_f1_se": 2.7272007361760697}}, "num_model_parameters": 124647939, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.06477804481983185, "test_micro_f1": 0.6663244353182751, "test_micro_f1_no_misc": 0.7512077294685989, "test_runtime": 4.3635, "test_samples_per_second": 469.348, "test_steps_per_second": 14.667}, {"test_loss": 0.06511396914720535, "test_micro_f1": 0.7033333333333334, "test_micro_f1_no_misc": 0.7752808988764046, "test_runtime": 3.9925, "test_samples_per_second": 512.966, "test_steps_per_second": 16.03}, {"test_loss": 0.0570133775472641, "test_micro_f1": 0.6911045943304007, "test_micro_f1_no_misc": 0.7380824852704874, "test_runtime": 3.9661, "test_samples_per_second": 516.373, "test_steps_per_second": 16.137}, {"test_loss": 0.05808490887284279, "test_micro_f1": 0.6750849927149101, "test_micro_f1_no_misc": 0.7257525083612041, "test_runtime": 4.311, "test_samples_per_second": 475.063, "test_steps_per_second": 14.846}, {"test_loss": 0.06126025319099426, "test_micro_f1": 0.6996197718631179, "test_micro_f1_no_misc": 0.7624190064794816, "test_runtime": 4.3096, "test_samples_per_second": 475.221, "test_steps_per_second": 14.851}, {"test_loss": 0.06405192613601685, "test_micro_f1": 0.6935405536668287, "test_micro_f1_no_misc": 0.7367859049652963, "test_runtime": 3.5135, "test_samples_per_second": 582.894, "test_steps_per_second": 18.215}, {"test_loss": 0.0676964595913887, "test_micro_f1": 0.6759581881533101, "test_micro_f1_no_misc": 0.7431506849315069, "test_runtime": 3.8122, "test_samples_per_second": 537.22, "test_steps_per_second": 16.788}, {"test_loss": 0.054513439536094666, "test_micro_f1": 0.6625698324022347, "test_micro_f1_no_misc": 0.7112718505123569, "test_runtime": 4.2867, "test_samples_per_second": 477.751, "test_steps_per_second": 14.93}, {"test_loss": 0.05482081323862076, "test_micro_f1": 0.7175721977484092, "test_micro_f1_no_misc": 0.7688083470620538, "test_runtime": 4.1676, "test_samples_per_second": 491.415, "test_steps_per_second": 15.357}, {"test_loss": 0.06242363527417183, "test_micro_f1": 0.6958193176357521, "test_micro_f1_no_misc": 0.7579062159214832, "test_runtime": 4.4441, "test_samples_per_second": 460.838, "test_steps_per_second": 14.401}]}, "total": {"test_micro_f1": 68.80927217166573, "test_micro_f1_se": 1.0882194374168697, "test_micro_f1_no_misc": 74.70665631848874, "test_micro_f1_no_misc_se": 1.2355410568302887}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.08352755010128021, "test_micro_f1": 0.743225806451613, "test_micro_f1_no_misc": 0.770891364902507, "test_runtime": 5.8949, "test_samples_per_second": 347.416, "test_steps_per_second": 10.857}, {"test_loss": 0.07748401165008545, "test_micro_f1": 0.7461688492616328, "test_micro_f1_no_misc": 0.7741228070175439, "test_runtime": 4.9473, "test_samples_per_second": 413.965, "test_steps_per_second": 12.936}, {"test_loss": 0.08351383358240128, "test_micro_f1": 0.740144810941271, "test_micro_f1_no_misc": 0.7639238232123607, "test_runtime": 5.8406, "test_samples_per_second": 350.651, "test_steps_per_second": 10.958}, {"test_loss": 0.08660277724266052, "test_micro_f1": 0.7319506432134418, "test_micro_f1_no_misc": 0.7571819425444596, "test_runtime": 5.7023, "test_samples_per_second": 359.156, "test_steps_per_second": 11.224}, {"test_loss": 0.08721054345369339, "test_micro_f1": 0.7295383743981876, "test_micro_f1_no_misc": 0.7584143605086013, "test_runtime": 6.0839, "test_samples_per_second": 336.625, "test_steps_per_second": 10.52}, {"test_loss": 0.0781659483909607, "test_micro_f1": 0.741900054914882, "test_micro_f1_no_misc": 0.76013143483023, "test_runtime": 5.6763, "test_samples_per_second": 360.799, "test_steps_per_second": 11.275}, {"test_loss": 0.07693636417388916, "test_micro_f1": 0.7447589098532496, "test_micro_f1_no_misc": 0.7694483734087695, "test_runtime": 6.0866, "test_samples_per_second": 336.479, "test_steps_per_second": 10.515}, {"test_loss": 0.07813909649848938, "test_micro_f1": 0.7434265153611956, "test_micro_f1_no_misc": 0.7685393258426967, "test_runtime": 5.8655, "test_samples_per_second": 349.159, "test_steps_per_second": 10.911}, {"test_loss": 0.08125327527523041, "test_micro_f1": 0.7390835579514825, "test_micro_f1_no_misc": 0.7605531295487626, "test_runtime": 5.7102, "test_samples_per_second": 358.656, "test_steps_per_second": 11.208}, {"test_loss": 0.08624213933944702, "test_micro_f1": 0.7572658772874058, "test_micro_f1_no_misc": 0.7874736101337086, "test_runtime": 5.1375, "test_samples_per_second": 398.636, "test_steps_per_second": 12.457}]}, "total": {"test_micro_f1": 74.17463399634362, "test_micro_f1_se": 0.47526173900814966, "test_micro_f1_no_misc": 76.7068017194964, "test_micro_f1_no_misc_se": 0.5701894391346796}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.06795394420623779, "test_micro_f1": 0.705798138869005, "test_micro_f1_no_misc": 0.742430200550531, "test_runtime": 4.6797, "test_samples_per_second": 437.635, "test_steps_per_second": 13.676}, {"test_loss": 0.0553540363907814, "test_micro_f1": 0.7209387605427209, "test_micro_f1_no_misc": 0.7439807383627608, "test_runtime": 4.6468, "test_samples_per_second": 440.729, "test_steps_per_second": 13.773}, {"test_loss": 0.05888604372739792, "test_micro_f1": 0.7809323519102699, "test_micro_f1_no_misc": 0.80546875, "test_runtime": 4.376, "test_samples_per_second": 468.006, "test_steps_per_second": 14.625}, {"test_loss": 0.05677170678973198, "test_micro_f1": 0.7510518934081346, "test_micro_f1_no_misc": 0.7742690058479531, "test_runtime": 4.4654, "test_samples_per_second": 458.635, "test_steps_per_second": 14.332}, {"test_loss": 0.05372016131877899, "test_micro_f1": 0.7482815057283142, "test_micro_f1_no_misc": 0.7723342939481267, "test_runtime": 4.6997, "test_samples_per_second": 435.769, "test_steps_per_second": 13.618}, {"test_loss": 0.06077086925506592, "test_micro_f1": 0.7846364883401921, "test_micro_f1_no_misc": 0.8009259259259258, "test_runtime": 4.7105, "test_samples_per_second": 434.777, "test_steps_per_second": 13.587}, {"test_loss": 0.05856071412563324, "test_micro_f1": 0.7529089664613278, "test_micro_f1_no_misc": 0.7784568372803667, "test_runtime": 4.328, "test_samples_per_second": 473.198, "test_steps_per_second": 14.787}, {"test_loss": 0.055111803114414215, "test_micro_f1": 0.752249134948097, "test_micro_f1_no_misc": 0.7763998496805711, "test_runtime": 4.3624, "test_samples_per_second": 469.47, "test_steps_per_second": 14.671}, {"test_loss": 0.05493056774139404, "test_micro_f1": 0.7481349911190053, "test_micro_f1_no_misc": 0.764080346593147, "test_runtime": 4.3503, "test_samples_per_second": 470.767, "test_steps_per_second": 14.711}, {"test_loss": 0.06331124156713486, "test_micro_f1": 0.7492406344920689, "test_micro_f1_no_misc": 0.7732149463559009, "test_runtime": 4.4435, "test_samples_per_second": 460.901, "test_steps_per_second": 14.403}]}, "total": {"test_micro_f1": 74.94172865819135, "test_micro_f1_se": 1.4569621363318277, "test_micro_f1_no_misc": 77.31560894545282, "test_micro_f1_no_misc_se": 1.262381280623368}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.07513755559921265, "test_micro_f1": 0.6995461422087745, "test_micro_f1_no_misc": 0.7411371237458194, "test_runtime": 4.2849, "test_samples_per_second": 477.961, "test_steps_per_second": 14.936}, {"test_loss": 0.07480241358280182, "test_micro_f1": 0.729997003296374, "test_micro_f1_no_misc": 0.755942417140944, "test_runtime": 4.2719, "test_samples_per_second": 479.408, "test_steps_per_second": 14.981}, {"test_loss": 0.071965292096138, "test_micro_f1": 0.7107487922705313, "test_micro_f1_no_misc": 0.7483399734395749, "test_runtime": 4.1229, "test_samples_per_second": 496.732, "test_steps_per_second": 15.523}, {"test_loss": 0.07844948768615723, "test_micro_f1": 0.6839409460680929, "test_micro_f1_no_misc": 0.7198675496688743, "test_runtime": 4.2625, "test_samples_per_second": 480.472, "test_steps_per_second": 15.015}, {"test_loss": 0.08280649036169052, "test_micro_f1": 0.6605011933174224, "test_micro_f1_no_misc": 0.7129810828440966, "test_runtime": 4.2275, "test_samples_per_second": 484.445, "test_steps_per_second": 15.139}, {"test_loss": 0.07348798215389252, "test_micro_f1": 0.6926536731634183, "test_micro_f1_no_misc": 0.726850315300365, "test_runtime": 4.1913, "test_samples_per_second": 488.628, "test_steps_per_second": 15.27}, {"test_loss": 0.06407464295625687, "test_micro_f1": 0.7175054029021302, "test_micro_f1_no_misc": 0.76, "test_runtime": 4.2973, "test_samples_per_second": 476.577, "test_steps_per_second": 14.893}, {"test_loss": 0.07309140264987946, "test_micro_f1": 0.7105740181268881, "test_micro_f1_no_misc": 0.7444219066937119, "test_runtime": 4.3473, "test_samples_per_second": 471.097, "test_steps_per_second": 14.722}, {"test_loss": 0.07749706506729126, "test_micro_f1": 0.7036809815950921, "test_micro_f1_no_misc": 0.738014854827819, "test_runtime": 4.1889, "test_samples_per_second": 488.916, "test_steps_per_second": 15.279}, {"test_loss": 0.07155574858188629, "test_micro_f1": 0.7110977080820267, "test_micro_f1_no_misc": 0.7377866400797608, "test_runtime": 4.2034, "test_samples_per_second": 487.229, "test_steps_per_second": 15.226}]}, "total": {"test_micro_f1": 70.20245861030749, "test_micro_f1_se": 1.2049614327812392, "test_micro_f1_no_misc": 73.85341863740966, "test_micro_f1_no_misc_se": 0.933184944288705}}, "num_model_parameters": 124061961, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.4333009719848633, "test_mcc": 0.6409428591836066, "test_macro_f1": 0.8085633141361269, "test_runtime": 1.8591, "test_samples_per_second": 1101.6, "test_steps_per_second": 34.425}, {"test_loss": 0.493905246257782, "test_mcc": 0.6057887110250716, "test_macro_f1": 0.7778895759170161, "test_runtime": 1.9413, "test_samples_per_second": 1054.945, "test_steps_per_second": 32.967}, {"test_loss": 0.42671895027160645, "test_mcc": 0.6198512234650173, "test_macro_f1": 0.8052455718101924, "test_runtime": 1.9124, "test_samples_per_second": 1070.884, "test_steps_per_second": 33.465}, {"test_loss": 0.4880240261554718, "test_mcc": 0.6348796130766748, "test_macro_f1": 0.8016769503448976, "test_runtime": 1.8839, "test_samples_per_second": 1087.1, "test_steps_per_second": 33.972}, {"test_loss": 0.43500447273254395, "test_mcc": 0.5920013811824382, "test_macro_f1": 0.7858717402858413, "test_runtime": 1.9016, "test_samples_per_second": 1076.99, "test_steps_per_second": 33.656}, {"test_loss": 0.45269620418548584, "test_mcc": 0.6039619115764462, "test_macro_f1": 0.7848670446355364, "test_runtime": 1.895, "test_samples_per_second": 1080.764, "test_steps_per_second": 33.774}, {"test_loss": 0.42628175020217896, "test_mcc": 0.677529309723795, "test_macro_f1": 0.8322714118931839, "test_runtime": 1.881, "test_samples_per_second": 1088.765, "test_steps_per_second": 34.024}, {"test_loss": 0.4841269850730896, "test_mcc": 0.6060615833945404, "test_macro_f1": 0.7864363407434569, "test_runtime": 1.9157, "test_samples_per_second": 1069.036, "test_steps_per_second": 33.407}, {"test_loss": 0.42468181252479553, "test_mcc": 0.6235755594078035, "test_macro_f1": 0.8090203938484521, "test_runtime": 1.8907, "test_samples_per_second": 1083.183, "test_steps_per_second": 33.849}, {"test_loss": 0.43985068798065186, "test_mcc": 0.6129772785805179, "test_macro_f1": 0.7948875866108354, "test_runtime": 1.8957, "test_samples_per_second": 1080.324, "test_steps_per_second": 33.76}]}, "total": {"test_mcc": 62.175694306159116, "test_mcc_se": 1.5235794586875266, "test_macro_f1": 79.86729930225539, "test_macro_f1_se": 0.9986505349013084}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.6862791776657104, "test_mcc": 0.09945662424919899, "test_macro_f1": 0.5496947496947497, "test_runtime": 2.6145, "test_samples_per_second": 783.318, "test_steps_per_second": 24.479}, {"test_loss": 0.6933011412620544, "test_mcc": 0.07886379938173937, "test_macro_f1": 0.5147680794739617, "test_runtime": 2.7438, "test_samples_per_second": 746.406, "test_steps_per_second": 23.325}, {"test_loss": 0.699067234992981, "test_mcc": 0.022800371905276652, "test_macro_f1": 0.48092124817960336, "test_runtime": 2.6566, "test_samples_per_second": 770.918, "test_steps_per_second": 24.091}, {"test_loss": 0.6611331701278687, "test_mcc": 0.24697759583620144, "test_macro_f1": 0.5749676931563497, "test_runtime": 2.7876, "test_samples_per_second": 734.684, "test_steps_per_second": 22.959}, {"test_loss": 0.6243813633918762, "test_mcc": 0.32532716953119395, "test_macro_f1": 0.6582738780207134, "test_runtime": 2.6809, "test_samples_per_second": 763.917, "test_steps_per_second": 23.872}, {"test_loss": 0.6015845537185669, "test_mcc": 0.3603289629867076, "test_macro_f1": 0.6683366938131186, "test_runtime": 2.612, "test_samples_per_second": 784.064, "test_steps_per_second": 24.502}, {"test_loss": 0.6068558692932129, "test_mcc": 0.34266750722475114, "test_macro_f1": 0.6664543046421061, "test_runtime": 2.5721, "test_samples_per_second": 796.25, "test_steps_per_second": 24.883}, {"test_loss": 0.6047053337097168, "test_mcc": 0.415269610237309, "test_macro_f1": 0.6962242991381414, "test_runtime": 2.6009, "test_samples_per_second": 787.424, "test_steps_per_second": 24.607}, {"test_loss": 0.6732734441757202, "test_mcc": 0.18980119369676837, "test_macro_f1": 0.5628882373905648, "test_runtime": 2.6, "test_samples_per_second": 787.686, "test_steps_per_second": 24.615}, {"test_loss": 0.7011229991912842, "test_mcc": -0.02276547780400412, "test_macro_f1": 0.4881543603254319, "test_runtime": 2.69, "test_samples_per_second": 761.351, "test_steps_per_second": 23.792}]}, "total": {"test_mcc": 20.587273572451426, "test_mcc_se": 9.599341853059187, "test_macro_f1": 58.6068354383474, "test_macro_f1_se": 4.987990367548167}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.6470085978507996, "test_mcc": 0.24925838082284033, "test_macro_f1": 0.6239964784138883, "test_runtime": 2.4063, "test_samples_per_second": 851.105, "test_steps_per_second": 26.597}, {"test_loss": 0.6475927829742432, "test_mcc": 0.3453032375118327, "test_macro_f1": 0.6290676380028577, "test_runtime": 2.4095, "test_samples_per_second": 849.96, "test_steps_per_second": 26.561}, {"test_loss": 0.6087225675582886, "test_mcc": 0.425852994388097, "test_macro_f1": 0.7065618336058213, "test_runtime": 2.4082, "test_samples_per_second": 850.426, "test_steps_per_second": 26.576}, {"test_loss": 0.6116865277290344, "test_mcc": 0.3613073517941846, "test_macro_f1": 0.6717080876790771, "test_runtime": 2.4511, "test_samples_per_second": 835.536, "test_steps_per_second": 26.11}, {"test_loss": 0.6432873010635376, "test_mcc": 0.39036125664815235, "test_macro_f1": 0.6790752167460752, "test_runtime": 2.5435, "test_samples_per_second": 805.177, "test_steps_per_second": 25.162}, {"test_loss": 0.6456819772720337, "test_mcc": 0.26511619636122685, "test_macro_f1": 0.6295876651712575, "test_runtime": 2.3445, "test_samples_per_second": 873.516, "test_steps_per_second": 27.297}, {"test_loss": 0.6911327838897705, "test_mcc": 0.06751057410367224, "test_macro_f1": 0.5234942416878821, "test_runtime": 2.3449, "test_samples_per_second": 873.386, "test_steps_per_second": 27.293}, {"test_loss": 0.60996413230896, "test_mcc": 0.3260539076187291, "test_macro_f1": 0.6626918769352395, "test_runtime": 2.441, "test_samples_per_second": 839.013, "test_steps_per_second": 26.219}, {"test_loss": 0.6208471655845642, "test_mcc": 0.3209770422084529, "test_macro_f1": 0.6394009535679663, "test_runtime": 2.3379, "test_samples_per_second": 876.014, "test_steps_per_second": 27.375}, {"test_loss": 0.6100797653198242, "test_mcc": 0.3622888759429129, "test_macro_f1": 0.671084817467455, "test_runtime": 2.5495, "test_samples_per_second": 803.303, "test_steps_per_second": 25.103}]}, "total": {"test_mcc": 31.140298174001003, "test_mcc_se": 6.244598790497202, "test_macro_f1": 64.36668809277519, "test_macro_f1_se": 3.08989209021111}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_loss": 0.6772266626358032, "test_mcc": 0.16993783854451439, "test_macro_f1": 0.5495819768360339, "test_runtime": 2.4475, "test_samples_per_second": 836.777, "test_steps_per_second": 26.149}, {"test_loss": 0.641984224319458, "test_mcc": 0.24893762250065984, "test_macro_f1": 0.6210551210090426, "test_runtime": 2.5099, "test_samples_per_second": 815.97, "test_steps_per_second": 25.499}, {"test_loss": 0.6688834428787231, "test_mcc": 0.20678964344975273, "test_macro_f1": 0.5916457791693049, "test_runtime": 2.5223, "test_samples_per_second": 811.959, "test_steps_per_second": 25.374}, {"test_loss": 0.6283141374588013, "test_mcc": 0.28478372565003246, "test_macro_f1": 0.6361809449556648, "test_runtime": 2.3965, "test_samples_per_second": 854.57, "test_steps_per_second": 26.705}, {"test_loss": 0.6311010122299194, "test_mcc": 0.2764706096132815, "test_macro_f1": 0.634758131374477, "test_runtime": 2.4493, "test_samples_per_second": 836.168, "test_steps_per_second": 26.13}, {"test_loss": 0.6343203186988831, "test_mcc": 0.27990458621207714, "test_macro_f1": 0.637645148569076, "test_runtime": 2.5067, "test_samples_per_second": 817.021, "test_steps_per_second": 25.532}, {"test_loss": 0.6807041168212891, "test_mcc": 0.13118818922568287, "test_macro_f1": 0.5654193262893269, "test_runtime": 2.4373, "test_samples_per_second": 840.264, "test_steps_per_second": 26.258}, {"test_loss": 0.6378173232078552, "test_mcc": 0.26379106791230966, "test_macro_f1": 0.6230953492446827, "test_runtime": 2.4529, "test_samples_per_second": 834.933, "test_steps_per_second": 26.092}, {"test_loss": 0.6938560009002686, "test_mcc": 0.019160683745241783, "test_macro_f1": 0.5036582803590363, "test_runtime": 2.4335, "test_samples_per_second": 841.58, "test_steps_per_second": 26.299}, {"test_loss": 0.6882086992263794, "test_mcc": 0.09180047530675986, "test_macro_f1": 0.5013695619510978, "test_runtime": 2.4864, "test_samples_per_second": 823.697, "test_steps_per_second": 25.741}]}, "total": {"test_mcc": 19.727644421603124, "test_mcc_se": 5.692092733850409, "test_macro_f1": 58.64409619757743, "test_macro_f1_se": 3.3242963108242334}}, "num_model_parameters": 124647170, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_em": 34.77924089852827, "test_f1": 38.03735814609498}, {"test_em": 34.263565891472865, "test_f1": 38.1380208139154}, {"test_em": 34.8531684698609, "test_f1": 38.24168196008818}, {"test_em": 35.046728971962615, "test_f1": 38.301278424719605}, {"test_em": 29.111969111969113, "test_f1": 33.528707583329435}, {"test_em": 28.604471858134154, "test_f1": 31.633297692004255}, {"test_em": 31.511009870918755, "test_f1": 35.56449907054998}, {"test_em": 34.52288595810706, "test_f1": 38.15889801404889}, {"test_em": 36.0, "test_f1": 40.10097005391124}, {"test_em": 28.88198757763975, "test_f1": 32.101063282737904}]}, "total": {"test_em": 32.75750286085935, "test_em_se": 1.8097372552556414, "test_f1": 36.38057750413999, "test_f1_se": 1.8437447400276126}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_em": 31.44848954298993, "test_f1": 35.53757009525661}, {"test_em": 33.798449612403104, "test_f1": 38.160380031645055}, {"test_em": 32.1483771251932, "test_f1": 36.736143669567056}, {"test_em": 24.221183800623052, "test_f1": 29.192343897846506}, {"test_em": 24.16988416988417, "test_f1": 29.48172096839483}, {"test_em": 36.700077101002314, "test_f1": 40.91270709478721}, {"test_em": 31.58694001518603, "test_f1": 36.098002789131364}, {"test_em": 31.419705197827774, "test_f1": 36.53410312436528}, {"test_em": 33.96078431372549, "test_f1": 38.63005348388704}, {"test_em": 31.75465838509317, "test_f1": 36.33264300836965}]}, "total": {"test_em": 31.120854926392827, "test_em_se": 2.4805621129529056, "test_f1": 35.76156681632506, "test_f1_se": 2.311212487280681}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_em": 37.33539891556933, "test_f1": 41.91465080579529}, {"test_em": 36.97674418604651, "test_f1": 40.877377421386804}, {"test_em": 33.84853168469861, "test_f1": 38.541930146078045}, {"test_em": 39.953271028037385, "test_f1": 44.05666451606963}, {"test_em": 32.664092664092664, "test_f1": 37.629573519008744}, {"test_em": 36.622976098689286, "test_f1": 40.71425268032928}, {"test_em": 38.49658314350797, "test_f1": 43.46548532740994}, {"test_em": 39.48797517455392, "test_f1": 44.030899677984884}, {"test_em": 40.0, "test_f1": 44.59173954936112}, {"test_em": 35.24844720496895, "test_f1": 38.977246453259646}]}, "total": {"test_em": 37.06340201001646, "test_em_se": 1.5756898729958937, "test_f1": 41.47998200966834, "test_f1_se": 1.5684303558704202}}, "num_model_parameters": 124057346, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "birgermoell/roberta-swedish", "results": {"raw": {"test": [{"test_speed": 1.97}, {"test_speed": 1.96}, {"test_speed": 1.94}, {"test_speed": 1.96}, {"test_speed": 1.9}, {"test_speed": 1.93}, {"test_speed": 1.96}, {"test_speed": 1.92}, {"test_speed": 1.89}, {"test_speed": 1.87}]}, "total": {"test_speed": 1.9300000000000002, "test_speed_se": 0.021270992245570275}}, "num_model_parameters": 124645632, "max_sequence_length": 512, "vocabulary_size": 50265}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.3998541235923767, "test_mcc": 0.7519895381913162, "test_macro_f1": 0.7559146625613448, "test_runtime": 10.2402, "test_samples_per_second": 199.996, "test_steps_per_second": 6.25}, {"test_loss": 0.44355326890945435, "test_mcc": 0.7239477959880756, "test_macro_f1": 0.6511269329969721, "test_runtime": 8.1057, "test_samples_per_second": 252.661, "test_steps_per_second": 31.583}, {"test_loss": 0.4618074893951416, "test_mcc": 0.7039286839141945, "test_macro_f1": 0.6369922620600926, "test_runtime": 8.3608, "test_samples_per_second": 244.953, "test_steps_per_second": 30.619}, {"test_loss": 0.3896191418170929, "test_mcc": 0.7387189634531552, "test_macro_f1": 0.7390145283516832, "test_runtime": 7.9856, "test_samples_per_second": 256.463, "test_steps_per_second": 32.058}, {"test_loss": 0.40603119134902954, "test_mcc": 0.745814694795884, "test_macro_f1": 0.7353582794847018, "test_runtime": 8.0011, "test_samples_per_second": 255.966, "test_steps_per_second": 31.996}, {"test_loss": 0.4387092590332031, "test_mcc": 0.7266047867886204, "test_macro_f1": 0.7217096071603036, "test_runtime": 8.3027, "test_samples_per_second": 246.666, "test_steps_per_second": 30.833}, {"test_loss": 0.40106120705604553, "test_mcc": 0.7455682227353502, "test_macro_f1": 0.7475878506860076, "test_runtime": 7.8546, "test_samples_per_second": 260.738, "test_steps_per_second": 32.592}, {"test_loss": 0.4281061291694641, "test_mcc": 0.7130517332629966, "test_macro_f1": 0.70223462163123, "test_runtime": 8.3945, "test_samples_per_second": 243.971, "test_steps_per_second": 30.496}, {"test_loss": 0.4250296950340271, "test_mcc": 0.724341320379601, "test_macro_f1": 0.7069270478312956, "test_runtime": 8.3624, "test_samples_per_second": 244.907, "test_steps_per_second": 30.613}, {"test_loss": 0.41164958477020264, "test_mcc": 0.7387716630868765, "test_macro_f1": 0.7511674040164458, "test_runtime": 8.1565, "test_samples_per_second": 251.089, "test_steps_per_second": 31.386}]}, "total": {"test_mcc": 73.1273740259607, "test_mcc_se": 0.9601748056078049, "test_macro_f1": 71.48033196780077, "test_macro_f1_se": 2.5699305907631}}, "num_model_parameters": 124445187, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.9825146198272705, "test_mcc": 0.3028648929855567, "test_macro_f1": 0.5121232788283067, "test_runtime": 2.9245, "test_samples_per_second": 700.281, "test_steps_per_second": 21.884}, {"test_loss": 1.0050312280654907, "test_mcc": 0.25921848961109695, "test_macro_f1": 0.41319068982862744, "test_runtime": 2.9089, "test_samples_per_second": 704.043, "test_steps_per_second": 22.001}, {"test_loss": 1.0629500150680542, "test_mcc": 0.25744771575099784, "test_macro_f1": 0.5001749835907504, "test_runtime": 2.8893, "test_samples_per_second": 708.821, "test_steps_per_second": 22.151}, {"test_loss": 1.0208868980407715, "test_mcc": 0.2479467391346613, "test_macro_f1": 0.47782179059756386, "test_runtime": 2.8836, "test_samples_per_second": 710.215, "test_steps_per_second": 22.194}, {"test_loss": 0.9679262638092041, "test_mcc": 0.3225515680507236, "test_macro_f1": 0.5423641316561373, "test_runtime": 2.939, "test_samples_per_second": 696.825, "test_steps_per_second": 21.776}, {"test_loss": 1.0842187404632568, "test_mcc": 0.25402874001813813, "test_macro_f1": 0.5004540637566975, "test_runtime": 2.8827, "test_samples_per_second": 710.452, "test_steps_per_second": 22.202}, {"test_loss": 1.0275369882583618, "test_mcc": 0.2408322748862503, "test_macro_f1": 0.45012314487364785, "test_runtime": 2.8825, "test_samples_per_second": 710.489, "test_steps_per_second": 22.203}, {"test_loss": 1.0247317552566528, "test_mcc": 0.22854927647939957, "test_macro_f1": 0.45633584023595325, "test_runtime": 2.9855, "test_samples_per_second": 685.99, "test_steps_per_second": 21.437}, {"test_loss": 0.9735839366912842, "test_mcc": 0.30237671799311944, "test_macro_f1": 0.5316425714874127, "test_runtime": 2.9249, "test_samples_per_second": 700.186, "test_steps_per_second": 21.881}, {"test_loss": 1.0392311811447144, "test_mcc": 0.26181839211431457, "test_macro_f1": 0.4665176965508781, "test_runtime": 2.8651, "test_samples_per_second": 714.808, "test_steps_per_second": 22.338}]}, "total": {"test_mcc": 26.776348070242584, "test_mcc_se": 1.903778561118992, "test_macro_f1": 48.507481914059746, "test_macro_f1_se": 2.467025587909105}}, "num_model_parameters": 124445187, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.918427050113678, "test_mcc": 0.3085403353217307, "test_macro_f1": 0.42841032762154585, "test_runtime": 2.4666, "test_samples_per_second": 830.294, "test_steps_per_second": 25.947}, {"test_loss": 0.8878828883171082, "test_mcc": 0.3128706466178564, "test_macro_f1": 0.4478819170596349, "test_runtime": 2.3427, "test_samples_per_second": 874.207, "test_steps_per_second": 27.319}, {"test_loss": 0.8656481504440308, "test_mcc": 0.33203567201317646, "test_macro_f1": 0.4661452145442309, "test_runtime": 2.318, "test_samples_per_second": 883.526, "test_steps_per_second": 27.61}, {"test_loss": 0.9185004234313965, "test_mcc": 0.2745192958942372, "test_macro_f1": 0.4020562496079763, "test_runtime": 2.3635, "test_samples_per_second": 866.52, "test_steps_per_second": 27.079}, {"test_loss": 0.952484130859375, "test_mcc": 0.25012501573618456, "test_macro_f1": 0.4111833920325115, "test_runtime": 2.4139, "test_samples_per_second": 848.412, "test_steps_per_second": 26.513}, {"test_loss": 0.9527332186698914, "test_mcc": 0.26774297020442156, "test_macro_f1": 0.4087949153197457, "test_runtime": 2.4368, "test_samples_per_second": 840.457, "test_steps_per_second": 26.264}, {"test_loss": 0.9097798466682434, "test_mcc": 0.30578131142551673, "test_macro_f1": 0.46028393655073757, "test_runtime": 2.3517, "test_samples_per_second": 870.858, "test_steps_per_second": 27.214}, {"test_loss": 0.9068423509597778, "test_mcc": 0.26304627696300986, "test_macro_f1": 0.40216601498859555, "test_runtime": 2.4042, "test_samples_per_second": 851.839, "test_steps_per_second": 26.62}, {"test_loss": 0.9018956422805786, "test_mcc": 0.302993431812827, "test_macro_f1": 0.4392615412817022, "test_runtime": 2.4112, "test_samples_per_second": 849.375, "test_steps_per_second": 26.543}, {"test_loss": 0.8857979774475098, "test_mcc": 0.36362717455821914, "test_macro_f1": 0.4588503912702336, "test_runtime": 2.4162, "test_samples_per_second": 847.605, "test_steps_per_second": 26.488}]}, "total": {"test_mcc": 29.812821305471797, "test_mcc_se": 2.153376634930735, "test_macro_f1": 43.25033900276914, "test_macro_f1_se": 1.5680870038635244}}, "num_model_parameters": 124445187, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.05805840343236923, "test_micro_f1": 0.7028948704926359, "test_micro_f1_no_misc": 0.7692307692307693, "test_runtime": 4.5952, "test_samples_per_second": 445.685, "test_steps_per_second": 13.928}, {"test_loss": 0.05121532827615738, "test_micro_f1": 0.7540983606557377, "test_micro_f1_no_misc": 0.8194878201124297, "test_runtime": 4.189, "test_samples_per_second": 488.902, "test_steps_per_second": 15.278}, {"test_loss": 0.047361671924591064, "test_micro_f1": 0.7538847117794487, "test_micro_f1_no_misc": 0.7951002227171493, "test_runtime": 4.0939, "test_samples_per_second": 500.255, "test_steps_per_second": 15.633}, {"test_loss": 0.0570787638425827, "test_micro_f1": 0.724087591240876, "test_micro_f1_no_misc": 0.7851428571428571, "test_runtime": 4.4728, "test_samples_per_second": 457.882, "test_steps_per_second": 14.309}, {"test_loss": 0.05715309455990791, "test_micro_f1": 0.7410838351088467, "test_micro_f1_no_misc": 0.8064516129032259, "test_runtime": 4.4856, "test_samples_per_second": 456.577, "test_steps_per_second": 14.268}, {"test_loss": 0.04877027869224548, "test_micro_f1": 0.7711511789181691, "test_micro_f1_no_misc": 0.8216970998925887, "test_runtime": 3.6788, "test_samples_per_second": 556.706, "test_steps_per_second": 17.397}, {"test_loss": 0.05497638136148453, "test_micro_f1": 0.7219796215429404, "test_micro_f1_no_misc": 0.7917364600781686, "test_runtime": 3.846, "test_samples_per_second": 532.503, "test_steps_per_second": 16.641}, {"test_loss": 0.051540277898311615, "test_micro_f1": 0.7366684991753711, "test_micro_f1_no_misc": 0.7930607187112764, "test_runtime": 4.4668, "test_samples_per_second": 458.496, "test_steps_per_second": 14.328}, {"test_loss": 0.04987158626317978, "test_micro_f1": 0.72552783109405, "test_micro_f1_no_misc": 0.7849223946784922, "test_runtime": 4.2462, "test_samples_per_second": 482.309, "test_steps_per_second": 15.072}, {"test_loss": 0.05334948003292084, "test_micro_f1": 0.7876984126984127, "test_micro_f1_no_misc": 0.8363838047698281, "test_runtime": 4.4799, "test_samples_per_second": 457.152, "test_steps_per_second": 14.286}]}, "total": {"test_micro_f1": 74.19074912706488, "test_micro_f1_se": 1.5703318888576308, "test_micro_f1_no_misc": 80.03213760236785, "test_micro_f1_no_misc_se": 1.2652037397621192}}, "num_model_parameters": 123859209, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.09764087200164795, "test_micro_f1": 0.7158062799361363, "test_micro_f1_no_misc": 0.7504363001745202, "test_runtime": 5.9571, "test_samples_per_second": 343.789, "test_steps_per_second": 10.743}, {"test_loss": 0.09315431118011475, "test_micro_f1": 0.7011428571428572, "test_micro_f1_no_misc": 0.7303754266211604, "test_runtime": 4.8683, "test_samples_per_second": 420.684, "test_steps_per_second": 13.146}, {"test_loss": 0.09791868925094604, "test_micro_f1": 0.7411504424778761, "test_micro_f1_no_misc": 0.7704426106526632, "test_runtime": 5.7335, "test_samples_per_second": 357.202, "test_steps_per_second": 11.163}, {"test_loss": 0.10070885717868805, "test_micro_f1": 0.7381203801478352, "test_micro_f1_no_misc": 0.753922967189729, "test_runtime": 5.5509, "test_samples_per_second": 368.951, "test_steps_per_second": 11.53}, {"test_loss": 0.10447828471660614, "test_micro_f1": 0.7350917431192661, "test_micro_f1_no_misc": 0.7761078998073218, "test_runtime": 5.9451, "test_samples_per_second": 344.485, "test_steps_per_second": 10.765}, {"test_loss": 0.104084312915802, "test_micro_f1": 0.7273241028539136, "test_micro_f1_no_misc": 0.7481315396113603, "test_runtime": 5.7723, "test_samples_per_second": 354.8, "test_steps_per_second": 11.087}, {"test_loss": 0.10714784264564514, "test_micro_f1": 0.7254408060453401, "test_micro_f1_no_misc": 0.748611625323954, "test_runtime": 6.0049, "test_samples_per_second": 341.055, "test_steps_per_second": 10.658}, {"test_loss": 0.09421661496162415, "test_micro_f1": 0.7290723981900453, "test_micro_f1_no_misc": 0.767324816105304, "test_runtime": 6.0878, "test_samples_per_second": 336.412, "test_steps_per_second": 10.513}, {"test_loss": 0.09849628061056137, "test_micro_f1": 0.7114495512646178, "test_micro_f1_no_misc": 0.7238372093023254, "test_runtime": 5.5537, "test_samples_per_second": 368.76, "test_steps_per_second": 11.524}, {"test_loss": 0.09747304022312164, "test_micro_f1": 0.7413745514766767, "test_micro_f1_no_misc": 0.7689981096408317, "test_runtime": 5.1672, "test_samples_per_second": 396.343, "test_steps_per_second": 12.386}]}, "total": {"test_micro_f1": 72.65973112654564, "test_micro_f1_se": 0.8358886063948603, "test_micro_f1_no_misc": 75.38188504429169, "test_micro_f1_no_misc_se": 1.0746048938029935}}, "num_model_parameters": 123859209, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.07895775884389877, "test_micro_f1": 0.7433501078360892, "test_micro_f1_no_misc": 0.7835218093699515, "test_runtime": 4.6189, "test_samples_per_second": 443.392, "test_steps_per_second": 13.856}, {"test_loss": 0.07147392630577087, "test_micro_f1": 0.768939393939394, "test_micro_f1_no_misc": 0.7962884858709406, "test_runtime": 4.613, "test_samples_per_second": 443.963, "test_steps_per_second": 13.874}, {"test_loss": 0.06814658641815186, "test_micro_f1": 0.7549530761209593, "test_micro_f1_no_misc": 0.7893708479874952, "test_runtime": 4.4599, "test_samples_per_second": 459.199, "test_steps_per_second": 14.35}, {"test_loss": 0.07167849689722061, "test_micro_f1": 0.7445766270118964, "test_micro_f1_no_misc": 0.7772142021069061, "test_runtime": 4.5554, "test_samples_per_second": 449.573, "test_steps_per_second": 14.049}, {"test_loss": 0.06330903619527817, "test_micro_f1": 0.7799278451951459, "test_micro_f1_no_misc": 0.8063241106719367, "test_runtime": 4.672, "test_samples_per_second": 438.356, "test_steps_per_second": 13.699}, {"test_loss": 0.06189241260290146, "test_micro_f1": 0.8005521048999309, "test_micro_f1_no_misc": 0.8315992292870905, "test_runtime": 4.6611, "test_samples_per_second": 439.381, "test_steps_per_second": 13.731}, {"test_loss": 0.06710769981145859, "test_micro_f1": 0.7632311977715877, "test_micro_f1_no_misc": 0.7972136222910218, "test_runtime": 4.3963, "test_samples_per_second": 465.843, "test_steps_per_second": 14.558}, {"test_loss": 0.06629719585180283, "test_micro_f1": 0.7918567918567918, "test_micro_f1_no_misc": 0.8230827638572513, "test_runtime": 4.4294, "test_samples_per_second": 462.365, "test_steps_per_second": 14.449}, {"test_loss": 0.06474824249744415, "test_micro_f1": 0.7679773290825364, "test_micro_f1_no_misc": 0.8050813815005954, "test_runtime": 4.436, "test_samples_per_second": 461.68, "test_steps_per_second": 14.428}, {"test_loss": 0.07440736889839172, "test_micro_f1": 0.7455744533148212, "test_micro_f1_no_misc": 0.7868852459016393, "test_runtime": 4.4696, "test_samples_per_second": 458.205, "test_steps_per_second": 14.319}]}, "total": {"test_micro_f1": 76.60938927029154, "test_micro_f1_se": 1.237502067261184, "test_micro_f1_no_misc": 79.96581698844828, "test_micro_f1_no_misc_se": 1.0721854610843249}}, "num_model_parameters": 123859209, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.08231392502784729, "test_micro_f1": 0.7036352433764632, "test_micro_f1_no_misc": 0.7420328748742033, "test_runtime": 4.3314, "test_samples_per_second": 472.825, "test_steps_per_second": 14.776}, {"test_loss": 0.09228752553462982, "test_micro_f1": 0.693913043478261, "test_micro_f1_no_misc": 0.7230136119025007, "test_runtime": 4.3437, "test_samples_per_second": 471.484, "test_steps_per_second": 14.734}, {"test_loss": 0.0834592804312706, "test_micro_f1": 0.673867386738674, "test_micro_f1_no_misc": 0.7193569993302076, "test_runtime": 4.2799, "test_samples_per_second": 478.521, "test_steps_per_second": 14.954}, {"test_loss": 0.0934571772813797, "test_micro_f1": 0.6680929095354523, "test_micro_f1_no_misc": 0.7167396429774334, "test_runtime": 4.3715, "test_samples_per_second": 468.494, "test_steps_per_second": 14.64}, {"test_loss": 0.09665191918611526, "test_micro_f1": 0.685909373060211, "test_micro_f1_no_misc": 0.7298810356892933, "test_runtime": 4.3117, "test_samples_per_second": 474.986, "test_steps_per_second": 14.843}, {"test_loss": 0.09373937547206879, "test_micro_f1": 0.6790865384615385, "test_micro_f1_no_misc": 0.7227885563959223, "test_runtime": 4.2959, "test_samples_per_second": 476.73, "test_steps_per_second": 14.898}, {"test_loss": 0.08503858000040054, "test_micro_f1": 0.6685499058380414, "test_micro_f1_no_misc": 0.7158322056833559, "test_runtime": 4.4227, "test_samples_per_second": 463.069, "test_steps_per_second": 14.471}, {"test_loss": 0.08979727327823639, "test_micro_f1": 0.6563071297989032, "test_micro_f1_no_misc": 0.6960208741030659, "test_runtime": 4.3987, "test_samples_per_second": 465.588, "test_steps_per_second": 14.55}, {"test_loss": 0.09648485481739044, "test_micro_f1": 0.6693276020878108, "test_micro_f1_no_misc": 0.7105352881009206, "test_runtime": 4.1451, "test_samples_per_second": 494.083, "test_steps_per_second": 15.44}, {"test_loss": 0.08429732918739319, "test_micro_f1": 0.7131350681536555, "test_micro_f1_no_misc": 0.7411883182275931, "test_runtime": 4.2003, "test_samples_per_second": 487.581, "test_steps_per_second": 15.237}]}, "total": {"test_micro_f1": 68.11824200529011, "test_micro_f1_se": 1.1044326587138966, "test_micro_f1_no_misc": 72.17389407284497, "test_micro_f1_no_misc_se": 0.8547535713039308}}, "num_model_parameters": 123859209, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.3789999485015869, "test_mcc": 0.7404796019817214, "test_macro_f1": 0.8700770425432053, "test_runtime": 1.854, "test_samples_per_second": 1104.641, "test_steps_per_second": 34.52}, {"test_loss": 0.3740045130252838, "test_mcc": 0.730532499287342, "test_macro_f1": 0.8579647758057862, "test_runtime": 1.9151, "test_samples_per_second": 1069.39, "test_steps_per_second": 33.418}, {"test_loss": 0.3343815207481384, "test_mcc": 0.7537460904837598, "test_macro_f1": 0.8739147959070792, "test_runtime": 1.9135, "test_samples_per_second": 1070.312, "test_steps_per_second": 33.447}, {"test_loss": 0.36290442943573, "test_mcc": 0.7180242150141839, "test_macro_f1": 0.8528246012568789, "test_runtime": 1.923, "test_samples_per_second": 1064.992, "test_steps_per_second": 33.281}, {"test_loss": 0.33752530813217163, "test_mcc": 0.7390560357761058, "test_macro_f1": 0.868357031657903, "test_runtime": 1.9145, "test_samples_per_second": 1069.73, "test_steps_per_second": 33.429}, {"test_loss": 0.42011934518814087, "test_mcc": 0.7044864776709653, "test_macro_f1": 0.8420251328911503, "test_runtime": 1.8767, "test_samples_per_second": 1091.301, "test_steps_per_second": 34.103}, {"test_loss": 0.3752380609512329, "test_mcc": 0.6941624651434452, "test_macro_f1": 0.8418558607643991, "test_runtime": 1.8931, "test_samples_per_second": 1081.808, "test_steps_per_second": 33.807}, {"test_loss": 0.3957163691520691, "test_mcc": 0.7347150459497904, "test_macro_f1": 0.8633386262254312, "test_runtime": 1.9167, "test_samples_per_second": 1068.512, "test_steps_per_second": 33.391}, {"test_loss": 0.37463897466659546, "test_mcc": 0.708769911938334, "test_macro_f1": 0.8518064159970558, "test_runtime": 1.9173, "test_samples_per_second": 1068.169, "test_steps_per_second": 33.38}, {"test_loss": 0.37197166681289673, "test_mcc": 0.7065892096432963, "test_macro_f1": 0.844953452628872, "test_runtime": 1.9153, "test_samples_per_second": 1069.257, "test_steps_per_second": 33.414}]}, "total": {"test_mcc": 72.30561552888945, "test_mcc_se": 1.1999878412406235, "test_macro_f1": 85.6711773567776, "test_macro_f1_se": 0.7361237255319418}}, "num_model_parameters": 124444418, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.6728502511978149, "test_mcc": 0.16168084078055345, "test_macro_f1": 0.5534334127342756, "test_runtime": 2.4458, "test_samples_per_second": 837.362, "test_steps_per_second": 26.168}, {"test_loss": 0.6838874816894531, "test_mcc": 0.1161267145571073, "test_macro_f1": 0.5556878553805946, "test_runtime": 2.5433, "test_samples_per_second": 805.244, "test_steps_per_second": 25.164}, {"test_loss": 0.6973341703414917, "test_mcc": -0.015567507832152442, "test_macro_f1": 0.4881879501187961, "test_runtime": 2.4956, "test_samples_per_second": 820.658, "test_steps_per_second": 25.646}, {"test_loss": 0.6618829965591431, "test_mcc": 0.22553987987026114, "test_macro_f1": 0.6127662871973515, "test_runtime": 2.5943, "test_samples_per_second": 789.42, "test_steps_per_second": 24.669}, {"test_loss": 0.6768583059310913, "test_mcc": 0.14724924899120403, "test_macro_f1": 0.5684808960894591, "test_runtime": 2.5106, "test_samples_per_second": 815.727, "test_steps_per_second": 25.491}, {"test_loss": 0.6553006172180176, "test_mcc": 0.2635258877645216, "test_macro_f1": 0.622731878051027, "test_runtime": 2.4361, "test_samples_per_second": 840.692, "test_steps_per_second": 26.272}, {"test_loss": 0.6590782403945923, "test_mcc": 0.2392443056175671, "test_macro_f1": 0.6195889088413237, "test_runtime": 2.4132, "test_samples_per_second": 848.668, "test_steps_per_second": 26.521}, {"test_loss": 0.6573392152786255, "test_mcc": 0.2866470954683153, "test_macro_f1": 0.6278667383680769, "test_runtime": 2.425, "test_samples_per_second": 844.531, "test_steps_per_second": 26.392}, {"test_loss": 0.6697450876235962, "test_mcc": 0.1805310419708145, "test_macro_f1": 0.5630968929042803, "test_runtime": 2.4459, "test_samples_per_second": 837.309, "test_steps_per_second": 26.166}, {"test_loss": 0.6546312570571899, "test_mcc": 0.27919100988085294, "test_macro_f1": 0.634660027951558, "test_runtime": 2.5074, "test_samples_per_second": 816.782, "test_steps_per_second": 25.524}]}, "total": {"test_mcc": 18.841685170690454, "test_mcc_se": 5.725500368298594, "test_macro_f1": 58.465008476367416, "test_macro_f1_se": 2.897911263787747}}, "num_model_parameters": 124444418, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.6839625835418701, "test_mcc": 0.10795437410798299, "test_macro_f1": 0.51747461148534, "test_runtime": 2.3088, "test_samples_per_second": 887.051, "test_steps_per_second": 27.72}, {"test_loss": 0.6458553075790405, "test_mcc": 0.24835056840923883, "test_macro_f1": 0.5869005084814138, "test_runtime": 2.3183, "test_samples_per_second": 883.406, "test_steps_per_second": 27.606}, {"test_loss": 0.6489367485046387, "test_mcc": 0.2815012877747879, "test_macro_f1": 0.6172059760812296, "test_runtime": 2.3893, "test_samples_per_second": 857.163, "test_steps_per_second": 26.786}, {"test_loss": 0.6471704244613647, "test_mcc": 0.25051507051025756, "test_macro_f1": 0.5926194504874709, "test_runtime": 2.3994, "test_samples_per_second": 853.564, "test_steps_per_second": 26.674}, {"test_loss": 0.6781735420227051, "test_mcc": 0.1706846915168552, "test_macro_f1": 0.5144117148941902, "test_runtime": 2.3788, "test_samples_per_second": 860.953, "test_steps_per_second": 26.905}, {"test_loss": 0.6682248115539551, "test_mcc": 0.23028726084905057, "test_macro_f1": 0.5975975975975976, "test_runtime": 2.2516, "test_samples_per_second": 909.572, "test_steps_per_second": 28.424}, {"test_loss": 0.6514815092086792, "test_mcc": 0.2911790689482521, "test_macro_f1": 0.6396061968826784, "test_runtime": 2.2915, "test_samples_per_second": 893.732, "test_steps_per_second": 27.929}, {"test_loss": 0.6538418531417847, "test_mcc": 0.2665341717839264, "test_macro_f1": 0.6278481500761564, "test_runtime": 2.3256, "test_samples_per_second": 880.615, "test_steps_per_second": 27.519}, {"test_loss": 0.6746392250061035, "test_mcc": 0.2208428155749183, "test_macro_f1": 0.5573482800039525, "test_runtime": 2.2763, "test_samples_per_second": 899.712, "test_steps_per_second": 28.116}, {"test_loss": 0.6517839431762695, "test_mcc": 0.23740813195712837, "test_macro_f1": 0.5976527722560323, "test_runtime": 2.3562, "test_samples_per_second": 869.213, "test_steps_per_second": 27.163}]}, "total": {"test_mcc": 23.052574414323985, "test_mcc_se": 3.3971518916666796, "test_macro_f1": 58.48665258246062, "test_macro_f1_se": 2.6572528651278406}}, "num_model_parameters": 124444418, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_loss": 0.6976433396339417, "test_mcc": 0.06115203423845529, "test_macro_f1": 0.4595898875799723, "test_runtime": 2.4032, "test_samples_per_second": 852.194, "test_steps_per_second": 26.631}, {"test_loss": 0.6671311855316162, "test_mcc": 0.15735874047869264, "test_macro_f1": 0.5726469261784721, "test_runtime": 2.4385, "test_samples_per_second": 839.847, "test_steps_per_second": 26.245}, {"test_loss": 0.667159914970398, "test_mcc": 0.19697243317238686, "test_macro_f1": 0.5653806347558368, "test_runtime": 2.443, "test_samples_per_second": 838.325, "test_steps_per_second": 26.198}, {"test_loss": 0.6607885360717773, "test_mcc": 0.22487699738549052, "test_macro_f1": 0.6112554608061962, "test_runtime": 2.3379, "test_samples_per_second": 875.981, "test_steps_per_second": 27.374}, {"test_loss": 0.655246913433075, "test_mcc": 0.23000167712644926, "test_macro_f1": 0.6149861628017941, "test_runtime": 2.4107, "test_samples_per_second": 849.54, "test_steps_per_second": 26.548}, {"test_loss": 0.6671693325042725, "test_mcc": 0.1875341895705188, "test_macro_f1": 0.5937580061104546, "test_runtime": 2.4261, "test_samples_per_second": 844.146, "test_steps_per_second": 26.38}, {"test_loss": 0.675858736038208, "test_mcc": 0.2159851391229661, "test_macro_f1": 0.5926217819631927, "test_runtime": 2.3868, "test_samples_per_second": 858.068, "test_steps_per_second": 26.815}, {"test_loss": 0.6598849892616272, "test_mcc": 0.20091461180192038, "test_macro_f1": 0.5904426181482222, "test_runtime": 2.417, "test_samples_per_second": 847.321, "test_steps_per_second": 26.479}, {"test_loss": 0.6603564620018005, "test_mcc": 0.18553352070824494, "test_macro_f1": 0.5889763092450663, "test_runtime": 2.3829, "test_samples_per_second": 859.444, "test_steps_per_second": 26.858}, {"test_loss": 0.6870391368865967, "test_mcc": 0.09129948083165787, "test_macro_f1": 0.5163226313255453, "test_runtime": 2.4166, "test_samples_per_second": 847.478, "test_steps_per_second": 26.484}]}, "total": {"test_mcc": 17.516288244367825, "test_mcc_se": 3.511822054617115, "test_macro_f1": 57.059804189147535, "test_macro_f1_se": 2.9707906316476}}, "num_model_parameters": 124444418, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_em": 30.518977536793184, "test_f1": 34.56775274248336}, {"test_em": 35.968992248062015, "test_f1": 40.41715682857953}, {"test_em": 33.46213292117465, "test_f1": 36.99176376192938}, {"test_em": 33.021806853582554, "test_f1": 36.86063509441017}, {"test_em": 29.575289575289574, "test_f1": 33.8857078016742}, {"test_em": 34.6183500385505, "test_f1": 38.54431175169192}, {"test_em": 32.194381169324224, "test_f1": 36.70906298924049}, {"test_em": 34.755624515128005, "test_f1": 39.63958512464083}, {"test_em": 29.568627450980394, "test_f1": 34.297229807502276}, {"test_em": 30.97826086956522, "test_f1": 35.298588225497454}]}, "total": {"test_em": 32.46624431784503, "test_em_se": 1.4054438072255973, "test_f1": 36.72117941276496, "test_f1_se": 1.4038369332567608}}, "num_model_parameters": 123853826, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "scandiqa-no", "task": "question-answering", "dataset_languages": ["nb", "nn"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_em": 34.469403563129354, "test_f1": 39.45272641754357}, {"test_em": 37.44186046511628, "test_f1": 41.82947130400958}, {"test_em": 34.93044822256569, "test_f1": 39.81323243028593}, {"test_em": 34.50155763239876, "test_f1": 39.15607568931153}, {"test_em": 34.20849420849421, "test_f1": 39.52025192421901}, {"test_em": 27.679259830377795, "test_f1": 32.606799073651636}, {"test_em": 36.902050113895214, "test_f1": 41.63584474429879}, {"test_em": 36.61753297129558, "test_f1": 41.570255492496734}, {"test_em": 33.80392156862745, "test_f1": 38.45032050919868}, {"test_em": 35.32608695652174, "test_f1": 40.49828059481221}]}, "total": {"test_em": 34.588061553242206, "test_em_se": 1.6884771040201918, "test_f1": 39.453325817982765, "test_f1_se": 1.6539284755356058}}, "num_model_parameters": 123853826, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "scandiqa-sv", "task": "question-answering", "dataset_languages": ["sv"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_em": 42.835011618900076, "test_f1": 47.90256784191673}, {"test_em": 39.30232558139535, "test_f1": 43.443518411029764}, {"test_em": 40.72642967542504, "test_f1": 45.67872483667961}, {"test_em": 41.43302180685358, "test_f1": 46.369453798494646}, {"test_em": 38.91891891891892, "test_f1": 44.159585027632986}, {"test_em": 41.480339244410175, "test_f1": 45.95714007220549}, {"test_em": 43.50797266514807, "test_f1": 48.195069752101986}, {"test_em": 41.272304111714504, "test_f1": 46.156873524063606}, {"test_em": 42.509803921568626, "test_f1": 48.250102254777424}, {"test_em": 38.19875776397515, "test_f1": 42.787381699294116}]}, "total": {"test_em": 41.01848853083095, "test_em_se": 1.0846211567412942, "test_f1": 45.890041721819635, "test_f1_se": 1.2027359068882186}}, "num_model_parameters": 123853826, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "KBLab/bert-base-swedish-cased-alpha", "results": {"raw": {"test": [{"test_speed": 1.94}, {"test_speed": 1.94}, {"test_speed": 1.88}, {"test_speed": 1.96}, {"test_speed": 1.97}, {"test_speed": 1.94}, {"test_speed": 2.05}, {"test_speed": 1.94}, {"test_speed": 2.02}, {"test_speed": 1.97}]}, "total": {"test_speed": 1.9609999999999999, "test_speed_se": 0.029137494744744266}}, "num_model_parameters": 124442880, "max_sequence_length": 512, "vocabulary_size": 50002}
{"dataset": "swerec", "task": "sentiment-classification", "dataset_languages": ["sv"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.4869183301925659, "test_mcc": 0.6707778773303988, "test_macro_f1": 0.6264213313518691, "test_runtime": 10.0329, "test_samples_per_second": 204.129, "test_steps_per_second": 6.379}, {"test_loss": 0.5361961126327515, "test_mcc": 0.6495788937164577, "test_macro_f1": 0.565917887817621, "test_runtime": 8.2111, "test_samples_per_second": 249.417, "test_steps_per_second": 31.177}, {"test_loss": 0.5789536237716675, "test_mcc": 0.6583167880301005, "test_macro_f1": 0.6656990199544356, "test_runtime": 8.5364, "test_samples_per_second": 239.915, "test_steps_per_second": 29.989}, {"test_loss": 0.47355180978775024, "test_mcc": 0.6907094417648573, "test_macro_f1": 0.6421627333912584, "test_runtime": 7.9991, "test_samples_per_second": 256.029, "test_steps_per_second": 32.004}, {"test_loss": 0.48084181547164917, "test_mcc": 0.690679754059294, "test_macro_f1": 0.6716982483250481, "test_runtime": 7.8178, "test_samples_per_second": 261.965, "test_steps_per_second": 32.746}, {"test_loss": 0.5031908750534058, "test_mcc": 0.6733103828062149, "test_macro_f1": 0.6795615879980538, "test_runtime": 8.1032, "test_samples_per_second": 252.741, "test_steps_per_second": 31.593}, {"test_loss": 0.5045907497406006, "test_mcc": 0.6602807118664257, "test_macro_f1": 0.6128062799514035, "test_runtime": 7.7531, "test_samples_per_second": 264.153, "test_steps_per_second": 33.019}, {"test_loss": 0.5101402997970581, "test_mcc": 0.6708854634361476, "test_macro_f1": 0.6508000735924676, "test_runtime": 8.2833, "test_samples_per_second": 247.246, "test_steps_per_second": 30.906}, {"test_loss": 0.5356360673904419, "test_mcc": 0.6632029324409195, "test_macro_f1": 0.602972094008826, "test_runtime": 8.2556, "test_samples_per_second": 248.074, "test_steps_per_second": 31.009}, {"test_loss": 0.5274404287338257, "test_mcc": 0.6450827463956194, "test_macro_f1": 0.6111114740414103, "test_runtime": 8.0903, "test_samples_per_second": 253.144, "test_steps_per_second": 31.643}]}, "total": {"test_mcc": 66.72824991846436, "test_mcc_se": 0.9490408497109866, "test_macro_f1": 63.291507304323936, "test_macro_f1_se": 2.2124133416349396}}, "num_model_parameters": 125980419, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "angry-tweets", "task": "sentiment-classification", "dataset_languages": ["da"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.9784474968910217, "test_mcc": 0.313826971457828, "test_macro_f1": 0.5264720739820475, "test_runtime": 3.1521, "test_samples_per_second": 649.728, "test_steps_per_second": 20.304}, {"test_loss": 0.9541910290718079, "test_mcc": 0.3074164516757322, "test_macro_f1": 0.5122222462455961, "test_runtime": 3.208, "test_samples_per_second": 638.403, "test_steps_per_second": 19.95}, {"test_loss": 1.0113164186477661, "test_mcc": 0.29136663723590395, "test_macro_f1": 0.5040918871306066, "test_runtime": 3.1851, "test_samples_per_second": 642.989, "test_steps_per_second": 20.093}, {"test_loss": 0.9775598049163818, "test_mcc": 0.29585297848086783, "test_macro_f1": 0.531622913076751, "test_runtime": 3.1811, "test_samples_per_second": 643.808, "test_steps_per_second": 20.119}, {"test_loss": 0.9701602458953857, "test_mcc": 0.3347796763802249, "test_macro_f1": 0.5478071037609354, "test_runtime": 3.1536, "test_samples_per_second": 649.409, "test_steps_per_second": 20.294}, {"test_loss": 0.9984508752822876, "test_mcc": 0.30385676555020547, "test_macro_f1": 0.5194362225227689, "test_runtime": 3.2556, "test_samples_per_second": 629.069, "test_steps_per_second": 19.658}, {"test_loss": 0.9922314882278442, "test_mcc": 0.30085540646758885, "test_macro_f1": 0.5307268178970702, "test_runtime": 3.2174, "test_samples_per_second": 636.539, "test_steps_per_second": 19.892}, {"test_loss": 1.0296711921691895, "test_mcc": 0.22392084616268806, "test_macro_f1": 0.4316872502022701, "test_runtime": 3.3873, "test_samples_per_second": 604.616, "test_steps_per_second": 18.894}, {"test_loss": 0.9783750176429749, "test_mcc": 0.2932448827503458, "test_macro_f1": 0.5030910278509965, "test_runtime": 3.2773, "test_samples_per_second": 624.897, "test_steps_per_second": 19.528}, {"test_loss": 0.9860314130783081, "test_mcc": 0.30991691499752333, "test_macro_f1": 0.5346413605652747, "test_runtime": 3.1411, "test_samples_per_second": 651.991, "test_steps_per_second": 20.375}]}, "total": {"test_mcc": 29.75037531158908, "test_mcc_se": 1.781199941197397, "test_macro_f1": 51.41798903234317, "test_macro_f1_se": 1.9966626274142085}}, "num_model_parameters": 125980419, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.942866325378418, "test_mcc": 0.24019298277282822, "test_macro_f1": 0.3959799633204321, "test_runtime": 2.5344, "test_samples_per_second": 808.074, "test_steps_per_second": 25.252}, {"test_loss": 0.9343260526657104, "test_mcc": 0.27562682764103535, "test_macro_f1": 0.40280018200397016, "test_runtime": 2.3848, "test_samples_per_second": 858.785, "test_steps_per_second": 26.837}, {"test_loss": 0.9882133603096008, "test_mcc": 0.22751929216391606, "test_macro_f1": 0.3808292995375333, "test_runtime": 2.3834, "test_samples_per_second": 859.267, "test_steps_per_second": 26.852}, {"test_loss": 0.9311826229095459, "test_mcc": 0.2688301636747545, "test_macro_f1": 0.40602635358771, "test_runtime": 2.4254, "test_samples_per_second": 844.406, "test_steps_per_second": 26.388}, {"test_loss": 0.9495877623558044, "test_mcc": 0.2205028001791941, "test_macro_f1": 0.3737514790315138, "test_runtime": 2.4717, "test_samples_per_second": 828.587, "test_steps_per_second": 25.893}, {"test_loss": 0.943115234375, "test_mcc": 0.2412032486540023, "test_macro_f1": 0.3951715991589262, "test_runtime": 2.5244, "test_samples_per_second": 811.274, "test_steps_per_second": 25.352}, {"test_loss": 0.9221910834312439, "test_mcc": 0.2955214639304467, "test_macro_f1": 0.45194807990646096, "test_runtime": 2.4273, "test_samples_per_second": 843.743, "test_steps_per_second": 26.367}, {"test_loss": 0.9874412417411804, "test_mcc": 0.217346039379505, "test_macro_f1": 0.3652844730330596, "test_runtime": 2.4639, "test_samples_per_second": 831.187, "test_steps_per_second": 25.975}, {"test_loss": 0.9519587755203247, "test_mcc": 0.24437637271943607, "test_macro_f1": 0.39994815588319543, "test_runtime": 2.5096, "test_samples_per_second": 816.05, "test_steps_per_second": 25.502}, {"test_loss": 0.9940658807754517, "test_mcc": 0.25525023586633894, "test_macro_f1": 0.3931723038865896, "test_runtime": 2.5272, "test_samples_per_second": 810.379, "test_steps_per_second": 25.324}]}, "total": {"test_mcc": 24.863694269814577, "test_mcc_se": 1.5651980357208006, "test_macro_f1": 39.64911889349391, "test_macro_f1_se": 1.4561283251716997}}, "num_model_parameters": 125980419, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "suc3", "task": "named-entity-recognition", "dataset_languages": ["sv"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06410336494445801, "test_micro_f1": 0.6872062663185379, "test_micro_f1_no_misc": 0.7629850746268656, "test_runtime": 4.4639, "test_samples_per_second": 458.794, "test_steps_per_second": 14.337}, {"test_loss": 0.06315726786851883, "test_micro_f1": 0.6889487870619947, "test_micro_f1_no_misc": 0.7483323226197696, "test_runtime": 4.076, "test_samples_per_second": 502.454, "test_steps_per_second": 15.702}, {"test_loss": 0.05414257198572159, "test_micro_f1": 0.6832601268911664, "test_micro_f1_no_misc": 0.7395776935571197, "test_runtime": 4.0877, "test_samples_per_second": 501.018, "test_steps_per_second": 15.657}, {"test_loss": 0.05513933300971985, "test_micro_f1": 0.7011214041930766, "test_micro_f1_no_misc": 0.7562296858071506, "test_runtime": 4.3418, "test_samples_per_second": 471.695, "test_steps_per_second": 14.74}, {"test_loss": 0.058910734951496124, "test_micro_f1": 0.7347703842549203, "test_micro_f1_no_misc": 0.7922350472193075, "test_runtime": 4.3612, "test_samples_per_second": 469.6, "test_steps_per_second": 14.675}, {"test_loss": 0.05540966987609863, "test_micro_f1": 0.7183908045977011, "test_micro_f1_no_misc": 0.7757774140752863, "test_runtime": 3.5768, "test_samples_per_second": 572.574, "test_steps_per_second": 17.893}, {"test_loss": 0.06298255920410156, "test_micro_f1": 0.6891495601173021, "test_micro_f1_no_misc": 0.7402597402597402, "test_runtime": 3.8523, "test_samples_per_second": 531.628, "test_steps_per_second": 16.613}, {"test_loss": 0.05096874386072159, "test_micro_f1": 0.6746594005449592, "test_micro_f1_no_misc": 0.7451227186910006, "test_runtime": 4.3643, "test_samples_per_second": 469.257, "test_steps_per_second": 14.664}, {"test_loss": 0.050055474042892456, "test_micro_f1": 0.7070217917675544, "test_micro_f1_no_misc": 0.7589473684210526, "test_runtime": 4.0712, "test_samples_per_second": 503.046, "test_steps_per_second": 15.72}, {"test_loss": 0.0555022656917572, "test_micro_f1": 0.7039603960396039, "test_micro_f1_no_misc": 0.7583561643835617, "test_runtime": 4.3512, "test_samples_per_second": 470.679, "test_steps_per_second": 14.709}]}, "total": {"test_micro_f1": 69.88488921786818, "test_micro_f1_se": 1.1175837146374694, "test_micro_f1_no_misc": 75.77823229660854, "test_micro_f1_no_misc_se": 1.0184452394612438}}, "num_model_parameters": 125394441, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "dane", "task": "named-entity-recognition", "dataset_languages": ["da"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.08614280819892883, "test_micro_f1": 0.6921883083290222, "test_micro_f1_no_misc": 0.7102177554438861, "test_runtime": 6.0076, "test_samples_per_second": 340.899, "test_steps_per_second": 10.653}, {"test_loss": 0.08534170687198639, "test_micro_f1": 0.6844319775596073, "test_micro_f1_no_misc": 0.7200593251761217, "test_runtime": 5.1332, "test_samples_per_second": 398.968, "test_steps_per_second": 12.468}, {"test_loss": 0.08544085919857025, "test_micro_f1": 0.7091149273447821, "test_micro_f1_no_misc": 0.7434017595307917, "test_runtime": 6.1378, "test_samples_per_second": 333.67, "test_steps_per_second": 10.427}, {"test_loss": 0.08721812069416046, "test_micro_f1": 0.7085452695829095, "test_micro_f1_no_misc": 0.7403581267217632, "test_runtime": 5.9334, "test_samples_per_second": 345.166, "test_steps_per_second": 10.786}, {"test_loss": 0.09245714545249939, "test_micro_f1": 0.6975817923186344, "test_micro_f1_no_misc": 0.7445755614769699, "test_runtime": 6.2465, "test_samples_per_second": 327.866, "test_steps_per_second": 10.246}, {"test_loss": 0.08981136977672577, "test_micro_f1": 0.7216890595009596, "test_micro_f1_no_misc": 0.737417943107221, "test_runtime": 5.9798, "test_samples_per_second": 342.484, "test_steps_per_second": 10.703}, {"test_loss": 0.09055672585964203, "test_micro_f1": 0.7276562088056947, "test_micro_f1_no_misc": 0.750087627059236, "test_runtime": 6.2618, "test_samples_per_second": 327.061, "test_steps_per_second": 10.221}, {"test_loss": 0.08498720824718475, "test_micro_f1": 0.72375533428165, "test_micro_f1_no_misc": 0.7468448403860432, "test_runtime": 6.055, "test_samples_per_second": 338.23, "test_steps_per_second": 10.57}, {"test_loss": 0.09150533378124237, "test_micro_f1": 0.7292340884573895, "test_micro_f1_no_misc": 0.7439824945295405, "test_runtime": 5.9125, "test_samples_per_second": 346.387, "test_steps_per_second": 10.825}, {"test_loss": 0.08651400357484818, "test_micro_f1": 0.7110512129380054, "test_micro_f1_no_misc": 0.736691675598428, "test_runtime": 5.1146, "test_samples_per_second": 400.426, "test_steps_per_second": 12.513}]}, "total": {"test_micro_f1": 71.05248179118655, "test_micro_f1_se": 0.954398474842464, "test_micro_f1_no_misc": 73.73637109030001, "test_micro_f1_no_misc_se": 0.781227342274721}}, "num_model_parameters": 125394441, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06382736563682556, "test_micro_f1": 0.7336823734729493, "test_micro_f1_no_misc": 0.7717348154029376, "test_runtime": 4.9117, "test_samples_per_second": 416.96, "test_steps_per_second": 13.03}, {"test_loss": 0.05274336040019989, "test_micro_f1": 0.7425454545454546, "test_micro_f1_no_misc": 0.77377579927155, "test_runtime": 4.8653, "test_samples_per_second": 420.941, "test_steps_per_second": 13.154}, {"test_loss": 0.05901547148823738, "test_micro_f1": 0.7560137457044672, "test_micro_f1_no_misc": 0.7895745496358758, "test_runtime": 4.7378, "test_samples_per_second": 432.272, "test_steps_per_second": 13.509}, {"test_loss": 0.05741921067237854, "test_micro_f1": 0.7544827586206896, "test_micro_f1_no_misc": 0.7906066536203522, "test_runtime": 4.8721, "test_samples_per_second": 420.352, "test_steps_per_second": 13.136}, {"test_loss": 0.05701204016804695, "test_micro_f1": 0.7776689520078355, "test_micro_f1_no_misc": 0.8154631655725747, "test_runtime": 4.9146, "test_samples_per_second": 416.714, "test_steps_per_second": 13.022}, {"test_loss": 0.05244497209787369, "test_micro_f1": 0.7767646065518405, "test_micro_f1_no_misc": 0.8092529389457717, "test_runtime": 4.9128, "test_samples_per_second": 416.869, "test_steps_per_second": 13.027}, {"test_loss": 0.05728663504123688, "test_micro_f1": 0.7372994652406417, "test_micro_f1_no_misc": 0.7689477557027226, "test_runtime": 4.5471, "test_samples_per_second": 450.398, "test_steps_per_second": 14.075}, {"test_loss": 0.053411535918712616, "test_micro_f1": 0.7755102040816326, "test_micro_f1_no_misc": 0.8029795158286779, "test_runtime": 4.7221, "test_samples_per_second": 433.705, "test_steps_per_second": 13.553}, {"test_loss": 0.05773266404867172, "test_micro_f1": 0.7315202231520224, "test_micro_f1_no_misc": 0.7707203718048025, "test_runtime": 4.6701, "test_samples_per_second": 438.531, "test_steps_per_second": 13.704}, {"test_loss": 0.06304645538330078, "test_micro_f1": 0.7930224756793023, "test_micro_f1_no_misc": 0.8311591502049943, "test_runtime": 4.5333, "test_samples_per_second": 451.769, "test_steps_per_second": 14.118}]}, "total": {"test_micro_f1": 75.78510259056837, "test_micro_f1_se": 1.3465854741397285, "test_micro_f1_no_misc": 79.2421471599026, "test_micro_f1_no_misc_se": 1.3445416564284873}}, "num_model_parameters": 125394441, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.06779387593269348, "test_micro_f1": 0.7036129822412737, "test_micro_f1_no_misc": 0.7332220367278798, "test_runtime": 4.4429, "test_samples_per_second": 460.959, "test_steps_per_second": 14.405}, {"test_loss": 0.07713472098112106, "test_micro_f1": 0.7176797284788645, "test_micro_f1_no_misc": 0.7533084492704445, "test_runtime": 4.5754, "test_samples_per_second": 447.614, "test_steps_per_second": 13.988}, {"test_loss": 0.07818970084190369, "test_micro_f1": 0.6810906935388263, "test_micro_f1_no_misc": 0.7216903268405416, "test_runtime": 4.3918, "test_samples_per_second": 466.321, "test_steps_per_second": 14.573}, {"test_loss": 0.08864749222993851, "test_micro_f1": 0.6773618538324421, "test_micro_f1_no_misc": 0.7221494102228048, "test_runtime": 4.4245, "test_samples_per_second": 462.878, "test_steps_per_second": 14.465}, {"test_loss": 0.08951102197170258, "test_micro_f1": 0.6944777911164466, "test_micro_f1_no_misc": 0.739541160593792, "test_runtime": 4.2337, "test_samples_per_second": 483.735, "test_steps_per_second": 15.117}, {"test_loss": 0.07958411425352097, "test_micro_f1": 0.7029239766081872, "test_micro_f1_no_misc": 0.7491120439134646, "test_runtime": 4.1512, "test_samples_per_second": 493.349, "test_steps_per_second": 15.417}, {"test_loss": 0.07282492518424988, "test_micro_f1": 0.6946401225114855, "test_micro_f1_no_misc": 0.739551989301237, "test_runtime": 4.6038, "test_samples_per_second": 444.853, "test_steps_per_second": 13.902}, {"test_loss": 0.07518765330314636, "test_micro_f1": 0.7244335578689529, "test_micro_f1_no_misc": 0.7557823129251701, "test_runtime": 4.6166, "test_samples_per_second": 443.617, "test_steps_per_second": 13.863}, {"test_loss": 0.08767932653427124, "test_micro_f1": 0.6654423018059382, "test_micro_f1_no_misc": 0.7034297242770678, "test_runtime": 4.2223, "test_samples_per_second": 485.044, "test_steps_per_second": 15.158}, {"test_loss": 0.07286111265420914, "test_micro_f1": 0.7215422276621787, "test_micro_f1_no_misc": 0.7563636363636363, "test_runtime": 4.4038, "test_samples_per_second": 465.051, "test_steps_per_second": 14.533}]}, "total": {"test_micro_f1": 69.83205235664596, "test_micro_f1_se": 1.2206220049942509, "test_micro_f1_no_misc": 73.74151090436038, "test_micro_f1_no_misc_se": 1.0829977662531238}}, "num_model_parameters": 125394441, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scala-sv", "task": "linguistic-acceptability", "dataset_languages": ["sv"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.5022214651107788, "test_mcc": 0.620646511105737, "test_macro_f1": 0.8057855671590488, "test_runtime": 1.8472, "test_samples_per_second": 1108.721, "test_steps_per_second": 34.648}, {"test_loss": 0.5630149841308594, "test_mcc": 0.6192544008824862, "test_macro_f1": 0.7972923385928659, "test_runtime": 1.8926, "test_samples_per_second": 1082.109, "test_steps_per_second": 33.816}, {"test_loss": 0.4802507758140564, "test_mcc": 0.6227802680722196, "test_macro_f1": 0.8001678278008704, "test_runtime": 1.8684, "test_samples_per_second": 1096.138, "test_steps_per_second": 34.254}, {"test_loss": 0.5928884744644165, "test_mcc": 0.6111975551898302, "test_macro_f1": 0.7922985708044685, "test_runtime": 1.8441, "test_samples_per_second": 1110.59, "test_steps_per_second": 34.706}, {"test_loss": 0.500949501991272, "test_mcc": 0.5952212460014786, "test_macro_f1": 0.7900800777938536, "test_runtime": 1.8759, "test_samples_per_second": 1091.76, "test_steps_per_second": 34.118}, {"test_loss": 0.49585872888565063, "test_mcc": 0.5438867532558049, "test_macro_f1": 0.7673064218740862, "test_runtime": 1.869, "test_samples_per_second": 1095.78, "test_steps_per_second": 34.243}, {"test_loss": 0.5047827959060669, "test_mcc": 0.6091989059641679, "test_macro_f1": 0.7937629182531611, "test_runtime": 1.8545, "test_samples_per_second": 1104.333, "test_steps_per_second": 34.51}, {"test_loss": 0.558256983757019, "test_mcc": 0.5888763404563725, "test_macro_f1": 0.7896131754212504, "test_runtime": 1.8845, "test_samples_per_second": 1086.765, "test_steps_per_second": 33.961}, {"test_loss": 0.49904197454452515, "test_mcc": 0.5733521233424602, "test_macro_f1": 0.7810305036159712, "test_runtime": 1.877, "test_samples_per_second": 1091.087, "test_steps_per_second": 34.096}, {"test_loss": 0.5193110108375549, "test_mcc": 0.5798263676826568, "test_macro_f1": 0.7752696962760295, "test_runtime": 1.8751, "test_samples_per_second": 1092.192, "test_steps_per_second": 34.131}]}, "total": {"test_mcc": 59.64240471953215, "test_mcc_se": 1.574849834610839, "test_macro_f1": 78.92607097591606, "test_macro_f1_se": 0.7252626180733258}}, "num_model_parameters": 125979650, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scala-da", "task": "linguistic-acceptability", "dataset_languages": ["da"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6822348833084106, "test_mcc": 0.1477300966140784, "test_macro_f1": 0.5633833526336446, "test_runtime": 2.6681, "test_samples_per_second": 767.587, "test_steps_per_second": 23.987}, {"test_loss": 0.693332314491272, "test_mcc": -0.009108776365375468, "test_macro_f1": 0.39640400965529476, "test_runtime": 2.7635, "test_samples_per_second": 741.082, "test_steps_per_second": 23.159}, {"test_loss": 0.6963201761245728, "test_mcc": 0.07603898242433273, "test_macro_f1": 0.4489239497501013, "test_runtime": 2.7252, "test_samples_per_second": 751.508, "test_steps_per_second": 23.485}, {"test_loss": 0.6716597080230713, "test_mcc": 0.18940938210141134, "test_macro_f1": 0.580048547490408, "test_runtime": 2.831, "test_samples_per_second": 723.428, "test_steps_per_second": 22.607}, {"test_loss": 0.6904834508895874, "test_mcc": 0.08011714551719684, "test_macro_f1": 0.4714299859904989, "test_runtime": 2.7323, "test_samples_per_second": 749.548, "test_steps_per_second": 23.423}, {"test_loss": 0.6710054874420166, "test_mcc": 0.2285565861540259, "test_macro_f1": 0.5756312381091853, "test_runtime": 2.6651, "test_samples_per_second": 768.442, "test_steps_per_second": 24.014}, {"test_loss": 0.6614238619804382, "test_mcc": 0.21035580339145882, "test_macro_f1": 0.6049803745699822, "test_runtime": 2.6201, "test_samples_per_second": 781.653, "test_steps_per_second": 24.427}, {"test_loss": 0.6796966791152954, "test_mcc": 0.14820235168778811, "test_macro_f1": 0.5736563671807466, "test_runtime": 2.6352, "test_samples_per_second": 777.184, "test_steps_per_second": 24.287}, {"test_loss": 0.6894705891609192, "test_mcc": 0.057835866615898845, "test_macro_f1": 0.4930776200296, "test_runtime": 2.6608, "test_samples_per_second": 769.703, "test_steps_per_second": 24.053}, {"test_loss": 0.6907624006271362, "test_mcc": 0.060545217236585486, "test_macro_f1": 0.5280269195121233, "test_runtime": 2.7251, "test_samples_per_second": 751.533, "test_steps_per_second": 23.485}]}, "total": {"test_mcc": 11.896826553774009, "test_mcc_se": 4.797068224002112, "test_macro_f1": 52.35562364921584, "test_macro_f1_se": 4.23574928434686}}, "num_model_parameters": 125979650, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6867395043373108, "test_mcc": 0.09700178187043242, "test_macro_f1": 0.5428354026928688, "test_runtime": 2.4034, "test_samples_per_second": 852.119, "test_steps_per_second": 26.629}, {"test_loss": 0.6809794902801514, "test_mcc": 0.16051476995312888, "test_macro_f1": 0.5793490450518536, "test_runtime": 2.472, "test_samples_per_second": 828.472, "test_steps_per_second": 25.89}, {"test_loss": 0.6534019708633423, "test_mcc": 0.24449806379931668, "test_macro_f1": 0.6177949506498968, "test_runtime": 2.523, "test_samples_per_second": 811.734, "test_steps_per_second": 25.367}, {"test_loss": 0.6641092300415039, "test_mcc": 0.18994680455163734, "test_macro_f1": 0.5787949711219145, "test_runtime": 2.4605, "test_samples_per_second": 832.35, "test_steps_per_second": 26.011}, {"test_loss": 0.6669355630874634, "test_mcc": 0.17701628649552933, "test_macro_f1": 0.5702921934568679, "test_runtime": 2.4544, "test_samples_per_second": 834.404, "test_steps_per_second": 26.075}, {"test_loss": 0.688265860080719, "test_mcc": 0.1117192738302652, "test_macro_f1": 0.5358720742680272, "test_runtime": 2.427, "test_samples_per_second": 843.839, "test_steps_per_second": 26.37}, {"test_loss": 0.6637381911277771, "test_mcc": 0.22978806181531158, "test_macro_f1": 0.6105885585993471, "test_runtime": 2.3792, "test_samples_per_second": 860.78, "test_steps_per_second": 26.899}, {"test_loss": 0.6784355044364929, "test_mcc": 0.17551059100052677, "test_macro_f1": 0.586564256820626, "test_runtime": 2.4219, "test_samples_per_second": 845.623, "test_steps_per_second": 26.426}, {"test_loss": 0.6888504028320312, "test_mcc": 0.11138074631878325, "test_macro_f1": 0.5513905184921718, "test_runtime": 2.373, "test_samples_per_second": 863.06, "test_steps_per_second": 26.971}, {"test_loss": 0.6833428740501404, "test_mcc": 0.23256796178198919, "test_macro_f1": 0.5788378171745596, "test_runtime": 2.4591, "test_samples_per_second": 832.812, "test_steps_per_second": 26.025}]}, "total": {"test_mcc": 17.299443414169208, "test_mcc_se": 3.310711251421932, "test_macro_f1": 57.52319788328133, "test_macro_f1_se": 1.655954368297169}}, "num_model_parameters": 125979650, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_loss": 0.6957492232322693, "test_mcc": 0.03232649133554415, "test_macro_f1": 0.4884322040173569, "test_runtime": 2.4443, "test_samples_per_second": 837.86, "test_steps_per_second": 26.183}, {"test_loss": 0.6913812160491943, "test_mcc": 0.07339692992772891, "test_macro_f1": 0.47647766111547674, "test_runtime": 2.4826, "test_samples_per_second": 824.948, "test_steps_per_second": 25.78}, {"test_loss": 0.6888128519058228, "test_mcc": 0.07050821506799465, "test_macro_f1": 0.4406249625105633, "test_runtime": 2.5104, "test_samples_per_second": 815.794, "test_steps_per_second": 25.494}, {"test_loss": 0.6682671308517456, "test_mcc": 0.2200425408430011, "test_macro_f1": 0.5939750446690338, "test_runtime": 2.4035, "test_samples_per_second": 852.088, "test_steps_per_second": 26.628}, {"test_loss": 0.6929000020027161, "test_mcc": 0.026107273133716642, "test_macro_f1": 0.500557845570619, "test_runtime": 2.4253, "test_samples_per_second": 844.415, "test_steps_per_second": 26.388}, {"test_loss": 0.675960898399353, "test_mcc": 0.1705357625255583, "test_macro_f1": 0.5807864600936052, "test_runtime": 2.4812, "test_samples_per_second": 825.41, "test_steps_per_second": 25.794}, {"test_loss": 0.6927118897438049, "test_mcc": 0.0043407638671892216, "test_macro_f1": 0.4409171589652289, "test_runtime": 2.4256, "test_samples_per_second": 844.326, "test_steps_per_second": 26.385}, {"test_loss": 0.6665140390396118, "test_mcc": 0.17055566544591833, "test_macro_f1": 0.581583269573841, "test_runtime": 2.4554, "test_samples_per_second": 834.097, "test_steps_per_second": 26.066}, {"test_loss": 0.6782690286636353, "test_mcc": 0.13481023404435377, "test_macro_f1": 0.5657466476346705, "test_runtime": 2.4315, "test_samples_per_second": 842.263, "test_steps_per_second": 26.321}, {"test_loss": 0.689089298248291, "test_mcc": 0.07641553326499656, "test_macro_f1": 0.5374466811433996, "test_runtime": 2.4877, "test_samples_per_second": 823.262, "test_steps_per_second": 25.727}]}, "total": {"test_mcc": 9.790394094560014, "test_mcc_se": 4.472145132570367, "test_macro_f1": 52.06547935293795, "test_macro_f1_se": 3.6479096084169145}}, "num_model_parameters": 125979650, "max_sequence_length": 512, "vocabulary_size": 52000}
{"dataset": "scandiqa-da", "task": "question-answering", "dataset_languages": ["da"], "model": "KBLab/roberta-base-swedish-cased", "results": {"raw": {"test": [{"test_em": 24.786986831913246, "test_f1": 29.13997475059654}, {"test_em": 23.25581395348837, "test_f1": 27.929977906164112}, {"test_em": 27.897990726429676, "test_f1": 31.493074732202942}, {"test_em": 21.339563862928348, "test_f1": 27.039581566181823}, {"test_em": 32.12355212355212, "test_f1": 36.149227976295656}, {"test_em": 21.2798766383963, "test_f1": 25.591352694574944}, {"test_em": 24.145785876993166, "test_f1": 28.57679596240709}, {"test_em": 32.35065942591156, "test_f1": 36.70206082139519}, {"test_em": 16.784313725490197, "test_f1": 20.892837903309594}, {"test_em": 31.75465838509317, "test_f1": 36.27898057576394}]}, "total": {"test_em": 25.571920155019615, "test_em_se": 3.293233421898334, "test_f1": 29.97938648888918, "test_f1_se": 3.217771387132563}}, "num_model_parameters": 125389826, "max_sequence_length": 512, "vocabulary_size": 52000}