model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,germeval,sb10k,scala_de,germanquad
deepset/gbert-large,335,31,512,5463,1.04,82.15,66.16,77.48,32.63
google/rembert,575,250,256,3355,1.17,79.32,59.69,72.25,34.48
FacebookAI/xlm-roberta-large,559,250,512,6663,1.25,80.27,58.44,62.12,32.23
microsoft/mdeberta-v3-base,278,251,512,9237,1.31,81.05,59.5,71.84,26.25
sentence-transformers/use-cmlm-multilingual,470,501,512,13305,1.39,78.99,59.17,61.58,30.42
deepset/gbert-base,109,31,512,16043,1.6,81.33,57.77,66.13,16.68
setu4993/LaBSE,470,501,512,13386,1.62,78.94,58.2,53.53,23.55
dbmdz/bert-base-german-cased,109,31,512,11844,1.71,80.9,53.44,67.08,14.49
dbmdz/bert-base-german-uncased,109,31,512,11438,1.74,79.93,56.26,68.22,13.87
ZurichNLP/unsup-simcse-xlm-roberta-base,277,250,512,10471,1.75,76.7,57.27,52.46,18.24
"gpt-3.5-turbo-0613 (few-shot, val)",-1,100,4095,1344,1.82,61.5,55.5,38.96,30.2
facebook/xlm-v-base,778,902,512,13135,1.88,73.96,57.43,35.0,20.81
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242,32,8192,2549,1.92,64.81,59.6,27.06,25.22
microsoft/infoxlm-base,277,250,512,14918,2.08,79.97,58.3,11.85,19.63
cardiffnlp/twitter-xlm-roberta-base,277,250,512,14837,2.13,75.55,63.32,49.39,1.43
mistralai/Mistral-7B-v0.1 (few-shot),7242,32,32768,2657,2.13,55.37,54.27,23.12,22.94
Twitter/twhin-bert-large,560,250,512,5299,2.16,74.8,55.04,29.15,11.93
microsoft/xlm-align-base,277,250,512,14744,2.17,79.38,58.58,15.34,16.58
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),-1,32,4096,7778,2.19,56.71,49.77,19.92,27.87
jhu-clsp/bernice,277,250,128,5567,2.2,72.25,62.0,48.1,0.0
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242,32,32768,5443,2.23,51.79,47.27,22.15,24.3
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242,32,32768,2538,2.23,55.15,47.85,24.29,23.98
01-ai/Yi-6B (few-shot),6061,64,4096,2786,2.3,44.97,53.14,7.64,30.12
clips/mfaq,277,250,128,5591,2.3,76.68,59.51,32.54,1.53
sentence-transformers/paraphrase-xlm-r-multilingual-v1,277,250,512,14994,2.36,71.8,57.71,38.75,0.3
meta-llama/Llama-2-7b-chat-hf (few-shot),6738,32,4096,2643,2.37,50.0,46.54,15.3,25.57
dbmdz/bert-base-historic-multilingual-cased,110,32,512,15165,2.41,67.24,41.36,48.21,7.75
Rijgersberg/GEITje-7B (few-shot),7242,32,32768,10401,2.44,39.09,47.83,10.31,26.13
sentence-transformers/stsb-xlm-r-multilingual,277,250,512,15040,2.45,69.4,52.68,34.44,0.73
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118,250,512,17428,2.51,65.62,55.6,32.22,0.64
AI-Sweden-Models/roberta-large-1160k,354,50,512,5741,2.55,68.39,45.91,2.79,18.83
AI-Sweden-Models/roberta-large-1350k,354,50,512,5744,2.57,67.24,45.84,2.28,18.17
meta-llama/Llama-2-7b-hf (few-shot),6738,32,4096,2648,2.59,41.88,50.17,15.82,18.35
DiscoResearch/DiscoLM_German_7b_v1 (few-shot),7242,32,32768,1972,2.62,2.21,48.67,8.72,34.07
"mayflowergmbh/Wiedervereinigung-7b-dpo (few-shot, val)",7242,32,32768,2374,2.69,6.74,51.92,29.06,15.01
sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking,135,120,512,26151,2.72,66.75,49.61,17.6,0.36
sentence-transformers/distiluse-base-multilingual-cased-v1,135,120,512,26344,2.78,53.77,53.53,20.15,0.58
sentence-transformers/distiluse-base-multilingual-cased-v2,135,120,512,17807,2.79,53.13,51.94,17.74,0.06
Qwen/Qwen1.5-4B-Chat (few-shot),3950,152,32768,4347,2.8,0.33,41.52,12.78,29.35
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918,64,2048,4880,2.99,35.78,34.13,2.18,17.99
Qwen/Qwen1.5-4B (few-shot),3950,152,32768,3248,2.99,0.19,39.91,3.27,27.55
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),-1,32,4096,10890,3.04,27.22,33.54,0.45,20.4
google/gemma-2b (few-shot),2506,256,8192,6087,3.11,1.08,44.96,0.77,17.92
google/gemma-2b-it (few-shot),2506,256,8192,6471,3.24,5.27,28.54,1.15,23.48
Qwen/Qwen1.5-1.8B (few-shot),1837,152,32768,5666,3.28,0.03,38.3,0.39,16.67
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837,152,32768,8304,3.32,1.45,36.21,3.12,16.36
3ebdola/Dialectal-Arabic-XLM-R-Base,277,250,512,15177,3.4,34.18,34.81,1.25,0.46
Qwen/Qwen1.5-0.5B-Chat (few-shot),620,152,32768,11740,3.76,3.95,9.31,1.11,13.61
Qwen/Qwen1.5-0.5B (few-shot),620,152,32768,11371,3.77,5.85,10.64,0.33,11.81
allenai/OLMo-1B (few-shot),1177,50,2080,8536,3.88,7.27,21.03,0.13,0.71
fresh-electra-small,13,31,512,7219,4.06,9.42,9.76,-0.18,0.0
RJuro/kanelsnegl-v0.1 (few-shot),7242,32,512,9757,4.3,0.0,0.0,0.0,0.0
ai-forever/mGPT (few-shot),-1,100,1024,13551,4.3,0.3,0.29,-0.11,0.0
