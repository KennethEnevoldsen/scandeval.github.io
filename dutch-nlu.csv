model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,conll_nl,dutch_social,scala_nl,squad_nl
intfloat/multilingual-e5-large,559,250,512,6732,1.34,82.31,32.64,58.51,45.32
setu4993/LaBSE,470,501,512,13386,1.42,82.02,33.99,60.77,41.55
gpt-4-1106-preview (few-shot),-1,100,128000,573,1.67,66.44,15.05,74.01,57.81
DTAI-KULeuven/robbert-2022-dutch-base,118,43,512,11307,1.68,79.84,24.58,68.76,27.63
pdelobelle/robbert-v2-dutch-base,116,40,512,15481,1.72,78.3,26.68,63.83,28.34
ZurichNLP/unsup-simcse-xlm-roberta-base,277,250,512,10471,1.75,78.45,22.67,54.92,31.82
intfloat/multilingual-e5-base,277,250,512,14965,1.84,79.12,27.67,39.28,35.71
FacebookAI/xlm-roberta-large,559,250,512,6663,1.95,83.49,8.82,64.8,50.72
DTAI-KULeuven/robbertje-1-gb-non-shuffled,74,40,512,21007,1.98,74.5,32.23,54.57,6.31
DTAI-KULeuven/robbert-2023-dutch-base,124,50,512,11230,2.0,82.22,28.2,55.12,9.74
microsoft/mdeberta-v3-base,278,251,512,9237,2.0,84.47,5.16,71.23,46.43
DTAI-KULeuven/robbertje-1-gb-merged,74,40,512,21027,2.06,72.51,32.26,50.0,5.97
jhu-clsp/bernice,277,250,128,5567,2.07,78.74,22.58,55.39,5.95
"gpt-3.5-turbo-0613 (few-shot, val)",-1,100,4095,921,2.08,68.96,8.81,58.95,55.57
DTAI-KULeuven/robbertje-1-gb-shuffled,74,40,512,20616,2.12,73.55,26.02,57.03,6.64
DTAI-KULeuven/robbert-2023-dutch-large,354,50,512,5444,2.13,81.05,16.35,65.18,11.44
cardiffnlp/twitter-xlm-roberta-base,277,250,512,14837,2.27,77.15,18.78,56.72,14.61
sentence-transformers/paraphrase-xlm-r-multilingual-v1,277,250,512,14994,2.3,70.59,21.37,45.86,5.2
microsoft/xlm-align-base,277,250,512,14744,2.35,78.85,11.8,14.56,42.08
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242,32,32768,2538,2.41,55.56,12.37,21.5,50.77
DTAI-KULeuven/robbertje-1-gb-bort,45,40,512,31087,2.42,66.74,24.93,37.19,5.23
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242,32,8192,2549,2.46,63.53,11.25,27.76,50.88
mistralai/Mistral-7B-v0.1 (few-shot),7242,32,32768,2657,2.5,58.15,7.94,25.41,62.56
"mlabonne/AlphaMonarch-7B (few-shot, val)",7242,32,8192,5340,2.53,64.71,11.14,25.22,46.34
BramVanroy/GEITje-7B-ultra (few-shot),7242,32,8192,2475,2.57,42.25,12.78,18.23,53.41
sentence-transformers/quora-distilbert-multilingual,135,120,512,26458,2.59,67.89,23.25,21.36,4.5
Geotrend/distilbert-base-25lang-cased,108,85,512,26099,2.62,75.02,7.45,45.28,20.18
Rijgersberg/GEITje-7B (few-shot),7242,32,32768,10401,2.65,47.53,4.36,30.67,56.55
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),-1,32,4096,7778,2.65,57.66,8.41,16.93,56.29
occiglot/occiglot-7b-eu5-instruct (few-shot),7242,32,32768,2088,2.66,48.14,7.78,16.23,63.09
Twitter/twhin-bert-base,278,250,512,11514,2.7,74.03,9.53,39.12,7.71
meta-llama/Llama-2-7b-chat-hf (few-shot),6738,32,4096,2643,2.72,50.23,10.07,14.73,53.42
EuropeanParliament/EUBERT,93,66,512,20070,2.75,49.54,14.86,27.9,20.65
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242,32,32768,5443,2.75,52.72,7.91,18.14,52.75
meta-llama/Llama-2-7b-hf (few-shot),6738,32,4096,2648,2.78,40.49,7.1,18.66,59.92
occiglot/occiglot-7b-eu5 (few-shot),7242,32,32768,2219,2.78,42.51,7.41,13.04,59.28
Twitter/twhin-bert-large,560,250,512,5299,2.82,77.35,6.55,18.25,28.37
Qwen/Qwen1.5-4B-Chat (few-shot),3950,152,32768,4347,2.84,22.82,14.68,4.07,55.18
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918,64,2048,4880,2.88,35.3,15.67,1.76,45.05
Qwen/Qwen1.5-4B (few-shot),3950,152,32768,3248,2.93,24.85,12.55,0.23,51.3
01-ai/Yi-6B (few-shot),6061,64,4096,2786,2.95,46.34,8.96,0.88,55.33
AI-Sweden-Models/roberta-large-1350k,354,50,512,5744,2.96,73.03,3.65,2.0,42.85
AI-Sweden-Models/roberta-large-1160k,354,50,512,5741,3.01,70.92,3.5,2.06,41.4
google/gemma-2b-it (few-shot),2506,256,8192,6471,3.09,38.85,11.25,-2.27,45.95
alpindale/Mistral-7B-v0.2-hf (few-shot),7242,32,32768,3467,3.1,5.83,7.04,23.83,61.88
sentence-transformers/distiluse-base-multilingual-cased-v1,135,120,512,26344,3.11,58.67,17.82,9.27,2.17
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),-1,32,4096,10890,3.17,35.49,11.36,2.52,37.56
sentence-transformers/distiluse-base-multilingual-cased,135,120,512,19206,3.2,56.98,9.66,19.37,3.11
google/gemma-2b (few-shot),2506,256,8192,6087,3.23,16.9,9.95,0.41,49.15
allenai/OLMo-7B (few-shot),6888,50,2176,5403,3.24,37.37,9.55,0.05,34.81
jpostma/DagoBERT,116,40,512,11241,3.32,42.28,8.01,31.21,3.65
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837,152,32768,8304,3.45,23.44,6.82,4.11,33.16
Qwen/Qwen1.5-0.5B-Chat (few-shot),620,152,32768,11740,3.55,18.66,8.59,0.34,26.74
allenai/OLMo-7B-Twin-2T (few-shot),6888,50,2176,5484,3.55,18.7,3.7,2.19,38.08
3ebdola/Dialectal-Arabic-XLM-R-Base,277,250,512,15177,3.57,44.46,8.39,2.07,4.3
Qwen/Qwen1.5-1.8B (few-shot),1837,152,32768,5666,3.58,11.66,5.2,2.89,34.6
dbmdz/bert-tiny-historic-multilingual-cased,5,32,512,78027,3.61,41.38,8.45,1.55,4.4
Qwen/Qwen1.5-0.5B (few-shot),620,152,32768,11371,3.64,28.3,4.54,-0.42,20.81
allenai/OLMo-1B (few-shot),1177,50,2176,8536,3.86,22.58,4.92,-1.27,6.64
fresh-xlm-roberta-base,277,250,512,1319,4.17,13.09,0.92,1.93,0.26
RJuro/kanelsnegl-v0.1 (few-shot),7242,32,512,9757,4.35,0.0,0.95,0.0,0.0
ai-forever/mGPT (few-shot),-1,100,1024,13551,4.37,0.11,-0.67,-0.97,0.29
