model_id,num_model_parameters,vocabulary_size,max_sequence_length,commercially_licensed,merge,speed,rank,da_rank,no_rank,sv_rank,dansk,angry_tweets,scala_da,scandiqa_da,norne_nb,norne_nn,norec,scala_nb,scala_nn,norquad,suc3,swerec,scala_sv,scandiqa_sv
AI-Sweden-Models/roberta-large-1160k,355,50,512,True,False,5741,1.31,1.34,1.34,1.25,74.16,51.2,73.87,49.34,92.01,87.17,60.11,72.85,65.56,60.38,82.65,77.25,77.9,49.64
gpt-4-0613 (val),-1,100,8192,True,False,597,1.31,1.33,1.45,1.14,64.94,59.97,71.56,49.82,81.16,75.75,72.72,77.3,57.18,49.93,76.86,79.19,80.93,56.5
ltg/norbert3-large,354,50,508,True,False,5048,1.33,1.45,1.13,1.41,73.62,48.29,71.55,48.59,93.12,89.39,64.62,77.97,76.3,66.03,79.01,75.32,69.11,48.88
AI-Sweden-Models/roberta-large-1350k,355,50,512,True,False,5744,1.34,1.4,1.36,1.27,75.22,49.94,72.59,48.97,92.49,87.22,58.77,76.3,64.11,60.69,82.97,77.37,73.81,49.5
danish-foundation-models/encoder-large-v1,355,50,512,True,False,6671,1.47,1.33,1.55,1.53,74.6,51.42,76.11,47.42,88.66,84.59,55.59,71.43,53.3,57.38,74.18,75.11,64.11,46.79
KennethEnevoldsen/dfm-sentence-encoder-large-1,355,50,512,True,False,6245,1.48,1.34,1.5,1.59,74.99,53.85,75.71,44.85,86.39,83.22,59.61,67.88,62.44,55.69,71.65,74.92,63.43,46.2
KennethEnevoldsen/dfm-sentence-encoder-large-2,355,50,512,True,False,6569,1.5,1.34,1.54,1.63,75.3,55.12,76.34,45.15,86.78,83.28,58.73,70.73,59.58,56.04,71.86,74.67,62.77,44.77
google/rembert,576,250,256,True,False,3355,1.53,1.57,1.59,1.42,70.19,50.19,69.72,39.85,88.7,86.11,54.19,69.83,54.84,58.18,78.23,75.99,72.17,46.0
intfloat/multilingual-e5-large,560,250,512,True,False,6732,1.56,1.58,1.69,1.42,69.5,55.07,57.67,46.71,89.86,84.32,61.52,62.34,34.88,53.01,80.36,79.65,63.15,46.99
NbAiLab/nb-roberta-base-scandi,278,250,512,True,False,15079,1.59,1.66,1.55,1.57,73.28,52.08,67.99,32.39,92.24,87.58,59.98,70.18,70.81,44.27,80.02,76.21,71.92,33.8
microsoft/mdeberta-v3-base,279,251,512,True,False,9237,1.6,1.71,1.65,1.43,72.9,43.38,67.05,42.15,91.9,86.81,53.69,70.55,61.21,48.82,78.84,75.24,72.3,44.74
NbAiLab/nb-roberta-base-scandi-1e4,278,250,512,True,False,15074,1.62,1.76,1.52,1.59,72.16,51.7,62.03,29.95,92.09,86.85,59.84,73.33,71.06,43.67,79.9,76.2,73.62,32.38
ltg/norbert3-base,124,50,508,True,False,11405,1.62,1.85,1.34,1.68,73.26,43.94,51.62,40.7,92.36,88.49,59.73,74.4,68.85,57.67,78.21,71.05,56.02,42.52
FacebookAI/xlm-roberta-large,560,250,512,True,False,6663,1.65,1.67,1.74,1.55,72.74,48.33,57.3,43.57,91.66,86.19,50.25,55.51,43.89,57.57,80.33,76.63,49.72,46.64
sentence-transformers/use-cmlm-multilingual,471,501,512,True,False,13305,1.65,1.79,1.68,1.49,69.17,48.03,55.31,42.34,90.08,86.04,56.35,59.38,46.54,55.05,80.05,75.09,61.83,45.69
KennethEnevoldsen/dfm-sentence-encoder-medium-3,178,120,512,True,False,14050,1.67,1.68,1.68,1.65,71.21,47.55,68.72,38.33,91.17,87.3,59.1,74.32,72.94,34.06,81.35,71.16,63.89,37.18
vesteinn/ScandiBERT-no-faroese,124,50,512,True,False,15436,1.68,1.8,1.66,1.57,69.79,47.73,68.28,31.9,91.09,85.72,50.9,69.34,66.24,48.45,79.08,72.53,73.01,36.92
NbAiLab/nb-bert-base,178,120,512,True,False,14050,1.69,1.76,1.63,1.69,70.36,46.32,66.41,36.42,93.01,88.43,60.84,73.89,72.1,33.01,80.38,71.21,64.03,35.33
gpt-3.5-turbo-0613,-1,100,4096,True,False,837,1.72,1.63,2.05,1.49,59.4,51.8,54.22,56.55,74.92,75.34,57.64,49.93,34.22,44.39,71.43,77.5,55.99,55.46
gpt-3.5-turbo-0613 (val),-1,100,4095,True,False,921,1.73,1.69,2.0,1.49,59.61,50.54,57.57,51.09,77.7,73.92,58.88,54.29,32.82,46.44,73.04,72.77,58.06,57.59
vesteinn/FoBERT,124,50,512,True,False,15623,1.73,1.79,1.72,1.67,69.65,49.18,65.45,32.4,90.65,84.88,52.44,68.77,65.4,43.13,78.58,73.41,71.14,31.62
pere/roberta-debug-8,278,250,512,True,False,15103,1.74,1.79,1.71,1.71,71.34,49.77,64.31,31.86,91.16,84.75,55.25,68.03,66.9,41.65,74.48,74.58,69.07,31.66
pere/roberta-base-exp-8,278,250,512,True,False,15112,1.75,1.83,1.62,1.79,68.77,49.66,60.13,32.6,88.99,82.99,57.37,69.92,70.05,41.98,73.44,73.63,58.91,32.39
setu4993/LaBSE,471,501,512,True,False,13386,1.75,1.8,1.85,1.61,71.24,46.5,52.92,40.08,90.58,85.21,54.26,59.44,49.3,46.42,77.78,73.58,60.36,41.71
pere/roberta-debug-32,278,250,512,True,False,14958,1.79,1.82,1.84,1.72,68.46,50.48,64.34,30.3,89.07,83.27,53.23,70.06,66.81,34.17,72.25,75.04,70.16,31.89
pere/roberta-base-exp-32,278,250,512,True,False,15081,1.8,1.96,1.67,1.78,71.9,51.33,44.45,32.51,91.66,87.74,57.43,63.31,62.79,41.05,79.75,74.73,53.55,32.2
AI-Sweden-Models/bert-large-nordic-pile-1M-steps,369,64,512,True,False,6571,1.91,2.11,2.22,1.41,67.4,41.53,41.62,37.3,87.5,80.57,47.11,52.62,25.06,38.4,80.65,77.43,76.56,41.54
pere/roberta-base-exp-32B,278,250,512,True,False,15103,1.96,1.94,2.01,1.93,71.81,47.83,54.99,29.92,90.6,86.76,52.19,54.98,58.33,29.17,77.97,73.27,47.19,31.07
vesteinn/DanskBERT,124,50,512,True,False,15749,1.98,1.52,2.22,2.19,72.55,52.86,75.2,37.65,86.82,79.91,47.84,51.99,30.57,36.75,72.33,67.77,33.79,32.71
Nexusflow/Starling-LM-7B-beta,7242,32,8192,False,False,5876,2.03,1.94,2.34,1.82,53.2,51.75,32.72,56.44,66.22,64.14,55.48,26.13,17.32,49.75,60.38,77.49,29.32,56.79
ltg/norbert3-small,41,50,508,True,False,13515,2.03,2.15,1.74,2.2,67.89,39.34,50.9,34.82,90.02,86.52,51.36,67.29,56.67,48.63,74.22,63.8,37.77,31.45
KBLab/megatron-bert-large-swedish-cased-165k,370,64,512,True,False,7138,2.06,2.35,2.5,1.32,58.5,41.02,27.1,39.99,85.99,79.47,39.53,27.39,23.56,39.01,81.05,78.0,76.79,45.71
upstage/SOLAR-10.7B-v1.0,10732,32,4096,True,False,3780,2.1,2.09,2.35,1.86,58.03,46.63,15.09,62.15,68.11,68.19,55.33,10.15,7.51,55.33,59.65,77.48,16.94,62.65
cardiffnlp/twitter-xlm-roberta-base,278,250,512,True,False,14837,2.11,2.14,2.28,1.9,70.1,45.3,51.74,22.01,87.7,81.41,48.34,55.3,37.46,24.49,72.49,70.69,56.6,31.89
RJuro/munin-neuralbeagle-7b (val),7242,32,32768,False,True,2493,2.12,1.99,2.48,1.88,51.44,54.91,22.77,56.51,61.18,65.16,55.61,20.84,9.12,42.92,62.96,77.13,15.73,58.43
AI-Nordics/bert-large-swedish-cased,335,31,512,True,False,7199,2.13,2.42,2.53,1.43,60.66,38.46,32.29,37.68,83.32,77.97,38.44,37.54,23.1,39.97,78.61,77.47,72.87,43.11
KBLab/megatron-bert-large-swedish-cased-110k,370,64,512,True,False,7075,2.13,2.41,2.64,1.34,60.18,39.2,26.68,39.34,84.03,77.98,39.15,21.39,17.1,35.32,80.39,78.45,76.28,44.56
timpal0l/BeagleCatMunin (val),7242,32,32768,False,True,2495,2.17,2.04,2.59,1.88,47.62,54.73,21.8,57.26,54.04,62.21,54.74,14.51,5.38,42.83,50.53,77.37,27.84,59.98
merge-crew/da-sv-dare-ties-density-0.9 (val),7242,32,32768,True,True,2443,2.2,2.12,2.57,1.92,45.61,53.73,17.08,56.67,48.24,61.5,49.4,24.12,13.2,47.93,46.61,76.38,34.16,58.77
merge-crew/da-sv-slerp (val),7242,32,32768,True,True,2467,2.2,2.04,2.68,1.89,45.94,51.75,28.04,57.65,49.67,61.11,56.07,3.81,-1.29,44.98,46.57,76.53,33.43,59.87
mhenrichsen/danskgpt-chat-v2.1,-1,32,32768,True,False,5085,2.2,1.93,2.65,2.03,51.08,54.69,30.95,56.56,62.43,60.68,53.41,-1.16,0.3,49.15,54.37,75.98,17.98,55.07
merge-crew/da-sv-task-arithmetic (val),7242,32,32768,True,True,2500,2.21,2.04,2.7,1.89,46.06,51.51,27.68,57.78,49.69,61.78,55.87,2.99,-1.29,44.62,47.28,76.62,33.23,60.0
microsoft/infoxlm-large,560,250,512,True,False,6696,2.21,2.28,2.49,1.87,74.42,37.94,15.26,44.25,91.9,86.59,30.56,9.79,6.36,60.47,79.53,75.42,18.44,48.19
google-bert/bert-base-multilingual-uncased,167,106,512,True,False,13993,2.22,2.3,2.32,2.04,64.92,33.5,46.75,37.09,82.9,77.33,37.28,49.41,43.58,40.35,70.85,63.3,48.97,38.0
Geotrend/bert-base-en-fr-de-no-da-cased,118,42,512,True,False,13973,2.24,2.23,2.42,2.08,63.38,34.78,41.08,40.32,88.05,83.08,35.34,31.45,36.12,41.59,76.55,61.6,37.44,39.32
KB/bert-base-swedish-cased,125,50,512,True,False,16181,2.24,2.57,2.73,1.42,61.74,33.28,33.15,28.67,85.91,79.67,38.7,39.13,24.13,19.04,81.95,75.58,78.86,38.56
Mabeck/Heidrun-Mistral-7B-chat,7242,32,32768,False,False,5822,2.24,2.19,2.57,1.95,50.8,42.79,23.25,59.9,61.41,59.49,49.19,15.17,10.78,48.99,55.06,77.5,17.47,58.67
birgermoell/Rapid-Cycling (val),7242,32,32768,False,True,2346,2.24,2.08,2.73,1.91,49.99,51.25,20.66,56.82,55.93,63.85,50.41,15.74,2.23,39.81,53.66,77.72,16.22,59.75
timpal0l/BeagleCatMunin2 (val),7242,32,32768,False,True,2477,2.24,2.2,2.48,2.05,51.53,47.95,14.1,58.28,61.17,65.44,58.69,15.03,5.95,42.42,60.87,73.72,6.78,58.75
Geotrend/bert-base-25lang-cased,151,85,512,True,False,13908,2.25,2.41,2.31,2.02,62.53,32.88,29.01,39.51,87.99,83.1,36.21,46.43,39.82,40.01,75.62,62.5,38.18,40.96
KBLab/bert-base-swedish-cased,125,50,512,True,False,16164,2.25,2.57,2.76,1.43,61.74,33.31,33.35,28.67,85.33,79.44,38.17,39.49,22.17,19.04,81.23,75.73,78.6,38.56
KBLab/megatron-bert-base-swedish-cased-600k,135,64,512,True,False,15726,2.25,2.58,2.66,1.51,57.97,39.4,23.5,31.87,82.2,76.64,40.2,24.45,19.18,30.69,78.91,76.09,70.08,41.14
birgermoell/BeagleCatMunin-Flashback-Bellman (val),7242,32,32768,False,True,2890,2.25,2.05,2.66,2.03,50.4,52.3,21.3,58.17,53.96,63.45,52.7,14.87,2.48,41.43,52.96,76.99,14.27,59.92
birgermoell/Flashback-Bellman (val),7242,32,32768,False,True,2887,2.25,2.13,2.68,1.93,47.71,48.21,19.55,56.46,56.44,66.56,53.24,11.96,2.5,39.21,55.29,78.29,18.45,58.42
Geotrend/bert-base-en-no-cased,111,33,512,True,False,14081,2.26,2.29,2.41,2.08,62.66,33.91,40.96,39.93,89.07,82.69,34.97,39.58,31.27,41.89,75.33,61.8,36.62,39.95
google-bert/bert-base-multilingual-cased,178,120,512,True,False,14083,2.26,2.46,2.36,1.97,63.17,32.38,27.93,39.57,88.72,83.08,35.87,44.22,39.55,40.55,76.29,61.78,47.74,41.17
mlabonne/NeuralBeagle14-7B (val),7242,32,8192,False,True,2549,2.26,2.14,2.64,2.01,53.02,51.29,19.73,51.69,62.47,66.69,54.04,16.75,13.0,34.48,61.25,76.03,16.28,50.96
microsoft/xlm-align-base,278,250,512,True,False,14744,2.28,2.39,2.26,2.2,70.36,47.83,11.87,29.87,90.07,85.65,54.46,12.16,8.99,49.24,78.6,73.67,15.41,32.41
facebook/xlm-v-base,778,902,512,True,False,13135,2.29,2.21,2.77,1.9,71.42,31.86,52.95,34.66,89.99,78.6,17.93,43.46,10.97,43.74,68.39,73.43,45.09,38.04
merge-crew/da-sv-ties (val),7242,32,32768,True,True,2457,2.29,2.18,2.67,2.02,45.39,51.95,13.25,58.51,47.61,60.57,44.46,23.99,11.6,47.02,48.36,76.57,20.94,59.07
birgermoell/Munin-NeuralBeagle-NorskGPT (val),7242,32,32768,False,True,2903,2.3,2.4,2.42,2.07,51.85,44.02,1.22,57.69,63.33,68.84,58.28,18.65,10.72,44.39,63.85,73.72,-0.56,60.1
birgermoell/WestLake-Munin-Cat-NorskGPT (val),7242,32,32768,False,True,2856,2.3,2.4,2.42,2.07,51.85,44.02,1.22,57.69,63.33,68.84,58.28,18.65,10.72,44.39,63.85,73.72,-0.56,60.1
merge-crew/da-sv-dare-ties-density-0.6 (val),7242,32,32768,True,True,2515,2.3,2.24,2.64,2.03,46.03,49.59,12.72,57.03,47.26,59.35,54.93,9.0,5.26,45.95,45.12,78.74,19.74,60.15
timpal0l/njord-alpha,7242,32,32768,True,False,5419,2.3,2.28,2.7,1.93,34.79,48.15,20.75,57.11,45.12,44.13,48.14,26.57,14.13,48.06,42.76,79.56,33.9,57.59
AI-Sweden-Models/tyr (val),7242,32,32768,False,True,6079,2.32,2.23,2.75,1.97,47.01,50.6,13.73,56.35,58.6,63.15,51.85,0.66,0.53,43.22,56.21,78.3,14.35,61.08
Geotrend/bert-base-en-da-cased,111,33,512,True,False,14062,2.32,2.39,2.48,2.08,62.57,33.67,35.79,38.77,88.55,83.09,35.16,31.82,32.94,39.46,74.88,61.89,40.22,39.95
KennethEnevoldsen/munin_mistral-7b (val),7242,32,32768,False,True,2543,2.32,2.29,2.61,2.07,46.7,47.52,8.04,60.05,51.82,62.55,56.37,6.04,-0.02,48.85,52.34,77.66,6.0,60.16
RJuro/munin-neuralbeagle-SkoleGPTOpenOrca-7b (val),7242,32,32768,False,True,3008,2.32,2.21,2.76,2.0,50.83,43.41,19.72,57.87,53.68,61.92,47.78,0.91,1.24,47.76,59.36,72.04,22.38,57.96
jonfd/electra-small-nordic,22,96,128,True,False,5989,2.33,2.49,2.34,2.15,65.4,34.43,67.27,6.6,84.95,79.57,40.15,72.87,63.77,14.16,71.07,66.42,69.19,11.85
timpal0l/Mistral-7B-v0.1-flashback-v2,7242,32,32768,True,False,5054,2.33,2.28,2.77,1.93,42.43,47.82,16.51,56.95,48.97,51.52,49.05,14.37,9.96,44.07,44.14,80.14,34.23,57.07
NickyNicky/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v2,-1,32,32768,False,False,5954,2.35,2.36,2.5,2.2,47.39,48.01,4.72,60.06,58.18,58.07,53.38,18.52,12.5,46.52,50.12,77.16,1.08,59.7
Geotrend/bert-base-da-cased,104,23,512,True,False,15432,2.38,2.46,2.54,2.13,62.76,32.06,30.95,37.79,87.52,82.66,32.73,36.41,30.37,37.71,74.13,62.18,36.93,37.59
alpindale/Mistral-7B-v0.2-hf,7242,32,32768,True,False,1841,2.39,2.29,2.82,2.07,43.65,45.86,15.19,59.14,50.63,52.69,44.05,11.6,9.26,45.23,48.96,78.9,10.82,58.91
bineric/NorskGPT-Mistral-7b,7242,32,32768,False,False,2443,2.39,2.54,2.47,2.17,50.76,40.41,0.0,57.26,63.28,61.25,56.9,13.86,10.17,49.03,58.4,74.3,0.0,59.16
danish-foundation-models/munin-7b-v0.1dev0,7242,32,8192,True,False,6113,2.39,2.43,2.71,2.04,39.12,36.47,26.76,58.75,50.43,54.2,39.21,20.51,11.66,51.57,47.1,73.05,30.29,57.39
mistralai/Mistral-7B-v0.1,7242,32,32768,True,False,2657,2.39,2.36,2.74,2.08,45.42,43.16,8.79,59.43,52.0,55.12,47.25,8.66,6.8,46.86,53.34,80.0,4.61,58.99
ThatsGroes/munin-SkoleGPTOpenOrca-7b-16bit,7242,32,32768,False,False,3006,2.4,2.34,2.79,2.07,45.37,39.63,21.77,58.28,51.99,52.74,50.39,0.99,1.27,47.95,44.64,77.98,16.57,57.31
mhenrichsen/hestenettetLM,7242,32,32768,True,False,5160,2.4,2.4,2.7,2.11,44.9,42.61,8.65,59.62,52.52,55.6,48.23,8.53,6.65,46.89,53.0,79.7,4.32,59.03
microsoft/infoxlm-base,278,250,512,True,False,14918,2.4,2.48,2.45,2.26,69.78,46.78,11.27,28.28,90.14,84.12,44.42,11.2,7.12,47.69,79.43,71.48,7.26,33.72
Mabeck/Heidrun-Mistral-7B-base,7242,32,32768,True,False,3823,2.41,2.42,2.8,2.0,40.14,39.38,21.85,58.07,50.1,54.81,48.64,10.31,1.11,42.2,48.43,79.43,17.37,57.05
KBLab/megatron-bert-base-swedish-cased-125k,135,64,512,True,False,15763,2.43,2.77,2.95,1.56,53.93,36.31,23.46,27.85,77.98,75.0,33.88,24.23,18.18,20.56,79.29,75.85,70.43,37.56
mlabonne/AlphaMonarch-7B (val),7242,32,8192,False,True,5340,2.45,2.29,2.73,2.32,52.72,49.11,16.09,46.28,61.9,66.92,48.8,19.53,9.83,30.27,60.53,67.03,15.1,42.46
clips/mfaq,278,250,128,True,False,5591,2.46,2.48,2.62,2.29,68.49,45.6,28.26,14.34,89.46,79.71,52.91,27.55,15.2,12.36,76.31,73.32,32.29,16.12
jhu-clsp/bernice,278,250,512,True,False,5567,2.48,2.47,2.77,2.2,61.98,47.2,40.52,13.53,84.11,77.82,39.63,45.75,33.74,5.35,71.34,70.91,53.52,16.41
birgermoell/NeuralBeagle-Flashback (val),7242,32,32768,False,True,2904,2.5,2.21,2.7,2.59,48.28,44.2,22.79,57.96,51.78,61.22,53.06,10.27,8.06,40.64,51.73,36.06,19.42,59.26
flax-community/nordic-roberta-wiki,125,50,512,True,False,16227,2.5,2.48,2.92,2.09,60.82,34.45,41.89,26.83,85.42,78.92,36.27,48.07,29.81,0.44,72.9,61.11,55.05,29.04
DDSC/roberta-base-scandinavian,125,50,512,True,False,14491,2.51,2.57,2.73,2.23,43.9,44.48,30.37,28.89,71.73,79.8,46.74,8.02,17.04,29.26,58.84,72.28,37.61,30.59
sentence-transformers/paraphrase-xlm-r-multilingual-v1,278,250,512,True,False,14994,2.51,2.4,2.83,2.3,61.17,46.39,38.61,19.9,81.26,74.05,49.93,38.26,25.17,0.0,70.22,71.33,39.6,18.65
KBLab/bert-base-swedish-cased-new,135,64,512,True,False,15933,2.52,2.93,3.02,1.61,59.37,38.46,4.61,23.13,83.23,79.16,33.94,9.56,4.16,22.84,79.99,76.04,73.52,30.6
RuterNorway/Llama-2-13b-chat-norwegian,-1,32,4096,False,False,7778,2.52,2.45,2.94,2.18,43.17,43.4,11.08,56.81,58.61,60.4,41.36,6.52,3.95,38.93,50.85,74.17,7.51,57.32
sentence-transformers/paraphrase-multilingual-mpnet-base-v2,278,250,512,True,False,15100,2.52,2.42,2.8,2.33,61.18,49.13,29.66,19.99,81.94,75.56,55.53,36.01,14.99,0.0,65.14,73.47,36.62,18.65
mistralai/Mistral-7B-Instruct-v0.2,7242,32,32768,False,False,2538,2.53,2.32,2.94,2.34,44.89,48.09,19.06,51.56,53.42,54.34,38.79,17.06,11.0,35.74,47.92,62.9,19.95,52.51
neph1/bellman-7b-mistral-instruct-v0.2,7242,32,32768,False,False,2518,2.54,2.3,2.99,2.33,46.11,47.58,18.41,52.78,57.01,56.77,38.81,14.16,9.29,32.75,54.38,55.84,16.05,53.22
bineric/NorskGPT-Llama-7B-v0.1,6738,32,4096,False,False,5384,2.57,2.52,2.74,2.45,41.63,47.73,0.0,54.25,56.18,56.96,50.94,8.19,5.55,41.35,53.95,60.91,0.32,55.28
flax-community/swe-roberta-wiki-oscar,125,50,512,True,False,15437,2.57,2.79,3.16,1.77,55.98,36.66,22.69,24.81,79.25,75.39,36.56,22.02,19.72,0.78,75.4,76.22,65.73,29.34
sentence-transformers/stsb-xlm-r-multilingual,278,250,512,True,False,15040,2.57,2.57,2.88,2.26,58.52,42.26,34.8,19.6,80.08,74.59,52.16,36.3,14.21,0.0,68.94,72.77,40.21,20.09
danish-foundation-models/munin-7b-alpha,7242,32,32768,True,False,6116,2.58,2.37,3.24,2.14,40.6,36.89,26.41,57.81,48.89,51.95,20.54,4.39,1.2,47.16,42.23,78.8,15.47,56.75
distilbert/distilbert-base-multilingual-cased,135,120,512,True,False,26355,2.6,2.65,2.82,2.32,58.12,32.53,35.53,28.19,83.62,80.69,33.16,36.1,30.1,19.26,70.08,59.66,33.71,31.48
mistralai/Mistral-7B-Instruct-v0.1,7242,32,32768,False,False,5443,2.6,2.52,2.96,2.33,37.93,44.49,14.09,51.38,50.08,51.27,43.65,14.09,8.28,37.23,45.01,73.33,11.59,52.12
occiglot/occiglot-7b-eu5,7242,32,32768,True,False,2219,2.6,2.58,3.0,2.21,37.93,44.62,0.28,58.05,45.28,46.0,44.95,0.0,0.0,43.88,49.02,76.56,2.18,58.98
occiglot/occiglot-7b-eu5-instruct,7242,32,32768,False,False,2088,2.61,2.61,2.94,2.27,40.19,42.31,1.14,57.89,45.5,45.96,44.46,0.0,0.0,52.19,47.67,71.73,7.9,57.78
Geotrend/distilbert-base-25lang-cased,109,85,512,True,False,26099,2.62,2.65,2.84,2.38,58.44,31.81,34.13,27.6,83.59,80.29,33.19,32.6,24.97,19.93,70.56,60.69,30.83,31.41
Geotrend/distilbert-base-en-fr-de-no-da-cased,76,42,512,True,False,26081,2.62,2.65,2.84,2.38,58.78,31.3,34.92,27.86,83.49,80.23,32.66,33.65,29.07,19.29,69.94,59.83,29.82,31.13
Geotrend/distilbert-base-en-no-cased,69,33,512,True,False,26597,2.63,2.67,2.83,2.38,57.53,32.95,33.63,27.21,83.93,79.39,32.32,36.15,30.17,19.71,69.28,59.53,29.36,30.42
tollefj/nordavind-7b-instruct-warm,7248,33,2048,False,False,6450,2.63,2.5,3.1,2.3,38.39,49.44,7.5,51.24,38.82,43.28,38.05,8.45,7.5,40.47,47.24,77.91,5.55,51.41
Geotrend/distilbert-base-en-da-cased,69,33,512,True,False,26196,2.64,2.63,2.92,2.38,59.5,31.89,36.0,28.41,83.27,79.59,29.37,31.5,24.06,18.62,69.62,59.42,29.01,31.82
Twitter/twhin-bert-large,561,250,512,True,False,5299,2.65,2.61,3.08,2.27,66.39,39.36,7.06,33.88,86.26,80.1,34.17,12.11,4.28,11.74,74.26,63.35,16.07,36.77
Geotrend/distilbert-base-da-cased,61,23,512,True,False,28950,2.66,2.65,2.92,2.4,58.36,32.13,34.75,27.5,82.84,78.83,30.7,34.24,27.2,16.44,69.25,58.47,29.8,30.61
meta-llama/Llama-2-7b-hf,6738,32,4096,True,False,2648,2.66,2.67,3.12,2.19,31.77,43.91,0.31,58.44,42.13,43.8,41.74,0.0,0.02,44.19,44.11,79.05,7.34,57.49
merge-crew/da-sv-dare-ties-density-0.3 (val),7242,32,32768,True,True,2461,2.68,2.56,3.11,2.36,30.16,48.49,5.52,52.44,35.98,47.39,38.98,11.54,5.2,37.54,32.37,75.33,12.73,53.05
sarnikowski/convbert-medium-small-da-cased,24,29,512,True,False,13821,2.68,2.23,3.01,2.79,64.28,36.85,63.55,24.52,79.5,73.03,32.4,41.65,25.53,5.41,58.01,57.67,13.4,24.92
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118,250,512,True,False,17428,2.72,2.66,3.02,2.48,56.75,44.48,26.74,17.89,78.31,72.13,47.53,26.92,14.63,0.0,66.5,72.19,28.75,15.91
Addedk/kbbert-distilled-cased,82,50,512,True,False,29698,2.73,2.99,3.3,1.9,57.84,31.18,13.25,22.73,81.82,75.89,33.42,14.99,13.63,0.0,80.12,71.28,51.58,28.16
meta-llama/Llama-2-7b-chat-hf,6738,32,4096,False,False,2643,2.73,2.53,3.16,2.5,35.44,44.88,9.74,55.04,44.99,49.09,41.56,3.04,4.03,33.77,39.72,66.18,6.74,54.05
timpal0l/Mistral-7B-v0.1-flashback-v2-instruct,7242,32,32768,False,False,5172,2.74,2.62,3.47,2.14,37.02,40.65,7.48,52.71,50.34,52.06,32.19,-0.22,0.0,20.57,46.74,77.06,14.0,56.74
jannikskytt/MeDa-Bert,111,32,511,True,False,16114,2.75,2.27,2.93,3.05,64.64,44.62,47.47,23.14,71.69,60.0,38.94,30.32,7.99,24.02,48.32,53.98,3.33,23.15
danish-foundation-models/encoder-medium-v1,111,32,512,True,False,16130,2.76,2.26,3.03,2.98,63.42,39.91,51.01,25.76,68.66,61.77,36.56,31.23,5.4,22.56,49.62,58.7,2.23,25.45
AI-Sweden-Models/gpt-sw3-20b,20918,64,2048,True,False,4880,2.79,2.94,3.1,2.33,27.41,30.24,11.34,52.8,30.82,39.56,34.51,15.17,12.46,42.81,31.86,78.88,12.26,53.58
Qwen/Qwen1.5-4B-Chat,3950,152,32768,False,False,4347,2.8,2.63,3.2,2.57,35.96,42.04,8.65,53.68,44.83,46.29,32.7,3.57,1.61,42.55,40.19,64.08,5.43,53.21
norallm/normistral-7b-warm,7248,33,2048,True,False,3175,2.8,2.69,3.32,2.38,37.8,40.51,3.35,49.08,42.29,46.29,27.05,1.63,2.57,39.18,48.78,76.09,2.53,48.93
DDSC/roberta-base-danish,125,50,512,True,False,15004,2.81,2.55,3.2,2.69,63.84,43.9,17.16,26.94,76.14,72.88,32.29,0.45,-0.08,23.91,65.95,64.02,0.8,28.46
Maltehb/danish-bert-botxo,111,32,512,True,False,16091,2.82,2.22,3.24,3.0,66.71,43.79,45.96,26.29,72.62,58.73,40.65,29.47,12.95,0.91,50.29,57.42,4.94,24.16
ltg/norbert3-xs,15,50,508,True,False,14208,2.82,2.89,2.77,2.8,59.94,39.16,2.16,24.69,87.63,80.19,49.92,7.93,5.06,22.46,67.53,59.27,2.83,24.11
birgermoell/roberta-swedish-scandi,125,50,512,True,False,15385,2.83,2.98,3.45,2.06,49.22,33.51,12.08,24.49,72.74,69.74,29.68,15.83,8.7,1.04,68.55,69.96,52.88,27.99
Addedk/mbert-swedish-distilled-cased,135,120,512,True,False,26091,2.86,2.96,3.16,2.47,56.36,31.16,21.08,19.63,82.98,76.65,30.38,21.99,19.06,9.47,73.41,62.1,34.86,18.1
sarnikowski/electra-small-discriminator-da-256-cased,13,29,512,True,False,20340,2.88,2.52,3.21,2.9,60.63,24.38,68.58,21.03,73.15,66.34,29.97,40.79,25.08,1.93,52.79,57.93,14.72,20.54
sarnikowski/convbert-small-da-cased,13,29,512,True,False,14273,2.89,2.54,3.16,2.96,60.59,29.52,57.1,20.16,76.07,70.94,32.49,35.43,21.11,1.84,55.06,53.7,12.38,22.53
01-ai/Yi-6B,6061,64,4096,True,False,2786,2.92,3.39,3.1,2.28,35.08,4.0,3.68,55.09,43.44,46.33,38.96,0.75,1.04,40.28,46.69,75.39,2.91,54.95
dbmdz/bert-base-historic-multilingual-cased,111,32,512,True,False,15165,2.98,3.24,3.33,2.38,47.61,24.17,8.14,25.19,68.63,67.7,25.68,6.73,3.35,22.57,68.83,64.25,28.62,28.78
AI-Sweden-Models/gpt-sw3-6.7b-v2,7111,64,2048,True,False,2351,2.99,3.28,3.19,2.49,20.84,18.07,10.54,51.22,29.62,32.3,34.67,8.37,7.76,44.62,28.73,77.47,8.78,50.57
sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking,135,120,512,True,False,26151,2.99,3.06,3.24,2.67,54.48,36.6,8.84,15.42,77.81,72.22,44.59,8.98,5.72,0.0,65.5,68.33,14.81,16.11
sentence-transformers/quora-distilbert-multilingual,135,120,512,True,False,26458,2.99,3.06,3.24,2.67,54.48,36.6,8.84,13.97,77.81,72.22,44.59,8.98,5.72,0.0,65.5,68.36,14.81,16.11
AI-Sweden-Models/gpt-sw3-20b-instruct,20918,64,2048,True,False,4572,3.01,3.11,3.19,2.73,15.94,32.78,7.86,52.16,23.95,26.55,40.89,9.45,8.32,43.19,15.7,68.23,12.39,52.04
Maltehb/aelaectra-danish-electra-small-cased,14,32,128,True,False,4593,3.02,2.64,3.3,3.13,63.31,32.72,67.74,0.0,71.85,67.14,29.0,33.57,21.79,0.03,57.82,55.68,19.26,0.0
LumiOpen/Viking-13B,14030,131,4099,True,False,3480,3.05,2.91,3.62,2.62,28.8,37.2,2.94,49.57,28.87,34.01,27.31,1.53,-0.63,25.53,32.3,72.28,2.46,48.88
dbmdz/bert-medium-historic-multilingual-cased,42,32,512,True,False,24291,3.06,3.22,3.42,2.53,49.88,27.93,5.42,22.93,69.65,66.78,26.33,6.62,5.16,15.75,66.11,59.66,26.28,24.36
google/gemma-2b,2506,256,8192,True,False,6087,3.09,2.97,3.61,2.68,19.97,40.21,2.27,50.55,15.53,19.78,32.89,1.18,0.0,33.33,14.67,75.45,3.82,51.73
Maltehb/aelaectra-danish-electra-small-uncased,14,32,128,True,False,5995,3.1,2.58,3.42,3.29,62.52,34.45,65.15,2.51,59.76,51.44,33.41,32.87,20.09,0.0,39.17,57.71,17.1,0.11
jjzha/dajobbert-base-uncased,110,32,512,True,False,16243,3.11,2.62,3.47,3.23,60.78,39.65,37.67,15.41,65.95,55.29,33.31,20.34,8.07,0.0,42.99,55.49,4.69,14.22
Qwen/Qwen1.5-4B,3950,152,32768,True,False,3248,3.12,2.73,3.23,3.39,32.28,39.62,5.38,54.16,32.12,36.86,36.97,5.27,1.4,40.0,37.26,5.2,1.85,54.15
AI-Sweden-Models/gpt-sw3-1.3b-instruct,1445,64,2048,True,False,4544,3.16,3.35,3.36,2.76,14.73,27.14,2.65,46.38,33.08,38.28,35.58,0.82,1.43,36.06,19.04,73.34,2.9,47.45
LumiOpen/Viking-7B,7550,131,4096,True,False,5723,3.23,3.1,3.68,2.9,16.67,38.36,1.22,47.53,20.17,24.06,33.84,1.05,-0.47,22.58,21.84,63.6,0.65,46.51
HPLT/gpt-7b-nordic-prerelease,7550,131,4096,True,False,5404,3.28,3.05,3.92,2.86,21.98,37.77,1.26,46.03,20.25,28.99,17.44,3.2,2.61,21.5,27.07,61.96,2.65,46.16
allenai/OLMo-7B,6888,50,2051,True,False,5403,3.28,3.16,4.05,2.62,26.76,30.76,0.55,45.65,34.42,35.17,21.46,0.34,0.26,0.12,37.36,72.08,-0.86,45.16
AI-Sweden-Models/gpt-sw3-1.3b,1445,64,2048,True,False,4608,3.3,3.34,3.66,2.91,8.8,28.65,2.84,45.34,13.49,14.74,27.28,3.09,1.86,34.91,6.08,71.38,1.17,45.55
AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct,7111,64,2048,True,False,2383,3.32,3.69,3.33,2.93,15.35,2.85,10.99,50.51,24.67,29.03,34.39,2.42,5.11,42.52,14.58,56.6,10.92,50.18
google/gemma-2b-it,2506,256,8192,False,False,6471,3.32,3.19,3.57,3.19,24.44,34.03,2.25,42.12,39.78,43.58,22.01,2.76,1.45,32.42,33.51,43.97,0.53,39.39
AI-Sweden-Models/gpt-sw3-6.7b,7111,64,2048,True,False,2285,3.33,3.29,3.67,3.02,18.23,22.71,5.03,49.11,22.35,21.98,18.23,1.68,2.49,41.8,18.83,53.68,3.49,49.81
norallm/normistral-7b-scratch,7248,33,2048,True,False,3192,3.33,3.29,3.74,2.97,14.88,34.66,0.29,42.16,14.58,21.06,32.02,1.49,0.98,22.87,13.79,71.59,-0.89,38.33
mhenrichsen/danskgpt-tiny-chat,1100,32,2048,False,False,1745,3.36,3.2,3.75,3.14,22.31,34.05,0.7,41.82,28.74,30.34,27.49,-2.17,0.26,19.1,27.31,45.94,-0.97,35.57
sentence-transformers/distiluse-base-multilingual-cased-v1,135,120,512,True,False,26344,3.4,3.41,3.73,3.06,46.78,27.78,3.04,15.52,60.76,59.62,25.98,2.65,3.47,0.2,49.86,60.06,3.18,16.08
AI-Sweden-Models/gpt-sw3-356m-instruct,471,64,2048,True,False,5855,3.43,3.38,3.67,3.24,11.28,34.94,2.08,36.59,24.38,31.28,30.88,-0.3,0.45,23.99,14.84,59.0,0.06,34.37
KBLab/albert-base-swedish-cased-alpha,14,50,512,True,False,15925,3.43,3.67,3.77,2.86,29.9,19.79,6.15,15.96,66.97,63.9,18.85,5.83,4.02,0.0,47.19,56.57,20.92,23.86
NbAiLab/nb-gpt-j-6B-alpaca,6055,50,1024,False,False,2607,3.45,3.48,3.72,3.15,12.95,27.68,1.65,38.6,23.82,26.04,32.6,0.34,2.26,21.33,13.28,60.17,1.52,37.23
dbmdz/bert-mini-historic-multilingual-cased,12,32,512,True,False,47122,3.46,3.55,3.68,3.15,41.7,26.03,2.19,13.82,61.55,59.9,24.59,3.45,2.72,3.99,50.07,56.1,5.05,14.49
Qwen/Qwen1.5-1.8B-Chat,1837,152,32768,False,False,8304,3.5,3.38,4.0,3.12,18.0,26.58,0.63,41.66,26.99,25.74,19.85,1.96,-0.01,16.33,20.94,52.54,0.34,43.55
Qwen/Qwen1.5-1.8B,1837,152,32768,True,False,5666,3.51,3.37,4.03,3.12,9.83,29.03,0.56,46.43,12.1,13.42,22.82,2.7,2.21,16.31,18.01,51.91,1.49,44.83
allenai/OLMo-7B-Twin-2T,6888,50,2051,True,False,5484,3.53,3.58,4.2,2.8,7.52,18.3,3.23,46.35,9.06,17.16,25.52,0.68,0.17,0.46,20.49,70.04,2.28,45.85
jannesg/bertsson,124,50,512,True,False,15314,3.54,3.66,3.94,3.03,32.63,24.11,2.91,15.37,49.3,46.11,23.21,2.26,-0.66,0.68,51.13,61.67,2.87,17.24
AI-Sweden-Models/gpt-sw3-356m,471,64,2048,True,False,5758,3.55,3.52,3.66,3.47,16.13,27.61,1.96,34.79,27.37,31.22,34.21,0.92,1.25,18.52,23.77,34.29,1.57,33.7
alexanderfalk/danbert-small-cased,83,52,512,True,False,30013,3.72,3.54,3.93,3.7,33.05,30.67,13.01,1.56,42.18,37.39,24.39,7.29,2.57,0.0,22.47,53.88,1.55,1.12
3ebdola/Dialectal-Arabic-XLM-R-Base,278,250,512,True,False,15177,3.75,3.77,3.98,3.51,36.51,22.07,1.63,3.09,55.55,53.53,12.69,2.79,1.66,0.0,42.78,44.95,1.43,8.71
mhenrichsen/danskgpt-tiny,1100,32,2048,True,False,8597,3.75,3.6,4.1,3.55,14.13,26.31,-0.54,32.12,27.37,27.59,18.09,-0.19,-0.8,5.84,23.92,31.93,0.46,30.81
Qwen/Qwen1.5-0.5B-Chat,620,152,32768,False,False,11740,3.82,3.81,4.18,3.47,17.38,10.72,1.32,34.58,29.52,31.27,11.49,0.29,-0.12,7.8,18.57,40.23,0.21,29.49
RuterNorway/Llama-2-7b-chat-norwegian,-1,32,4096,False,False,10890,3.82,4.01,4.08,3.37,10.12,10.65,-0.66,26.08,21.04,18.71,12.22,-1.18,0.36,26.86,22.38,31.11,0.09,44.36
Qwen/Qwen1.5-0.5B,620,152,32768,True,False,11371,3.88,3.79,4.23,3.61,19.01,8.88,0.66,32.78,34.46,33.41,6.31,-1.59,0.61,5.95,28.96,26.58,-1.88,34.59
allenai/OLMo-1B,1177,50,2051,True,False,8536,3.91,3.89,4.29,3.56,13.39,17.94,-2.02,23.65,30.79,31.12,9.95,-0.95,-0.04,0.0,29.39,38.95,-1.35,17.85
RabotaRu/HRBert-mini,80,200,512,True,False,54951,3.96,3.99,4.23,3.66,22.21,20.33,0.9,2.73,31.87,32.47,15.07,1.26,0.49,0.0,24.61,52.31,1.32,2.86
fresh-xlm-roberta-base,278,250,512,True,False,2214,4.06,4.08,4.28,3.81,16.04,17.37,1.34,1.58,25.49,25.94,12.6,0.5,1.83,0.0,11.91,51.11,0.86,2.0
fresh-electra-small,14,31,512,True,False,7561,4.13,4.23,4.32,3.84,12.87,18.61,0.3,0.0,18.38,12.76,15.29,0.17,0.37,0.0,10.54,55.54,-0.15,0.02
NbAiLab/nb-gpt-j-6B-v2,6051,50,1024,False,False,2556,4.15,4.14,4.32,4.0,0.24,27.8,0.56,6.84,5.29,6.77,20.84,0.45,0.48,2.43,0.31,27.42,0.07,17.82
AI-Sweden-Models/gpt-sw3-126m-instruct,186,64,2048,True,False,7717,4.18,4.19,4.28,4.08,13.98,6.37,0.41,20.46,27.66,30.88,5.13,0.0,0.0,7.55,23.05,12.47,0.08,20.43
AI-Sweden-Models/gpt-sw3-126m,186,64,2048,True,False,8958,4.36,4.2,4.54,4.34,3.43,9.18,-0.22,16.64,13.55,9.38,7.78,-1.46,-2.97,2.32,5.66,8.15,-0.81,16.4
NbAiLab/nb-gpt-j-6B@sharded,-1,50,1024,True,False,2630,4.36,4.43,4.44,4.2,0.36,11.0,-0.11,5.15,0.22,0.24,20.64,-0.99,-0.15,0.53,0.01,33.5,-0.02,4.79
RJuro/kanelsnegl-v0.1,7242,32,512,True,False,9757,4.55,4.55,4.81,4.28,0.0,13.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,34.63,0.0,0.0
RJuro/kanelsnegl-v0.2,7242,32,512,True,False,1373,4.58,4.68,4.77,4.28,0.0,4.81,0.0,0.0,0.0,0.0,1.27,0.0,0.0,0.0,0.0,28.62,0.0,0.0
NorGLM/NorGPT-369M,-1,64,1024,True,False,19896,4.66,4.63,4.7,4.64,1.13,2.06,-0.36,0.32,3.14,3.0,3.41,0.22,0.27,0.0,1.47,5.5,-2.19,0.1
ai-forever/mGPT,-1,100,1024,True,False,13551,4.67,4.63,4.69,4.69,0.65,2.61,-0.73,1.99,0.08,0.0,4.76,0.67,-0.88,0.0,0.0,0.0,0.49,6.24
peter-sk/gpt-neox-da,1515,50,1024,True,False,6025,4.76,4.7,4.84,4.74,0.64,-0.52,-0.02,0.48,0.29,0.25,-1.43,-0.42,1.11,0.0,0.26,4.75,-0.6,0.06
