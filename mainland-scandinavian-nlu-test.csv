model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,dansk,angry_tweets,scala_da,scandiqa_da,norne_nb,norne_nn,norec,scala_nb,scala_nn,norquad,suc3,swerec,scala_sv,scandiqa_sv
ltg/norbert3-large,354.0,50,508,5048,2.34,73.62,48.29,71.55,48.59,93.12,89.39,64.62,77.97,76.3,66.03,79.01,75.32,69.11,48.88
"gpt-4-0613 (few-shot, val)",unknown,100,8192,1244,2.78,64.94,59.97,71.56,49.82,81.16,75.75,72.72,77.3,57.18,49.93,76.86,79.19,80.93,56.5
AI-Sweden-Models/roberta-large-1160k,355.0,50,512,5741,3.21,74.16,51.2,73.87,49.34,92.01,87.17,60.11,72.85,65.56,60.38,82.65,77.25,77.9,49.64
AI-Sweden-Models/roberta-large-1350k,355.0,50,512,5744,3.21,75.22,49.94,72.59,48.97,92.49,87.22,58.77,76.3,64.11,60.69,82.97,77.37,73.81,49.5
google/rembert,576.0,250,256,3355,3.38,70.19,50.19,69.72,39.85,88.7,86.11,54.19,69.83,54.84,58.18,78.23,75.99,72.17,46.0
microsoft/infoxlm-large,560.0,250,512,6696,3.57,74.42,37.94,15.26,44.25,91.9,86.59,30.56,9.79,6.36,60.47,79.53,75.42,18.44,48.19
danish-foundation-models/encoder-large-v1,355.0,50,512,6671,3.58,74.6,51.42,76.11,47.42,88.66,84.59,55.59,71.43,53.3,57.38,74.18,75.11,64.11,46.79
ltg/norbert3-base,124.0,50,508,11405,3.58,73.26,43.94,51.62,40.7,92.36,88.49,59.73,74.4,68.85,57.67,78.21,71.05,56.02,42.52
KennethEnevoldsen/dfm-sentence-encoder-large-1,355.0,50,512,6245,3.65,74.99,53.85,75.71,44.85,86.39,83.22,59.61,67.88,62.44,55.69,71.65,74.92,63.43,46.2
KennethEnevoldsen/dfm-sentence-encoder-large-2,355.0,50,512,6569,3.65,75.3,55.12,76.34,45.15,86.78,83.28,58.73,70.73,59.58,56.04,71.86,74.67,62.77,44.77
gpt-3.5-turbo-0613 (few-shot),unknown,100,4096,1344,3.66,59.4,51.8,54.22,56.55,74.92,75.34,57.64,49.93,34.22,44.39,71.43,77.5,55.99,55.46
sentence-transformers/use-cmlm-multilingual,471.0,501,512,13305,3.66,69.17,48.03,55.31,42.34,90.08,86.04,56.35,59.38,46.54,55.05,80.05,75.09,61.83,45.69
xlm-roberta-large,560.0,250,512,6663,3.66,72.74,48.33,57.3,43.57,91.66,86.19,50.25,55.51,43.89,57.57,80.33,76.63,49.72,46.64
microsoft/mdeberta-v3-base,279.0,251,512,9237,3.74,72.9,43.38,67.05,42.15,91.9,86.81,53.69,70.55,61.21,48.82,78.84,75.24,72.3,44.74
intfloat/multilingual-e5-large,560.0,250,512,6732,3.87,69.5,55.07,57.67,46.71,89.86,84.32,61.52,62.34,34.88,53.01,80.36,79.65,63.15,46.99
NbAiLab/nb-roberta-base-scandi-1e4,278.0,250,512,15074,3.89,72.16,51.7,62.03,29.95,92.09,86.85,59.84,73.33,71.06,43.67,79.9,76.2,73.62,32.38
NbAiLab/nb-roberta-base-scandi,278.0,250,512,15079,3.89,73.28,52.08,67.99,32.39,92.24,87.58,59.98,70.18,70.81,44.27,80.02,76.21,71.92,33.8
pere/roberta-debug-32,278.0,250,512,14958,3.89,68.46,50.48,64.34,30.3,89.07,83.27,53.23,70.06,66.81,34.17,72.25,75.04,70.16,31.89
pere/roberta-debug-8,278.0,250,512,15103,3.89,71.34,49.77,64.31,31.86,91.16,84.75,55.25,68.03,66.9,41.65,74.48,74.58,69.07,31.66
vesteinn/FoBERT,124.0,50,512,15623,3.89,69.65,49.18,65.45,32.4,90.65,84.88,52.44,68.77,65.4,43.13,78.58,73.41,71.14,31.62
vesteinn/ScandiBERT-no-faroese,124.0,50,512,15436,3.89,69.79,47.73,68.28,31.9,91.09,85.72,50.9,69.34,66.24,48.45,79.08,72.53,73.01,36.92
AI-Sweden-Models/bert-large-nordic-pile-1M-steps,369.0,64,512,6571,3.91,67.4,41.53,41.62,37.3,87.5,80.57,47.11,52.62,25.06,38.4,80.65,77.43,76.56,41.54
Mabeck/Heidrun-Mistral-7B-chat (few-shot),7242.0,32,32768,5822,3.91,50.8,42.79,23.25,59.82,61.41,59.49,49.19,15.17,10.78,48.98,55.06,77.5,17.47,58.6
"RJuro/munin-neuralbeagle-7b (few-shot, val)",7242.0,32,32768,2493,3.91,51.44,54.91,22.77,56.7,61.18,65.16,55.61,20.84,9.12,42.98,62.96,77.13,15.73,58.43
"RJuro/munin-neuralbeagle-SkoleGPTOpenOrca-7b (few-shot, val)",7242.0,32,32768,3008,3.91,50.83,43.41,19.72,57.88,53.68,61.92,47.78,0.91,1.24,47.95,59.36,72.04,22.38,58.03
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),unknown,32,4096,7778,3.91,43.17,43.4,11.08,56.81,58.61,60.4,41.36,6.52,3.95,38.93,50.85,74.17,7.51,57.32
bineric/NorskGPT-Mistral-7b (few-shot),7242.0,32,32768,2443,3.91,50.76,40.41,0.0,57.24,63.28,61.25,56.9,13.86,10.17,49.06,58.4,74.3,0.0,59.13
"birgermoell/BeagleCatMunin-Flashback-Bellman (few-shot, val)",7242.0,32,32768,2890,3.91,50.4,52.3,21.3,58.23,53.96,63.45,52.7,14.87,2.48,41.56,52.96,76.99,14.27,60.1
"birgermoell/Flashback-Bellman (few-shot, val)",7242.0,32,32768,2887,3.91,47.71,48.21,19.55,58.27,56.44,66.56,53.24,11.96,2.5,42.02,55.29,78.29,18.45,60.18
"birgermoell/Munin-NeuralBeagle-NorskGPT (few-shot, val)",7242.0,32,32768,2903,3.91,51.85,44.02,1.22,57.38,63.33,68.84,58.28,18.65,10.72,44.57,63.85,73.72,-0.56,59.98
"birgermoell/Rapid-Cycling (few-shot, val)",7242.0,32,32768,2346,3.91,49.99,51.25,20.66,56.81,55.93,63.85,50.41,15.74,2.23,39.87,53.66,77.72,16.22,59.81
"birgermoell/WestLake-Munin-Cat-NorskGPT (few-shot, val)",7242.0,32,32768,2856,3.91,51.85,44.02,1.22,57.38,63.33,68.84,58.28,18.65,10.72,44.57,63.85,73.72,-0.56,59.98
"merge-crew/da-sv-dare-ties-density-0.6 (few-shot, val)",7242.0,32,32768,2515,3.91,46.03,49.59,12.72,57.03,47.26,59.35,54.93,9.0,5.26,45.95,45.12,78.74,19.74,60.15
"merge-crew/da-sv-dare-ties-density-0.9 (few-shot, val)",7242.0,32,32768,2443,3.91,45.61,53.73,17.08,56.67,48.24,61.5,49.4,24.12,13.2,47.93,46.61,76.38,34.16,58.77
"merge-crew/da-sv-slerp (few-shot, val)",7242.0,32,32768,2467,3.91,45.94,51.75,28.04,57.65,49.67,61.11,56.07,3.81,-1.29,44.98,46.57,76.53,33.43,59.87
"merge-crew/da-sv-task-arithmetic (few-shot, val)",7242.0,32,32768,2500,3.91,46.06,51.51,27.68,57.78,49.69,61.78,55.87,2.99,-1.29,44.62,47.28,76.62,33.23,60.0
"merge-crew/da-sv-ties (few-shot, val)",7242.0,32,32768,2457,3.91,45.39,51.95,13.25,58.51,47.61,60.57,44.46,23.99,11.6,47.02,48.36,76.57,20.94,59.07
mhenrichsen/danskgpt-chat-v2.1 (few-shot),unknown,32,32768,5085,3.91,51.08,54.69,30.95,56.56,62.43,60.68,53.41,-1.16,0.3,49.15,54.37,75.98,17.98,55.07
"timpal0l/BeagleCatMunin2 (few-shot, val)",7242.0,32,32768,2477,3.91,51.53,47.95,14.1,58.28,61.17,65.44,58.69,15.03,5.95,42.42,60.87,73.72,6.78,58.69
"timpal0l/BeagleCatMunin (few-shot, val)",7242.0,32,32768,2495,3.91,47.62,54.73,21.8,57.39,54.04,62.21,54.74,14.51,5.38,42.71,50.53,77.37,27.84,59.92
KennethEnevoldsen/dfm-sentence-encoder-medium-3,178.0,120,512,14050,3.94,71.21,47.55,68.72,38.33,91.17,87.3,59.1,74.32,72.94,34.06,81.35,71.16,63.89,37.18
NbAiLab/nb-bert-base,178.0,120,512,14050,3.94,70.36,46.32,66.41,36.42,93.01,88.43,60.84,73.89,72.1,33.01,80.38,71.21,64.03,35.33
AI-Nordics/bert-large-swedish-cased,335.0,31,512,7199,3.98,60.66,38.46,32.29,37.68,83.32,77.97,38.44,37.54,23.1,39.97,78.61,77.47,72.87,43.11
KBLab/megatron-bert-large-swedish-cased-110k,370.0,64,512,7075,3.98,60.18,39.2,26.68,39.34,84.03,77.98,39.15,21.39,17.1,35.32,80.39,78.45,76.28,44.56
KBLab/megatron-bert-large-swedish-cased-165k,370.0,64,512,7138,3.98,58.5,41.02,27.1,39.99,85.99,79.47,39.53,27.39,23.56,39.01,81.05,78.0,76.79,45.71
setu4993/LaBSE,471.0,501,512,13386,4.02,71.24,46.5,52.92,40.08,90.58,85.21,54.26,59.44,49.3,46.42,77.78,73.58,60.36,41.71
Mabeck/Heidrun-Mistral-7B-base (few-shot),7242.0,32,32768,3823,4.07,40.14,39.38,21.85,58.07,50.1,54.81,48.64,10.31,1.11,42.2,48.43,79.43,17.37,57.05
ThatsGroes/munin-SkoleGPTOpenOrca-7b-16bit (few-shot),7242.0,32,32768,3006,4.07,45.37,39.63,21.77,58.35,51.99,52.74,50.39,0.99,1.27,47.77,44.64,77.98,16.57,57.33
"birgermoell/NeuralBeagle-Flashback (few-shot, val)",7242.0,32,32768,2904,4.07,48.28,44.2,22.79,58.16,51.78,61.22,53.06,10.27,8.06,41.18,51.73,36.06,19.42,59.03
pere/roberta-base-exp-32,278.0,250,512,15081,4.09,71.9,51.33,44.45,32.51,91.66,87.74,57.43,63.31,62.79,41.05,79.75,74.73,53.55,32.2
pere/roberta-base-exp-8,278.0,250,512,15112,4.09,68.77,49.66,60.13,32.6,88.99,82.99,57.37,69.92,70.05,41.98,73.44,73.63,58.91,32.39
KBLab/megatron-bert-base-swedish-cased-600k,135.0,64,512,15726,4.14,57.97,39.4,23.5,31.87,82.2,76.64,40.2,24.45,19.18,30.69,78.91,76.09,70.08,41.14
pere/roberta-base-exp-32B,278.0,250,512,15103,4.17,71.81,47.83,54.99,29.92,90.6,86.76,52.19,54.98,58.33,29.17,77.97,73.27,47.19,31.07
"gpt-3.5-turbo-0613 (few-shot, val)",unknown,100,4095,1344,4.18,59.61,50.54,57.57,51.09,77.7,73.92,58.88,54.29,32.82,46.44,73.04,72.77,58.06,57.59
vesteinn/DanskBERT,124.0,50,512,15749,4.18,72.55,52.86,75.2,37.65,86.82,79.91,47.84,51.99,30.57,36.75,72.33,67.77,33.79,32.71
01-ai/Yi-6B (few-shot),6061.0,64,4096,2786,4.25,35.08,4.0,3.68,55.0,43.44,46.33,38.96,0.75,1.04,40.33,46.69,75.39,2.91,55.05
bert-base-multilingual-uncased,167.0,106,512,13993,4.25,64.92,33.5,46.75,37.09,82.9,77.33,37.28,49.41,43.58,40.35,70.85,63.3,48.97,38.0
ltg/norbert3-small,41.0,50,508,13515,4.25,67.89,39.34,50.9,34.82,90.02,86.52,51.36,67.29,56.67,48.63,74.22,63.8,37.77,31.45
Geotrend/bert-base-25lang-cased,151.0,85,512,13908,4.26,62.53,32.88,29.01,39.51,87.99,83.1,36.21,46.43,39.82,40.01,75.62,62.5,38.18,40.96
Geotrend/bert-base-da-cased,104.0,23,512,15432,4.26,62.76,32.06,30.95,37.79,87.52,82.66,32.73,36.41,30.37,37.71,74.13,62.18,36.93,37.59
Geotrend/bert-base-en-da-cased,111.0,33,512,14062,4.26,62.57,33.67,35.79,38.77,88.55,83.09,35.16,31.82,32.94,39.46,74.88,61.89,40.22,39.95
Geotrend/bert-base-en-fr-de-no-da-cased,118.0,42,512,13973,4.26,63.38,34.78,41.08,40.32,88.05,83.08,35.34,31.45,36.12,41.59,76.55,61.6,37.44,39.32
Geotrend/bert-base-en-no-cased,111.0,33,512,14081,4.26,62.66,33.91,40.96,39.93,89.07,82.69,34.97,39.58,31.27,41.89,75.33,61.8,36.62,39.95
bert-base-multilingual-cased,178.0,120,512,14083,4.26,63.17,32.38,27.93,39.57,88.72,83.08,35.87,44.22,39.55,40.55,76.29,61.78,47.74,41.17
facebook/xlm-v-base,778.0,902,512,13135,4.26,71.42,31.86,52.95,34.66,89.99,78.6,17.93,43.46,10.97,43.74,68.39,73.43,45.09,38.04
microsoft/infoxlm-base,278.0,250,512,14918,4.26,69.78,46.78,11.27,28.28,90.14,84.12,44.42,11.2,7.12,47.69,79.43,71.48,7.26,33.72
microsoft/xlm-align-base,278.0,250,512,14744,4.26,70.36,47.83,11.87,29.87,90.07,85.65,54.46,12.16,8.99,49.24,78.6,73.67,15.41,32.41
KB/bert-base-swedish-cased,125.0,50,512,16181,4.32,61.74,33.28,33.15,28.67,85.91,79.67,38.7,39.13,24.13,19.04,81.95,75.58,78.86,38.56
KBLab/bert-base-swedish-cased-new,135.0,64,512,15933,4.32,59.37,38.46,4.61,23.13,83.23,79.16,33.94,9.56,4.16,22.84,79.99,76.04,73.52,30.6
KBLab/bert-base-swedish-cased,125.0,50,512,16164,4.32,61.74,33.31,33.35,28.67,85.33,79.44,38.17,39.49,22.17,19.04,81.23,75.73,78.6,38.56
KBLab/megatron-bert-base-swedish-cased-125k,135.0,64,512,15763,4.32,53.93,36.31,23.46,27.85,77.98,75.0,33.88,24.23,18.18,20.56,79.29,75.85,70.43,37.56
meta-llama/Llama-2-7b-chat-hf (few-shot),6738.0,32,4096,2643,4.4,35.44,44.88,9.74,55.0,44.99,49.09,41.56,3.04,4.03,33.76,39.72,66.18,6.74,54.07
DDSC/roberta-base-scandinavian,125.0,50,512,14491,4.42,43.9,44.48,30.37,28.89,71.73,79.8,46.74,8.02,17.04,29.26,58.84,72.28,37.61,30.59
cardiffnlp/twitter-xlm-roberta-base,278.0,250,512,14837,4.44,70.1,45.3,51.74,22.01,87.7,81.41,48.34,55.3,37.46,24.49,72.49,70.69,56.6,31.89
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242.0,32,8192,2549,4.44,53.02,51.29,19.73,51.75,62.47,66.69,54.04,16.75,13.0,34.48,61.25,76.03,16.28,50.96
flax-community/swe-roberta-wiki-oscar,125.0,50,512,15437,4.51,55.98,36.66,22.69,24.81,79.25,75.39,36.56,22.02,19.72,0.78,75.4,76.22,65.73,29.34
danish-foundation-models/munin-7b-alpha (few-shot),7242.0,32,32768,3019,4.59,38.31,37.13,26.46,39.77,46.32,48.2,20.46,4.5,1.1,31.16,39.55,78.79,15.77,39.62
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242.0,32,32768,5443,4.59,37.93,44.49,14.09,51.42,50.08,51.27,43.65,14.09,8.28,37.31,45.01,73.33,11.59,52.05
mistralai/Mistral-7B-v0.1 (few-shot),7242.0,32,32768,2657,4.59,45.42,43.16,8.79,48.51,52.0,55.12,47.25,8.66,6.8,29.44,53.34,80.0,4.61,48.43
norallm/normistral-7b-warm (few-shot),7248.0,33,2048,3175,4.59,37.8,40.51,3.35,49.08,42.29,46.29,27.05,1.63,2.57,39.18,48.78,76.09,2.53,48.93
timpal0l/Mistral-7B-v0.1-flashback-v2 (few-shot),7242.0,32,32768,2505,4.59,41.66,47.52,17.36,51.28,48.28,50.51,49.76,14.54,9.16,32.04,44.16,80.29,34.8,51.82
birgermoell/roberta-swedish-scandi,125.0,50,512,15385,4.6,49.22,33.51,12.08,24.49,72.74,69.74,29.68,15.83,8.7,1.04,68.55,69.96,52.88,27.99
DDSC/roberta-base-danish,125.0,50,512,15004,4.67,63.84,43.9,17.16,26.94,76.14,72.88,32.29,0.45,-0.08,23.91,65.95,64.02,0.8,28.46
Geotrend/distilbert-base-25lang-cased,109.0,85,512,26099,4.67,58.44,31.81,34.13,27.6,83.59,80.29,33.19,32.6,24.97,19.93,70.56,60.69,30.83,31.41
Geotrend/distilbert-base-da-cased,61.0,23,512,28950,4.67,58.36,32.13,34.75,27.5,82.84,78.83,30.7,34.24,27.2,16.44,69.25,58.47,29.8,30.61
Geotrend/distilbert-base-en-da-cased,69.0,33,512,26196,4.67,59.5,31.89,36.0,28.41,83.27,79.59,29.37,31.5,24.06,18.62,69.62,59.42,29.01,31.82
Geotrend/distilbert-base-en-fr-de-no-da-cased,76.0,42,512,26081,4.67,58.78,31.3,34.92,27.86,83.49,80.23,32.66,33.65,29.07,19.29,69.94,59.83,29.82,31.13
Geotrend/distilbert-base-en-no-cased,69.0,33,512,26597,4.67,57.53,32.95,33.63,27.21,83.93,79.39,32.32,36.15,30.17,19.71,69.28,59.53,29.36,30.42
Twitter/twhin-bert-large,561.0,250,512,5299,4.67,66.39,39.36,7.06,33.88,86.26,80.1,34.17,12.11,4.28,11.74,74.26,63.35,16.07,36.77
distilbert-base-multilingual-cased,135.0,120,512,26355,4.67,58.12,32.53,35.53,28.19,83.62,80.69,33.16,36.1,30.1,19.26,70.08,59.66,33.71,31.48
flax-community/nordic-roberta-wiki,125.0,50,512,16227,4.67,60.82,34.45,41.89,26.83,85.42,78.92,36.27,48.07,29.81,0.44,72.9,61.11,55.05,29.04
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242.0,32,32768,2538,4.75,44.89,48.09,19.06,51.49,53.42,54.34,38.79,17.06,11.0,35.68,47.92,62.9,19.95,52.5
Addedk/kbbert-distilled-cased,82.0,50,512,29698,4.76,57.84,31.18,13.25,22.73,81.82,75.89,33.42,14.99,13.63,0.0,80.12,71.28,51.58,28.16
Rijgersberg/GEITje-7B (few-shot),7242.0,32,32768,10401,4.77,33.41,26.08,-0.22,51.9,41.44,45.09,34.51,0.0,0.56,24.53,41.08,76.38,-0.21,52.58
meta-llama/Llama-2-7b-hf (few-shot),6738.0,32,4096,2648,4.77,31.77,43.91,0.31,45.42,42.13,43.8,41.74,0.0,0.02,18.67,44.11,79.05,7.34,43.42
dbmdz/bert-base-historic-multilingual-cased,111.0,32,512,15165,4.85,47.61,24.17,8.14,25.19,68.63,67.7,25.68,6.73,3.35,22.57,68.83,64.25,28.62,28.78
neph1/bellman-7b-mistral-instruct-v0.2 (few-shot),7242.0,32,32768,2518,4.85,46.11,47.58,18.41,46.93,57.01,56.77,38.81,14.16,9.29,25.79,54.38,55.84,16.05,48.44
clips/mfaq,278.0,250,128,5591,4.87,68.49,45.6,28.26,14.34,89.46,79.71,52.91,27.55,15.2,12.36,76.31,73.32,32.29,16.12
"merge-crew/da-sv-dare-ties-density-0.3 (few-shot, val)",7242.0,32,32768,2461,4.88,30.16,48.49,5.52,52.44,35.98,47.39,38.98,11.54,5.2,37.54,32.37,75.33,12.73,53.05
ltg/norbert3-xs,15.0,50,508,14208,4.89,59.94,39.16,2.16,24.69,87.63,80.19,49.92,7.93,5.06,22.46,67.53,59.27,2.83,24.11
jonfd/electra-small-nordic,22.0,96,128,5989,4.94,65.4,34.43,67.27,6.6,84.95,79.57,40.15,72.87,63.77,14.16,71.07,66.42,69.19,11.85
jhu-clsp/bernice,278.0,250,512,5567,4.95,61.98,47.2,40.52,13.53,84.11,77.82,39.63,45.75,33.74,5.35,71.34,70.91,53.52,16.41
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918.0,64,2048,4880,4.96,27.41,30.24,11.34,52.8,30.82,39.56,34.51,15.17,12.46,42.81,31.86,78.88,12.26,53.58
sarnikowski/convbert-medium-small-da-cased,24.0,29,512,13821,4.96,64.28,36.85,63.55,24.52,79.5,73.03,32.4,41.65,25.53,5.41,58.01,57.67,13.4,24.92
sarnikowski/convbert-small-da-cased,13.0,29,512,14273,4.96,60.59,29.52,57.1,20.16,76.07,70.94,32.49,35.43,21.11,1.84,55.06,53.7,12.38,22.53
Maltehb/danish-bert-botxo,111.0,32,512,16091,5.04,66.71,43.79,45.96,26.29,72.62,58.73,40.65,29.47,12.95,0.91,50.29,57.42,4.94,24.16
jannikskytt/MeDa-Bert,111.0,32,511,16114,5.04,64.64,44.62,47.47,23.14,71.69,60.0,38.94,30.32,7.99,24.02,48.32,53.98,3.33,23.15
sarnikowski/electra-small-discriminator-da-256-cased,13.0,29,512,20340,5.04,60.63,24.38,68.58,21.03,73.15,66.34,29.97,40.79,25.08,1.93,52.79,57.93,14.72,20.54
sentence-transformers/stsb-xlm-r-multilingual,278.0,250,512,15040,5.05,58.52,42.26,34.8,19.6,80.08,74.59,52.16,36.3,14.21,0.0,68.94,72.77,40.21,20.09
Addedk/mbert-swedish-distilled-cased,135.0,120,512,26091,5.11,56.36,31.16,21.08,19.63,82.98,76.65,30.38,21.99,19.06,9.47,73.41,62.1,34.86,18.1
danish-foundation-models/encoder-medium-v1,111.0,32,512,16130,5.14,63.42,39.91,51.01,25.76,68.66,61.77,36.56,31.23,5.4,22.56,49.62,58.7,2.23,25.45
dbmdz/bert-medium-historic-multilingual-cased,42.0,32,512,24291,5.14,49.88,27.93,5.42,22.93,69.65,66.78,26.33,6.62,5.16,15.75,66.11,59.66,26.28,24.36
sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking,135.0,120,512,26151,5.2,54.48,36.6,8.84,15.42,77.81,72.22,44.59,8.98,5.72,0.0,65.5,68.33,14.81,16.11
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118.0,250,512,17428,5.2,56.75,44.48,26.74,17.89,78.31,72.13,47.53,26.92,14.63,0.0,66.5,72.19,28.75,15.91
sentence-transformers/paraphrase-multilingual-mpnet-base-v2,278.0,250,512,15100,5.2,61.18,49.13,29.66,19.99,81.94,75.56,55.53,36.01,14.99,0.0,65.14,73.47,36.62,18.65
sentence-transformers/paraphrase-xlm-r-multilingual-v1,278.0,250,512,14994,5.2,61.17,46.39,38.61,19.9,81.26,74.05,49.93,38.26,25.17,0.0,70.22,71.33,39.6,18.65
sentence-transformers/quora-distilbert-multilingual,135.0,120,512,26458,5.2,54.48,36.6,8.84,13.97,77.81,72.22,44.59,8.98,5.72,0.0,65.5,68.36,14.81,16.11
dbmdz/bert-mini-historic-multilingual-cased,12.0,32,512,47122,5.36,41.7,26.03,2.19,13.82,61.55,59.9,24.59,3.45,2.72,3.99,50.07,56.1,5.05,14.49
sentence-transformers/distiluse-base-multilingual-cased-v1,135.0,120,512,26344,5.36,46.78,27.78,3.04,15.52,60.76,59.62,25.98,2.65,3.47,0.2,49.86,60.06,3.18,16.08
KBLab/albert-base-swedish-cased-alpha,14.0,50,512,15925,5.39,29.9,19.79,6.15,15.96,66.97,63.9,18.85,5.83,4.02,0.0,47.19,56.57,20.92,23.86
AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct (few-shot),7111.0,64,2048,2383,5.49,15.35,2.85,10.99,44.04,24.67,29.03,34.39,2.42,5.11,31.39,14.58,56.6,10.92,42.72
AI-Sweden-Models/gpt-sw3-6.7b (few-shot),7111.0,64,2048,2285,5.49,18.23,22.71,5.03,49.11,22.35,21.98,18.23,1.68,2.49,41.8,18.83,53.68,3.49,49.81
AI-Sweden-Models/gpt-sw3-6.7b-v2 (few-shot),7111.0,64,2048,2351,5.51,20.84,18.07,10.54,39.18,29.62,32.3,34.67,8.37,7.76,24.67,28.73,77.47,8.78,35.78
norallm/normistral-7b-scratch (few-shot),7248.0,33,2048,3192,5.51,14.88,34.66,0.29,42.16,14.58,21.06,32.02,1.49,0.98,22.87,13.79,71.59,-0.89,38.33
jannesg/bertsson,124.0,50,512,15314,5.52,32.63,24.11,2.91,15.37,49.3,46.11,23.21,2.26,-0.66,0.68,51.13,61.67,2.87,17.24
AI-Sweden-Models/gpt-sw3-1.3b (few-shot),1445.0,64,2048,4608,5.55,8.8,28.65,2.84,45.31,13.49,14.74,27.28,3.09,1.86,34.9,6.08,71.38,1.17,45.53
NbAiLab/nb-gpt-j-6B-alpaca (few-shot),6055.0,50,1024,2607,5.67,12.95,27.68,1.65,38.57,23.82,26.04,32.6,0.34,2.26,21.34,13.28,60.17,1.52,37.22
jjzha/dajobbert-base-uncased,110.0,32,512,16243,5.69,60.78,39.65,37.67,15.41,65.95,55.29,33.31,20.34,8.07,0.0,42.99,55.49,4.69,14.22
AI-Sweden-Models/gpt-sw3-356m (few-shot),471.0,64,2048,5758,5.82,16.13,27.61,1.96,34.81,27.37,31.22,34.21,0.92,1.25,18.54,23.77,34.29,1.57,33.71
3ebdola/Dialectal-Arabic-XLM-R-Base,278.0,250,512,15177,5.96,36.51,22.07,1.63,3.09,55.55,53.53,12.69,2.79,1.66,0.0,42.78,44.95,1.43,8.71
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),unknown,32,4096,10890,6.04,10.12,10.65,-0.66,26.21,21.04,18.71,12.22,-1.18,0.36,26.79,22.38,31.11,0.09,44.37
Maltehb/aelaectra-danish-electra-small-uncased,14.0,32,128,5995,6.11,62.52,34.45,65.15,2.51,59.76,51.44,33.41,32.87,20.09,0.0,39.17,57.71,17.1,0.11
mhenrichsen/danskgpt-tiny (few-shot),1100.0,32,2048,8597,6.11,14.13,26.31,-0.54,14.16,27.37,27.59,18.09,-0.19,-0.8,2.15,23.92,31.93,0.46,21.56
Qwen/Qwen1.5-0.5B-Chat (few-shot),620.0,152,32768,11740,6.24,1.2,10.72,1.32,34.52,1.06,0.81,11.49,0.29,-0.12,7.73,0.24,40.23,0.21,29.46
Maltehb/aelaectra-danish-electra-small-cased,14.0,32,128,6035,6.26,63.31,32.72,67.74,0.0,71.85,67.14,29.0,33.57,21.79,0.03,57.82,55.68,19.26,0.0
mhenrichsen/danskgpt-tiny-chat (few-shot),1100.0,32,2048,1745,6.26,22.31,34.05,0.7,18.78,28.74,30.34,27.49,-2.17,0.26,5.35,27.31,45.94,-0.97,15.08
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837.0,152,32768,8304,6.27,0.37,26.58,0.63,41.68,0.36,0.3,19.85,1.96,-0.01,16.36,0.4,52.54,0.34,43.49
Qwen/Qwen1.5-1.8B (few-shot),1837.0,152,32768,5666,6.27,0.3,29.03,0.56,46.43,0.01,0.0,22.82,2.7,2.21,16.31,0.12,51.91,1.49,44.83
alexanderfalk/danbert-small-cased,83.0,52,512,30013,6.33,33.05,30.67,13.01,1.56,42.18,37.39,24.39,7.29,2.57,0.0,22.47,53.88,1.55,1.12
Qwen/Qwen1.5-0.5B (few-shot),620.0,152,32768,11371,6.39,1.56,8.88,0.66,32.78,1.05,1.37,6.31,-1.59,0.61,5.95,0.56,26.58,-1.88,34.59
AI-Sweden-Models/gpt-sw3-126m-instruct (few-shot),186.0,64,2048,7717,6.52,13.98,6.37,0.41,20.48,27.66,30.88,5.13,0.0,0.0,7.54,23.05,12.47,0.08,20.46
RabotaRu/HRBert-mini,80.0,200,512,54951,6.7,22.21,20.33,0.9,2.73,31.87,32.47,15.07,1.26,0.49,0.0,24.61,52.31,1.32,2.86
fresh-xlm-roberta-base,278.0,250,512,1319,6.85,16.04,17.37,1.34,1.58,25.49,25.94,12.6,0.5,1.83,0.0,11.91,51.11,0.86,2.0
NbAiLab/nb-gpt-j-6B-v2 (few-shot),6051.0,50,1024,2556,6.87,0.24,27.8,0.56,6.82,5.29,6.77,20.84,0.45,0.48,2.45,0.31,27.42,0.07,17.79
NbAiLab/nb-gpt-j-6B@sharded (few-shot),unknown,50,1024,2630,7.06,0.36,11.0,-0.11,5.16,0.22,0.24,20.64,-0.99,-0.15,0.55,0.01,33.5,-0.02,4.82
AI-Sweden-Models/gpt-sw3-126m (few-shot),186.0,64,2048,8958,7.09,3.43,9.18,-0.22,7.7,13.55,9.38,7.78,-1.46,-2.97,0.9,5.66,8.15,-0.81,7.64
fresh-electra-small,14.0,31,512,7219,7.33,12.87,18.61,0.3,0.0,18.38,12.76,15.29,0.17,0.37,0.0,10.54,55.54,-0.15,0.02
ai-forever/mGPT (few-shot),unknown,100,1024,13551,8.03,0.65,2.61,-0.73,2.0,0.08,0.0,4.76,0.67,-0.88,0.0,0.0,0.0,0.49,6.24
RJuro/kanelsnegl-v0.1 (few-shot),7242.0,32,512,9757,8.5,0.0,13.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,34.63,0.0,0.0
RJuro/kanelsnegl-v0.2 (few-shot),7242.0,32,512,1373,8.5,0.0,4.81,0.0,0.0,0.0,0.0,1.27,0.0,0.0,0.0,0.0,28.62,0.0,0.0
peter-sk/gpt-neox-da (few-shot),1515.0,50,1024,6025,8.71,0.64,-0.52,-0.02,0.48,0.29,0.25,-1.43,-0.42,1.11,0.0,0.26,4.75,-0.6,0.06
